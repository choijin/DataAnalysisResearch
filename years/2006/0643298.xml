<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Robotic BioTelemetry</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2007</AwardEffectiveDate>
<AwardExpirationDate>12/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
<PO_EMAI>tleen@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>CAREER: Robotic BioTelemetry&lt;br/&gt;&lt;br/&gt;Abstract&lt;br/&gt;&lt;br/&gt;This project aims to develop new algorithms and systems to quantitatively measure natural habitats and animal activities via remotely controlled networked robotic cameras. Since human activity can be very disturbing to the animal under scrutiny and its colony, the project will develop new non-intrusive biotelemetry methods based on emerging advances in high-resolution networked robotic cameras and long-range wireless networking. With the potential of changing the way to study nature, the project will allow groups of scientists, via the internet, to remotely identify and measure in real-time important variables such as quantity, size, volume, speed, motion pattern, and behavior characteristics. Since objects or its collection in a natural environment are often nonlinear, non-deterministic, non-convex/concave, irregular, deformable, and time-variant / transient, the challenging problem requires new algorithm and system development. Collaborating with natural scientists, the project undertake this long term effort by building prototypes and investigating new metrics, mathematical models, algorithms, and architectures for robot biotelemetry systems in a five-year integrated research and educational project that will emphasize active robotic actuation,  automation, collaboration, and optimal system design.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>12/27/2006</MinAmdLetterDate>
<MaxAmdLetterDate>09/29/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0643298</AwardID>
<Investigator>
<FirstName>Dezhen</FirstName>
<LastName>Song</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dezhen Song</PI_FULL_NAME>
<EmailAddress>dzsong@cs.tamu.edu</EmailAddress>
<PI_PHON>9798621696</PI_PHON>
<NSF_ID>000354064</NSF_ID>
<StartDate>12/27/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M Engineering Experiment Station</Name>
<CityName>College Station</CityName>
<ZipCode>778454645</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Pkwy S</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>847205572</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A&amp;M ENGINEERING EXPERIMENT STATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042915991</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&amp;M Engineering Experiment Station]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778454645</ZipCode>
<StreetAddress><![CDATA[400 Harvey Mitchell Pkwy S]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~79982</FUND_OBLG>
<FUND_OBLG>2008~79886</FUND_OBLG>
<FUND_OBLG>2009~80075</FUND_OBLG>
<FUND_OBLG>2010~160057</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The objective of my RBT project is to a new class of hybrid tele-operated / autonomous networked robotic cameras that can allow groups of scientists, via the internet, to non-intrusively and remotely identify and measure in real-time important variables such as quantity, size, volume, speed, motion pattern, and behavior characteristics in natural observation. The primary research goals of the project are fourfold:</p> <p>&nbsp;</p> <ol> <li><em>active      robotic biotelemetry</em>: This goal was set to develop algorithms for optimal actuation of      robotic cameras to achieve the least measurement error considering terrain      and dynamics of the measured objects. This goal was completed as results      published in Autonomous Robots [Song, Qin and Goldberg 2008], and early      conference versions. We actually extend the work scope from active vision-based      animal tracking to radio-based robotic observation, which results in two publications      in IEEE Transactions on Robotics [Song, Kim and Yi, 2011] and [Song, Kim      and Yi, 2012]</li> <li><em>automated      robotic biotelemetry</em>: This goal was set to develop new motion algorithms, geometric      data structures, numerical approximation schemes, and projection models to      allow automated real-time telemetry. This goal is also mostly completed as      results published in IEEE Transactions on Image Processing [Song and Xu      2012], and in IEEE Transactions on Automation Science and Engineering [Li      and Song, accepted, to appear].</li> <li><em>collaborative      biotelemetry</em>: This goal is to develop formal models that allow collaborative      information gathering among scientists with different backgrounds and      automated agents. This goal is fully accomplished as results published in &nbsp;IEEE Transactions on Robotics [Song and Goldberg      2007] and in Autonomous Robots [Xu and Song 2011].</li> <li><em>system      design and layout tools</em>: This goal was set to develop efficient      algorithms for optimal placement, rapid setup, and ongoing re-calibration      of robotic camera actuators. The goal was partially completed because the goal      was too ambitious. The different scope and interest in different      biological observations may result in different setup scenarios and data      processing needs. Although we have developed tools for two different representative      applications: 1) autonomously searching for certain animal species, and 2)      intelligently documenting activities over time, we just scratch the      surface of domain. Even though our findings are partial, the results are      presented in my monograph [Song 2009]. </li> </ol> <p><strong>&nbsp;</strong></p> <p><strong>For education and outreach: </strong>This project has achieved its goals. The project partially supported 4 Ph.D. students and two master students to finish their degrees, and more importantly, the project provides research experience for over dozen undergraduates and even high school students. The project also enabled curriculum development at both graduate level and undergrad level: At graduate level, two new courses (i.e. CSCE 643 advanced topics in networked robots, and CSCE 689: multiple view geometry in computer vision) have been developed as regularly offered to TAMU students since. &nbsp;At undergrad level, we revitalized CSCE 452, the introduction to spatial intelligence and robotics, and greatly augmented the capstone design CSCE 483. As a web-based project, the project also reaches the public, including local Audubon society, and high school where a group of local high school students use the website to learn concept of teleoperation and robots. The project has attracted a great deal of media attention including ScientificAmerica, Washington Post, New York Times, Times Online, Discovery, ACM Tech News, and NSF Multimedia Gallery. These media exposure have greatly enhanced th...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The objective of my RBT project is to a new class of hybrid tele-operated / autonomous networked robotic cameras that can allow groups of scientists, via the internet, to non-intrusively and remotely identify and measure in real-time important variables such as quantity, size, volume, speed, motion pattern, and behavior characteristics in natural observation. The primary research goals of the project are fourfold:     active      robotic biotelemetry: This goal was set to develop algorithms for optimal actuation of      robotic cameras to achieve the least measurement error considering terrain      and dynamics of the measured objects. This goal was completed as results      published in Autonomous Robots [Song, Qin and Goldberg 2008], and early      conference versions. We actually extend the work scope from active vision-based      animal tracking to radio-based robotic observation, which results in two publications      in IEEE Transactions on Robotics [Song, Kim and Yi, 2011] and [Song, Kim      and Yi, 2012] automated      robotic biotelemetry: This goal was set to develop new motion algorithms, geometric      data structures, numerical approximation schemes, and projection models to      allow automated real-time telemetry. This goal is also mostly completed as      results published in IEEE Transactions on Image Processing [Song and Xu      2012], and in IEEE Transactions on Automation Science and Engineering [Li      and Song, accepted, to appear]. collaborative      biotelemetry: This goal is to develop formal models that allow collaborative      information gathering among scientists with different backgrounds and      automated agents. This goal is fully accomplished as results published in  IEEE Transactions on Robotics [Song and Goldberg      2007] and in Autonomous Robots [Xu and Song 2011]. system      design and layout tools: This goal was set to develop efficient      algorithms for optimal placement, rapid setup, and ongoing re-calibration      of robotic camera actuators. The goal was partially completed because the goal      was too ambitious. The different scope and interest in different      biological observations may result in different setup scenarios and data      processing needs. Although we have developed tools for two different representative      applications: 1) autonomously searching for certain animal species, and 2)      intelligently documenting activities over time, we just scratch the      surface of domain. Even though our findings are partial, the results are      presented in my monograph [Song 2009].       For education and outreach: This project has achieved its goals. The project partially supported 4 Ph.D. students and two master students to finish their degrees, and more importantly, the project provides research experience for over dozen undergraduates and even high school students. The project also enabled curriculum development at both graduate level and undergrad level: At graduate level, two new courses (i.e. CSCE 643 advanced topics in networked robots, and CSCE 689: multiple view geometry in computer vision) have been developed as regularly offered to TAMU students since.  At undergrad level, we revitalized CSCE 452, the introduction to spatial intelligence and robotics, and greatly augmented the capstone design CSCE 483. As a web-based project, the project also reaches the public, including local Audubon society, and high school where a group of local high school students use the website to learn concept of teleoperation and robots. The project has attracted a great deal of media attention including ScientificAmerica, Washington Post, New York Times, Times Online, Discovery, ACM Tech News, and NSF Multimedia Gallery. These media exposure have greatly enhanced the social impact of the project.       Last Modified: 01/28/2013       Submitted by: Dezhen Song]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
