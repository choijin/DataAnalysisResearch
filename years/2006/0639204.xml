<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SGER:  Exploring Universal Acoustic Characterization of Spoken Languages</AwardTitle>
<AwardEffectiveDate>08/15/2006</AwardEffectiveDate>
<AwardExpirationDate>01/31/2009</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>199557</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Exploring Universal Acoustic Characterization of Spoken Languages&lt;br/&gt;&lt;br/&gt;Abstract&lt;br/&gt;&lt;br/&gt;We explore a novel approach to modeling all human languages by assuming that the sound characteristics of spoken languages can be covered by a universal set of acoustic units with no direct link to conventional phonetic definitions. Their corresponding models, called acoustic segment models (ASMs), can be used to decode spoken utterances into strings of such units. The statistics of these units and their co-occurrences corresponding to utterances in a training set of a particular language can be used to construct feature vectors to build vector-based language classifiers for automatic spoken language identification (LID). For spoken queries, ASM-derived feature vectors are extracted in a similar manner and then used to discriminate individual spoken languages. This collection of ASMs can be established from bottom up in an unsupervised manner, and will serve as models of acoustic alphabets to construct acoustic lexicons for speech recognition and language identification. In the project we study three fundamental issues related to UAC, namely:  (1) acoustic coverage and resolution of acoustic units needed to model spoken languages; (2) complexity and discriminative power of UAC-derived features for spoken language identification; and (3) relationship of language cues with UAC units for modeling spoken languages. This research facilitates a better understanding of human identification of spoken languages through acoustic and linguistic cues, and provides mathematical modeling and computing techniques to build LID systems. We also intend to leverage our research results in another NSF grant on automatic speech attribute transcription (ASAT) to model salient speech cues for language characterization and their relevance to auditory perception. The entire collection of available language cues, including phones, syllables, words, prosody, and lexical cues, can also be incorporated into this synergistic approach to spoken language modeling and identification.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/01/2006</MinAmdLetterDate>
<MaxAmdLetterDate>04/29/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0639204</AwardID>
<Investigator>
<FirstName>Chin-Hui</FirstName>
<LastName>Lee</LastName>
<EmailAddress>chl@ece.gatech.edu</EmailAddress>
<StartDate>08/01/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7602</Code>
<Text>INFORMATION INTEGRATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9237</Code>
<Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
