<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Memory Caching and Prefetching to Improve I/O Performance in High-End Systems</AwardTitle>
<AwardEffectiveDate>10/01/2006</AwardEffectiveDate>
<AwardExpirationDate>09/30/2008</AwardExpirationDate>
<AwardTotalIntnAmount>93999.00</AwardTotalIntnAmount>
<AwardAmount>93999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
</ProgramOfficer>
<AbstractNarration>With the rapid advancement of processor and networking technology, and with the falling price of memory and disks, computing resources of CPU cycles, available bandwidths at different levels of inter- and external connections (memory, I/O, and Internet), and large capacity of memory and disks are increasingly plentiful to us to build high-end systems. Unfortunately, the improvement of data access latency, particularly, the access latency to disks, has significantly lagged behind. The speed gap between data processing in CPU and data accessing in disks has reached to an intolerable level and will only become worse as time goes by.  This bottleneck has seriously hindered the development of high-end computing systems for data-intensive applications that demand fast accesses to a huge amount of data. One solution to address this problem is to build large memory buffers to cache data for reuse by taking advantage of low price and large capacity of DRAM memory, and to prefetch data for predicted future use by taking advantage of high and idle bandwidths of networks.&lt;br/&gt;This research project will focus on a small buffer caching topic: to develop and test a general clock-based system framework for caching management in a large scope of storage hierarchy for core, distributed and Internet systems. The PI will design and implement a clock-based and  unified memory buffer management framework with following unique merits: (1) it does not require any global synchronization, and it is system independent; (2) it will be easily used  by any types of buffer management at any level of the storage hierarchy,  such as buffer caches for I/O data, data buffer for large scientific data bases, memory buffers for large data streams, and others; and (3) it will be designed to flexibly adopt and test different types of novel ideas of exploiting data access localities. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/18/2006</MinAmdLetterDate>
<MaxAmdLetterDate>09/18/2006</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0620152</AwardID>
<Investigator>
<FirstName>Xiaodong</FirstName>
<LastName>Zhang</LastName>
<EmailAddress>zhang@cse.ohio-state.edu</EmailAddress>
<StartDate>09/18/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University Research Foundation -DO NOT USE</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888734</PhoneNumber>
<StreetAddress>1960 KENNY RD</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
</Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>4080</Code>
<Text>ADVANCED COMP RESEARCH PROGRAM</Text>
</ProgramElement>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
