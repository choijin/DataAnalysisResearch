<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ADAPTIVE AND INTELLIGENT SYSTEMS: Models of Photometric, Geometric and Dynamic Characteristics of Video Imagery for Segmentation, Classification and Synthesis, Including Layers</AwardTitle>
<AwardEffectiveDate>07/01/2006</AwardEffectiveDate>
<AwardExpirationDate>06/30/2010</AwardExpirationDate>
<AwardTotalIntnAmount>240000.00</AwardTotalIntnAmount>
<AwardAmount>240000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;&lt;br/&gt;Intellectual Merit:&lt;br/&gt;&lt;br/&gt;The objective of this research is to develop stochastic dynamical &lt;br/&gt;models of video imagery for the purpose of synthesis and classification &lt;br/&gt;of spatio-temporal events in video.&lt;br/&gt;The approach is based on exploiting tools from dynamical systems &lt;br/&gt;theory, statistical signal processing, differential geometry and &lt;br/&gt;functional analysis in order to infer the spatio-temporal statistics of &lt;br/&gt;a video segment and learn (identify) a dynamical model that represents &lt;br/&gt;its "signature". This allows generating novel portions of a video &lt;br/&gt;segment, or recognizing it in previously unseen video. The &lt;br/&gt;investigators will develop identification algorithms for such models, &lt;br/&gt;segmentation schemes to partition their spatio-temporal domain into &lt;br/&gt;statistically coherent regions, and endow them with a metric structure &lt;br/&gt;to enable classification and recognition.&lt;br/&gt;&lt;br/&gt;Broader Impacts:&lt;br/&gt;&lt;br/&gt;The models developed will allow the generation of synthetic portions of &lt;br/&gt;video, and the manipulation of their spatio-temporal statistics, which &lt;br/&gt;is relevant for compression and transmission, and post-production &lt;br/&gt;editing and development of interactive games. Furthermore, these models &lt;br/&gt;support classification tasks, including detection of events of interest &lt;br/&gt;in video and segmentation into spatio-temporal segments. This is &lt;br/&gt;important for video-based recognition in security, surveillance, video &lt;br/&gt;coding, and environmental monitoring (remote detection of fire, smoke, &lt;br/&gt;steam). A particular class of spatio-temporal processes studied &lt;br/&gt;includes human motion. The investigators will develop analytical and &lt;br/&gt;computational tools to enable the detection and recognition of &lt;br/&gt;individuals and their gait from video data. Training students in such a &lt;br/&gt;diverse set of analytical and computational tools is a challenge, but &lt;br/&gt;one that must be tackled in a modern engineering academic environment.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/21/2006</MinAmdLetterDate>
<MaxAmdLetterDate>05/01/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0622245</AwardID>
<Investigator>
<FirstName>Stefano</FirstName>
<LastName>Soatto</LastName>
<EmailAddress>soatto@ucla.edu</EmailAddress>
<StartDate>04/21/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<FoaInformation>
<Code>0112000</Code>
<Name>System Theory</Name>
</FoaInformation>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>7234</Code>
<Text>SENSORS NON-SOLICITATION RESEA</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
