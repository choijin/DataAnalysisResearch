<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:     Providing Tools for Richer eLearning Assessment</AwardTitle>
<AwardEffectiveDate>08/01/2006</AwardEffectiveDate>
<AwardExpirationDate>07/31/2010</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>1020000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Glenn H. Larsen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase II project will study effective models for carrying out assessments employing challenging puzzle-like questions that incorporate distractor analyses in which meaning is assigned to complex responses. Such distractor analyses apply where there is the possibility that the test taker can give alternative correct, partially correct, and incorrect answers. Metadata and distractor analyses will be combined to provide in-depth reports on student test performance. This new rule-based solution to distractor analysis meets a significant challenge in being able to include engaging problems in assessments of student progress in quantitative courses, such as Algebra and Geometry. The research will further develop question authoring and test construction tools. &lt;br/&gt;&lt;br/&gt;As a consequence of this work, educators using these new technologies will be able to move beyond online testing based solely on multiple-choice, single-answer questions that are known to be unmotivating for many students. The goals are twofold: to provide varied, interesting, and even gamelike learning interactions that incorporate motivational and pedagogically valuable feedback; and to do so in a form in which empirical evidence can be used to improve the assessment corpus - both the metadata and the rules used for defining distractor analysis, especially where the items are novel question types. &lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/03/2006</MinAmdLetterDate>
<MaxAmdLetterDate>03/24/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0620380</AwardID>
<Investigator>
<FirstName>Linda</FirstName>
<LastName>Chaput</LastName>
<EmailAddress>lchaput@agilemind.com</EmailAddress>
<StartDate>08/03/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>AGILE MIND INC</Name>
<CityName>GRAPEVINE</CityName>
<ZipCode>760517615</ZipCode>
<PhoneNumber>8174242863</PhoneNumber>
<StreetAddress>4101 WILLIAM D. TATE AVENUE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<FoaInformation>
<Code>0510604</Code>
<Name>Analytic Tools</Name>
</FoaInformation>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>7218</Code>
<Text>RET SUPP-Res Exp for Tchr Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>7261</Code>
<Text>PROGRAM EVALUATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
