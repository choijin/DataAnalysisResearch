<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Understanding Internal Memory Representations in Object Recognition</AwardTitle>
<AwardEffectiveDate>08/15/2006</AwardEffectiveDate>
<AwardExpirationDate>09/30/2011</AwardExpirationDate>
<AwardAmount>320000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Gottlob</SignBlockName>
</ProgramOfficer>
<AbstractNarration>How do humans store memories of their visual world?  Most people have the experience of being able to replay in the mind's eye past visual experiences.  Sometimes one can recall clear and vivid images, while other times the memories are less distinct.  But in all cases one may have the intuition that visual memory is like a video recording: the memories are coded in terms of the images that are projected onto the retina, analogous to how videos are stored impressions of the images projected  through the lens of a camera.  This intuition has parallels in the science of human vision, for most theories of visual memory are image-based.&lt;br/&gt;&lt;br/&gt;With support of the National Science Foundation, Dr. Liu will investigate a distinct and potentially groundbreaking alternative to image-based theories of visual memory.  On the basis of prior results, Dr. Liu and his collaborators have hypothesized that visual experiences are coded not in terms of the images projected on the retina, but rather, in terms of the objects from which those images originate.  In other words, humans use their lifelong visual experiences to convert retinal images into more meaningfully representations of visual scenes.  Dr. Liu will conduct a series of experiments to test the differential predictions that these theories make with regard to memory performance for previously seen versus unseen images.  The results of this research may help us to better understand how people may be trained and supported in conducting difficult visual tasks such as baggage screening, and the results may also inform the development of more robust machine vision systems.</AbstractNarration>
<MinAmdLetterDate>08/02/2006</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2006</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0617628</AwardID>
<Investigator>
<FirstName>Zili</FirstName>
<LastName>Liu</LastName>
<EmailAddress>zili@psych.ucla.edu</EmailAddress>
<StartDate>08/02/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7252</Code>
<Text>PERCEPTION, ACTION &amp; COGNITION</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
