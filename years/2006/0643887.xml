<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Ground Truth Dataset and Benchmarks for Mid-Level Vision</AwardTitle>
    <AwardEffectiveDate>01/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2008</AwardExpirationDate>
    <AwardAmount>300552</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>David R. Martin&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Abstract&lt;br/&gt;&lt;br/&gt;Machine vision systems can now do amazing things: Reading irises and faces, helping to drive autonomous cars in real environments, locating and measuring anatomical structures in medical scans -- these are just a few examples of capabilities that have emerged in recent years.&lt;br/&gt;Special-purpose domains still mark the limit of our success, however.&lt;br/&gt;The goal of human-level machine vision is still out of reach because the solutions found to these problems do not require the machine to understand the rich structure of visual information.&lt;br/&gt;&lt;br/&gt;It is essential to take an empirical approach to the problem of visual perception. The primary goal of this project is to build a dataset of ground truth image annotations that provides the perception of scenes at the level of surfaces, objects, and basic 3D scene geometry. This dataset will be unprecedentedly rich and detailed, providing precisely the information and representations needed to bring general purpose capabilities to machine vision systems. A secondary goal of this project is to create the associated benchmarks and methodologies for evaluating machine systems with respect to the ground truth data.&lt;br/&gt;&lt;br/&gt;Intellectual Merit: At the heart of this proposal is the design of a dataset for mid-level vision. The mid-level representation of visual information proposed in this project is of fundamental importance, because there is currently no viable mid-level representation in machine vision. A good mid-level representation is both computable from images as well as useful for higher level tasks. A generic, concrete, and testable mid-level representation is perhaps the most important deliverable of the proposed project.&lt;br/&gt;&lt;br/&gt;Broader Impact: The proposed project will have broad impact on the machine vision and human vision research communities. Machine vision models require complex ground truth data for training and benchmarks for evaluation, while psychophysics modelers face the challenge of data from natural images. Additionally, this project will make all its data and tools freely available to the research community. In general, this is an exciting time for machine vision. We are at the threshold of building machines that attain human-level visual perception, which would dramatically alter the relationship between people and machines. With datasets targeting the strategic research problems, significant progress is at hand.&lt;br/&gt;&lt;br/&gt;URL: http://vision.bc.edu/~dmartin/MidLevel</AbstractNarration>
    <MinAmdLetterDate>12/22/2006</MinAmdLetterDate>
    <MaxAmdLetterDate>01/16/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0643887</AwardID>
    <Investigator>
      <FirstName>David</FirstName>
      <LastName>Martin</LastName>
      <EmailAddress>dmartin@cs.bc.edu</EmailAddress>
      <StartDate>12/22/2006</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Boston College</Name>
      <CityName>Chestnut Hill</CityName>
      <ZipCode>024673800</ZipCode>
      <PhoneNumber>6175528000</PhoneNumber>
      <StreetAddress>140 Commonwealth Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>1187</Code>
      <Text>PECASE- eligible</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
