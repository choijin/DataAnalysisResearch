<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI Development:  Enabling Lightweight Planetary Scale Services</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2006</AwardEffectiveDate>
<AwardExpirationDate>08/31/2011</AwardExpirationDate>
<AwardTotalIntnAmount>955933.00</AwardTotalIntnAmount>
<AwardAmount>987933</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita Rodriguez</SignBlockName>
<PO_EMAI>rrodrigu@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project, developing virtual PlanetLab(an emulation Planet Lab), targets verifying whether an experiment attains the same performance and failure behavior as when run directly on the PlanetLab/ GENI system. The work involves network emulation, building a toolkit to ease the development and programming on PlanetLab, investigating control, and managing plane services. At present, only with extreme effort on the part of the researcher is this verification theoretically possible with Emulab. In fifteen years the Internet has gone from an obscure research network known to the academic community to a critical piece of national infrastructure; but, because its architecture is unable to quickly adapt to meet emerging challenges, it is becoming the victim of its own success. Vulnerabilities are being increasingly exploited limiting assimilation of new technologies and support of new applications. To foster the development of a new generation of distributed systems and network protocols, researchers around the world have created a testbed called PlanetLab, enabling research into truly planetary scale services where each researcher may utilize a virtualized slice across a widely distributed set of nodes. PlanetLab currently spans three hundred separate locations worldwide hosting over four hundred active research projects. Consequently, to support network and distributed systems research, NSF CISE has recently proposed constructing GENI (Global Environment for Network Investigations). This work aims to&lt;br/&gt;&lt;br/&gt;-Dramatically improve the cost-effectiveness of planetary scale testbeds such as PlanetLab and GENI and&lt;br/&gt;-Reduce the startup time for new PlanetLab/GENI researchers to develop and deploy an experiment.&lt;br/&gt;&lt;br/&gt;A transactional service manager that can adapt/survive the myriad types of node failures encountered in practice, simple job and pipe control, and distributed debugger are expected to facilitate the use of PlanetLab. The software toolkit enables research in&lt;br/&gt;&lt;br/&gt;-Robust content distribution, Real time multimedia delivery, Security, Routing,&lt;br/&gt;-Network embedded storage and file sharing, Distributed information management,&lt;br/&gt;-Internet Measurement, Distributed resource allocation, and Network layer modifications.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/10/2006</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0619836</AwardID>
<Investigator>
<FirstName>Edward</FirstName>
<LastName>Lazowska</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edward D Lazowska</PI_FULL_NAME>
<EmailAddress>lazowska@cs.washington.edu</EmailAddress>
<PI_PHON>2065434755</PI_PHON>
<NSF_ID>000476615</NSF_ID>
<StartDate>08/10/2006</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Thomas</FirstName>
<LastName>Anderson</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thomas E Anderson</PI_FULL_NAME>
<EmailAddress>tom@cs.washington.edu</EmailAddress>
<PI_PHON>2065439348</PI_PHON>
<NSF_ID>000196821</NSF_ID>
<StartDate>08/10/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Arvind</FirstName>
<LastName>Krishnamurthy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arvind Krishnamurthy</PI_FULL_NAME>
<EmailAddress>arvind@cs.washington.edu</EmailAddress>
<PI_PHON>2066160957</PI_PHON>
<NSF_ID>000488256</NSF_ID>
<StartDate>08/10/2006</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981950001</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>024F</Code>
<Text>GENI CONCEPT/DEVELOPMENT</Text>
</ProgramElement>
<ProgramElement>
<Code>1189</Code>
<Text>Major Research Instrumentation</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2006~955933</FUND_OBLG>
<FUND_OBLG>2009~16000</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>For planetary-scale testbeds, such as GENI/PlanetLab, to have the greatest possible impact in enabling experimental network and distributed systems research, they must be accessible to the broadest set of researchers.&nbsp; Unfortunately, this is not the case now, with these testbeds being hard to use for anyone who is not an expert programmer.&nbsp; A typical experience is that it takes a new user over a month to figure out how to write even the simplest PlanetLab program.&nbsp; What is required is a smooth implementation path, from initial experimentation to eventual deployment, with a single, integrated toolset that is universally accessible.<br /><br />To this end, we have developed a set of technologies to make it easier to use planetary-scale testbeds.&nbsp; For networking researchers, we have developed better tools that reduce the overhead in doing their work.&nbsp; For students, we have developed a rich and realistic platform for teaching and experimentation that won't be effectively off limits due to the prohibitive cost of experimentation.&nbsp; For the broader community of users, commercial developers, and society at large, our work offers the potential to catalyze a future Internet that is worthy of our society's trust.&nbsp; In particular, the key thrusts have been the following.<br /><br />a)&nbsp; Development of Seattle, a platform for networking and distributed systems research.&nbsp; Testbeds, such as PlanetLab and RON, are critical for evaluating networked and distributed systems.&nbsp; These testbeds, however, are limited in their scale, lack realistic use patterns, and are composed of nodes whose connectivity is not representative of most Internet hosts.&nbsp; In our work, we relax the assumption of dedicated testbed resources and present a new point in the space of testbed designs.&nbsp; We design, implement, and deploy a peer-to-peer networked testbed called Seattle. This open research testbed is enabled through broad end-user participation.&nbsp; Seattle is designed to preserve user security and to minimally impact application performance.&nbsp; Despite the necessary restrictions inherent to our platform, our experience with the testbed indicates that it is easy to program and provides researchers with sufficient functionality to create enticing prototypes.<br /><br />b) Self-managing overlays:&nbsp; The trend towards cloud and utility computing infrastructures raises challenges not only for application development, but also for management: diverse resources, changing resource availability, and differing application requirements create a complex optimization problem.&nbsp; Most existing cloud applications are managed externally, and this separation can lead to increased response time to failures, and slower or less appropriate adaptation to resource availability and pricing changes.&nbsp; We therefore explore a different approach more akin to P2P systems: we closely couple a decentralized management runtime ("Rhizoma") with the application itself.&nbsp; The application expresses its resource requirements to the runtime as a constrained optimization problem.&nbsp; Rhizoma then fuses multiple real-time sources of resource availability data, from which it decides to acquire or release resources (such as virtual machines), redeploying the system to continually maximize its utility.<br /><br />c) Control plane for testbeds:&nbsp; Development of a control plane abstraction layer that allows experimenters to migrate from locally available clusters to planetary-scale testbeds.&nbsp; Development and integration of commonly used distributed services such as distributed hash tables, content distribution systems, and various monitoring sensors.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/24/2011<br>      Modified by: Thomas&nbsp;E&nbsp;Anderson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ For planetary-scale testbeds, such as GENI/PlanetLab, to have the greatest possible impact in enabling experimental network and distributed systems research, they must be accessible to the broadest set of researchers.  Unfortunately, this is not the case now, with these testbeds being hard to use for anyone who is not an expert programmer.  A typical experience is that it takes a new user over a month to figure out how to write even the simplest PlanetLab program.  What is required is a smooth implementation path, from initial experimentation to eventual deployment, with a single, integrated toolset that is universally accessible.  To this end, we have developed a set of technologies to make it easier to use planetary-scale testbeds.  For networking researchers, we have developed better tools that reduce the overhead in doing their work.  For students, we have developed a rich and realistic platform for teaching and experimentation that won't be effectively off limits due to the prohibitive cost of experimentation.  For the broader community of users, commercial developers, and society at large, our work offers the potential to catalyze a future Internet that is worthy of our society's trust.  In particular, the key thrusts have been the following.  a)  Development of Seattle, a platform for networking and distributed systems research.  Testbeds, such as PlanetLab and RON, are critical for evaluating networked and distributed systems.  These testbeds, however, are limited in their scale, lack realistic use patterns, and are composed of nodes whose connectivity is not representative of most Internet hosts.  In our work, we relax the assumption of dedicated testbed resources and present a new point in the space of testbed designs.  We design, implement, and deploy a peer-to-peer networked testbed called Seattle. This open research testbed is enabled through broad end-user participation.  Seattle is designed to preserve user security and to minimally impact application performance.  Despite the necessary restrictions inherent to our platform, our experience with the testbed indicates that it is easy to program and provides researchers with sufficient functionality to create enticing prototypes.  b) Self-managing overlays:  The trend towards cloud and utility computing infrastructures raises challenges not only for application development, but also for management: diverse resources, changing resource availability, and differing application requirements create a complex optimization problem.  Most existing cloud applications are managed externally, and this separation can lead to increased response time to failures, and slower or less appropriate adaptation to resource availability and pricing changes.  We therefore explore a different approach more akin to P2P systems: we closely couple a decentralized management runtime ("Rhizoma") with the application itself.  The application expresses its resource requirements to the runtime as a constrained optimization problem.  Rhizoma then fuses multiple real-time sources of resource availability data, from which it decides to acquire or release resources (such as virtual machines), redeploying the system to continually maximize its utility.  c) Control plane for testbeds:  Development of a control plane abstraction layer that allows experimenters to migrate from locally available clusters to planetary-scale testbeds.  Development and integration of commonly used distributed services such as distributed hash tables, content distribution systems, and various monitoring sensors.          Last Modified: 10/24/2011       Submitted by: Thomas E Anderson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
