<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Dissertation Research:   An Investigation of the Nexus of Survey Nonresponse and Measurement Error</AwardTitle>
<AwardEffectiveDate>09/01/2006</AwardEffectiveDate>
<AwardExpirationDate>08/31/2009</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>12000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert O'Connor</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project will examine the nexus between nonresponse and measurement errors in sample surveys.  Recent research has not demonstrated a strong relationship between nonresponse rates and nonresponse bias.  Nonetheless, best practices argue that researchers should attempt to maximize response rates.  One voiced concern about practices involving nonresponse reduction is that reluctant people in the sample, successfully brought into the respondent data set through persuasive efforts, may provide data filled with measurement error.  However, no study has looked at links among the propensity to be a respondent, true values on a question of interest, and the respondent's measurement error properties for that question.  The research will fill this gap by addressing three questions.  First, under what circumstances is nonresponse propensity related to the survey variables of interest?  Is noncontact or refusal nonresponse more likely to induce nonresponse bias?  Second, what is the relationship between nonresponse propensity, nonresponse bias, and measurement error?  In particular, how do properties of questions and characteristics of respondents affect the nexus between nonresponse bias and measurement error?  Is nonresponse propensity arising from noncontact or that from refusal more susceptible to a correlation with measurement-error bias?  Third, can traditional statistical adjustments or analytic techniques remedy the problem?  Data from two national and two regional surveys will be analyzed to answer these questions.  The research will demonstrate when placing resources into nonresponse reduction is outweighed by increases in measurement error on key statistics.  The research also will suggest changes to be made during field collection or in postsurvey adjustments that jointly account for two error sources: nonresponse and measurement error. &lt;br/&gt;&lt;br/&gt;Sample surveys are the mechanism by which key indicators of the nation's well-being are created and through which mechanisms of personal and societal changes are tested.  Understanding error structures of sample surveys - both in terms of when errors occur and the mechanism behind their occurrence - is critically important because conclusions made from surveys could be dramatically wrong.  As nonresponse rates continue to rise, survey organizations are increasing their persuasive efforts in an attempt to maintain a representative sample on which inferences can be made.  If these persuasive efforts actually lower the quality of data, then the additional funds for these efforts are misguided.  The findings from this research will inform survey practitioners in how to conduct surveys and obtain better quality data and the scientific community that uses surveys to understand when survey-derived findings may be at risk.  As a Doctoral Dissertation Research Improvement award, this award also will provide support to enable a promising student to establish a strong independent research career.  The research is supported by the Methodology, Measurement, and Statistics Program and a consortium of federal statistical agencies as part of a joint activity to support research on survey and statistical methodology.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/28/2006</MinAmdLetterDate>
<MaxAmdLetterDate>05/26/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0620228</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Groves</LastName>
<EmailAddress>bgroves@isr.umich.edu</EmailAddress>
<StartDate>08/27/2008</StartDate>
<EndDate>05/26/2009</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Trivellore</FirstName>
<LastName>Raghunathan</LastName>
<EmailAddress>teraghu@umich.edu</EmailAddress>
<StartDate>05/26/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
</Institution>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramElement>
<Code>T463</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
