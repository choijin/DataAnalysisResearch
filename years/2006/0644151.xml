<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Exploring Creative Expression through Music and Audio Technology</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2007</AwardEffectiveDate>
<AwardExpirationDate>04/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>499936.00</AwardTotalIntnAmount>
<AwardAmount>609936</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Music contributes substantially to every culture on Earth, and the enjoyment of music is nearly universal. The appeal of music is that it provides expression to our own emotions, and it follows logically that individuals would want some creative input to that expression. Historically the primary exposure to music has been through live performance, providing audiences an opportunity for interaction with the musicians and music, but today the vast majority of music is experienced through recordings. And though recent digital audio technologies have had a tremendous impact on the world of recorded music, its fundamental nature remains unchanged: once a recording is made, that single "performance" is forever fixed, preventing any true interaction with the listener. The proposed work integrates research in digital audio technology with educational activities under a common vision of transforming the act of listening to "recorded" music into an interactive experience in which the "performance" responds to the creative input of the listener. Central to this vision is a concept known as Structured Audio, a semantic object-based representation of sound. &lt;br/&gt;&lt;br/&gt;The specific work activity consists of the following efforts: . Structured Sound Modeling (SSM) of musical instruments, which uses a novel signal processing and machine learning framework to facilitate a greater degree of musically expressive control than can be achieved with existing models for sound synthesis. . Development of the Structured Audio Platform (SAP), consisting of devices and software that employ these new instrument models to provide an expanded artistic palette for music producers and interfaces enabling nonmusicians to interact with their music by controlling creative aspects of the "performance." An outreach program that uses music technology to attract students to science, technology, engineering, and mathematics (STEM) by demonstrating the contributions of these disciplines to modern music production as well as the creativity inherent within STEM and related fields. &lt;br/&gt;&lt;br/&gt;With respect to intellectual merit, there are many methods of modeling musical instrument sounds, but most are limited in their ability to capture the full expressive range of those instruments. The project will employ a novel framework for modeling time-varying sounds using jointly estimated parameters of an excitation-resonance model to derive a HiddenMarkovModel (HMM) of expressive sound. This framework employs an analysis/synthesis scheme: input sound is parameterized by the model and can be regenerated from the model parameters. This process has been used to model the singing voice and can be applied to other instruments, resulting in high sound quality while retaining a full range of musical expression. Knowledge gained through this project will also benefit other machine listening applications, such as audio identification and sound sensing. The research activity includes the development of a custom platform of devices and interfaces that offer artists new creative options and allow non-musicians to also provide creative input to their music. A key area of research will investigate appropriate mappings from the expressive controls of SSM instruments to a simple, low-dimensional interface for musical novices. Creativity is a difficult subject to study quantitatively, but this project presents a framework from which a small subset of creative expression can be assessed and analyzed. &lt;br/&gt;&lt;br/&gt;The educational activities of this project are designed to broadly impact students at many levels. The proposed outreach program will introduce high school students, particularly from underrepresented groups, to the technology of digital music, revealing the influence of science and engineering on music performance, recording, and listening. By engaging students' affinity for popular music the program seeks to foster curiosity in science and technology. The research component of the proposal will also be directly integrated into this program via custom music devices that allow students to creatively interact with music in Structured Audio format. This confluence of engineering and art has the potential to incubate interest in both fields. Given the diminishing support for music education in the public school system, this multi-disciplinary approach may be a solution to sustaining creative arts in the curriculum. The proposed research integrates knowledge from a wide range of areas. Participating graduate students will receive interdisciplinary training in fields such as acoustics, music theory, signal processing, performance practice, and machine learning. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/18/2007</MinAmdLetterDate>
<MaxAmdLetterDate>05/16/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0644151</AwardID>
<Investigator>
<FirstName>Youngmoo</FirstName>
<LastName>Kim</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Youngmoo E Kim</PI_FULL_NAME>
<EmailAddress>ykim@drexel.edu</EmailAddress>
<PI_PHON>2158955973</PI_PHON>
<NSF_ID>000307796</NSF_ID>
<StartDate>04/18/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Drexel University</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191021119</ZipCode>
<PhoneNumber>2158956342</PhoneNumber>
<StreetAddress>1505 Race St, 10th Floor</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002604817</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DREXEL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002604817</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Drexel University]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191021119</ZipCode>
<StreetAddress><![CDATA[1505 Race St, 10th Floor]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9232</Code>
<Text>RES OPPOR AWARDS(ROA) (SUPPLEM</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~122389</FUND_OBLG>
<FUND_OBLG>2008~102377</FUND_OBLG>
<FUND_OBLG>2009~135899</FUND_OBLG>
<FUND_OBLG>2010~144643</FUND_OBLG>
<FUND_OBLG>2011~104628</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This CAREER project integrated computational media research investigating creative expression with educational activities to enhance STEM learning through music technology. The project team developed multiple systems for automatically assessing the emotional content of music, with a particular focus on how the acoustic properties change along with the emotions conveyed over the course of a song. These results could be used, for example, by digital music services to group songs with similar emotional content to improve music recommendations. This research included a new method for collecting music emotion labels using a novel online game, resulting in a highly detailed data set for hundreds of songs that was made publicly available. Several additional online activities were developed for collecting listening data, some of which also aimed to educate participants regarding specific mathematical and scientific concepts related to sound and acoustics. Over the course of this project, the research team published over 30 papers on these topics and organized multiple conferences and workshops specifically on the topic of emotion recognition in music. The researchers also developed a variety of new acoustic, electronic, and computing systems used to create interactive music performances. This work was also presented through novel music performances for large audiences as part of the Philadelphia Science Festival in 2012 and 2013. Another system for live music performance tracking developed through this project received considerable recognition in the popular media, including a front page article in The Philadelphia Inquirer in June, 2011.</p> <p>Additionally, this award enabled the development of the Summer Music Technology (SMT) program, a one-week camp for high school students that uses music technology to motivate interest in Science, Technology, Engineering, and Math (STEM). Since its inception in 2007, over 150 high school students have participated in SMT over 6 summers, and the program continues to attract a large number of applications each summer. Program activities cover topics including loudspeaker construction, musical instrument acoustics, sound synthesis, and digital sound effects, and the project team developed a suite of custom iPad apps to provide an exploratory and highly interactive component to each activity. Recent cohorts using the custom tools and curriculum had better learning outcomes than earlier groups using off-the-shelf tools and activities, and several of the activities have been used in local Philadelphia high school classrooms. The curriculum, lesson plans, worksheets, and custom software developed for the Summer Music Technology program are freely available online.</p><br> <p>            Last Modified: 08/14/2013<br>      Modified by: Youngmoo&nbsp;E&nbsp;Kim</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2013/0644151/0644151_10022494_1376514933412_ScienceOfMusic-closeup--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/0644151/0644151_10022494_1376514933412_ScienceOfMusic-closeup--rgov-800width.jpg" title="Science of Music Concert (April, 2012)"><img src="/por/images/Reports/POR/2013/0644151/0644151_10022494_1376514933412_ScienceOfMusic-closeup--rgov-66x44.jpg" alt="Science of Music Concert (April, 2012)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Jazz musicians Stephon Alexander, Marc Cary, and John Benitez perform with ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This CAREER project integrated computational media research investigating creative expression with educational activities to enhance STEM learning through music technology. The project team developed multiple systems for automatically assessing the emotional content of music, with a particular focus on how the acoustic properties change along with the emotions conveyed over the course of a song. These results could be used, for example, by digital music services to group songs with similar emotional content to improve music recommendations. This research included a new method for collecting music emotion labels using a novel online game, resulting in a highly detailed data set for hundreds of songs that was made publicly available. Several additional online activities were developed for collecting listening data, some of which also aimed to educate participants regarding specific mathematical and scientific concepts related to sound and acoustics. Over the course of this project, the research team published over 30 papers on these topics and organized multiple conferences and workshops specifically on the topic of emotion recognition in music. The researchers also developed a variety of new acoustic, electronic, and computing systems used to create interactive music performances. This work was also presented through novel music performances for large audiences as part of the Philadelphia Science Festival in 2012 and 2013. Another system for live music performance tracking developed through this project received considerable recognition in the popular media, including a front page article in The Philadelphia Inquirer in June, 2011.  Additionally, this award enabled the development of the Summer Music Technology (SMT) program, a one-week camp for high school students that uses music technology to motivate interest in Science, Technology, Engineering, and Math (STEM). Since its inception in 2007, over 150 high school students have participated in SMT over 6 summers, and the program continues to attract a large number of applications each summer. Program activities cover topics including loudspeaker construction, musical instrument acoustics, sound synthesis, and digital sound effects, and the project team developed a suite of custom iPad apps to provide an exploratory and highly interactive component to each activity. Recent cohorts using the custom tools and curriculum had better learning outcomes than earlier groups using off-the-shelf tools and activities, and several of the activities have been used in local Philadelphia high school classrooms. The curriculum, lesson plans, worksheets, and custom software developed for the Summer Music Technology program are freely available online.       Last Modified: 08/14/2013       Submitted by: Youngmoo E Kim]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
