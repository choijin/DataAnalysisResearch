<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Investigating classroom assessment practices in science</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>673560.00</AwardTotalIntnAmount>
<AwardAmount>673560</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Julio Lopez-Ferrao</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Intellectual Merit: The proposed project attempts to draw from several intellectual threads in science assessment to examine teachers classroom assessment beliefs and practices in the form of understanding their own (latent) interpretative framework for assessment. &lt;br/&gt;&lt;br/&gt;In contrast to many models proposed in the tradition of formative assessment, this project stresses the central role of teachers interpretative frameworks in assessment practices. A series of studies will be conducted to reveal how teachers think about and implement assessment practices, to identify challenging aspects of classroom assessments, and to construct and validate measures to capture classroom practices. The specific objectives of the proposed research are to: &lt;br/&gt;&lt;br/&gt;Conduct descriptive research to conceptualize, characterize, and document middle school science teachers understanding and beliefs about classroom assessment. &lt;br/&gt;Construct authentic scenario-based assessment tasks to capture the key aspects of teachers classroom assessment practices. &lt;br/&gt;Carry out reliability and validity research to validate the constructed tasks. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/01/2007</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0644435</AwardID>
<Investigator>
<FirstName>Min</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Min Li</PI_FULL_NAME>
<EmailAddress>minli@u.washington.edu</EmailAddress>
<PI_PHON>2066166305</PI_PHON>
<NSF_ID>000486022</NSF_ID>
<StartDate>08/01/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981950001</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0407</Code>
<Name>NSF,Education &amp; Human Resource</Name>
<APP_SYMB_ID>490106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0408</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0409</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0410</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~114519</FUND_OBLG>
<FUND_OBLG>2008~166395</FUND_OBLG>
<FUND_OBLG>2009~145415</FUND_OBLG>
<FUND_OBLG>2010~127419</FUND_OBLG>
<FUND_OBLG>2011~119812</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project&rsquo;s purpose is to develop and validate instruments to evaluate and monitor patterns in teachers&rsquo; assessment practices and pedagogical reasoning. In contrast to other studies that focus on the types of assessments teachers select or use, this project investigates how teachers make sense of the assessment information already available in their daily teaching and how they use such information in contingent instruction or subsequent assessments. We hypothesized that competent teachers apply their understanding of learners, learning, pedagogy, and content, and engage in continuous internal dialogues throughout the assessment cycle in order to implement assessments appropriately and flexibly. To this end, we conducted a series of case studies and a small-scale survey study to explore measurement issues around science teachers&rsquo; assessment practices as well as the pedagogical reasoning they engage with when assessing their students.</p> <p>We conceptualize teachers&rsquo; classroom assessment practices as a cycle of four components, all of which must be explicitly coordinated and grounded in an interpretative framework meant to guide teachers to reason, reflect, and monitor themselves throughout the assessment processes. The four components include purposefully selecting and designing assessment tasks, and collecting, interpreting, and acting upon assessment information. The assessment cycle is a purposeful, dynamic, and nonlinear flow of assessment actions that can blend with and support teaching and learning events. Each of the substudies focuses on one assessment component and involves the construction and validation of four measures: (1) questionnaire items; (2) stimulus-based interviews that asked teachers to reflect on and describe the reasoning behind assessment tasks, actions, or decisions; (3) qualitative coding of video-taped lessons or class artifacts that captured the process or products of assessment activities; and (4) teacher-written responses to scenario-based tasks of interpreting students&rsquo; responses and contingent planning of instructional movements. For example, our coding of teacher feedback practices for oral feedback (in videos) and written feedback (in student written work) categorizes teachers&rsquo; feedback into four types: affirming, corrective, descriptive evaluation, and explorative/provocative (i.e., probing deeper or stimulating further student thinking). We then describe various characteristics of feedback practices, such as accuracy, as indicated by appropriately judging the quality of student work; responsiveness to students&rsquo; learning needs, as indicated by sufficiently addressing any unique learning needs; or alignment with lesson objectives with the learning objectives at the lesson or unit level.</p> <p>Our findings include technical information about the measures we developed. We compare the technical quality of these measures and determine the number of units of analysis, raters, and coding dimensions needed to draw reliable and accurate inferences about the targeted construct. We also provide empirical evidence to describe patterns of teacher assessment practices. In one study on teachers&rsquo; learning goal practices in the context of elementary science classes, we observed that the better teachers understood the learning goals, the more frequently they tended to use key vocabulary associated with the module&rsquo;s big ideas. Further, the better teachers grasped the learning goals, the more they tended to provide real-world examples and address the conceptual essence when introducing a new module, lesson, or activity. Lastly, the higher teachers&rsquo; competency the more they tended to explicitly express or explain to students how previous or future learning was connected to the current lessons. In another study on teachers&rsquo; on-the-fly assessment conversations in four middle school science classrooms, we evaluated the quality of assessment conversations using various indicators and produced a feedback map that visually demonstrates the dynamics of the feedback practice. Our analysis revealed that feedback conversations tended to be brief, with half involving only two moves. We also found that the longer the assessment event, the more likely it involved reasoning and explanation from students. Approximately one in five assessment events involved reasoning, but it was most often the teacher playing the role of primary questioner. Teachers initiated most assessment events and rarely took a critical position or expressed any corrective feedback. In one study on the accommodation strategies used to support English language learners (ELLs) on written assessments, teachers used only a few accommodation strategies and were most comfortable using bolding of key words in prompts or providing sentence starters to their students instead of using strategies requiring a deep understanding of language and social-linguistics issues.</p> <p>Our findings have important measurement and professional development implications. First, measurement instruments need to account for the nature of the construct to decide the unit of analysis when evaluating teachers&rsquo; assessment practice, given the complexity of assessment. The findings also suggest a need for collaborative consultations between science and/or ELL coaches and teachers to modify curricula and assessment materials to more effectively assess and monitor ELL students&rsquo; understanding and responsively address their learning needs. For example, many informal assessment routines we observed from the video analysis, such as pair talk, can be greatly enhanced by redesigning assessment prompts and adding elements that accommodate ELL students.</p><br> <p>            Last Modified: 06/15/2017<br>      Modified by: Min&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project?s purpose is to develop and validate instruments to evaluate and monitor patterns in teachers? assessment practices and pedagogical reasoning. In contrast to other studies that focus on the types of assessments teachers select or use, this project investigates how teachers make sense of the assessment information already available in their daily teaching and how they use such information in contingent instruction or subsequent assessments. We hypothesized that competent teachers apply their understanding of learners, learning, pedagogy, and content, and engage in continuous internal dialogues throughout the assessment cycle in order to implement assessments appropriately and flexibly. To this end, we conducted a series of case studies and a small-scale survey study to explore measurement issues around science teachers? assessment practices as well as the pedagogical reasoning they engage with when assessing their students.  We conceptualize teachers? classroom assessment practices as a cycle of four components, all of which must be explicitly coordinated and grounded in an interpretative framework meant to guide teachers to reason, reflect, and monitor themselves throughout the assessment processes. The four components include purposefully selecting and designing assessment tasks, and collecting, interpreting, and acting upon assessment information. The assessment cycle is a purposeful, dynamic, and nonlinear flow of assessment actions that can blend with and support teaching and learning events. Each of the substudies focuses on one assessment component and involves the construction and validation of four measures: (1) questionnaire items; (2) stimulus-based interviews that asked teachers to reflect on and describe the reasoning behind assessment tasks, actions, or decisions; (3) qualitative coding of video-taped lessons or class artifacts that captured the process or products of assessment activities; and (4) teacher-written responses to scenario-based tasks of interpreting students? responses and contingent planning of instructional movements. For example, our coding of teacher feedback practices for oral feedback (in videos) and written feedback (in student written work) categorizes teachers? feedback into four types: affirming, corrective, descriptive evaluation, and explorative/provocative (i.e., probing deeper or stimulating further student thinking). We then describe various characteristics of feedback practices, such as accuracy, as indicated by appropriately judging the quality of student work; responsiveness to students? learning needs, as indicated by sufficiently addressing any unique learning needs; or alignment with lesson objectives with the learning objectives at the lesson or unit level.  Our findings include technical information about the measures we developed. We compare the technical quality of these measures and determine the number of units of analysis, raters, and coding dimensions needed to draw reliable and accurate inferences about the targeted construct. We also provide empirical evidence to describe patterns of teacher assessment practices. In one study on teachers? learning goal practices in the context of elementary science classes, we observed that the better teachers understood the learning goals, the more frequently they tended to use key vocabulary associated with the module?s big ideas. Further, the better teachers grasped the learning goals, the more they tended to provide real-world examples and address the conceptual essence when introducing a new module, lesson, or activity. Lastly, the higher teachers? competency the more they tended to explicitly express or explain to students how previous or future learning was connected to the current lessons. In another study on teachers? on-the-fly assessment conversations in four middle school science classrooms, we evaluated the quality of assessment conversations using various indicators and produced a feedback map that visually demonstrates the dynamics of the feedback practice. Our analysis revealed that feedback conversations tended to be brief, with half involving only two moves. We also found that the longer the assessment event, the more likely it involved reasoning and explanation from students. Approximately one in five assessment events involved reasoning, but it was most often the teacher playing the role of primary questioner. Teachers initiated most assessment events and rarely took a critical position or expressed any corrective feedback. In one study on the accommodation strategies used to support English language learners (ELLs) on written assessments, teachers used only a few accommodation strategies and were most comfortable using bolding of key words in prompts or providing sentence starters to their students instead of using strategies requiring a deep understanding of language and social-linguistics issues.  Our findings have important measurement and professional development implications. First, measurement instruments need to account for the nature of the construct to decide the unit of analysis when evaluating teachers? assessment practice, given the complexity of assessment. The findings also suggest a need for collaborative consultations between science and/or ELL coaches and teachers to modify curricula and assessment materials to more effectively assess and monitor ELL students? understanding and responsively address their learning needs. For example, many informal assessment routines we observed from the video analysis, such as pair talk, can be greatly enhanced by redesigning assessment prompts and adding elements that accommodate ELL students.       Last Modified: 06/15/2017       Submitted by: Min Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
