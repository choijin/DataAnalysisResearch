<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Deeper modeling via affective meta-tutoring</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>947919.00</AwardTotalIntnAmount>
<AwardAmount>1011363</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sarah-Kay McDonald</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The studies address through investigation of students in Arizona High School summer programs how students learn, understand and manipulate scientific models of the carbon cycle and the water cycle. The investigators of this project have identified problems that on-line tutors have with creating conditions for students to regulate their own behavior. Instead of taking advantage of the available learning opportunities, some students ask for hints until the tutor gives them the correct answer. &lt;br/&gt;&lt;br/&gt;The investigators hypothesize that lasting benefits require changing students beliefs about shallow compared with deep modeling practices and breaking their modeling habits and instilling new ones.  They intend to add affective learning companions to the on-line tutors.   The modules use the teachable agent metaphor called Betty's Brain. &lt;br/&gt;The study analysis will be conducted in high school summer schools in Arizona for students that are mostly Native Americans.  The students are self-selected for attending the summer school.  Data collection will include student logs, verbal protocols and affect sensor data from the summer school participants (approximately 30 students).  Three studies will be conducted: 1. to develop a meta tutoring tool, 2. to develop an affective learning agent with verbal and physical gestures, and 3. a measure of whether the new tool results in increases in learning.  The analysis will involve causal inference and data mining of student records of their activities.  The third phase of the learning will compare students who use one agent with the teachable agent; a second group will compare two agents, the teachable agent and the meta-tutor; and a third group will compare three agents.  The outcome of the study is a developed and tested tool to increase student learning and statistical analysis of records maintained by the investigators of student activities with the teachable agent.  The study should help indicate whether computer tutors are more effective if they have integrated features that mimic human performance.</AbstractNarration>
<MinAmdLetterDate>05/13/2009</MinAmdLetterDate>
<MaxAmdLetterDate>01/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0910221</AwardID>
<Investigator>
<FirstName>Winslow</FirstName>
<LastName>Burleson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Winslow Burleson</PI_FULL_NAME>
<EmailAddress>win@arizona.edu</EmailAddress>
<PI_PHON>6467552824</PI_PHON>
<NSF_ID>000249639</NSF_ID>
<StartDate>05/13/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kurt</FirstName>
<LastName>VanLehn</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>PhD</PI_SUFX_NAME>
<PI_FULL_NAME>Kurt VanLehn</PI_FULL_NAME>
<EmailAddress>Kurt.Vanlehn@asu.edu</EmailAddress>
<PI_PHON>4809653190</PI_PHON>
<NSF_ID>000504773</NSF_ID>
<StartDate>05/13/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2><![CDATA[660 South Mill Avenue, Suite 310]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>TEMPE</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852816011</ZipCode>
<StreetAddress><![CDATA[ORSPA]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>7625</Code>
<Text>REESE</Text>
</ProgramReference>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0409</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0410</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0412</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~308480</FUND_OBLG>
<FUND_OBLG>2010~334638</FUND_OBLG>
<FUND_OBLG>2011~336536</FUND_OBLG>
<FUND_OBLG>2012~15781</FUND_OBLG>
<FUND_OBLG>2013~15928</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>A student&rsquo;s affective state (frustrated, engaged, bored&hellip;) can be detect with a variety of sensors, including webcams, posture-sensing chairs and pressure sensitive mice.&nbsp; We wondered if such technology would allow us to present affective messages (e.g., congratulations, sympathy, encouragement, etc.) at exactly the right time to increase students&rsquo; motivation .&nbsp; &nbsp;To future increase the effectiveness, the messages could be presented by an agent that the student selected as a learning companion and had had a brief get-to-know-you conversation.&nbsp; &nbsp;</p> <p>In order to test this hypothesis, we picked a type of learning that is known to be extremely challenging and yet increasingly important given the new common core and next generation standards.&nbsp; The challenge is for students to learn how to construct models of systems that change over time&mdash;dynamic systems.&nbsp; When given such model-construction problems, students often exhibit shallow modeling behavior: guessing, copying from old models, plugging numbers from the problem statement into random places in the model, etc.&nbsp; How can we teach them to use deep model practices?</p> <p>We developed a model construction editor that gave students simple right/wrong feedback and demonstrations as they built their model.&nbsp; This of course allowed them to abuse the help by asking for it when they didn&rsquo;t really need.&nbsp; Next we built a coach (called a &ldquo;meta-tutor&rdquo; in the literature) that observed the students&rsquo; behavior and gave them advice about how to use the help effectively and how to do deep modeling.&nbsp; &nbsp;As expected, this nagging was partially effective.&nbsp; When the coach was giving advice, students exhibited more deep modeling practices, better use of help and somewhat more learning.&nbsp; However, also as expected, when the coach&rsquo;s nagging stopped, students resumed their poor practices.&nbsp; This is typical of earlier attempts to teach beneficial strategies to students, including attempts that don&rsquo;t involve computers. &nbsp;The work described so far merely set the stage for what we hoped would be the main event.</p> <p>We hypothesized that an affective learning companion could get students to persist in using deep modeling and effective help-seeking strategies.&nbsp; The agent&rsquo;s job was to first build rapport with the student, then increase the students&rsquo; confidence by crediting success to the students&rsquo; hard work, and pointing out that such hard work built the &ldquo;muscles&rdquo; of the mind, making it even easier to succeed the next time.&nbsp; &nbsp;To make the affective learning companion effective, its affective message were selected and timed to be appropriate for the students&rsquo; emotional state, as detected using a webcam, posture chair, pressure mouse and other sensors.&nbsp; We develop complex rules (mostly induced from data) to determine what the agent should say under what circumstances.&nbsp;</p> <p>We tested our software with high school students participating in summer schools.&nbsp;&nbsp; This is a challenging experimental setting, as the students varied widely in age, mathematical preparation and motivation.&nbsp; Nonetheless, despite the large variation due to incoming attributes, we believed that the affective learning companion&rsquo;s engaging persona and skillful timing of messages would create a powerful enough benefit that it could be detected amidst the noise.&nbsp; &nbsp;&nbsp;&nbsp;</p> <p>We ran several experiments, and each taking about 2.5 hours.&nbsp; We randomly assigned students to two groups: using the software (including the coach) either with or without the agent.&nbsp; Students first solved modeling problems for 75 minutes with the help of the coach.&nbsp; Students in the experimental group also interacted with their affective learning companion.&nbsp; After...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ A studentÆs affective state (frustrated, engaged, bored&hellip;) can be detect with a variety of sensors, including webcams, posture-sensing chairs and pressure sensitive mice.  We wondered if such technology would allow us to present affective messages (e.g., congratulations, sympathy, encouragement, etc.) at exactly the right time to increase studentsÆ motivation .   To future increase the effectiveness, the messages could be presented by an agent that the student selected as a learning companion and had had a brief get-to-know-you conversation.     In order to test this hypothesis, we picked a type of learning that is known to be extremely challenging and yet increasingly important given the new common core and next generation standards.  The challenge is for students to learn how to construct models of systems that change over time&mdash;dynamic systems.  When given such model-construction problems, students often exhibit shallow modeling behavior: guessing, copying from old models, plugging numbers from the problem statement into random places in the model, etc.  How can we teach them to use deep model practices?  We developed a model construction editor that gave students simple right/wrong feedback and demonstrations as they built their model.  This of course allowed them to abuse the help by asking for it when they didnÆt really need.  Next we built a coach (called a "meta-tutor" in the literature) that observed the studentsÆ behavior and gave them advice about how to use the help effectively and how to do deep modeling.   As expected, this nagging was partially effective.  When the coach was giving advice, students exhibited more deep modeling practices, better use of help and somewhat more learning.  However, also as expected, when the coachÆs nagging stopped, students resumed their poor practices.  This is typical of earlier attempts to teach beneficial strategies to students, including attempts that donÆt involve computers.  The work described so far merely set the stage for what we hoped would be the main event.  We hypothesized that an affective learning companion could get students to persist in using deep modeling and effective help-seeking strategies.  The agentÆs job was to first build rapport with the student, then increase the studentsÆ confidence by crediting success to the studentsÆ hard work, and pointing out that such hard work built the "muscles" of the mind, making it even easier to succeed the next time.   To make the affective learning companion effective, its affective message were selected and timed to be appropriate for the studentsÆ emotional state, as detected using a webcam, posture chair, pressure mouse and other sensors.  We develop complex rules (mostly induced from data) to determine what the agent should say under what circumstances.   We tested our software with high school students participating in summer schools.   This is a challenging experimental setting, as the students varied widely in age, mathematical preparation and motivation.  Nonetheless, despite the large variation due to incoming attributes, we believed that the affective learning companionÆs engaging persona and skillful timing of messages would create a powerful enough benefit that it could be detected amidst the noise.       We ran several experiments, and each taking about 2.5 hours.  We randomly assigned students to two groups: using the software (including the coach) either with or without the agent.  Students first solved modeling problems for 75 minutes with the help of the coach.  Students in the experimental group also interacted with their affective learning companion.  After a 15 minute cookie-and-water break, students solved more modeling problems with both the coach and the agent turned off.  During this second phase, we expected to see the experimental group, who had interacted with their affective learning companion, more frequently use deep modeling and better help seeking than the control group.     Unfo...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
