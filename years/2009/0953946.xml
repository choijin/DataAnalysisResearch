<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Data-Intensive HPC Analytics: A Systems Approach Through Extended Interfaces, Data Restructuring and Data-centric Scheduling</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2010</AwardEffectiveDate>
<AwardExpirationDate>02/28/2017</AwardExpirationDate>
<AwardTotalIntnAmount>438909.00</AwardTotalIntnAmount>
<AwardAmount>454909</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>With the advent of emerging e-Science applications, today's scientific research increasingly relies on petascale-and-beyond computing over large data sets with petabyte-and-beyond sizes. Representatives include analytics- and simulation- driven applications such as the human vision simulation, astrophysics data analysis, earthquake modeling, climate modeling using ensemble runs, etc. In many of the above-mentioned fields, scientists are dealing with large amounts of data and analyzing them to explore new concepts and ideas. These applications make up data-intensive HPC analytics, which lies at the intersection of current HPC and Data-Intensive Scalable Computing (DISC).&lt;br/&gt;When HPC systems use traditional configurations to support data-intensive HPC analytics, data is copied from a large remote storage system to diskless compute nodes for processing. Copying data back and forth is an expensive and time consuming process. These data-intensive applications do not require compute intensive resources, but rather moderate compute power machines with the capability of local storage so that data can be processed in-place. One such example of this configuration is the Hadoop framework. However, there are currently limitations in this framework which must be overcome in order to make Hadoop an effective HPC tool. The investigator is leveraging the Hadoop framework to process large amount of patterned data in HPC. This research program includes three thrusts. It is developing the MapReduce API to support a wider range of I/O access patterns, various data restructuring schemes to improve I/O performance for these access patterns, and an efficient scheduling scheme considering multiple chunk locations and data transfer latencies over the network. The research is integrated into several educational activities, such as the development of data-intensive HPC curricula.</AbstractNarration>
<MinAmdLetterDate>03/08/2010</MinAmdLetterDate>
<MaxAmdLetterDate>12/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0953946</AwardID>
<Investigator>
<FirstName>Jun</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jun Wang</PI_FULL_NAME>
<EmailAddress>Jun.Wang@ucf.edu</EmailAddress>
<PI_PHON>4078230449</PI_PHON>
<NSF_ID>000277527</NSF_ID>
<StartDate>03/08/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>The University of Central Florida Board of Trustees</Name>
<CityName>Orlando</CityName>
<ZipCode>328168005</ZipCode>
<PhoneNumber>4078230387</PhoneNumber>
<StreetAddress>4000 CNTRL FLORIDA BLVD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>150805653</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The University of Central Florida Board of Trustees]]></Name>
<CityName>Orlando</CityName>
<StateCode>FL</StateCode>
<ZipCode>328168005</ZipCode>
<StreetAddress><![CDATA[4000 CNTRL FLORIDA BLVD]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~101659</FUND_OBLG>
<FUND_OBLG>2012~125864</FUND_OBLG>
<FUND_OBLG>2013~112365</FUND_OBLG>
<FUND_OBLG>2014~115021</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Helvetica} --> <p class="p1">This CAREER project makes it major research contribution by defining a new computing paradigm for high-performance computing scientists and engineers to better handle the onslaught of data towards scientific inquiry in today&rsquo;s big data era. Rather than moving data to the demanding applications, we develop a data-centric computing platform to prepare data ahead of time, distribute data appropriately at target computers, and launch big data applications from desirable place where we like to go. This is among the first to develop a unified big data and big compute framework to accelerate HPC big data analytics. We develop a new big data computing framework which provides a suite of open-source software tools for many interdisciplinary scientists and big data analysts in a wide variety of disciplines (e.g., bioinformatics, life science, high energy physicists, astrophysics) to conduct their data analyses in a fast and cost-effective fashion. Both times and amount of big data movement taking place in anywhere and anytime has been significantly reduced. In addition, we port our data intensive computing framework to both Windows and Amazon two different cloud computing platforms, which enables scientists to perform fast big data analysis at any time, and in any place.</p> <p class="p1">Regarding the broad impact, our new interdisciplinary research framework in support of data-intensive HPC analytics enables many bioinformatics and astrophysics scientists and engineers to conduct data analyses in comprehensive access patterns by a super faster and easier way compared with the state-of-the-art solutions. We estimate it can not only save millions of dollars of physicists&rsquo; labor cost in national lab, but also significantly shorten the development cycle of analyses programs.</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/11/2017<br>      Modified by: Jun&nbsp;Wang</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/0953946/0953946_10013915_1489266178825_nsf_figure_2017--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/0953946/0953946_10013915_1489266178825_nsf_figure_2017--rgov-800width.jpg" title="Big Data Express"><img src="/por/images/Reports/POR/2017/0953946/0953946_10013915_1489266178825_nsf_figure_2017--rgov-66x44.jpg" alt="Big Data Express"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Accelerating Big Data Processing</div> <div class="imageCredit">Mr. Dan Huang and Dr. Jun Wang</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Jun&nbsp;Wang</div> <div class="imageTitle">Big Data Express</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This CAREER project makes it major research contribution by defining a new computing paradigm for high-performance computing scientists and engineers to better handle the onslaught of data towards scientific inquiry in today?s big data era. Rather than moving data to the demanding applications, we develop a data-centric computing platform to prepare data ahead of time, distribute data appropriately at target computers, and launch big data applications from desirable place where we like to go. This is among the first to develop a unified big data and big compute framework to accelerate HPC big data analytics. We develop a new big data computing framework which provides a suite of open-source software tools for many interdisciplinary scientists and big data analysts in a wide variety of disciplines (e.g., bioinformatics, life science, high energy physicists, astrophysics) to conduct their data analyses in a fast and cost-effective fashion. Both times and amount of big data movement taking place in anywhere and anytime has been significantly reduced. In addition, we port our data intensive computing framework to both Windows and Amazon two different cloud computing platforms, which enables scientists to perform fast big data analysis at any time, and in any place. Regarding the broad impact, our new interdisciplinary research framework in support of data-intensive HPC analytics enables many bioinformatics and astrophysics scientists and engineers to conduct data analyses in comprehensive access patterns by a super faster and easier way compared with the state-of-the-art solutions. We estimate it can not only save millions of dollars of physicists? labor cost in national lab, but also significantly shorten the development cycle of analyses programs.          Last Modified: 03/11/2017       Submitted by: Jun Wang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
