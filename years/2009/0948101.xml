<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Workshop Proposal: Content of Linguistic Annotation: Standards and Practices (CLASP)</AwardTitle>
    <AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2015</AwardExpirationDate>
    <AwardAmount>22500</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>At a September, 2009 NSF-sponsored meeting in New York City, the NLP community is discussing the standardization and harmonization of the content of manual/automatic linguistic annotation. The meeting is building on the results of the previous Computing Research Infrastructure (CRI) award "Towards a Comprehensive Linguistic Annotation of Language" by establishing standards that researchers and developers are likely to follow. These standards govern tokenization, part of speech, head selection and other basic components&lt;br/&gt;of linguistic content that higher level annotation schema assume in common. Once standards are set, violations should be conscious (not accidental) and researchers should justify any violations. The meeting also aims to set up incentives, in the form of grants for small (e.g., student) projects, because several initial standard-compliant annotation projects could plant the seeds needed for the standards to take root.&lt;br/&gt;&lt;br/&gt;Intellectual merit: Establishing a common base for linguistic annotation will: (1) make it easier to use, merge and compare different types of annotation (from different transducers, different manual sets of annotation, etc.); (2) make a more rigorous set of annoation standards possible; and (3) facilitate the use of sophisticated natural language informed applications that can draw on annotation created by several different projects simultaneously.&lt;br/&gt;&lt;br/&gt;Broader impact: This standardization process will bring about greater cooperation among annotation researchers and, as a result, greatly improve the efficiency of such research. This could significantly improve the state of the art of all linguistic processing, and thus, all applications (automatic search, translation, etc.) that rely on the automatic linguistic analysis of text.</AbstractNarration>
    <MinAmdLetterDate>09/09/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>08/15/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0948101</AwardID>
    <Investigator>
      <FirstName>Adam</FirstName>
      <LastName>Meyers</LastName>
      <EmailAddress>meyers@cs.nyu.edu</EmailAddress>
      <StartDate>09/09/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>New York University</Name>
      <CityName>NEW YORK</CityName>
      <ZipCode>100121019</ZipCode>
      <PhoneNumber>2129982121</PhoneNumber>
      <StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
