<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Integrating Cognition and Measurement with Conceptual Knowledge: Establishing the Validity and Diagnostic Capacity of Concept Inventories</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>517541.00</AwardTotalIntnAmount>
<AwardAmount>517541</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This collaborative research project implements a comprehensive, multidisciplinary approach to the design and validation of concept inventories (CIs). The purpose is to braoden and enhance the effective use of concept inventories in STEM education for formative and summative assessment. To accomplish this goal the project will focus on a specific concept inventory, the Thermal Transport Concept Inventory (TTCI). The data will be collected from the varied undergarduate student samples. The research would develop an explicit set of facets of understanding for diagnostic measurement and reporting, would gather multi-level empirical data of student performance on the TTCI (including student protocol and interview studies, and large scale data for psychometric modeling), would revise both the items and facets based upon these empirical data analyses, and would gather further data on the revised instrument. The data on TTCI will be analyzed in terms of the underlying conceptual knowledge and skills that it taps in critical areas of science and engineering. Additional empirical data on student reasoning and performance will be analyzed applying modern psychometric analysis techniques focused on diagnostic modeling. Research outcomes expected are: (1) an improved TTCI available through the web and accompanied by interpretive tools for use by faculty; (2) an in-depth, multi-level analysis of the assessment validity and diagnostic capacity of the TTCI; (3) a comprehensive inventory of possible formative and summative uses of CIs, including what is needed by STEM practitioners to make good use of CIs; and (4) a research and development framework for designing, developing, evaluating, improving, and/or implementing CIs in other STEM areas.&lt;br/&gt;&lt;br/&gt;In general, the study will contribute to the better understanding of student learning and more authentic diagnostic and formative assessment, leading to better learning and teaching of important concepts in STEM.  The use of the TTCI will elicit student misconceptions in the thermal and transport engineering sciences such as fluid mechanics, heat transfer, and thermodynamics. The TTCI particularly focuses on concepts deemed important but difficult for undergraduate engineering students. Thus, the proposed research is likely to lead to expanded uses of the TTCI and other CIs for formative classroom purposes as well as for a variety of summative purposes. This project are both an expansion of the psychometric modeling and methods for applying diagnostic models to CIs, and an expanded assessment validity in the area of measurement and assessment of key concepts in science and engineering.</AbstractNarration>
<MinAmdLetterDate>08/31/2009</MinAmdLetterDate>
<MaxAmdLetterDate>09/28/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0918552</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Pellegrino</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James W Pellegrino</PI_FULL_NAME>
<EmailAddress>pellegjw@uic.edu</EmailAddress>
<PI_PHON>3123552493</PI_PHON>
<NSF_ID>000178292</NSF_ID>
<StartDate>08/31/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Louis</FirstName>
<LastName>DiBello</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Louis V DiBello</PI_FULL_NAME>
<EmailAddress>ldibello@uic.edu</EmailAddress>
<PI_PHON>2155346239</PI_PHON>
<NSF_ID>000226126</NSF_ID>
<StartDate>08/31/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606124305</ZipCode>
<PhoneNumber>3129962862</PhoneNumber>
<StreetAddress>809 S. Marshfield Avenue</StreetAddress>
<StreetAddress2><![CDATA[MB 502, M/C 551]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>098987217</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606124305</ZipCode>
<StreetAddress><![CDATA[809 S. Marshfield Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0409</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0410</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~167315</FUND_OBLG>
<FUND_OBLG>2010~174163</FUND_OBLG>
<FUND_OBLG>2011~176063</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This Collaborative Project involved the University of Illinois at Chicago (Lou DiBello and Jim Pellegrino co-PIs) NSF Grant # 0918552; the Colorado School of Mines (Ron Miller PI) NSF Grant # 0918436; and Purdue University (Ruth Streveler PI) NSF Grant # 0918531.</p> <p><strong>Goal.</strong> The overarching goal was to demonstrate a comprehensive, multidisciplinary approach to the design and validation of concept inventories (CIs) capable of enhancing their effectiveness and impact and transforming their use in STEM classrooms. Two specific CIs, the Thermal and Transport Concept Inventory (TTCI) (Streveler, Olds, &amp; Miller, 2003), and the Concept Assessment Tool for Statics (CATS) (Steif &amp; Dantzler, 2004) were investigated, applying expertise from the multiple disciplines of STEM content knowledge, STEM teaching and learning, cognitive science, educational measurement, and psychometric modeling.</p> <p><strong>Primary research questions: </strong></p> <p>--What do the TTCI and CATS really measure relative to their conceptual foundations, their assessment claims and their intended uses?</p> <p>--Do TTCI and CATS items and distractors reliably diagnose conceptual understanding and robust misconceptions? Can new items and distractors improve the diagnostic functioning and utility of the TTCI?</p> <p>--How should instructors think about the use of CIs for instruction? How do CI concepts correspond to the standard topics taught in a typical STEM course? How can CIs be used formatively in classrooms? What impact do such formative uses have on student learning and performance?</p> <p><strong>Significant Accomplishments</strong></p> <p>--Multiple quantitative and qualitative analyses of both the CATS and TTCI inventories furthered our understanding of how to use and interpret students&rsquo; scores on these inventories.</p> <p>--The Evidence Centered Design (ECD) procedure was used to clarify the domain concepts measured by the TTCI, and to write new items to expand and improve the TTCI.</p> <p>--Research outcomes were extensively disseminated through journal submissions, national and international conferences, and book chapters.</p> <p><strong>Key Outcomes and Other Achievements: </strong></p> <p>A new version of the TTCI was developed iteratively, using the ECD approach and incorporating findings from think-aloud studies and online TTCI data from university students.</p> <p>A framework was developed and documented that incorporates both qualitative and quantitative CI data to investigate the validity of CI claims relative to intended uses.</p> <p><strong>Impacts:</strong></p> <p><strong>Engineering Education:</strong> CIs are increasingly popular in STEM education settings and yet relatively little is known about their validity and instructional utility. As part of an ongoing discussion among engineering educators about extending CI uses beyond the common pre-posttest comparisons, our project outcomes provide a comprehensive theoretical and analytical framework for analyzing multiple aspects of the validity of CIs. Our approach is grounded in a guiding validity perspective that is directly applicable to typical CI uses and that addresses issues of expanded diagnostic reporting for formative classroom uses.</p> <p><strong>Educational Assessment:</strong> Recent developments in educational assessment stress the relationships among curriculum, instruction and assessments. This project extends classical and current thinking about the validity of large-scale assessments to classroom assessments that can directly inform teaching and learning. Our theoretical framework can assist STEM practitioners at all levels including instructors, departments, and developers of both curricula and assessments to improve their understanding of what makes quality assessment and support instructors use of assessments as part of their instructional practice.</p> <p><strong>Educational Me...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This Collaborative Project involved the University of Illinois at Chicago (Lou DiBello and Jim Pellegrino co-PIs) NSF Grant # 0918552; the Colorado School of Mines (Ron Miller PI) NSF Grant # 0918436; and Purdue University (Ruth Streveler PI) NSF Grant # 0918531.  Goal. The overarching goal was to demonstrate a comprehensive, multidisciplinary approach to the design and validation of concept inventories (CIs) capable of enhancing their effectiveness and impact and transforming their use in STEM classrooms. Two specific CIs, the Thermal and Transport Concept Inventory (TTCI) (Streveler, Olds, &amp; Miller, 2003), and the Concept Assessment Tool for Statics (CATS) (Steif &amp; Dantzler, 2004) were investigated, applying expertise from the multiple disciplines of STEM content knowledge, STEM teaching and learning, cognitive science, educational measurement, and psychometric modeling.  Primary research questions:   --What do the TTCI and CATS really measure relative to their conceptual foundations, their assessment claims and their intended uses?  --Do TTCI and CATS items and distractors reliably diagnose conceptual understanding and robust misconceptions? Can new items and distractors improve the diagnostic functioning and utility of the TTCI?  --How should instructors think about the use of CIs for instruction? How do CI concepts correspond to the standard topics taught in a typical STEM course? How can CIs be used formatively in classrooms? What impact do such formative uses have on student learning and performance?  Significant Accomplishments  --Multiple quantitative and qualitative analyses of both the CATS and TTCI inventories furthered our understanding of how to use and interpret studentsÆ scores on these inventories.  --The Evidence Centered Design (ECD) procedure was used to clarify the domain concepts measured by the TTCI, and to write new items to expand and improve the TTCI.  --Research outcomes were extensively disseminated through journal submissions, national and international conferences, and book chapters.  Key Outcomes and Other Achievements:   A new version of the TTCI was developed iteratively, using the ECD approach and incorporating findings from think-aloud studies and online TTCI data from university students.  A framework was developed and documented that incorporates both qualitative and quantitative CI data to investigate the validity of CI claims relative to intended uses.  Impacts:  Engineering Education: CIs are increasingly popular in STEM education settings and yet relatively little is known about their validity and instructional utility. As part of an ongoing discussion among engineering educators about extending CI uses beyond the common pre-posttest comparisons, our project outcomes provide a comprehensive theoretical and analytical framework for analyzing multiple aspects of the validity of CIs. Our approach is grounded in a guiding validity perspective that is directly applicable to typical CI uses and that addresses issues of expanded diagnostic reporting for formative classroom uses.  Educational Assessment: Recent developments in educational assessment stress the relationships among curriculum, instruction and assessments. This project extends classical and current thinking about the validity of large-scale assessments to classroom assessments that can directly inform teaching and learning. Our theoretical framework can assist STEM practitioners at all levels including instructors, departments, and developers of both curricula and assessments to improve their understanding of what makes quality assessment and support instructors use of assessments as part of their instructional practice.  Educational Measurement and Psychometrics: Research outcomes demonstrate how psychometrics contributes to quality STEM assessment. A validity perspective and related multidimensional diagnostic framework was developed to guide evaluation and improvement of CIs.  Learning Sciences: Assessment forms a core...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
