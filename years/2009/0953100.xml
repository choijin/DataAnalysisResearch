<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:  Autotuning Foundations for Exascale Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2010</AwardEffectiveDate>
<AwardExpirationDate>03/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>460000.00</AwardTotalIntnAmount>
<AwardAmount>460000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this research is to discover novel foundational principles&lt;br/&gt;for developing highly-efficient and reliable software that can achieve&lt;br/&gt;sustainable performance on the exascale computing platforms expected by&lt;br/&gt;2020. Such platforms will deliver three orders of magnitude beyond&lt;br/&gt;today?s systems; harnessing this raw computational power could&lt;br/&gt;revolutionize our modeling and understanding of critical phenomena in&lt;br/&gt;areas like climate modeling, energy, medicine, sustainability,&lt;br/&gt;cosmology, engineering design, and massive-scale data analytics. Yet,&lt;br/&gt;developing software for exascale systems is a tremendous challenge&lt;br/&gt;because the hardware is complex and it is not believed that the most&lt;br/&gt;productive ?high-level? software development environments (e.g.,&lt;br/&gt;programming languages and libraries) will be able to effectively exploit&lt;br/&gt;these exascale systems.&lt;br/&gt;&lt;br/&gt;The investigator aims to address this challenge by using automated&lt;br/&gt;tuning (autotuning) to eliminate the low performance traditionally&lt;br/&gt;associated with high-level programming models. This research (a)&lt;br/&gt;develops new model-driven frameworks for tuning parallel algorithms and&lt;br/&gt;data structures, going beyond existing techniques that focus on&lt;br/&gt;low-level code tuning; and (b) studies autotuning for programs expressed&lt;br/&gt;in high-level programming models, with the aim of eliminating the&lt;br/&gt;performance gap. Concomitant with this research, the PI will create a&lt;br/&gt;new practicum course: The HPC Garage. The HPC Garage physically&lt;br/&gt;co-locates interdisciplinary teams in a social collaborative lab space;&lt;br/&gt;the teams engage in a year-long competition, called the XD Prize, to&lt;br/&gt;develop highly scalable algorithms and software for NSF TeraGrid?s&lt;br/&gt;next-generation XD facilities. The HPC Garage also hosts summer interns&lt;br/&gt;in Georgia Tech?s Computing Research Undergraduate Intern Summer&lt;br/&gt;Experience (CRUISE) program, whose mission is to encourage students,&lt;br/&gt;especially those from underrepresented groups, to pursue graduate&lt;br/&gt;degrees in computing.</AbstractNarration>
<MinAmdLetterDate>04/21/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/01/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0953100</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Vuduc</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard W Vuduc</PI_FULL_NAME>
<EmailAddress>richie@cc.gatech.edu</EmailAddress>
<PI_PHON>5103017014</PI_PHON>
<NSF_ID>000080331</NSF_ID>
<StartDate>04/21/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320420</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Programs]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramElement>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~120437</FUND_OBLG>
<FUND_OBLG>2011~81830</FUND_OBLG>
<FUND_OBLG>2012~83830</FUND_OBLG>
<FUND_OBLG>2013~85890</FUND_OBLG>
<FUND_OBLG>2014~88013</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this CAREER project was to discover fundamental principles of designing automatically tuned algorithms and software for next-generation high-performance computing (or <em>supercomputing</em>) systems. In this context, &ldquo;automatically tuned&rdquo; (<em>autotuned</em>) refers to the idea of an algorithm or software adjusting itself to run as efficiently as possible on a given machine. The motivation for autotuned systems is that supercomputer-class systems are become so complex that it is become harder to predict how efficiently an algorithm or piece of software will run. Consequently, high-performance software development is becoming more costly, as is the cost of running the machines, in terms of all the metrics of time, energy, and power to execute a program.</p> <p><br />The <strong>intellectual merit </strong>of this CAREER project has been to produce a number of research results that advance our understanding of how to build autotuned systems for supercomputers.</p> <p><br />The first set of research results concerns a number of new principles for designing algorithms and improving the performance of software on current and future supercomputers that contain, as one of their key components, <em>manycore co-processors</em>. These principles highlight not just the benefits of using such co-processors, but also their limitations, which is critical to our understanding of such systems. One highlight of these results was the collaborative development of a blood flow simulation code that, in 2010, received the Gordon Bell Prize, an award for setting a new high-water mark in achieved supercomputer performance.</p> <p><br />The second research set of results concerns new models for predicting how well a program will perform. Models are critical to developing autotuned systems in the following way: a &ldquo;tunable&rdquo; or &ldquo;adaptive&rdquo; program will having a number of parameters that need to be set correctly for a given machine; and <em>models</em>&nbsp;can narrow the set of parameters that need to be considered.</p> <p>One of these models, referred to as the <em>energy roofline model</em>, permits reasoning not just about the execution time of an algorithm or program, but also its execution <em>energy</em> and&nbsp;<em>power</em>. These latter metrics are becoming as or arguably more important costs to consider than time as the scale of supercomputers increases. A new NSF project to extend this model is underway.</p> <p><br />One culmination of these research results is the development of an autotuning framework for a class of computations known as <em>sparse direct solvers</em>. Such solvers lie at the heart of a number of computational science and engineering applications. As this project comes to a close, this prototype is being integrated into a widely used open source solver package.</p> <p><br />Beyond its research outcomes, the <strong>broader impact</strong> of this CAREER project has been to advance several educational outcomes aimed at broadening interest in and the use of high-performance computing. These outcomes include the development of a new massively open online course on high-performance computing, which is to become part of Georgia Tech&rsquo;s experimental low-cost Online Masters in Computer Science degree program; as well a new Research Experience for Undergraduate (REU) sub-project that aims to bring high-performance computing to the Web.</p><br> <p>            Last Modified: 07/07/2015<br>      Modified by: Richard&nbsp;W&nbsp;Vuduc</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this CAREER project was to discover fundamental principles of designing automatically tuned algorithms and software for next-generation high-performance computing (or supercomputing) systems. In this context, "automatically tuned" (autotuned) refers to the idea of an algorithm or software adjusting itself to run as efficiently as possible on a given machine. The motivation for autotuned systems is that supercomputer-class systems are become so complex that it is become harder to predict how efficiently an algorithm or piece of software will run. Consequently, high-performance software development is becoming more costly, as is the cost of running the machines, in terms of all the metrics of time, energy, and power to execute a program.   The intellectual merit of this CAREER project has been to produce a number of research results that advance our understanding of how to build autotuned systems for supercomputers.   The first set of research results concerns a number of new principles for designing algorithms and improving the performance of software on current and future supercomputers that contain, as one of their key components, manycore co-processors. These principles highlight not just the benefits of using such co-processors, but also their limitations, which is critical to our understanding of such systems. One highlight of these results was the collaborative development of a blood flow simulation code that, in 2010, received the Gordon Bell Prize, an award for setting a new high-water mark in achieved supercomputer performance.   The second research set of results concerns new models for predicting how well a program will perform. Models are critical to developing autotuned systems in the following way: a "tunable" or "adaptive" program will having a number of parameters that need to be set correctly for a given machine; and models can narrow the set of parameters that need to be considered.  One of these models, referred to as the energy roofline model, permits reasoning not just about the execution time of an algorithm or program, but also its execution energy and power. These latter metrics are becoming as or arguably more important costs to consider than time as the scale of supercomputers increases. A new NSF project to extend this model is underway.   One culmination of these research results is the development of an autotuning framework for a class of computations known as sparse direct solvers. Such solvers lie at the heart of a number of computational science and engineering applications. As this project comes to a close, this prototype is being integrated into a widely used open source solver package.   Beyond its research outcomes, the broader impact of this CAREER project has been to advance several educational outcomes aimed at broadening interest in and the use of high-performance computing. These outcomes include the development of a new massively open online course on high-performance computing, which is to become part of Georgia TechÆs experimental low-cost Online Masters in Computer Science degree program; as well a new Research Experience for Undergraduate (REU) sub-project that aims to bring high-performance computing to the Web.       Last Modified: 07/07/2015       Submitted by: Richard W Vuduc]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
