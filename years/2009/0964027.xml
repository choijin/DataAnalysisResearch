<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: Collaborative Research:  Reconstructing Cities from Photographs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2010</AwardEffectiveDate>
<AwardExpirationDate>04/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>240000.00</AwardTotalIntnAmount>
<AwardAmount>240000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is focused on research issues associated with producing extremely detailed and accurate 3D geometry and appearance (BRDF) models at city scale from internet collections of photos from various sources containing millions of photos of enormous diversity such as viewing range and conditions, time of day and weather conditions, to name a few.  The properties of urban scenes may include low-texture surfaces, reflective and transparent materials, and repeated structures that challenge existing reconstruction algorithms. The investigators will address these challenges with the aim of reconstructing several large US and foreign cities.   Historical photos and virtual models may also be incorporated.  There are a number of research topics associated with the project. To register photographs and recover sparse geometry at city-scale, a new, unified, structure-from-motion (SfM) algorithm will be designed to take advantage of large, parallel computing platforms.  With registered photographs and sparse 3D scene points recovered by SfM, multi-view stereo (MVS) algorithms can reconstruct detailed geometric models.  Novel MVS algorithms will then exploit the structure of architectural scenes and volumetric reconstruction methods will be employed to produce annotated models of exceptional accuracy and usability. Digital models are playing an increasingly important role in social, cultural and economic endeavor and are central to next-generation mapping and visualization applications.  All models and datasets will be made freely available to researchers and the general public.</AbstractNarration>
<MinAmdLetterDate>05/19/2010</MinAmdLetterDate>
<MaxAmdLetterDate>03/31/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964027</AwardID>
<Investigator>
<FirstName>Noah</FirstName>
<LastName>Snavely</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Noah Snavely</PI_FULL_NAME>
<EmailAddress>snavely@cs.cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000533237</NSF_ID>
<StartDate>05/19/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~77893</FUND_OBLG>
<FUND_OBLG>2011~80097</FUND_OBLG>
<FUND_OBLG>2012~82010</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We are living in a time of unparalleled capture of visual data, with billions of photos shared online every day. &nbsp;These 2D photos collectively reveal the 3D structure and appearance of our cities. &nbsp;In this research, we have created new methods for automatically, quickly, and reliably building 3D models from very large community photo collections found online. &nbsp;Our work has addressed key problems in scalability and robustness, leading to methods that can reconstruct geometry from hundreds of thousands or millions of photos of a city. &nbsp;Beyond the 3D geometry of cities, we have also developed techniques to reconstruct scene appearance from photo collections, for instance the intrinsic color of each point in a scene. &nbsp;To make this all possible, we needed to create new computer vision algorithms that efficiently process very large collections of images. &nbsp;We have found that a key way to represent such image collections is as networks with links between overlapping images (akin to the links between friends in social networks). &nbsp;Given this representation, we use tools originally developed for analyzing complex networks to help us filter out noise and reconstruct geometry from the photo collection.</p> <p>The models we can build from our methods can have applications in a range of areas, from urban planning to ecology, and can also be used in education and entertainment. &nbsp;Much of the software and data we have developed throughout this project is available online; please see http://www.cs.cornell.edu/projects/bigsfm/ for pointers to all of our individual projects and for software, videos, and data.</p><br> <p>            Last Modified: 08/07/2014<br>      Modified by: Noah&nbsp;Snavely</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2014/0964027/0964027_10016209_1407396859115_disambig_cover--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/0964027/0964027_10016209_1407396859115_disambig_cover--rgov-800width.jpg" title="Reconstructing Difficult Scenes using 3D Disambiguation"><img src="/por/images/Reports/POR/2014/0964027/0964027_10016209_1407396859115_disambig_cover--rgov-66x44.jpg" alt="Reconstructing Difficult Scenes using 3D Disambiguation"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Repeated features are common in urban scenes. Many objects, such as clock towers with nearly identical sides, or domes with strong radial symmetries, pose challenges for structure from motion. We correct these errors using tools from network analysis.</div> <div class="imageCredit">Kyle Wilson and Noah Snavely</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Noah&nbsp;Snavely</div> <div class="imageTitle">Reconstructing Difficult Scenes using 3D Disambiguation</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We are living in a time of unparalleled capture of visual data, with billions of photos shared online every day.  These 2D photos collectively reveal the 3D structure and appearance of our cities.  In this research, we have created new methods for automatically, quickly, and reliably building 3D models from very large community photo collections found online.  Our work has addressed key problems in scalability and robustness, leading to methods that can reconstruct geometry from hundreds of thousands or millions of photos of a city.  Beyond the 3D geometry of cities, we have also developed techniques to reconstruct scene appearance from photo collections, for instance the intrinsic color of each point in a scene.  To make this all possible, we needed to create new computer vision algorithms that efficiently process very large collections of images.  We have found that a key way to represent such image collections is as networks with links between overlapping images (akin to the links between friends in social networks).  Given this representation, we use tools originally developed for analyzing complex networks to help us filter out noise and reconstruct geometry from the photo collection.  The models we can build from our methods can have applications in a range of areas, from urban planning to ecology, and can also be used in education and entertainment.  Much of the software and data we have developed throughout this project is available online; please see http://www.cs.cornell.edu/projects/bigsfm/ for pointers to all of our individual projects and for software, videos, and data.       Last Modified: 08/07/2014       Submitted by: Noah Snavely]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
