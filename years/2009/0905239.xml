<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC:Medium: Collaborative Research: Effective Communication with Robotic Assistants for the Elderly: Integrating Speech, Vision and Haptics</AwardTitle>
<AwardEffectiveDate>07/15/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2012</AwardExpirationDate>
<AwardTotalIntnAmount>212720.00</AwardTotalIntnAmount>
<AwardAmount>212720</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). &lt;br/&gt;&lt;br/&gt;The purpose of this study is to develop a communication interface that &lt;br/&gt;will enable older people to effectively communicate with robotic &lt;br/&gt;assistants, allowing them in this way to remain living safely in their &lt;br/&gt;homes. The proposed communication interface will be: (1) multimodal, &lt;br/&gt;that is supporting spoken, gestural and physical interactions, as all &lt;br/&gt;these typically occur simultaneously when people communicate with one &lt;br/&gt;another, and (2) adaptive so that the robotic assistant will adjust to &lt;br/&gt;the older person rather than the older person to the robotic &lt;br/&gt;assistant. The combination of speech, gestures and physical &lt;br/&gt;interactions (haptics) has received only limited attention, but it &lt;br/&gt;will be critical for successful deployment of assistive robots for &lt;br/&gt;many elderly individuals. The transformative component of this &lt;br/&gt;research is to view haptics as one of the drivers of the dialogue &lt;br/&gt;between the user and the robot, and to study its relation to speech &lt;br/&gt;and gestures through language processing methods. To adapt to each &lt;br/&gt;user, the interpretation of the speech, gestures and haptic signals &lt;br/&gt;will be performed by means of RISq (Recognition by Indexing and &lt;br/&gt;Sequencing), a novel, adaptive and reliable recognition &lt;br/&gt;methodology. Finally, a formal and modular control design methodology &lt;br/&gt;will be developed, that guarantees that the robot responds safely and &lt;br/&gt;reliably to the interpretation of the user intent provided by dialogue &lt;br/&gt;processing. &lt;br/&gt;&lt;br/&gt;Robot assistive technology holds immense promise for the &lt;br/&gt;future. Supporting the independent functioning of older people so that &lt;br/&gt;they can safely remain living in the community is of paramount &lt;br/&gt;importance, especially since the world's population is aging at an &lt;br/&gt;ever increasing pace. However, one of the main obstacles to the &lt;br/&gt;widespread use of robot assistants is the lack of interfaces that are &lt;br/&gt;easy to use for the elderly and allow the robot to be used in complex &lt;br/&gt;real-world environments such as a typical apartment. The proposed &lt;br/&gt;research aims to develop new tools that will enable robot developers &lt;br/&gt;to fill this void. The research could also have significant &lt;br/&gt;implications for the delivery of institutionally based health &lt;br/&gt;care. The deployment of robots to assist nursing personnel in &lt;br/&gt;hospitals and long-term care facilities, as well as at home, has &lt;br/&gt;enormous implications for improved health outcomes and quality of life &lt;br/&gt;for older patients while minimizing costs of care. Furthermore, the &lt;br/&gt;reduction of the nursing workload by such robot assistants promises to &lt;br/&gt;alleviate the critical shortage of nursing personnel in the USA that &lt;br/&gt;is only expected to worsen.</AbstractNarration>
<MinAmdLetterDate>07/10/2009</MinAmdLetterDate>
<MaxAmdLetterDate>07/10/2009</MaxAmdLetterDate>
<ARRAAmount>212720</ARRAAmount>
<AwardID>0905239</AwardID>
<Investigator>
<FirstName>Marquis</FirstName>
<LastName>Foreman</LastName>
<EmailAddress>mark_d_foreman@rush.edu</EmailAddress>
<StartDate>07/10/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rush-Presbyterian-St Luke's Med Center</Name>
<CityName>Chicago</CityName>
<ZipCode>606123809</ZipCode>
<PhoneNumber>3129425479</PhoneNumber>
<StreetAddress>1653 West Congress Parkway</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>6890</Code>
<Text>RECOVERY ACT ACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
