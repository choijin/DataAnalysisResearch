<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDI-Type II:   Collaborative Research: Integrating Statistical and Computational Approaches to Privacy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>409296.00</AwardTotalIntnAmount>
<AwardAmount>409296</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
<PO_EMAI>ceavey@nsf.gov</PO_EMAI>
<PO_PHON>7032927269</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Data privacy is a fundamental problem of the modern information infrastructure. Increasing volumes of personal and sensitive data are collected and archived by health networks, government agencies, search engines, social networking websites, and other organizations. The social benefits of analyzing these databases are significant. At the same time, the release of information from sensitive data repositories can be devastating to the privacy of individuals and organizations. The challenge is to discover and release important characteristics of these databases without compromising the privacy of those whose data they contain. The main goal of this project is to design scalable computational techniques that are statistically sound, yield broadly useful data, and yet preserve privacy in the face of realistic external information. The project aims to integrate two essentially different approaches to the complex problem of data privacy. The reconciliation of these approaches raises a number of fundamental questions for statistical theory and cryptography, as well as methodological challenges that must be overcome to enable practical applications. This research is centered around three themes: (1) Integrating the computationally-focused, rigorous definitions of privacy emanating from computer science with notions of utility from statistics. (2) Developing cryptographic protocols for distributing privacy-preserving algorithms for valid statistical analysis among a group of servers so as to avoid pooling data in any single location. (3) Understanding the practical potential of the developed techniques by applying them to concrete problems in the behavioral and social sciences and analyzing important data sources from the official statistical community. The research will be carried out in collaboration with social scientists and industry researchers. &lt;br/&gt;&lt;br/&gt;The project will increase awareness of data privacy issues and promote research on statistical disclosure limitation, cryptography and privacy-preserving data mining. Moreover, this research will transform the way statistical agencies, social scientists, medical researchers, and those in industry approach privacy?in particular, how they collect, share and publish information. The integration of statistical and cryptographic methods in the form of ex ante provably secure procedures will provide the essential scientific fundamentals for official statistical agencies to fulfill their mission of useful data production, which the proliferation of digital information has endangered. Finally, the new techniques will permit opening the vault of industrial data, such as search logs and data on social networks, to statistical analysis?greatly expanding the research domain of the social and health sciences.</AbstractNarration>
<MinAmdLetterDate>08/31/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0941226</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Abowd</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John M Abowd</PI_FULL_NAME>
<EmailAddress>john.abowd@cornell.edu</EmailAddress>
<PI_PHON>6072558024</PI_PHON>
<NSF_ID>000332299</NSF_ID>
<StartDate>08/31/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7751</Code>
<Text>CDI TYPE II</Text>
</ProgramElement>
<ProgramReference>
<Code>7721</Code>
<Text>FROM DATA TO KNOWLEDGE</Text>
</ProgramReference>
<ProgramReference>
<Code>7752</Code>
<Text>CDI NON SOLICITED RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~409296</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the past five years we have seen heightened public concerns regarding the privacy of personal data. &nbsp; These concerns have been the result of a variety of disclosures regarding improper access to government and commercial data. &nbsp;In our project, we have focused on how individual-level data can be shared for research and related purposes without the identification of individuals involved. &nbsp;Such privacy-protected data access has been a growing topic in both the statistical and and computer science literatures. &nbsp;The method of differential privacy, proposed initially over a decade ago, offers a very strong probabilisitic privacy guarantee with important statistical properties. Our project has (1) investigated theoretical properties of differential privacy mechanisms, and (2) explored applications of differential privacy to a wide variety of statistical problems.</p> <p><br />Differential Privacy applies to the release mechanism and not to the dataset per se, and implies that, for any two datasets that are close to one another, the mechanism will behave approximately the same on both data sets. &nbsp;A principal difficulty is getting differential privacy mechanisms to scale, i.e., to allow for the release on increasing numbers of queries or components of the output of statistical analyses. &nbsp;We have explored alternative theoretical approaches to this scaling problem including special circumstances when computational approaches to producing statistical summaries also provide privacy protection at no additional cost.</p> <p><br />Among the practical statistical problems we have addressed are: &nbsp;(a) the release of information associated with the most important single-nucleotide polymorphisms (SNPs) in genome-wide association studies of &nbsp;the DNA of individual with diseases such as Crohnos disease and forms of cancer, (b) the release of summary statistics for large scale social network data analyzed with methods based on exponential random graph models, and release of synthetic differentially private networks (c) summary census and survey data in the form of multi-dimensional tabulations, and synthesizers for the Census Bureau local labor market data system known as the Quarterly Workforce Indicators (QWI), &nbsp;(d) a new set of modeling tools for incorporating the effects of statistical disclosure limitation on models used in economic analyses, which were developed with the QWIs as a primary example.</p> <p><br />Finally, we have worked to develop teaching materials on data privacy for graduate students and researchers in statistics and other sciences, and have organized and participated in numerous cross-disciplinary workshops and conferences, including computer scientists, statisticians, and social scientists.</p><br> <p>            Last Modified: 12/09/2015<br>      Modified by: John&nbsp;M&nbsp;Abowd</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the past five years we have seen heightened public concerns regarding the privacy of personal data.   These concerns have been the result of a variety of disclosures regarding improper access to government and commercial data.  In our project, we have focused on how individual-level data can be shared for research and related purposes without the identification of individuals involved.  Such privacy-protected data access has been a growing topic in both the statistical and and computer science literatures.  The method of differential privacy, proposed initially over a decade ago, offers a very strong probabilisitic privacy guarantee with important statistical properties. Our project has (1) investigated theoretical properties of differential privacy mechanisms, and (2) explored applications of differential privacy to a wide variety of statistical problems.   Differential Privacy applies to the release mechanism and not to the dataset per se, and implies that, for any two datasets that are close to one another, the mechanism will behave approximately the same on both data sets.  A principal difficulty is getting differential privacy mechanisms to scale, i.e., to allow for the release on increasing numbers of queries or components of the output of statistical analyses.  We have explored alternative theoretical approaches to this scaling problem including special circumstances when computational approaches to producing statistical summaries also provide privacy protection at no additional cost.   Among the practical statistical problems we have addressed are:  (a) the release of information associated with the most important single-nucleotide polymorphisms (SNPs) in genome-wide association studies of  the DNA of individual with diseases such as Crohnos disease and forms of cancer, (b) the release of summary statistics for large scale social network data analyzed with methods based on exponential random graph models, and release of synthetic differentially private networks (c) summary census and survey data in the form of multi-dimensional tabulations, and synthesizers for the Census Bureau local labor market data system known as the Quarterly Workforce Indicators (QWI),  (d) a new set of modeling tools for incorporating the effects of statistical disclosure limitation on models used in economic analyses, which were developed with the QWIs as a primary example.   Finally, we have worked to develop teaching materials on data privacy for graduate students and researchers in statistics and other sciences, and have organized and participated in numerous cross-disciplinary workshops and conferences, including computer scientists, statisticians, and social scientists.       Last Modified: 12/09/2015       Submitted by: John M Abowd]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
