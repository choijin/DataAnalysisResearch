<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF:  Medium: Programmable Monitoring Framework for Multicore Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>576840.00</AwardTotalIntnAmount>
<AwardAmount>734040</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The advent of multicore processors has introduced new opportunities for achieving&lt;br/&gt;increased software performance, reliability, security, and availability. However,&lt;br/&gt;powerful dynamic execution monitoring capabilities are required to realize these&lt;br/&gt;opportunities. This project addresses the challenges of developing a Dynamic&lt;br/&gt;Binary Translation based monitoring framework for parallel applications running on&lt;br/&gt;multicore systems. The programmability of the framework will enable realization of &lt;br/&gt;benefits in achieving enhanced performance, reliability, security, and availability.&lt;br/&gt;&lt;br/&gt; Some of the instrumentation code required in context of parallel applications &lt;br/&gt;must be executed by a core in response to events that involve other cores. In particular, &lt;br/&gt;events relevant to many performance, reliability, and security related tasks correspond &lt;br/&gt;to the manifestation of interprocessor data dependences due to updates of shared &lt;br/&gt;memory locations by multiple cores. Based upon this observation programmable &lt;br/&gt;architectural mechanisms will be provided that not only enable the detection of &lt;br/&gt;interprocessor dependence events but also enable the triggering of the execution of &lt;br/&gt;application specific monitoring code. This project will then employ these mechanisms &lt;br/&gt;for improving performance via speculative parallelism, enabling debugging via a&lt;br/&gt;novel strategy of execution suppression, improving reliability via an approach that&lt;br/&gt;allows applications to automatically recover from failures, providing security via&lt;br/&gt;dynamic detection of mutating viruses, and software availability via dynamic updates.</AbstractNarration>
<MinAmdLetterDate>07/22/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0963996</AwardID>
<Investigator>
<FirstName>Rajiv</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rajiv Gupta</PI_FULL_NAME>
<EmailAddress>gupta@cs.ucr.edu</EmailAddress>
<PI_PHON>9518272558</PI_PHON>
<NSF_ID>000077772</NSF_ID>
<StartDate>07/22/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Iulian</FirstName>
<LastName>Neamtiu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Iulian Neamtiu</PI_FULL_NAME>
<EmailAddress>ineamtiu@njit.edu</EmailAddress>
<PI_PHON>9735963340</PI_PHON>
<NSF_ID>000537180</NSF_ID>
<StartDate>07/22/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Riverside</Name>
<CityName>RIVERSIDE</CityName>
<ZipCode>925210217</ZipCode>
<PhoneNumber>9518275535</PhoneNumber>
<StreetAddress>Research &amp; Economic Development</StreetAddress>
<StreetAddress2><![CDATA[245 University Office Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>44</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA44</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>627797426</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Riverside]]></Name>
<CityName>RIVERSIDE</CityName>
<StateCode>CA</StateCode>
<ZipCode>925210217</ZipCode>
<StreetAddress><![CDATA[Research &amp; Economic Developm]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>44</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA44</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramElement>
<ProgramElement>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~363000</FUND_OBLG>
<FUND_OBLG>2011~346840</FUND_OBLG>
<FUND_OBLG>2012~24200</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>With the widespread use of computing devices and software in critical tasks, high software reliability and performance are paramount. To ensure that software is running reliably, it is important to monitor its execution to identify faulty behavior and then correct it. Also, since deployed software must handle a wide range of situations, it is important to monitor program's input and dependence characteristics during execution and adapt it to deliver high performance. The research project has delivered techniques to enable efficient runtime monitoring of software, tools for debugging of parallel programs to improve their reliability, and runtime techniques for improving performance of complex real-world applications.<br /><br />1. Efficient Runtime Monitoring.<br />Continuous monitoring of running software can result in high runtime overhead, since a significant portion of the compute cycles can be taken up by monitoring activities. In this work we designed lightweight hardware support that can be programmed to perform a wide range of monitoring tasks with minimal runtime overhead. The effectiveness of programmable hardware was demonstrated by using it to perform monitoring needed for software reliability (e.g., record-and-replay) and software performance (e.g., speculative parallel execution). An important contribution of the above work is that it considers the relationship between memory models and runtime monitoring of memory accesses. We have solved the long standing problem of efficiently supporting the sequential consistency memory model which makes the task of producing reliable software much more manageable.<br /><br />2. Debugging Tools for Parallel Software.<br />Existing debugging tools provide little guidance for the programmers towards locating the bug source. We have developed a new tool, DrDebug, for efficiently debugging multithreaded programs. By providing several new commands we make the task of examining and analyzing the state of a running program much easier. The insights gained by using these commands helps the user track down the root cause of faulty behavior and improve program understanding, allowing the programmer to modify the program to eliminate faulty behavior. DrDebug works for parallel programs and can efficiently monitor long program runs. Additional support for replaying parts of program execution is provided so that the user can efficiently explore and understand program behavior. The effectiveness of DrDebug was demonstrated by monitoring and debugging of real-world programs containing bugs.<br /><br />3. Exploiting Parallelism in Real-world Applications.<br />Modern applications in important domains such as genomics and data mining are characterized by their need for massive computing power both due to their computational complexity and their handling of massive amounts of data. We have observed that the massive amounts of input, intermediate, and output data that these applications must handle causes programmers to develop code which continuously carries out data transfers between files and memory to make the best use of limited available memory. Frequent I/O operations that perform these data transfers introduce dependences that greatly limit our ability to exploit parallelism in hybrid loops (i.e., loops containing a mix of computation and I/O). While much research has been carried out over past several decades on exploiting parallelism, these techniques are mostly applicable to computations that are free of I/O operations. We have developed a novel technique that breaks I/O caused dependences and greatly enhances our ability to exploit parallelism for real-world applications. As an example we studied Velvet, a popular de novo genomic assembler. Velvet must deal with large input sizes and large amounts of intermediate data. For example, for processing of the wheat genome, Velvet must handle an input file that is 15 Gb in size ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With the widespread use of computing devices and software in critical tasks, high software reliability and performance are paramount. To ensure that software is running reliably, it is important to monitor its execution to identify faulty behavior and then correct it. Also, since deployed software must handle a wide range of situations, it is important to monitor program's input and dependence characteristics during execution and adapt it to deliver high performance. The research project has delivered techniques to enable efficient runtime monitoring of software, tools for debugging of parallel programs to improve their reliability, and runtime techniques for improving performance of complex real-world applications.  1. Efficient Runtime Monitoring. Continuous monitoring of running software can result in high runtime overhead, since a significant portion of the compute cycles can be taken up by monitoring activities. In this work we designed lightweight hardware support that can be programmed to perform a wide range of monitoring tasks with minimal runtime overhead. The effectiveness of programmable hardware was demonstrated by using it to perform monitoring needed for software reliability (e.g., record-and-replay) and software performance (e.g., speculative parallel execution). An important contribution of the above work is that it considers the relationship between memory models and runtime monitoring of memory accesses. We have solved the long standing problem of efficiently supporting the sequential consistency memory model which makes the task of producing reliable software much more manageable.  2. Debugging Tools for Parallel Software. Existing debugging tools provide little guidance for the programmers towards locating the bug source. We have developed a new tool, DrDebug, for efficiently debugging multithreaded programs. By providing several new commands we make the task of examining and analyzing the state of a running program much easier. The insights gained by using these commands helps the user track down the root cause of faulty behavior and improve program understanding, allowing the programmer to modify the program to eliminate faulty behavior. DrDebug works for parallel programs and can efficiently monitor long program runs. Additional support for replaying parts of program execution is provided so that the user can efficiently explore and understand program behavior. The effectiveness of DrDebug was demonstrated by monitoring and debugging of real-world programs containing bugs.  3. Exploiting Parallelism in Real-world Applications. Modern applications in important domains such as genomics and data mining are characterized by their need for massive computing power both due to their computational complexity and their handling of massive amounts of data. We have observed that the massive amounts of input, intermediate, and output data that these applications must handle causes programmers to develop code which continuously carries out data transfers between files and memory to make the best use of limited available memory. Frequent I/O operations that perform these data transfers introduce dependences that greatly limit our ability to exploit parallelism in hybrid loops (i.e., loops containing a mix of computation and I/O). While much research has been carried out over past several decades on exploiting parallelism, these techniques are mostly applicable to computations that are free of I/O operations. We have developed a novel technique that breaks I/O caused dependences and greatly enhances our ability to exploit parallelism for real-world applications. As an example we studied Velvet, a popular de novo genomic assembler. Velvet must deal with large input sizes and large amounts of intermediate data. For example, for processing of the wheat genome, Velvet must handle an input file that is 15 Gb in size and intermediate data that exceeds 10 Gb.  Therefore I/O operations appear frequently in the program and li...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
