<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>II-NEW: ARC: A Root Cluster for Research into Scalable Computer Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2010</AwardEffectiveDate>
<AwardExpirationDate>02/28/2013</AwardExpirationDate>
<AwardTotalIntnAmount>549999.00</AwardTotalIntnAmount>
<AwardAmount>549999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Krishna Kant</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Scalability is one of the key challenges to computing with hundreds if not thousands of processor.  Yet, testing software at scale with hundreds of processing cores is impossible if system software with privileged access rights needs to be modified. The inability to change system software at will in large-scale computing installations thus impedes progress in system software.&lt;br/&gt;&lt;br/&gt;This project creates a mid-size computational infrastructure, called ARC (A Root Cluster), that directly supports research into scalability for system-level software solutions.  ARC empowers users temporarily with administrator (root) rights and allows them to replace arbitrary components of the software stack.  Such replacements range from entire operating systems over drivers, kernel modules to runtime libraries, middleware and system tools.&lt;br/&gt;&lt;br/&gt;ARC ultimately enables a multitude of systems research directions to be assessed under scalability that could otherwise not be conducted.  Through ARC, methodologies for scalability of experimental system software in various institutional projects and beyond can be explored and systematically improved.  ARC is positioned to benefit the software systems community and indirectly science in general by this assessment of system software requirements at scale.</AbstractNarration>
<MinAmdLetterDate>02/22/2010</MinAmdLetterDate>
<MaxAmdLetterDate>02/22/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0958311</AwardID>
<Investigator>
<FirstName>Vincent</FirstName>
<LastName>Freeh</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vincent W Freeh</PI_FULL_NAME>
<EmailAddress>vwfreeh@ncsu.edu</EmailAddress>
<PI_PHON>9195137196</PI_PHON>
<NSF_ID>000285544</NSF_ID>
<StartDate>02/22/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Frank</FirstName>
<LastName>Mueller</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Frank Mueller</PI_FULL_NAME>
<EmailAddress>mueller@cs.ncsu.edu</EmailAddress>
<PI_PHON>9195157889</PI_PHON>
<NSF_ID>000484031</NSF_ID>
<StartDate>02/22/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiaosong</FirstName>
<LastName>Ma</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaosong Ma</PI_FULL_NAME>
<EmailAddress>ma@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195137577</PI_PHON>
<NSF_ID>000300080</NSF_ID>
<StartDate>02/22/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xuxian</FirstName>
<LastName>Jiang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xuxian Jiang</PI_FULL_NAME>
<EmailAddress>jiang@cs.ncsu.edu</EmailAddress>
<PI_PHON>9195137835</PI_PHON>
<NSF_ID>000073185</NSF_ID>
<StartDate>02/22/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiaohui</FirstName>
<LastName>Gu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaohui Gu</PI_FULL_NAME>
<EmailAddress>gu@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195159676</PI_PHON>
<NSF_ID>000302228</NSF_ID>
<StartDate>02/22/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957514</ZipCode>
<StreetAddress><![CDATA[2601 Wolf Village Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~549999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project created a mid-size computational infrastructure,<br />called ARC (A Root Cluster), that directly supports research into<br />scalability for system-level software solutions.&nbsp; ARC empowers users<br />temporarily with administrator (root) rights and allows them to<br />replace arbitrary components of the software stack.&nbsp; ARC<br />enables a multitude of research directions to be assessed under<br />scalability.<br /><br />During the project period, the ARC infrastructure was the planned,<br />specified, a bid was issued, the equipment was purchased, and<br />hardware/software were installed. The cluster was in experimental mode<br />from November 2010 and entered production mode in January<br />2011. Extensive hardware/software enhancements continued during the<br />remainder of the project period, including specialized thermal<br />balancing software.<br /><br />Educational activities included coverage of parallel programming on<br />clusters and data parallelism on GPUs in graduate and undergraduate<br />classes of the Computer Science curriculum with resources (slides,<br />programming examples) made publicly available on the web.<br />An educational highlight was a short course on ``Introduction to<br />Parallel Programming with Single and Multiple GPUs'', taught by the<br />PI, to allow scientists and non-scientists of all disciplines to<br />acquaint themselves with GPU programming. The online material is<br />periodically updated to include novel features (e.g., OpenACC support).<br /><br />Research conducted on the ARC infrastructure resulted in numerous<br />publications that have since shaped the landscape of parallel<br />computing contributing to future advances toward the path to exascale<br />HPC computing. <br /><br />This research has helped in assessing the scalability of experimental<br />system software components. It has contributed to a better<br />understanding of infrastructure needs for future system-level research<br />on large-scale many-core and many-node computational facilities.<br />Individual projects exploiting ARC have advanced the knowledge in<br />scalable software design for high-performance computing, fault<br />tolerance, I/O, cloud computing and security.<br /><br />The ARC cluster remains invaluable to the PIs and many<br />users (across numerous department at and beyond NC State University)<br />in conducting cutting-edge research. It has also fostered new research<br />projects with inter-disciplinary participation.</p><br> <p>            Last Modified: 04/10/2013<br>      Modified by: Frank&nbsp;Mueller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project created a mid-size computational infrastructure, called ARC (A Root Cluster), that directly supports research into scalability for system-level software solutions.  ARC empowers users temporarily with administrator (root) rights and allows them to replace arbitrary components of the software stack.  ARC enables a multitude of research directions to be assessed under scalability.  During the project period, the ARC infrastructure was the planned, specified, a bid was issued, the equipment was purchased, and hardware/software were installed. The cluster was in experimental mode from November 2010 and entered production mode in January 2011. Extensive hardware/software enhancements continued during the remainder of the project period, including specialized thermal balancing software.  Educational activities included coverage of parallel programming on clusters and data parallelism on GPUs in graduate and undergraduate classes of the Computer Science curriculum with resources (slides, programming examples) made publicly available on the web. An educational highlight was a short course on ``Introduction to Parallel Programming with Single and Multiple GPUs'', taught by the PI, to allow scientists and non-scientists of all disciplines to acquaint themselves with GPU programming. The online material is periodically updated to include novel features (e.g., OpenACC support).  Research conducted on the ARC infrastructure resulted in numerous publications that have since shaped the landscape of parallel computing contributing to future advances toward the path to exascale HPC computing.   This research has helped in assessing the scalability of experimental system software components. It has contributed to a better understanding of infrastructure needs for future system-level research on large-scale many-core and many-node computational facilities. Individual projects exploiting ARC have advanced the knowledge in scalable software design for high-performance computing, fault tolerance, I/O, cloud computing and security.  The ARC cluster remains invaluable to the PIs and many users (across numerous department at and beyond NC State University) in conducting cutting-edge research. It has also fostered new research projects with inter-disciplinary participation.       Last Modified: 04/10/2013       Submitted by: Frank Mueller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
