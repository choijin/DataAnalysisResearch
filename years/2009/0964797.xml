<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGR:  Perceptually Optimized Semantic Media Adaptation for Mobile Device Access</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2010</AwardEffectiveDate>
<AwardExpirationDate>03/31/2011</AwardExpirationDate>
<AwardTotalIntnAmount>59999.00</AwardTotalIntnAmount>
<AwardAmount>59999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project develops a semantic media adaptation scheme for mobile access of information that is perceptually optimized for users to enjoy semantically relevant media content using small display mobile devices. The research team explores seamless integration of multidisciplinary technologies from computer vision, media coding and transmission, wireless networking, mobile device, and human visual perception to tackle the challenges in closing the gap between rich content in high resolution and size limited mobile device access.&lt;br/&gt;&lt;br/&gt;The intellectual merit of this project lies in the exploration and development of several relevant techniques in (1) Limited user interface media semantic extraction; (2) Capacity and resource constrained media content adaptation; (3) Perceptually optimized delivery and display of adapted media to small sized mobile devices. The research team addresses these issues by seamless integration of technologies from different research fields that traditionally have less interaction. &lt;br/&gt;&lt;br/&gt;The project bridges both semantic gap and user intention gap in mobile multimedia search and access. First, the innovative scheme of semantic adaptation can be extended for any media search application based on semantically relevant characteristics.  Second, the adaptation of high resolution media content for small sized mobile device plays a key role in media gateway for wireless mobile access. Finally, the investigation of perceptual optimized display on mobile devices shall open up a new research avenue to understand how mobile users perceive rich media content with small displays.</AbstractNarration>
<MinAmdLetterDate>03/23/2010</MinAmdLetterDate>
<MaxAmdLetterDate>03/23/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964797</AwardID>
<Investigator>
<FirstName>Chang Wen</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chang Wen Chen</PI_FULL_NAME>
<EmailAddress>chencw@buffalo.edu</EmailAddress>
<PI_PHON>7166454760</PI_PHON>
<NSF_ID>000458930</NSF_ID>
<StartDate>03/23/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Buffalo</Name>
<CityName>Buffalo</CityName>
<ZipCode>142282567</ZipCode>
<PhoneNumber>7166452634</PhoneNumber>
<StreetAddress>520 Lee Entrance</StreetAddress>
<StreetAddress2><![CDATA[Suite 211]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY26</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>038633251</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Buffalo]]></Name>
<CityName>Buffalo</CityName>
<StateCode>NY</StateCode>
<ZipCode>142282567</ZipCode>
<StreetAddress><![CDATA[520 Lee Entrance]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY26</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~59999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The objective of the proposed research is to develop a platform for mobile devices to access the image and video database by means of wireless communication. Typical mobile devices can be smart phones that are available everywhere. One major barrier for developing such platform is to<br />adaptively change the size of image and video to fit relatively small display<br />size of smart phones. The most challenging technical issue is to find a region-of-interest from high definition images and videos and transmit the region for smart phone display that matches exactly the user request.&nbsp;</p> <p>The intellectual merit of this project lies in the exploration and development of several emerging techniques in (1) How the mobile search is executed based on limited user interface of smart phone; (2) How to work with the wireless networks that are changing constantly for information exchange; (3) How to guarantee that the images and videos the system finds for you matches well with users' request. We have answered these three important questions as stated above and have developed algorithms and software to perform these desired functions via simulated wireless networks and smart phones. We have gained significant insight into the challenges of these emerging research topics. The proposed research involves several disciplines of technology in image/video processing and analysis, wireless communication, mobile display, and human perception.&nbsp;</p> <p>The broader impact of this project reaches out to both educational training of both graduate and undergraduate students in computer programming and research methodology. The techniques developed in this project will have significant implications for next generation commercial mobile phones development that will be smart enough to search in the vast image and video<br />database for any particular image or video that a user really wants. We expect to extend the technologies developed in this project to the social networking scenarios in which friends are sharing true media content among themselves via smart mobile devices.</p><br> <p>            Last Modified: 05/16/2011<br>      Modified by: Chang Wen&nbsp;Chen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The objective of the proposed research is to develop a platform for mobile devices to access the image and video database by means of wireless communication. Typical mobile devices can be smart phones that are available everywhere. One major barrier for developing such platform is to adaptively change the size of image and video to fit relatively small display size of smart phones. The most challenging technical issue is to find a region-of-interest from high definition images and videos and transmit the region for smart phone display that matches exactly the user request.   The intellectual merit of this project lies in the exploration and development of several emerging techniques in (1) How the mobile search is executed based on limited user interface of smart phone; (2) How to work with the wireless networks that are changing constantly for information exchange; (3) How to guarantee that the images and videos the system finds for you matches well with users' request. We have answered these three important questions as stated above and have developed algorithms and software to perform these desired functions via simulated wireless networks and smart phones. We have gained significant insight into the challenges of these emerging research topics. The proposed research involves several disciplines of technology in image/video processing and analysis, wireless communication, mobile display, and human perception.   The broader impact of this project reaches out to both educational training of both graduate and undergraduate students in computer programming and research methodology. The techniques developed in this project will have significant implications for next generation commercial mobile phones development that will be smart enough to search in the vast image and video database for any particular image or video that a user really wants. We expect to extend the technologies developed in this project to the social networking scenarios in which friends are sharing true media content among themselves via smart mobile devices.       Last Modified: 05/16/2011       Submitted by: Chang Wen Chen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
