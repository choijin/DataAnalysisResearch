<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Preliminary Investigation of Virtual Tactual Stereognosis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2011</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>154250</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Imagine reaching into your pocket, locating and grasping your car;'s key fob amongst a clutter of coins, bills and keys, then finding the unlock button (not the lock button, not the trunk release, especially not the panic button) and pressing it.  This is an example of Tactual Stereognosis (TS), the ability of people to identify familiar items using touch alone.  It is commonplace and uneventful.  Yet no programmable haptic interface has ever been developed that would allow people to identify virtual objects using what might be termed Virtual Tactual Stereognosis (VTS).  Creating such an interface is a long-range goal of the PIs.  VTS has long been out of reach because it depends on active touch, multi-finger interaction, and bare fingertips, which are all difficult to achieve with existing display technology.  The PIs' recent research has led to a new class of prototype devices (xPaDs), which address each of these limitations.  These devices use friction modulation to control forces between the fingertip and a flat plate.  The basic TPaD (Tactile Pattern Display) can create effects such as virtual textures, virtual bumps and holes, and more.  More advanced versions such as the ShiverPad and SwirlPad synchronize in-plane vibrations to friction levels in order to generate active pushing forces on the fingertip.  It is possible to generate many additional effects with these devices, including virtual edges that can be traced with the fingertip.  The xPaD devices thus appear to be well suited to VTS.  They are active touch devices that work with bare fingertips (in other words, the xPaD is fixed and the finger slides over it). Moreover, they are very compact, potentially enabling multiple panels to be arrayed over the surface of an object in order to support a multi-finger interface.  In this study the PIs will begin exploration of a multi-xPaD interface, by performing experiments on an interface consisting of two opposing ShiverPads with subjects employing a pinch grip (that is, index finger on one ShiverPaD, and thumb on the other), in order to demonstrate "binding," the perceptual fusion of the finger and thumb percepts into an integrated object representation.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  Virtual Tactual Stereognosis is an important goal for many reasons.  Graphical displays have become an important form of interface in venues ranging from the living room, to the office, to the car, to any place that a person may be.  Yet as graphical displays grow more prevalent, natural touch interactions seemingly grow more obsolete.  VTS aims to achieve the opposite, to empower future interfaces with sophisticated tactual capabilities that engage perceptual as well as sensory mechanisms in the hand and brain.  Imagine a doctor able to simultaneously look at and palpate tissue within the body, a pregnant mother able to caress the ultrasound image of her unborn child, an autistic child able to cooperate with an animated character in a construction task, or a driver able to reach out, find and operate touch screen controls without taking his/her eyes off the road.  VTS would be an enabler for new types of electronic displays for the blind.  And it would be a powerful new tool to extend our basic knowledge of haptic perception as it occurs naturally.</AbstractNarration>
<MinAmdLetterDate>07/02/2009</MinAmdLetterDate>
<MaxAmdLetterDate>05/18/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0941581</AwardID>
<Investigator>
<FirstName>J. Edward</FirstName>
<LastName>Colgate</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>J. Edward Colgate</PI_FULL_NAME>
<EmailAddress>colgate@northwestern.edu</EmailAddress>
<PI_PHON>8474914264</PI_PHON>
<NSF_ID>000267549</NSF_ID>
<StartDate>07/02/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Peshkin</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael A Peshkin</PI_FULL_NAME>
<EmailAddress>peshkin@northwestern.edu</EmailAddress>
<PI_PHON>8474914630</PI_PHON>
<NSF_ID>000317165</NSF_ID>
<StartDate>07/02/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606114579</ZipCode>
<StreetAddress><![CDATA[750 N. Lake Shore Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~150000</FUND_OBLG>
<FUND_OBLG>2010~4250</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The touch screen is the preeminent human-computer interface of our times.&nbsp; Touch input technologies such as projected capacitance and in-cell sensing are rapidly advancing.&nbsp; For example, a variety of commercially-available sensors can measure ten or more fingertip contact locations as well as identify gestures.&nbsp; But what about touch output?&nbsp; Here, the technology is far less advanced.&nbsp; Indeed, most touch screen technologies don't provide any haptic feedback at all.&nbsp; In other words, it is not possible to actually feel graphical widgets such as buttons and switches.&nbsp;</p> <p>Intellectual Merit -- Our research focuses on novel technologies for &ldquo;surface haptics&rdquo;, a term that refers to programmable haptic interaction on physical surfaces such as touch screens and touch pads.&nbsp; The engineering literature reveals four main approaches to surface haptics &ndash; vibration, shape, electrotactile, and shear force.&nbsp; &nbsp;Our research on this EAGER project has focused on the last of these.&nbsp; Shear force is uniquely suited to <em>bilateral</em> (e.g., force feedback) interaction between a fingertip and a surface.&nbsp; Among the various approaches, only shear force can be used to affect the actual behavior of the finger.&nbsp; For example, control of shear force can be used to create force patterns that push a fingertip toward a certain spot on the surface.&nbsp; These patterns are perceived as indentations.&nbsp; Patterns that push the finger away from a certain spot are perceived as bumps.&nbsp; &nbsp;More complicated behaviors, such as contours that can be traced with a fingertip, can be created as well.&nbsp;</p> <p>The technical challenge that our group has faced is that of controlling the shear force between an inert surface (typically glass) and a human fingertip.&nbsp; We have approached this by manipulating friction in novels ways. &nbsp;We have developed methods for controlling coefficient of friction, the normal force<em>&nbsp;</em>, and the relative velocity between the finger and the surface<em></em>, and we have developed a variety of devices &ndash; the TPaD, ShiverPaD, SwirlPaD, and ActivePaD &ndash; to demonstrate the methods.&nbsp;</p> <p>Broader Impacts --&nbsp; Our research is laying a technical foundation for future interfaces with sophisticated tactual capabilities that engage not just sensory, but perceptual mechanisms in the hand and brain.&nbsp; Imagine a doctor able to simultaneously look at and palpate tissue inside the body, a pregnant mother able to caress the ultrasound image of her unborn child, an autistic child able to cooperate with an animated character in a construction task, or a driver able to reach out, find and operate touch screen controls without taking eyes off the road.&nbsp; Surface haptics will also be an enabler for new types of electronic displays for the blind and low-sighted.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/09/2011<br>      Modified by: J. Edward&nbsp;Colgate</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The touch screen is the preeminent human-computer interface of our times.  Touch input technologies such as projected capacitance and in-cell sensing are rapidly advancing.  For example, a variety of commercially-available sensors can measure ten or more fingertip contact locations as well as identify gestures.  But what about touch output?  Here, the technology is far less advanced.  Indeed, most touch screen technologies don't provide any haptic feedback at all.  In other words, it is not possible to actually feel graphical widgets such as buttons and switches.   Intellectual Merit -- Our research focuses on novel technologies for "surface haptics", a term that refers to programmable haptic interaction on physical surfaces such as touch screens and touch pads.  The engineering literature reveals four main approaches to surface haptics &ndash; vibration, shape, electrotactile, and shear force.   Our research on this EAGER project has focused on the last of these.  Shear force is uniquely suited to bilateral (e.g., force feedback) interaction between a fingertip and a surface.  Among the various approaches, only shear force can be used to affect the actual behavior of the finger.  For example, control of shear force can be used to create force patterns that push a fingertip toward a certain spot on the surface.  These patterns are perceived as indentations.  Patterns that push the finger away from a certain spot are perceived as bumps.   More complicated behaviors, such as contours that can be traced with a fingertip, can be created as well.   The technical challenge that our group has faced is that of controlling the shear force between an inert surface (typically glass) and a human fingertip.  We have approached this by manipulating friction in novels ways.  We have developed methods for controlling coefficient of friction, the normal force , and the relative velocity between the finger and the surface, and we have developed a variety of devices &ndash; the TPaD, ShiverPaD, SwirlPaD, and ActivePaD &ndash; to demonstrate the methods.   Broader Impacts --  Our research is laying a technical foundation for future interfaces with sophisticated tactual capabilities that engage not just sensory, but perceptual mechanisms in the hand and brain.  Imagine a doctor able to simultaneously look at and palpate tissue inside the body, a pregnant mother able to caress the ultrasound image of her unborn child, an autistic child able to cooperate with an animated character in a construction task, or a driver able to reach out, find and operate touch screen controls without taking eyes off the road.  Surface haptics will also be an enabler for new types of electronic displays for the blind and low-sighted.           Last Modified: 08/09/2011       Submitted by: J. Edward Colgate]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
