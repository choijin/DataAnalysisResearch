<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Medium: Iterative Decoding Beyond Belief Propagation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>674222.00</AwardTotalIntnAmount>
<AwardAmount>682222</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>richard brown</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Error correcting codes are an integral part of modern day communications, computer and data storage systems and play a vital role in ensuring the integrity of data.  At the heart of modern coding theory is the fact that the low-density parity check codes can be efficiently decoded by the algorithm known as belief propagation (BP). The BP is an iterative algorithm which operates on a graphical representation of a code by sending coded bit likelihoods - beliefs. The project establishes a new paradigm and develops tools for the design and analysis of decoding algorithms which are much simpler yet better than belief propagation.  This novel paradigm provides a new angle in addressing a fundamental coding theory questions and a methodology for designing a class of decoding algorithms with provable performance and large flexibility in controlling complexity and speed.&lt;br/&gt;&lt;br/&gt;Unlike BP decoders, these decoders do not propagate beliefs but a rather different kind of messages that reflect the local structure of the code graph.  The methodology for designing such decoders involves identifying graphical structures on which traditional decoders fail, and deriving message passing rules that can correct a majority of these structures with minimal number of bits used in the messages.  New and successively better decoding algorithms are built by adding more bits to the messages passed in a simpler decoder.  The project develops a comprehensive framework to study decoders that achieve the best possible trade-off between the complexity and performance in the low noise region.  Also by increasing the number of bits to represent the input alphabet successively better approximations of the behavior of the decoders for continuous channels are obtained.</AbstractNarration>
<MinAmdLetterDate>09/16/2010</MinAmdLetterDate>
<MaxAmdLetterDate>04/14/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0963726</AwardID>
<Investigator>
<FirstName>Bane</FirstName>
<LastName>Vasic</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bane Vasic</PI_FULL_NAME>
<EmailAddress>vasic@ece.arizona.edu</EmailAddress>
<PI_PHON>5206265550</PI_PHON>
<NSF_ID>000178000</NSF_ID>
<StartDate>09/16/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857194824</ZipCode>
<StreetAddress><![CDATA[888 N Euclid Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramElement>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~674222</FUND_OBLG>
<FUND_OBLG>2015~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Error-correcting codes (ECC) have played a vital role in making sure that digital data maintain their integrity within computer, communication and storage systems. Low-density parity-check (LDPC) codes are a class of linear error correcting codes that are widely used in communication systems and have been standardized in many applications such as wireless communications, deep-space communications, satellite and power-line communications. The ECC chips based on LDPC codes are used or are being developed for magnetic hard disk drives, optical communications and flash memories.</p> <p>&nbsp;The goal of a communication system is to transmit data over different media, called a communication channel, while ensuring that all the data arrives at its destination intact. Error-correction techniques guarantee the flawless transmission of digital messages even in the presence of corrupting influences, called noise. When received under influence of noise, information bits in a data sequence may be flipped from zero to one or vice versa. After receiving the noisy data, the decoder attempts to detect and correct the possible errors that have been occurred during transmitting data.</p> <p>&nbsp;All conventional decoders used for decoding LDPC codes are based on an artificial intelligence algorithm called the belief propagation (BP) decoding algorithm. It has been shown that the LDPC codes when decoded by the BP approach theoretical limits of channel capacity. However, this capacity approaching property holds only in the asymptotic limit of code length, while codes of practical lengths suffer from abrupt performance degradation in the low noise regime known as the error floor phenomenon. Therefore, the need for the design of better decoders for LDPC codes that address the error floor problem is of paramount importance, and this is the main motivation for this project. &nbsp;</p> <p>&nbsp;In this project, we have designed a new framework for decoding of LDPC codes.&nbsp; The new class of decoders is called the finite alphabet iterative decoder (FAID). Not do our decoders correct more errors than the BP decoder, but they require only a fraction of hardware resources needed for implementing the BP decoder.</p> <p>&nbsp;Low hardware complexity or our decoders has led to another possibility &ndash; instead of using one complex decoder such as BP, we can now afford to use multiple FAID decoders in parallel or in series. These decoders are designed to correct different error patterns, but they can collectively correct more error patterns not correctable by any of the individual decoders. The attractiveness of the &ldquo;collective&rdquo; decoding concept is not only theoretical - switching between decoders can be accomplished by minor variations in each decoder and therefore does not require elaborate changes to the decoder architecture on the chip.</p> <p>&nbsp;The techniques that were developed in our group to design better decoders help making computer chips which work faster and consume less energy. These findings have led the PI to establish Codelucida, a start-up company aiming to ensure highly efficient error correction and communication between computer chips on solid-state drives. This endeavor was motivated by the excellent performance of the decoders studied in this project and by the intellectual property developed by the PI and students involved in this project. The enterprise is commercializing hardware and software solutions for iterative decoders, error correction codes, encoders, transmitters, receivers, for various applications such as flash memories, wireless and optical communications.</p> <p>One postdoctoral researcher, five graduate and one undergraduate students have been involved in the project.&nbsp; The students have received broad training in mathematics, science, and engineering, and have successful careers in both academia in industry.&nbsp; Their educational ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Error-correcting codes (ECC) have played a vital role in making sure that digital data maintain their integrity within computer, communication and storage systems. Low-density parity-check (LDPC) codes are a class of linear error correcting codes that are widely used in communication systems and have been standardized in many applications such as wireless communications, deep-space communications, satellite and power-line communications. The ECC chips based on LDPC codes are used or are being developed for magnetic hard disk drives, optical communications and flash memories.   The goal of a communication system is to transmit data over different media, called a communication channel, while ensuring that all the data arrives at its destination intact. Error-correction techniques guarantee the flawless transmission of digital messages even in the presence of corrupting influences, called noise. When received under influence of noise, information bits in a data sequence may be flipped from zero to one or vice versa. After receiving the noisy data, the decoder attempts to detect and correct the possible errors that have been occurred during transmitting data.   All conventional decoders used for decoding LDPC codes are based on an artificial intelligence algorithm called the belief propagation (BP) decoding algorithm. It has been shown that the LDPC codes when decoded by the BP approach theoretical limits of channel capacity. However, this capacity approaching property holds only in the asymptotic limit of code length, while codes of practical lengths suffer from abrupt performance degradation in the low noise regime known as the error floor phenomenon. Therefore, the need for the design of better decoders for LDPC codes that address the error floor problem is of paramount importance, and this is the main motivation for this project.     In this project, we have designed a new framework for decoding of LDPC codes.  The new class of decoders is called the finite alphabet iterative decoder (FAID). Not do our decoders correct more errors than the BP decoder, but they require only a fraction of hardware resources needed for implementing the BP decoder.   Low hardware complexity or our decoders has led to another possibility &ndash; instead of using one complex decoder such as BP, we can now afford to use multiple FAID decoders in parallel or in series. These decoders are designed to correct different error patterns, but they can collectively correct more error patterns not correctable by any of the individual decoders. The attractiveness of the "collective" decoding concept is not only theoretical - switching between decoders can be accomplished by minor variations in each decoder and therefore does not require elaborate changes to the decoder architecture on the chip.   The techniques that were developed in our group to design better decoders help making computer chips which work faster and consume less energy. These findings have led the PI to establish Codelucida, a start-up company aiming to ensure highly efficient error correction and communication between computer chips on solid-state drives. This endeavor was motivated by the excellent performance of the decoders studied in this project and by the intellectual property developed by the PI and students involved in this project. The enterprise is commercializing hardware and software solutions for iterative decoders, error correction codes, encoders, transmitters, receivers, for various applications such as flash memories, wireless and optical communications.  One postdoctoral researcher, five graduate and one undergraduate students have been involved in the project.  The students have received broad training in mathematics, science, and engineering, and have successful careers in both academia in industry.  Their educational experiences have been enriched by the close collaboration between the PI and his French collaborators. A dual degree graduate program has been established ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
