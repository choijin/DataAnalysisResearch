<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Medium: Collaborative Research:  Geometric Network Analysis Tools:  Algorithmic Methods for Identifying Structure in Large Informatics Graphs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>418011.00</AwardTotalIntnAmount>
<AwardAmount>418011</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Frank Olken</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>There has been an enormous amount of work in recent years directed&lt;br/&gt;toward understanding the structural and dynamical properties of&lt;br/&gt;"informatics graphs" or "complex networks." Most of this work has been&lt;br/&gt;on small to medium-sized networks, and it has led to an improved&lt;br/&gt;understanding of the properties of networks arising in many graph&lt;br/&gt;mining applications.  In spite of this, formulating appropriate models&lt;br/&gt;for and answering even basic questions about larger informatics&lt;br/&gt;graphs remains challenging.  For instance, recent work has shown that&lt;br/&gt;dynamic properties as well as basic structural properties of large&lt;br/&gt;informatics graphs are not reproduced even qualitatively by popular&lt;br/&gt;network generative models.&lt;br/&gt;&lt;br/&gt;The proposed work will use traditional and recently-developed&lt;br/&gt;approximation algorithms for the graph partitioning problem as&lt;br/&gt;"experimental probes" of large informatics graphs in order to&lt;br/&gt;characterize in a more robust and scalable manner the structural and&lt;br/&gt;dynamic properties of very large informatics graphs.  This will&lt;br/&gt;include extending and implementing recently-developed algorithms such&lt;br/&gt;as "local" spectral methods and algorithms that intuitively&lt;br/&gt;"interpolate" between spectral and flow-based methods, as well as&lt;br/&gt;revisiting in light of new applications traditional methods such as&lt;br/&gt;the global spectral method and ideas underlying the popular package&lt;br/&gt;Metis.  A central goal will be to provide the analyst with tools that&lt;br/&gt;have sufficient algorithmic and statistical flexibility to&lt;br/&gt;characterize the local and global structures of large networks in a&lt;br/&gt;rich and robust way.&lt;br/&gt;&lt;br/&gt;The Intellectual Merit of the proposed work lies in extending recent&lt;br/&gt;theoretical and algorithmic developments and applying them to very&lt;br/&gt;real-world problems.  The Broader Impact of the project lies in&lt;br/&gt;enhancing interdisciplinary education at Berkeley and Stanford and&lt;br/&gt;more generally.  This will involve the organization of meetings and&lt;br/&gt;courses that will include the opportunity for research projects,&lt;br/&gt;including by students from underrepresented groups, that focus on&lt;br/&gt;bridging theoretical methods and real-world applications.  For&lt;br/&gt;further information see the project web page:&lt;br/&gt;URL:  http://cs.stanford.edu/people/mmahoney/graphmining/</AbstractNarration>
<MinAmdLetterDate>04/28/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0963904</AwardID>
<Investigator>
<FirstName>Satish</FirstName>
<LastName>Rao</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Satish B Rao</PI_FULL_NAME>
<EmailAddress>satishr@cs.berkeley.edu</EmailAddress>
<PI_PHON>5106424328</PI_PHON>
<NSF_ID>000373507</NSF_ID>
<StartDate>04/28/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>BERKELEY</CityName>
<StateCode>CA</StateCode>
<ZipCode>947101749</ZipCode>
<StreetAddress><![CDATA[Sponsored Projects Office]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramElement>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramElement>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~145305</FUND_OBLG>
<FUND_OBLG>2011~136676</FUND_OBLG>
<FUND_OBLG>2012~136030</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Given a corpus of document, what are the topics covered in the corpus?<br />Which topics are covered in each document? Automatically discovering<br />using a computer is termed topic modelling.&nbsp;&nbsp;&nbsp; Numerous approaches<br />for this problem have been proposed in the last few years. This<br />project undertook the task of evaluating these techniques in<br />a common framework and in coming up with more effective evaluation<br />techniques as well as more effective methods.<br /><br />In this project, we decided just looking at the topics that<br />were output was interesting but hard to evaluate. Instead, we<br />regarded a set of topics to be useful, if it could help us<br />predict something new about a document; for example, other related<br />topics, or related language that might be useful.&nbsp; Our framework<br />thus, dropped half of a document and tried to recover information<br />about the dropped half the topic models found using the various<br />approaches. We found that recent sophisticated approaches were<br />actually inferior to older, more established, but more<br />straightforward approaches.&nbsp; We then examined various difficult<br />cases, and derived an approach which were intuitive variations<br />on the traditional effective approaches to get still better<br />methods for topic modelling.<br /><br />In sum, we took a fresh look at topic modelling as a tool for<br />prediction, found that this view reflected negatively on currently<br />popular methods for this task, and found an improved method<br />which works better with this view of the world.<br /><br /><br /><br /><br /><br /></p><br> <p>            Last Modified: 01/06/2014<br>      Modified by: Satish&nbsp;B&nbsp;Rao</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Given a corpus of document, what are the topics covered in the corpus? Which topics are covered in each document? Automatically discovering using a computer is termed topic modelling.    Numerous approaches for this problem have been proposed in the last few years. This project undertook the task of evaluating these techniques in a common framework and in coming up with more effective evaluation techniques as well as more effective methods.  In this project, we decided just looking at the topics that were output was interesting but hard to evaluate. Instead, we regarded a set of topics to be useful, if it could help us predict something new about a document; for example, other related topics, or related language that might be useful.  Our framework thus, dropped half of a document and tried to recover information about the dropped half the topic models found using the various approaches. We found that recent sophisticated approaches were actually inferior to older, more established, but more straightforward approaches.  We then examined various difficult cases, and derived an approach which were intuitive variations on the traditional effective approaches to get still better methods for topic modelling.  In sum, we took a fresh look at topic modelling as a tool for prediction, found that this view reflected negatively on currently popular methods for this task, and found an improved method which works better with this view of the world.             Last Modified: 01/06/2014       Submitted by: Satish B Rao]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
