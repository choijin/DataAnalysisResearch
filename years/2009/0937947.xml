<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative:Balanced Scalable Architectures for Data-Intensive Supercomputing</AwardTitle>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>354018.00</AwardTotalIntnAmount>
<AwardAmount>354018</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). &lt;br/&gt;&lt;br/&gt;The nature of scientific computing is changing: it is becoming increasingly data-centric. We use Amdahl's Laws to quantify (i) what is a data-intensive computational problem, and (ii) what is a data-intensive computational architecture. Based on these objective metrics we propose several different architectural approaches, including some next-generation, low-power processors and storage devices, e.g., Solid-State Drives (SSDs), and consider how these architectures might provide substantial benefits.  &lt;br/&gt;&lt;br/&gt;In this research, we plan to explore approaches where the first steps of the scientific data processing are performed on the backplane of the database servers, the closest we can get to low level scientific data.  We will also explore how we can use trees and arrays, representing very large scientific data sets, in both relational databases and on a MapReduce/Hadoop like environment. &lt;br/&gt;&lt;br/&gt;While SSDs can provide an excellent performance for both sequential and random I/Os, we will still need traditional hard disks for the bulk volume. This research will rethink and redesign our existing database clusters and data management systems, as the emergence of these new devices has undoubtedly introduced exciting opportunities for improving not only performance but also energy efficiency. &lt;br/&gt;&lt;br/&gt;The education and outreach plan in this proposal consists of four tasks: developing educational materials, mentoring underrepresented students, developing collaborations in the industry and public outreach activities. We plan to interleave them to maximize the broader impact on multiple fronts.</AbstractNarration>
<MinAmdLetterDate>08/19/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2009</MaxAmdLetterDate>
<ARRAAmount>354018</ARRAAmount>
<AwardID>0937947</AwardID>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Szalay</LastName>
<EmailAddress>aszalay1@jhu.edu</EmailAddress>
<StartDate>08/19/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>7684</Code>
<Text>CESER-Cyberinfrastructure for</Text>
</ProgramElement>
<ProgramReference>
<Code>6890</Code>
<Text>RECOVERY ACT ACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>7684</Code>
<Text>STRATEGIC TECHNOLOGIES FOR CI</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
