<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Coordinating Language Modeling, Computer Vision, and Machine Learning for Dramatic Advances in Optical Character Recognition</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>463395.00</AwardTotalIntnAmount>
<AwardAmount>487395</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this research is to develop new methods for improving the performance of optical character recognition (OCR) systems. In particular, the PI investigates "iterative contextual modeling", an approach to OCR in which high confidence recognitions of easier document portions are used to help in developing document specific models. These models can be related to appearance--for example a sample of correct words can be used to develop a model for the font in a particular document. In addition, the models can be based on language and vocabulary information. For example, after recognizing a portion of the words in a document, the general topic of the document may be detected, at which point the distribution over likely words in the document can be changed. The ability to modify character appearance distributions and language statistics and tune them specifically to the document at hand is expected to produce significant increases in the quality of OCR results.</AbstractNarration>
<MinAmdLetterDate>08/27/2009</MinAmdLetterDate>
<MaxAmdLetterDate>03/13/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0916555</AwardID>
<Investigator>
<FirstName>Erik</FirstName>
<LastName>Learned-Miller</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Erik Learned-Miller</PI_FULL_NAME>
<EmailAddress>elm@cs.umass.edu</EmailAddress>
<PI_PHON>4135452746</PI_PHON>
<NSF_ID>000342665</NSF_ID>
<StartDate>08/27/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>McCallum</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew K McCallum</PI_FULL_NAME>
<EmailAddress>mccallum@cs.umass.edu</EmailAddress>
<PI_PHON>4135451323</PI_PHON>
<NSF_ID>000253651</NSF_ID>
<StartDate>08/27/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010359450</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~463395</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<FUND_OBLG>2012~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this work, we have made a number of important steps forward for research in optical character recognition (OCR). In our original proposal, we made the point that while OCR has been a successful commercial application of pattern recognition for some time, the level of accuracy is still not sufficient for many applications.</p> <p>We have made five principal contributions to the field supported by this grant. These include 1) a method for assessing which outputs of an OCR system have probability of error below some preset threshold and a method to use the high confidence outputs to build an OCR system specifically adapted to a particular document, without any human intervention, 2) a method to do OCR in any alphabetic language, such as Russian, English, or Greek, given only an electronic dictionary for that language and no information about the appearance of any characters in that language, 3) a new model for the spelling of syllables that can be used to improve research in difficult OCR problems, 4) a new system for recognizing text in outdoor scenes, and 5) a new method for segmenting text in outdoor scenes based on computer graphics rendering.</p> <p><strong>1. Confidence assessment and a document-specific OCR system. </strong>In this work, we ask the question, can we find a way to set aside some of the high confidence outputs of an OCR system, and retrain the character models using some of the data from the current document. That is, can we use correctly recognized text to better model the appearance of words in a document with unique visual appearance? To do this, we need to run a baseline OCR system and figure out which words are correct. Previously, there was no reliable way to assess the confidence in an OCR system's output. In a paper in the Journal of Machine Learning Research, we describe how to assess an upper bound on the probability that a word from an OCR system is correct. Given such a bound, we can set aside words that have very low probability of error. Using these highly reliable words, we can train a new OCR system which has been trained on the specific document of interest. We show how this leads to significant gains in accuracy over using a generically trained OCR system.</p> <p><strong>2. Font-free OCR. </strong>When most people hear that there is an OCR system which isn't given any information about what particular characters look like, they think there has been some error in communication--it sounds impossible. But consider the problem of trying to decode a word in which each letter has been consistently replaced by a number, such as "01221221331". It turns out that the only English word that fits this pattern is "Mississippi". Hence, we can decode the word without knowing anything a priori about how each letter is represented. Such techniques are often called cryptogram technicques, since a cryptogram is a code in which each letter has been substituted with another symbol. Previously, cryptogram techniques had only been applied to very clean, high-resolution documents. In an invited IJDAR paper, we showed how to apply them in difficult-to-read documents where even character segmentation is difficult. We significantly extended the purview of such methods, even outperforming Google's Greek OCR, despite the fact that our method used no training data. This method can be used to perform OCR in any alphabetic language in which the characters are separable. Thus it could be used for Russian, Greek, or Spanish, but not Chinese (non-alphabetic), or Arabic (characters are not separable).</p> <p><strong>3, 4, 5.</strong>&nbsp;Our last three contributions (all presented at ICDAR 2013) are for the problem of "scene text recognition", in which the goal is to recognize words from photos of the real-world--street signs, restaurant signs, and movie marquees. This problem is characterized by very difficult fonts (stylized by graphic designers), non-English...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this work, we have made a number of important steps forward for research in optical character recognition (OCR). In our original proposal, we made the point that while OCR has been a successful commercial application of pattern recognition for some time, the level of accuracy is still not sufficient for many applications.  We have made five principal contributions to the field supported by this grant. These include 1) a method for assessing which outputs of an OCR system have probability of error below some preset threshold and a method to use the high confidence outputs to build an OCR system specifically adapted to a particular document, without any human intervention, 2) a method to do OCR in any alphabetic language, such as Russian, English, or Greek, given only an electronic dictionary for that language and no information about the appearance of any characters in that language, 3) a new model for the spelling of syllables that can be used to improve research in difficult OCR problems, 4) a new system for recognizing text in outdoor scenes, and 5) a new method for segmenting text in outdoor scenes based on computer graphics rendering.  1. Confidence assessment and a document-specific OCR system. In this work, we ask the question, can we find a way to set aside some of the high confidence outputs of an OCR system, and retrain the character models using some of the data from the current document. That is, can we use correctly recognized text to better model the appearance of words in a document with unique visual appearance? To do this, we need to run a baseline OCR system and figure out which words are correct. Previously, there was no reliable way to assess the confidence in an OCR system's output. In a paper in the Journal of Machine Learning Research, we describe how to assess an upper bound on the probability that a word from an OCR system is correct. Given such a bound, we can set aside words that have very low probability of error. Using these highly reliable words, we can train a new OCR system which has been trained on the specific document of interest. We show how this leads to significant gains in accuracy over using a generically trained OCR system.  2. Font-free OCR. When most people hear that there is an OCR system which isn't given any information about what particular characters look like, they think there has been some error in communication--it sounds impossible. But consider the problem of trying to decode a word in which each letter has been consistently replaced by a number, such as "01221221331". It turns out that the only English word that fits this pattern is "Mississippi". Hence, we can decode the word without knowing anything a priori about how each letter is represented. Such techniques are often called cryptogram technicques, since a cryptogram is a code in which each letter has been substituted with another symbol. Previously, cryptogram techniques had only been applied to very clean, high-resolution documents. In an invited IJDAR paper, we showed how to apply them in difficult-to-read documents where even character segmentation is difficult. We significantly extended the purview of such methods, even outperforming Google's Greek OCR, despite the fact that our method used no training data. This method can be used to perform OCR in any alphabetic language in which the characters are separable. Thus it could be used for Russian, Greek, or Spanish, but not Chinese (non-alphabetic), or Arabic (characters are not separable).  3, 4, 5. Our last three contributions (all presented at ICDAR 2013) are for the problem of "scene text recognition", in which the goal is to recognize words from photos of the real-world--street signs, restaurant signs, and movie marquees. This problem is characterized by very difficult fonts (stylized by graphic designers), non-English words (since proper names are common), and very short texts (1-5 words) that make using a language model difficult or impossible.  One contri...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
