<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Upgrade of the Alliance for Computational Earth Science (ACES) high performance computing facility</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2010</AwardEffectiveDate>
<AwardExpirationDate>04/30/2012</AwardExpirationDate>
<AwardTotalIntnAmount>75000.00</AwardTotalIntnAmount>
<AwardAmount>75000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>06030202</Code>
<Directorate>
<Abbreviation>GEO</Abbreviation>
<LongName>Directorate For Geosciences</LongName>
</Directorate>
<Division>
<Abbreviation>EAR</Abbreviation>
<LongName>Division Of Earth Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Russell Kelz</SignBlockName>
<PO_EMAI>rkelz@nsf.gov</PO_EMAI>
<PO_PHON>7032924747</PO_PHON>
</ProgramOfficer>
<AbstractNarration>0948438&lt;br/&gt;Hager&lt;br/&gt;&lt;br/&gt;This grants supports an upgrade of the computer facilities now maintained by the Alliance for Computational Earth Science (ACES) at MIT.   ACES manages cluster computing resources for three academic departments spanning two schools at MIT. Approximately 1/3 of the processors are in the geophysics subcluster, ACES-GEO.  ACES-GEO Pis will  purchase a pre-assembled cluster machine from THINKMATE which would include a controlling node, at least 11 compute nodes and a switch unit.  Node configurations will include multi Quad-core Intel CPU, massive RAM and storage capacities.  The new cluster will support computationally intensive PI and student research involving  geodynamical modeling of Earth and Planetary interiors, geodetic data analysis, cryosphere dynamical modeling, seismic imaging and interpretation, land form evolution, and inversion of remnant magnetization.  The cluster will support the computational needs of four assistant professors, two of whom are women.</AbstractNarration>
<MinAmdLetterDate>05/10/2010</MinAmdLetterDate>
<MaxAmdLetterDate>05/10/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.050</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0948438</AwardID>
<Investigator>
<FirstName>Bradford</FirstName>
<LastName>Hager</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bradford H Hager</PI_FULL_NAME>
<EmailAddress>bhhager@mit.edu</EmailAddress>
<PI_PHON>6172530126</PI_PHON>
<NSF_ID>000208758</NSF_ID>
<StartDate>05/10/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Thomas</FirstName>
<LastName>Herring</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thomas A Herring</PI_FULL_NAME>
<EmailAddress>tah@mit.edu</EmailAddress>
<PI_PHON>6172535941</PI_PHON>
<NSF_ID>000100996</NSF_ID>
<StartDate>05/10/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>van der Hilst</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert D van der Hilst</PI_FULL_NAME>
<EmailAddress>hilst@mit.edu</EmailAddress>
<PI_PHON>6172536977</PI_PHON>
<NSF_ID>000090254</NSF_ID>
<StartDate>05/10/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stephane</FirstName>
<LastName>Rondenay</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stephane Rondenay</PI_FULL_NAME>
<EmailAddress>rondenay@mit.edu</EmailAddress>
<PI_PHON>6172536299</PI_PHON>
<NSF_ID>000109596</NSF_ID>
<StartDate>05/10/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Linda</FirstName>
<LastName>Elkins-Tanton</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Linda T Elkins-Tanton</PI_FULL_NAME>
<EmailAddress>ltelkins@asu.edu</EmailAddress>
<PI_PHON>4807272451</PI_PHON>
<NSF_ID>000599702</NSF_ID>
<StartDate>05/10/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>1580</Code>
<Text>Instrumentation &amp; Facilities</Text>
</ProgramElement>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~75000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>A broad group of MIT researchers have formed a coalition, called Alliance for Computational Earth Science (ACES) at MIT, that focuses on developing and deploying advanced computational technologies to address challenging problems of Earth science. The EAR-funded subset of these researchers acquired $75,000 under this grant to upgrade the then existing ACES cluster. Funds from this grant were leveraged with ~ $225k of funding from several other investigators and from MIT institutional funds. These funds were used to purchase and assemble an Infiniband-interconnected cluster with 456 Intel Westmere cores, a total of 2TB memory, and 200TB of&nbsp;shared storage. Serious issues facing cluster computing at MIT and elsewhere include the need for precious space with substantial cooling capacity and power.&nbsp; To solve these problems, MIT has developed and operates a shared, purpose built computer facility&nbsp;off campus in a facility that was built previously to house a particle accelerator. A 10 gigabit ethernet network connects the facility (including our system) to the main campus.</p> <p class="PropParagraph">The system supports research computing for about 50 users, using a queue system to manage access to resources. To date almost 50,000 jobs have been run on the system, with typical job sizes ranging from 6 to 200 cores.&nbsp; This readily accessible high performance computing facility is beginning to enable a broad portfolio of research, with funding from NSF, other governmental agencies, and industry.&nbsp; Because the cluster has been running at full capacity for less than a year, the facility has not yet had time to result in many publications. Important findings will be forthcoming shortly.</p> <p class="PropParagraph"><em>Intellectual Merit</em>:&nbsp; The upgraded ACES cluster at MIT is allowing the application of advanced computing technologies to solve a wide variety of Earth science problems.&nbsp; The areas of research being carried out on the cluster include geodynamical modeling of both the Earth and other bodies in various evolutionary stages, analysis geodetic data, ice sheet models (and other dynamic systems) driven by large data sets, seismic imaging and interpretation, land form evolution, and inversion of remnant magnetization.&nbsp; The participants interact and exchange ideas across a broad set of topics and among the new developments in computational methods, modeling, and data analysis to be explored and implemented.</p> <p class="PropParagraph"><em>Broader impacts</em>: The upgraded cluster is being used for educating undergraduate and graduate students in the rapidly developing field of computational science, a matter of national interest. The coinvestigators on this proposal have an excellent track record of educating both undergraduate and graduate students.&nbsp; Most of our undergraduate majors and about half of our graduate students are women. The ACES upgrade is providing these young investigators the hardware and software necessary to produce more complete and comprehensive models and simulations in vastly shorter time frames. Additionally, by leveraging the experience and knowledge of existing ACES investigators in high performance computing and parallel programming, these new investigators enjoy additional productivity gains.</p> <p class="PropParagraph">The software to be developed on the ACES cluster will be open-source or freely available to academic researchers. The core of the queuing, scheduling and check-pointing software is also open source.&nbsp; The developments made on ACES will be readily accessible to other investigators including those using somewhat smaller clusters.</p> <p class="PropParagraph">Societally important problems are being addressed using the ACES system. Problems addressed include estimating the state of the sea surface and how it responds to climate change. Understanding volcanic and magmatic systems...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ A broad group of MIT researchers have formed a coalition, called Alliance for Computational Earth Science (ACES) at MIT, that focuses on developing and deploying advanced computational technologies to address challenging problems of Earth science. The EAR-funded subset of these researchers acquired $75,000 under this grant to upgrade the then existing ACES cluster. Funds from this grant were leveraged with ~ $225k of funding from several other investigators and from MIT institutional funds. These funds were used to purchase and assemble an Infiniband-interconnected cluster with 456 Intel Westmere cores, a total of 2TB memory, and 200TB of shared storage. Serious issues facing cluster computing at MIT and elsewhere include the need for precious space with substantial cooling capacity and power.  To solve these problems, MIT has developed and operates a shared, purpose built computer facility off campus in a facility that was built previously to house a particle accelerator. A 10 gigabit ethernet network connects the facility (including our system) to the main campus. The system supports research computing for about 50 users, using a queue system to manage access to resources. To date almost 50,000 jobs have been run on the system, with typical job sizes ranging from 6 to 200 cores.  This readily accessible high performance computing facility is beginning to enable a broad portfolio of research, with funding from NSF, other governmental agencies, and industry.  Because the cluster has been running at full capacity for less than a year, the facility has not yet had time to result in many publications. Important findings will be forthcoming shortly. Intellectual Merit:  The upgraded ACES cluster at MIT is allowing the application of advanced computing technologies to solve a wide variety of Earth science problems.  The areas of research being carried out on the cluster include geodynamical modeling of both the Earth and other bodies in various evolutionary stages, analysis geodetic data, ice sheet models (and other dynamic systems) driven by large data sets, seismic imaging and interpretation, land form evolution, and inversion of remnant magnetization.  The participants interact and exchange ideas across a broad set of topics and among the new developments in computational methods, modeling, and data analysis to be explored and implemented. Broader impacts: The upgraded cluster is being used for educating undergraduate and graduate students in the rapidly developing field of computational science, a matter of national interest. The coinvestigators on this proposal have an excellent track record of educating both undergraduate and graduate students.  Most of our undergraduate majors and about half of our graduate students are women. The ACES upgrade is providing these young investigators the hardware and software necessary to produce more complete and comprehensive models and simulations in vastly shorter time frames. Additionally, by leveraging the experience and knowledge of existing ACES investigators in high performance computing and parallel programming, these new investigators enjoy additional productivity gains. The software to be developed on the ACES cluster will be open-source or freely available to academic researchers. The core of the queuing, scheduling and check-pointing software is also open source.  The developments made on ACES will be readily accessible to other investigators including those using somewhat smaller clusters. Societally important problems are being addressed using the ACES system. Problems addressed include estimating the state of the sea surface and how it responds to climate change. Understanding volcanic and magmatic systems can have a direct societal impact in volcanically active regions, as does the more detailed understanding of plate movements, seismicity (including induced seismicity). The elements needed to understand these classes of problems are included in the ACES science section.  Al...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
