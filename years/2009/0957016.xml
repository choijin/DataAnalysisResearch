<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Context-based Indoor Object Detection</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>101671.00</AwardTotalIntnAmount>
<AwardAmount>133671</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Robust and efficient indoor object detection can help people with severe vision impairment to independently access unfamiliar indoor environments. However, most existing object detection methods are developed either for a specific type of object (e.g. face) or for general nature objects (e.g., building, sky, etc) which cannot be directly applied to indoor objects due to following challenges: 1) big inter-class variations of the object model among different indoor environments, 2) small intra-class variations of different object models, 3) less texture compared to objects in natural scene or outdoor environments, 4) only part of the object is captured due to occlusions or blind user, 5) view and scale variations of the objects caused by the position and distance change between the user and the object, and 6) lack of suitable databases.&lt;br/&gt;&lt;br/&gt;This EAGER project is to explore new methods to detect indoor objects by incorporating the context information from signs (both text and iconic) and other visual clues such as signage of bathrooms and elevator floor numbers. The research enriches the study of object detection by incorporating context information, and leads to significant improvements over existing methods. The methods developed in this project provide new strategies and technologies for the blind and visually impaired to access unfamiliar indoor environments. The research also benefits many important research areas including video surveillance, intelligent conference rooms, video indexing, and human-computer interactions.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/16/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/08/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0957016</AwardID>
<Investigator>
<FirstName>YingLi</FirstName>
<LastName>Tian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>YingLi Tian</PI_FULL_NAME>
<EmailAddress>ytian@ccny.cuny.edu</EmailAddress>
<PI_PHON>2126507046</PI_PHON>
<NSF_ID>000517490</NSF_ID>
<StartDate>09/16/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>CUNY City College</Name>
<CityName>New York</CityName>
<ZipCode>100319101</ZipCode>
<PhoneNumber>2126505418</PhoneNumber>
<StreetAddress>Convent Ave at 138th St</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>603503991</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073268849</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[CUNY City College]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100319101</ZipCode>
<StreetAddress><![CDATA[Convent Ave at 138th St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~101671</FUND_OBLG>
<FUND_OBLG>2011~16000</FUND_OBLG>
<FUND_OBLG>2012~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Robust and efficient indoor object detection can help people with severe vision impairment to independently access unfamiliar indoor environments. With the support of this project, we have developed several new to detect indoor objects by incorporating the context information from signs (both text and iconic) and other visual clues such as floor map, etc. In particular, we have developed a navigation prototype system for blind people to find destinations, missing items, clothing colors and patterns. The research enriches the study of object detection by incorporating context information, and leads to significant improvements over existing methods. The methods developed in this project provide new strategies and technologies for the blind and visually impaired to access unfamiliar indoor environments. The research also benefits many important research areas including video surveillance, intelligent conference rooms, video indexing, and human-computer interactions. We have published a total of 46 papers in conferences and journals supported in part by this project and 4 more papers under review.</p> <p>With the support of this project and the REU program, A total of 4 PhD students, 5 masters students, 7 undergraduate students (5 of them are minority students) participated the project. Students have gained interdisciplinary knowledge and unique research experience in video processing and data mining technologies, real problem solving skills, as well as theoretical model development. The research experience have prepared them for graduate study and careers in industry. The research findings are used in PI&rsquo;s courses for both undergraduate and graduate students.</p><br> <p>            Last Modified: 09/04/2013<br>      Modified by: Ying Li&nbsp;Tian</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Robust and efficient indoor object detection can help people with severe vision impairment to independently access unfamiliar indoor environments. With the support of this project, we have developed several new to detect indoor objects by incorporating the context information from signs (both text and iconic) and other visual clues such as floor map, etc. In particular, we have developed a navigation prototype system for blind people to find destinations, missing items, clothing colors and patterns. The research enriches the study of object detection by incorporating context information, and leads to significant improvements over existing methods. The methods developed in this project provide new strategies and technologies for the blind and visually impaired to access unfamiliar indoor environments. The research also benefits many important research areas including video surveillance, intelligent conference rooms, video indexing, and human-computer interactions. We have published a total of 46 papers in conferences and journals supported in part by this project and 4 more papers under review.  With the support of this project and the REU program, A total of 4 PhD students, 5 masters students, 7 undergraduate students (5 of them are minority students) participated the project. Students have gained interdisciplinary knowledge and unique research experience in video processing and data mining technologies, real problem solving skills, as well as theoretical model development. The research experience have prepared them for graduate study and careers in industry. The research findings are used in PIÃ†s courses for both undergraduate and graduate students.       Last Modified: 09/04/2013       Submitted by: Ying Li Tian]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
