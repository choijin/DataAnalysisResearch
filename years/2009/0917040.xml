<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC-Small:Interactive Auditory Displays</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>499982.00</AwardTotalIntnAmount>
<AwardAmount>547665</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Interactive Auditory Displays&lt;br/&gt;&lt;br/&gt;PI: Ming C. Lin&lt;br/&gt;Co-PIs: Gary Bishop and Dinesh Manocha&lt;br/&gt;Department of Computer Science&lt;br/&gt;University of North Carolina at Chapel Hill&lt;br/&gt;&lt;br/&gt;An auditory display utilizes sound to communicate information to a user and offers an alternative means of visualization.  By harnessing the sense of hearing, audio rendering can further enhance a user's experience in a multimodal virtual world.  Acoustic realism has many areas of applicability including virtual reality, computer gaming, training systems, desktop interfaces, education, and scientific visualization.&lt;br/&gt;&lt;br/&gt;We are conducting an ambitious research program to develop interactive auditory displays.  Our goal is to develop new algorithms for physics-based sound synthesis and sound propagation for interactive applications including computer gaming, training systems, and enabling technologies. The approach involves the fusion of both geometry (for high frequencies) and physics (for low frequencies) to model sound propagation and the development of techniques for acoustic levels of detail. To this end we are developing efficient numerical algorithms based on domain decomposition and exploiting modern architecture features to further accelerate the overall performance. We are also evaluating the performance of our algorithms on different applications. In addition to acoustic simulation, our research is generating a fundamental scientific foundation and interactive performance methods for solving wave/sound propagation problems in highly complex domains that span many scientific and engineering disciplines.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/10/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0917040</AwardID>
<Investigator>
<FirstName>Gary</FirstName>
<LastName>Bishop</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gary Bishop</PI_FULL_NAME>
<EmailAddress>bishop@cs.unc.edu</EmailAddress>
<PI_PHON>9199621886</PI_PHON>
<NSF_ID>000260864</NSF_ID>
<StartDate>07/10/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dinesh</FirstName>
<LastName>Manocha</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dinesh Manocha</PI_FULL_NAME>
<EmailAddress>dm@cs.umd.edu</EmailAddress>
<PI_PHON>9192184986</PI_PHON>
<NSF_ID>000291378</NSF_ID>
<StartDate>07/10/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ming</FirstName>
<LastName>Lin</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ming C Lin</PI_FULL_NAME>
<EmailAddress>lin@cs.umd.edu</EmailAddress>
<PI_PHON>3014052662</PI_PHON>
<NSF_ID>000453947</NSF_ID>
<StartDate>07/10/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Chapel Hill]]></Name>
<CityName>CHAPEL HILL</CityName>
<StateCode>NC</StateCode>
<ZipCode>275991350</ZipCode>
<StreetAddress><![CDATA[104 AIRPORT DR STE 2200]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~328894</FUND_OBLG>
<FUND_OBLG>2010~218771</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Extending the frontier of visual computing, an auditory display utilizes sound to communicate information to a user and offers an alternative means of visualization. By harnessing the sense of hearing, audio rendering can further enhance a user&rsquo;s experience in a multimodal virtual world. In addition to immersive environments, auditory displays can provide a natural and intuitive human-computer interface for many desktop applications. Furthermore, audio interfaces are increasingly used to develop assistive technologies for the visually impaired. Despite the significance of hearing as one of the dominant senses, auditory displays have not received as much attention as computer graphics.</p> <p>The driving impetus of our research comes from <em><span style="text-decoration: underline;">interactive</span></em> applications, including emergency personnel training systems, desktop interfaces, education, scientific visualization and computer-aided design.&nbsp; Furthermore, interactive modeling and simulation of acoustic spaces can significantly enhance numerous scientific and engineering applications. However, due to intrinsic characteristics of sound, interactive auditory displays pose major computational challenges.</p> <p>&nbsp;</p> <p><strong>INTELLECTUAL MERIT</strong></p> <p>The following major scientific contributions have been achieved during this project:</p> <p>(1)&nbsp; new interactive acoustic algorithms for dynamic virtual environments using acoustics transfer operators, equivalent source methods, and adaptive spatial decomposition;</p> <p>(2)&nbsp; novel sound generation algorithm for liquids based on bubble acoustics;</p> <p>(3)&nbsp; automatic extraction of material properties from one audio sample;</p> <p>(4)&nbsp; innovative application for rapid acoustic prototyping of complex 3D structures for conceptual design and assistive technology.</p> <p>&nbsp;</p> <p><strong>BROADER IMPACT</strong></p> <p>Applications and impacts of interactive auditory displays enabled by new scientific advances include enabling technologies for visually impaired, multimodal human-centric interfaces, immersive teleconferencing, rapid prototyping of acoustic spaces for urban planning, structural design, and reduction of noise pollution.&nbsp; In addition, this research could also offer a fundamentally new solver for wave propagation problems in highly complex, vast domains for seismology, geophysics, meteorology, engineering design, urban planning, etc.</p> <p>The resulting research has been demonstrated to thousands of K-12 students and senior members in the nearby communities and in NC, helping to attract K-12 students and enhance study opportunities for under-represented groups and women students. &nbsp;&nbsp;Two Ph.D. students have completed their doctoral dissertation supported by this grant; and other graduate and undergraduate students working on the project were also partially supported. Resulting software systems have been licensed to a start-up company, creating new jobs for the local community.&nbsp; They are also under further development for designing accessible games for children with disabilities.&nbsp;&nbsp; Tens of refereed publications are disseminated through websites, courses, and international conferences.</p><br> <p>            Last Modified: 09/10/2014<br>      Modified by: Ming&nbsp;C&nbsp;Lin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Extending the frontier of visual computing, an auditory display utilizes sound to communicate information to a user and offers an alternative means of visualization. By harnessing the sense of hearing, audio rendering can further enhance a userÃ†s experience in a multimodal virtual world. In addition to immersive environments, auditory displays can provide a natural and intuitive human-computer interface for many desktop applications. Furthermore, audio interfaces are increasingly used to develop assistive technologies for the visually impaired. Despite the significance of hearing as one of the dominant senses, auditory displays have not received as much attention as computer graphics.  The driving impetus of our research comes from interactive applications, including emergency personnel training systems, desktop interfaces, education, scientific visualization and computer-aided design.  Furthermore, interactive modeling and simulation of acoustic spaces can significantly enhance numerous scientific and engineering applications. However, due to intrinsic characteristics of sound, interactive auditory displays pose major computational challenges.     INTELLECTUAL MERIT  The following major scientific contributions have been achieved during this project:  (1)  new interactive acoustic algorithms for dynamic virtual environments using acoustics transfer operators, equivalent source methods, and adaptive spatial decomposition;  (2)  novel sound generation algorithm for liquids based on bubble acoustics;  (3)  automatic extraction of material properties from one audio sample;  (4)  innovative application for rapid acoustic prototyping of complex 3D structures for conceptual design and assistive technology.     BROADER IMPACT  Applications and impacts of interactive auditory displays enabled by new scientific advances include enabling technologies for visually impaired, multimodal human-centric interfaces, immersive teleconferencing, rapid prototyping of acoustic spaces for urban planning, structural design, and reduction of noise pollution.  In addition, this research could also offer a fundamentally new solver for wave propagation problems in highly complex, vast domains for seismology, geophysics, meteorology, engineering design, urban planning, etc.  The resulting research has been demonstrated to thousands of K-12 students and senior members in the nearby communities and in NC, helping to attract K-12 students and enhance study opportunities for under-represented groups and women students.   Two Ph.D. students have completed their doctoral dissertation supported by this grant; and other graduate and undergraduate students working on the project were also partially supported. Resulting software systems have been licensed to a start-up company, creating new jobs for the local community.  They are also under further development for designing accessible games for children with disabilities.   Tens of refereed publications are disseminated through websites, courses, and international conferences.       Last Modified: 09/10/2014       Submitted by: Ming C Lin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
