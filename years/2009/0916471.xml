<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF:Small:Visual Information Measures for Task-Based Imaging Applications</AwardTitle>
<AwardEffectiveDate>08/01/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardAmount>268261</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Many digital images are not acquired for documentary evidence or for archival use, but instead are intermediate pieces of information to be ultimately used by a human to assess a situation, make a decision, or reach a conclusion. Often, the image need not provide "picture-perfect quality" in order for a human to successfully perform a task - consider security screening of carry-on baggage, for example. Many tasks can be easily performed with images that would be considered to be severely degraded in a purely aesthetic sense.  To date, however, image assessment algorithms have been primarily focused on evaluating aesthetic quality.  These algorithms are typically designed for relatively high-quality images, and they do not perform well on highly degraded images which exhibit low aesthetic quality but remain useful for human-performed tasks.&lt;br/&gt;&lt;br/&gt;This research characterizes the suitability of an image for recognition and the perceived utility in terms of conveying information about content. The characterization is performed in terms of properties of the image, rather than in terms of the response of higher-level vision to the image, and is based upon extensive subjective experiments quantifing the perceived utility of highly degraded images and identifing recognition thresholds for images - maximally degraded images that still allow recognition.  A utility measure is developed which takes as input the original image and the distorted image and outputs a distance quantifying the amount of degradation in the image relative to both the recognition threshold (at the low end) and to the original or a visually lossless representation of the original (at the high end).  Use of this measure is demonstrated by integration this measure into imaging applications including compression and enhancement.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/27/2009</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0916471</AwardID>
<Investigator>
<FirstName>Sheila</FirstName>
<LastName>Hemami</LastName>
<EmailAddress>hemami@ece.neu.edu</EmailAddress>
<StartDate>07/27/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
