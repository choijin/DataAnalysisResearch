<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium:  New Tools and Methods for Very-Large-Scale Phonetics Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>449927.00</AwardTotalIntnAmount>
<AwardAmount>449927</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The field of phonetics has experienced two revolutions in the last century: the advent of the sound spectrograph in the 1950s and the application of computers beginning in the 1970s. Today, advances in digital multimedia, networking and mass storage are promising a third revolution: a movement from the study of small, individual datasets to the analysis of published corpora that are several orders of magnitude larger.&lt;br/&gt;&lt;br/&gt;These new bodies of data are badly needed, to enable the field of phonetics to develop and test hypotheses across languages and across the many types of individual, social and contextual variation. However, in contrast to speech technology research, speech science has so far taken relatively little advantage of this opportunity, because access to these resources for phonetics research requires tools and methods that are now incomplete, untested, and inaccessible to most researchers.&lt;br/&gt;&lt;br/&gt;This project fills this gap by integrating, adapting and improving techniques developed in speech technology research, mainly forced alignment of digital audio with phonetic representations derived from orthographic transcripts. The research will help the field of phonetics to enter a new era: conducting research using very large speech corpora, in the range from hundreds of hours to hundreds of thousands of hours.</AbstractNarration>
<MinAmdLetterDate>06/24/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/25/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964556</AwardID>
<Investigator>
<FirstName>Susan</FirstName>
<LastName>Davidson</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Susan B Davidson</PI_FULL_NAME>
<EmailAddress>susan@cis.upenn.edu</EmailAddress>
<PI_PHON>2158983490</PI_PHON>
<NSF_ID>000135773</NSF_ID>
<StartDate>06/24/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Liberman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark Liberman</PI_FULL_NAME>
<EmailAddress>myl@unagi.cis.upenn.edu</EmailAddress>
<PI_PHON>2155735490</PI_PHON>
<NSF_ID>000118365</NSF_ID>
<StartDate>06/24/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andreas</FirstName>
<LastName>Stolcke</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andreas Stolcke</PI_FULL_NAME>
<EmailAddress>stolcke@speech.sri.com</EmailAddress>
<PI_PHON>5106662969</PI_PHON>
<NSF_ID>000490048</NSF_ID>
<StartDate>06/24/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jiahong</FirstName>
<LastName>Yuan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jiahong Yuan</PI_FULL_NAME>
<EmailAddress>jiahong@ling.upenn.edu</EmailAddress>
<PI_PHON>2157463136</PI_PHON>
<NSF_ID>000148891</NSF_ID>
<StartDate>06/24/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Wen</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wen Wang</PI_FULL_NAME>
<EmailAddress>wen.wang@sri.com</EmailAddress>
<PI_PHON>6508593571</PI_PHON>
<NSF_ID>000588067</NSF_ID>
<StartDate>06/28/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<StreetAddress2><![CDATA[3451 Walnut St, 5th Flr Franklin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042250712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042250712</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pennsylvania]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191046205</ZipCode>
<StreetAddress><![CDATA[Research Services]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~177869</FUND_OBLG>
<FUND_OBLG>2011~159923</FUND_OBLG>
<FUND_OBLG>2012~112135</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp; &nbsp; With the progression of computer and computation technology, phonetics is undergoing a revolution from individual observations and measurements to data- and computation-intensive methodologies. This project developed new tools and methods that make it possible to use large speech corpora in phonetics research and all other sciences of spoken language, from not only within linguistics, but also in psychology, in clinical applications, and in the social sciences.</p> <p>&nbsp; &nbsp; We developed and distributed open-source software for automated alignment of orthographic transcriptions and audio recordings. We also made this software available as a web service, and have integrated a new version into the NSF-sponsored "Language Grid" project. Among many other applications, this software was used in preparing the oyez.org digital archive of U.S. Supreme Court oral arguments. This software has been used in more than 100 journal and conference publications and 10 dissertations and theses.</p> <p>&nbsp; &nbsp; We developed and tested new algorithms for fine-scale phonetic alignment, achieving significantly better accuracy against human phonetic annotation than has ever been achieved before. We also developed and tested successful algorithms for automatic phonetic analysis, including detection of speech activity, detection of speech disfluencies, measurement of phonetic variation (such as /l/ pronunciation, &ldquo;g-dropping&rdquo;, nasalization, VOT, etc.), Mandarin tone recognition, and a Bayesian approach to produce accurate automated formant analyses.</p> <p>&nbsp; &nbsp; We organized a workshop on new tools and methods for very-large-scale phonetics research. We developed a large corpus on Mandarin phonetic segmentation and tone. The corpus will be distributed by the Linguistic Data Consortium.&nbsp;</p><br> <p>            Last Modified: 03/17/2015<br>      Modified by: Jiahong&nbsp;Yuan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[     With the progression of computer and computation technology, phonetics is undergoing a revolution from individual observations and measurements to data- and computation-intensive methodologies. This project developed new tools and methods that make it possible to use large speech corpora in phonetics research and all other sciences of spoken language, from not only within linguistics, but also in psychology, in clinical applications, and in the social sciences.      We developed and distributed open-source software for automated alignment of orthographic transcriptions and audio recordings. We also made this software available as a web service, and have integrated a new version into the NSF-sponsored "Language Grid" project. Among many other applications, this software was used in preparing the oyez.org digital archive of U.S. Supreme Court oral arguments. This software has been used in more than 100 journal and conference publications and 10 dissertations and theses.      We developed and tested new algorithms for fine-scale phonetic alignment, achieving significantly better accuracy against human phonetic annotation than has ever been achieved before. We also developed and tested successful algorithms for automatic phonetic analysis, including detection of speech activity, detection of speech disfluencies, measurement of phonetic variation (such as /l/ pronunciation, "g-dropping", nasalization, VOT, etc.), Mandarin tone recognition, and a Bayesian approach to produce accurate automated formant analyses.      We organized a workshop on new tools and methods for very-large-scale phonetics research. We developed a large corpus on Mandarin phonetic segmentation and tone. The corpus will be distributed by the Linguistic Data Consortium.        Last Modified: 03/17/2015       Submitted by: Jiahong Yuan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
