<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Learning Models for Scalable Content-Based Image Retrieval</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2010</AwardEffectiveDate>
<AwardExpirationDate>03/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>494964.00</AwardTotalIntnAmount>
<AwardAmount>494964</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project addresses the design of machine learning algorithms enabling content-based image retrieval in Web-scale collections of photos. This research formulates image retrieval as a binary classification problem: decide which database images are the "same" as the user-provided photo. Efficiency and scalability to large collections are achieved by constraining the classifiers to be models supported by traditional text-search engines, which perform real-time search in databases of several billion documents. In order to implement search based on high-level notions of similarity, the research team develops methods to automatically localize the most content-relevant regions in the input photo and to extract from them semantically powerful classifiers combining appearance cues with robust geometric constraints. The algorithms learn from user-provided labels indicating the presence but not the location of similar visual content, thus requiring a minimal amount of human supervision. This research investigates also how this advanced form of similar-image search can be used to organize personal photos, provide semantic annotations, and support content-based clustering of pictures.  Furthermore, this work provides technical advances in a wide range of computer vision problems including object detection, visual saliency, and content-based clustering of photos. Moreover, the research team is collecting an unprecedentedly large image data set to evaluate the developed image retrieval system and to be  available to the community. Research is naturally integrated with education and outreach by means of related courses and out-of-classroom activities aimed at attracting students to this field and at encouraging interdisciplinary collaborations.</AbstractNarration>
<MinAmdLetterDate>03/23/2010</MinAmdLetterDate>
<MaxAmdLetterDate>03/08/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0952943</AwardID>
<Investigator>
<FirstName>Lorenzo</FirstName>
<LastName>Torresani</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lorenzo Torresani</PI_FULL_NAME>
<EmailAddress>lorenzo@cs.dartmouth.edu</EmailAddress>
<PI_PHON>6036463048</PI_PHON>
<NSF_ID>000533673</NSF_ID>
<StartDate>03/23/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Dartmouth College</Name>
<CityName>HANOVER</CityName>
<ZipCode>037551421</ZipCode>
<PhoneNumber>6036463007</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROJECTS</StreetAddress>
<StreetAddress2><![CDATA[11 ROPE FERRY RD #6210]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041027822</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF DARTMOUTH COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041027822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dartmouth College]]></Name>
<CityName>HANOVER</CityName>
<StateCode>NH</StateCode>
<ZipCode>037551421</ZipCode>
<StreetAddress><![CDATA[OFFICE OF SPONSORED PROJECTS]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NH02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~228710</FUND_OBLG>
<FUND_OBLG>2013~130104</FUND_OBLG>
<FUND_OBLG>2014~136150</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary goal of this project was the design of novel methods and representations to address two fundamental scalability challenges in learning-based computer vision:</p> <p>1. Modern applications of computer vision tend to have very tight efficiency requirements. For example, systems may need to operate in real-time on massive image collections (e.g., the photos on the Web) or perhaps run on low-power mobile devices. Most existing learning-based vision models are simply too computationally expensive to be used in these settings.</p> <p>2. The typical learning-to-see paradigm of machine vision requires training models on massive collections of manually labeled image examples. For instance, in order to train an image recognition model, human observers must annotate thousands of photos with the names of the objects appearing in them and delineate by hand the regions containing the objects of interest in all the image examples so the computer can learn to separate them from their background.&nbsp;</p> <p>To tackle these two scalability problems the PI developed algorithms that can learn visual models with minimal human supervision and that can support real-time analysis in Web-scale image collections. This research has centered around the design of several novel image descriptors that require very little storage space (as small as 100 bytes per image) and produce high recognition accuracy even with few training examples and highly efficient recognition models, such as linear classifiers. These image descriptors are inspired by the visual learning mechanism exploited by humans. It has been shown that humans learn to recognize a new object class by relating it to classes we already know. For example, given a few pictures of an animal that we have never seen before, we form a conceptual model of this new class by defining it in terms of similar, already-known animals. Following this analogy, our descriptors represent each image in terms of its visual closeness to a predefined set of object classes.</p> <p>The technical advances produced by this project have extended beyond the areas of computer vision and machine learning. Both the PI and other researchers have applied the methods and findings of this project to several other disciplines. For example, our compact image descriptor has been successfully applied to problems involving multimedia Web document search, video event analysis, and robot localization. This project has also provided the opportunity to train in research two PhD students, who have been closely involved in several aspects of this work.&nbsp;</p><br> <p>            Last Modified: 08/03/2017<br>      Modified by: Lorenzo&nbsp;Torresani</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The primary goal of this project was the design of novel methods and representations to address two fundamental scalability challenges in learning-based computer vision:  1. Modern applications of computer vision tend to have very tight efficiency requirements. For example, systems may need to operate in real-time on massive image collections (e.g., the photos on the Web) or perhaps run on low-power mobile devices. Most existing learning-based vision models are simply too computationally expensive to be used in these settings.  2. The typical learning-to-see paradigm of machine vision requires training models on massive collections of manually labeled image examples. For instance, in order to train an image recognition model, human observers must annotate thousands of photos with the names of the objects appearing in them and delineate by hand the regions containing the objects of interest in all the image examples so the computer can learn to separate them from their background.   To tackle these two scalability problems the PI developed algorithms that can learn visual models with minimal human supervision and that can support real-time analysis in Web-scale image collections. This research has centered around the design of several novel image descriptors that require very little storage space (as small as 100 bytes per image) and produce high recognition accuracy even with few training examples and highly efficient recognition models, such as linear classifiers. These image descriptors are inspired by the visual learning mechanism exploited by humans. It has been shown that humans learn to recognize a new object class by relating it to classes we already know. For example, given a few pictures of an animal that we have never seen before, we form a conceptual model of this new class by defining it in terms of similar, already-known animals. Following this analogy, our descriptors represent each image in terms of its visual closeness to a predefined set of object classes.  The technical advances produced by this project have extended beyond the areas of computer vision and machine learning. Both the PI and other researchers have applied the methods and findings of this project to several other disciplines. For example, our compact image descriptor has been successfully applied to problems involving multimedia Web document search, video event analysis, and robot localization. This project has also provided the opportunity to train in research two PhD students, who have been closely involved in several aspects of this work.        Last Modified: 08/03/2017       Submitted by: Lorenzo Torresani]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
