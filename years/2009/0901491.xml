<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Implicit Learning-Based Optimal Control of Uncertain Nonlinear Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2009</AwardEffectiveDate>
<AwardExpirationDate>07/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>306000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Werbos</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>A Summary&lt;br/&gt;Project Summary: This project focuses on the synthesis of new implicit learning-based methods that&lt;br/&gt;can optimally achieve some control objective for an uncertain nonlinear system. The main research goals&lt;br/&gt;include the development and experimental verification of implicit learning and adaptive methods that enable&lt;br/&gt;the mismatch between the desired and actual response of an uncertain nonlinear system to converge&lt;br/&gt;while optimizing a trade-off between performance and control energy. Efforts will investigate if different&lt;br/&gt;learning and adaptive methods have properties that yield more optimal solutions or lead to improved stability&lt;br/&gt;margins. Progress on this research topic has been stymied by the challenge of solving a Hamilton-Jacobi&lt;br/&gt;equation, and the lack of mathematical tools to asymptotically compensate for generic disturbances with a&lt;br/&gt;continuous controller. With the emergence of new implicit learning methods and general Lyapunov analysis&lt;br/&gt;techniques, the community is now well positioned to focus increasing attention on simultaneously achieving&lt;br/&gt;optimality and stability for uncertain nonlinear systems. The learning capacity of the developed controllers&lt;br/&gt;will enable analytical optimal control solutions for a broader class of engineering systems than is currently&lt;br/&gt;possible. Optimizing the performance of a control system along with the required control effort will yield&lt;br/&gt;improved efficiency that can lead to timely economic and environmental cost savings.&lt;br/&gt;Intellectual Merit: Few mathematical tools exist to synthesize controllers for nonlinear systems with model&lt;br/&gt;uncertainty and unmodeled disturbances. Of the few tools that exist, either the developed controller requires&lt;br/&gt;discontinuous feedback or exhibits degraded steady-state performance in the sense of residual errors.&lt;br/&gt;Recent developments have produced a new class of continuous controllers that can implicitly learn such&lt;br/&gt;disturbances through a nonlinear differential equation. This advancement opens new possibilities to refocus&lt;br/&gt;the nonlinear systems community on the dual stability and optimality problem for general systems. Efforts in&lt;br/&gt;this project seek to explore how such implicit learning controllers (and potential permutations) can be used&lt;br/&gt;to yield analytical solutions to different optimal control problems. The ability to integrate the proposed class&lt;br/&gt;of implicit learning controllers (and such controllers integrated with other adaptive and learning techniques)&lt;br/&gt;with optimal control methods is an unexplored concept. New closed-loop error system development, stability&lt;br/&gt;analysis, and optimal analysis methods will be required to determine the interplay of optimality, learning&lt;br/&gt;capacity, and robustness. Outcomes from these aims may provide an inroad to new ways to augment&lt;br/&gt;controllers to incorporate optimality into the design process.&lt;br/&gt;Broad Impact: The theoretical discoveries are expected to have a transformative impact on optimal control&lt;br/&gt;methods for uncertain nonlinear systems. One approach to solve current optimal control problems is to&lt;br/&gt;use numerical methods that only provide local optimal results (at best), typically do not have a proof of&lt;br/&gt;stability or optimality, and are typically open-loop. Also, numerical methods are black box approaches, so&lt;br/&gt;the designer is shielded from any intuition regarding the effect of the system parameters on the optimality.&lt;br/&gt;These issues motivate the need for analytical methods. Yet, the challenge to develop analytical solutions&lt;br/&gt;is that they often do not optimize the real engineering problem because of the narrow class of systems&lt;br/&gt;that can be analytically examined. The expected outcomes of this project are new mathematical tools to&lt;br/&gt;develop analytical stability and optimality solutions for broad classes of nonlinear systems. Further broad&lt;br/&gt;impact will be realized by integrating the research outcomes into educational and outreach efforts. Efforts&lt;br/&gt;will seek to disseminate the research outcomes to engineers in industry, researchers, and students ranging&lt;br/&gt;from grade school through graduate school with an emphasis on under-represented groups. Outcomes of&lt;br/&gt;the research will be disseminated to these groups through outlets including: peer-reviewed publications,&lt;br/&gt;conference workshops, curriculum development, the development of a new certificate program for industrial&lt;br/&gt;control engineers, undergraduate honor?s thesis research, existing University of Florida programs for highschool&lt;br/&gt;and under-represented students, and a robotics summer camp for grade school children.&lt;br/&gt;A-</AbstractNarration>
<MinAmdLetterDate>08/10/2009</MinAmdLetterDate>
<MaxAmdLetterDate>04/29/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0901491</AwardID>
<Investigator>
<FirstName>Warren</FirstName>
<LastName>Dixon</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Warren E Dixon</PI_FULL_NAME>
<EmailAddress>wdixon@ufl.edu</EmailAddress>
<PI_PHON>3528461463</PI_PHON>
<NSF_ID>000250994</NSF_ID>
<StartDate>08/10/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Florida</Name>
<CityName>GAINESVILLE</CityName>
<ZipCode>326112002</ZipCode>
<PhoneNumber>3523923516</PhoneNumber>
<StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>969663814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Florida]]></Name>
<CityName>GAINESVILLE</CityName>
<StateCode>FL</StateCode>
<ZipCode>326112002</ZipCode>
<StreetAddress><![CDATA[1 UNIVERSITY OF FLORIDA]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0510403</Code>
<Name>Engineering &amp; Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>093E</Code>
<Text>System fab/packaging &amp; assembly</Text>
</ProgramReference>
<ProgramReference>
<Code>096E</Code>
<Text>High freq comm/sensing circuits</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~300000</FUND_OBLG>
<FUND_OBLG>2010~6000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Few mathematical tools exist to synthesize controllers to enable autonomy for nonlinear systems with general unstructured uncertainty. Recent breakthroughs in nonlinear systems theory have produced a new class of autonomous controllers that can implicitly learn and accommodate for such disturbances. This advancement opens new possibilities to refocus the autonomous systems community on the dual stability and optimality problem for general systems. Optimizing the performance of a control system while minimizing a user defined cost function can yield improved efficiency that can lead to timely economic and environmental cost savings. The general outcomes from this project are mathematical methods that exploit different learning strategies that produce controllers which ensure stable and predictable response by an autonomous system in the presence of uncertainty while also enabling the system to perform the tasks with minimal cost, in terms of a user defined criteria (e.g., time, energy, accuracy). One set of results that were obtained used a robust control strategy that converges to the best solution over time. This set of results is based on the idea that the controller learns the uncertain disturbances, and then converges to an optimal solution. A second set of controllers was developed that always provides the best control solution, but the objectives result from the analysis, instead of being defined by the user. Both sets of control solutions were developed for an individual system as well as a collection of systems that may have competing objectives.</p> <p>In the final stages of the project, a different learning method was explored that leverages reinforcement learning ideas derived from how mammals are thought to learn (i.e., Pavlov&rsquo;s dog experiments). In this approach, reinforcement learning ideas are used to alter the adaptation through evaluative feedback of the controller similar to how a critic evaluates the performance of an actor (i.e., the autonomous controller in this context). The result from this approach is a controller that adapts over time so that it converges to the optimal control solution.</p> <p>These accomplishments resulted in broad impact. Within the control systems community, the developed controller provides a framework that illustrates how different learning and adaptation methods can be applied to yield optimal control strategies. The impact of such strategies is that automated process may be able to achieve improved or equal performance at a lower energy cost. Specifically, improved motor control can yield significant fuel savings, which also result in reduced environmental impact of some industrial processes. The project served as a venue to provide training to graduate and undergraduate students. Specifically, two doctoral dissertations were completed that focused on this topic, and two additional dissertations are in progress. Undergraduates were also included in the research process, resulting in an honor&rsquo;s thesis for a student that wants to apply the developed control methods for improved efficiency in hybrid electric vehicles.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/29/2013<br>      Modified by: Warren&nbsp;E&nbsp;Dixon</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Few mathematical tools exist to synthesize controllers to enable autonomy for nonlinear systems with general unstructured uncertainty. Recent breakthroughs in nonlinear systems theory have produced a new class of autonomous controllers that can implicitly learn and accommodate for such disturbances. This advancement opens new possibilities to refocus the autonomous systems community on the dual stability and optimality problem for general systems. Optimizing the performance of a control system while minimizing a user defined cost function can yield improved efficiency that can lead to timely economic and environmental cost savings. The general outcomes from this project are mathematical methods that exploit different learning strategies that produce controllers which ensure stable and predictable response by an autonomous system in the presence of uncertainty while also enabling the system to perform the tasks with minimal cost, in terms of a user defined criteria (e.g., time, energy, accuracy). One set of results that were obtained used a robust control strategy that converges to the best solution over time. This set of results is based on the idea that the controller learns the uncertain disturbances, and then converges to an optimal solution. A second set of controllers was developed that always provides the best control solution, but the objectives result from the analysis, instead of being defined by the user. Both sets of control solutions were developed for an individual system as well as a collection of systems that may have competing objectives.  In the final stages of the project, a different learning method was explored that leverages reinforcement learning ideas derived from how mammals are thought to learn (i.e., PavlovÆs dog experiments). In this approach, reinforcement learning ideas are used to alter the adaptation through evaluative feedback of the controller similar to how a critic evaluates the performance of an actor (i.e., the autonomous controller in this context). The result from this approach is a controller that adapts over time so that it converges to the optimal control solution.  These accomplishments resulted in broad impact. Within the control systems community, the developed controller provides a framework that illustrates how different learning and adaptation methods can be applied to yield optimal control strategies. The impact of such strategies is that automated process may be able to achieve improved or equal performance at a lower energy cost. Specifically, improved motor control can yield significant fuel savings, which also result in reduced environmental impact of some industrial processes. The project served as a venue to provide training to graduate and undergraduate students. Specifically, two doctoral dissertations were completed that focused on this topic, and two additional dissertations are in progress. Undergraduates were also included in the research process, resulting in an honorÆs thesis for a student that wants to apply the developed control methods for improved efficiency in hybrid electric vehicles.          Last Modified: 10/29/2013       Submitted by: Warren E Dixon]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
