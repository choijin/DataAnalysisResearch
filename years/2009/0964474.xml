<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DC: Medium: Designing and Programming a Low-Power Cluster Architecture for Data-Intensive Workloads</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>600000.00</AwardTotalIntnAmount>
<AwardAmount>600000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project defines a novel architecture for energy efficient computing, called FAWN, or a "Fast Array of Wimpy Nodes", which uses a large collection of small, slower computers to do tasks formerly handled by a single large, fast computer. By using more, slower, computers in tandem, the architecture runs more energy efficiently.  However, doing so in a practical manner requires overcoming many significant challenges: The individual nodes have much less memory than programmers are used to; the computational task must be split across a much larger number of nodes, and the load must be balanced between them so that no single slow computer will cause the overall operation to be delayed too long.  Modern datacenter environments further operate under very strict requirements for processing delay in order to ensure user satisfaction; these requirements may be harder to meet when running on the FAWN architecture.&lt;br/&gt;&lt;br/&gt;The project is tackling these challenges by developing new techniques for storing and managing large volumes of data on fast solid-state&lt;br/&gt;(Flash) memory.  Through collaboration with experts in CS theory, the project is developing new algorithms for memory-efficient, highly parallel data analysis and data-mining, and implementing and evaluating them in a demanding, high-performance environment.  Through a collaboration with Intel, the project is constructing a 100-node prototype of a FAWN cluster using cutting-edge low-power processors.&lt;br/&gt;&lt;br/&gt;This project has the potential to substantially reduce the capital and operating costs of large Internet services, and to greatly reduce their energy costs and footprint.  It may also substantially advance the state of the art in practical algorithms and systems architectures for data-intensive and energy-efficient computing.</AbstractNarration>
<MinAmdLetterDate>05/26/2010</MinAmdLetterDate>
<MaxAmdLetterDate>05/26/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964474</AwardID>
<Investigator>
<FirstName>Anupam</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anupam Gupta</PI_FULL_NAME>
<EmailAddress>anupamg@cs.cmu.edu</EmailAddress>
<PI_PHON>4122687127</PI_PHON>
<NSF_ID>000486839</NSF_ID>
<StartDate>05/26/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Andersen</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David G Andersen</PI_FULL_NAME>
<EmailAddress>dga@cs.cmu.edu</EmailAddress>
<PI_PHON>4122683064</PI_PHON>
<NSF_ID>000423704</NSF_ID>
<StartDate>05/26/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7793</Code>
<Text>DATA-INTENSIVE COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7793</Code>
<Text>DATA-INTENSIVE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~600000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Energy efficiency has become extremely important for large-scale computing; &nbsp;power draw limits both the affordability and scale of large datacenters and supercomputers. &nbsp;The overall goal of this project was to explore both practical and theoretical techniques to use a more energy-efficient type of cluster architecture. &nbsp;Clusters made of larger numbers of individually slower processors are known to use less energy to accomplish the same computation, but using them can be extremely challenging: &nbsp;programmers must "scale out" their code to run on more machines at the same time; &nbsp;they must contend with limited memory on each node; &nbsp;and they must mitigate the costs of increased communication between processors. &nbsp;During the course of this project, the PIs explored several techniques for facilitating the use of such clusters, generated useful and practical algorithms for data storage and searching that work on all types of clusters, and explored the theoretical aspects of how to schedule work across many machines.</p> <p>During the course of the project, the PIs constructed an 80-node test cluster of such "wimpy" nodes, used to evaluate many of the algorithms and systems designed. &nbsp;The cluster is shown in Figure 1.</p> <p>As with many academic research projects, one of the major outcomes was the education and training of several excellent Ph.D. students, several of whom have now graduated and gone on to work in both research and in industry. &nbsp;On a technical front, the major outcomes of this project center around a much deeper understanding of the challenges and opportunities in using alternative cluster architectures in pursuit of energy efficiency. &nbsp;The FAWN, or "fast array of wimpy nodes" project has become one of the foundational studies in this area, with broad impact both in follow-on academic research, but also with a surprising amount of attention in popular press venues such as Wired, as attention has increasingly turned to understanding how leading-edge Internet services such as Google operate at the astonshing scales they do.</p> <p>As with all research, we did not know at the outset exactly what the results would look like. &nbsp;One of the biggest specific technical contributions of this project is a set of "data structures" and algorithms --- methods for accomplishing tasks on a computer, such as "find all sentences in this book that contain the word 'computer'". &nbsp;To our surprise, the algorithms we developed with "wimpy" hardware in mind also perform extremely well on conventional hardware, and have set new standards for simultaneously being very fast, while also using very little memory to accomplish their goals.&nbsp;In retrospect, focusing on the problem of wimpy nodes with limited memory forced the PIs to adapt to a different set of constraints than programmers normally do, and in so doing, took them down an optimization path that previous work had not explored. &nbsp;The results include best-in-class practical implementations data structures for storing and retrieving data ("cuckoo hash tables"), and searching for data items ("cuckoo filters" and "feed-forward Bloom filters"). &nbsp;The project demonstrated that these algorithms could be applied, for example, to double the speed of an open-source virus scanning program, and to reduce by up to 30% the amount of memory needed in a popular storage system ("memcached") used by many popular websites, including giants such as Facebook.</p> <p>In total, the contributions of this project will help future systems designers and implementers build more energy and memory-efficient systems, both for single machines and for huge datacenters, that could help reduce all of the costs of operating and providing compute-based services.</p><br> <p>            Last Modified: 12/11/2014<br>      Modified by: David&nbsp;G&nbsp;Andersen</p> </div> <div class="porSideCol"> <d...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Energy efficiency has become extremely important for large-scale computing;  power draw limits both the affordability and scale of large datacenters and supercomputers.  The overall goal of this project was to explore both practical and theoretical techniques to use a more energy-efficient type of cluster architecture.  Clusters made of larger numbers of individually slower processors are known to use less energy to accomplish the same computation, but using them can be extremely challenging:  programmers must "scale out" their code to run on more machines at the same time;  they must contend with limited memory on each node;  and they must mitigate the costs of increased communication between processors.  During the course of this project, the PIs explored several techniques for facilitating the use of such clusters, generated useful and practical algorithms for data storage and searching that work on all types of clusters, and explored the theoretical aspects of how to schedule work across many machines.  During the course of the project, the PIs constructed an 80-node test cluster of such "wimpy" nodes, used to evaluate many of the algorithms and systems designed.  The cluster is shown in Figure 1.  As with many academic research projects, one of the major outcomes was the education and training of several excellent Ph.D. students, several of whom have now graduated and gone on to work in both research and in industry.  On a technical front, the major outcomes of this project center around a much deeper understanding of the challenges and opportunities in using alternative cluster architectures in pursuit of energy efficiency.  The FAWN, or "fast array of wimpy nodes" project has become one of the foundational studies in this area, with broad impact both in follow-on academic research, but also with a surprising amount of attention in popular press venues such as Wired, as attention has increasingly turned to understanding how leading-edge Internet services such as Google operate at the astonshing scales they do.  As with all research, we did not know at the outset exactly what the results would look like.  One of the biggest specific technical contributions of this project is a set of "data structures" and algorithms --- methods for accomplishing tasks on a computer, such as "find all sentences in this book that contain the word 'computer'".  To our surprise, the algorithms we developed with "wimpy" hardware in mind also perform extremely well on conventional hardware, and have set new standards for simultaneously being very fast, while also using very little memory to accomplish their goals. In retrospect, focusing on the problem of wimpy nodes with limited memory forced the PIs to adapt to a different set of constraints than programmers normally do, and in so doing, took them down an optimization path that previous work had not explored.  The results include best-in-class practical implementations data structures for storing and retrieving data ("cuckoo hash tables"), and searching for data items ("cuckoo filters" and "feed-forward Bloom filters").  The project demonstrated that these algorithms could be applied, for example, to double the speed of an open-source virus scanning program, and to reduce by up to 30% the amount of memory needed in a popular storage system ("memcached") used by many popular websites, including giants such as Facebook.  In total, the contributions of this project will help future systems designers and implementers build more energy and memory-efficient systems, both for single machines and for huge datacenters, that could help reduce all of the costs of operating and providing compute-based services.       Last Modified: 12/11/2014       Submitted by: David G Andersen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
