<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Medium: Collaborative Research: Frankencamera - an open-source Camera for Research and Teaching in Computational Photography</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2010</AwardEffectiveDate>
<AwardExpirationDate>03/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>344688.00</AwardTotalIntnAmount>
<AwardAmount>344688</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Rosenblum</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Computational photography refers broadly to sensing strategies and algorithmic techniques that enhance or extend the capabilities of digital photography.  Representative techniques include high dynamic range (HDR) imaging, flash-noflash imaging, panoramic stitching, and refocusable photography.  Although interest in computational photography has steadily increased among graphics and vision researchers, progress has been hampered by the lack of a portable, programmable camera platform with enough image quality and computing power to be used outside the laboratory, i.e. for everyday photography. Similarly, courses in computational photography are offered in dozens of universities nationwide.  However, none of these courses provide students with a camera on which they can implement the algorithms currently being published in the literature.&lt;br/&gt;&lt;br/&gt;To address these two problems, we are building an open-source camera platform (called Frankencamera) that is portable, self-powered, connected to the Internet, and accommodates SLR-quality lenses and sensors.  We also describe a software architecture based on Linux, and an API with bindings for C++, that permits control and synchronization of camera functions at the microsecond time scale.  Our API includes pre-capture functions like metering and focusing, an image post-processing pipeline, a user interface toolkit for the viewfinder, and support for current and future I/O devices.  Our plan is to distribute this platform at minimal cost to researchers and university instructors nationwide, using the computational photography courses they already teach as a natural distribution vehicle.  Instructors will apply to us to be part of this outreach program, and a standing committee will evaluate these applications.  Our long-term goal is to spur creation of a community of photographer-programmers who write plug-ins and apps for cameras.</AbstractNarration>
<MinAmdLetterDate>03/31/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/12/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964004</AwardID>
<Investigator>
<FirstName>William</FirstName>
<LastName>Freeman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>William Freeman</PI_FULL_NAME>
<EmailAddress>wtf@ai.mit.edu</EmailAddress>
<PI_PHON>6172538828</PI_PHON>
<NSF_ID>000418387</NSF_ID>
<StartDate>03/31/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fredo</FirstName>
<LastName>Durand</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fredo Durand</PI_FULL_NAME>
<EmailAddress>fredo@graphics.lcs.mit.edu</EmailAddress>
<PI_PHON>6172537223</PI_PHON>
<NSF_ID>000107364</NSF_ID>
<StartDate>03/31/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~111137</FUND_OBLG>
<FUND_OBLG>2011~114857</FUND_OBLG>
<FUND_OBLG>2012~118694</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>We introduced a new programming language and compiler, Halide, that allow regular programmers to get an order of magnitude speedup for image processing pipelines, while keeping their code concise and easy to maintain. Furthermore, Halide allows the same code to be compiled for regular (x86) CPUS, for GPUS and for the ARM processors found on mobile devices. The key intellectual breakthrough is to decouple the notion of an algorithm (operations that lead to pixel values) from the organization of this computation (in what order and at what spatial granularity is the computation performed and stored). With our compiler, programmers can easily explore different organizations of computation and find a strategy that maximizes parallelism and locality (such as cache coherence) while minimizing redundant computation. We released the compiler free and open source.</p> <p>&nbsp;</p> <p>We developed automatic and user-assisted algorithms that enable the enhancement of tones and color in photographs.&nbsp; Fort his, we gathered a database of photographs together with enhancements performed by trained photographers. This allowed us to train a supervised machine learning algorithm to infer enhancement for arbitrary new input images. The algorithm seeks to predict what our trained users would have done for the new image, and takes into account characteristics of the input photo that are both low level (such as tone distribution) and high level (such as the presence of faces). We also designed a new user-driven approach that allows a photographer to address spatially-varying white balance for scenes with mixed lighting. The photographer can specify information about the scene such as which parts share the same color or which parts are grey, and we use a new propagation approach to extend this information to the whole image in order to remove color cast due to lighting.</p> <p>&nbsp;</p> <p>We developed a technique that can process time lapse videos to remove unwanted motion jitter due to temporal undersampling. We set up a Bayesian optimization method that synthesizes a new video that respects the long-range changes in the video but eliminates high-frequency artifacts.</p> <p>&nbsp;</p> <p>We studied the problem of blind deblurring where we week to remove blur in images where the exact blur is unknown. We introduced an algorithm that is much simpler than previous approaches while providing better results. It is based on a probabilistic formulation and a derivation of efficient approximation for the corresponding variational problem.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/10/2013<br>      Modified by: Fredo&nbsp;Durand</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2013/0964004/0964004_10014509_1370903991035_ScreenShot2013-06-10at6.34.37PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/0964004/0964004_10014509_1370903991035_ScreenShot2013-06-10at6.34.37PM--rgov-800width.jpg" title="User-driven white balance for mixed lighting"><img src="/por/images/Reports/POR/2013/0964004/0964004_10014509_1370903991035_ScreenShot2013-06-10at6.34.37PM--rgov-66x44.jpg" alt="User-driven white balance for mixed lighting"></a> <div class="imageCaptionContainer"> <div class="imageCaption">We remove unwanted color cast in images with light source of different color, such as this combination of sunlight and fluorescent lights. The user provides information as scribbles, and...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    We introduced a new programming language and compiler, Halide, that allow regular programmers to get an order of magnitude speedup for image processing pipelines, while keeping their code concise and easy to maintain. Furthermore, Halide allows the same code to be compiled for regular (x86) CPUS, for GPUS and for the ARM processors found on mobile devices. The key intellectual breakthrough is to decouple the notion of an algorithm (operations that lead to pixel values) from the organization of this computation (in what order and at what spatial granularity is the computation performed and stored). With our compiler, programmers can easily explore different organizations of computation and find a strategy that maximizes parallelism and locality (such as cache coherence) while minimizing redundant computation. We released the compiler free and open source.     We developed automatic and user-assisted algorithms that enable the enhancement of tones and color in photographs.  Fort his, we gathered a database of photographs together with enhancements performed by trained photographers. This allowed us to train a supervised machine learning algorithm to infer enhancement for arbitrary new input images. The algorithm seeks to predict what our trained users would have done for the new image, and takes into account characteristics of the input photo that are both low level (such as tone distribution) and high level (such as the presence of faces). We also designed a new user-driven approach that allows a photographer to address spatially-varying white balance for scenes with mixed lighting. The photographer can specify information about the scene such as which parts share the same color or which parts are grey, and we use a new propagation approach to extend this information to the whole image in order to remove color cast due to lighting.     We developed a technique that can process time lapse videos to remove unwanted motion jitter due to temporal undersampling. We set up a Bayesian optimization method that synthesizes a new video that respects the long-range changes in the video but eliminates high-frequency artifacts.     We studied the problem of blind deblurring where we week to remove blur in images where the exact blur is unknown. We introduced an algorithm that is much simpler than previous approaches while providing better results. It is based on a probabilistic formulation and a derivation of efficient approximation for the corresponding variational problem.           Last Modified: 06/10/2013       Submitted by: Fredo Durand]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
