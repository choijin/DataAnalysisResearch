<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Sensory subsystems in jumping spiders</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>410000.00</AwardTotalIntnAmount>
<AwardAmount>452435</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08090500</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>IOS</Abbreviation>
<LongName>Division Of Integrative Organismal Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jodie Jawor</SignBlockName>
<PO_EMAI>jjawor@nsf.gov</PO_EMAI>
<PO_PHON>7032927887</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Animals receive information about the environment from different sense organs, and they must evaluate and integrate these inputs in order to make behavioral decisions. Jumping spiders have four pairs of eyes specialized for different functions, making them useful models for studying this type of integration. Their unique principal eyes function like telephoto lenses and have very high resolution. The retinas are tiny but can be directed, via movable eye tubes, toward different stimuli. The less complex secondary eyes are specialized for detecting movement. In this research, the detailed function of each type of eye will first be studied by masking sets of eyes and measuring spiders' responses to stimuli such as video images of prey. The investigators will also build an innovative eyetracker to monitor and measure the movement of the principal eyes. Next, the investigators will study how the eyes interact, and how spiders integrate visual information from each eye type. The comparison of two spider species, each with the same eye arrangement but very different behavioral patterns, will provide examples of how this basic system can be modified for different purposes. The results will shed light on how specialized units in a perceptual system function together to provide information that can be analyzed by a tiny brain. In addition, the results will have implications for robotic design. The project will provide support for a postdoctoral researcher, a graduate student, and numerous undergraduates, and will enhance an international collaboration. Results will be communicated to lay audiences via a website in coordination with the American Arachnological Society.</AbstractNarration>
<MinAmdLetterDate>06/29/2010</MinAmdLetterDate>
<MaxAmdLetterDate>04/16/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0952822</AwardID>
<Investigator>
<FirstName>Elizabeth</FirstName>
<LastName>Jakob</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elizabeth M Jakob</PI_FULL_NAME>
<EmailAddress>ejakob@umass.edu</EmailAddress>
<PI_PHON>4135770707</PI_PHON>
<NSF_ID>000114902</NSF_ID>
<StartDate>06/29/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010359450</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>7659</Code>
<Text>Animal Behavior</Text>
</ProgramElement>
<ProgramReference>
<Code>1228</Code>
<Text>MINORITY INVOLVEMENT -- BIO</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9183</Code>
<Text>GENERAL FOUNDATIONS OF BIOTECHNOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>BIOT</Code>
<Text>BIOTECHNOLOGY</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~145028</FUND_OBLG>
<FUND_OBLG>2011~174453</FUND_OBLG>
<FUND_OBLG>2012~126991</FUND_OBLG>
<FUND_OBLG>2013~5963</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual merit</p> <p>&nbsp;</p> <p>Jumping spiders are a compelling model system for understanding how different types of sensors work together when there is limited power to process the incoming information. Jumping spiders use their vision in hunting, courtship, navigation, and learning. They have very small brains with which to process information from eight eyes that differ tremendously in morphology and capability. The three pairs of secondary eyes are simple in structure, with a nonmoving lens and a large retina with a wide angle of view. The principal eyes, in contrast, offer high spatial resolution but have a tiny retina with a small angle of view situated at the back of an eye tube. The eye tubes can move inside the spider's cephalothorax to direct the retinas toward different areas of the visual field.</p> <p>&nbsp;</p> <p>We studied the interaction between the principal eyes and the anterior lateral secondary eyes (AL eyes). Both face forward and share a field of view, so the spider collects visual information about the same stimulus with both eye types simultaneously. We selectively masked eyes to examine the role of each eye type. Further, we developed a specialized eyetracker to track the movements of the principal eyes as the spiders examine a visual image.</p> <p>&nbsp;</p> <p>We examined how spiders detect and respond to motion and to spatial detail, presented both separately and together. When presented with living prey, which offer complicated motion and shape cues, both types of eyes were necessary to get normal behavior, and the principal eyes were necessary for prey identification. In contrast, the AL eyes are wholly responsible for driving the spiders' responses to back away or flee from looming stimuli and drive the response to biological motion cues, a series of dots with coordinated movements corresponding to different animals, but devoid of all other recognizable details. In contrast, in a series of experiments using aversive conditioning, we have found no evidence that the AL eyes gather information about shape. Thus, there is a clear division of labor between the principal and the AL eyes.</p> <p>&nbsp;</p> <p>Our eyetracker allowed us to test exactly how the principal and AL eyes interact. The principal eyes easily track moving objects of a range of sizes and speeds when the AL eyes are unmasked. However, if the AL eyes are masked, the principal eyes cease tracking moving stimuli and do not respond to stimuli that appear suddenly in the visual field. Thus, the AL eyes tell the principal eyes where in the visual field a moving stimulus can be found. However, when the principal eyes do happen upon a nonmoving stimulus, such as one that is presented directly in front of them, the principal eyes will examine it (scanning back and forth and twisting on their axes) regardless of whether the AL eyes are masked.</p> <p>&nbsp;</p> <p>These experiments not only give us new information about a unique visual system but also give us insight into how any sort of sensor system might be put together. For example, autonomous robots might use a similar system for using one sensor to detect movement and direct a high-acuity sensor toward it.</p> <p>&nbsp;</p> <p>We initiated collaborations with Dinesh Rao from the University of Veracruz on how spiders perceive fruit-fly signals that elicit antipredator responses; with Nathan Morehouse and Daniel Zurek at the University of Pittsburgh on the evolution of courtship signaling in Habronattus jumping spiders (just today we heard this was funded by NSF); and with Ron Hoy at Cornell on the relationship between retinal movement and brain activity. My graduate student created a new method for imaging spider brains and completed a comparative study of brains across the order, revealing remarkable variation. We also studied how spider behavior is influenced by firefly flashing.</p> <p>&nbsp;</p> <p>Broader impa...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual merit     Jumping spiders are a compelling model system for understanding how different types of sensors work together when there is limited power to process the incoming information. Jumping spiders use their vision in hunting, courtship, navigation, and learning. They have very small brains with which to process information from eight eyes that differ tremendously in morphology and capability. The three pairs of secondary eyes are simple in structure, with a nonmoving lens and a large retina with a wide angle of view. The principal eyes, in contrast, offer high spatial resolution but have a tiny retina with a small angle of view situated at the back of an eye tube. The eye tubes can move inside the spider's cephalothorax to direct the retinas toward different areas of the visual field.     We studied the interaction between the principal eyes and the anterior lateral secondary eyes (AL eyes). Both face forward and share a field of view, so the spider collects visual information about the same stimulus with both eye types simultaneously. We selectively masked eyes to examine the role of each eye type. Further, we developed a specialized eyetracker to track the movements of the principal eyes as the spiders examine a visual image.     We examined how spiders detect and respond to motion and to spatial detail, presented both separately and together. When presented with living prey, which offer complicated motion and shape cues, both types of eyes were necessary to get normal behavior, and the principal eyes were necessary for prey identification. In contrast, the AL eyes are wholly responsible for driving the spiders' responses to back away or flee from looming stimuli and drive the response to biological motion cues, a series of dots with coordinated movements corresponding to different animals, but devoid of all other recognizable details. In contrast, in a series of experiments using aversive conditioning, we have found no evidence that the AL eyes gather information about shape. Thus, there is a clear division of labor between the principal and the AL eyes.     Our eyetracker allowed us to test exactly how the principal and AL eyes interact. The principal eyes easily track moving objects of a range of sizes and speeds when the AL eyes are unmasked. However, if the AL eyes are masked, the principal eyes cease tracking moving stimuli and do not respond to stimuli that appear suddenly in the visual field. Thus, the AL eyes tell the principal eyes where in the visual field a moving stimulus can be found. However, when the principal eyes do happen upon a nonmoving stimulus, such as one that is presented directly in front of them, the principal eyes will examine it (scanning back and forth and twisting on their axes) regardless of whether the AL eyes are masked.     These experiments not only give us new information about a unique visual system but also give us insight into how any sort of sensor system might be put together. For example, autonomous robots might use a similar system for using one sensor to detect movement and direct a high-acuity sensor toward it.     We initiated collaborations with Dinesh Rao from the University of Veracruz on how spiders perceive fruit-fly signals that elicit antipredator responses; with Nathan Morehouse and Daniel Zurek at the University of Pittsburgh on the evolution of courtship signaling in Habronattus jumping spiders (just today we heard this was funded by NSF); and with Ron Hoy at Cornell on the relationship between retinal movement and brain activity. My graduate student created a new method for imaging spider brains and completed a comparative study of brains across the order, revealing remarkable variation. We also studied how spider behavior is influenced by firefly flashing.     Broader impacts     We presented talks to the public (nature clubs, rangers at a local preserve, Science Cafes) and to undergraduate groups. Our work was featured in a documentary on spiders, p...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
