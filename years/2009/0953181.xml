<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Socially Guided Machine Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2010</AwardEffectiveDate>
<AwardExpirationDate>12/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>541113.00</AwardTotalIntnAmount>
<AwardAmount>551063</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>There is currently a surge of interest in service robotics, a desire to have robots leave the labs and factory floors to help solve issues facing society.  But if robots are to play a useful role in domains ranging from eldercare to education, they will need the ability to interact with ordinary people and to acquire new relevant skills after they are deployed; we cannot pre-program these robots with every skill they might conceivably need.  The PI's approach to solving this critical issue is Socially Guided Machine Learning (SG-ML).  In this project she will explore ways in which machine learning agents can exploit principles of human social learning.  An important question for SG-ML is "What is the right level of human involvement?"  Previous efforts in machine learning systems that use human input have tended to hold this level constant (e.g., guidance oriented approaches that are completely dependent on human instruction in order to learn, and exploration oriented approaches with limited input from a human partner).  The PI, taking her inspiration from human learning and from her prior work in robot learning, posits that a robot should be able to explore and learn on its own, while also taking full advantage of a human partner's guidance when available.  The PI's goal in this work is to successfully incorporate self and social learning within a single SG-ML framework, enabling a robot learner to dynamically adjust to varying levels of human involvement in the learning process.  To this end, the PI will seek to make progress toward four main objectives:&lt;br/&gt;&lt;br/&gt;1) Motivations for learning: Typically machines learn because they are programmed to do so, unlike children and animals who learn because they are motivated to master their environment.  A key component of this work is computational motivations that drive a robot to good learning opportunities.&lt;br/&gt;&lt;br/&gt;2) Multiple learning strategies: As mentioned above, an SG-ML framework should have a repertoire of self and social learning mechanisms working together. A central issue of this research is how the robot should best arbitrate and manage the use of multiple strategies.&lt;br/&gt;&lt;br/&gt;3) Transparency devices: Learning is a collaborative activity. The learner's behavior has to be understandable, and has to express a certain level of internal state to help the teacher guide the learning process.  Transparency is a fundamental issue of this work, developing robot behaviors that successfully communicate the progress of the learning process.&lt;br/&gt;&lt;br/&gt;4) Engagement mechanisms: In human social learning, teaching is a rewarding process for both the learner and the teacher.  This is a positive feedback loop from which a machine learner could benefit.  A primary component of this work is to develop mechanisms that make the teaching process rewarding.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  The long-term promise of this research is robots in society able to adapt and learn from everyday people.  The core principles developed in this work will one day enable robots to adapt and learn about the changing needs of people in their homes, or staff in a hospital.  The lessons learned about social learning with robots will be relevant both to computational devices and to human-computer interaction in general.  The PI will exploit the fact that social robot projects like this one generate particular interest in the community to conduct outreach programs in local area high schools, to raise awareness about the work of women in science, and to stimulate the American public's interest in science.</AbstractNarration>
<MinAmdLetterDate>01/11/2010</MinAmdLetterDate>
<MaxAmdLetterDate>02/07/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0953181</AwardID>
<Investigator>
<FirstName>Andrea</FirstName>
<LastName>Thomaz</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrea L Thomaz</PI_FULL_NAME>
<EmailAddress>athomaz@ece.utexas.edu</EmailAddress>
<PI_PHON>6177847154</PI_PHON>
<NSF_ID>000082310</NSF_ID>
<StartDate>01/11/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7218</Code>
<Text>RET SUPP-Res Exp for Tchr Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~63025</FUND_OBLG>
<FUND_OBLG>2011~117247</FUND_OBLG>
<FUND_OBLG>2012~127372</FUND_OBLG>
<FUND_OBLG>2013~124352</FUND_OBLG>
<FUND_OBLG>2014~119067</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="font-size: 11.000000pt; font-family: 'CMR10';">The goal of  this CAREER grant has been to successfully incorporate self and social  learning in a single Socially Guided-Machine Learning framework,  enabling a robot learner to dynamically adjust to varying levels of  human involvement in the learning process.&nbsp; Over 5 years the objectives have been to understand how to best get information from naive human teachers and model that in such a way that a robot learning algorithm can make use of it to efficiently learn a new skill.<br /></span></p> <p><span style="font-size: 11.000000pt; font-family: 'CMR10';">In the final year of this CAREER award the project has culminated in  achieving our original objective of combining self with social  learning.&nbsp; Our previous work on active learning and keyframe-based Learning from Demonstration has lead to our ability to  represent salient aspects of skills, through social interaction with a  human partner, and we can use this to seed an active exploration process  that is an efficient use of the human's time and talent.&nbsp; These goal objectives can be represented as either visual goals or haptic goals, and in both cases we can seed an exploration process toward self-improvement.</span></p> <p><span style="font-size: 11.000000pt; font-family: 'CMR10';">This work was published in the IROS 2015 conference, the IEEE Haptics Symposium 2016, and was nominated for a best paper award at the IEEE/ACM HRI 2016 conference.&nbsp; There is one journal article from this year, in the Journal of Autonomous Robotics.&nbsp; </span></p> <p><span style="font-size: 11.000000pt; font-family: 'CMR10';">Additionally PI Thomaz gave a TEDx talk in Nov 2015 on the impact that socially interactive robots can have in the future and a live demonstration of what it takes to build social intelligence into robots, the talk can be seen at: https://www.youtube.com/watch?v=O1ZhWv84eWE</span></p><br> <p>            Last Modified: 05/11/2016<br>      Modified by: Andrea&nbsp;L&nbsp;Thomaz</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of  this CAREER grant has been to successfully incorporate self and social  learning in a single Socially Guided-Machine Learning framework,  enabling a robot learner to dynamically adjust to varying levels of  human involvement in the learning process.  Over 5 years the objectives have been to understand how to best get information from naive human teachers and model that in such a way that a robot learning algorithm can make use of it to efficiently learn a new skill.   In the final year of this CAREER award the project has culminated in  achieving our original objective of combining self with social  learning.  Our previous work on active learning and keyframe-based Learning from Demonstration has lead to our ability to  represent salient aspects of skills, through social interaction with a  human partner, and we can use this to seed an active exploration process  that is an efficient use of the human's time and talent.  These goal objectives can be represented as either visual goals or haptic goals, and in both cases we can seed an exploration process toward self-improvement.  This work was published in the IROS 2015 conference, the IEEE Haptics Symposium 2016, and was nominated for a best paper award at the IEEE/ACM HRI 2016 conference.  There is one journal article from this year, in the Journal of Autonomous Robotics.    Additionally PI Thomaz gave a TEDx talk in Nov 2015 on the impact that socially interactive robots can have in the future and a live demonstration of what it takes to build social intelligence into robots, the talk can be seen at: https://www.youtube.com/watch?v=O1ZhWv84eWE       Last Modified: 05/11/2016       Submitted by: Andrea L Thomaz]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
