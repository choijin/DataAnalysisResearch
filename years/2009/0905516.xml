<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Medium: The Accessible Aquarium Project: Access to Dynamic Informal Learning Environments via Advanced Bio-Tracking and Adaptive Sonification</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2009</AwardEffectiveDate>
<AwardExpirationDate>07/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>1200002.00</AwardTotalIntnAmount>
<AwardAmount>1216002</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to make dynamic exhibits in informal learning environments (ILEs), such as zoos, science centers, and aquaria, accessible and engaging for visitors with vision impairments by providing real-time audio interpretations. Our efforts will also enhance the exhibit experience for all visitors, regardless of visual ability. We focus on the aquarium domain, since virtually every exhibit is dynamic, and the aquatic nature of the facility provides unique and interesting challenges to bio-tracking. The principles and techniques we develop will be immediately applicable to zoos, museums, and other ILEs with dynamic exhibits, potentially leading to a dramatic increase in the educational and entertainment opportunities for people with vision impairments. The project will employ focus groups and innovative simulations to test prototype exhibits during the development stages. The tracking and auditory displays will then be evaluated through laboratory studies and field testing in exhibits in a large public aquarium.&lt;br/&gt; &lt;br/&gt;The ability to design exhibits and interpretation materials that are accessible to visitors with vision impairments is a growing concern. In addition to persons with specific vision impairments, the underserved population includes their family members, as well as the millions of older adults who have some vision loss that impacts their ability to read signage, see artifacts, and follow the activity in a dynamic exhibit. The results of our project will also enhance the experience for those with full vision, but for whom mobility, height, or other problems make it hard to see traditional signage. Indeed, all visitors will benefit from an audio enhancement that allows them to learn about the exhibit, while keeping their visual attention on the exhibit itself.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/07/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0905516</AwardID>
<Investigator>
<FirstName>Aaron</FirstName>
<LastName>Bobick</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Aaron F Bobick</PI_FULL_NAME>
<EmailAddress>afb@wustl.edu</EmailAddress>
<PI_PHON>3149356350</PI_PHON>
<NSF_ID>000122613</NSF_ID>
<StartDate>08/07/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tucker</FirstName>
<LastName>Balch</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tucker Balch</PI_FULL_NAME>
<EmailAddress>tucker@cc.gatech.edu</EmailAddress>
<PI_PHON>4043852861</PI_PHON>
<NSF_ID>000267564</NSF_ID>
<StartDate>08/07/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Bruce</FirstName>
<LastName>Walker</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bruce Walker</PI_FULL_NAME>
<EmailAddress>bruce.walker@psych.gatech.edu</EmailAddress>
<PI_PHON>4048948265</PI_PHON>
<NSF_ID>000492288</NSF_ID>
<StartDate>08/07/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gil</FirstName>
<LastName>Weinberg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gil Weinberg</PI_FULL_NAME>
<EmailAddress>gil.weinberg@coa.gatech.edu</EmailAddress>
<PI_PHON>4048948939</PI_PHON>
<NSF_ID>000105700</NSF_ID>
<StartDate>08/07/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Carrie</FirstName>
<LastName>Bruce</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Carrie M Bruce</PI_FULL_NAME>
<EmailAddress>carrie.bruce@gatech.edu</EmailAddress>
<PI_PHON>4043856916</PI_PHON>
<NSF_ID>000484592</NSF_ID>
<StartDate>08/07/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~287229</FUND_OBLG>
<FUND_OBLG>2010~613776</FUND_OBLG>
<FUND_OBLG>2012~314997</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of our project was to help make dynamic exhibits such as those at museums, science centers, zoos and aquaria more engaging and accessible for visitors with vision impairments by providing real-time interpretations of the exhibits using innovative tracking, music, narrations, and adaptive sonification. This project included half a dozen senior researchers, more than a dozen graduate students, and many undergraduate students, who all gained research experience, while contributing to general knowledge about how and why people with vision loss visit aquariums, and how to support those visitors better.</p> <p>Providing sophisticated interpretation to help convey what is happening in a dynamic exhibit requires that the system be aware of fish behavior and movement. This entailed tracking fish in real time, and making sense of their behavior. Then, once we understood how to track fish,&nbsp;a broad range of information could be communicated to the visitor using speech messages, non-speech sonification, and data-driven computer music.</p> <p>We designed and built a fully functioning prototype system that could track fish in real time, and convey to the (blind or sighted) visitor an audio interpretation and description of the scene in the aquarium. We then evaluated the effectiveness of this system with visitors with and without vision loss.</p> <p>The results include design guidelines for the development of real time interpretation in a dynamic informal learning environment, such as an aquarium.</p> <p>An added benefit of Universal Design is that providing access to dynamic exhibits for visitors with vision impairments should simultaneously enhance the experience for those with full vision. Our evaluation with sighted users confirmed that the experience was enhanced. We believe that enhancing docent effectiveness, in conjunction with technology, will lead to even greater access.</p> <p class="BodyTextNext">Our research also provided valuable training opportunities for all levels of students, many of whom also got involved in other research in the fields of human-centered design and assistive technology. This should increase awareness about the needs of persons with vision impairments. Then, as graduates in the work force, these researchers will go on to have more direct and tangible impacts, whether in the implementation of accessibility measures at their companies, developing other accessible products, or even hiring persons with disabilities. In addition to those directly involved in the proposed research, the fruits of this project have become available to many more students as it will form part of the content and project activities in several university courses.</p> <p class="BodyTextNext">Through publications and conference activities, a wide range of academic, rehabilitation, corporate, and government interests have become more aware of this important area of research. We have leveraged the vast reach of collaborating organizations including the Center for Assistive Technology and Environmental Access (CATEA), Center for Visually Impaired (CVI), AZA, and others to maximize the distribution of knowledge, tools and methods developed. Research contributions from the visually impaired community are also important benefits from this project. Advisors to the effort include experts in assistive technology and accessible education. Participants with vision impairments will be a major constituent in focus groups, experiments, and prototype evaluation. This has not only advanced the stated research goals, it has also encouraged them to become proactively involved in future research and development efforts that focus on technologies of use and of interest to them.</p> <p class="BodyTextNext">Finally, the development of innovative tracking technology and techniques will have applications in the tracking of all kinds of organic systems, including individuals in a crowd, ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of our project was to help make dynamic exhibits such as those at museums, science centers, zoos and aquaria more engaging and accessible for visitors with vision impairments by providing real-time interpretations of the exhibits using innovative tracking, music, narrations, and adaptive sonification. This project included half a dozen senior researchers, more than a dozen graduate students, and many undergraduate students, who all gained research experience, while contributing to general knowledge about how and why people with vision loss visit aquariums, and how to support those visitors better.  Providing sophisticated interpretation to help convey what is happening in a dynamic exhibit requires that the system be aware of fish behavior and movement. This entailed tracking fish in real time, and making sense of their behavior. Then, once we understood how to track fish, a broad range of information could be communicated to the visitor using speech messages, non-speech sonification, and data-driven computer music.  We designed and built a fully functioning prototype system that could track fish in real time, and convey to the (blind or sighted) visitor an audio interpretation and description of the scene in the aquarium. We then evaluated the effectiveness of this system with visitors with and without vision loss.  The results include design guidelines for the development of real time interpretation in a dynamic informal learning environment, such as an aquarium.  An added benefit of Universal Design is that providing access to dynamic exhibits for visitors with vision impairments should simultaneously enhance the experience for those with full vision. Our evaluation with sighted users confirmed that the experience was enhanced. We believe that enhancing docent effectiveness, in conjunction with technology, will lead to even greater access. Our research also provided valuable training opportunities for all levels of students, many of whom also got involved in other research in the fields of human-centered design and assistive technology. This should increase awareness about the needs of persons with vision impairments. Then, as graduates in the work force, these researchers will go on to have more direct and tangible impacts, whether in the implementation of accessibility measures at their companies, developing other accessible products, or even hiring persons with disabilities. In addition to those directly involved in the proposed research, the fruits of this project have become available to many more students as it will form part of the content and project activities in several university courses. Through publications and conference activities, a wide range of academic, rehabilitation, corporate, and government interests have become more aware of this important area of research. We have leveraged the vast reach of collaborating organizations including the Center for Assistive Technology and Environmental Access (CATEA), Center for Visually Impaired (CVI), AZA, and others to maximize the distribution of knowledge, tools and methods developed. Research contributions from the visually impaired community are also important benefits from this project. Advisors to the effort include experts in assistive technology and accessible education. Participants with vision impairments will be a major constituent in focus groups, experiments, and prototype evaluation. This has not only advanced the stated research goals, it has also encouraged them to become proactively involved in future research and development efforts that focus on technologies of use and of interest to them. Finally, the development of innovative tracking technology and techniques will have applications in the tracking of all kinds of organic systems, including individuals in a crowd, and group movement behavior. The applications of the auditory display research here ranges from more effective training and simulation tools, to complex multimodal monitoring ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
