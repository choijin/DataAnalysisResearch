<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Impact of Calibration Data on Evaluating Plausibility of Alternative Groundwater Models</AwardTitle>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardAmount>105266</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>06030109</Code>
<Directorate>
<LongName>Directorate For Geosciences</LongName>
</Directorate>
<Division>
<LongName>Division Of Earth Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Thomas Torgersen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Impact of Calibration Data on Evaluating Plausibility of Alternative Groundwater Models&lt;br/&gt;&lt;br/&gt;This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).  &lt;br/&gt;&lt;br/&gt;Hydrologic environments are open and complex, rendering them prone to multiple interpretations and mathematical descriptions regardless of the quantity and quality of available data. This recognition has led to a growing tendency among hydrologists to postulate several alternative hydrologic models for a site. Models here are not limited to governing equations and associated boundary/initial conditions, but refer to conceptual-mathematical representations of hydrologic systems (e.g., their processes and interactions). Facing the alternative models, the scientific question to be answered is how to evaluate plausibility of the models so that the models can be properly used to yield optimum predictions. Evaluating model plausibility considers the entire modeling process (including model formulation, calibration, and validation), and calibration/validation data play a key role in the evaluation process. Although calibrating a single model has been studied for decades, impact of calibration data on evaluating plausibility of multiple models has not been well understood. Open questions are as follows: What kinds of calibration data can be used to most effectively discriminate between models? How many data are needed to reliably evaluate model plausibility? How does data correlation (spatial and temporal) affect the evaluation? How does biased evaluation of model plausibility influence predictive performance? These fundamental questions will be addressed using an interdisciplinary approach combining Bayesian statistical and computational methods. Model plausibility will be quantified using model probability, which is estimated, in a Bayesian framework, based on conformity of model simulations to calibration data, complexity of models, and expert judgment. Based on the model probability, one can choose a single model (i.e., Bayesian model selection) or use multiple models (i.e., Bayesian model averaging) to make predictions. Predictive performance of the Bayesian model selection or averaging will be investigated. Hypothesis will be tested using a two-pronged strategy based on both synthetic and real-world modeling. For the synthetic case, alternative groundwater models will be developed based on different representations of site heterogeneity and boundary conditions. The real-world modeling will be conducted at the Naturita site, Colorado, where a risk exists that uranium may reach the Colorado River. Alternative models will be developed based on different ways of formulations of uranium reactive transport models, such as surface complexation models with different numbers of functional groups. For the real-world modeling, model predictive performance will be evaluated using cross-validation methods such as leave-one-out and K-fold. The synthetic and real-world modeling will be conducted together with USGS scientists at Boulder and Menlo Park. Scientific insights gained in this project will be valuable to any environmental modeling through cost-effective data collection for refining existing models and developing new models for environmental restoration and protection. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/31/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2009</MaxAmdLetterDate>
<ARRAAmount>105266</ARRAAmount>
<AwardID>0911074</AwardID>
<Investigator>
<FirstName>Ming</FirstName>
<LastName>Ye</LastName>
<EmailAddress>mye@fsu.edu</EmailAddress>
<StartDate>08/31/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida State University</Name>
<CityName>TALLAHASSEE</CityName>
<ZipCode>323064166</ZipCode>
<PhoneNumber>8506445260</PhoneNumber>
<StreetAddress>874 Traditions Way, 3rd Floor</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>1579</Code>
<Text>HYDROLOGIC SCIENCES</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>6890</Code>
<Text>RECOVERY ACT ACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
