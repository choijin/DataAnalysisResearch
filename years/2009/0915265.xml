<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Exploiting Bilingual Resources to Improve Monolingual Syntactic Tools</AwardTitle>
<AwardEffectiveDate>09/15/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2010</AwardExpirationDate>
<AwardTotalIntnAmount>100000.00</AwardTotalIntnAmount>
<AwardAmount>100000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Natural language processing systems currently degrade when used outside of their training domains and languages.  However, when text is analyzed along with translations into another language, the two languages provide powerful constraints on each other.  For example, a syntactic construction which is ambiguous in one language may be unambiguous in another.  We exploit such constraints by using multilingual models that capture the ways in which linguistic structures correspond between one language and another.  These models are then used to accurately analyze both sides of parallel texts, which can in turn be used to train new, better, models for each language alone.  Multilingual models are challenging because each language alone is complex, and the correspondences between languages can include deep syntactic and semantic restructurings.  Focusing on syntactic parsing, we address these complexities with a hierarchy of increasingly complex models, each constraining the next.  Our approach of multilingual analysis improves three technologies: resource projection, wherein tools for resource-rich languages are transferred to resource-poor ones, domain adaptation, wherein tools are transferred from one domain to another, and multilingual alignment, wherein correspondences between languages are extracted for use in machine translation pipelines.  In addition to publishing the research results from this work, we also make freely available the multilingual modeling tools we develop.</AbstractNarration>
<MinAmdLetterDate>09/09/2009</MinAmdLetterDate>
<MaxAmdLetterDate>09/09/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0915265</AwardID>
<Investigator>
<FirstName>Dan</FirstName>
<LastName>Klein</LastName>
<EmailAddress>klein@cs.berkeley.edu</EmailAddress>
<StartDate>09/09/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
