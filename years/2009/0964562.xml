<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: Collaborative Research:  Recognition of Materials</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>394581.00</AwardTotalIntnAmount>
<AwardAmount>406581</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.&lt;br/&gt;&lt;br/&gt;The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums.</AbstractNarration>
<MinAmdLetterDate>06/28/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/15/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964562</AwardID>
<Investigator>
<FirstName>Srinivasa</FirstName>
<LastName>Narasimhan</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Srinivasa G Narasimhan</PI_FULL_NAME>
<EmailAddress>srinivas@cs.cmu.edu</EmailAddress>
<PI_PHON>4122688746</PI_PHON>
<NSF_ID>000149438</NSF_ID>
<StartDate>06/28/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~92139</FUND_OBLG>
<FUND_OBLG>2011~96337</FUND_OBLG>
<FUND_OBLG>2012~100749</FUND_OBLG>
<FUND_OBLG>2013~117356</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this research project is to provide a comprehensive visual understanding of materials from imagery. Algorithms that try to understand a scene from images/videos must work in the presence of complex transparent, translucent and shiny materials. &nbsp;The propagation of light in materials is hard to model and analyze. Once the materials in the scene are understood, any computer vision system can be used for many applications - navigation in rough terrains, visual inspection of manufacturing processes and products for quality control, medical imaging and understanding of tissue structures, etc. The NSF supported research has resulted in key accomplishments in the following areas.</p> <p>1) Intellectual Merit: Sensing in the presence of complex materials</p> <p>The research has resulted in several algorithms and 3D sensors that demonstrate new capabilities such as: (a) reconstruction of shiny and translucent objects, (b) algorithms not (or less) influenced by complex specular inter-reflections such as those from mirrors or glass objects, (c) good working ranges with low light source power in bright sunlight conditions, (d) 3D reconstruction of micro-vasculature, (e) visibility improvement in the presence of smoky environments, (f) classification of different types of materials including diffuse, translucent, transparent and metallic, (g) analyzing components of light transport in the presence of ambient light, defocus and sensor motion, and (h) modeling and real-time rendering of light transport in translucent scenes.</p> <p>2) Broader impact in many application domains</p> <p>The research resulted in a system built to analyze quality and quantify yields of crops. This was achieved by designing a camera-projection module and installing it on a farm vehicle that captured images of grapes in a large vineyard. The images of the grapes were analyzed to estimate yield accurately. The translucent appearance of the grapes was exploited to estimate the quality of the grapes and the time for harvesting them. This type of system allows farmers to get critical data regarding their crops at unprecendented resolution across their farms and over time, facilitating timely crop interventions and business decisions.</p> <p>The research has impacted the area of cardio-vascular critical care during or after bleeding episodes. The algorithms developed allow the surgeons to monitor in real-time the subtle variations of blood flow in the micro-vessels (not apparent in blood-pressure monitors) and help predict the condition of the patient faster and more accurately. Doctors have used our system to study bleeding effects and response to medical interventions.</p> <p>The research also has potential impact on mobile robots that need to navigate in dangerous situations such as across rubble that contains materials like sharp glass and metallic objects, and navigate through mines filled with smoke hazardous for humans to enter. &nbsp;Initial proof of concept demonstrations in these areas have shown good potential of the research.</p> <p>The project supported and trained multiple doctoral and post-doctoral students and has received multiple awards.</p><br> <p>            Last Modified: 10/17/2015<br>      Modified by: Srinivasa&nbsp;G&nbsp;Narasimhan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this research project is to provide a comprehensive visual understanding of materials from imagery. Algorithms that try to understand a scene from images/videos must work in the presence of complex transparent, translucent and shiny materials.  The propagation of light in materials is hard to model and analyze. Once the materials in the scene are understood, any computer vision system can be used for many applications - navigation in rough terrains, visual inspection of manufacturing processes and products for quality control, medical imaging and understanding of tissue structures, etc. The NSF supported research has resulted in key accomplishments in the following areas.  1) Intellectual Merit: Sensing in the presence of complex materials  The research has resulted in several algorithms and 3D sensors that demonstrate new capabilities such as: (a) reconstruction of shiny and translucent objects, (b) algorithms not (or less) influenced by complex specular inter-reflections such as those from mirrors or glass objects, (c) good working ranges with low light source power in bright sunlight conditions, (d) 3D reconstruction of micro-vasculature, (e) visibility improvement in the presence of smoky environments, (f) classification of different types of materials including diffuse, translucent, transparent and metallic, (g) analyzing components of light transport in the presence of ambient light, defocus and sensor motion, and (h) modeling and real-time rendering of light transport in translucent scenes.  2) Broader impact in many application domains  The research resulted in a system built to analyze quality and quantify yields of crops. This was achieved by designing a camera-projection module and installing it on a farm vehicle that captured images of grapes in a large vineyard. The images of the grapes were analyzed to estimate yield accurately. The translucent appearance of the grapes was exploited to estimate the quality of the grapes and the time for harvesting them. This type of system allows farmers to get critical data regarding their crops at unprecendented resolution across their farms and over time, facilitating timely crop interventions and business decisions.  The research has impacted the area of cardio-vascular critical care during or after bleeding episodes. The algorithms developed allow the surgeons to monitor in real-time the subtle variations of blood flow in the micro-vessels (not apparent in blood-pressure monitors) and help predict the condition of the patient faster and more accurately. Doctors have used our system to study bleeding effects and response to medical interventions.  The research also has potential impact on mobile robots that need to navigate in dangerous situations such as across rubble that contains materials like sharp glass and metallic objects, and navigate through mines filled with smoke hazardous for humans to enter.  Initial proof of concept demonstrations in these areas have shown good potential of the research.  The project supported and trained multiple doctoral and post-doctoral students and has received multiple awards.       Last Modified: 10/17/2015       Submitted by: Srinivasa G Narasimhan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
