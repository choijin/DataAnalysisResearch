<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS Small:  Control of Surgical Robots: Network Layer to Tissue  Contact</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>12/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>549999.00</AwardTotalIntnAmount>
<AwardAmount>638118</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>CPS Small: Control of Surgical Robots: Network Layer to Tissue Contact&lt;br/&gt;&lt;br/&gt;Research Objectives: This proposed CPS project aims to enable intelligent telesurgery in which a surgeon, or a distributed team of surgeons, can work on tiny regions in the body with minimal access. The University of Washington will expand an existing open surgical robot testbed, and create a robust infrastructure for cyber-physical systems with which to extend traditional real-time control and teleoperation concepts by adding three new interfaces to the system: networking, intelligent robotics, and novel non-linear controllers.  &lt;br/&gt;&lt;br/&gt;Intellectual Merit: This project aims to break new ground beyond teleoperation by adding advanced robotic functions. Equally robust and flexible networking, high-level interfaces, and novel controllers will be added to the existing sytsem. The resulting system will be an open architecture and a substrate upon which many cyber-physical system ideas and algorithms will be tested under realistic conditions.  The platforms proven physical robustness will permit rigorous evaluation of results and the open interfaces will encourage collaboration and sharing of results. &lt;br/&gt;&lt;br/&gt;Broader Impacts: We expect the results to enable new research in multiple ways. First, the collaborators such as Johns Hopkins, U.C. Santa Cruz, and several foreign institutions will be able to remotely connect to new high level interfaces provided by this project. Second, for the first time a robust and completely open surgical telerobot will be available for research so that CPS researchers do not need to be limited to isolated toy problems but instead be able to prototype advanced surgical robotics techniques and evaluate them in realistic contexts including animal procedures.</AbstractNarration>
<MinAmdLetterDate>09/15/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/30/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0930930</AwardID>
<Investigator>
<FirstName>Blake</FirstName>
<LastName>Hannaford</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Blake Hannaford</PI_FULL_NAME>
<EmailAddress>blake@ee.washington.edu</EmailAddress>
<PI_PHON>2065432197</PI_PHON>
<NSF_ID>000316142</NSF_ID>
<StartDate>09/15/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Howard</FirstName>
<LastName>Chizeck</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Howard J Chizeck</PI_FULL_NAME>
<EmailAddress>chizeck@uw.edu</EmailAddress>
<PI_PHON>2062653609</PI_PHON>
<NSF_ID>000204918</NSF_ID>
<StartDate>09/15/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981950001</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramElement>
<Code>7680</Code>
<Text>EDA-Eng Diversity Activities</Text>
</ProgramElement>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>152E</Code>
<Text>Cyber-Physical Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7751</Code>
<Text>CDI TYPE II</Text>
</ProgramReference>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7974</Code>
<Text>GRAD RESEARCH SUPPLEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~549999</FUND_OBLG>
<FUND_OBLG>2010~49970</FUND_OBLG>
<FUND_OBLG>2011~38149</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Control of Surgical Robots: Network Layer to Tissue Contact<br />Surgical robots are now widespread in operating rooms around the world. &nbsp;These devices give the surgeon high dexterity and visibility inside very small spaces in the body. &nbsp; However, the current state of the art does not take advantage of any of the massive information &nbsp;sources available today. &nbsp;For example, one surgeon tapes printouts of medical images next to the high resolution visual display of da Vinci. &nbsp; There is huge potential to integrate today's surgical robots with computers into a human-machine Cyber-Physical System. &nbsp; As an example, surgeons frequently operate in close proximity to delicate structures such as nerves and blood vessels which must be protected but are hard to keep visible. &nbsp; A CPS equipped surgical robot system could create a virtual protective force field around this structure based on machine sensing and tracking. &nbsp; It would be harder for the surgeon to accidentally nick that structure and cause complications. Patient safety would be improved.<br /><br />This proposed project took an existing open surgical robot testbed, The RAVEN (funded with DOD and NSF prior support), and created a robust software infrastructure for cyber-physical systems with which to extend traditional real-time control and teleoperation. &nbsp; We developed and evaluated two key pieces of software. &nbsp; First, we created an open network protocol, Interoperable Teleoperation Protocol (ITP), which efficiently allows different control stations and remote robots to connect and be controlled. &nbsp; We demonstrated that a wide variety of robots around the world could intercommunicate through a 24 hour event in which about a dozen labs all interconnected their control stations and remote manipulators. &nbsp; This successful event demonstrated a plug-and-play capability between surgical robot components.<br />Second, we added the widely adopted open source robotic control software package ROS (Robot Operating System) to the Raven control system. &nbsp; This radically expands the ease with which new advanced algorithms can be studied. &nbsp; To evaluate this capability, we have interfaced the Raven, through ROS, to Microsoft's Kinect 3D camera. &nbsp;This $150 device is revolutionizing 3D perception in robotics. &nbsp; We have used it to sense, in real-time, the environment, identify specific structures, and create a protective virtual force field around it, preventing contact by the robot. &nbsp; Although the Kinect is not suitable for actual medical use, other groups are developing similar 3D sensors for medical robotics.<br /><br />Broader Impacts. &nbsp; This work has supported the training of many graduate students in engineering. &nbsp;Undergraduate students participated extensively in the work as well, many of them from underrepresented groups. &nbsp; The software produced has been installed in Raven robots at seven universities (Harvard, Johns Hopkins, Nebraska, UCLA, UC Berkeley, UC Santa Cruz, University of Washington), by leading researchers in the Medical Robotics field. &nbsp;These groups are begining to contribute extensions and bug fixes through a common software repository and web site.</p><br> <p>            Last Modified: 06/13/2013<br>      Modified by: Blake&nbsp;Hannaford</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2013/0930930/0930930_10029063_1371142293356...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Control of Surgical Robots: Network Layer to Tissue Contact Surgical robots are now widespread in operating rooms around the world.  These devices give the surgeon high dexterity and visibility inside very small spaces in the body.   However, the current state of the art does not take advantage of any of the massive information  sources available today.  For example, one surgeon tapes printouts of medical images next to the high resolution visual display of da Vinci.   There is huge potential to integrate today's surgical robots with computers into a human-machine Cyber-Physical System.   As an example, surgeons frequently operate in close proximity to delicate structures such as nerves and blood vessels which must be protected but are hard to keep visible.   A CPS equipped surgical robot system could create a virtual protective force field around this structure based on machine sensing and tracking.   It would be harder for the surgeon to accidentally nick that structure and cause complications. Patient safety would be improved.  This proposed project took an existing open surgical robot testbed, The RAVEN (funded with DOD and NSF prior support), and created a robust software infrastructure for cyber-physical systems with which to extend traditional real-time control and teleoperation.   We developed and evaluated two key pieces of software.   First, we created an open network protocol, Interoperable Teleoperation Protocol (ITP), which efficiently allows different control stations and remote robots to connect and be controlled.   We demonstrated that a wide variety of robots around the world could intercommunicate through a 24 hour event in which about a dozen labs all interconnected their control stations and remote manipulators.   This successful event demonstrated a plug-and-play capability between surgical robot components. Second, we added the widely adopted open source robotic control software package ROS (Robot Operating System) to the Raven control system.   This radically expands the ease with which new advanced algorithms can be studied.   To evaluate this capability, we have interfaced the Raven, through ROS, to Microsoft's Kinect 3D camera.  This $150 device is revolutionizing 3D perception in robotics.   We have used it to sense, in real-time, the environment, identify specific structures, and create a protective virtual force field around it, preventing contact by the robot.   Although the Kinect is not suitable for actual medical use, other groups are developing similar 3D sensors for medical robotics.  Broader Impacts.   This work has supported the training of many graduate students in engineering.  Undergraduate students participated extensively in the work as well, many of them from underrepresented groups.   The software produced has been installed in Raven robots at seven universities (Harvard, Johns Hopkins, Nebraska, UCLA, UC Berkeley, UC Santa Cruz, University of Washington), by leading researchers in the Medical Robotics field.  These groups are begining to contribute extensions and bug fixes through a common software repository and web site.       Last Modified: 06/13/2013       Submitted by: Blake Hannaford]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
