<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Towards a Constructive Theory of Networked Interactions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2010</AwardEffectiveDate>
<AwardExpirationDate>01/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>600000.00</AwardTotalIntnAmount>
<AwardAmount>600000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As Computer Science struggles to understand the Internet and its capabilities, computer scientists are incorporating concepts and methodologies from Economics and Game Theory into their discipline. In the past decade, there has been a tremendous growth in  research, centering around the following questions: what game-theoretic tools are applicable to computer systems? How far is the performance of a system from optimality due to the conflict of interests of its users and administrators? And, how can we design a system whose performance is robust with respect to the potential conflict of interests inside the system? The proposed research aims to tackle some of the fundamental problems at the interface of Computer Science and Game Theory, with a focus on networked interactions.&lt;br/&gt;&lt;br/&gt;The tools that game theorists have traditionally used to model behavior in systems of interacting individuals, such as the Nash and the market equilibria, have been recently shown to be computationally intractable. The intractability of these concepts limits their applicability to policy making since their predictions, although mathematically well-defined, are hard to compute. Moreover, this intractability result raises suspicion as to whether these predictions arise in actuality: if the behavior predicted by some equilibrium concept cannot be found efficiently, how is it that rational individuals find it and adopt it?&lt;br/&gt;&lt;br/&gt;The goal of this project is to develop a theory of networked interactions that does not run into the computational complexity barrier, answering such questions as: In what settings is it possible to use existing tools, such as the Nash equilibrium, to predict selfish behavior computationally efficiently? How does the structure of the interaction graph affect the tractability of equilibria? When computing Nash equilibria is intractable, is it possible to make approximate predictions efficiently? And if this is infeasible, are there other concepts of equilibrium that are both plausible and tractable? Also, in the context of trading: What kind of market equilibrium comes about in a trading network? Is it always identical to the market equilibrium assuming full information? If so, how does it come to arise in the presence of the communication constraints imposed by the network structure? If not, how different is it? And for what kinds of networks is it similar to the full-information one?&lt;br/&gt;&lt;br/&gt;The development of a successful theory of networked interactions will necessitate answering deep questions within the theory of computation. Equilibrium concepts typically correspond to fixed points of continuous maps, which have proven to be a challenging computational object for present techniques. In recent years, algorithmic progress on computing equilibria has brought new techniques to the theoretical computer science community. Likewise, characterizing the complexity of game-theoretic concepts has broadened the computational complexity landscape beyond traditional complexity classes. Several questions, such as the approximation complexity of Nash equilibria, the complexity of simple stochastic games as well as other fixed points at the intersection of the complexity classes known as PLS and PPAD, and the complexity of market equilibria for constant elasticity of substitution (CES) utility functions, are evading existing techniques. Furthering our understanding of rational behavior in large systems will necessarily involve developing novel algorithmic and complexity-theoretic tools to meet the challenges posed by these problems.</AbstractNarration>
<MinAmdLetterDate>03/05/2010</MinAmdLetterDate>
<MaxAmdLetterDate>04/15/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0953960</AwardID>
<Investigator>
<FirstName>Constantinos</FirstName>
<LastName>Daskalakis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Constantinos Daskalakis</PI_FULL_NAME>
<EmailAddress>costis@csail.mit.edu</EmailAddress>
<PI_PHON>6172539643</PI_PHON>
<NSF_ID>000537704</NSF_ID>
<StartDate>03/05/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramElement>
<Code>7932</Code>
<Text>COMPUT GAME THEORY &amp; ECON</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~110886</FUND_OBLG>
<FUND_OBLG>2011~115405</FUND_OBLG>
<FUND_OBLG>2012~119867</FUND_OBLG>
<FUND_OBLG>2013~124508</FUND_OBLG>
<FUND_OBLG>2014~129334</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Computer systems have undergone a tremendous transformation in the past  couple of decades, comprising the following developments: <br /> <br />- With the advent of the Internet, online markets and social networks,  computational environments have gained socio-economic characteristics.  This means that, to properly design and analyze them, we need to blend  tools from Economics and the Social Sciences to the traditional  computational thinking. Addressing this need, this project contributed  research at the interface of Algorithms, Economics and Game Theory. <br /> <br />- At the same time, human activity has been generating and storing  tremendous amounts data, which bear the promise to revolutionalize  scientific discovery. The sheer magnitude of the data, however, poses  great challenges to Statistical analysis. To address this challenge,  this project contributed research at the interface of Learning,  Algorithms and Statistics. <br /> <br />In the next few paragraphs, I describe the contributions of this project  to Algorithms, Economics, Game Theory, and Statistics: <br /> <br />Our research studied the foundations of Economics from a computational  perspective. Economists develop tools with which they predict what  happens in economic systems. When these systems become the size of the  Internet however, the computational features of economic tools become  critical, as it is crucial to know how quickly one can predict what will  happen in a system even if its size is huge. At the same time,  participants in an economic system are computationally bounded. So their  behavior may diverge from the predictions of the theory, if the theory  posits that they have unbounded computational abilities. Our research  has identified computational problems with widely accepted tools in  Economics, such as the concept of the Nash equilibrium, and has proposed  alternatives with better computational properties. <br /> <br />Meanwhile, the design of online platforms, such as ad-exchanges and  cloud computation, requires the coordination of users who may come to  the platform with different objectives. The platform often needs to  extract private information from users who may prefer to lie about it to  improve the service they receive (in our examples, pay less for  advertizing or get more computational resources). However, this may  deteriorate the experience of other users as different users may be  compete for resources. The field of Mechanism Design studies problems of  this sort, developing techniques that allow aligning the objectives of  the users and the designer of the system, often through payments. As  this field is becoming increasingly relevant in the design of online  platforms, it is crucial to study it from a computational viewpoint. Our  research developed new tools that both push the boundary in the field of  Mechanism design and provide computational procedures for designing good  mechanisms. Our work has resolved algorithmically a 30-year old open  problem raised by Roger Myerson's work in 1981. Myerson's work provided  signle-item revenue maximizing auctions, and was awarded a Nobel prize  in Economics in 2007. We provide generalizations of this work to  multiple items. At the same time, we provide computational tools that  can be used to design good mechanisms. We have also applied our tools to  crowdsourcing and peer grading, where a central entity interacts with  "workers" and needs help with performing a task. <br /> <br />On the front of Learning and Statistics, this project developed  practical algorithms for learning and testing properties of  distributions from samples. Modern data sets are large, but they also  pertain to high-dimensional data; for instance, the dataset Imagenet  contains millions of images, but images live in thousands of dimensions.  In particular, the volume of modern datasets does not always compensate  their high-dimensionali...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Computer systems have undergone a tremendous transformation in the past  couple of decades, comprising the following developments:    - With the advent of the Internet, online markets and social networks,  computational environments have gained socio-economic characteristics.  This means that, to properly design and analyze them, we need to blend  tools from Economics and the Social Sciences to the traditional  computational thinking. Addressing this need, this project contributed  research at the interface of Algorithms, Economics and Game Theory.    - At the same time, human activity has been generating and storing  tremendous amounts data, which bear the promise to revolutionalize  scientific discovery. The sheer magnitude of the data, however, poses  great challenges to Statistical analysis. To address this challenge,  this project contributed research at the interface of Learning,  Algorithms and Statistics.    In the next few paragraphs, I describe the contributions of this project  to Algorithms, Economics, Game Theory, and Statistics:    Our research studied the foundations of Economics from a computational  perspective. Economists develop tools with which they predict what  happens in economic systems. When these systems become the size of the  Internet however, the computational features of economic tools become  critical, as it is crucial to know how quickly one can predict what will  happen in a system even if its size is huge. At the same time,  participants in an economic system are computationally bounded. So their  behavior may diverge from the predictions of the theory, if the theory  posits that they have unbounded computational abilities. Our research  has identified computational problems with widely accepted tools in  Economics, such as the concept of the Nash equilibrium, and has proposed  alternatives with better computational properties.    Meanwhile, the design of online platforms, such as ad-exchanges and  cloud computation, requires the coordination of users who may come to  the platform with different objectives. The platform often needs to  extract private information from users who may prefer to lie about it to  improve the service they receive (in our examples, pay less for  advertizing or get more computational resources). However, this may  deteriorate the experience of other users as different users may be  compete for resources. The field of Mechanism Design studies problems of  this sort, developing techniques that allow aligning the objectives of  the users and the designer of the system, often through payments. As  this field is becoming increasingly relevant in the design of online  platforms, it is crucial to study it from a computational viewpoint. Our  research developed new tools that both push the boundary in the field of  Mechanism design and provide computational procedures for designing good  mechanisms. Our work has resolved algorithmically a 30-year old open  problem raised by Roger Myerson's work in 1981. Myerson's work provided  signle-item revenue maximizing auctions, and was awarded a Nobel prize  in Economics in 2007. We provide generalizations of this work to  multiple items. At the same time, we provide computational tools that  can be used to design good mechanisms. We have also applied our tools to  crowdsourcing and peer grading, where a central entity interacts with  "workers" and needs help with performing a task.    On the front of Learning and Statistics, this project developed  practical algorithms for learning and testing properties of  distributions from samples. Modern data sets are large, but they also  pertain to high-dimensional data; for instance, the dataset Imagenet  contains millions of images, but images live in thousands of dimensions.  In particular, the volume of modern datasets does not always compensate  their high-dimensionality and, given this, learning and hypothesis  testing must in fact be done in the low-sample regime. On the other  hand, th...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
