<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Medium: Sound Rendering for Physically Based Simulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>1193830.00</AwardTotalIntnAmount>
<AwardAmount>1213705</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computational physics can help us animate crashing rigid and deformable bodies, or fracturing solids, or splashing water, but the results are silent movies.  Virtually no practical algorithms exist for synthesizing synchronized sounds automatically.  Instead, sound recordings are edited manually for pre-produced animations or triggered automatically in interactive settings.  The former is labor intensive and inflexible, while the latter produces awkward, repetitive results.  This situation is a serious obstacle to building realistic, interactive simulations (whether for entertainment, training, or other applications), which require sound to be compelling,.  In this research the PIs will begin filling this broad void by pursuing fundamental advances in computational methods while solving several particularly challenging sound rendering problems.  The goal is to produce some of the first viable methods in this area, upon which many more can be built.  Successful implementation of this program will fundamentally transform our relationship with our increasingly convincing simulated realities, because for the first time we will be able to hear them as well as see them.  To these ends, the PIs will develop fundamental algorithms that address the problems of simulating the vibrations that cause sound and computing the sound field produced by those vibrations.&lt;br/&gt;&lt;br/&gt;1) Reduced-order vibration models.  Simulating vibration in complex structures is expensive because of the need for both high model complexity and audio-rate temporal resolution.  The PIs will develop dimensional model reduction methods to enable efficient sound rendering from complex, nonlinearly vibrating geometry, such as thin shells.&lt;br/&gt;&lt;br/&gt;2) All-frequency sound radiation.  Realistic sound requires computing the radiated sound field from a vibrating surface over the very broad range of audible frequencies.  But existing methods are either inaccurate for low frequencies or impractical for high frequencies.  The PIs will develop hybrid algorithms based on a broad toolbox and discover which methods are most successful for which problems.&lt;br/&gt;&lt;br/&gt;Complementing the algorithmic work, the PIs will pursue solutions to a series of difficult, unsolved sound rendering problems that are of value in applications:&lt;br/&gt;&lt;br/&gt;a) Harmonic fluid sounds.  Few sounds are as distinctive as pouring a glass of water or the babbling of a brook, yet no algorithms exist to compute these sounds automatically.  The PIs will investigate practical algorithms for harmonic bubble-based sound radiation characteristic of splashing fluids.&lt;br/&gt;&lt;br/&gt;b) Multi-object sound.  Sounds made by collections of objects in contact (think of a bin of LEGOs or a basket of blocks) involve close-proximity effects that are often ignored.  The PIs will develop sound rendering methods to approximate multi-object contact sounds with object-object interactions.&lt;br/&gt;&lt;br/&gt;c) Fracture.  Brittle fracture creates distinctive sounds during destructive processes like breakage of glass.  The PIs will research the efficient generation and excitation of vibrating fragments, and multi-object sound radiation from vibrating debris.&lt;br/&gt;&lt;br/&gt;In all aspects of this research, the PIs will ensure that they are solving problems accurately by comparing every approximation to a reference solution, and they will also ensure they are solving the right problems by testing perceptual equivalence between approximate solutions, reference solutions, and recorded sounds.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  Successful implementation of this program will lead to practical innovations of immediate relevance to computer graphics, and applications of acoustic simulation.  In the future, the methods developed in this project or their successors will completely transform how sound is computed in interactive virtual environments.</AbstractNarration>
<MinAmdLetterDate>06/26/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0905506</AwardID>
<Investigator>
<FirstName>Steve</FirstName>
<LastName>Marschner</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steve Marschner</PI_FULL_NAME>
<EmailAddress>srm@cs.cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000302708</NSF_ID>
<StartDate>06/26/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kavita</FirstName>
<LastName>Bala</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kavita Bala</PI_FULL_NAME>
<EmailAddress>kb@cs.cornell.edu</EmailAddress>
<PI_PHON>6072551383</PI_PHON>
<NSF_ID>000179613</NSF_ID>
<StartDate>06/26/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Doug</FirstName>
<LastName>James</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Doug L James</PI_FULL_NAME>
<EmailAddress>djames@cs.stanford.edu</EmailAddress>
<PI_PHON>6507230104</PI_PHON>
<NSF_ID>000219736</NSF_ID>
<StartDate>06/26/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~507972</FUND_OBLG>
<FUND_OBLG>2010~355640</FUND_OBLG>
<FUND_OBLG>2012~350093</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="white-space: pre;"> </span>This project sought to make fundamental advances in computational methods to support efficient sound synthesis for a wide variety of physics-based simulation models commonly used in visual computing: rigid bodies, deformable solids, brittle fracture, water, fire, etc. &nbsp;Research addressed both difficulties in physical modeling of the sound generation processes, and the high computational cost of resolving fast acoustic timescales which are usually missing from visual animations. &nbsp;The core research topics were vibration modeling of rigid and deformable solids using reduced-order modeling techniques, collision and contact modeling, and acoustic radiation modeling. &nbsp;Results were generated by a team involving graduate students (Changxi Zheng, Jeffrey Chadwick, Steven An, Timothy Langlois) and (REU) undergraduate assistants.<br /><span style="white-space: pre;"> </span>Significant advances in sound synthesis can be reported for many important physics-based simulation models (enumerated in what follows).<br /><span style="white-space: pre;"> </span>egarding sounds generated by fluid processes: (1) The project led to the first computer methods for synthesizing bubble-based liquid sounds from 3D simulations of incompressible fluid flows, including computer models for estimating the radiated sound fields [Zheng and James 2009]. (2) Methods for synthesizing combustion sounds were developed which augment the low-frequency sound generated by a visual fire simulation with fine-scale details from fire sound recordings [Chadwick and James 2011].<br /><span style="white-space: pre;"> </span>Regarding sounds generated by solid objects: (3) We developed the first methods for estimating sound radiation due to brittle fracture processes, with an efficient simulation methodology based on rigid-body sound models and soundbanks of precomputed models [Zheng and James 2010]. (4) We developed advanced contact handling methods for modal contact sounds which can capture important contact chattering and vibrational coupling between objects typically missing in prior work when rigid-body animations are used to drive modal sound models [Zheng and James 2011]. (5) Practical applications of modal sound models for rigid-body animation are limited by huge memory requirements, so we devised eigenmode compression methods that exploit object symmetries and human hearing perception [Langlois et al. 2014]. (6) In addition to vibration, the near-instantaneous rigid-body acceleration during impact can produce loud "click"-like acoustic emissions which help create "crisp" contact sounds; to improve the realism of rigid-body impact sounds we devised efficient methods to approximate these "acceleration noise" sounds [Chadwick et al. 2012b], and related methods to improve performance [Chadwick et al. 2012a]. Thin deformable surfaces are particularly challenging to simulate due to their complex vibrations and sound emissions, and we explored two areas: (7) we developed methods to synthesize noisy sounds generated by nonlinear vibrations of thin shells using advances in reduced-order simulation techniques [Chadwick et al. 2009]; (8) the acoustic emissions of clothing due to characteristic buckling and frictional sliding were approxiamted for cloth animations using a combination of simulated and data-driven synthesis techniques [An et al. 2012]. (9) Finally, observed sounds provide important clues and constraints on the motion of contacting objects, and are important for motion inference, e.g., in robotics.&nbsp;We proposed computer methods to estimate the passive rigid-body motion of an object impacting the ground which are synchronized with input contact sounds and/or audiovisual recordings [Langlois and James 2014].<br /><span style="white-space: pre;"> </span>Geometric algorithms for collision detection: Efficient geometric methods for detecting collisions...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This project sought to make fundamental advances in computational methods to support efficient sound synthesis for a wide variety of physics-based simulation models commonly used in visual computing: rigid bodies, deformable solids, brittle fracture, water, fire, etc.  Research addressed both difficulties in physical modeling of the sound generation processes, and the high computational cost of resolving fast acoustic timescales which are usually missing from visual animations.  The core research topics were vibration modeling of rigid and deformable solids using reduced-order modeling techniques, collision and contact modeling, and acoustic radiation modeling.  Results were generated by a team involving graduate students (Changxi Zheng, Jeffrey Chadwick, Steven An, Timothy Langlois) and (REU) undergraduate assistants.  Significant advances in sound synthesis can be reported for many important physics-based simulation models (enumerated in what follows).  egarding sounds generated by fluid processes: (1) The project led to the first computer methods for synthesizing bubble-based liquid sounds from 3D simulations of incompressible fluid flows, including computer models for estimating the radiated sound fields [Zheng and James 2009]. (2) Methods for synthesizing combustion sounds were developed which augment the low-frequency sound generated by a visual fire simulation with fine-scale details from fire sound recordings [Chadwick and James 2011].  Regarding sounds generated by solid objects: (3) We developed the first methods for estimating sound radiation due to brittle fracture processes, with an efficient simulation methodology based on rigid-body sound models and soundbanks of precomputed models [Zheng and James 2010]. (4) We developed advanced contact handling methods for modal contact sounds which can capture important contact chattering and vibrational coupling between objects typically missing in prior work when rigid-body animations are used to drive modal sound models [Zheng and James 2011]. (5) Practical applications of modal sound models for rigid-body animation are limited by huge memory requirements, so we devised eigenmode compression methods that exploit object symmetries and human hearing perception [Langlois et al. 2014]. (6) In addition to vibration, the near-instantaneous rigid-body acceleration during impact can produce loud "click"-like acoustic emissions which help create "crisp" contact sounds; to improve the realism of rigid-body impact sounds we devised efficient methods to approximate these "acceleration noise" sounds [Chadwick et al. 2012b], and related methods to improve performance [Chadwick et al. 2012a]. Thin deformable surfaces are particularly challenging to simulate due to their complex vibrations and sound emissions, and we explored two areas: (7) we developed methods to synthesize noisy sounds generated by nonlinear vibrations of thin shells using advances in reduced-order simulation techniques [Chadwick et al. 2009]; (8) the acoustic emissions of clothing due to characteristic buckling and frictional sliding were approxiamted for cloth animations using a combination of simulated and data-driven synthesis techniques [An et al. 2012]. (9) Finally, observed sounds provide important clues and constraints on the motion of contacting objects, and are important for motion inference, e.g., in robotics. We proposed computer methods to estimate the passive rigid-body motion of an object impacting the ground which are synchronized with input contact sounds and/or audiovisual recordings [Langlois and James 2014].  Geometric algorithms for collision detection: Efficient geometric methods for detecting collisions between deforming surfaces are fundamental to physical computations. To this end we devised faster methods for self-collision detection (in order to determine when triangle meshes contact themselves) by avoiding vast numbers of pair-wise triangle-triangle overlap tests using (10) subspace deform...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
