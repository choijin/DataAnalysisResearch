<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Geometric Algorithms For Data Analysis In Spaces Of Distributions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2010</AwardEffectiveDate>
<AwardExpirationDate>01/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>489081.00</AwardTotalIntnAmount>
<AwardAmount>505081</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jack S. Snoeyink</SignBlockName>
<PO_EMAI>jsnoeyin@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Collections of distributions arise naturally when analyzing large data sets. Since it is impractical to store all but a small fraction of such data, distributional representations are typically used to summarize the data in compact form. For example, a document in a corpus is typically represented by a normalized vector of frequencies of occurrence of keywords, an image is represented by a histogram over gradient features and speech signals are represented by spectral densities over a frequency domain.&lt;br/&gt;&lt;br/&gt;Representing data sets as collections of distributions enables analysis via powerful concepts from statistics, learning theory and information theory.  Concepts like strength of belief, information content, and pattern likelihood are used to extract meaning and structure from the data and are quantified using information measures like the Kullback-Leibler distance and its parent class, the Bregman divergences.&lt;br/&gt;&lt;br/&gt;These measures capture meaning in data in a manner that traditional metrics cannot, by connecting abstract notions of information loss and transfer with concrete geometric notions like distances. However, they lack properties like symmetry and the triangle inequality that are essential requirements for the application of traditional geometric algorithms for data analysis.&lt;br/&gt;&lt;br/&gt;In this project, the PI will develop a systematic, rigorous and global algorithmic framework for manipulating these distances. This framework will provide the foundation for efficient and accurate data analysis of spaces of distributions, and will lead to deeper insights into analysis problems across a wide range of applications.</AbstractNarration>
<MinAmdLetterDate>01/22/2010</MinAmdLetterDate>
<MaxAmdLetterDate>04/15/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0953066</AwardID>
<Investigator>
<FirstName>Suresh</FirstName>
<LastName>Venkatasubramanian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Suresh Venkatasubramanian</PI_FULL_NAME>
<EmailAddress>suresh@cs.utah.edu</EmailAddress>
<PI_PHON>8015818233</PI_PHON>
<NSF_ID>000074075</NSF_ID>
<StartDate>01/22/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<StreetAddress2><![CDATA[Second Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009095365</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF UTAH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009095365</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Utah]]></Name>
<CityName>SALT LAKE CITY</CityName>
<StateCode>UT</StateCode>
<ZipCode>841128930</ZipCode>
<StreetAddress><![CDATA[75 S 2000 E]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramElement>
<Code>7929</Code>
<Text>COMPUTATIONAL GEOMETRY</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7929</Code>
<Text>COMPUTATIONAL GEOMETRY</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~75330</FUND_OBLG>
<FUND_OBLG>2011~119219</FUND_OBLG>
<FUND_OBLG>2012~96133</FUND_OBLG>
<FUND_OBLG>2013~99738</FUND_OBLG>
<FUND_OBLG>2014~114661</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Geometry is the mathematical foundation of data science. The right geometric representations of data reveals pattern and structure, and allows us to design fast algorithms to find these patterns.&nbsp;</p> <p>In this project, my goal was to understand the geometry of collections of probability distributions. There is a natural way to compare probability distributions using ideas from information theory, but these methods of comparison result in a geometry that is not well understood from the point of view of designing efficient algorithms. My research in this project has shown that for many different kinds of geometries that arise naturally from thinking about probability distributions, it is possible to design efficient algorithms that look very much like the algorithms we use for "simpler" geometries like that of Euclidean space.&nbsp;</p> <p>Proving this requires advanced generalizations of known algorithms and analysis for the corresponding problems in Euclidean space. However, the algorithms themselves change very little -- rather, the analysis of why the algorithms work has to be done more carefully.&nbsp;</p> <p>This is a useful outcome, because it means that we can extend our knowledge of algorithms and data structures to a much larger class of spaces than we knew how to do before, without needed to fundamentally change the algorithms.&nbsp;</p> <p>Continuing along these lines, I've also looked at other related geometries that appear in data science, such as the well known reproducing kernel Hilbert spaces (RKHS). While the geometry of these spaces is well-understood, it has been hard to design efficient algorithms for learning the right kind of RKHS for use in a learning problem. Again, by exploiting geometric insights about the spaces, I've been able to design algorithms that are much faster than those currently in existence, and even connect these ideas to new areas like deep learning.&nbsp;</p><br> <p>            Last Modified: 07/06/2016<br>      Modified by: Suresh&nbsp;Venkatasubramanian</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Geometry is the mathematical foundation of data science. The right geometric representations of data reveals pattern and structure, and allows us to design fast algorithms to find these patterns.   In this project, my goal was to understand the geometry of collections of probability distributions. There is a natural way to compare probability distributions using ideas from information theory, but these methods of comparison result in a geometry that is not well understood from the point of view of designing efficient algorithms. My research in this project has shown that for many different kinds of geometries that arise naturally from thinking about probability distributions, it is possible to design efficient algorithms that look very much like the algorithms we use for "simpler" geometries like that of Euclidean space.   Proving this requires advanced generalizations of known algorithms and analysis for the corresponding problems in Euclidean space. However, the algorithms themselves change very little -- rather, the analysis of why the algorithms work has to be done more carefully.   This is a useful outcome, because it means that we can extend our knowledge of algorithms and data structures to a much larger class of spaces than we knew how to do before, without needed to fundamentally change the algorithms.   Continuing along these lines, I've also looked at other related geometries that appear in data science, such as the well known reproducing kernel Hilbert spaces (RKHS). While the geometry of these spaces is well-understood, it has been hard to design efficient algorithms for learning the right kind of RKHS for use in a learning problem. Again, by exploiting geometric insights about the spaces, I've been able to design algorithms that are much faster than those currently in existence, and even connect these ideas to new areas like deep learning.        Last Modified: 07/06/2016       Submitted by: Suresh Venkatasubramanian]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
