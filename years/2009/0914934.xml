<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III:Small:Privacy Preserving Data Publishing: A Second Look on Group based Anonymization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>499831.00</AwardTotalIntnAmount>
<AwardAmount>499831</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Group based anonymization is the most widely studied approach for privacy preserving data publishing. This includes k-anonymity, l-diversity, and t-closeness, to name a few. The goal of this proposal is to raise a fundamental issue on the privacy exposure of this approach which has been overlooked in the past and come out with a computationally efficient solution. The group based anonymization approach basically hides each individual record behind a group to preserve data privacy. However, patterns may still be derived or mined from the published anonymized data and be used by the adversary to breach individual privacy.  The objective of this research is therefore to develop novel group-based anonymization methods that can defend against such an attack.  The first part of the project is to define the attack problem, i.e., the published anonymized data can in fact be mined for privacy attacks. It identifies and formulates the privacy exposure to such an attack. The second part is to conduct a systematic study on the exposure of existing privacy techniques to the attack. The third part is to derive the condition that is able to resist such an attack and develop efficient data publishing algorithms to prevent it from occurring.</AbstractNarration>
<MinAmdLetterDate>09/05/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/09/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0914934</AwardID>
<Investigator>
<FirstName>Philip</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Philip S Yu</PI_FULL_NAME>
<EmailAddress>psyu@cs.uic.edu</EmailAddress>
<PI_PHON>3129960498</PI_PHON>
<NSF_ID>000079589</NSF_ID>
<StartDate>09/05/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606124305</ZipCode>
<PhoneNumber>3129962862</PhoneNumber>
<StreetAddress>809 S. Marshfield Avenue</StreetAddress>
<StreetAddress2><![CDATA[MB 502, M/C 551]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>098987217</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606124305</ZipCode>
<StreetAddress><![CDATA[809 S. Marshfield Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~157358</FUND_OBLG>
<FUND_OBLG>2010~342473</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><em>Due to the rapid advancement in storing, processing, and networking capabilities of computing devices, there has been a tremendous growth in the collection of digital information about individuals. The collected data offer tremendous opportunities for mining useful information, such as research on patient records to devise personalized medicine, research on trading records to devise more effective policy to avoid the financial meltdown of banking systems, etc.&nbsp; However, there is also a threat to privacy because data in raw form often contain sensitive information about individuals. Privacy-preserving data publishing (PPDP) studies how to transform raw data into a version that is immunized against privacy attacks but that still supports effective data analysis. Our work identifies the weakness of current PPDP approaches and comes out with novel alternatives that will make sharing of valuable data safer and more likely so that the rich information can be used to build a better society. </em></p> <p><em>&nbsp;</em><em>Group based anonymization is the most widely studied approach for privacy-preserving data publishing. Our work is the first to identify its exposure. &nbsp;</em><em>?</em><em> -differential privacy is another approach designed for an interactive querying model. We propose a novel data publishing approach for the non-interactive setting based on </em><em>?</em><em> -differential privacy.</em></p> <p><em>&nbsp;</em><em>The work creates an awareness of the weakness of the current privacy preserving data publishing schemes and provides an alternative approach by extending a privacy preservation scheme designed for an interactive query model to the non-interactive data publishing model. This will facilitate the sharing of data to advance data-driven research.</em></p> <p>&nbsp;</p><br> <p>            Last Modified: 09/30/2013<br>      Modified by: Philip&nbsp;S&nbsp;Yu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Due to the rapid advancement in storing, processing, and networking capabilities of computing devices, there has been a tremendous growth in the collection of digital information about individuals. The collected data offer tremendous opportunities for mining useful information, such as research on patient records to devise personalized medicine, research on trading records to devise more effective policy to avoid the financial meltdown of banking systems, etc.  However, there is also a threat to privacy because data in raw form often contain sensitive information about individuals. Privacy-preserving data publishing (PPDP) studies how to transform raw data into a version that is immunized against privacy attacks but that still supports effective data analysis. Our work identifies the weakness of current PPDP approaches and comes out with novel alternatives that will make sharing of valuable data safer and more likely so that the rich information can be used to build a better society.    Group based anonymization is the most widely studied approach for privacy-preserving data publishing. Our work is the first to identify its exposure.  ? -differential privacy is another approach designed for an interactive querying model. We propose a novel data publishing approach for the non-interactive setting based on ? -differential privacy.   The work creates an awareness of the weakness of the current privacy preserving data publishing schemes and provides an alternative approach by extending a privacy preservation scheme designed for an interactive query model to the non-interactive data publishing model. This will facilitate the sharing of data to advance data-driven research.          Last Modified: 09/30/2013       Submitted by: Philip S Yu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
