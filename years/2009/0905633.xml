<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: Collaborative Research: Explicit Articulatory Models of Spoken Language, with Application to Automatic Speech Recognition</AwardTitle>
<AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardAmount>438830</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).&lt;br/&gt;&lt;br/&gt;One of the main challenges in automatic speech recognition is variability in speaking style, including speaking rate changes and coarticulation.  Models of the articulators (such as the lips and tongue) can succinctly represent much of this variability.  Most previous work on articulatory models has focused on the relationship between acoustics and articulation, but more significant improvements require models of the hidden articulatory state structure.  This work has both a technological goal of improving recognition and a scientific goal of better understanding articulatory phenomena.&lt;br/&gt;&lt;br/&gt;The project considers larger model classes than previously studied.  In particular, the project develops graphical models, including dynamic Bayesian networks and conditional random fields, designed to take advantage of articulatory knowledge.  A new framework for hybrid directed and undirected graphical models is being developed, in recognition of the benefits of both directed and undirected models, and of both generative and discriminative training.  The project activities include major extension of earlier articulatory models with context modeling, asynchrony structures, and specialized training; development of factored conditional random field models of articulatory variables; and discriminative training to alleviate word confusability.&lt;br/&gt;&lt;br/&gt;The scientific goal addresses questions about the ways in which articulatory trajectories vary in different contexts.  Existing databases are used, and initial work in manual articulatory annotation is being extended.  In addition, the project uses articulatory models to perform forced transcription of larger data sets, providing an additional resource for the research community.  Other broad impacts include new models and techniques with applicability to other time-series modeling problems.  Extending the applicability of speech recognition will help it fulfill its promise of enabling more efficient storage of and access to spoken information, and equalizing the technological playing field for those with hearing or motor disabilities.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/26/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/26/2009</MaxAmdLetterDate>
<ARRAAmount>438830</ARRAAmount>
<AwardID>0905633</AwardID>
<Investigator>
<FirstName>Karen</FirstName>
<LastName>Livescu</LastName>
<EmailAddress>klivescu@ttic.edu</EmailAddress>
<StartDate>06/26/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Toyota Technological Institute at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372803</ZipCode>
<PhoneNumber>7738340409</PhoneNumber>
<StreetAddress>6045 S Kenwood Ave</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>6890</Code>
<Text>RECOVERY ACT ACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
