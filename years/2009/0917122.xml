<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Efficient Reinforcement Learning for Generic Large-Scale Tasks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>485000.00</AwardTotalIntnAmount>
<AwardAmount>501000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent advances in autonomous agents research are pushing our society closer to the brink of the widespread adoption of autonomous agents in everyday life. Applications that incorporate agents already exist or are quickly emerging, such as domestic robots, autonomous vehicles, and financial management agents. Reinforcement learning (RL) of sequential decision making is an important paradigm for enabling the widespread deployment of autonomous agents. However, a few notable successes notwithstanding, state-of-the-art reinforcement learning algorithms are not yet fully capable of addressing generic large-scale applications. &lt;br/&gt;&lt;br/&gt;This project is advancing in four directions to scale-up application of RL systems. Specifically, the project is (1) developing algorithms to automatically structure the input, output, and policy representations for learning; (2) introducing parallelizable reinforcement learning algorithms so as to exploit modern parallel architectures; (3) unifying abstraction and hierarchical reasoning with model-based learning for the purpose of enabling intelligent exploration of large-scale environments; and (4) enabling reinforcement learning algorithms to benefit from low-bandwidth interactions with human users. Finally, we intend to unify the four research thrusts above into a single algorithm and conduct empirical evaluation on real-world/large-scale applications, to include biped robot balancing and walking, robot soccer in simulation and with real robots, and a full-size autonomous vehicle capable of planning paths in an urban environment.&lt;br/&gt;&lt;br/&gt;In addition to research advances and implications for improving national infrastructure, the project will contribute to undergraduate and graduate curriculum development.</AbstractNarration>
<MinAmdLetterDate>08/22/2009</MinAmdLetterDate>
<MaxAmdLetterDate>05/25/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0917122</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Stone</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter H Stone</PI_FULL_NAME>
<EmailAddress>pstone@cs.utexas.edu</EmailAddress>
<PI_PHON>5124716424</PI_PHON>
<NSF_ID>000156504</NSF_ID>
<StartDate>08/22/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787595316</ZipCode>
<StreetAddress><![CDATA[3925 W Braker Lane, Ste 3.340]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~485000</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Recent advances in autonomous agents research are pushing our society<br />closer to the brink of the widespread adoption of autonomous agents in<br />everyday life. Applications that incorporate agents already exist or<br />are quickly emerging, such as domestic robots, autonomous vehicles,<br />and financial management agents. Reinforcement learning (RL) of<br />sequential decision making is an important paradigm for enabling the<br />widespread deployment of autonomous agents. However, a few notable<br />successes notwithstanding, state-of-the-art reinforcement learning<br />algorithms are not yet fully capable of addressing generic large-scale<br />applications.<br /><br />This project advanced in four directions to scale-up application of RL<br />systems. Specifically, the project (1) developed algorithms to<br />automatically structure the input, output, and policy representations<br />for learning; (2) introduced parallelizable reinforcement learning<br />algorithms so as to exploit modern parallel architectures; (3) unified<br />abstraction and hierarchical reasoning with model-based learning for<br />the purpose of enabling intelligent exploration of large-scale<br />environments; and (4) enabled reinforcement learning algorithms to<br />benefit from low-bandwidth interactions with human users. Finally, we<br />unified the four research thrusts above into a single algorithm and<br />conduct empirical evaluation on real-world/large-scale applications,<br />to include biped robot balancing and walking, robot soccer in<br />simulation and with real robots, and a full-size autonomous vehicle<br />capable of planning paths in an urban environment.<br /><br />With regards to broader impacts, the PI actively worked with all of<br />the postdocs and graduate students on the project on all of their<br />research activities. Several of the participants have jointly written<br />papers with the PIs, and then have received detailed feedback on their<br />presentations prior to attending the conferences. Those nearing<br />graduation have worked closely with the PI on securing future job<br />opportunities. They have all also participated actively on the<br />project's outreach activities, including Explore UT, an annual open<br />house for the general public, and First Bytes, an annual summer camp<br />for high school girls, designed to increase female participation in<br />Computer Science.<br /><br />The project also supported two undergrad students, one of whom<br />traveled to a conference as the first author of a paper, and the other<br />of whom traveled with our team to RoboCup and completed a<br />project-related undergraduate thesis.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/19/2014<br>      Modified by: Peter&nbsp;H&nbsp;Stone</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Recent advances in autonomous agents research are pushing our society closer to the brink of the widespread adoption of autonomous agents in everyday life. Applications that incorporate agents already exist or are quickly emerging, such as domestic robots, autonomous vehicles, and financial management agents. Reinforcement learning (RL) of sequential decision making is an important paradigm for enabling the widespread deployment of autonomous agents. However, a few notable successes notwithstanding, state-of-the-art reinforcement learning algorithms are not yet fully capable of addressing generic large-scale applications.  This project advanced in four directions to scale-up application of RL systems. Specifically, the project (1) developed algorithms to automatically structure the input, output, and policy representations for learning; (2) introduced parallelizable reinforcement learning algorithms so as to exploit modern parallel architectures; (3) unified abstraction and hierarchical reasoning with model-based learning for the purpose of enabling intelligent exploration of large-scale environments; and (4) enabled reinforcement learning algorithms to benefit from low-bandwidth interactions with human users. Finally, we unified the four research thrusts above into a single algorithm and conduct empirical evaluation on real-world/large-scale applications, to include biped robot balancing and walking, robot soccer in simulation and with real robots, and a full-size autonomous vehicle capable of planning paths in an urban environment.  With regards to broader impacts, the PI actively worked with all of the postdocs and graduate students on the project on all of their research activities. Several of the participants have jointly written papers with the PIs, and then have received detailed feedback on their presentations prior to attending the conferences. Those nearing graduation have worked closely with the PI on securing future job opportunities. They have all also participated actively on the project's outreach activities, including Explore UT, an annual open house for the general public, and First Bytes, an annual summer camp for high school girls, designed to increase female participation in Computer Science.  The project also supported two undergrad students, one of whom traveled to a conference as the first author of a paper, and the other of whom traveled with our team to RoboCup and completed a project-related undergraduate thesis.          Last Modified: 10/19/2014       Submitted by: Peter H Stone]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
