<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Assessing Instructional Quality in Mathematics: A Comparative Study of High and Low Value-Added Teachers' Videotaped Lessons</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
<AwardExpirationDate>09/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>1437572.00</AwardTotalIntnAmount>
<AwardAmount>1262024</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Karen King</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Using value-added data from the Los Angeles Unified School Districts, the researchers determine individual teacher effect estimates and investigate their stability across models.  This study also investigates the instructional practices of a sub-sample of 30 highly effective and 30 less effective sixth-grade mathematics teachers.  Five classroom lessons are videotaped per teacher. The videotapes are coded and analyzed by researchers who are blind to the value-added effectiveness of the teachers. The reliability of measured teaching practice will be investigated by applying hierarchical linear models. Practices of highly effective and less effective teachers will be compared through analyses of variance and regression models.</AbstractNarration>
<MinAmdLetterDate>07/17/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/10/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0949241</AwardID>
<Investigator>
<FirstName>Nicole</FirstName>
<LastName>Kersting</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nicole Kersting</PI_FULL_NAME>
<EmailAddress>nickik@email.arizona.edu</EmailAddress>
<PI_PHON>5206269509</PI_PHON>
<NSF_ID>000071971</NSF_ID>
<StartDate>07/17/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857194824</ZipCode>
<StreetAddress><![CDATA[888 N Euclid Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7645</Code>
<Text>Discovery Research K-12</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0407</Code>
<Name>NSF,Education &amp; Human Resource</Name>
<APP_SYMB_ID>490106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0410</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0412</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~414428</FUND_OBLG>
<FUND_OBLG>2010~344778</FUND_OBLG>
<FUND_OBLG>2011~199814</FUND_OBLG>
<FUND_OBLG>2012~303004</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Understanding what constitutes effective mathematics teaching, and devising reliable and valid ways to measure it, are key prerequisites for improving instruction and increasing student learning.&nbsp; In this study we explored value-added models as one potential approach to measuring teacher performance, and then studied the relationship between teachers&rsquo; value-added scores and observational indicators of instructional quality. Working in a large urban school district, we started by analyzing value-added data over a four-year period for a large sample of fifth-grade teachers. A subsample of teachers was videotaped teaching fractions, and these videos were analyzed using observational rubrics we developed to assess instructional quality. Our goal was to investigate the stability of value-added scores over time, and to see whether teachers with higher value-added scores also had higher instructional quality as measured by our observational rubrics.&nbsp; As a secondary goal, we also explored the number of classroom lessons one would need to videotape to obtain accurate information about teaching quality for individual teachers.</p> <p>Teacher value-added scores reflect the degree to which students of a given teacher learned more or less than expected as measured by standardized test scores over a given school year.&nbsp; If students learned more than would be expected based on their prior learning, their teacher is said to have added value; if they learned less, their teacher did not add value or added less value.&nbsp; Our methodological investigations revealed that fifth grade mathematics teachers&rsquo; value-added scores were reasonably stable over three consecutive cohorts of students. Further, the number of student test scores available was the largest factor affecting teacher rank-ordering and performance group designation over time. We also learned that teacher value-added scores estimated from multiple cohorts, which reflects teacher&rsquo;s average weighted performance, provided the most robust and precise estimate of teacher performance.&nbsp;</p> <p>To examine how instructional quality relates to teacher value-added scores we recruited 57 fifth-grade mathematics teachers in the district and videotaped them five times as they taught a unit on fractions. To control for any systematic relationships between teacher value-added scores and student characteristics &ndash; e.g., the possibility that more effective teachers might be assigned to teach higher achieving students &ndash; we only videotaped classrooms of teachers who taught in average performing schools of average size and who had at least two years of teaching experience in the district. We reasoned that this design would allow us to find out whether teachers teaching somewhat comparable students produced differential learning outcomes as measured by students&rsquo; value-added scores on standardized tests. We observed notable variation in teachers&rsquo; value-added scores within our sub-sample of teachers, with some having value-added scores considerably above, and some considerably below, the district average.</p> <p>The observational rubrics we developed to measure instructional quality were organized around two broad dimensions: the degree to which the underlying mathematics was made visible for students, and the kind and amount of mathematical work students engaged in during the lesson. Both of these had been found in the literature, across different studies, to enhance student learning. We applied the instructional quality codes reliably to the entire set of lesson videos. All lesson videos were coded blind, meaning that none of the raters had any information on teachers&rsquo; value-added scores.&nbsp; We aggregated each teacher&rsquo;s instructional quality information across the five videotaped lessons and obtained a reliable estimate of overall instructional quality for each teacher....]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Understanding what constitutes effective mathematics teaching, and devising reliable and valid ways to measure it, are key prerequisites for improving instruction and increasing student learning.  In this study we explored value-added models as one potential approach to measuring teacher performance, and then studied the relationship between teachersÃ† value-added scores and observational indicators of instructional quality. Working in a large urban school district, we started by analyzing value-added data over a four-year period for a large sample of fifth-grade teachers. A subsample of teachers was videotaped teaching fractions, and these videos were analyzed using observational rubrics we developed to assess instructional quality. Our goal was to investigate the stability of value-added scores over time, and to see whether teachers with higher value-added scores also had higher instructional quality as measured by our observational rubrics.  As a secondary goal, we also explored the number of classroom lessons one would need to videotape to obtain accurate information about teaching quality for individual teachers.  Teacher value-added scores reflect the degree to which students of a given teacher learned more or less than expected as measured by standardized test scores over a given school year.  If students learned more than would be expected based on their prior learning, their teacher is said to have added value; if they learned less, their teacher did not add value or added less value.  Our methodological investigations revealed that fifth grade mathematics teachersÃ† value-added scores were reasonably stable over three consecutive cohorts of students. Further, the number of student test scores available was the largest factor affecting teacher rank-ordering and performance group designation over time. We also learned that teacher value-added scores estimated from multiple cohorts, which reflects teacherÃ†s average weighted performance, provided the most robust and precise estimate of teacher performance.   To examine how instructional quality relates to teacher value-added scores we recruited 57 fifth-grade mathematics teachers in the district and videotaped them five times as they taught a unit on fractions. To control for any systematic relationships between teacher value-added scores and student characteristics &ndash; e.g., the possibility that more effective teachers might be assigned to teach higher achieving students &ndash; we only videotaped classrooms of teachers who taught in average performing schools of average size and who had at least two years of teaching experience in the district. We reasoned that this design would allow us to find out whether teachers teaching somewhat comparable students produced differential learning outcomes as measured by studentsÃ† value-added scores on standardized tests. We observed notable variation in teachersÃ† value-added scores within our sub-sample of teachers, with some having value-added scores considerably above, and some considerably below, the district average.  The observational rubrics we developed to measure instructional quality were organized around two broad dimensions: the degree to which the underlying mathematics was made visible for students, and the kind and amount of mathematical work students engaged in during the lesson. Both of these had been found in the literature, across different studies, to enhance student learning. We applied the instructional quality codes reliably to the entire set of lesson videos. All lesson videos were coded blind, meaning that none of the raters had any information on teachersÃ† value-added scores.  We aggregated each teacherÃ†s instructional quality information across the five videotaped lessons and obtained a reliable estimate of overall instructional quality for each teacher. We also learned that rubrics that assess highly frequent events, such as the quality of teacher student interactions, can be measured reliably based on...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
