<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Heterogeneous Multi-core Architectures from Homogeneous Arrays using Configurable Interconnect</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2009</AwardEffectiveDate>
<AwardExpirationDate>07/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>280000.00</AwardTotalIntnAmount>
<AwardAmount>347629</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hong Jiang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;Recent trends in microprocessor design are shifting toward incorporation of heterogeneous core types onto the same die. However, current design techniques provision only a fixed set of cores and suffer from poor resource utilization when the workload is not a good match for those resources and the system cannot efficiently employ all resources simultaneously.  Hardware should adapt the organization of the heterogeneous cores in response to dynamic behavior.   &lt;br/&gt;This project lays the groundwork for realizing such a dynamic heterogeneous processor - the field programmable core array (FPCA) - that is capable of simultaneously implementing many heterogeneous architectural configurations on a configurable, homogeneous platform. The required flexibility will be provided through a combination of architecture, circuit, and EDA advances. &lt;br/&gt;&lt;br/&gt;The intellectual merit of this project is the technique of separating a processor's front end and functional units into homogeneous pools of building blocks, and development of a programmable interconnect allowing these building blocks to be coupled and decoupled dynamically, enabling efficient intra- and inter-core connectivity and the assembly of a variety of heterogeneous organizations. The broader impact will be the development of a new design paradigm that allows the same chip to be used for a wider range of markets and workloads.  This reduces design and procurement costs, while improving programmer productivity - all of which will provide economic and social benefits. This project also includes education and outreach activities, including improved teaching of emerging programming models and outreach to high school students and underrepresented groups.</AbstractNarration>
<MinAmdLetterDate>08/02/2009</MinAmdLetterDate>
<MaxAmdLetterDate>09/05/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0903471</AwardID>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Skadron</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin Skadron</PI_FULL_NAME>
<EmailAddress>skadron@cs.virginia.edu</EmailAddress>
<PI_PHON>4349822042</PI_PHON>
<NSF_ID>000393383</NSF_ID>
<StartDate>08/02/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>John</FirstName>
<LastName>Lach</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John C Lach</PI_FULL_NAME>
<EmailAddress>jlach@gwu.edu</EmailAddress>
<PI_PHON>2029946081</PI_PHON>
<NSF_ID>000333844</NSF_ID>
<StartDate>08/02/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Benton</FirstName>
<LastName>Calhoun</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benton H Calhoun</PI_FULL_NAME>
<EmailAddress>bcalhoun@virginia.edu</EmailAddress>
<PI_PHON>4342432076</PI_PHON>
<NSF_ID>000240584</NSF_ID>
<StartDate>08/02/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>065391526</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RECTOR &amp; VISITORS OF THE UNIVERSITY OF VIRGINIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>065391526</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Virginia Main Campus]]></Name>
<CityName>CHARLOTTESVILLE</CityName>
<StateCode>VA</StateCode>
<ZipCode>229044195</ZipCode>
<StreetAddress><![CDATA[P.O.  BOX 400195]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramElement>
<Code>7786</Code>
<Text>MCDA</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7786</Code>
<Text>MCDA</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~280000</FUND_OBLG>
<FUND_OBLG>2011~18379</FUND_OBLG>
<FUND_OBLG>2012~49250</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Single-Instruction Multiple-Data (SIMD) and Multiple-Instructions Multiple-Data (MIMD) are two processor design styles that have emerged to take advantage of data- and thread-level parallelism. While each architecture is well suited to the parallelism it targets, they are highly inefficient when executing applications exhibiting alternative behavior. This project therefore developed ParaFlex, a configurable architecture capable of dynamically switching between several SIMD and MIMD organizations. ParaFlex is constructed out of partitioned OpenRISC cores that make use of reconfigurable interconnect to manage the movement of instructions between instruction fetch, decode and execution units. Experiments show that ParaFlex using 90nm commercial technology can achieve average energy and running time equal to 59% and 58% of running on single core respectively with limited area and energy overheads.&nbsp; The energy savings have the potential to improve national energy efficiency, given the growing role that IT systems play in national energy consumption.</p> <p>To develop this architecture, this project conducted a broad exploration ofthe design space for SIMD processors, and developed an automatic, runtime reconfiguration approach.</p> <p>This project also made improvements in on-chip interconnect, on-chip power delivery, and voltage scaling for energy efficiency, developed a new programming framework, and developed a new modeling tool to explore the complex heterogeneous design space.</p> <p>Altogether, this work resulted in 12 peer-reviewed publications so far, one PhD dissertation (and significant portions of two other PhD dissertations), and several pieces of software.&nbsp;&nbsp; Two of the papers were close collaborations with leading IT companies. The work involved numerous graduate and undergraduate students, who are either continuing their studies or have all gone on to careers in IT, finance, or have gone on to graduate school.&nbsp; The graduate students also participated in numerous summer internships with leading semiconductor companies.&nbsp;</p><br> <p>            Last Modified: 10/29/2013<br>      Modified by: Kevin&nbsp;Skadron</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2013/0903471/0903471_10088296_1383084031328_paraflex-wider--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/0903471/0903471_10088296_1383084031328_paraflex-wider--rgov-800width.jpg" title="Paraflex"><img src="/por/images/Reports/POR/2013/0903471/0903471_10088296_1383084031328_paraflex-wider--rgov-66x44.jpg" alt="Paraflex"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Paraflex architecture overview, showing how processing elements can be configured to share fetch in various granularities for SIMD operation, or can be operated independently for MIMD.</div> <div class="imageCredit">University of Virginia</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kevin&nbsp;Skadron</div> <div class="imageTitle">Paraflex</div> </div> </li> <li> <a href="/por/images/Reports/POR/2013/0903471/0903471_10088296_1383083950057_archs--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/0903471/0903471_10088296_1383083950057_archs--rgov-800width.jpg" title="MIMD and SIMD architectures"><img src="/por/images/Reports/POR/2013/0903471/0903471_10088296_1383083950057_archs--rgov-66x44.jpg" alt="MIMD and SIMD architectures"></a> <div class="imageCaptionConta...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Single-Instruction Multiple-Data (SIMD) and Multiple-Instructions Multiple-Data (MIMD) are two processor design styles that have emerged to take advantage of data- and thread-level parallelism. While each architecture is well suited to the parallelism it targets, they are highly inefficient when executing applications exhibiting alternative behavior. This project therefore developed ParaFlex, a configurable architecture capable of dynamically switching between several SIMD and MIMD organizations. ParaFlex is constructed out of partitioned OpenRISC cores that make use of reconfigurable interconnect to manage the movement of instructions between instruction fetch, decode and execution units. Experiments show that ParaFlex using 90nm commercial technology can achieve average energy and running time equal to 59% and 58% of running on single core respectively with limited area and energy overheads.  The energy savings have the potential to improve national energy efficiency, given the growing role that IT systems play in national energy consumption.  To develop this architecture, this project conducted a broad exploration ofthe design space for SIMD processors, and developed an automatic, runtime reconfiguration approach.  This project also made improvements in on-chip interconnect, on-chip power delivery, and voltage scaling for energy efficiency, developed a new programming framework, and developed a new modeling tool to explore the complex heterogeneous design space.  Altogether, this work resulted in 12 peer-reviewed publications so far, one PhD dissertation (and significant portions of two other PhD dissertations), and several pieces of software.   Two of the papers were close collaborations with leading IT companies. The work involved numerous graduate and undergraduate students, who are either continuing their studies or have all gone on to careers in IT, finance, or have gone on to graduate school.  The graduate students also participated in numerous summer internships with leading semiconductor companies.        Last Modified: 10/29/2013       Submitted by: Kevin Skadron]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
