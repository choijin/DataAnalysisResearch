<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small:Data Staging and Parallel Applications in Robust Desktop Grids</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>475000.00</AwardTotalIntnAmount>
<AwardAmount>475000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is an investigation into algorithms and mechanisms that will allow sophisticated staging of input and output data in desktop grids.  Data staging allows the system to store data semi-permanently in the underlying peer-to-peer structure, and to run multi-node jobs (applications) whether they be tightly-coupled parallel applications, arbitrary work-flows, or anything between.&lt;br/&gt;We are building support for these application types by extending our current desktop grid infrastructure in three distinct areas.  We are developing cluster identification techniques that can define arbitrarily-sized virtual clusters through both passive and active network measurement.  We are incorporating virtual cluster descriptions into the underlying peer-to-peer infrastructure to allow the scheduling algorithms to map multi-node jobs to the clusters.  Finally, we are incorporating data placement into the underlying infrastructure; data is placed according to use and process binding.&lt;br/&gt;This work will impact several research areas, including that of distributed and decentralized scheduling, application description, network characterization, and storage networks.  In all of these areas our work will explore the tension between local autonomy and global, aggregate objectives.&lt;br/&gt;The algorithms and techniques will have broad applicability across a wide range of emerging distributed and collaborative applications.  However, the work described here will also explicitly and immediately impact the quality of research conducted by our collaborators in astronomy and elsewhere.  The ability to run parallel applications, and those with more complicated inter-relationships, will enable whole new classes of scientific applications to be run on top of ad-hoc grid-like systems.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/17/2009</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0916742</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Keleher</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter J Keleher</PI_FULL_NAME>
<EmailAddress>keleher@cs.umd.edu</EmailAddress>
<PI_PHON>3014050345</PI_PHON>
<NSF_ID>000278516</NSF_ID>
<StartDate>09/17/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alan</FirstName>
<LastName>Sussman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alan Sussman</PI_FULL_NAME>
<EmailAddress>als@cs.umd.edu</EmailAddress>
<PI_PHON>3014053360</PI_PHON>
<NSF_ID>000185968</NSF_ID>
<StartDate>09/17/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Derek</FirstName>
<LastName>Richardson</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Derek C Richardson</PI_FULL_NAME>
<EmailAddress>dcr@astro.umd.edu</EmailAddress>
<PI_PHON>3014058786</PI_PHON>
<NSF_ID>000489796</NSF_ID>
<StartDate>09/17/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~161500</FUND_OBLG>
<FUND_OBLG>2010~156750</FUND_OBLG>
<FUND_OBLG>2011~156750</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project explored decentralized approaches to scheduling of sequential and parallel jobs across multiple clusters, both those defined explicitly and ad-hoc clusters identified automatically. We have demonstrated a number of contributions. First, we have described a decentralized approach to matching parallel jobs to appropriate resources. &nbsp;By publishing parallel resources as the number of near nodes within a latency radius of each system node, we can route to parallel resources without the need for explicit clustering.<br />Second, we have shown that we can use soft-state techniques to coordinate running parallel jobs in a distributed, decentralized system.<br />Third, we demonstrate the utility of these algorithms with experiments that use actual job traces rather than synthetic inputs.<br />Fourth, we have demonstrated a completely decentralized scheduler that performs comparably to a globally load balanced scheduler. &nbsp;The experiments that show this use actual job traces rather than synthetic inputs.<br />Fifth, we have also established criteria for successful and efficient application of this scheduler: clusters must be as large as possible, and we must limit certain pathological overlap in clusters.<br />Finally, our collaborator in Astronomy has used the system to perform numerical experiments testing the behavior of cohesionless gravitational aggregates experiencing a gradual increase of angular momentum. The test bodies used in the numerical simulations are gravitational aggregates of different construction, distinguished by the size distribution of the particles constituting them, parameterized in terms of the angle of friction. Shape change and mass loss are found to depend strongly on the friction angle, with results ranging from oblate spheroids forming binary systems to near-fluid behavior characterized by mass shedding bursts and no binary formation.</p><br> <p>            Last Modified: 11/04/2013<br>      Modified by: Peter&nbsp;J&nbsp;Keleher</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project explored decentralized approaches to scheduling of sequential and parallel jobs across multiple clusters, both those defined explicitly and ad-hoc clusters identified automatically. We have demonstrated a number of contributions. First, we have described a decentralized approach to matching parallel jobs to appropriate resources.  By publishing parallel resources as the number of near nodes within a latency radius of each system node, we can route to parallel resources without the need for explicit clustering. Second, we have shown that we can use soft-state techniques to coordinate running parallel jobs in a distributed, decentralized system. Third, we demonstrate the utility of these algorithms with experiments that use actual job traces rather than synthetic inputs. Fourth, we have demonstrated a completely decentralized scheduler that performs comparably to a globally load balanced scheduler.  The experiments that show this use actual job traces rather than synthetic inputs. Fifth, we have also established criteria for successful and efficient application of this scheduler: clusters must be as large as possible, and we must limit certain pathological overlap in clusters. Finally, our collaborator in Astronomy has used the system to perform numerical experiments testing the behavior of cohesionless gravitational aggregates experiencing a gradual increase of angular momentum. The test bodies used in the numerical simulations are gravitational aggregates of different construction, distinguished by the size distribution of the particles constituting them, parameterized in terms of the angle of friction. Shape change and mass loss are found to depend strongly on the friction angle, with results ranging from oblate spheroids forming binary systems to near-fluid behavior characterized by mass shedding bursts and no binary formation.       Last Modified: 11/04/2013       Submitted by: Peter J Keleher]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
