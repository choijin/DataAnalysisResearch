<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS:Medium:Hybrid Systems for Modeling and Teaching the Language of Surgery</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>12/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>1499828.00</AwardTotalIntnAmount>
<AwardAmount>1515578</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ralph Wachter</SignBlockName>
<PO_EMAI>rwachter@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The objective of this research is to develop new principles for&lt;br/&gt;creating and comparing models of skilled human activities, and to&lt;br/&gt;apply those models to systems for teaching, training and assistance of&lt;br/&gt;humans performing these activities. The models investigated will&lt;br/&gt;include both hybrid systems and language-based models. The research&lt;br/&gt;will focus on modeling surgical manipulations during robotic minimally&lt;br/&gt;invasive surgery. Models for expert performance of surgical tasks will&lt;br/&gt;be derived from recorded motion and video data. Student data will be&lt;br/&gt;compared with these expert models, and both physical guidance and&lt;br/&gt;information display methods will be developed to provide feedback to&lt;br/&gt;the student based on the expert model.&lt;br/&gt;&lt;br/&gt;The intellectual merit of this work lies in the development of a new&lt;br/&gt;set of mathematical tools for modeling human skilled activity. These&lt;br/&gt;tools will provide new insights into the relationship between skill,&lt;br/&gt;style, and content in human motion. Additional intellectual merit lies&lt;br/&gt;in the connection of hybrid systems modeling to language models, the&lt;br/&gt;creation of techniques for automated training, and in the assessment&lt;br/&gt;of new training methods.&lt;br/&gt;&lt;br/&gt;The broader impact of this research will be the creation of automated&lt;br/&gt;methods for modeling and teaching skilled human motion. These methods&lt;br/&gt;will have enormous implications for the training and re-training of&lt;br/&gt;the US workforce.  This project will also impact many diversity and&lt;br/&gt;outreach activities, including REU programs and summer camps for K-12&lt;br/&gt;outreach. The senior personnel of this project also participate in the&lt;br/&gt;Robotic Systems Challenge and the Women in Science and Engineering&lt;br/&gt;program.</AbstractNarration>
<MinAmdLetterDate>09/23/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0931805</AwardID>
<Investigator>
<FirstName>Gregory</FirstName>
<LastName>Hager</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gregory D Hager</PI_FULL_NAME>
<EmailAddress>hager@cs.jhu.edu</EmailAddress>
<PI_PHON>4105165521</PI_PHON>
<NSF_ID>000385453</NSF_ID>
<StartDate>09/23/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sanjeev</FirstName>
<LastName>Khudanpur</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sanjeev P Khudanpur</PI_FULL_NAME>
<EmailAddress>khudanpur@jhu.edu</EmailAddress>
<PI_PHON>4105167024</PI_PHON>
<NSF_ID>000236251</NSF_ID>
<StartDate>09/23/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rene</FirstName>
<LastName>Vidal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rene Vidal</PI_FULL_NAME>
<EmailAddress>rvidal@cis.jhu.edu</EmailAddress>
<PI_PHON>4105167306</PI_PHON>
<NSF_ID>000486258</NSF_ID>
<StartDate>09/23/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rajesh</FirstName>
<LastName>Kumar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rajesh Kumar</PI_FULL_NAME>
<EmailAddress>rajesh@jhu.edu</EmailAddress>
<PI_PHON>4105166708</PI_PHON>
<NSF_ID>000083560</NSF_ID>
<StartDate>09/23/2009</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182686</ZipCode>
<StreetAddress><![CDATA[1101 E 33rd St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~499841</FUND_OBLG>
<FUND_OBLG>2010~515750</FUND_OBLG>
<FUND_OBLG>2011~499987</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project investigated methods for modeling the performance of skilled, complex manipulation tasks using hand movement and video data. For example, modeling surgical tasks by decomposing them into sequences of surgical gestures (which we call surgemes) while assessing the skill level of a surgeon at performing those tasks. The key idea is to first build language-like models that describe the hand movements necessary to perform a skilled task, followed by analysis of the hand movements to determine if there are structures that are indicative of skilled movement. The same ideas can be applied to many different types of movement ranging from dexterous manipulation to whole body motion.</p> <p>We have focused specifically on data that we have acquired from a <em>da Vinci</em> Surgical System (Intuitive Surgical, Inc., Sunnyvale, CA) while surgeons with differing levels of training and experience performed a series of standardized training tasks. With this data, we have developed and evaluated a number of models and implemented a number of applications.</p> <p>With regards to modeling, we began with traditional hidden Markov models (HMMs), which are widely used in speech and language processing by machines. We adapted and improved these models for our domain of interest in several ways. Our most successful methods were based on adapting the notion of dictionary learning for these models. A dictionary is a small set of typical mini-movements that are highly descriptive of all of the observed hand movements. We represent the actual data in terms of the dictionary. We then learn the HMMs from these dictionary-based representations. We also extended these modeling methods to perform joint learning of the dictionary and the HMM simultaneously.&nbsp; We showed that these methods, which we call Sparse HMMs (S-HMMs), outperformed all prior methods in terms of recognition accuracy across a variety of surgical tasks including suturing, needle passing, and knot tying.</p> <p>We then applied the models that we developed to skill classification tasks. We did so by asking an expert to provide a &ldquo;ground truth&rdquo; label for the execution of a given task on a numeric scale, with 1 being poor, and 5 being excellent. We then disaggregated the data into three groups which we called novice, intermediate, and expert, and we learned a model, as described above, for each group. We then classified held-out data by determining which of the three models best described the held out data. We found that when the system had a chance to observe the surgeon in question during training, it was able to classify his or her skill with 94-97% accuracy, but when it did not, the accuracy dropped to 40-50%. This suggests that the classifier associates high skill with the surgical styles of the particular surgeons it has seen before, and mislabels a skilled movement performed in a different style as unskilled.&nbsp; This problem is most easily cured by acquiring larger data sets that allow the classifier to see a wider range of individual variability.</p> <p>We have also used time-series data models to develop new modes of training and assistance. for performing surgical tasks.&nbsp; In one study, we used the data to learn a HMM for the task, as described above. We then annotated the states of the HMM to indicate what portions of the task an operator would perform manually, versus portions of the task that the robot would perform automatically. For the automatic portions, the training data was averaged to produce a nominal trajectory for the robot. During execution, the robot observed the actions of the operator and when it recognized that it was transitioning to an automated action, took control and carried out the action. As a result, the operator was able to perform the task more efficiently, but with the same fidelity, through collaboration with the robot.</p> <p>In the course of this project, w...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project investigated methods for modeling the performance of skilled, complex manipulation tasks using hand movement and video data. For example, modeling surgical tasks by decomposing them into sequences of surgical gestures (which we call surgemes) while assessing the skill level of a surgeon at performing those tasks. The key idea is to first build language-like models that describe the hand movements necessary to perform a skilled task, followed by analysis of the hand movements to determine if there are structures that are indicative of skilled movement. The same ideas can be applied to many different types of movement ranging from dexterous manipulation to whole body motion.  We have focused specifically on data that we have acquired from a da Vinci Surgical System (Intuitive Surgical, Inc., Sunnyvale, CA) while surgeons with differing levels of training and experience performed a series of standardized training tasks. With this data, we have developed and evaluated a number of models and implemented a number of applications.  With regards to modeling, we began with traditional hidden Markov models (HMMs), which are widely used in speech and language processing by machines. We adapted and improved these models for our domain of interest in several ways. Our most successful methods were based on adapting the notion of dictionary learning for these models. A dictionary is a small set of typical mini-movements that are highly descriptive of all of the observed hand movements. We represent the actual data in terms of the dictionary. We then learn the HMMs from these dictionary-based representations. We also extended these modeling methods to perform joint learning of the dictionary and the HMM simultaneously.  We showed that these methods, which we call Sparse HMMs (S-HMMs), outperformed all prior methods in terms of recognition accuracy across a variety of surgical tasks including suturing, needle passing, and knot tying.  We then applied the models that we developed to skill classification tasks. We did so by asking an expert to provide a "ground truth" label for the execution of a given task on a numeric scale, with 1 being poor, and 5 being excellent. We then disaggregated the data into three groups which we called novice, intermediate, and expert, and we learned a model, as described above, for each group. We then classified held-out data by determining which of the three models best described the held out data. We found that when the system had a chance to observe the surgeon in question during training, it was able to classify his or her skill with 94-97% accuracy, but when it did not, the accuracy dropped to 40-50%. This suggests that the classifier associates high skill with the surgical styles of the particular surgeons it has seen before, and mislabels a skilled movement performed in a different style as unskilled.  This problem is most easily cured by acquiring larger data sets that allow the classifier to see a wider range of individual variability.  We have also used time-series data models to develop new modes of training and assistance. for performing surgical tasks.  In one study, we used the data to learn a HMM for the task, as described above. We then annotated the states of the HMM to indicate what portions of the task an operator would perform manually, versus portions of the task that the robot would perform automatically. For the automatic portions, the training data was averaged to produce a nominal trajectory for the robot. During execution, the robot observed the actions of the operator and when it recognized that it was transitioning to an automated action, took control and carried out the action. As a result, the operator was able to perform the task more efficiently, but with the same fidelity, through collaboration with the robot.  In the course of this project, we have trained four graduate students and two postdoctoral scholars. We have also engaged several undergraduates in our research...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
