<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Top-down Signals for Eye Movements and Perception</AwardTitle>
    <AwardEffectiveDate>08/15/2009</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>299943</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Betty H. Tuller</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).&lt;br/&gt;&lt;br/&gt;Real-world decisions utilize both sensory evidence and "top-down" signals. When buying a house, for example, sensory evidence might consist of the immediate characteristics of the particular house (e.g., location, size, state of repair) and top-down signals might include both objective (e.g., local school test scores) and subjective (e.g., desirability) factors. How these two types of information are combined in the brain is not well-understood. Voluntary eye movements provide a model system to study this process because the visual stimuli can be carefully controlled and relevant information can be specified exactly. In the brain, eye movement decisions are guided using signals from an interconnected network of areas, some thought to provide a purely sensory encoding of the visual stimulus to support unbiased perception, and others thought to provide the top-down signals known to bias behavioral choices. The central hypothesis of this project is that top-down signals influence visual perception. (For example, expected stimuli can appear brighter than unexpected stimuli.)&lt;br/&gt;&lt;br/&gt;To test this hypothesis, Principal Investigator Dorion Liston at San Jose State University will utilize a series of two-stage tasks. The first stage requires the subject to make an eye-movement choice (e.g., look at the brighter of the two stimuli). Biases in these choices will be induced by varying top-down signals (e.g., the bright stimulus is most likely to appear in one location). The second stage requires comparing a perceptual property (like brightness) of the initially-selected stimulus with a neutral test stimulus. This allows the observer's perceptions of favored and unfavored stimuli to be quantified and mathematically modeled. Using this approach, factors that contribute to the economic concept of "expected value" (i.e., reward magnitude multiplied by the probability of obtaining the reward) have been shown to shape perception. In the house example, this might correspond to a factor like the desirability of the location influencing the perceived state of repair of the house. A mechanistic description of how top-down signals interact with sensory signals to generate perceptions and choices will help us to better understand how these processes occur within the brain.</AbstractNarration>
    <MinAmdLetterDate>08/16/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>08/16/2009</MaxAmdLetterDate>
    <ARRAAmount>299943</ARRAAmount>
    <AwardID>0924841</AwardID>
    <Investigator>
      <FirstName>Dorion</FirstName>
      <LastName>Liston</LastName>
      <EmailAddress>dorion.b.liston@nasa.gov</EmailAddress>
      <StartDate>08/16/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>San Jose State University Foundation</Name>
      <CityName>San Jose</CityName>
      <ZipCode>951125569</ZipCode>
      <PhoneNumber>4089241400</PhoneNumber>
      <StreetAddress>210 North Fourth Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>6890</Code>
      <Text>RECOVERY ACT ACTION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
