<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small:  Computational Models of Context-awareness and Selective Attention for Persistent Visual Target Tracking</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>375986.00</AwardTotalIntnAmount>
<AwardAmount>391986</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Although persistent and long-duration tracking of general targets is a basic function in the human vision system, this task is quite challenging for computer vision algorithms, because the visual appearances of real world targets vary greatly and the environments are heavily cluttered and distractive. This large gap has been a bottleneck in many video analysis applications. This project aims to bridge this gap and to overcome the challenges that confront the design of long-duration tracking systems, by developing new computational models to integrate and represent some important aspects in the human visual perception of dynamics, including selective attention and context-awareness that have been largely ignored in existing computer vision algorithms.   &lt;br/&gt;&lt;br/&gt;This project performs in-depth investigations of a new computational paradigm, called the synergetic selective attention model that integrates four processes: the early selection process that extracts informative attentional regions (ARs), the synergetic tracking process that estimates the target motion based on these ARs, the robust integration process that resolves the inconsistency among the motion estimates of these ARs for robust information fusion, and the context-aware learning process that performs late selection and learning on-the-fly to discover contextual associations and to learn discriminative-ARs for adaptation.  &lt;br/&gt;&lt;br/&gt;This research enriches the study of visual motion analysis by accommodating aspects from the human visual perception and leads to significant improvements for video analysis. It benefits many important areas including intelligent video surveillance, human-computer interaction and video information management.  The project is linked to educational activities to promote learning and innovation through curriculum development, research opportunities, knowledge dissemination through conferences and the internet as well as other outreach activities, and the involvements of underrepresented groups. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/07/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/26/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0916607</AwardID>
<Investigator>
<FirstName>Ying</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ying Wu</PI_FULL_NAME>
<EmailAddress>yingwu@eecs.northwestern.edu</EmailAddress>
<PI_PHON>8474912901</PI_PHON>
<NSF_ID>000299558</NSF_ID>
<StartDate>08/07/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606114579</ZipCode>
<StreetAddress><![CDATA[750 N. Lake Shore Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~375986</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p { margin-bottom: 0.1in; direction: ltr; color: rgb(0, 0, 0); line-height: 120%; widows: 2; orphans: 2; }p.western { font-family: "Times New Roman",serif; font-size: 12pt; }p.cjk { font-family: "??","SimSun"; font-size: 12pt; }p.ctl { font-family: "Times New Roman",serif; font-size: 12pt; }a:visited { color: rgb(128, 0, 128); }a.western:visited {  }a.cjk:visited {  }a.ctl:visited {  }a:link { color: rgb(0, 0, 255); } --> <p class="western" style="margin-bottom: 0in; line-height: 100%;"><span style="font-family: Garamond,serif;"><span style="font-size: x-small;">Persistent long-duration tracking of general targets in video is challenging for computer vision, when the visual appearances of the target are subject to large uncertainty and variations, and when the environment is distractive. In contrast, being able to follow the target is a very basic and natural functionality in the human visual perception. This project is targeted on investigate the gap in the tracking performance between the human vision system and computer vision system, and on a new computational model to bridge the gap.</span></span></p> <p class="western" style="margin-bottom: 0in; line-height: 100%;"><span style="font-family: Garamond,serif;"><span style="font-size: x-small;"><br /></span></span></p> <p class="western" style="margin-bottom: 0in; line-height: 100%;"><span style="font-family: Garamond,serif;"><span style="font-size: x-small;">The human perception of visual dynamics is attentional and selective. This has not been well incorporated in the computational models. This project has produced a novel computational model, called the synergetic selective attention (SSA) model that integrates four important processes: early visual selection that extracts informative local attentiaonl regions (Ars), synergetic tracking of these ARs, robust integration that resolves the inconsistency in fusion, and late selection based on context-aware learning to discover contextual and discriminative ARs on the fly. This model unifies selective attention and context-awareness, and balanced between modeling and learning. This new model has demonstrated his powerfulness in handling visual clutters, occlusion and distractions in persistent visual target tracking. This project also produced methods and tools for video analytics to benefit many applications such as video surveillance, human computer interaction, robotics, multimedia databases, etc. </span></span></p><br> <p>            Last Modified: 08/31/2015<br>      Modified by: Ying&nbsp;Wu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Persistent long-duration tracking of general targets in video is challenging for computer vision, when the visual appearances of the target are subject to large uncertainty and variations, and when the environment is distractive. In contrast, being able to follow the target is a very basic and natural functionality in the human visual perception. This project is targeted on investigate the gap in the tracking performance between the human vision system and computer vision system, and on a new computational model to bridge the gap.   The human perception of visual dynamics is attentional and selective. This has not been well incorporated in the computational models. This project has produced a novel computational model, called the synergetic selective attention (SSA) model that integrates four important processes: early visual selection that extracts informative local attentiaonl regions (Ars), synergetic tracking of these ARs, robust integration that resolves the inconsistency in fusion, and late selection based on context-aware learning to discover contextual and discriminative ARs on the fly. This model unifies selective attention and context-awareness, and balanced between modeling and learning. This new model has demonstrated his powerfulness in handling visual clutters, occlusion and distractions in persistent visual target tracking. This project also produced methods and tools for video analytics to benefit many applications such as video surveillance, human computer interaction, robotics, multimedia databases, etc.        Last Modified: 08/31/2015       Submitted by: Ying Wu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
