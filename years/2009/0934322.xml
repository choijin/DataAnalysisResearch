<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CI-ADDO-EN: Collaborative Proposal: Supporting Web-Scale Experimentation using the Lemur Toolkit</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2010</AwardEffectiveDate>
<AwardExpirationDate>05/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>530000.00</AwardTotalIntnAmount>
<AwardAmount>530000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project maintains and enhances existing community software&lt;br/&gt;infrastructure, and creates new community data infrastructure to&lt;br/&gt;enable the information retrieval research community and related&lt;br/&gt;research communities to conduct research on a "web scale",&lt;br/&gt;meaning datasets of a billion or more web pages together with&lt;br/&gt;large query logs. The software infrastructure is based on the&lt;br/&gt;Lemur Toolkit and the associated Indri search engine, which are&lt;br/&gt;used by many information retrieval researchers due to the support&lt;br/&gt;for multiple retrieval models, multiple forms of evidence, and a&lt;br/&gt;powerful probabilistic query language. The enhancements to Lemur&lt;br/&gt;include support for the popular MapReduce style of distributed&lt;br/&gt;processing and other efficiency improvements to make it practical&lt;br/&gt;to do research on large web datasets 'out of the box' in common&lt;br/&gt;computer hardware environments.&lt;br/&gt;&lt;br/&gt;The new data infrastructure consists of maintenance and&lt;br/&gt;distribution of a newly created billion-page dataset, another new&lt;br/&gt;web dataset, and large, anonymized search logs that match the&lt;br/&gt;datasets. The combination of large datasets and corresponding&lt;br/&gt;large search logs enable a broad community to conduct research&lt;br/&gt;with more realistic data resources than were available&lt;br/&gt;previously. This research will lead to further advances in the&lt;br/&gt;understanding of the underlying issues for large-scale,&lt;br/&gt;personalized search, which will be an important part of the next&lt;br/&gt;generation of search engines.&lt;br/&gt;&lt;br/&gt;For further information, see the project web site at the URL:&lt;br/&gt;http://www.lemurproject.org.</AbstractNarration>
<MinAmdLetterDate>06/15/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/10/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0934322</AwardID>
<Investigator>
<FirstName>W. Bruce</FirstName>
<LastName>Croft</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>W. Bruce Croft</PI_FULL_NAME>
<EmailAddress>croft@cs.umass.edu</EmailAddress>
<PI_PHON>4135450463</PI_PHON>
<NSF_ID>000095962</NSF_ID>
<StartDate>06/15/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010359450</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~135000</FUND_OBLG>
<FUND_OBLG>2011~135000</FUND_OBLG>
<FUND_OBLG>2012~260000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project created, operated, and enhanced software, datasets, and web services used by researchers and scientists studying information retrieval and other topics related to the processing of &ldquo;web scale&rdquo; text datasets.&nbsp; The software infrastructure was based on the Lemur Toolkit and its associated Indri and Galago search engines, which are popular with researchers because they are open-source software that deliver state-of-the-art accuracy and can be modified easily to support varied research and educational needs.</p> <p>The Galago search engine was developed originally to support undergraduate and graduate courses that teach students about the software architectures of search engines containing a few million documents.&nbsp; This project made major improvements to Galago to support use in mobile environments such as Android, which have strict memory and storage limitations, as well as Linux computers clusters that support web-scale datasets.&nbsp; A variety of new features were added, for example, n-gram (phrase) indexing, tools for large-scale distributed computing environments, document fields, common document formats, user-developed ranking algorithms, and machine learning algorithms.&nbsp; Additionally, Galago supports many user convenience functions allowing researchers easier analysis of indexed document collections, such as term statistics for specified documents or provided queries, dumping of specified raw input texts or index file contents and self-documentation.</p> <p>Machine learning algorithms have become an important method of tuning search engine parameters and effectively combining diverse evidence about how well a document matches a query.&nbsp; A new library of &lsquo;learning to rank&rsquo; machine learning algorithms (<em>RankLib</em>) was developed to support this style of research.</p> <p>A prior Lemur project created <em>ClueWeb09</em>, a dataset of 1 billion web pages.&nbsp; This project created ClueWeb12, a dataset of 730 million English web pages.&nbsp; ClueWeb12 contains less &lsquo;spam&rsquo;, malware, and pornography than prior datasets; more coverage of topics discussed in social media; and more complete metadata.&nbsp; The ClueWeb09 and ClueWeb12 datasets were used in the TREC evaluations of information retrieval software conducted by the National Institute of Standards and Technologies (NIST) during each year of the project; they were also used by NTCIR, a similar evaluation conducted in Japan.&nbsp; 263 copies of ClueWeb09 and 147 copies of ClueWeb12 were licensed and distributed during the project.&nbsp; These datasets are used most actively by university-based researchers, but they are also used by small companies to test their products and by large companies to test potential product enhancements.</p> <p>Deploying reliable search services for terabytes of web data is a significant burden for organizations and researchers without significant computational resources of their own.&nbsp; The Indri search engine software and machines donated by Yahoo were used to provide web-based search services for the ClueWeb09 and ClueWeb12 datasets.&nbsp; These services serviced 4,000 - 10,000 queries per month from other educational and research institutions.</p> <p>Two additional datasets have been made available to researchers focused on question answering tasks.&nbsp; A Web Answer Passages (WebAP) dataset is derived from the 2004 TREC Terabyte Track Gov2 data and contains over 8,000 answer passage judgment annotations for 82 TREC queries.&nbsp; A Yahoo Non-Factoid Question dataset (nfL6)&nbsp; contains over 87,000 questions and corresponding answers, derived from the Yahoo Webscope L6 collection.</p> <p>New versions of software were released twice a year (June, December) throughout the project; occasionally there were also interim releases to fix important errors.&nbsp; User support services included wiki-based documenta...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project created, operated, and enhanced software, datasets, and web services used by researchers and scientists studying information retrieval and other topics related to the processing of "web scale" text datasets.  The software infrastructure was based on the Lemur Toolkit and its associated Indri and Galago search engines, which are popular with researchers because they are open-source software that deliver state-of-the-art accuracy and can be modified easily to support varied research and educational needs.  The Galago search engine was developed originally to support undergraduate and graduate courses that teach students about the software architectures of search engines containing a few million documents.  This project made major improvements to Galago to support use in mobile environments such as Android, which have strict memory and storage limitations, as well as Linux computers clusters that support web-scale datasets.  A variety of new features were added, for example, n-gram (phrase) indexing, tools for large-scale distributed computing environments, document fields, common document formats, user-developed ranking algorithms, and machine learning algorithms.  Additionally, Galago supports many user convenience functions allowing researchers easier analysis of indexed document collections, such as term statistics for specified documents or provided queries, dumping of specified raw input texts or index file contents and self-documentation.  Machine learning algorithms have become an important method of tuning search engine parameters and effectively combining diverse evidence about how well a document matches a query.  A new library of ælearning to rankÆ machine learning algorithms (RankLib) was developed to support this style of research.  A prior Lemur project created ClueWeb09, a dataset of 1 billion web pages.  This project created ClueWeb12, a dataset of 730 million English web pages.  ClueWeb12 contains less æspamÆ, malware, and pornography than prior datasets; more coverage of topics discussed in social media; and more complete metadata.  The ClueWeb09 and ClueWeb12 datasets were used in the TREC evaluations of information retrieval software conducted by the National Institute of Standards and Technologies (NIST) during each year of the project; they were also used by NTCIR, a similar evaluation conducted in Japan.  263 copies of ClueWeb09 and 147 copies of ClueWeb12 were licensed and distributed during the project.  These datasets are used most actively by university-based researchers, but they are also used by small companies to test their products and by large companies to test potential product enhancements.  Deploying reliable search services for terabytes of web data is a significant burden for organizations and researchers without significant computational resources of their own.  The Indri search engine software and machines donated by Yahoo were used to provide web-based search services for the ClueWeb09 and ClueWeb12 datasets.  These services serviced 4,000 - 10,000 queries per month from other educational and research institutions.  Two additional datasets have been made available to researchers focused on question answering tasks.  A Web Answer Passages (WebAP) dataset is derived from the 2004 TREC Terabyte Track Gov2 data and contains over 8,000 answer passage judgment annotations for 82 TREC queries.  A Yahoo Non-Factoid Question dataset (nfL6)  contains over 87,000 questions and corresponding answers, derived from the Yahoo Webscope L6 collection.  New versions of software were released twice a year (June, December) throughout the project; occasionally there were also interim releases to fix important errors.  User support services included wiki-based documentation, a discussion forum where questions and answers were posted, and support by email.  During the life of the project, several hundred scientific papers that were published in top information retrieval journals and conferences des...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
