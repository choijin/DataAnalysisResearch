<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Interactions between Word and Speech Sound Categorization in Language Acquisition</AwardTitle>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>09/30/2011</AwardExpirationDate>
<AwardTotalIntnAmount>136671.00</AwardTotalIntnAmount>
<AwardAmount>136671</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;What do babies learn first -- sounds or words? The standard view is that infants learn sounds first. In order to represent words most efficiently, they must have acquired an appropriate set of speech sound categories. However, infants appear to be able to recognize words in fluent speech well before speech sound category learning is complete.  Speech sound categories often display considerable overlap, so that focusing solely on distributions of speech sound characteristics may lead learners to posit supercategories that conflate differences used to distinguish among words. This research investigates how infants might learn multiple layers of linguistic structure simultaneously rather than sequentially, learning to categorize both speech sounds and words from unlabeled input.  A combination of empirical and computational techniques will be used to investigate whether infants can combine these learning processes in artificial language learning tasks and how such interaction might actually make the learning problem easier.&lt;br/&gt;&lt;br/&gt;This research will directly contribute to our understanding of normal language development. The research is highly interdisciplinary, involving ideas from psychology, linguistics, statistics and computer science, and its outcome has the potential to inform future research on disordered acquisition and the development of computer systems that can learn speech sound categories from unlabeled data.</AbstractNarration>
<MinAmdLetterDate>08/20/2009</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2009</MaxAmdLetterDate>
<ARRAAmount>136671</ARRAAmount>
<AwardID>0924821</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Morgan</LastName>
<EmailAddress>james_morgan@brown.edu</EmailAddress>
<StartDate>08/20/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>6890</Code>
<Text>RECOVERY ACT ACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
