<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Automating Correctness Proofs of Transactionalized Data Structures</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>166000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In multi-core computing, programmers must write concurrent code to obtain&lt;br/&gt;performance, much harder than sequential code. Transactions are part of the&lt;br/&gt;solution: they reduce concurrent reasoning to sequential reasoning.  But&lt;br/&gt;high-performance data structures require relaxed transactional memory&lt;br/&gt;techniques like open nesting.  This places a tricky correctness burden on the&lt;br/&gt;programmer: identifying which operations on the data structure conflict&lt;br/&gt;(cannot run in simultaneous transactions), and how to undo operations to back&lt;br/&gt;out incomplete transactions.&lt;br/&gt;&lt;br/&gt;The proposed solution is to specify what a data structure ought to do, and to&lt;br/&gt;prove that the programmer's conflict and undo specifications are correct. The&lt;br/&gt;project will complete a proof-of-concept tool to demonstrate the feasibility&lt;br/&gt;of the approach.&lt;br/&gt;&lt;br/&gt;The intellectual merit includes: a language for specifying data abstractions&lt;br/&gt;as abstract models amenable to the proofs required; a way to describe&lt;br/&gt;conflicts between operations on the data type, and undos; a tool to process&lt;br/&gt;the descriptions and build proofs as satisfiability problems; and algorithms&lt;br/&gt;to prove correctness of abstract locking procotols. The project will be more&lt;br/&gt;successful than general program proving since it works with abstractions, not&lt;br/&gt;implementations, and it deals with specific properties of interest. Future&lt;br/&gt;work can address correctness of implementation.&lt;br/&gt;&lt;br/&gt;The broader impact consists in assisting programmers in building safe&lt;br/&gt;high-performance concurrent data structures for multi-core platforms. The&lt;br/&gt;tools and libraries produced will be widely available. Helping solve the&lt;br/&gt;multi-core software problem has huge implications for our economy and society.</AbstractNarration>
<MinAmdLetterDate>09/09/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/02/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0953761</AwardID>
<Investigator>
<FirstName>J. Eliot</FirstName>
<LastName>Moss</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>J. Eliot B Moss</PI_FULL_NAME>
<EmailAddress>moss@cs.umass.edu</EmailAddress>
<PI_PHON>4135454206</PI_PHON>
<NSF_ID>000261930</NSF_ID>
<StartDate>09/09/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010359450</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~150000</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>?Until the last decade, computers kept increasing in the speed of their individual computations. Further speed increase of this kind is no longer practical, and future increases in computer performance require applying more computers ("cores") to the same problem. However, just as when multiple people become involved in the same task, when there are multiple computers problems arise concerning how to coordinate them. We have found that it is enormously difficult to program without highly structured coordination. One of the key coordination approaches is called "atomic transactions", long used in large commercial databases, and now being applied to ordinary computations in a form called "transactional memory". (This approach was co-invented by the PI in the 1990s and hardware support for it is now starting to appear from major computer manufacturers such as Intel and IBM.)<br />Ordinary transactional memory does not always allow the maximum safe number of computations to proceed at the same time. A technique that allows the maximum number, and thus potentially the highest performance, is called "open nested transactions." However, open nesting is somewhat harder to use since it requires programmers to say more about which parts of their code may interfere with other parts, and also to indicate how partial units of work can be undone and cleaned up if there is a problem. Perhaps the most troubling part of open nesting is that if the programmer-supplied additional information is wrong, then even if the basic algorithm is correct, things may break unpredictably when run on multiple cores. Also, this additional information is of kinds that programmers are not used to supplying, so it may be more likely to be wrong than happens with ordinary code.<br />This project aimed to check these additional specifications given by programmers, and also to help determine how close we can get to the maximum possible performance if we obey the programmer's rules about interference. This requires performing mathematical proofs, automatically, using computer analysis of descriptions of the data manipulations used in computer programs. We found that it was possible to design a way of writing the specifications that is fairly natural for programmers and that at the same time is not too difficult to prove the facts that we need to prove. This is pleasantly different from the more common experience of trying to prove things about computer programs, particular their basic correctness, where the mathematical sophistication required to write the specifications is unreasonably high, and the ability of automated tools to prove correctness is disappointingly low.<br />Concrete products of the grant include several small workshop papers and presentations, a PhD dissertation that is nearly complete, and a software tool that demonstrates the technology. The support contributed to the graduate education of two students, both working in the area of describing and proving properties of concurrent programs.</p><br> <p>            Last Modified: 01/27/2013<br>      Modified by: J. Eliot&nbsp;B&nbsp;Moss</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ ?Until the last decade, computers kept increasing in the speed of their individual computations. Further speed increase of this kind is no longer practical, and future increases in computer performance require applying more computers ("cores") to the same problem. However, just as when multiple people become involved in the same task, when there are multiple computers problems arise concerning how to coordinate them. We have found that it is enormously difficult to program without highly structured coordination. One of the key coordination approaches is called "atomic transactions", long used in large commercial databases, and now being applied to ordinary computations in a form called "transactional memory". (This approach was co-invented by the PI in the 1990s and hardware support for it is now starting to appear from major computer manufacturers such as Intel and IBM.) Ordinary transactional memory does not always allow the maximum safe number of computations to proceed at the same time. A technique that allows the maximum number, and thus potentially the highest performance, is called "open nested transactions." However, open nesting is somewhat harder to use since it requires programmers to say more about which parts of their code may interfere with other parts, and also to indicate how partial units of work can be undone and cleaned up if there is a problem. Perhaps the most troubling part of open nesting is that if the programmer-supplied additional information is wrong, then even if the basic algorithm is correct, things may break unpredictably when run on multiple cores. Also, this additional information is of kinds that programmers are not used to supplying, so it may be more likely to be wrong than happens with ordinary code. This project aimed to check these additional specifications given by programmers, and also to help determine how close we can get to the maximum possible performance if we obey the programmer's rules about interference. This requires performing mathematical proofs, automatically, using computer analysis of descriptions of the data manipulations used in computer programs. We found that it was possible to design a way of writing the specifications that is fairly natural for programmers and that at the same time is not too difficult to prove the facts that we need to prove. This is pleasantly different from the more common experience of trying to prove things about computer programs, particular their basic correctness, where the mathematical sophistication required to write the specifications is unreasonably high, and the ability of automated tools to prove correctness is disappointingly low. Concrete products of the grant include several small workshop papers and presentations, a PhD dissertation that is nearly complete, and a software tool that demonstrates the technology. The support contributed to the graduate education of two students, both working in the area of describing and proving properties of concurrent programs.       Last Modified: 01/27/2013       Submitted by: J. Eliot B Moss]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
