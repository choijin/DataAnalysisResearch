<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI:  Medium:  Collaborative Research:  Recognition of Materials</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>285959.00</AwardTotalIntnAmount>
<AwardAmount>285959</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.&lt;br/&gt;&lt;br/&gt;The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums.</AbstractNarration>
<MinAmdLetterDate>06/28/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0964429</AwardID>
<Investigator>
<FirstName>Shree</FirstName>
<LastName>Nayar</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shree K Nayar</PI_FULL_NAME>
<EmailAddress>nayar@cs.columbia.edu</EmailAddress>
<PI_PHON>2129397092</PI_PHON>
<NSF_ID>000253705</NSF_ID>
<StartDate>06/28/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName>NEW YORK</CityName>
<StateCode>NY</StateCode>
<ZipCode>100276902</ZipCode>
<StreetAddress><![CDATA[2960 Broadway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~62574</FUND_OBLG>
<FUND_OBLG>2011~64758</FUND_OBLG>
<FUND_OBLG>2012~74228</FUND_OBLG>
<FUND_OBLG>2013~84399</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project was focused on computer vision, an area within computer science that explores the ways in which computers modelled on the basic properties of human vision and cameras and other visual sensors can be used to expand the properties of what vision is, even to the point where computers can be taught to "recognize" objects, textures, and physical properties of the visual world.&nbsp;</p> <p><strong>1: Shape and Material Recovery in the Presence of Global Illumination</strong></p> <p>Most classical photometry based scene recovery techniques assume that scene points are illuminated only directly by the light source(s). Consequently, global illumination effects, such as inter-reflections, subsurface and volumetric scattering cause systematic biases in recovered scene properties, such as material and geometry.&nbsp; We have studied the problem of direct-global separation for multiple light sources.&nbsp; In practice, due to optical effects (e.g., defocus, color bleeding, screen-door), light sources cannot project perfect step edges. We showed that multiplexed illumination can be used to recover the N direct components corresponding to N different light sources by capturing just 2N + 1 images.</p> <p><strong>&nbsp;</strong></p> <p><strong>2: Recovering 3D Shape of Translucent Materials</strong></p> <p>Conventional shape recovery techniques which use active illumination, such as phase shifting, make strong assumptions on the scene, light sources and sensors. For example, objects are assumed to be made of mostly opaque and diffuse materials. Light sources and sensors are assumed to have infinite depth-of-field.</p> <p>For most practical scenarios, these assumptions are not true. Virtually every real world scene has global illumination &ndash; subsurface scattering in translucent materials (e.g., wax, marble, skin, plants, fruits, etc.) and interreflections between different parts of the scene.&nbsp; Because of global illumination and defocus effects, conventional techniques often result in large errors in the recovered shapes.</p> <p>We have developed a shape recovery technique called Micro Phase Shifting (Micro PS) which overcomes these problems.&nbsp;</p> <p><strong>Findings and Results: </strong>Micro PS enables high quality reconstructions of scenes which have traditionally been considered hard, using only a small number of images. Scenes exhibiting a variety of global illumination effects (scattering, interreflections), or combinations of multiple effects - can be handled.</p> <p><strong>Website: </strong><a href="http://www.cs.columbia.edu/CAVE/projects/MicroPhaseShifting/">http://www.cs.columbia.edu/CAVE/projects/MicroPhaseShifting/</a></p> <p><strong>3: Recovering 3D Shape of Specular Materials</strong></p> <p><strong>Research Activities:</strong> Current structured light methods are faced with two serious limitations. First, they are unable to cope with specular materials (e.g., metals, ceramic, glass) that produce strong highlights due to specular reflection. Second, they cannot recover useful information for regions that lie within shadows.</p> <p>We propose diffuse structured light, a simple but effective approach to mitigate both specularities and shadows in structured light methods.</p> <p><strong>Website: </strong><a href="http://www.cs.columbia.edu/CAVE/projects/DiffuseSL/">http://www.cs.columbia.edu/CAVE/projects/DiffuseSL/</a></p> <p>&nbsp;</p> <p><strong>4: Material and 3D Shape using Active Illumination in Sunlight</strong></p> <p><strong>Research Activities:</strong> Structured light based techniques are used in several applications, including factory automation, material recognition for food inspection and digitization of cultural heritage, robotic manipulation, performance capture and autonomous vehicles. In many real-world settings, structured light sources have to compete with strong ambient illumination. In these scenarios, because of the ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project was focused on computer vision, an area within computer science that explores the ways in which computers modelled on the basic properties of human vision and cameras and other visual sensors can be used to expand the properties of what vision is, even to the point where computers can be taught to "recognize" objects, textures, and physical properties of the visual world.   1: Shape and Material Recovery in the Presence of Global Illumination  Most classical photometry based scene recovery techniques assume that scene points are illuminated only directly by the light source(s). Consequently, global illumination effects, such as inter-reflections, subsurface and volumetric scattering cause systematic biases in recovered scene properties, such as material and geometry.  We have studied the problem of direct-global separation for multiple light sources.  In practice, due to optical effects (e.g., defocus, color bleeding, screen-door), light sources cannot project perfect step edges. We showed that multiplexed illumination can be used to recover the N direct components corresponding to N different light sources by capturing just 2N + 1 images.     2: Recovering 3D Shape of Translucent Materials  Conventional shape recovery techniques which use active illumination, such as phase shifting, make strong assumptions on the scene, light sources and sensors. For example, objects are assumed to be made of mostly opaque and diffuse materials. Light sources and sensors are assumed to have infinite depth-of-field.  For most practical scenarios, these assumptions are not true. Virtually every real world scene has global illumination &ndash; subsurface scattering in translucent materials (e.g., wax, marble, skin, plants, fruits, etc.) and interreflections between different parts of the scene.  Because of global illumination and defocus effects, conventional techniques often result in large errors in the recovered shapes.  We have developed a shape recovery technique called Micro Phase Shifting (Micro PS) which overcomes these problems.   Findings and Results: Micro PS enables high quality reconstructions of scenes which have traditionally been considered hard, using only a small number of images. Scenes exhibiting a variety of global illumination effects (scattering, interreflections), or combinations of multiple effects - can be handled.  Website: http://www.cs.columbia.edu/CAVE/projects/MicroPhaseShifting/  3: Recovering 3D Shape of Specular Materials  Research Activities: Current structured light methods are faced with two serious limitations. First, they are unable to cope with specular materials (e.g., metals, ceramic, glass) that produce strong highlights due to specular reflection. Second, they cannot recover useful information for regions that lie within shadows.  We propose diffuse structured light, a simple but effective approach to mitigate both specularities and shadows in structured light methods.  Website: http://www.cs.columbia.edu/CAVE/projects/DiffuseSL/     4: Material and 3D Shape using Active Illumination in Sunlight  Research Activities: Structured light based techniques are used in several applications, including factory automation, material recognition for food inspection and digitization of cultural heritage, robotic manipulation, performance capture and autonomous vehicles. In many real-world settings, structured light sources have to compete with strong ambient illumination. In these scenarios, because of the limited dynamic range of image sensors, the signal (intensity due to structured light) in the captured images can be extremely low, resulting in poor scene understanding (e.g., erroneous shape reconstruction and material recognition).  This is especially true outdoors, where sunlight is often 2-5 orders of magnitude brighter than the projected structured light. For instance, it is known that Kinect, a popular structured light device, cannot recover 3D shape in strong sunlight.  We have developed the...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
