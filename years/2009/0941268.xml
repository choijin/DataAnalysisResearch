<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDI-Type II: Collaborative Research: Groupscope: Instrumenting Research on Interaction Networks in Complex Social Contexts</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>1697482.00</AwardTotalIntnAmount>
<AwardAmount>1697482</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amber L. Story</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Many of the most important functions in society are undertaken by large groups or teams.  Emergency response, product development, health care, education, and economic activity are pursued in the context of large, dynamic, interacting networks of groups.  Theory and research on such networks of groups is much less developed than research on isolated small groups or formal organizations.  A major challenge for research on networks of groups is the difficulties that accompany the collection and analysis of the huge bodies of high resolution, high volume, observational data necessary to study these large, dynamic networks of groups.  The goal of this project is to address this challenge by applying advanced computing applications to capture, manage, annotate and analyze these massive observational sets of video, audio, and other data.  The resulting data analysis system, GroupScope, will enable breakthrough research into social interaction in large, dynamic groups to be conducted much more quickly and with much higher reliability than was previously possible.  It will do this by automating as many functions as possible to the highest degree possible, including managing huge volumes of video, audio, and sensor data, transcription, parsing audio for critical discourse events, annotation and indexing of video streams, and coding interaction.  These first pass analyses can then be supplemented by human analysts (and their analyses in turn will feed into machine learning that will improve the computerized analysis).  &lt;br/&gt;&lt;br/&gt;GroupScope will be developed with the collaboration of social scientists studying emergency response teams, children's playground behavior, distributed teams, and product development teams.  When developed, GroupScope will be deployed in a cyberenvironment, a Web 2.0 based cyberinfrastructure that enables a community of researchers to collaborate on common problems.  The cyberenvironment will enable multiple researchers to analyze and code the same group data for both small groups and large dynamic groups and networks.  Multiple analyses and codings working from diverse perspectives will enable discovery of previously unsuspected relationships among different levels and layers of human interaction.  They can also be linked to survey responses from participants, enabling linkage to the realm of perceptions and traits.&lt;br/&gt;&lt;br/&gt;Many of the most fundamental advances in science have come through the development of new instruments, such as more powerful telescopes or microscopes that can allow scientists to view molecules.  In the same way GroupScope will shed light on the workings of critical functions performed by real world groups such as emergency response units, health care teams, stock exchanges, and military units.  GroupScope will also have applications in the training of those working in multi-team systems, such as first responders to disasters.  It can be used to record and "grade" training sessions, giving participants feedback on both strengths and weaknesses of their approaches.</AbstractNarration>
<MinAmdLetterDate>09/14/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/22/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0941268</AwardID>
<Investigator>
<FirstName>Marshall</FirstName>
<LastName>Poole</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marshall S Poole</PI_FULL_NAME>
<EmailAddress>mspoole@uiuc.edu</EmailAddress>
<PI_PHON>2173335571</PI_PHON>
<NSF_ID>000369771</NSF_ID>
<StartDate>09/14/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Forsyth</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David A Forsyth</PI_FULL_NAME>
<EmailAddress>daf@cs.uiuc.edu</EmailAddress>
<PI_PHON>2172656851</PI_PHON>
<NSF_ID>000391155</NSF_ID>
<StartDate>09/14/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Feniosky</FirstName>
<LastName>Pena-Mora</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Feniosky Pena-Mora</PI_FULL_NAME>
<EmailAddress>feniosky@columbia.edu</EmailAddress>
<PI_PHON>2128546574</PI_PHON>
<NSF_ID>000150581</NSF_ID>
<StartDate>09/14/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Hasegawa-Johnson</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark A Hasegawa-Johnson</PI_FULL_NAME>
<EmailAddress>jhasegaw@illinois.edu</EmailAddress>
<PI_PHON>2173330925</PI_PHON>
<NSF_ID>000431210</NSF_ID>
<StartDate>09/14/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Bajcsy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter Bajcsy</PI_FULL_NAME>
<EmailAddress>pbajcsy@ncsa.uiuc.edu</EmailAddress>
<PI_PHON>2172655387</PI_PHON>
<NSF_ID>000216452</NSF_ID>
<StartDate>09/14/2010</StartDate>
<EndDate>09/22/2011</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kenton</FirstName>
<LastName>McHenry</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kenton McHenry</PI_FULL_NAME>
<EmailAddress>kmchenry@ncsa.uiuc.edu</EmailAddress>
<PI_PHON>2173332187</PI_PHON>
<NSF_ID>000539645</NSF_ID>
<StartDate>09/22/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207406</ZipCode>
<StreetAddress><![CDATA[1901 South First Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>7721</Code>
<Text>FROM DATA TO KNOWLEDGE</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~1697482</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The purpose of the GroupScope project was to develop a system for observational study of&nbsp;large, dynamic groups (8-200 members) that utilizes advances in computer's capacities to automatically analyze video, audio, and text transcriptions of human interactions.&nbsp; This project advanced the stdy of large group interactions by conducting the initial conceptualization and development of a method for integrating, processing, and automating the many hours of video and audio that result from recording large group interaction.&nbsp; The primary tasks conducted in this project were: 1) collection of testbed data from real and virtual-world group interactions (emergency responders planning large-scale responses, children interacting on grade school playgrounds, and multi-team systems carrying out experimental tasks in a virtual environment); 2)development of tools and procedures for data management of video, audio, text, sensor, and other data; 3) integration of databases and analytic tools; 4) development of speech-to-text technologies; 5) development of person tracking and annotation applications for video analysis.</p> <p>The products of this project include 55 large group datasets comprised of high quality audio as well as multi-angle, multidimensional, and point-of-vew video recordings; an audio recorded database of Midwestern dialect news readings with matching time-annotated transcriptions designed to train automatic transcription software; a web-based scalable data repository with build-in extractors that stores project data in a format-neutral manner, allowing researchers to systematically search, preview, and analyze different types of data; tests of five automatic audio transcription algorithms; person tracking software that identifies and tracks people in videorecordings; a visualizer for person tracking that allows the user to edit the tracks manually and visually compare relationships between individuals; a tool that syncs audio and video files recorded during the same data collection based on an audio signal; a test of two criticial incident recognition methods; a prototype mobile game app where players transcribe segments of audio data while competing with one another during gameplay; an algorithm for identifying network linkages from video cues; and 17 publications in refereed journals or conference proceedings, 14 conference papers/presentations, and 2 posters.</p> <p>One important conclusion of this project is that an integrated system is not ideal for conducting large-scale social scientific research.&nbsp; Instead, our findings suggest that general-purpose content management systems that can connect data and software tools together in a format-neutral manner are the best avenue for storing, synchronizing, and analyzing large scale observational data.&nbsp; Such systems are more flexible and allow for updates to data formatting and software without rendering a project or a tool obsolete.&nbsp; The CLOWDER (formerly MEDICI) system, which was refined in this project, is one such integrative content management system.&nbsp; It will be further developed in a subsequent NSF funded project (Brown Dog).</p> <p>This project yielded the foundations for several innovative avenues for future research,&nbsp; The next step in developing the person tracking software is to extract network data from the tracking data.&nbsp; Network extraction from video will enable automatic social network analysis of video data.&nbsp;Audio analyswis based on the transfer learning appoach should be refined. The GroupScope web-based data repository system should be further developed.&nbsp;</p> <p>The GroupScope project demonstrates how advances in research methodology can be achieved during interdisciplinary collaborations by utilizijng traditional forms of social scientific data in innovative ways to develop advanced software and data analysis systems.</p><br> <p>            Last...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The purpose of the GroupScope project was to develop a system for observational study of large, dynamic groups (8-200 members) that utilizes advances in computer's capacities to automatically analyze video, audio, and text transcriptions of human interactions.  This project advanced the stdy of large group interactions by conducting the initial conceptualization and development of a method for integrating, processing, and automating the many hours of video and audio that result from recording large group interaction.  The primary tasks conducted in this project were: 1) collection of testbed data from real and virtual-world group interactions (emergency responders planning large-scale responses, children interacting on grade school playgrounds, and multi-team systems carrying out experimental tasks in a virtual environment); 2)development of tools and procedures for data management of video, audio, text, sensor, and other data; 3) integration of databases and analytic tools; 4) development of speech-to-text technologies; 5) development of person tracking and annotation applications for video analysis.  The products of this project include 55 large group datasets comprised of high quality audio as well as multi-angle, multidimensional, and point-of-vew video recordings; an audio recorded database of Midwestern dialect news readings with matching time-annotated transcriptions designed to train automatic transcription software; a web-based scalable data repository with build-in extractors that stores project data in a format-neutral manner, allowing researchers to systematically search, preview, and analyze different types of data; tests of five automatic audio transcription algorithms; person tracking software that identifies and tracks people in videorecordings; a visualizer for person tracking that allows the user to edit the tracks manually and visually compare relationships between individuals; a tool that syncs audio and video files recorded during the same data collection based on an audio signal; a test of two criticial incident recognition methods; a prototype mobile game app where players transcribe segments of audio data while competing with one another during gameplay; an algorithm for identifying network linkages from video cues; and 17 publications in refereed journals or conference proceedings, 14 conference papers/presentations, and 2 posters.  One important conclusion of this project is that an integrated system is not ideal for conducting large-scale social scientific research.  Instead, our findings suggest that general-purpose content management systems that can connect data and software tools together in a format-neutral manner are the best avenue for storing, synchronizing, and analyzing large scale observational data.  Such systems are more flexible and allow for updates to data formatting and software without rendering a project or a tool obsolete.  The CLOWDER (formerly MEDICI) system, which was refined in this project, is one such integrative content management system.  It will be further developed in a subsequent NSF funded project (Brown Dog).  This project yielded the foundations for several innovative avenues for future research,  The next step in developing the person tracking software is to extract network data from the tracking data.  Network extraction from video will enable automatic social network analysis of video data. Audio analyswis based on the transfer learning appoach should be refined. The GroupScope web-based data repository system should be further developed.   The GroupScope project demonstrates how advances in research methodology can be achieved during interdisciplinary collaborations by utilizijng traditional forms of social scientific data in innovative ways to develop advanced software and data analysis systems.       Last Modified: 12/15/2015       Submitted by: Marshall S Poole]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
