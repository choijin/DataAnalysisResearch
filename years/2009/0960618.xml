<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Automating the Large-Scale Measurement of Insect Behavior</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>784948.00</AwardTotalIntnAmount>
<AwardAmount>784948</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08080200</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DBI</Abbreviation>
<LongName>Div Of Biological Infrastructure</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter McCartney</SignBlockName>
<PO_EMAI>pmccartn@nsf.gov</PO_EMAI>
<PO_PHON>7032928470</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Georgia Institute of Technology and Arizona State University are awarded grants to develop an integrated approach to automating measurements of insect behavior from video records. The study of insect behavior plays a fundamental role in biology, but progress is limited by the rate at which data can be gathered. Researchers have relied largely on direct observation or time-consuming manual annotation of video records. This project will create an automated solution that combines theory, algorithms, software modules, and databases of behavior measurements. These tools will be widely applicable to studies of animal behavior, but development will focus on the particularly rich and challenging problems offered by ants, where multiple interacting animals must be simultaneously tracked. Current multi-tracking technologies are limited in their ability to deal with the huge degree of target interaction in this context, including significant periods of occlusion of one target by another. This project will generate a novel approach that applies the graph-cut optimization method to video object segmentation. This method will be able to identify which portions of the video correspond to distinct targets even when they overlap. Accurate target segmentation will also facilitate more accurate adaptation to changes in appearance due to lighting or other environmental effects. The project will also develop novel behavior recognition methods that infer behavior from target configuration and appearance. Unlike traditional methods this approach will not rely on the state of the tracker and thus will avoid the compounding of recognition errors by tracking errors.&lt;br/&gt;&lt;br/&gt;Two cross-cutting themes inform this project. The first is a focus on algorithms and methods compatible with modular software tools, thus allowing biologists to develop a customized solution to a wide range of sensing tasks. The second theme is the utilization of state-of-the-art ultra-high resolution imaging sensors to obtain more information about ant behavior and identity than is currently possible. These capabilities will enable insect biologists to frame and answer research questions that exceed the limited data collection capabilities of current methods. Algorithms and software modules will be widely disseminated, to maximize their power to transform biology in a more general setting. For more information visit the project website at http://www.kinetrack.org/</AbstractNarration>
<MinAmdLetterDate>09/08/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/12/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0960618</AwardID>
<Investigator>
<FirstName>Tucker</FirstName>
<LastName>Balch</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tucker Balch</PI_FULL_NAME>
<EmailAddress>tucker@cc.gatech.edu</EmailAddress>
<PI_PHON>4043852861</PI_PHON>
<NSF_ID>000267564</NSF_ID>
<StartDate>09/08/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>James</FirstName>
<LastName>Rehg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James Rehg</PI_FULL_NAME>
<EmailAddress>rehg@cc.gatech.edu</EmailAddress>
<PI_PHON>4048949105</PI_PHON>
<NSF_ID>000257071</NSF_ID>
<StartDate>09/08/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1165</Code>
<Text>ADVANCES IN BIO INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9183</Code>
<Text>GENERAL FOUNDATIONS OF BIOTECHNOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>9184</Code>
<Text>BIOTECHNOLOGY - INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>BIOT</Code>
<Text>BIOTECHNOLOGY</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~224894</FUND_OBLG>
<FUND_OBLG>2011~274397</FUND_OBLG>
<FUND_OBLG>2012~285657</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed new capabilities for automatically tracking animals using video and other sensors, and created computational models of animal group behaviors. The software tools for animal tracking and multi-agent behavior modeling developed under this award are freely available to the research community at <a href="http://www.bio-tracking.org/category/software/">http://www.bio-tracking.org/category/software/</a> and <a href="https://github.com/biotracking/biosim2">https://github.com/biotracking/biosim2</a>. The lack of effective tools for measuring animal behavior on a large scale is a barrier to research in biology, and the problem is particularly acute for researchers studying social animals such as ants or primates. Interactions between animals can be quantified if the animals can be tracked over time and their patterns of interaction can be characterized. The current gold standard for research data collection is human annotation of animal behaviors, which requires specially-trained researchers to observe animals and record behaviors of interest, or manually track animal movement frame-by-frame in a video. This laborious manual process does not scale to the quantity and variety of data that is needed for discovery science.</p> <p>&nbsp;</p> <p>Technology for multi-target tracking in video provides a potential solution to the large-scale measurement of animal behavior. In multi-target tracking, the goal is to analyze a video clip containing a number of targets moving throughout the field of view. For example, in an ant experiment a camera might observe an ant colony from overhead and an experimental variable of interest might be the number of head-to-head interactions between pairs of ants. If all of the ants could be tracked automatically over time, the process of counting head-to-head interactions would be a straightforward process. Unfortunately, relatively little research has been done on animal tracking, and the majority of video-based multi-target tracking research has focused on pedestrians in surveillance video. In comparison, animals exhibit much more complex patterns of movement, including a greater facility for moving in three dimensions (e.g. ants, fish, primates). Our solution was to develop a modular tracking framework in which different target models, motion models, and visual features that could be mixed and matched to identify the best solution for a particular tracking problem. We also developed an interface through which a researcher can edit the resulting tracking data, thereby gaining robustness to errors.</p> <p>&nbsp;</p> <p>One major outcome of the project was the development of the BioTrack Pack tracking system and its evaluation on multiple domains on animal behavior including ants, fish, and primates. A second major outcome was the development of a multi-agent-based simulation system for animal group behaviors. BioSim can be used to study mechanisms by which the actions of individual animals lead to group behavior. A third major outcome was the utilization of the automated tracking software to examine three different phenomena in ant behavior: social hierarchy formation in <em>Harpegnathos</em> ants, colony level behavioral syndromes in <em>Azteca</em> ants, and information transfer during tandem run recruitment. Additional tracking-enabled studies were conducted using cockroaches and rhesus monkeys. These studies demonstrate the feasibility of integrating automated tracking into research practices and the potential for this technology to support larger-scale studies than would otherwise be possible.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/18/2015<br>      Modified by: James&nbsp;Rehg</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <di...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed new capabilities for automatically tracking animals using video and other sensors, and created computational models of animal group behaviors. The software tools for animal tracking and multi-agent behavior modeling developed under this award are freely available to the research community at http://www.bio-tracking.org/category/software/ and https://github.com/biotracking/biosim2. The lack of effective tools for measuring animal behavior on a large scale is a barrier to research in biology, and the problem is particularly acute for researchers studying social animals such as ants or primates. Interactions between animals can be quantified if the animals can be tracked over time and their patterns of interaction can be characterized. The current gold standard for research data collection is human annotation of animal behaviors, which requires specially-trained researchers to observe animals and record behaviors of interest, or manually track animal movement frame-by-frame in a video. This laborious manual process does not scale to the quantity and variety of data that is needed for discovery science.     Technology for multi-target tracking in video provides a potential solution to the large-scale measurement of animal behavior. In multi-target tracking, the goal is to analyze a video clip containing a number of targets moving throughout the field of view. For example, in an ant experiment a camera might observe an ant colony from overhead and an experimental variable of interest might be the number of head-to-head interactions between pairs of ants. If all of the ants could be tracked automatically over time, the process of counting head-to-head interactions would be a straightforward process. Unfortunately, relatively little research has been done on animal tracking, and the majority of video-based multi-target tracking research has focused on pedestrians in surveillance video. In comparison, animals exhibit much more complex patterns of movement, including a greater facility for moving in three dimensions (e.g. ants, fish, primates). Our solution was to develop a modular tracking framework in which different target models, motion models, and visual features that could be mixed and matched to identify the best solution for a particular tracking problem. We also developed an interface through which a researcher can edit the resulting tracking data, thereby gaining robustness to errors.     One major outcome of the project was the development of the BioTrack Pack tracking system and its evaluation on multiple domains on animal behavior including ants, fish, and primates. A second major outcome was the development of a multi-agent-based simulation system for animal group behaviors. BioSim can be used to study mechanisms by which the actions of individual animals lead to group behavior. A third major outcome was the utilization of the automated tracking software to examine three different phenomena in ant behavior: social hierarchy formation in Harpegnathos ants, colony level behavioral syndromes in Azteca ants, and information transfer during tandem run recruitment. Additional tracking-enabled studies were conducted using cockroaches and rhesus monkeys. These studies demonstrate the feasibility of integrating automated tracking into research practices and the potential for this technology to support larger-scale studies than would otherwise be possible.          Last Modified: 06/18/2015       Submitted by: James Rehg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
