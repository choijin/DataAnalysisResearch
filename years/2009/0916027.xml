<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III:   Small:  RIOT:   Statistical Computing with Efficient, Transparent I/O</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>516000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;Recent technological advances enable collection of massive amounts of&lt;br/&gt;data in science, commerce, and society.  These datasets bring us&lt;br/&gt;closer than ever before to solving important problems such as decoding&lt;br/&gt;human genomes and coping with climate changes.  Meanwhile, the&lt;br/&gt;exponential growth in data volume creates an urgent challenge.  Many&lt;br/&gt;existing analysis tools assume datasets fit in memory; when applied to&lt;br/&gt;massive datasets, they become unacceptably slow because of excessive&lt;br/&gt;disk input/output (I/O) operations.&lt;br/&gt;&lt;br/&gt;Across application domains, much of advanced data analysis is done&lt;br/&gt;with custom programming by statisticians.  Progress has been hindered&lt;br/&gt;by the lack of easy-to-use statistical computing environments that&lt;br/&gt;support I/O-efficient processing of large datasets.  There have been&lt;br/&gt;many approaches toward I/O-efficiency, but none has gained traction&lt;br/&gt;with statisticians because of issues ranging from efficiency to&lt;br/&gt;usability.  Disk-based storage engines and I/O-efficient function&lt;br/&gt;libraries are only a partial solution, because many sources of&lt;br/&gt;I/O-inefficiency in programs remain at a higher, inter-operation&lt;br/&gt;level.  Database systems seem to be a natural solution, with efficient&lt;br/&gt;I/O and a declarative language (SQL) enabling high-level&lt;br/&gt;optimizations.  However, much work in integrating databases and&lt;br/&gt;statistical computing remains database-centric, forcing statisticians&lt;br/&gt;to learn unfamiliar languages and deal with their impedance mismatch&lt;br/&gt;with host languages.&lt;br/&gt;&lt;br/&gt;To make a practical impact on statistical computing, this project&lt;br/&gt;postulates that a better approach is to make it transparent to users&lt;br/&gt;how I/O-efficiency is achieved.  Transparency means no SQL, or any new&lt;br/&gt;language to learn.  Transparency means that existing code should run&lt;br/&gt;without modification, and automatically gain I/O-efficiency.  The&lt;br/&gt;project, nicknamed RIOT, aims at extending R---a widely popular&lt;br/&gt;open-source statistical computing environment---to transparently&lt;br/&gt;provide efficient I/O.  Achieving transparency is challenging; RIOT&lt;br/&gt;does so with an end-to-end solution addressing issues on all fronts:&lt;br/&gt;I/O-efficient algorithms, pipelined execution, deferred evaluation,&lt;br/&gt;I/O-cost-driven expression optimization, smart storage and&lt;br/&gt;materialization, and seamless integration with an interpreted host&lt;br/&gt;language.&lt;br/&gt;&lt;br/&gt;RIOT integrates research and education, and continues the tradition of&lt;br/&gt;involving undergraduates through REU and independent studies.  As a&lt;br/&gt;database researcher, the PI is committed to learning and drawing from&lt;br/&gt;work from programming languages and high-performance computing.&lt;br/&gt;Findings from RIOT help create synergy and seed further collaboration&lt;br/&gt;with these communities.  To ensure practical impact on statistical&lt;br/&gt;computing, RIOT has enlisted collaboration from statisticians and the&lt;br/&gt;R core development team on developing, evaluating, and disseminating&lt;br/&gt;RIOT.&lt;br/&gt;&lt;br/&gt;Further information can be found at: &lt;br/&gt;http://www.cs.duke.edu/dbgroup/Main/RIOT</AbstractNarration>
<MinAmdLetterDate>09/04/2009</MinAmdLetterDate>
<MaxAmdLetterDate>05/11/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0916027</AwardID>
<Investigator>
<FirstName>Jun</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jun Yang</PI_FULL_NAME>
<EmailAddress>junyang@cs.duke.edu</EmailAddress>
<PI_PHON>9196606587</PI_PHON>
<NSF_ID>000486379</NSF_ID>
<StartDate>09/04/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<StateCode>NC</StateCode>
<ZipCode>277054010</ZipCode>
<StreetAddress><![CDATA[2200 W. Main St, Suite 710]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~500000</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Recent technological advances have enabled collection of massive amounts of data in science, commerce, and society. These large, high-resolution datasets have brought us closer than ever before to solving important problems such as decoding human genomes and coping with climate changes. Meanwhile, the exponential growth in the amount of data has created an urgent and difficult technical challenge. Many existing data analysis tools still assume that datasets fit in main memory of a single machine; they are unable to cope with massive datasets.</p> <p>Across application domains, much of advanced data analysis is done with programs custom-developed by statisticians. Unfortunately, progress has been hindered by the lack of easy-to-use statistical computing environments that support efficient and scalable execution of programs over large datasets. High-performance libraries provide only a partial solution, because many optimization opportunities in a program remain at a higher, inter-operation level. &nbsp;The goal of this project is to provide a more usable platform for big data analytics.</p> <p><strong>Intellectual Merit</strong><br />To make a practical impact on the statistical computing community, this project postulates that a better approach is to make it transparent to users how efficiency and scalability is achieved. Transparency means new language to learn; the system automatically optimizes the programs written in a high-level language familiar to statisticians. &nbsp;To achieve I/O-efficiency, this project has developed an end-to-end solution that addresses issues on all fronts in an innovative way: efficient and flexible storage and indexing, pipelined execution to avoid intermediate results, I/O-cost-driven optimization through aggressively deferred evaluation, and seamless integration of these features with an interpreted host language R. &nbsp;The project has also investigated various methods for leveraging emerging hardware and platform for scalable statistical analysis, including the use of a computing cloud, solid-state drives (SSDs), and graphics processing units (GPUs). &nbsp;Users can benefit from these technologies without having to rewrite programs specifically for them.</p> <p>This project has generated many publications in database research venues, including CIDR 2009, ICDE 2010, PVLDB 2011, PVLDB 2012, CIKM 2012, SIGMOD 2013, PVLDB 2013, and IEEE Data Engineering Bulletin 2014. &nbsp;The software artifacts developed by the project include a proof-of-concept implementation on top of a database system (available from the project website), a prototype system for I/O-efficient linear algebra built from ground up to overcome the limitations and inefficiency of database systems (demonstrated at ICDE 2010), and a prototype system that jointly optimizes parallel execution and deployment strategies for linear algebra workloads on a cloud.</p> <p><strong>Broader Impact</strong><br />The PI has been part of other interdisciplinary projects funded by NSF&shy;&shy;&shy;one studied how to collect and analyze ecological data from a sensor network, and another one investigating how to simplify the development and deployment of statistical data analysis in a cloud. &nbsp;Much of the work in this project is motivated by the ecological data analysis problems faced in the first project on sensors, while many of the results from this project are now being applied in the second project to problems in statistics and political science.</p> <p>The project has provided training for a number of PhD students: Yi Zhang, Risi Thonangi, and Botong Huang. &nbsp;Yi Zhang, the lead student on this project, graduated with a PhD in 2012. &nbsp;The PI has also supervised undergraduate researchers, Weiping Zhang and Jiaqi Yan, to work on this project.</p><br> <p>            Last Modified: 11/10/2014<br>      Modified by: Jun&nbsp;Yang</p> </div> <div class="porSideCol"></div> </d...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Recent technological advances have enabled collection of massive amounts of data in science, commerce, and society. These large, high-resolution datasets have brought us closer than ever before to solving important problems such as decoding human genomes and coping with climate changes. Meanwhile, the exponential growth in the amount of data has created an urgent and difficult technical challenge. Many existing data analysis tools still assume that datasets fit in main memory of a single machine; they are unable to cope with massive datasets.  Across application domains, much of advanced data analysis is done with programs custom-developed by statisticians. Unfortunately, progress has been hindered by the lack of easy-to-use statistical computing environments that support efficient and scalable execution of programs over large datasets. High-performance libraries provide only a partial solution, because many optimization opportunities in a program remain at a higher, inter-operation level.  The goal of this project is to provide a more usable platform for big data analytics.  Intellectual Merit To make a practical impact on the statistical computing community, this project postulates that a better approach is to make it transparent to users how efficiency and scalability is achieved. Transparency means new language to learn; the system automatically optimizes the programs written in a high-level language familiar to statisticians.  To achieve I/O-efficiency, this project has developed an end-to-end solution that addresses issues on all fronts in an innovative way: efficient and flexible storage and indexing, pipelined execution to avoid intermediate results, I/O-cost-driven optimization through aggressively deferred evaluation, and seamless integration of these features with an interpreted host language R.  The project has also investigated various methods for leveraging emerging hardware and platform for scalable statistical analysis, including the use of a computing cloud, solid-state drives (SSDs), and graphics processing units (GPUs).  Users can benefit from these technologies without having to rewrite programs specifically for them.  This project has generated many publications in database research venues, including CIDR 2009, ICDE 2010, PVLDB 2011, PVLDB 2012, CIKM 2012, SIGMOD 2013, PVLDB 2013, and IEEE Data Engineering Bulletin 2014.  The software artifacts developed by the project include a proof-of-concept implementation on top of a database system (available from the project website), a prototype system for I/O-efficient linear algebra built from ground up to overcome the limitations and inefficiency of database systems (demonstrated at ICDE 2010), and a prototype system that jointly optimizes parallel execution and deployment strategies for linear algebra workloads on a cloud.  Broader Impact The PI has been part of other interdisciplinary projects funded by NSF&shy;&shy;&shy;one studied how to collect and analyze ecological data from a sensor network, and another one investigating how to simplify the development and deployment of statistical data analysis in a cloud.  Much of the work in this project is motivated by the ecological data analysis problems faced in the first project on sensors, while many of the results from this project are now being applied in the second project to problems in statistics and political science.  The project has provided training for a number of PhD students: Yi Zhang, Risi Thonangi, and Botong Huang.  Yi Zhang, the lead student on this project, graduated with a PhD in 2012.  The PI has also supervised undergraduate researchers, Weiping Zhang and Jiaqi Yan, to work on this project.       Last Modified: 11/10/2014       Submitted by: Jun Yang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
