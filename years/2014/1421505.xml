<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Optimizing Compiler and Runtime for Concurrency-Oriented Execution Model</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>378141.00</AwardTotalIntnAmount>
<AwardAmount>426141</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Title: SHF:Small:Optimizing Compiler and Runtime for Concurrency-Oriented Execution Model&lt;br/&gt;&lt;br/&gt;The "dark silicon" effect, where an increasing fraction of cores will have to be kept powered off (or, "dark"), at every generation of transistor downsizing, has made it difficult to sustain further efficiency gains via the scaling of semiconductor technology.  However, the demands of applications and their data on storage and processing capabilities are rapidly growing, thus increasing the gap between the efficiency of the system stack and the needs of modern applications.  This research project aims to redesign the system stack based on a novel paradigm that combines throughput-processing architecture and a concurrency-centric compilation framework.  The system stack used in this research project consists of architecture specialized for throughput, which trades single-thread instruction level parallelism (ILP) exploitation units for throughput units.  The compiler is specialized for concurrency, which minimizes single thread latency by interleaved execution of a tremendous number of concurrent threads.&lt;br/&gt;&lt;br/&gt;This research project reveals the implications of concurrent execution on throughput processors and how these implications affect compile-time decisions and the corresponding runtime optimization. The intellectual merits are two-fold: 1) it reveals that the existing mainstream CPU compilation techniques are concurrency-oblivious, which leaves both many challenging problems unanswered and many opportunities for performance improvement to be explored, and 2) it tackles these problems by addressing both the resource allocation and instruction/thread scheduling aspects of compile-time decision making, which is where the fundamental difference between the concurrent execution model and the traditional CPU execution model arises. The broader impacts of this project are that the research results will drive innovation in business, education, and computing applications by reinventing the system stack to enhance efficiency and to help achieve the next supercomputing milestone, namely, exascale-computing.</AbstractNarration>
<MinAmdLetterDate>06/11/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421505</AwardID>
<Investigator>
<FirstName>Zheng</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zheng Zhang</PI_FULL_NAME>
<EmailAddress>eddy.zhengzhang@cs.rutgers.edu</EmailAddress>
<PI_PHON>8489320150</PI_PHON>
<NSF_ID>000630494</NSF_ID>
<StartDate>06/11/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName>Piscataway</CityName>
<StateCode>NJ</StateCode>
<ZipCode>088548019</ZipCode>
<StreetAddress><![CDATA[110 Frelinghuysen Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~378141</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<FUND_OBLG>2017~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 10.0px 0.0px; line-height: 20.0px; font: 14.0px Arial; color: #000000} p.p2 {margin: 0.0px 0.0px 10.0px 0.0px; line-height: 20.0px; font: 14.0px Arial; color: #000000; min-height: 16.0px} p.p3 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; line-height: 57.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000; min-height: 14.0px} span.s1 {font-kerning: none} --> <p class="p1"><span class="s1">Contemporary many-core accelerators such as general purpose GPU are undertaking computation intensive tasks that enable the most important discovery and evolution in science and industry. However, programming many-core processors requires significant time and domain expertise including task decomposition, resource allocation, mapping, scheduling, and memory management. The goal of this project is to develop a concurrency-oriented compiler and runtime to lower the software expertise for programmers in the backend optimization phase and to enable efficient program execution in the context of throughput-oriented computing.<span>&nbsp; &nbsp;</span></span></p> <p class="p1"><span class="s1">Today&rsquo;s many-core architecture is specialized for throughput, in which instruction level parallelism (ILP) exploitation units (such as cache, sophisticated branch predictors) are traded for throughput units (ALU units). The need to offload the hardware ILP optimization to software ILP optimization is pressing. To maximize ILP by software in throughput architecture, the key is to develop the compiler and runtime stack that is specialized for concurrency, which allows a large number of concurrent threads to run simultaneously, hide latency for each other, and mitigate the resource contention. In this project, we develop a concurrency-oriented software stack. We explore the relationship between resource allocation and concurrency adaptation, the tradeoff between concurrent execution performance and individual thread performance, as well as the interplay between thread/instruction scheduling and concurrent efficiency. We developed a single-procedure register allocation module that minimizes register contention among concurrent threads. We built a concurrency-aware inter-procedure register allocation module that automatically determines resource allocation across procedures and can be proved to have minimum number of local data movements. We created an unified on-chip memory allocator that considers not only register but also shared memory and cache. Last but not least we developed a compile-time transformation module that enables concurrency-aware runtime instruction scheduling.<span>&nbsp;</span></span></p> <p class="p1"><span class="s1">The work in this project is an important step towards redesigning the system stack for throughput-oriented architecture. It enhances software-hardware cooperation for achieving the next exa-scale supercomputing milestone, which will continuously drive innovation in science, business and education. Our exploration results in precious experience and data sets for understanding the performance tradeoff in the development of concurrency-oriented software stack. We disseminate the results of our research by publishing papers in premium research venues and giving talks at conferences as well as top universities in the United States and Europe. We released an open source tool for binary level instruction instrumentation and optimization for NVIDIA GPUs to allow the research community to develop better backend optimization tools with ease. Additionally, this grant provides training for 1 post-doc, 2 PhD students, and &gt; 5 undergrad students. Among the undergrad students, there is one African American student and one female student. The project encourages and enhances the representation of minority groups in STEM research.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p3"><span class="s1">&nbsp;</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 02/14/2020<br>      Modified by: Zheng&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Contemporary many-core accelerators such as general purpose GPU are undertaking computation intensive tasks that enable the most important discovery and evolution in science and industry. However, programming many-core processors requires significant time and domain expertise including task decomposition, resource allocation, mapping, scheduling, and memory management. The goal of this project is to develop a concurrency-oriented compiler and runtime to lower the software expertise for programmers in the backend optimization phase and to enable efficient program execution in the context of throughput-oriented computing.    Today’s many-core architecture is specialized for throughput, in which instruction level parallelism (ILP) exploitation units (such as cache, sophisticated branch predictors) are traded for throughput units (ALU units). The need to offload the hardware ILP optimization to software ILP optimization is pressing. To maximize ILP by software in throughput architecture, the key is to develop the compiler and runtime stack that is specialized for concurrency, which allows a large number of concurrent threads to run simultaneously, hide latency for each other, and mitigate the resource contention. In this project, we develop a concurrency-oriented software stack. We explore the relationship between resource allocation and concurrency adaptation, the tradeoff between concurrent execution performance and individual thread performance, as well as the interplay between thread/instruction scheduling and concurrent efficiency. We developed a single-procedure register allocation module that minimizes register contention among concurrent threads. We built a concurrency-aware inter-procedure register allocation module that automatically determines resource allocation across procedures and can be proved to have minimum number of local data movements. We created an unified on-chip memory allocator that considers not only register but also shared memory and cache. Last but not least we developed a compile-time transformation module that enables concurrency-aware runtime instruction scheduling.  The work in this project is an important step towards redesigning the system stack for throughput-oriented architecture. It enhances software-hardware cooperation for achieving the next exa-scale supercomputing milestone, which will continuously drive innovation in science, business and education. Our exploration results in precious experience and data sets for understanding the performance tradeoff in the development of concurrency-oriented software stack. We disseminate the results of our research by publishing papers in premium research venues and giving talks at conferences as well as top universities in the United States and Europe. We released an open source tool for binary level instruction instrumentation and optimization for NVIDIA GPUs to allow the research community to develop better backend optimization tools with ease. Additionally, this grant provides training for 1 post-doc, 2 PhD students, and &gt; 5 undergrad students. Among the undergrad students, there is one African American student and one female student. The project encourages and enhances the representation of minority groups in STEM research.                Last Modified: 02/14/2020       Submitted by: Zheng Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
