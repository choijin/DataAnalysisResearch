<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Score-Based Tests of Measurement Bias in Explanatory Item Response Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>280000.00</AwardTotalIntnAmount>
<AwardAmount>280000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
<PO_EMAI>ceavey@nsf.gov</PO_EMAI>
<PO_PHON>7032927269</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Large-scale, standardized ability tests have a prominent role in society, impacting college admissions, occupational decisions, and resource distribution.  This research project will involve the development of novel statistical methods that make it easier to determine whether or not the items making up a test are fair.  If a test (or specific items on a test) were to unfairly advantage one group of students over others, then some students from the disadvantaged groups may miss out on the opportunities that they deserve based on their abilities.  Thus, it is important to ensure that standardized tests are fair to the diverse groups of students taking the tests.  The new methods will be implemented in free software, and all data resulting from the project will be openly disseminated via the internet.  The project also will support a doctoral student in psychometrics, which is a STEM discipline with a documented shortage of students.&lt;br/&gt;&lt;br/&gt;This project will develop statistical methods that are designed to be used with item response models.  Item response models are considered to be state-of-the-art methodology for educational test development and analysis.  The new methods involve generalizations of the score test (also known as the Lagrange multiplier test) that is well known to statisticians.  These generalizations have been relatively unexplored in psychometrics, so that the methods developed in this project will address unresolved problems related to the study of test fairness.  In particular, these new methods will allow one to study novel hypotheses of fairness using simpler statistical models than are required for traditional methods.  The new methods will further allow for the study of fairness across many groups of students and within a large class of item response models, many of which are more complex than traditional models.  Along with theoretical development and software implementation, the project will illustrate the methods' abilities via simulation.  The simulations will directly compare the new methods to traditional methods and compare multiple novel statistics to one another.  The project will provide researchers with novel methods to study test fairness, free software to carry out the methods, and simulation results that guide researchers in the methods' optimal uses.</AbstractNarration>
<MinAmdLetterDate>04/06/2015</MinAmdLetterDate>
<MaxAmdLetterDate>04/06/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1460719</AwardID>
<Investigator>
<FirstName>Edgar</FirstName>
<LastName>Merkle</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edgar Merkle</PI_FULL_NAME>
<EmailAddress>merklee@missouri.edu</EmailAddress>
<PI_PHON>5738827560</PI_PHON>
<NSF_ID>000524470</NSF_ID>
<StartDate>04/06/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Missouri-Columbia</Name>
<CityName>COLUMBIA</CityName>
<ZipCode>652110001</ZipCode>
<PhoneNumber>5738827560</PhoneNumber>
<StreetAddress>115 Business Loop 70 W</StreetAddress>
<StreetAddress2><![CDATA[Mizzou North, Room 501]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153890272</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Missouri-Columbia]]></Name>
<CityName/>
<StateCode>MO</StateCode>
<ZipCode>652111230</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~280000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main goal of the project was to provide tools to facilitate the detection of bias in educational tests and psychometric scales, including the standardized tests that are required for admission to most universities and graduate/professional schools. The tools build off of relevant, modern statistical models (including item response theory and generalized linear mixed modeling), so that they supplement the methods that researchers already commonly use. The results of the project have the potential to generally improve standardized test development. This can lead to tests that are fair to the diverse groups of test takers observed in practice, helping to ensure that the best-qualified applicants (as opposed to the luckiest applicants) receive the best scores on the tests.<br /><br />The project included the specific steps of (i) developing and extending a family of statistical tests for bias detection, (ii) studying the tests' properties in controlled environments and in realistic applications, and (iii) developing free, open source implementations of the tests using the R software for statistical computing. We found that the test performance is competitive with existing statistical tests designed for similar purposes, though our proposed tests are more general in that they can typically handle a wider variety of data than existing tests. Additionally, because we also provided software tools for carrying out the tests, we were able to build on these tools and apply them to related issues, including comparing multiple statistical models to one another. These types of comparisons can be useful when one is deciding which of multiple statistical models is best for summarizing a dataset.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/04/2019<br>      Modified by: Edgar&nbsp;Merkle</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1460719/1460719_10357809_1572882333928_merderiv--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1460719/1460719_10357809_1572882333928_merderiv--rgov-800width.jpg" title="merDeriv"><img src="/por/images/Reports/POR/2019/1460719/1460719_10357809_1572882333928_merderiv--rgov-66x44.jpg" alt="merDeriv"></a> <div class="imageCaptionContainer"> <div class="imageCaption">R package merDeriv, which contains some of the tools resulting from the project.</div> <div class="imageCredit">Ed Merkle</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Edgar&nbsp;Merkle</div> <div class="imageTitle">merDeriv</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main goal of the project was to provide tools to facilitate the detection of bias in educational tests and psychometric scales, including the standardized tests that are required for admission to most universities and graduate/professional schools. The tools build off of relevant, modern statistical models (including item response theory and generalized linear mixed modeling), so that they supplement the methods that researchers already commonly use. The results of the project have the potential to generally improve standardized test development. This can lead to tests that are fair to the diverse groups of test takers observed in practice, helping to ensure that the best-qualified applicants (as opposed to the luckiest applicants) receive the best scores on the tests.  The project included the specific steps of (i) developing and extending a family of statistical tests for bias detection, (ii) studying the tests' properties in controlled environments and in realistic applications, and (iii) developing free, open source implementations of the tests using the R software for statistical computing. We found that the test performance is competitive with existing statistical tests designed for similar purposes, though our proposed tests are more general in that they can typically handle a wider variety of data than existing tests. Additionally, because we also provided software tools for carrying out the tests, we were able to build on these tools and apply them to related issues, including comparing multiple statistical models to one another. These types of comparisons can be useful when one is deciding which of multiple statistical models is best for summarizing a dataset.          Last Modified: 11/04/2019       Submitted by: Edgar Merkle]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
