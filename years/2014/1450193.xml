<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Computational Propaganda and The Production/Detection of Bots</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>218825.00</AwardTotalIntnAmount>
<AwardAmount>218825</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
<PO_EMAI>skiesler@nsf.gov</PO_EMAI>
<PO_PHON>7032928643</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Political bots are manipulating public opinion over major social networking applications. This project enables a new team of social and information scientists to investigate the impact of automated scripts, commonly called bots, on social media. The PIs will study both the bot scripts and the people making such bots, and then work with computer scientists to improve the way we catch and stop such bots. Experience suggests that political bots are most likely to appear during an international crisis, and are usually designed to promote the interests of a government in trouble. Political actors have used bots to manipulate conversations, demobilize opposition, and generate false support on popular sites like Twitter and Facebook from the U.S. as well as Sina Weibo from China. &lt;br/&gt;&lt;br/&gt;The first stage of this research is international fieldwork with the political consultants and computer experts who are commissioned to make bots. Second, the PIs are building an original database of political incidents involving bots. Finally, the PIs are using this knowledge to make better tools for detecting political bots when they appear. The PIs are doing "real-time" social and information science, and actively disseminating their findings to journalists, industry, and foreign policy experts. By developing an a network of experts in political bot detection and an original data set, the researchers will not only have a better understanding of how bots are manipulating social networks but also advance the conversation in the social sciences, computer sciences, and industry about the size of the problem and the possible solutions.</AbstractNarration>
<MinAmdLetterDate>08/01/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1450193</AwardID>
<Investigator>
<FirstName>Philip</FirstName>
<LastName>Howard</LastName>
<PI_MID_INIT>N</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Philip N Howard</PI_FULL_NAME>
<EmailAddress>pnhoward@u.washington.edu</EmailAddress>
<PI_PHON>2062216532</PI_PHON>
<NSF_ID>000302782</NSF_ID>
<StartDate>08/01/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>McDonald</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David W McDonald</PI_FULL_NAME>
<EmailAddress>dwmc@u.washington.edu</EmailAddress>
<PI_PHON>2066852945</PI_PHON>
<NSF_ID>000470515</NSF_ID>
<StartDate>08/01/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName/>
<StateCode>WA</StateCode>
<ZipCode>981953740</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~218825</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to assemble an interdisciplinary team to investigate the production and impact of computational propaganda.&nbsp; We define computational propaganda as systems of algorithms and automation on social media designed to delivery political messages.&nbsp; In understanding who is producing such &ldquo;bots&rdquo; and why, we can explain how to build more secure and trustworthy social media systems and offer strategies for dealing with such political bots.</p> <p>We were successful in that we assembled a new and balanced team of social and computer scientists to work on our intelletual merit goals.&nbsp; The computer scientists learned about the best practises in social inquiry, did methodological training on interviewing, coding event datasets and international fieldwork, and participated in writing papers and attending social science conferences.&nbsp; The social scientists learned to code and work with teams of computer scientists either designing bots or reverse engineering their design, and participated in writing papers and attending computer science conferences.&nbsp; Perhaps more important, team members from both the computer and social scientists were able to identify the good crossover conferences and publication outlets that let us disseminate our findings to other interdisciplinary teams.&nbsp;</p> <p>We faced several challenges along the way.&nbsp; First, it turned out to be difficult to study Sina Weibo on this timeline, and efforts to work with Facebook were not successful.&nbsp; So we chose Twitter as the primary source of data.&nbsp; Second, we were presented with opportunities to do research dissemination through public writing.&nbsp; We valued these, so we reprioritized our writing to take advantage of these invitations and writing for scholarly audiences will continue after the close of the project.</p> <p>Our three stage project evolved as planned and fit our broad impact goals.&nbsp; Our fieldwork involved interviews and site visits in Seattle, San Francisco, New York and Budapest.&nbsp; The event database became a useful log of incidents that helped develop the typology of bot activities we are still working with.&nbsp; The computational theory about how bots can be detected has allowed us to make a positive impact with civil society groups, journalists, and the interested public, because we have been able to offer strategies for catching and responding to political bot activity.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/27/2016<br>      Modified by: Philip&nbsp;N&nbsp;Howard</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to assemble an interdisciplinary team to investigate the production and impact of computational propaganda.  We define computational propaganda as systems of algorithms and automation on social media designed to delivery political messages.  In understanding who is producing such "bots" and why, we can explain how to build more secure and trustworthy social media systems and offer strategies for dealing with such political bots.  We were successful in that we assembled a new and balanced team of social and computer scientists to work on our intelletual merit goals.  The computer scientists learned about the best practises in social inquiry, did methodological training on interviewing, coding event datasets and international fieldwork, and participated in writing papers and attending social science conferences.  The social scientists learned to code and work with teams of computer scientists either designing bots or reverse engineering their design, and participated in writing papers and attending computer science conferences.  Perhaps more important, team members from both the computer and social scientists were able to identify the good crossover conferences and publication outlets that let us disseminate our findings to other interdisciplinary teams.   We faced several challenges along the way.  First, it turned out to be difficult to study Sina Weibo on this timeline, and efforts to work with Facebook were not successful.  So we chose Twitter as the primary source of data.  Second, we were presented with opportunities to do research dissemination through public writing.  We valued these, so we reprioritized our writing to take advantage of these invitations and writing for scholarly audiences will continue after the close of the project.  Our three stage project evolved as planned and fit our broad impact goals.  Our fieldwork involved interviews and site visits in Seattle, San Francisco, New York and Budapest.  The event database became a useful log of incidents that helped develop the typology of bot activities we are still working with.  The computational theory about how bots can be detected has allowed us to make a positive impact with civil society groups, journalists, and the interested public, because we have been able to offer strategies for catching and responding to political bot activity.          Last Modified: 11/27/2016       Submitted by: Philip N Howard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
