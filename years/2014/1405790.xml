<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>II-EN:  Collaborative Research:  Large-Scale FPGA-Centric Cluster with Direct and Programmable Communication</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>650000.00</AwardTotalIntnAmount>
<AwardAmount>687333</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Together with theory and experimentation, computer simulation now constitutes the third pillar of scientific inquiry, enabling researchers to build and test models of complex phenomena that either cannot be, or would be prohibitively expensive to be, replicated in the laboratory. Applications range from the practical, such as designing more efficient aircraft and effective drugs, to basic research in understanding the molecular basis of diseases such as Alzheimer?s. Yet computing capability is currently only a small fraction of what is needed: detailed biological simulations are limited to small numbers of macro-molecules; additional factors of millions are needed to simulate cells and far more than that for larger structures. The overall goal of this work is to give the Scientific Computing user community the capability to conduct transformative research via scalable, cost-effective, high-performance, general-purpose systems built from off-the-shelf components. The particular objective is to build a compute cluster and related infrastructure that facilitates research that advances such computer systems. The unifying technical mechanism to be explored is the integration of communication and computation in accelerator-centric clusters with direct and programmable interconnects.&lt;br/&gt;&lt;br/&gt;Three fundamental issues limiting performance are computational efficiency, power density, and communication latency. All of these issues are being addressed through increased heterogeneity, but the last in particular by integrating communication into the accelerator. This integration enables direct and programmable communication among compute components. Direct links enable the bypassing of CPU, network interface, and even device memory. Programmable communication enables data transfers to proceed with high efficiency even under substantial loads. The proposed infrastructure is a large-scale FPGA-centric cluster with direct and programmable communication (DPC). This server class is referred to as Novo-G#, where # is a place holder for DPC, because this award will target enhancing and leveraging Novo-G, the reconfigurable supercomputer at the University of Florida. The infrastructure will consist of the physical hardware, but also software and configurations to be developed to enhance both general usability and the enabled research projects. Another aspect of this infrastructure, as with the Novo-G, is the community of collaborators who will contribute tools, applications, evaluation, and feedback. Currently, a number of internal and external collaborators have been identified but there are more potential research projects?in diverse areas of applications, architecture, and systems that will be enabled by the proposed infrastructure.&lt;br/&gt;&lt;br/&gt;The broader impact of the enabled research is to advance the capability of scientific computing. The technical broader impact of the proposed infrastructure is to provide a system testbed for transformative research in a variety of areas in Computer Science and Engineering including programmable network components, processor/network interfaces especially for accelerators, FPGA-based systems, applications in Reconfigurable Computing, architecture of clusters with direct and programmable communication, and libraries and tools to support such clusters. The community of researchers using the infrastructure will consist of the PIs and their collaborators, but also the members of the broader community who commit to contributing to the infrastructure. The infrastructure will provide a platform to develop novel components for education and outreach.</AbstractNarration>
<MinAmdLetterDate>07/24/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1405790</AwardID>
<Investigator>
<FirstName>Herman</FirstName>
<LastName>Lam</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Herman Lam</PI_FULL_NAME>
<EmailAddress>hlam@ufl.edu</EmailAddress>
<PI_PHON>3523922689</PI_PHON>
<NSF_ID>000259794</NSF_ID>
<StartDate>06/28/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Herman</FirstName>
<LastName>Lam</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Herman Lam</PI_FULL_NAME>
<EmailAddress>hlam@ufl.edu</EmailAddress>
<PI_PHON>3523922689</PI_PHON>
<NSF_ID>000259794</NSF_ID>
<StartDate>07/24/2014</StartDate>
<EndDate>07/06/2017</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alan</FirstName>
<LastName>George</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alan D George</PI_FULL_NAME>
<EmailAddress>alan.george@pitt.edu</EmailAddress>
<PI_PHON>4126249664</PI_PHON>
<NSF_ID>000267484</NSF_ID>
<StartDate>07/24/2014</StartDate>
<EndDate>07/06/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Florida</Name>
<CityName>GAINESVILLE</CityName>
<ZipCode>326112002</ZipCode>
<PhoneNumber>3523923516</PhoneNumber>
<StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>969663814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Florida]]></Name>
<CityName>Gainesville</CityName>
<StateCode>FL</StateCode>
<ZipCode>326116200</ZipCode>
<StreetAddress><![CDATA[1 University of Florida]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramElement>
<Code>R198</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>U129</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>8237</Code>
<Text>CISE Interagency Agreements</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~650000</FUND_OBLG>
<FUND_OBLG>2018~23367</FUND_OBLG>
<FUND_OBLG>2020~13966</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Until recent years, computers and other digital devices can depend on vastly improved performance and functionality for each new generation (every 18 months) simply by doubling the number of transistors that can be placed onto an integrated circuit (known as Moore's Law). Similarly, further performance gain can be realized for every generation through the increase in clock frequency. However, Moore's Law has been tapering as device dimension (for increasing the number of transistors) is reaching its physical limits; and clock rates can no longer be vastly increased within a reasonable power budget. In the past two decades, performance gain has been maintained through the use of parallel computing, in the form of multi-core or many-core processors (CPUs); and large-scale HPC (High-Performance Computing) systems consisting of a large number of these CPUs.</p> <p>More recently, another trend has emerged in the use of heterogeneous computing (complementing CPUs with accelerators) to enhance performance. This trend is exemplified by this project and was well-documented in a 2018 report from the Department of Energy on the basic research needs on Extreme Heterogeneity [1]. As shown in Figure 1, existing heterogeneous systems consist of a number of computing nodes, each containing CPUs accelerated by GPUs (Graphics Processing Units). In fact, most of the most powerful HPC systems in world today have such heterogeneous architecture (<a href="https://www.top500.org/">https://www.top500.org/</a>). In the near future, emerging heterogeneous architectures are expected to contain both general-purpose accelerators (e.g., GPUs) and other science-targeted accelerators such as FPGAs (Field-Programmable Gate Arrays) and tensor accelerators (e.g., for accelerating machine learning). Looking even further into the future, computing systems are expected to be "extremely heterogenous", having a broad range of compute accelerators and other specialized technologies (e.g., compute-in-memory/storage, compute-near-memory/storage, compute-in-network), supported by open interconnects and deep memory hierarchies.</p> <p>The overall goal of this project is to research, develop, construct, and demonstrate innovations that give the high-performance computing user community the capability to conduct transformative research using a scalable, high-performance computing system which is equipped with science-targeted accelerators. The system should be cost-effective, a general-purpose system built from commercial-off-the-shelf (COTS) components.&nbsp; The objective is to build a computing&nbsp;infrastructure (called Novo-G#) that facilitates research that advances such computer systems. Specifically,&nbsp;Novo-G# is an enhancement of Novo-G, an accelerator-based reconfigurable compute (RC) cluster developed at the University of Florida.&nbsp; The unifying technical mechanism is the integration of communication and computation in accelerator-centric clusters with direct and programmable interconnects.&nbsp; A key aspect of the project is to research and develop clusters where the accelerators themselves are the central components and communicate directly with one another.&nbsp; The specific accelerator technology we are investigating is FPGA-based, currently the only COTS component that combines innate communication support, high-computational capability, low power, and an installed application base.</p> <p>The original Novo-G started in 2009 as a modest cluster of 24 compute servers and 96 Altera Stratix-III FPGAs. Thanks to this CRI grant (2014), it has since grown into a reconfigurable supercomputer containing nearly 450 Stratix-III, IV, and V FPGAs, with direct 3D-torus interconnection among the Stratix-Vs (Novo-G#). The Novo-G# computing infrastructure was upgraded in 2018-2019 in the form of two additional clusters: (1)&nbsp;Novo-G* cluster consists of 16 Altera state-of-the-art Arria 10 FPGA nodes; and (2) Novo-G Heterogeneous Computing (HGC) cluster which enables the exploration of using HGC (CPU+FPGA+GPU) to accelerate convolutional neural nets for machine learning. Mostly recently, a new node for Novo-G# was added, providing new computing capabilities to support research in using FPGA-based compute-near-memory and computing-in-memory capabilities to accelerate machine-learning and data-analytics applications.</p> <p>The technical impact of Novo-G# on scientific computing has been significant as we move accelerators such as FPGAs from a niche technology into widespread usage by broadening the applicability of large-scale reconfigurable computing (RC) systems across new domains and industry sectors whose computational demands have become the principal bottleneck. Since the beginning of this project in 2014, leading IT companies have followed Novo-G#'s lead in leveraging&nbsp;scalable FPGA-based RC technologies. Key examples include Microsoft's Catapult to accelerate the Bing search engine and their investment of large-scale incorporation of FPGAs into the Microsoft Azure cloud service. Similarly, Amazon has made major FPGA investment into their Amazon Web Services. For this project in particular, acceleration of impactful applications in molecular dynamics, graph processing, bioinformatics, and machine learning will support and impact those science domains, allowing research and development in new directions perhaps not possible before.</p> <p>For broader impact, the outcome of this project has the potential to substantively impact society by advancing computational analysis methods of increasingly vital importance to researchers in the various science domains, thereby enabling new and better scientific experiments that are impractical on conventional computing technologies, leading to far-reaching impact. Furthermore, the reduced energy consumption of scalable RC systems is a major advantage that is becoming an increasingly important societal impact.</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/01/2021<br>      Modified by: Herman&nbsp;Lam</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1405790/1405790_10322797_1609550259799_Figure1-ExtremeHeterogeneity--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1405790/1405790_10322797_1609550259799_Figure1-ExtremeHeterogeneity--rgov-800width.jpg" title="Figure 1 - Towards Extreme Heterogeneity [1]"><img src="/por/images/Reports/POR/2021/1405790/1405790_10322797_1609550259799_Figure1-ExtremeHeterogeneity--rgov-66x44.jpg" alt="Figure 1 - Towards Extreme Heterogeneity [1]"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 1 - Towards Extreme Heterogeneity [1]</div> <div class="imageCredit">[1] 2018 Report for DOE ASCR Basic Research Needs Workshop on Extreme Heterogeneity https://orau.gov/exheterogeneity2018/2018-Extreme-Heterogeneity-BRN-report-final.pdf</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Herman&nbsp;Lam</div> <div class="imageTitle">Figure 1 - Towards Extreme Heterogeneity [1]</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Until recent years, computers and other digital devices can depend on vastly improved performance and functionality for each new generation (every 18 months) simply by doubling the number of transistors that can be placed onto an integrated circuit (known as Moore's Law). Similarly, further performance gain can be realized for every generation through the increase in clock frequency. However, Moore's Law has been tapering as device dimension (for increasing the number of transistors) is reaching its physical limits; and clock rates can no longer be vastly increased within a reasonable power budget. In the past two decades, performance gain has been maintained through the use of parallel computing, in the form of multi-core or many-core processors (CPUs); and large-scale HPC (High-Performance Computing) systems consisting of a large number of these CPUs.  More recently, another trend has emerged in the use of heterogeneous computing (complementing CPUs with accelerators) to enhance performance. This trend is exemplified by this project and was well-documented in a 2018 report from the Department of Energy on the basic research needs on Extreme Heterogeneity [1]. As shown in Figure 1, existing heterogeneous systems consist of a number of computing nodes, each containing CPUs accelerated by GPUs (Graphics Processing Units). In fact, most of the most powerful HPC systems in world today have such heterogeneous architecture (https://www.top500.org/). In the near future, emerging heterogeneous architectures are expected to contain both general-purpose accelerators (e.g., GPUs) and other science-targeted accelerators such as FPGAs (Field-Programmable Gate Arrays) and tensor accelerators (e.g., for accelerating machine learning). Looking even further into the future, computing systems are expected to be "extremely heterogenous", having a broad range of compute accelerators and other specialized technologies (e.g., compute-in-memory/storage, compute-near-memory/storage, compute-in-network), supported by open interconnects and deep memory hierarchies.  The overall goal of this project is to research, develop, construct, and demonstrate innovations that give the high-performance computing user community the capability to conduct transformative research using a scalable, high-performance computing system which is equipped with science-targeted accelerators. The system should be cost-effective, a general-purpose system built from commercial-off-the-shelf (COTS) components.  The objective is to build a computing infrastructure (called Novo-G#) that facilitates research that advances such computer systems. Specifically, Novo-G# is an enhancement of Novo-G, an accelerator-based reconfigurable compute (RC) cluster developed at the University of Florida.  The unifying technical mechanism is the integration of communication and computation in accelerator-centric clusters with direct and programmable interconnects.  A key aspect of the project is to research and develop clusters where the accelerators themselves are the central components and communicate directly with one another.  The specific accelerator technology we are investigating is FPGA-based, currently the only COTS component that combines innate communication support, high-computational capability, low power, and an installed application base.  The original Novo-G started in 2009 as a modest cluster of 24 compute servers and 96 Altera Stratix-III FPGAs. Thanks to this CRI grant (2014), it has since grown into a reconfigurable supercomputer containing nearly 450 Stratix-III, IV, and V FPGAs, with direct 3D-torus interconnection among the Stratix-Vs (Novo-G#). The Novo-G# computing infrastructure was upgraded in 2018-2019 in the form of two additional clusters: (1) Novo-G* cluster consists of 16 Altera state-of-the-art Arria 10 FPGA nodes; and (2) Novo-G Heterogeneous Computing (HGC) cluster which enables the exploration of using HGC (CPU+FPGA+GPU) to accelerate convolutional neural nets for machine learning. Mostly recently, a new node for Novo-G# was added, providing new computing capabilities to support research in using FPGA-based compute-near-memory and computing-in-memory capabilities to accelerate machine-learning and data-analytics applications.  The technical impact of Novo-G# on scientific computing has been significant as we move accelerators such as FPGAs from a niche technology into widespread usage by broadening the applicability of large-scale reconfigurable computing (RC) systems across new domains and industry sectors whose computational demands have become the principal bottleneck. Since the beginning of this project in 2014, leading IT companies have followed Novo-G#'s lead in leveraging scalable FPGA-based RC technologies. Key examples include Microsoft's Catapult to accelerate the Bing search engine and their investment of large-scale incorporation of FPGAs into the Microsoft Azure cloud service. Similarly, Amazon has made major FPGA investment into their Amazon Web Services. For this project in particular, acceleration of impactful applications in molecular dynamics, graph processing, bioinformatics, and machine learning will support and impact those science domains, allowing research and development in new directions perhaps not possible before.  For broader impact, the outcome of this project has the potential to substantively impact society by advancing computational analysis methods of increasingly vital importance to researchers in the various science domains, thereby enabling new and better scientific experiments that are impractical on conventional computing technologies, leading to far-reaching impact. Furthermore, the reduced energy consumption of scalable RC systems is a major advantage that is becoming an increasingly important societal impact.          Last Modified: 01/01/2021       Submitted by: Herman Lam]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
