<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Medium: Automated Graphical User Interface Testing  with Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>850000.00</AwardTotalIntnAmount>
<AwardAmount>850000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Smartphones and tablets with rich graphical user interfaces (GUIs) are&lt;br/&gt;becoming increasingly popular.  Hundreds of thousands of specialized&lt;br/&gt;applications, called apps, are already available for these mobile&lt;br/&gt;platforms, and the number of newly released apps continues to&lt;br/&gt;increase.  The complexity of these apps lies often in the user&lt;br/&gt;interface, with data processing either minor, or delegated to a&lt;br/&gt;backend component. A similar situation exists in applications using&lt;br/&gt;the software-as-a-service architecture, where the client-side&lt;br/&gt;component consists mostly of user interface code.  Testing such&lt;br/&gt;applications predominantly involves GUI testing. Existing automatic&lt;br/&gt;techniques for testing these interfaces either require a priori models&lt;br/&gt;of the interface and are thus hard to use, or operate blindly by&lt;br/&gt;sending random user events to the application and are typically unable&lt;br/&gt;to test the application in satisfactory depth.&lt;br/&gt;&lt;br/&gt;This project investigates automatic GUI testing techniques that&lt;br/&gt;systematically explore the state space of an application without&lt;br/&gt;requiring an a priori defined model.  One insight behind this project&lt;br/&gt;is that the automatic construction of a model of the user interface&lt;br/&gt;and the testing of the interface are tasks that can cooperate in a&lt;br/&gt;mutually beneficial way. Furthermore, a guiding principle throughout&lt;br/&gt;this research is to design algorithms that operate with abstractions&lt;br/&gt;and heuristics that are simple enough to be understood by humans who&lt;br/&gt;do not necessarily understand the internals of the tested app. Such&lt;br/&gt;algorithms are easier to comprehend and to incorporate into a&lt;br/&gt;wholistic test process that includes automated techniques, such as the&lt;br/&gt;ones developed in this project, and manual testing and guidance.  The&lt;br/&gt;techniques developed in this project benefit directly programmers for&lt;br/&gt;these apps, and indirectly the numerous users of mobile and web&lt;br/&gt;applications.</AbstractNarration>
<MinAmdLetterDate>07/29/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/15/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1409872</AwardID>
<Investigator>
<FirstName>George</FirstName>
<LastName>Necula</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>George C Necula</PI_FULL_NAME>
<EmailAddress>necula@cs.berkeley.edu</EmailAddress>
<PI_PHON>5106431481</PI_PHON>
<NSF_ID>000215459</NSF_ID>
<StartDate>07/29/2014</StartDate>
<EndDate>05/15/2018</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Koushik</FirstName>
<LastName>Sen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Koushik Sen</PI_FULL_NAME>
<EmailAddress>ksen@eecs.berkeley.edu</EmailAddress>
<PI_PHON>5106422420</PI_PHON>
<NSF_ID>000490260</NSF_ID>
<StartDate>07/29/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947201776</ZipCode>
<StreetAddress><![CDATA[581 Soda Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~850000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>Graphical User Interfaces (GUI) are increasingly popular, with significant growth in the mobile and web application area. This project developed automatic GUI testing techniques that systematically explore an application's state space without requiring an a priori defined model.&nbsp;</span></p> <p>&nbsp;</p> <p><span>In the project, we developed automated testing techniques SwiftHand and EventBreak, for graphical user interfaces (GUI) of Android apps using machine learning and program analysis. We also developed a technique called DETREDUCE to significantly reduce the size of test-suites generated by such automated testing techniques. In the past, I created a customizable dynamic analysis framework for JavaScript programs called Jalangi. Javascript is widely used to make websites GUIs interactive. Recently we have built several dynamic analyses on top of Jalangi:</span></p> <ul> <li><span>Trace typing, a technique for automatically and quantitatively evaluating variations of a retrofitted type system on JavaScript programs.</span></li> <li><span>Travioli, a technique for detecting and visualizing data-structure traversals, for manually generating performance regression tests, and for discovering performance bugs caused by redundant traversals.</span></li> <li><span>EventRaceCommander, a technique for automated repair of event race errors in JavaScript web applications.</span></li> <li><span>A platform-independent dynamic taint analysis technique for JavaScript.&nbsp;</span></li> </ul> <p><span>While working with GUI testing, we realized that we could apply feedback-directed fuzzing and machine learning to get better coverage.  We developed ground-breaking automated test generation techniques that can find deep correctness and security bugs and pathological performance and resource usage bugs in real-world software. Such bugs were beyond the reach of existing automated testing techniques. A key insight behind this work is that if one could use machine learning and solicit high-level insights and guidance from developers, automated testing's effectiveness and efficiency can be dramatically improved. Our research contributions have made fuzz testing smarter and dramatically more effective for real-world software. Our papers have won awards: ACM SIGSOFT Distinguished Paper, ACM SIGSOFT Distinguished Artifact, and Best Tool Demo. Large tech firms have adopted our testing tools (e.g., Netflix and Samsung) and have been commercialized by security-oriented startups (e.g., FuzzIt and Pentagrid AG).</span></p> <p><span><br /></span></p> <p>&nbsp;</p> </div> </div> </div><br> <p>            Last Modified: 11/02/2020<br>      Modified by: Koushik&nbsp;Sen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    Graphical User Interfaces (GUI) are increasingly popular, with significant growth in the mobile and web application area. This project developed automatic GUI testing techniques that systematically explore an application's state space without requiring an a priori defined model.      In the project, we developed automated testing techniques SwiftHand and EventBreak, for graphical user interfaces (GUI) of Android apps using machine learning and program analysis. We also developed a technique called DETREDUCE to significantly reduce the size of test-suites generated by such automated testing techniques. In the past, I created a customizable dynamic analysis framework for JavaScript programs called Jalangi. Javascript is widely used to make websites GUIs interactive. Recently we have built several dynamic analyses on top of Jalangi:  Trace typing, a technique for automatically and quantitatively evaluating variations of a retrofitted type system on JavaScript programs. Travioli, a technique for detecting and visualizing data-structure traversals, for manually generating performance regression tests, and for discovering performance bugs caused by redundant traversals. EventRaceCommander, a technique for automated repair of event race errors in JavaScript web applications. A platform-independent dynamic taint analysis technique for JavaScript.    While working with GUI testing, we realized that we could apply feedback-directed fuzzing and machine learning to get better coverage.  We developed ground-breaking automated test generation techniques that can find deep correctness and security bugs and pathological performance and resource usage bugs in real-world software. Such bugs were beyond the reach of existing automated testing techniques. A key insight behind this work is that if one could use machine learning and solicit high-level insights and guidance from developers, automated testing's effectiveness and efficiency can be dramatically improved. Our research contributions have made fuzz testing smarter and dramatically more effective for real-world software. Our papers have won awards: ACM SIGSOFT Distinguished Paper, ACM SIGSOFT Distinguished Artifact, and Best Tool Demo. Large tech firms have adopted our testing tools (e.g., Netflix and Samsung) and have been commercialized by security-oriented startups (e.g., FuzzIt and Pentagrid AG).                Last Modified: 11/02/2020       Submitted by: Koushik Sen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
