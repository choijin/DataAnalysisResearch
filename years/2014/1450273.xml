<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SI2-SSI: Collaborative Research: A Sustainable Infrastructure for Perfomance, Security, and Correctness Tools</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>1500000.00</AwardTotalIntnAmount>
<AwardAmount>1500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Bogdan Mihaila</SignBlockName>
<PO_EMAI>bmihaila@nsf.gov</PO_EMAI>
<PO_PHON>7032928235</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Software has become indispensable to society, used by computational scientists for science and engineering, by analysts mining big data for value, and to connect society over the Internet. However, the properties of software systems for any of these purposes cannot be understood without accounting for code transformations applied by optimizing compilers used to compose algorithm and data structure templates, and libraries available only in binary form. To address this need, this project will overhaul, integrate, and enhance static binary analysis and runtime technologies to produce components that provide a foundation for performance, correctness, and security tools. The project will build upon three successful and widely adopted open source software packages: the DynInst library for analysis and transformation of application binaries, the MRNet infrastructure for control of large-scale parallel executions and data analysis of their results, and the HPCToolkit performance analysis tools. The project team will engage the community to participate in the design and evaluation of the emerging components, as well as to adopt its components. &lt;br/&gt;&lt;br/&gt;This project will have a wide range of impacts. First, software components built by the project will enable the development of sophisticated, high-quality, end-user performance, correctness, and security tools built by the project team, as well as others in academia, government, and industry. Software developed by the project team will help researchers and developers tackle testing, debugging, monitoring, analysis, and tuning of applications for systems at all scales. Second, end-user tools produced by the project have a natural place in the classroom to help students write efficient, correct, and secure programs. Third, components produced by the project will lower the barrier for new researchers to enter the field and build tools that have impact on production applications without years of investment. Fourth, the project will provide training for graduate students and interns in the area of software for performance, correctness, and security. Finally, through workshops and tutorials, the project will disseminate project results, provide training to enable others to leverage project software, and grow a community of tool researchers who depend on project components and thus have a strong motivation to help sustain project software into the future.&lt;br/&gt;&lt;br/&gt;Modernizing open-source software components and tools for binary analysis will enable static analysis of application characteristics at the level of executable machine code, transformation of binaries to inject monitoring code, measurement to capture a detailed record of application?s interactions with all facets of a target platform, analysis of recorded data in parallel, and attribution of analysis results back to application source code in meaningful ways. Providing innovative, software components that support development of robust performance, correctness, and security tools will accelerate innovation by tools researchers and help them grapple with the increasing complexity of modern software. Of particular note, helping tools researchers and computational scientists grapple with the challenges of software for modern parallel systems and producing training materials that help people use this software, addresses several of the needs identified in the NSF Vision for Cyberinfrastructure for the 21st Century.</AbstractNarration>
<MinAmdLetterDate>07/20/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1450273</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Mellor-Crummey</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John M Mellor-Crummey</PI_FULL_NAME>
<EmailAddress>johnmc@rice.edu</EmailAddress>
<PI_PHON>7133485179</PI_PHON>
<NSF_ID>000195018</NSF_ID>
<StartDate>07/20/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050299031</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WILLIAM MARSH RICE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050299031</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[William Marsh Rice University]]></Name>
<CityName>Houston</CityName>
<StateCode>TX</StateCode>
<ZipCode>770051827</ZipCode>
<StreetAddress><![CDATA[6100 Main St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8004</Code>
<Text>Software Institutes</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8009</Code>
<Text>Scientifc Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~1500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In a collaboration with the University of Wisconsin, the project team at Rice University extended Wisconsin's Dyninst binary analysis toolkit, Rice University's HPCToolkit performance analysis tools, and leveraged both of these software systems to build a new correctness tool - the ROMP data race detector for multithreaded OpenMP programs - and evaluate its performance. Below are brief highlights of the sustainable software infrastructure project's technical accomplishments.</p> <ul> <li>The project team extended Dyninst with support for analysis of binaries for ARM processors and IBM Power processors that operate in little-endian mode, e.g. Power8 and Power9.&nbsp;</li> <li><span style="font-size: 12px;">The project team enhanced the precision of binary analysis in Dyninst by improving the analysis of jump tables and improving machine code parsing for vector instructions.</span></li> <li><span style="font-size: 12px;">The project team extended Dyninst with an API that enables client tools to inject information about basic blocks and control flow edges obtained from machine code parsed outside Dyninst. This capability enables HPCToolkit to use Dyninst to support analysis of loop nests in binaries for Intel and NVIDIA GPUs.</span></li> <li><span style="font-size: 12px;">The project team replaced HPCToolkit's home-grown binary analysis capabilities with Dyninst, which improves HPCToolkit's ability to attribute performance measurements back to application source code at multiple levels. Leveraging Dyninst enabled porting of HPCToolkit to ARM, Power8, and Power9 processors.</span></li> <li><span style="font-size: 12px;">The project team leveraged Dyninst's binary analysis capabilities to extend HPCToolkit to support performance measurement and analysis of GPU-accelerated parallel applications.&nbsp;</span></li> <li><span style="font-size: 12px;">To better support analysis of large application binaries, the project team enhanced Dyninst to parse machine code and symbol table information in parallel. Using this multithreaded version of Dyninst reduced HPCToolkit's program structure analysis of a 7.7GiB TensorFlow binary from over 20 minutes to 161s on 16 cores.&nbsp;</span></li> <li><span style="font-size: 12px;">The project team at Rice University used Dyninst to implement ROMP - a new correctness tool for detecting data races in multithreaded programs written using the OpenMP programming model. (Data races, which occur when multiple accesses, including one or more writes, to a shared variable are not synchronized, are errors can cause multithreaded programs to behave unpredictably.)</span></li> <li><span style="font-size: 12px;">The project team at Rice University contributed to the open-source libunwind project to (1) enable it to be used to unwind an application's call stack from within a signal handler in an async-signal-safe fashion, and (2) enable memoization of unwind recipes at runtime to reduce unwinding overhead. These capabilities were pre-requisites for HPCToolkit to use libunwind.</span></li> <li><span style="font-size: 12px;">The project team leveraged libunwind in HPCToolkit to collect calling context profiles on ARM processors and to improve existing call stack unwinding capabilities for x86_64 processors.&nbsp;</span></li> <li><span style="font-size: 12px;">The project team began modernizing HPCToolkit's Graphical User Interface (GUI). This modernization included combining support for both trace and profile views into a single GUI and porting the GUI to the Eclipse4 framework, which works with newer versions of Java. The new implementation uses the Apache Maven build system to generate GUI executables for Windows, MacOS and Linux.</span></li> <li><span style="font-size: 12px;">The project team leveraged both Dyninst's binary analysis and HPCToolkit's performance measurement and attribution to develop new capabilities for automated diagnosis of scalability losses in parallel applications.&nbsp;</span></li> <li><span style="font-size: 12px;">The project team began development of "hpctest" a python-based framework for automated regression testing of HPCToolkit. This work leverages the DOE Spack package manager to support testing across multiple configurations and versions of compilers and software frameworks.</span></li> </ul> <p dir="ltr"><span>The project team disseminates Dyninst and HPCToolkit as open source software. Dyninst is distributed as part of Red Hat Linux. HPCToolkit has been deployed on systems around the world and is used in academia, industry, and at national laboratories. Notably, HPCToolkit is used to analyze GPU-accelerated computations on the Summit and Sierra supercomputers at Oak Ridge and Lawrence Livermore National Laboratories - two of the fastest supercomputers in the world.&nbsp;</span></p> <p dir="ltr"><span>The project team achieved the sustainability goals for HPCToolkit and Dyninst, securing new funding from the Department of Energy's (DOE) Exascale Computing Program, ARM, AMD, Intel, Cray, Argonne National Laboratory, and DOE National Nuclear Security Administration laboratories (Livermore, Sandia, Los Alamos).</span></p> <p dir="ltr"><span>The project has included participation by graduate students and undergraduates at Rice University, as well as summer interns from the University of Novi Sad and the University of Belgrade in Serbia. Every year since the beginning of this project (with an exception for 2020 due to COVID-19), the project team has led an annual Scalable Tools Workshop, which attracts approximately 40 tool developers from academia, industry, and national laboratories around the world. Every summer during the term of the grant, the Rice University PI has lectured and supervised a hands-on session about the HPCToolkit performance tools at the Argonne Training Program for Extreme-Scale Computing (ATPESC) - a program for graduate students, postdocs, and computational scientists.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 01/12/2021<br>      Modified by: John&nbsp;M&nbsp;Mellor-Crummey</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In a collaboration with the University of Wisconsin, the project team at Rice University extended Wisconsin's Dyninst binary analysis toolkit, Rice University's HPCToolkit performance analysis tools, and leveraged both of these software systems to build a new correctness tool - the ROMP data race detector for multithreaded OpenMP programs - and evaluate its performance. Below are brief highlights of the sustainable software infrastructure project's technical accomplishments.  The project team extended Dyninst with support for analysis of binaries for ARM processors and IBM Power processors that operate in little-endian mode, e.g. Power8 and Power9.  The project team enhanced the precision of binary analysis in Dyninst by improving the analysis of jump tables and improving machine code parsing for vector instructions. The project team extended Dyninst with an API that enables client tools to inject information about basic blocks and control flow edges obtained from machine code parsed outside Dyninst. This capability enables HPCToolkit to use Dyninst to support analysis of loop nests in binaries for Intel and NVIDIA GPUs. The project team replaced HPCToolkit's home-grown binary analysis capabilities with Dyninst, which improves HPCToolkit's ability to attribute performance measurements back to application source code at multiple levels. Leveraging Dyninst enabled porting of HPCToolkit to ARM, Power8, and Power9 processors. The project team leveraged Dyninst's binary analysis capabilities to extend HPCToolkit to support performance measurement and analysis of GPU-accelerated parallel applications.  To better support analysis of large application binaries, the project team enhanced Dyninst to parse machine code and symbol table information in parallel. Using this multithreaded version of Dyninst reduced HPCToolkit's program structure analysis of a 7.7GiB TensorFlow binary from over 20 minutes to 161s on 16 cores.  The project team at Rice University used Dyninst to implement ROMP - a new correctness tool for detecting data races in multithreaded programs written using the OpenMP programming model. (Data races, which occur when multiple accesses, including one or more writes, to a shared variable are not synchronized, are errors can cause multithreaded programs to behave unpredictably.) The project team at Rice University contributed to the open-source libunwind project to (1) enable it to be used to unwind an application's call stack from within a signal handler in an async-signal-safe fashion, and (2) enable memoization of unwind recipes at runtime to reduce unwinding overhead. These capabilities were pre-requisites for HPCToolkit to use libunwind. The project team leveraged libunwind in HPCToolkit to collect calling context profiles on ARM processors and to improve existing call stack unwinding capabilities for x86_64 processors.  The project team began modernizing HPCToolkit's Graphical User Interface (GUI). This modernization included combining support for both trace and profile views into a single GUI and porting the GUI to the Eclipse4 framework, which works with newer versions of Java. The new implementation uses the Apache Maven build system to generate GUI executables for Windows, MacOS and Linux. The project team leveraged both Dyninst's binary analysis and HPCToolkit's performance measurement and attribution to develop new capabilities for automated diagnosis of scalability losses in parallel applications.  The project team began development of "hpctest" a python-based framework for automated regression testing of HPCToolkit. This work leverages the DOE Spack package manager to support testing across multiple configurations and versions of compilers and software frameworks.  The project team disseminates Dyninst and HPCToolkit as open source software. Dyninst is distributed as part of Red Hat Linux. HPCToolkit has been deployed on systems around the world and is used in academia, industry, and at national laboratories. Notably, HPCToolkit is used to analyze GPU-accelerated computations on the Summit and Sierra supercomputers at Oak Ridge and Lawrence Livermore National Laboratories - two of the fastest supercomputers in the world.  The project team achieved the sustainability goals for HPCToolkit and Dyninst, securing new funding from the Department of Energy's (DOE) Exascale Computing Program, ARM, AMD, Intel, Cray, Argonne National Laboratory, and DOE National Nuclear Security Administration laboratories (Livermore, Sandia, Los Alamos). The project has included participation by graduate students and undergraduates at Rice University, as well as summer interns from the University of Novi Sad and the University of Belgrade in Serbia. Every year since the beginning of this project (with an exception for 2020 due to COVID-19), the project team has led an annual Scalable Tools Workshop, which attracts approximately 40 tool developers from academia, industry, and national laboratories around the world. Every summer during the term of the grant, the Rice University PI has lectured and supervised a hands-on session about the HPCToolkit performance tools at the Argonne Training Program for Extreme-Scale Computing (ATPESC) - a program for graduate students, postdocs, and computational scientists.          Last Modified: 01/12/2021       Submitted by: John M Mellor-Crummey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
