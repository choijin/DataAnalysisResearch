<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Exploring Heuristics and Designing Interface Cues to Understand Revealing or Withholding of Private Information</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>262383.00</AwardTotalIntnAmount>
<AwardAmount>278383</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In individual pursuits of personalized service and other functionalities, people disclose personal and private information by trusting certain online sites and services. Scholars often assume that such trust is based on a careful assessment of the benefits and risks of disclosing information online. This project departs from such an assumption and investigates the possibility that decision-making about online information disclosure is not systematic, but rather based on cognitive heuristics (or mental shortcuts) triggered by cues in the interaction context. The objective of this project is to identify positive and negative heuristics triggered by online interface cues that predict why users instinctively trust or distrust certain online systems. &lt;br/&gt;&lt;br/&gt;Phase 1 involves exploratory interviews and a survey pertaining to privacy and security mishaps. Based on findings from these studies, the PIs design cues and related interface functionalities in Phase 2. Phase 3 features controlled experiments that empirically assess how interface cues trigger heuristics and what role they play in user trust and information disclosure.&lt;br/&gt;&lt;br/&gt;The findings of this research can be transformational in advancing knowledge about the many paradoxes that confront researchers, such as the privacy paradox (users reveal more than they admit) and control paradox (provision of control to users makes them worry more, not less, about security). Design insights from this project can be propagated to a variety of contexts to trigger desired heuristics and promote secure and trustworthy computing. The enumeration of heuristics serves a media-literacy function by alerting users to common psychological biases that compromise the security of their information.</AbstractNarration>
<MinAmdLetterDate>08/27/2014</MinAmdLetterDate>
<MaxAmdLetterDate>04/24/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1450500</AwardID>
<Investigator>
<FirstName>Mary Beth</FirstName>
<LastName>Rosson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mary Beth Rosson</PI_FULL_NAME>
<EmailAddress>mrosson@psu.edu</EmailAddress>
<PI_PHON>8148633450</PI_PHON>
<NSF_ID>000421157</NSF_ID>
<StartDate>08/27/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>S. Shyam</FirstName>
<LastName>Sundar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>S. Shyam Sundar</PI_FULL_NAME>
<EmailAddress>SSS12@psu.edu</EmailAddress>
<PI_PHON>8148652173</PI_PHON>
<NSF_ID>000350722</NSF_ID>
<StartDate>08/27/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~262383</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In pursuit of personalized service and other functionalities, online users often disclose more personal information than ever before. They do so by making daily decisions about the trustworthiness of online systems. Scholars assume that this decision-making is thoughtful and deliberate, based on a calculation of the benefits and risks of disclosing information online. However, our project departed from this assumption and investigated the possibility that decision-making about disclosure is based on heuristics triggered by cues in the interaction context. Heuristics are mental shortcuts or rules of thumb that we use to quickly draw a conclusion. They are triggered by visible cues which lead us to make a superficial decision rather than go through an effortful consideration of underlying details. For example, the presence of a lock symbol on a banking website may encourage users to conduct sensitive transactions even when they have an insecure connection, while the logo of FDIC may engender greater trust in a bank site by triggering the "authority heuristic" (rule of thumb: It it&rsquo;s guaranteed by an authority, then it must be safe).</p> <p>The central goal of our project was to advance our understanding of such rules of thumb involved in online decision-making, by identifying and testing an exhaustive list of both positive and negative heuristics triggered by online interface cues that predict why users instinctively trust or distrust certain online systems (see attached Table). We employed innovative probes pertaining to privacy and security mishaps, as well as positive experiences, in a series of exploratory interviews, followed by a large-scale survey in Phase 1. Findings informed scenario-based design of cues in Phase 2, for isolating these heuristics and implementing them on mobile and Web interfaces. In Phase 3, we used controlled online experiments to empirically assess how these cues trigger heuristics and what role they played in user trust and information disclosure.</p> <p>We conducted a variety of studies involving nearly 4,000 participants. The interview study in Phase 1 provided evidence to support the privacy paradox&ndash; users are able to articulate quite a large number of cognitive heuristics that influence their privacy perceptions and behaviors. In some cases, we were able to map the contextual factors to psychologically salient interface features, revealing that the underlying heuristics may be more generalizable across contexts than previously thought. Besides the interview study, the national survey data showed that cognitive heuristics indeed play a statistically significant role in predicting users&rsquo; tendency to instinctively trust (or distrust) certain online systems and divulge (or withhold) their private information. Based on the findings from Phase 1, a user study was conducted in Phase 2 in which we found that participants speculated that their decisions may have been based on their general beliefs about privacy and information sharing, which is consistent with other studies that have reported a mismatch between what people think they know and feel about privacy and how they behave. To test if such belief in heuristics plays a role in various online and mobile contexts, 9 experiments were conducted, which coherently showed that the operation of privacy-related heuristics on users&rsquo; decision-making on information disclosure. That is, the data altogether suggested that users rely on specific rules of thumb to decide whether to reveal (or hide) their private information in diverse contexts, ranging from ordering airline tickets online to chatting with a robot nurse about personal health issues. The table below summarizes all heuristics that were identified and tested in the current project.</p> <p>In all, the findings of our project imply that a scientific understanding of user psychology and disclosure behaviors is quite critical for engineering responsive systems that encourage responsible behaviors by triggering appropriate cognitive heuristics. Our discoveries may have direct applicability to computing systems in making privacy and security notices simpler and more psychologically accessible. The design insights that emerge from this study can be propagated to a variety of online/mobile contexts and adapted in site-specific ways to trigger the desired heuristics among users and promote secure and trustworthy computing. Moreover, our enumeration of heuristics may serve a media-literacy function by alerting users to psychological biases that compromise the privacy and security of their information. Additionally, the identification of heuristics related to online privacy and security may be transformational in advancing our knowledge about the many paradoxes that confront researchers&ndash; the privacy paradox (users reveal more than they admit), personalization paradox (users want systems to cater to them without profiling them), and control paradox (provision of control to users makes them worry more, not less, about security). Overall, our project not only provided user-based guidelines for designing and engineering secure and trustworthy computing systems, but achieved new collaboration between a communication scientist and a computer-and-information-science researcher, making basic theoretical contributions to human-centered computing, communication and psychology, by attempting a unique synergy between experimental social science and evolutionary design research.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/19/2017<br>      Modified by: S. Shyam&nbsp;Sundar</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1450500/1450500_10338630_1513694911687_HeuristicsTableforPOR--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1450500/1450500_10338630_1513694911687_HeuristicsTableforPOR--rgov-800width.jpg" title="List of Privacy Heuristics"><img src="/por/images/Reports/POR/2017/1450500/1450500_10338630_1513694911687_HeuristicsTableforPOR--rgov-66x44.jpg" alt="List of Privacy Heuristics"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Privacy heuristics and their corresponding rules of thumb</div> <div class="imageCredit">Jinyoung Kim & S. Shyam Sundar</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">S. Shyam&nbsp;Sundar</div> <div class="imageTitle">List of Privacy Heuristics</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In pursuit of personalized service and other functionalities, online users often disclose more personal information than ever before. They do so by making daily decisions about the trustworthiness of online systems. Scholars assume that this decision-making is thoughtful and deliberate, based on a calculation of the benefits and risks of disclosing information online. However, our project departed from this assumption and investigated the possibility that decision-making about disclosure is based on heuristics triggered by cues in the interaction context. Heuristics are mental shortcuts or rules of thumb that we use to quickly draw a conclusion. They are triggered by visible cues which lead us to make a superficial decision rather than go through an effortful consideration of underlying details. For example, the presence of a lock symbol on a banking website may encourage users to conduct sensitive transactions even when they have an insecure connection, while the logo of FDIC may engender greater trust in a bank site by triggering the "authority heuristic" (rule of thumb: It it?s guaranteed by an authority, then it must be safe).  The central goal of our project was to advance our understanding of such rules of thumb involved in online decision-making, by identifying and testing an exhaustive list of both positive and negative heuristics triggered by online interface cues that predict why users instinctively trust or distrust certain online systems (see attached Table). We employed innovative probes pertaining to privacy and security mishaps, as well as positive experiences, in a series of exploratory interviews, followed by a large-scale survey in Phase 1. Findings informed scenario-based design of cues in Phase 2, for isolating these heuristics and implementing them on mobile and Web interfaces. In Phase 3, we used controlled online experiments to empirically assess how these cues trigger heuristics and what role they played in user trust and information disclosure.  We conducted a variety of studies involving nearly 4,000 participants. The interview study in Phase 1 provided evidence to support the privacy paradox&ndash; users are able to articulate quite a large number of cognitive heuristics that influence their privacy perceptions and behaviors. In some cases, we were able to map the contextual factors to psychologically salient interface features, revealing that the underlying heuristics may be more generalizable across contexts than previously thought. Besides the interview study, the national survey data showed that cognitive heuristics indeed play a statistically significant role in predicting users? tendency to instinctively trust (or distrust) certain online systems and divulge (or withhold) their private information. Based on the findings from Phase 1, a user study was conducted in Phase 2 in which we found that participants speculated that their decisions may have been based on their general beliefs about privacy and information sharing, which is consistent with other studies that have reported a mismatch between what people think they know and feel about privacy and how they behave. To test if such belief in heuristics plays a role in various online and mobile contexts, 9 experiments were conducted, which coherently showed that the operation of privacy-related heuristics on users? decision-making on information disclosure. That is, the data altogether suggested that users rely on specific rules of thumb to decide whether to reveal (or hide) their private information in diverse contexts, ranging from ordering airline tickets online to chatting with a robot nurse about personal health issues. The table below summarizes all heuristics that were identified and tested in the current project.  In all, the findings of our project imply that a scientific understanding of user psychology and disclosure behaviors is quite critical for engineering responsive systems that encourage responsible behaviors by triggering appropriate cognitive heuristics. Our discoveries may have direct applicability to computing systems in making privacy and security notices simpler and more psychologically accessible. The design insights that emerge from this study can be propagated to a variety of online/mobile contexts and adapted in site-specific ways to trigger the desired heuristics among users and promote secure and trustworthy computing. Moreover, our enumeration of heuristics may serve a media-literacy function by alerting users to psychological biases that compromise the privacy and security of their information. Additionally, the identification of heuristics related to online privacy and security may be transformational in advancing our knowledge about the many paradoxes that confront researchers&ndash; the privacy paradox (users reveal more than they admit), personalization paradox (users want systems to cater to them without profiling them), and control paradox (provision of control to users makes them worry more, not less, about security). Overall, our project not only provided user-based guidelines for designing and engineering secure and trustworthy computing systems, but achieved new collaboration between a communication scientist and a computer-and-information-science researcher, making basic theoretical contributions to human-centered computing, communication and psychology, by attempting a unique synergy between experimental social science and evolutionary design research.             Last Modified: 12/19/2017       Submitted by: S. Shyam Sundar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
