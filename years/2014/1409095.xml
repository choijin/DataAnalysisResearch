<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Medium: Collaborative Research: Enabling GPUs as First-Class Computing Engines</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>484068.00</AwardTotalIntnAmount>
<AwardAmount>484068</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Graphics Processing Units (GPUs) are rapidly bringing the computing&lt;br/&gt;power traditionally associated with massively parallel supercomputers&lt;br/&gt;into the mainstream devices we use today. They have the power to&lt;br/&gt;revolutionize computing by enabling orders of magnitude faster and&lt;br/&gt;more efficient execution of many applications. Unfortunately, many&lt;br/&gt;modern applications and users cannot take advantage of the computing&lt;br/&gt;capability present in today's GPUs because today's GPUs are used as&lt;br/&gt;secondary devices to the much less powerful CPUs. As a result, the massive&lt;br/&gt;computing power of GPUs gets wasted and underutilized for a large&lt;br/&gt;number of important applications.&lt;br/&gt;&lt;br/&gt;This project aims to take a fresh and comprehensive look at GPU design&lt;br/&gt;with the goal of enabling GPUs as first-class computing engines that&lt;br/&gt;can benefit an overwhelming majority of real-world applications and&lt;br/&gt;users. To this end, this project systematically investigates the&lt;br/&gt;hardware/software design space of three new execution models, which&lt;br/&gt;progressively turn a GPU into an independent, first-class compute&lt;br/&gt;engine in a hybrid computing system: 1) an enhanced master-slave model&lt;br/&gt;where the GPU is able to perform multiple-application execution, 2) a&lt;br/&gt;new peer-to-peer model where the GPU is autonomous of the CPU, 3) a&lt;br/&gt;hybrid model where GPUs and CPUs are integrated on the same die and&lt;br/&gt;are equals from the applications' and system's viewpoint. The project&lt;br/&gt;comprehensively develops software, hardware and software/hardware&lt;br/&gt;cooperative scheduling, resource management, and system design&lt;br/&gt;techniques for all three models.&lt;br/&gt;&lt;br/&gt;If successful, this project can pave the way to making GPUs&lt;br/&gt;first-class computing engines used in all aspects of our everyday&lt;br/&gt;lives for a majority of applications. Doing so is not only expected to&lt;br/&gt;lead to much higher degrees of energy efficiency and user productivity&lt;br/&gt;but can also potentially enable new applications and devices that can&lt;br/&gt;take advantage GPUs.</AbstractNarration>
<MinAmdLetterDate>07/31/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/08/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1409095</AwardID>
<Investigator>
<FirstName>Chitaranjan</FirstName>
<LastName>Das</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chitaranjan Das</PI_FULL_NAME>
<EmailAddress>cxd12@psu.edu</EmailAddress>
<PI_PHON>8148650194</PI_PHON>
<NSF_ID>000358842</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mahmut</FirstName>
<LastName>Kandemir</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mahmut T Kandemir</PI_FULL_NAME>
<EmailAddress>mtk2@psu.edu</EmailAddress>
<PI_PHON>8148634888</PI_PHON>
<NSF_ID>000163936</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~128331</FUND_OBLG>
<FUND_OBLG>2015~160384</FUND_OBLG>
<FUND_OBLG>2016~195353</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Abstract at the Time of Award</strong></p> <p>Graphics Processing Units (GPUs) are rapidly bringing the computing power traditionally associated with massively parallel supercomputers into the mainstream devices we use today. They have the power to revolutionize computing by enabling orders of magnitude faster and more efficient execution of many applications. Unfortunately, many modern applications and users cannot take advantage of the computing capability present in today's GPUs because today's GPUs are used as secondary devices to the much less powerful CPUs. As a result, the massive computing power of GPUs gets wasted and underutilized for a large number of important applications.<br /> <br /> This project aims to take a fresh and comprehensive look at GPU design with the goal of enabling GPUs as first-class computing engines that can benefit an overwhelming majority of real-world applications and users. To this end, this project systematically investigates the hardware/software design space of three new execution models, which progressively turn a GPU into an independent, first-class compute engine in a hybrid computing system: (1) an enhanced master-slave model where the GPU is able to perform multiple-application execution, (2) a new peer-to-peer model where the GPU is autonomous of the CPU, (3) a hybrid model where GPUs and CPUs are integrated on the same die and are equals from the applications' and system's viewpoint.&nbsp;<br /> <br /> If successful, this project can pave the way to making GPUs first-class computing engines used in all aspects of our everyday lives for a majority of applications.&nbsp;</p> <p><strong>Publications Produced as a Result of this Research</strong></p> <ul> <li>Haibo Zhang, Prasanna Venkatesh Rengasamy, Nachiappan Chidambaram Nachiappan, Shulin Zhao, Anand Sivasubramaniam, Mahmut T. Kandemir, Chita R. Das&nbsp;(2018).&nbsp;FLOSS: FLOw sensitive scheduling on mobile platforms.&nbsp;&nbsp;<em>Design Automation Conference</em><em> (DAC)</em>.&nbsp; </li> <li>Jihyun Ryoo, Orhan Kislal, Xulong Tang, Mahmut T. Kandemir&nbsp;(2018).&nbsp;Quantifying and Optimizing Data Access Parallelism on Manycores.&nbsp;<em>MASCOTS</em>.&nbsp; &nbsp;</li> <li>Kaisheng Ma, Xueqing Li, Mahmut Taylan Kandemir, Jack Sampson, Vijaykrishnan Narayanan, Jinyang Li, Tongda Wu, Zhibo Wang, Yongpan Liu, Yuan Xie&nbsp;(2018).&nbsp;NEOFog: Nonvolatility-Exploiting Optimizations for Fog Computing.&nbsp;&nbsp;<em>ASPLOS</em>.&nbsp; </li> <li>Orhan Kislal, Jagadish B. Kotra, Xulong Tang, Mahmut T. Kandemir, Myoungsoo Jung&nbsp;(2018).&nbsp;Enhancing Computation-to-Core Assignment with Physical Location Information.&nbsp;&nbsp;<em>ACM SIGPLAN C</em><em>onference on Programming Language Design and Implementation</em><em> (PLDI)</em>.&nbsp; </li> <li>Orhan Kislal, Mahmut T. Kandemir&nbsp;(2018).&nbsp;Data access skipping for recursive partitioning methods.&nbsp;&nbsp;<em>Computer Languages, Systems &amp; Structures</em>.&nbsp; &nbsp;</li> <li>Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut T. Kandemir, Chita R. Das&nbsp;(2018).&nbsp;The Curious Case of Container Orchestration and Scheduling in GPU-based Datacenters.&nbsp;&nbsp;<em>SoCC</em>.&nbsp; &nbsp;</li> <li>Xulong Tang, Ashutosh Pattnaik, Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, Chita Das&nbsp;(2019).&nbsp;Quantifying Data Locality in Dynamic Parallelism in GPUs.&nbsp;&nbsp;<em>ACM SIGMETRICS</em>.&nbsp; &nbsp;</li> <li>J. Ryoo, M. Arunachalam, R. Khanna, M. Kandemir&nbsp;(2018).&nbsp;<em>Efficient K Nearest Neighbor Algorithm Implementations for Throughput-Oriented Architectures</em>. ISQED.&nbsp;</li> <li>Rachata Ausavarungnirun, Saugata Ghose, Onur Kayiran, Gabriel H. Loh, Chita R. Das, Mahmut T. Kandemir, Onur Mutlu&nbsp;(2018).&nbsp;<em>Holistic Management of the GPGPU Memory Hierarchy to Manage Warp-level Latency Tolerance</em>. Technical Report. </li> <li>A. Pattnaik, X. Tang, O. Kayiran, A. Jog, A. Mishra, M. Kandemir, A. Sivasubramaniam, C. Das&nbsp;(2019).&nbsp;<em>Opportunistic Computing in GPU architectures</em>. ISCA.&nbsp;</li> <li>Xulong Tang, Mahmut T Kandemir&nbsp;(2019).&nbsp;<em>Quantifying the impact of GPU optimizations on address translation overheads</em>. SIGMETRICS (in preparation).&nbsp;</li> </ul> <p class="indentedcitation">&nbsp;</p> <p class="indentedcitation"><strong>Project Outcomes</strong></p> <p class="indentedcitation"><strong>&nbsp;</strong>The performance and effectiveness of many scientific applications of national interest, e.g., those from nuclear simulations, astrophysics, climate analysis, computational chemistry and bioinformatics depend strongly on high performance computing machines installed throughout the States. An overwhelming majority of these machines employ a high performance accelerator named GPU (graphical processing unit). The question of architecting next generation GPUs and integrating them with the current and emerging high computing platforms has been the overreaching goal of this NSF project.</p> <p><strong>Major Research Outcomes:</strong> Our research activities (1) enabled researchers investigate&nbsp;the limits of the current CPUs and GPUs and investigate novel techniques for significantly enhancing both performance and energy efficiency. The techniques explored included efficient scheduling techniques, facilitating dynamic parallelism in GPU cores, compiler support for identifying multiple parallel kernels, and resource partitioning/scheduling for maximizing resource utilization; (2) &nbsp;explored a new peer-to-peer model of computation, where the GPU acts as a peer with the CPU by providing feedback to accelerate/initiate computation on both CPUs/GPUs. Using feedback and autonomous actions from the GPU, we devised effective warp/thread/kernel/application scheduling techniques to enable better cooperation between CPUs/GPUs; and (3) studied an integrated/hybrid CPU-GPU paradigm to its limits via new software/hardware mechanisms.&nbsp;</p> <p class="indentedcitation"><strong>Broader Impact: </strong>&nbsp;This funding has enabled graduate student education and&nbsp;training&nbsp;on topics that go beyond conventional computing, covering cross-layer management of novel GPU architectures and behavior of scientific applications that run on top of them. The training from this project enabled students to better prepare as the next generation workforce in science and enginerring. The project also generated research publications in several top computer science and engineering conferences, including ISCA, PLDI, ASPLOS, SIGMETRICS, and DAC.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/10/2018<br>      Modified by: Mahmut&nbsp;T&nbsp;Kandemir</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Abstract at the Time of Award  Graphics Processing Units (GPUs) are rapidly bringing the computing power traditionally associated with massively parallel supercomputers into the mainstream devices we use today. They have the power to revolutionize computing by enabling orders of magnitude faster and more efficient execution of many applications. Unfortunately, many modern applications and users cannot take advantage of the computing capability present in today's GPUs because today's GPUs are used as secondary devices to the much less powerful CPUs. As a result, the massive computing power of GPUs gets wasted and underutilized for a large number of important applications.    This project aims to take a fresh and comprehensive look at GPU design with the goal of enabling GPUs as first-class computing engines that can benefit an overwhelming majority of real-world applications and users. To this end, this project systematically investigates the hardware/software design space of three new execution models, which progressively turn a GPU into an independent, first-class compute engine in a hybrid computing system: (1) an enhanced master-slave model where the GPU is able to perform multiple-application execution, (2) a new peer-to-peer model where the GPU is autonomous of the CPU, (3) a hybrid model where GPUs and CPUs are integrated on the same die and are equals from the applications' and system's viewpoint.     If successful, this project can pave the way to making GPUs first-class computing engines used in all aspects of our everyday lives for a majority of applications.   Publications Produced as a Result of this Research  Haibo Zhang, Prasanna Venkatesh Rengasamy, Nachiappan Chidambaram Nachiappan, Shulin Zhao, Anand Sivasubramaniam, Mahmut T. Kandemir, Chita R. Das (2018). FLOSS: FLOw sensitive scheduling on mobile platforms.  Design Automation Conference (DAC).   Jihyun Ryoo, Orhan Kislal, Xulong Tang, Mahmut T. Kandemir (2018). Quantifying and Optimizing Data Access Parallelism on Manycores. MASCOTS.    Kaisheng Ma, Xueqing Li, Mahmut Taylan Kandemir, Jack Sampson, Vijaykrishnan Narayanan, Jinyang Li, Tongda Wu, Zhibo Wang, Yongpan Liu, Yuan Xie (2018). NEOFog: Nonvolatility-Exploiting Optimizations for Fog Computing.  ASPLOS.   Orhan Kislal, Jagadish B. Kotra, Xulong Tang, Mahmut T. Kandemir, Myoungsoo Jung (2018). Enhancing Computation-to-Core Assignment with Physical Location Information.  ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI).   Orhan Kislal, Mahmut T. Kandemir (2018). Data access skipping for recursive partitioning methods.  Computer Languages, Systems &amp; Structures.    Prashanth Thinakaran, Jashwant Raj Gunasekaran, Bikash Sharma, Mahmut T. Kandemir, Chita R. Das (2018). The Curious Case of Container Orchestration and Scheduling in GPU-based Datacenters.  SoCC.    Xulong Tang, Ashutosh Pattnaik, Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, Chita Das (2019). Quantifying Data Locality in Dynamic Parallelism in GPUs.  ACM SIGMETRICS.    J. Ryoo, M. Arunachalam, R. Khanna, M. Kandemir (2018). Efficient K Nearest Neighbor Algorithm Implementations for Throughput-Oriented Architectures. ISQED.  Rachata Ausavarungnirun, Saugata Ghose, Onur Kayiran, Gabriel H. Loh, Chita R. Das, Mahmut T. Kandemir, Onur Mutlu (2018). Holistic Management of the GPGPU Memory Hierarchy to Manage Warp-level Latency Tolerance. Technical Report.  A. Pattnaik, X. Tang, O. Kayiran, A. Jog, A. Mishra, M. Kandemir, A. Sivasubramaniam, C. Das (2019). Opportunistic Computing in GPU architectures. ISCA.  Xulong Tang, Mahmut T Kandemir (2019). Quantifying the impact of GPU optimizations on address translation overheads. SIGMETRICS (in preparation).     Project Outcomes  The performance and effectiveness of many scientific applications of national interest, e.g., those from nuclear simulations, astrophysics, climate analysis, computational chemistry and bioinformatics depend strongly on high performance computing machines installed throughout the States. An overwhelming majority of these machines employ a high performance accelerator named GPU (graphical processing unit). The question of architecting next generation GPUs and integrating them with the current and emerging high computing platforms has been the overreaching goal of this NSF project.  Major Research Outcomes: Our research activities (1) enabled researchers investigate the limits of the current CPUs and GPUs and investigate novel techniques for significantly enhancing both performance and energy efficiency. The techniques explored included efficient scheduling techniques, facilitating dynamic parallelism in GPU cores, compiler support for identifying multiple parallel kernels, and resource partitioning/scheduling for maximizing resource utilization; (2)  explored a new peer-to-peer model of computation, where the GPU acts as a peer with the CPU by providing feedback to accelerate/initiate computation on both CPUs/GPUs. Using feedback and autonomous actions from the GPU, we devised effective warp/thread/kernel/application scheduling techniques to enable better cooperation between CPUs/GPUs; and (3) studied an integrated/hybrid CPU-GPU paradigm to its limits via new software/hardware mechanisms.  Broader Impact:  This funding has enabled graduate student education and training on topics that go beyond conventional computing, covering cross-layer management of novel GPU architectures and behavior of scientific applications that run on top of them. The training from this project enabled students to better prepare as the next generation workforce in science and enginerring. The project also generated research publications in several top computer science and engineering conferences, including ISCA, PLDI, ASPLOS, SIGMETRICS, and DAC.          Last Modified: 12/10/2018       Submitted by: Mahmut T Kandemir]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
