<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: The Interaction of Pitch and Timing in the Perception of Prosodic Grouping</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2015</AwardEffectiveDate>
<AwardExpirationDate>04/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>7884.00</AwardTotalIntnAmount>
<AwardAmount>7884</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tyler Kendall</SignBlockName>
<PO_EMAI>tkendall@nsf.gov</PO_EMAI>
<PO_PHON>7032922434</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Speakers break the otherwise continuous stream of their speech into smaller, meaningful segments, the edges of which are marked by audible cues such as pauses, rate changes and pitch movement. Prosodic boundaries, as these segment edges and the cues that mark them, are known to play a role critical to language processing and spoken language acquisition. While great progress has been made documenting the range of cues that mark boundaries, much is not understood about the cognitive processes listeners use to make sense of these cues in interpreting the speech stream. The signaling of a boundary includes multiple cues from timing and pitch.  Current models of prosodic boundaries, such as are used in spoken language processing and text-to-speech (TTS) systems, rely heavily on timing cues. Pitch cues are typically considered to merely support timing cues, and are even considered redundant. However, growing evidence suggests that pitch and timing interact in perception, including speech and non-speech research demonstrating pitch-based distortions of perceived duration.&lt;br/&gt;&lt;br/&gt;This dissertation project seeks to enhance our knowledge of the psychological processes involved in boundary perception through empirical work on the perceptual interaction, integration and weighting of acoustic cues that have typically been measured independently. Quantifications of these interrelations will inform models of boundary detection in spoken language processing, and boundary generation in synthetic speech, by reflecting a richness of prosodic structure lacking in models using primarily objective duration measures. Synthetic speech has been shown to have a higher cognitive load (lower intelligibility, lower recall) than natural speech, and is especially challenging for populations such as non-native speakers, aging and/or hearing-impaired speakers, or those with language disorders. Redundant acoustic cues are known to increase speech comprehensibility in noisy conditions, and to potentially lighten the listeners' cognitive load. Increasing the strength of pitch-based cues that facilitate boundary processing may increase both the intelligibility and naturalness of synthetic speech and TTS-based assistive technologies.</AbstractNarration>
<MinAmdLetterDate>04/21/2015</MinAmdLetterDate>
<MaxAmdLetterDate>03/25/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1451663</AwardID>
<Investigator>
<FirstName>Jonathan</FirstName>
<LastName>Barnes</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonathan Barnes</PI_FULL_NAME>
<EmailAddress>jabarnes@bu.edu</EmailAddress>
<PI_PHON>6173534365</PI_PHON>
<NSF_ID>000111624</NSF_ID>
<StartDate>04/21/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alejna</FirstName>
<LastName>Brugos</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alejna M Brugos</PI_FULL_NAME>
<EmailAddress>alejna.brugos2@simmons.edu</EmailAddress>
<PI_PHON>5087892587</PI_PHON>
<NSF_ID>000674197</NSF_ID>
<StartDate>04/21/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName/>
<StateCode>MA</StateCode>
<ZipCode>022151300</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8374</Code>
<Text>DDRI Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~7884</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-e209b16b-7fff-b813-c331-b6b71b623cb2">&nbsp;</span></p> <p dir="ltr"><span>The broader goals of this dissertation project are: 1) to enhance our knowledge of the psychological processes involved in the processing of acoustic cues in the perception of prosodic boundaries, through empirical work on the perceptual interaction, integration and weighting of acoustic cues that have typically been measured independently, and 2) </span><span>to work towards the development of operational and quantitative measures of&nbsp; prosodic boundaries that incorporate pitch and timing cues together, and which take into account their interactions in perception.&nbsp;</span></p> <p dir="ltr"><span>The research design of this dissertation project was based on methods and insights from multiple disciplines, including music processing, non-speech auditory perception, as well as linguistics. </span><span>The core of the project was 3 pairs of perception experiments investigating pitch-time interaction, including putative distortion of perceived duration from dynamic pitch and cross-silence pitch jumps (i.e. the kappa effect). Each pair used the same set of stimuli, resynthesized with crossed continua of pitch and timing manipulations, in two different tasks: one psychoacoustic judgment of duration, and one of linguistic interpretation. Results suggest that perceptual interaction of major cues from timing (pre-boundary lengthening and pauses) and pitch (edge tones and reset) can be analyzed as reflecting gestalt-like grouping principles (proximity, similarity and continuity) that have been shown to play a role in perceptual grouping in other cognitive domains, including vision and non-speech auditory perception. In addition to these potentially more domain-general cognitive principles, a new role is introduced for learned and potentially language-specific pitch patterns in prosodic grouping, in particular intonational schemas, i.e. recognizable cross-phrase pitch patterns. Beyond this, results also support the hypothesis that perceived grouping is the driving force behind several types of pitch-based auditory illusions, including the auditory kappa effect. Follow-up investigations addressed how the contributions of pitch and timing cues to boundary contribute to the perception of both prosodic boundaries and disfluencies (where cues to well-formed prosodic structure are disrupted) in the annotation of naturally produced speech.</span></p> <p dir="ltr"><span>This research worked to address a gap in the literature by investigating the role played in speech perception of pitch manipulations that have been shown previously to modulate perceived duration in non-speech auditory research.</span><span> The major findings and novel contributions of this project can be summarized as follows:</span></p> <p dir="ltr"><span>1) Perceived prosodic grouping can lead to distortion of perceived duration in spoken utterances, such that silent intervals between groups are perceived as longer than comparable objective duration within groups. This result is compatible with several experiments from non-speech auditory experiments.</span></p> <p dir="ltr"><span>2) Pitch patterns (including those often described as &ldquo;reset&rdquo;) cue grouping in ways consistent with domain-general cognitive principles like those in the Gestalt tradition, such as pitch continuity and pitch proximity. Such principles have previously been evoked for timing cues to prosodic boundaries.</span></p> <p dir="ltr"><span>3) Higher-level learned patterns potentially also play a role in&#8232; grouping. Intonational schemas, a term used here to describe cross&#8209;phrase global pitch patterns (such as rise-fall or fall-rise patterns), have an effect that appears different from many commonly studied boundary effects. Intonational schemas were shown to both cue prosodic grouping, and trigger distortions of perceived duration between those perceived groups.</span></p> <p dir="ltr"><span>4) Attending to the cues relating to timing and f0 separately can facilitate prosodic annotation, and reveal patterns relating to perceived prosodic structure (namely boundary strength and disfluencies), as are operationalized via prosodic annotation in ToBI.&nbsp;</span></p> <p dir="ltr"><span>This research offers insights into why prosodic boundaries are expressed with the particular pitch and timing cues that are common cross-linguistically. While much language form is arbitrary, the expression of grouping by way of acoustic cues appears to be much less so. This research has potential to explain the perceptual foundations of boundary cues, and therefore the cross-linguistic similarities of prosodic grouping cues. </span><span>While this work uses English language materials, it investigates potentially more general cognitive grouping principles, and therefore the methodologies can be adapted to explore time-pitch interactions in the perception of duration and grouping of other language speakers. It is expected that, while the same underlying cognitive grouping principles will guide perception cross-linguistically, the specific tone and timing cues are likely to be phonologized differently in different languages.</span><span> Further, </span><span>findings from this research have strong potential to improve systems of speech synthesis and TTS-based assistive technologies. Increasing the strength of pitch-based cues to boundaries in a way that makes reference to potentially domain-general grouping principles (pitch proximity and pitch continuity), may increase both the intelligibility and naturalness of synthetic speech.</span><span><span> </span></span><span><span> </span></span></p> <p dir="ltr"><span>In addition to being included as part of the dissertation, results from this project have been disseminated through presentations at linguistics and speech science conferences: ETaP, LSA, ICPhS and Speech Prosody. The dissertation and other resulting publications are available online, along with stimuli used in perception experiments, such that others may attempt to replicate the results.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 09/01/2020<br>      Modified by: Alejna&nbsp;M&nbsp;Brugos</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The broader goals of this dissertation project are: 1) to enhance our knowledge of the psychological processes involved in the processing of acoustic cues in the perception of prosodic boundaries, through empirical work on the perceptual interaction, integration and weighting of acoustic cues that have typically been measured independently, and 2) to work towards the development of operational and quantitative measures of  prosodic boundaries that incorporate pitch and timing cues together, and which take into account their interactions in perception.  The research design of this dissertation project was based on methods and insights from multiple disciplines, including music processing, non-speech auditory perception, as well as linguistics. The core of the project was 3 pairs of perception experiments investigating pitch-time interaction, including putative distortion of perceived duration from dynamic pitch and cross-silence pitch jumps (i.e. the kappa effect). Each pair used the same set of stimuli, resynthesized with crossed continua of pitch and timing manipulations, in two different tasks: one psychoacoustic judgment of duration, and one of linguistic interpretation. Results suggest that perceptual interaction of major cues from timing (pre-boundary lengthening and pauses) and pitch (edge tones and reset) can be analyzed as reflecting gestalt-like grouping principles (proximity, similarity and continuity) that have been shown to play a role in perceptual grouping in other cognitive domains, including vision and non-speech auditory perception. In addition to these potentially more domain-general cognitive principles, a new role is introduced for learned and potentially language-specific pitch patterns in prosodic grouping, in particular intonational schemas, i.e. recognizable cross-phrase pitch patterns. Beyond this, results also support the hypothesis that perceived grouping is the driving force behind several types of pitch-based auditory illusions, including the auditory kappa effect. Follow-up investigations addressed how the contributions of pitch and timing cues to boundary contribute to the perception of both prosodic boundaries and disfluencies (where cues to well-formed prosodic structure are disrupted) in the annotation of naturally produced speech. This research worked to address a gap in the literature by investigating the role played in speech perception of pitch manipulations that have been shown previously to modulate perceived duration in non-speech auditory research. The major findings and novel contributions of this project can be summarized as follows: 1) Perceived prosodic grouping can lead to distortion of perceived duration in spoken utterances, such that silent intervals between groups are perceived as longer than comparable objective duration within groups. This result is compatible with several experiments from non-speech auditory experiments. 2) Pitch patterns (including those often described as "reset") cue grouping in ways consistent with domain-general cognitive principles like those in the Gestalt tradition, such as pitch continuity and pitch proximity. Such principles have previously been evoked for timing cues to prosodic boundaries. 3) Higher-level learned patterns potentially also play a role in&#8232; grouping. Intonational schemas, a term used here to describe cross&#8209;phrase global pitch patterns (such as rise-fall or fall-rise patterns), have an effect that appears different from many commonly studied boundary effects. Intonational schemas were shown to both cue prosodic grouping, and trigger distortions of perceived duration between those perceived groups. 4) Attending to the cues relating to timing and f0 separately can facilitate prosodic annotation, and reveal patterns relating to perceived prosodic structure (namely boundary strength and disfluencies), as are operationalized via prosodic annotation in ToBI.  This research offers insights into why prosodic boundaries are expressed with the particular pitch and timing cues that are common cross-linguistically. While much language form is arbitrary, the expression of grouping by way of acoustic cues appears to be much less so. This research has potential to explain the perceptual foundations of boundary cues, and therefore the cross-linguistic similarities of prosodic grouping cues. While this work uses English language materials, it investigates potentially more general cognitive grouping principles, and therefore the methodologies can be adapted to explore time-pitch interactions in the perception of duration and grouping of other language speakers. It is expected that, while the same underlying cognitive grouping principles will guide perception cross-linguistically, the specific tone and timing cues are likely to be phonologized differently in different languages. Further, findings from this research have strong potential to improve systems of speech synthesis and TTS-based assistive technologies. Increasing the strength of pitch-based cues to boundaries in a way that makes reference to potentially domain-general grouping principles (pitch proximity and pitch continuity), may increase both the intelligibility and naturalness of synthetic speech.   In addition to being included as part of the dissertation, results from this project have been disseminated through presentations at linguistics and speech science conferences: ETaP, LSA, ICPhS and Speech Prosody. The dissertation and other resulting publications are available online, along with stimuli used in perception experiments, such that others may attempt to replicate the results.          Last Modified: 09/01/2020       Submitted by: Alejna M Brugos]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
