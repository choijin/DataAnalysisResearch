<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Revealing the Invisible: Data-Intensive Research Using Cognitive, Psychological, and Physiological Measures to Optimize STEM Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>01/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>270363.00</AwardTotalIntnAmount>
<AwardAmount>270363</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregg Solomon</SignBlockName>
<PO_EMAI>gesolomo@nsf.gov</PO_EMAI>
<PO_PHON>7032928333</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Virtual learning environments are an increasingly important component of individualized learning in STEM domains. New technologies (including biometry and neuro-imaging) provide new opportunities to unobtrusively measure student engagement and learning. This project-developed in connection with an Ideas Lab on Data-Intensive Research to Improve Teaching and Learning that NSF convened in October 2014 -will utilize these technologies to provide foundational knowledge of the ways in which measures of implicit learning might be linked to explicit learning to develop educationally relevant games that are adaptive to diverse learners.  &lt;br/&gt;&lt;br/&gt;Investigators from TERC, Landmark College, and the Massachusetts Institute of Technology will collaborate to examine the relationships among: (1) patterns of play in a digital game ("Impulse"); (2) student attention (measured from eye- and head-tracking devices); and (3) student learning about Newton's first and second law. The researchers will collect measures of student engagement and learning outcomes embedded in the game. Subjects will comprise a neurodiverse group of students including regular undergraduates and those with Attention Deficit Hyperactivity Disorder and/or Autism Spectrum Disorder. The researchers will develop a model of visual attention and patterns of play, examining the extent to which eye movements are allocated strategically to objects of relevance to the current game state as a student learns in the game. They will then link the initial model with measures of student engagement and conceptual understanding of relevant physical science constructs to refine the model.  The refined model will be used to develop a modified game based on the players' attention, and a prototype of the modified game will be tested. The final phase of the research will be a within-subject design with the adaptive version versus the normal version of the game across learners with different profiles of disability.</AbstractNarration>
<MinAmdLetterDate>08/05/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1417456</AwardID>
<Investigator>
<FirstName>Ibrahim</FirstName>
<LastName>Dahlstrom-Hakki</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ibrahim H Dahlstrom-Hakki</PI_FULL_NAME>
<EmailAddress>idahlstromhakki@terc.edu</EmailAddress>
<PI_PHON>6178739837</PI_PHON>
<NSF_ID>000584157</NSF_ID>
<StartDate>08/05/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Landmark College</Name>
<CityName>Putney</CityName>
<ZipCode>053460820</ZipCode>
<PhoneNumber>8023876730</PhoneNumber>
<StreetAddress>19 River Road South</StreetAddress>
<StreetAddress2><![CDATA[River Road South]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Vermont</StateName>
<StateCode>VT</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VT00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>122784374</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LANDMARK COLLEGE, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Landmark College]]></Name>
<CityName/>
<StateCode>VT</StateCode>
<ZipCode>053460820</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Vermont</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VT00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>8244</Code>
<Text>EHR CL Opportunities (NSF 14-302)</Text>
</ProgramReference>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~270363</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The Revealing the Invisible (RtI) project is an effort that came out of NSF's first Ideas Lab and brought together a collaborative multi-disciplinary team from three distinct institutions with the aim of using data intensive methods to measure implicit learning. The measurement of implicit learning requires tools that can analyze learners' behaviors in natural settings rather than relying on the learners' articulation of their knowledge. RtI builds on prior work by augmenting game-based learning data with eye-tracking data to explore multi-modal models of implicit learning. Many learners, particularly neurodiverse learners, are unable to demonstrate their knowledge on traditional paper and pencil assessments due to language and attention related barriers. RtI has sought to address this challenge by exploring ways and developing tools that can be used to allow learners to demonstrate knowledge through their behaviors and neurophysical activity during a learning task.</p> <p>The team's prior research has shown that data mining methods can reliably detect behaviors consistent with implicit physics learning of high school students in the game <em>Impulse</em>, thus serving as a formative assessment of implicit learning. RtI delves deeper into the study of implicit learning by collecting eye-tracking data tightly synchronized with game data logs. FunAtomic, RtI's development partners, built a data architecture <em>DataArcade</em> that can integrate multimodal data streams within 10 ms accuracy (exceeding common industry standards) to enable the analysis of eye events during a fast action video game. During Impulse gameplay, the patterns of visual attention provide information about how well the player is attending to the salient phenomena. <em>DataArcade</em> was developed to be used with a range of different types of learning games and can collect and synchronize data from a wide array of sensors.</p> <p>The key outcome of RtI is <em>DataArcade'</em>s data collection, synchronization, and visualization tools. RtI has collected data using this platform and established a proof of concept for the use of multimodal analytics for the assessment of Implicit learning among diverse learners. <em>DataArcade</em> facilitates a range of data collection and analysis techniques from simple forms like the rough percentage of visual attention allocated across regions of interest in the visual field to tools for the analysis of relational data during game play that may indicate the strategies players are using to plan actions. This analysis can be used to provide insight into planning, working memory, and attentional processing that may be useful for identifying different learning and cognitive strategies.</p> <p>RtI has created the tools and established the proof of concept needed for the collection of a range of behavioral and neurocognitive data from learners, the synchronization and analysis of that data, and the development of detectors that can be used to measure implicit learning. The methods and tools developed by RtI can facilitate moving the field forward in terms of bringing objective measures of implicit knowledge to real world learning contexts. We anticipate continuing the efforts of this project and inviting other researchers to use the tools, technologies, and techniques developed by RtI.</p><br> <p>            Last Modified: 03/29/2019<br>      Modified by: Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833060001_replay1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833060001_replay1--rgov-800width.jpg" title="Example of DataArcade replay of Impulse game"><img src="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833060001_replay1--rgov-66x44.jpg" alt="Example of DataArcade replay of Impulse game"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Still image captured from a replay of Impulse in DataArcade with eye data visualization superimposed.</div> <div class="imageCredit">Revealing the Invisible Project</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</div> <div class="imageTitle">Example of DataArcade replay of Impulse game</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833281017_replay2--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833281017_replay2--rgov-800width.jpg" title="Example of DataArcade replay of Impulse game"><img src="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833281017_replay2--rgov-66x44.jpg" alt="Example of DataArcade replay of Impulse game"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Still image captured from a replay of Impulse in DataArcade with eye data visualization superimposed.</div> <div class="imageCredit">Revealing the Invisible Project</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</div> <div class="imageTitle">Example of DataArcade replay of Impulse game</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833430282_Viz1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833430282_Viz1--rgov-800width.jpg" title="Example of DataArcade visualization of game features and detectors"><img src="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833430282_Viz1--rgov-66x44.jpg" alt="Example of DataArcade visualization of game features and detectors"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Still image captured from visualization of data from Impulse in DataArcade synchronized with game replay.</div> <div class="imageCredit">Revealing the Invisible Project</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</div> <div class="imageTitle">Example of DataArcade visualization of game features and detectors</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833535527_replay4--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833535527_replay4--rgov-800width.jpg" title="Example of DataArcade replay of Impulse game"><img src="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833535527_replay4--rgov-66x44.jpg" alt="Example of DataArcade replay of Impulse game"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Still image captured from a replay of Impulse in DataArcade with eye data visualization superimposed.</div> <div class="imageCredit">Revealing the Invisible Project</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</div> <div class="imageTitle">Example of DataArcade replay of Impulse game</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833611279_replay5--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833611279_replay5--rgov-800width.jpg" title="Example of DataArcade replay of Impulse game"><img src="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833611279_replay5--rgov-66x44.jpg" alt="Example of DataArcade replay of Impulse game"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Still image captured from a replay of Impulse in DataArcade with eye data visualization superimposed.</div> <div class="imageCredit">Revealing the Invisible Project</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</div> <div class="imageTitle">Example of DataArcade replay of Impulse game</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833745135_Viz2--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833745135_Viz2--rgov-800width.jpg" title="Example of DataArcade visualization of game features and detectors"><img src="/por/images/Reports/POR/2019/1417456/1417456_10328426_1553833745135_Viz2--rgov-66x44.jpg" alt="Example of DataArcade visualization of game features and detectors"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Still image captured from visualization of data from Impulse in DataArcade synchronized with game replay.</div> <div class="imageCredit">Revealing the Invisible Project</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ibrahim&nbsp;H&nbsp;Dahlstrom-Hakki</div> <div class="imageTitle">Example of DataArcade visualization of game features and detectors</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Revealing the Invisible (RtI) project is an effort that came out of NSF's first Ideas Lab and brought together a collaborative multi-disciplinary team from three distinct institutions with the aim of using data intensive methods to measure implicit learning. The measurement of implicit learning requires tools that can analyze learners' behaviors in natural settings rather than relying on the learners' articulation of their knowledge. RtI builds on prior work by augmenting game-based learning data with eye-tracking data to explore multi-modal models of implicit learning. Many learners, particularly neurodiverse learners, are unable to demonstrate their knowledge on traditional paper and pencil assessments due to language and attention related barriers. RtI has sought to address this challenge by exploring ways and developing tools that can be used to allow learners to demonstrate knowledge through their behaviors and neurophysical activity during a learning task.  The team's prior research has shown that data mining methods can reliably detect behaviors consistent with implicit physics learning of high school students in the game Impulse, thus serving as a formative assessment of implicit learning. RtI delves deeper into the study of implicit learning by collecting eye-tracking data tightly synchronized with game data logs. FunAtomic, RtI's development partners, built a data architecture DataArcade that can integrate multimodal data streams within 10 ms accuracy (exceeding common industry standards) to enable the analysis of eye events during a fast action video game. During Impulse gameplay, the patterns of visual attention provide information about how well the player is attending to the salient phenomena. DataArcade was developed to be used with a range of different types of learning games and can collect and synchronize data from a wide array of sensors.  The key outcome of RtI is DataArcade's data collection, synchronization, and visualization tools. RtI has collected data using this platform and established a proof of concept for the use of multimodal analytics for the assessment of Implicit learning among diverse learners. DataArcade facilitates a range of data collection and analysis techniques from simple forms like the rough percentage of visual attention allocated across regions of interest in the visual field to tools for the analysis of relational data during game play that may indicate the strategies players are using to plan actions. This analysis can be used to provide insight into planning, working memory, and attentional processing that may be useful for identifying different learning and cognitive strategies.  RtI has created the tools and established the proof of concept needed for the collection of a range of behavioral and neurocognitive data from learners, the synchronization and analysis of that data, and the development of detectors that can be used to measure implicit learning. The methods and tools developed by RtI can facilitate moving the field forward in terms of bringing objective measures of implicit knowledge to real world learning contexts. We anticipate continuing the efforts of this project and inviting other researchers to use the tools, technologies, and techniques developed by RtI.       Last Modified: 03/29/2019       Submitted by: Ibrahim H Dahlstrom-Hakki]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
