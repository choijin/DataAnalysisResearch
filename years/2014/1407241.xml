<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Graph-based Learning and Inference for Sparse Regularized Techniques</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>120000.00</AwardTotalIntnAmount>
<AwardAmount>120000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Machine learning is a very active area of interdisciplinary research, closely related to statistics, optimization, and computer science. The goal of this project is to develop several cutting-edge machine learning techniques for solving high dimensional problems. The team plans to develop new techniques for estimating complex graphs and to establish inference procedures for sparse regression methods, using some recently developed tools in optimization. Techniques to be developed in this project have a wide range of applications in many disciplines. Such applications help to promote interdisciplinary research among statistics, operations research, and bioinformatics. Several students will be involved in the research activities.&lt;br/&gt;&lt;br/&gt;Many machine learning techniques fit in the regularization framework. This project will develop several new regularized methods. In particular, the team will use sparse regularized tools for complex graphical model estimation. Furthermore, the team will build a new inference tool for sparse regularized regression methods such as the LASSO, by reformulating the LASSO problem as a stochastic variational inequality in optimization. State-of-the-art techniques in optimization will be introduced to the statistical community.  The researchers are committed to establishing both theoretical properties and efficient computational tools for the designed methods. Applications in various disciplines will help to generate new knowledge and inspirations from those disciplines.</AbstractNarration>
<MinAmdLetterDate>08/07/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1407241</AwardID>
<Investigator>
<FirstName>Yufeng</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yufeng Liu</PI_FULL_NAME>
<EmailAddress>yfliu@email.unc.edu</EmailAddress>
<PI_PHON>9198431899</PI_PHON>
<NSF_ID>000274908</NSF_ID>
<StartDate>08/07/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Shu</FirstName>
<LastName>Lu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shu Lu</PI_FULL_NAME>
<EmailAddress>shulu@email.unc.edu</EmailAddress>
<PI_PHON>9199621048</PI_PHON>
<NSF_ID>000080619</NSF_ID>
<StartDate>08/07/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Chapel Hill]]></Name>
<CityName>Chapel Hill</CityName>
<StateCode>NC</StateCode>
<ZipCode>275993260</ZipCode>
<StreetAddress><![CDATA[354 Hanes Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~20000</FUND_OBLG>
<FUND_OBLG>2015~49436</FUND_OBLG>
<FUND_OBLG>2016~50564</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major goals of the project, &ldquo;Graph-based Learning and Inference for Sparse Regularized Techniques&rdquo;, was to develop new methodology on graph-based methods and theory and inference tools for sparse methods, to disseminate the new research findings, and to educate students with the cutting-edge techniques in machine learning.</p> <p>&nbsp;</p> <p>Intellectual Merit:</p> <p>&nbsp;</p> <p>During the entire project period, the PI and co-PI made important contributions in development of methods and theory for the field of statistical learning. In particular, the research team developed new techniques for graph-based regression, classification, clustering, and inference tools for sparse methods using optimization techniques. Many of these new developments have been reported in publications as well as disseminated in research conferences. This project leaded to over 15 publications in major statistics, machine learning and optimization journals. These methods will be widely used in the community.</p> <p>&nbsp;</p> <p>Broader impacts:</p> <p>&nbsp;</p> <p>The developed methods and theory through this project made important contributions to the field of statistics, machine learning, optimization, and beyond. Through collaboration with domain scientists such as genetics, and neuroimaging, the methods have been introduced and applied to other fields. In terms of education, the new research developments of the project were incorporated into the undergraduate and graduate course on statistical machine learning and optimization at University of North Carolina at Chapel Hill. Furthermore, the project has directly benefited Ph.D student research training. Two graduated Ph.D students mentored by the PI and co-PI were involved in the research developments of this project.</p> <p>&nbsp;</p> <p>In summary, the original proposed goals of this project have been achieved, and the project resulted in fruitful outcomes both in terms of intellectual merit and broader impacts. The project leaded to productive research development and effective training and education.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/01/2018<br>      Modified by: Yufeng&nbsp;Liu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goals of the project, "Graph-based Learning and Inference for Sparse Regularized Techniques", was to develop new methodology on graph-based methods and theory and inference tools for sparse methods, to disseminate the new research findings, and to educate students with the cutting-edge techniques in machine learning.     Intellectual Merit:     During the entire project period, the PI and co-PI made important contributions in development of methods and theory for the field of statistical learning. In particular, the research team developed new techniques for graph-based regression, classification, clustering, and inference tools for sparse methods using optimization techniques. Many of these new developments have been reported in publications as well as disseminated in research conferences. This project leaded to over 15 publications in major statistics, machine learning and optimization journals. These methods will be widely used in the community.     Broader impacts:     The developed methods and theory through this project made important contributions to the field of statistics, machine learning, optimization, and beyond. Through collaboration with domain scientists such as genetics, and neuroimaging, the methods have been introduced and applied to other fields. In terms of education, the new research developments of the project were incorporated into the undergraduate and graduate course on statistical machine learning and optimization at University of North Carolina at Chapel Hill. Furthermore, the project has directly benefited Ph.D student research training. Two graduated Ph.D students mentored by the PI and co-PI were involved in the research developments of this project.     In summary, the original proposed goals of this project have been achieved, and the project resulted in fruitful outcomes both in terms of intellectual merit and broader impacts. The project leaded to productive research development and effective training and education.           Last Modified: 08/01/2018       Submitted by: Yufeng Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
