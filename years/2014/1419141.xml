<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Chameleon: A Large-Scale, Reconfigurable Experimental Environment for Cloud Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>12/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>2486536.00</AwardTotalIntnAmount>
<AwardAmount>2658399</AwardAmount>
<AwardInstrument>
<Value>Cooperative Agreement</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Deepankar Medhi</SignBlockName>
<PO_EMAI>dmedhi@nsf.gov</PO_EMAI>
<PO_PHON>7032922935</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A persistent problem facing academic cloud research is the lack of infrastructure and data to perform experimental research: large-scale hardware is needed to investigate the scalability of cloud infrastructure and applications, heterogeneous hardware is needed to investigate algorithmic and implementation tradeoffs, fully-configurable software environments are needed to investigate the performance of virtualization techniques and the differences between cloud software stacks, and data about how clouds are used is needed to evaluate virtual machine scheduling and data placement algorithms. &lt;br/&gt;&lt;br/&gt;The Chameleon project will addresses these needs by providing a large-scale, fully configurable experimental testbed driven by the needs of the cloud research and education communities. The testbed, and the ecosystem associated with it, will enable researchers to explore a range of cloud research challenges, from large scale to small scale, including exploring low-level problems in hardware architecture, systems research, network configuration, and software design, or at higher levels of abstraction looking at cloud scheduling, cloud platforms, and cloud applications. &lt;br/&gt;&lt;br/&gt;Chameleon will significantly enhance the ability of the computing research community to understand the behavior of Internet scale cloud systems, and to develop new software, ideas and algorithms for the cloud environment. As the tremendous shift to cloud as the primary means of providing computing infrastructure continues, a large-scale testbed tailored to researchers' needs is essential to the continued relevance of a large fraction of computing research. &lt;br/&gt;&lt;br/&gt;The project is led by the University of Chicago and includes partners from the Texas Advanced Computing Center (TACC), Northwestern University, the Ohio State University, and the University of Texas at San Antonio, comprising a highly qualified and experienced team, with research leaders from the cloud and networking world blended with providers of production quality cyberinfrastructure.  The team includes members from the NSF-supported FutureGrid project and from the GENI community, both forerunners of the NSFCloud solicitation under which this project is funded. &lt;br/&gt;&lt;br/&gt;The Chameleon testbed, will be deployed at the University of Chicago (UC) and the Texas Advanced Computing Center (TACC) and will consist of 650 multi-core cloud nodes, 5PB of total disk space, and leverage 100 Gbps connection between the sites. While a large part of the testbed will consist of homogenous hardware to support large-scale experiments, a portion of it will support heterogeneous units allowing experimentation with high-memory, large-disk, low-power, GPU, and co-processor units. The project will also leverage existing FutureGrid hardware at UC and TACC in its first year to provide a transition period for the existing FutureGrid community of experimental users. &lt;br/&gt;&lt;br/&gt;To support a broad range of experiments emphasizing a range of requirements ranging from a high degree of control to ease of use the project will support a graduated configuration system allowing full user configurability of the stack, from provisioning of bare metal and network interconnects to delivery of fully functioning cloud environments. In addition, to facilitate experiments, Chameleon will support a set of services designed to meet researchers needs, including support for experimental management, reproducibility, and repositories of trace and workload data of production cloud workloads. &lt;br/&gt;&lt;br/&gt;To facilitate the latter, the project will form a set of partnerships with commercial as well as academic clouds, such as Rackspace and Open Science Data Cloud (OSDC). It will also partner with other testbeds, notably GENI and INRIA's Grid5000 testbed, and reach out to the user community to shape the policy an direction of the testbed. &lt;br/&gt;&lt;br/&gt;The Chameleon project will bring a new dimension and scale of resources to the CS community who wish to educate their students about design, implementation, operation and applications of cloud computing, a critical skillset for future computing professionals. It will enhance the understanding and application of experimental methodology in computer science and generate new educational materials and resources, with the participation of, and for, Minority Serving Institution (MSI) students.</AbstractNarration>
<MinAmdLetterDate>08/19/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/08/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>CoopAgrmnt</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1419141</AwardID>
<Investigator>
<FirstName>Katarzyna</FirstName>
<LastName>Keahey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katarzyna Keahey</PI_FULL_NAME>
<EmailAddress>keahey@mcs.anl.gov</EmailAddress>
<PI_PHON>6302521673</PI_PHON>
<NSF_ID>000286883</NSF_ID>
<StartDate>08/19/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606371433</ZipCode>
<StreetAddress><![CDATA[5801 South Ellis]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>2890</Code>
<Text>CISE Research Resources</Text>
</ProgramElement>
<ProgramReference>
<Code>7363</Code>
<Text>RES IN NETWORKING TECH &amp; SYS</Text>
</ProgramReference>
<ProgramReference>
<Code>8002</Code>
<Text>CISE Research Resources</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~1303503</FUND_OBLG>
<FUND_OBLG>2015~1183033</FUND_OBLG>
<FUND_OBLG>2017~171863</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-ad57bb0d-7fff-0fe2-7741-5f305c6188e4">&nbsp;</span></p> <p dir="ltr"><span>The Chameleon project designed and deployed a scientific instrument: a large-scale, deeply reconfigurable testbed for research into cloud computing.&nbsp; The shift of computing to the cloud is one of the more fundamental transformations of information technology in recent years, and affects not only research in computing, but a wide array of business functions for enterprises at all scale, the way consumers interact with technology, and is having profound implications on the economy and everyday life.&nbsp;&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Chameleon differs substantially from other NSF computing resources in that it is directly focused on research in computer science.&nbsp; While other scientific computing resources provide tremendous computing power for engineering and science research, as production systems, the computers themselves and their system software components can not be changed by the end user.&nbsp; Chameleon, in contrast, provided tremendous flexibility to computing researchers to deploy alternate software stacks; users could start with "bare metal" allocations (computers on which they deploy the operating software of their choice), or select from a library of pre-configured images. In addition to flexibility in software, Chameleon also offered users a range of different hardware types, including a variety of processors, accelerators, network equipment, and storage devices. The infrastructure is physically distributed across multiple sites (in Chicago, Illinois and Austin, Texas) to allow researchers to replicate the multi-datacenter conditions that exist in most production cloud environments.</span></p> <p dir="ltr"><span>&nbsp;</span></p> <p dir="ltr"><span>In addition to the hardware itself, the Chameleon project created the software, training, and user support to complete the testbed ecosystem. Unlike traditional Computer Science experimental systems which have overwhelmingly been configured by technologies developed in-house, Chameleon adapted OpenStack, a mainstream open source cloud technology, to provide its capabilities. This has a range of practical benefits including familiar interfaces for users and operators, workforce development potential, leverage of contributions from a large development community, and leverage of the ecosystem of mainstream tools providing portability across different clouds. At the same time, to fully support the research and sharing functions required of a scientific instrument, Chameleon significantly extended the capabilities of OpenStack, making substantial open source contributions to the OpenStack project, and creating other open source software in the process.&nbsp;</span></p> <p dir="ltr"><span>&nbsp;&nbsp;</span></p> <p dir="ltr"><span>Over its lifetime, Chameleon supported over 5,000 users working on nearly 700 research and education projects, which ultimately resulted in close to 400 research publications. Research was performed in cybersecurity, scalable operating systems, power management, cloud application performance, machine learning, and many other critical areas of computing research.&nbsp; The Chameleon infrastructure lives on and continues to support the community through renewal grants.</span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/18/2021<br>      Modified by: Katarzyna&nbsp;Keahey</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The Chameleon project designed and deployed a scientific instrument: a large-scale, deeply reconfigurable testbed for research into cloud computing.  The shift of computing to the cloud is one of the more fundamental transformations of information technology in recent years, and affects not only research in computing, but a wide array of business functions for enterprises at all scale, the way consumers interact with technology, and is having profound implications on the economy and everyday life.      Chameleon differs substantially from other NSF computing resources in that it is directly focused on research in computer science.  While other scientific computing resources provide tremendous computing power for engineering and science research, as production systems, the computers themselves and their system software components can not be changed by the end user.  Chameleon, in contrast, provided tremendous flexibility to computing researchers to deploy alternate software stacks; users could start with "bare metal" allocations (computers on which they deploy the operating software of their choice), or select from a library of pre-configured images. In addition to flexibility in software, Chameleon also offered users a range of different hardware types, including a variety of processors, accelerators, network equipment, and storage devices. The infrastructure is physically distributed across multiple sites (in Chicago, Illinois and Austin, Texas) to allow researchers to replicate the multi-datacenter conditions that exist in most production cloud environments.   In addition to the hardware itself, the Chameleon project created the software, training, and user support to complete the testbed ecosystem. Unlike traditional Computer Science experimental systems which have overwhelmingly been configured by technologies developed in-house, Chameleon adapted OpenStack, a mainstream open source cloud technology, to provide its capabilities. This has a range of practical benefits including familiar interfaces for users and operators, workforce development potential, leverage of contributions from a large development community, and leverage of the ecosystem of mainstream tools providing portability across different clouds. At the same time, to fully support the research and sharing functions required of a scientific instrument, Chameleon significantly extended the capabilities of OpenStack, making substantial open source contributions to the OpenStack project, and creating other open source software in the process.     Over its lifetime, Chameleon supported over 5,000 users working on nearly 700 research and education projects, which ultimately resulted in close to 400 research publications. Research was performed in cybersecurity, scalable operating systems, power management, cloud application performance, machine learning, and many other critical areas of computing research.  The Chameleon infrastructure lives on and continues to support the community through renewal grants.             Last Modified: 05/18/2021       Submitted by: Katarzyna Keahey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
