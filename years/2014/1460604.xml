<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>How prefrontal cortex augments reinforcement learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/15/2015</AwardEffectiveDate>
<AwardExpirationDate>01/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>592520.00</AwardTotalIntnAmount>
<AwardAmount>592520</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kurt Thoroughman</SignBlockName>
<PO_EMAI>kthoroug@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research project investigates the nature of interactions between different brain regions involved in how people learn and control their actions. Theoretical models and empirical data suggest that the prefrontal cortex (PFC) and basal ganglia (BG) interact in these types of motivated behavior, and that the neurochemical dopamine plays a central role in both of these brain regions. However, it has been difficult to isolate the separable contributions of these different brain systems to learning. Dr. Frank and colleagues will investigate how PFC augments human reinforcement learning by leveraging its well-studied roles in working memory, cognitive control, abstraction, and rule representation. This work has potential to substantially advance our understanding of how humans are able to regulate their behaviors as a function of motivation and cognitive control.  Learning impairments are prevalent in many psychiatric disorders. While in some cases, such as Parkinson's disease, the mechanisms involved are relatively well understood, in others, such as schizophrenia, the underlying deficits are poorly characterized. It is crucial to properly isolate different components contributing to learning, so as to appropriately relate them to separable mechanisms giving rise to those deficits.  If learning is considered as a unitary system, learning deficits that arise due to impairments in one process and brain system may be mistakenly attributed to the other system and lead to erroneous conclusions. Following the same approach will shed light on the actual cause of learning impairments.  As such, this research has the potential to identify mechanisms that explain how disruption of such brain circuitry leads to disorders in motivated behavior, cognitive control, and impulsivity. Similarly, developmental learning disabilities may involve a deficit in abstraction and generalization. The aim is to better understand the underlying mechanisms and computations needed for such functions. Drs. Frank and Collins will also provide mentoring on computational and data analytic methods for under-represented women in the STEM disciplines. &lt;br/&gt;&lt;br/&gt;Computerized experimental tasks will manipulate factors thought to depend on PFC function, including working memory load and the degree to which the discovery of coherent rules can be used to speed learning. Dr. Frank and colleagues use mathematical modeling to separately estimate the contributions of PFC function from that of basic BG processes. Using electroencephalography (EEG), the investigators will measure human participants' brain waves associated with PFC activity while they perform these tasks. Brain wave activity is expected to predict cognitive performance on these tasks. Critically, this brain-behavior relationship is expected to differ as a function of genetic variants that reflect differences in dopamine function in PFC and BG. Another study will directly manipulate dopamine (pharmacologically) in order to determine how these brain and behavior relationships are causally altered by dopamine levels. In all of these studies the investigators use detailed mathematical models to isolate specific brain-behavior relationships guided by contemporary theory. It is expected that genetic variants and pharmacological manipulations will affect the way that the brain learns from decision outcomes and controls actions.</AbstractNarration>
<MinAmdLetterDate>02/05/2015</MinAmdLetterDate>
<MaxAmdLetterDate>02/05/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1460604</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Frank</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael J Frank</PI_FULL_NAME>
<EmailAddress>michael_frank@brown.edu</EmailAddress>
<PI_PHON>4018636872</PI_PHON>
<NSF_ID>000176925</NSF_ID>
<StartDate>02/05/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Anne</FirstName>
<LastName>Collins</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anne G Collins</PI_FULL_NAME>
<EmailAddress>annecollins@berkeley.edu</EmailAddress>
<PI_PHON>5106647146</PI_PHON>
<NSF_ID>000677515</NSF_ID>
<StartDate>02/05/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129093</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Projects]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~592520</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-fef34a0c-7fff-3410-5fb8-f9ddcf1789bb"> <p dir="ltr"><span>Collins, Ciullo, Frank, and Badre (Journal of Neuroscience, 2017) used neuroimaging and computational modeling to investigate how working memory (WM) load may affect the reinforcement learning (RL) process. Analysis of fMRI data revealed neural activation in the striatum and lateral prefrontal cortex specifically sensitive to reward prediction errors when the learning problem was within WM capacity. The extent of which WM and RL interacted in this way related to how much WM was used to guide behavioral learning, indicating that these two learning systems ultimately interact during learning as opposed to processing information independently.</span></p> <br /> <p dir="ltr"><span>Along a similar vein of Collins et al., 2017, Collins (Journal of Cognitive Neuroscience, 2017) studied the interactions between RL (a slow but steady process) and WM (a fast, flexible but capacity-limited process) in human learning. Collins, using computational modeling, showed that WM interferes with RL in a behavioral task. Specifically, the use of WM to learn quickly resulted in a cost in long-term retention, and computational modeling revealed that this cost was due to WM interfering with the RL process. These results further our understanding of how multiple systems work in parallel in the context of human learning, and may provide valuable insights into applications for education and computational psychiatry. </span><span><br /><br /></span></p> <p dir="ltr"><span>Collins, Albrecht, Waltz, Gold, and Frank (Biological Psychiatry, 2017) further investigated the separable contributions of WM and RL processes in human learning but within a comparison between healthy controls and schizophrenia patients. Behavioral results confirmed that WM and RL compete for choice during learning and as they perform their computations in parallel. Further, findings showed enhanced RL under high WM load. Collins et al., 2017 used computational modeling to additionally show that although WM processing during learning is impaired in schizophrenia patients, RL value learning is intact. This work hoped to uncover the underlying neural mechanisms of human learning as well as learning impairments in different clinical populations.</span></p> <p dir="ltr"><span>Nassar, Helmers, and Frank (Psychological Review, 2018) focused on WM in terms of how humans optimize performance on visual WM tasks, combining two parallel lines of research: 1) how encoding and decoding of working memories are optimized under statistical contingencies and 2) capacity limitations in visual WM. Nassar et al. proposed that people jointly encode similar visual features through a &ldquo;chunking&rdquo; process to help facilitate performance improvements. In manipulating working memory load in terms of both discrete and continuous aspects, findings showed that a tradeoff exists between better working memory storage and memory precision through the use of chunking strategies. </span></p> <br /> <p dir="ltr"><span>Franklin and Frank (2018) created computational models to capture how human learning and knowledge in one context generalizes to other context. Previous computational models and data showed that humans build latent structures from contexts and then learn to link these structures to facilitate the transfer of knowledge from context to the next. However, this previous research built models that reused policies (i.e the mapping of actions one should taken within a given environment) as a whole, and thus were unable to capture when only some task structure aspects are shared between contexts and separately from other aspects. Franklin and Frank built a novel non-parametric Bayesian agent that is able to separate two aspects of a task structure by forming independent latent clusters. This work further compared this Bayesian agent with an agent that generalizes policies as a whole, and showed that the better agent for a given task depends on how closely related task structures are. When task structures are closely related, an agent which generalizes policies as a whole is more successful, and when task structures are weakly related, the novel type of agent Franklin and Frank propose shows greater success. Franklin and Frank ultimately propose to use a &ldquo;meta-learning&rdquo; model to then capture both of these types of behaviors, to then dynamically arbitrate between these two forms of structure learning to better capture human learning. </span></p> <br /> <p dir="ltr"><span>To mirror the investigation into the parallel use of multiple learning algorithms in artificial learning, Collins and Frank (PNAS, 2018) built on prior work (Collins et al., 2017), and further examined the interactions of RL and WM in human learning. Leveraging computational modeling and human electroencephalography (EEG), Collins and Frank went beyond behavioral data affordances, and were able to extract time-specific trials of RL and WM contributions. Findings suggest that WM contributes expectations to inform RL, and neural dynamics correlated with WM and RL processing systems confirmed this. In other words, humans store their expectations in their working memory, and this information is then used by RL to properly compute the difference between an outcome of an experience and the expectation of it. This difference is then used to update internal value functions to assign more or less value to a stimulus. This work deepened understanding of how human learning utilizes these two learning systems (RL and WM) in parallel.</span></p> </span></p><br> <p>            Last Modified: 05/01/2019<br>      Modified by: Michael&nbsp;J&nbsp;Frank</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Collins, Ciullo, Frank, and Badre (Journal of Neuroscience, 2017) used neuroimaging and computational modeling to investigate how working memory (WM) load may affect the reinforcement learning (RL) process. Analysis of fMRI data revealed neural activation in the striatum and lateral prefrontal cortex specifically sensitive to reward prediction errors when the learning problem was within WM capacity. The extent of which WM and RL interacted in this way related to how much WM was used to guide behavioral learning, indicating that these two learning systems ultimately interact during learning as opposed to processing information independently.   Along a similar vein of Collins et al., 2017, Collins (Journal of Cognitive Neuroscience, 2017) studied the interactions between RL (a slow but steady process) and WM (a fast, flexible but capacity-limited process) in human learning. Collins, using computational modeling, showed that WM interferes with RL in a behavioral task. Specifically, the use of WM to learn quickly resulted in a cost in long-term retention, and computational modeling revealed that this cost was due to WM interfering with the RL process. These results further our understanding of how multiple systems work in parallel in the context of human learning, and may provide valuable insights into applications for education and computational psychiatry.    Collins, Albrecht, Waltz, Gold, and Frank (Biological Psychiatry, 2017) further investigated the separable contributions of WM and RL processes in human learning but within a comparison between healthy controls and schizophrenia patients. Behavioral results confirmed that WM and RL compete for choice during learning and as they perform their computations in parallel. Further, findings showed enhanced RL under high WM load. Collins et al., 2017 used computational modeling to additionally show that although WM processing during learning is impaired in schizophrenia patients, RL value learning is intact. This work hoped to uncover the underlying neural mechanisms of human learning as well as learning impairments in different clinical populations. Nassar, Helmers, and Frank (Psychological Review, 2018) focused on WM in terms of how humans optimize performance on visual WM tasks, combining two parallel lines of research: 1) how encoding and decoding of working memories are optimized under statistical contingencies and 2) capacity limitations in visual WM. Nassar et al. proposed that people jointly encode similar visual features through a "chunking" process to help facilitate performance improvements. In manipulating working memory load in terms of both discrete and continuous aspects, findings showed that a tradeoff exists between better working memory storage and memory precision through the use of chunking strategies.    Franklin and Frank (2018) created computational models to capture how human learning and knowledge in one context generalizes to other context. Previous computational models and data showed that humans build latent structures from contexts and then learn to link these structures to facilitate the transfer of knowledge from context to the next. However, this previous research built models that reused policies (i.e the mapping of actions one should taken within a given environment) as a whole, and thus were unable to capture when only some task structure aspects are shared between contexts and separately from other aspects. Franklin and Frank built a novel non-parametric Bayesian agent that is able to separate two aspects of a task structure by forming independent latent clusters. This work further compared this Bayesian agent with an agent that generalizes policies as a whole, and showed that the better agent for a given task depends on how closely related task structures are. When task structures are closely related, an agent which generalizes policies as a whole is more successful, and when task structures are weakly related, the novel type of agent Franklin and Frank propose shows greater success. Franklin and Frank ultimately propose to use a "meta-learning" model to then capture both of these types of behaviors, to then dynamically arbitrate between these two forms of structure learning to better capture human learning.    To mirror the investigation into the parallel use of multiple learning algorithms in artificial learning, Collins and Frank (PNAS, 2018) built on prior work (Collins et al., 2017), and further examined the interactions of RL and WM in human learning. Leveraging computational modeling and human electroencephalography (EEG), Collins and Frank went beyond behavioral data affordances, and were able to extract time-specific trials of RL and WM contributions. Findings suggest that WM contributes expectations to inform RL, and neural dynamics correlated with WM and RL processing systems confirmed this. In other words, humans store their expectations in their working memory, and this information is then used by RL to properly compute the difference between an outcome of an experience and the expectation of it. This difference is then used to update internal value functions to assign more or less value to a stimulus. This work deepened understanding of how human learning utilizes these two learning systems (RL and WM) in parallel.        Last Modified: 05/01/2019       Submitted by: Michael J Frank]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
