<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Distributed Solution Algorithms for Large-Scale Multi-Stage Stochastic Programs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>141862.00</AwardTotalIntnAmount>
<AwardAmount>141862</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Georgia-Ann Klutke</SignBlockName>
<PO_EMAI>gaklutke@nsf.gov</PO_EMAI>
<PO_PHON>7032922443</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many important decision problems in areas such as energy, finance, manufacturing, telecommunication, transportation, logistics, and health care are difficult to solve because they are characterized by uncertain outcomes when decisions are made, and furthermore the decisions and subsequent outcomes occur repeatedly, in multiple stages over time. Solving such complex problems easily exceeds the state-of-the-art capabilities of current desktop computers.  To overcome this issue, typical methods discard or aggregate problem data, thereby losing information that may be critical.  This award supports fundamental research to develop, evaluate, and implement a comprehensive methodology for optimizing such large-scale multi-stage problems under uncertainty by using a distributed computing environment. The need for this research is evident from the lack of generally applicable efficient solution methods for such problems.  The results of this project will be directly applicable to sequential decision-making problems under uncertainty that are widely encountered in public and private sectors, therefore benefiting the U.S. economy and society. This research will positively impact engineering education by promoting the participation of underrepresented groups in research.&lt;br/&gt; &lt;br/&gt;This research consists of theoretical and methodological advancements for solving large-scale multi-stage stochastic programs. Specifically, it involves designing bounding schemes and exact solution algorithms to solve such problems in a distributed fashion. There is a lack of efficient solutions methods, particularly when mixed-integer decision variables are involved. Existing methods typically make restrictive assumptions such as convexity.  This methodology is broadly applicable, as it does not assume any special problem structure. Moreover, an inherent feature of this approach is its natural fit into a distributed computing environment, which makes it amenable to solving truly large-scale instances. In addition to developing methods, the research team will implement and evaluate their performance using large-scale instances on a state-of-the-art high-performance computing cluster.</AbstractNarration>
<MinAmdLetterDate>06/24/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1436177</AwardID>
<Investigator>
<FirstName>Osman</FirstName>
<LastName>Ozaltin</LastName>
<PI_MID_INIT>Y</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Osman Y Ozaltin</PI_FULL_NAME>
<EmailAddress>oyozalti@ncsu.edu</EmailAddress>
<PI_PHON>9195156399</PI_PHON>
<NSF_ID>000651106</NSF_ID>
<StartDate>06/24/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>RALEIGH</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957906</ZipCode>
<StreetAddress><![CDATA[400 Daniels Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5514</Code>
<Text>OPERATIONS RESEARCH</Text>
</ProgramElement>
<ProgramReference>
<Code>072E</Code>
<Text>NETWORKS &amp; QUEUING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>073E</Code>
<Text>OPTIMIZATION &amp; DECISION MAKING</Text>
</ProgramReference>
<ProgramReference>
<Code>077E</Code>
<Text>SIMULATION MODELS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~141862</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Many sequential decision-making problems involving uncertainty can be appropriately modeled as multistage stochastic programs. Examples include problems in energy, finance, manufacturing, telecommunication, transportation and logistics, and health care. Despite their appeal as a flexible modeling framework, stochastic programming models typically suffer unbearable growth in their size as the number of decision stages increase. The size of many models can easily exceed the available memory on a state-of-art desktop computer. To overcome this barrier, typical applications content with truncating or merging the problem data, and therefore, losing information that is otherwise available. Even then, modern algorithms employed in solving such problems can hit the memory barrier during the solution process, or solution times can be excessive. Therefore, practical applications have generally been restricted to two-stage linear models with limited modeling of parameter uncertainty. Two-stage models, however, lack an ability to dynamically respond to information that gradually becomes available to the decision maker. Furthermore, the linearity assumption hampers the applicability for a broad set of questions, as most applications involve discrete/integer/binary decision variables.<br /><br />In this project, we have developed, analyzed, implemented, and tested a comprehensive methodology for solving large-scale multi-stage stochastic programs. Since the developed methodology does not make restrictive assumptions (such as convexity), it is much broadly applicable than most approaches in the literature. Furthermore, our methodology is designed around distributed computing, and it achieves very high computing efficiency due to minimum communication overhead between the parallel running computing processors. This aspect makes our approach amenable to solving truly large-scale instances. We have designed and implemented robust and efficient distributed computer codes of our methodology using resources available at the University of Chicago Research Computing Center, which maintains a state-of-theart high-performance computing grid. We have also tested the performance of this method using an extensive set of test instances that have been carefully selected to demonstrate scalability, reliability, and efficiency required for large-scale practical applications. The sizes of some of the instances solved are several orders of magnitude larger than what has been previously reported in the literature for multi-stage stochastic mixed-integer programs. The success of the method on such large-scale tests demonstrate its immense potential to obtain high-quality solutions to practical instances within a reasonable time frame.<br /><br />The methods developed in this project alleviate the challenges associated with multi-stage stochastic programs, and therefore encourages the research community to further study and utilize multi-stage stochastic programming models. The results of this project are directly applicable to large-scale sequential decision-making problems under uncertainty that are widely encountered in public and private sectors as well as a variety of industries including energy, finance, health care, manufacturing, and telecommunication. This project has lead to high quality journal publications at SIAM Journal on Optimization and IISE Transactions, as well as several invited/peer-reviewed conference presentations. The project has provided the opportunity for the professional development of a research associate as well as an undergraduate student at the University of Chicago to work on state-of-the-art high performance computing. This project also justifies the establishment and sustenance of high performance computing clusters such as the Research Computing Center at the University of Chicago as well as the need for institutional resources such as establishment and sustenance of societies and/or organizations to facilitate the development and utilization of distributed algorithms for dealing with data-driven large-scale real life problems. Advances in data collection and storage technologies have made unsurmounted amount of data available to the research community. However, this data is mostly unexplored to its full extent, because the traditional algorithms utilized in solving stochastic programming models are typically very slow and cannot cope with data at such scale. This project demonstrates that such large scale data is now within our reach.</p><br> <p>            Last Modified: 11/12/2018<br>      Modified by: Osman&nbsp;Y&nbsp;Ozaltin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Many sequential decision-making problems involving uncertainty can be appropriately modeled as multistage stochastic programs. Examples include problems in energy, finance, manufacturing, telecommunication, transportation and logistics, and health care. Despite their appeal as a flexible modeling framework, stochastic programming models typically suffer unbearable growth in their size as the number of decision stages increase. The size of many models can easily exceed the available memory on a state-of-art desktop computer. To overcome this barrier, typical applications content with truncating or merging the problem data, and therefore, losing information that is otherwise available. Even then, modern algorithms employed in solving such problems can hit the memory barrier during the solution process, or solution times can be excessive. Therefore, practical applications have generally been restricted to two-stage linear models with limited modeling of parameter uncertainty. Two-stage models, however, lack an ability to dynamically respond to information that gradually becomes available to the decision maker. Furthermore, the linearity assumption hampers the applicability for a broad set of questions, as most applications involve discrete/integer/binary decision variables.  In this project, we have developed, analyzed, implemented, and tested a comprehensive methodology for solving large-scale multi-stage stochastic programs. Since the developed methodology does not make restrictive assumptions (such as convexity), it is much broadly applicable than most approaches in the literature. Furthermore, our methodology is designed around distributed computing, and it achieves very high computing efficiency due to minimum communication overhead between the parallel running computing processors. This aspect makes our approach amenable to solving truly large-scale instances. We have designed and implemented robust and efficient distributed computer codes of our methodology using resources available at the University of Chicago Research Computing Center, which maintains a state-of-theart high-performance computing grid. We have also tested the performance of this method using an extensive set of test instances that have been carefully selected to demonstrate scalability, reliability, and efficiency required for large-scale practical applications. The sizes of some of the instances solved are several orders of magnitude larger than what has been previously reported in the literature for multi-stage stochastic mixed-integer programs. The success of the method on such large-scale tests demonstrate its immense potential to obtain high-quality solutions to practical instances within a reasonable time frame.  The methods developed in this project alleviate the challenges associated with multi-stage stochastic programs, and therefore encourages the research community to further study and utilize multi-stage stochastic programming models. The results of this project are directly applicable to large-scale sequential decision-making problems under uncertainty that are widely encountered in public and private sectors as well as a variety of industries including energy, finance, health care, manufacturing, and telecommunication. This project has lead to high quality journal publications at SIAM Journal on Optimization and IISE Transactions, as well as several invited/peer-reviewed conference presentations. The project has provided the opportunity for the professional development of a research associate as well as an undergraduate student at the University of Chicago to work on state-of-the-art high performance computing. This project also justifies the establishment and sustenance of high performance computing clusters such as the Research Computing Center at the University of Chicago as well as the need for institutional resources such as establishment and sustenance of societies and/or organizations to facilitate the development and utilization of distributed algorithms for dealing with data-driven large-scale real life problems. Advances in data collection and storage technologies have made unsurmounted amount of data available to the research community. However, this data is mostly unexplored to its full extent, because the traditional algorithms utilized in solving stochastic programming models are typically very slow and cannot cope with data at such scale. This project demonstrates that such large scale data is now within our reach.       Last Modified: 11/12/2018       Submitted by: Osman Y Ozaltin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
