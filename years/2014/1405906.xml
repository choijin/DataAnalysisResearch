<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CI-P: Computer System Failure Data Repository to Enable Data-Driven Dependability Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>49891.00</AwardTotalIntnAmount>
<AwardAmount>65891</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Dependability is a requirement for computer systems; however, research&lt;br/&gt;on dependable systems is hampered by a lack of real and publicly&lt;br/&gt;available failure data.  This can result in productive paths of&lt;br/&gt;research being closed to most researchers and, conversely,&lt;br/&gt;unproductive research being performed due to faulty assumptions about&lt;br/&gt;the manner in which real systems fail.  The goal of this project is to&lt;br/&gt;plan a collaborative effort to collect, curate, and provide public&lt;br/&gt;access to failure data for large scale computer systems through a&lt;br/&gt;community repository.  One challenge is that failure data is&lt;br/&gt;considered sensitive by the owners.  The ultimate goal of this project&lt;br/&gt;is to collect the data from some of the NSF-funded large&lt;br/&gt;cyberinfrastructure projects, such as NEES, LIGO, XSEDE, and NRAO.&lt;br/&gt;&lt;br/&gt;The specific goal of this planning project is to collect requirements&lt;br/&gt;from potential praticipants (both users and contributors of data sets)&lt;br/&gt;and seed a prototype repository with data sets from two of the largest&lt;br/&gt;and latest clusters at Purdue. The data sets will comprise static&lt;br/&gt;information, dynamic information about the workloads, and failure&lt;br/&gt;information, for both planned and unplanned outages.&lt;br/&gt;&lt;br/&gt;The broader impact in the project will be achieved through the&lt;br/&gt;dissemination of the data sets to a wide variety of researchers, and&lt;br/&gt;perhaps even, practitioners. The datasets will let people run their&lt;br/&gt;campus clusters more efficiently, i.e., with fewer failures, at higher&lt;br/&gt;utilization and energy efficiency.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/17/2014</MinAmdLetterDate>
<MaxAmdLetterDate>04/15/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1405906</AwardID>
<Investigator>
<FirstName>Xiaohui Carol</FirstName>
<LastName>Song</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaohui Carol Song</PI_FULL_NAME>
<EmailAddress>cxsong@purdue.edu</EmailAddress>
<PI_PHON>7654967467</PI_PHON>
<NSF_ID>000298986</NSF_ID>
<StartDate>07/17/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Saurabh</FirstName>
<LastName>Bagchi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Saurabh Bagchi</PI_FULL_NAME>
<EmailAddress>sbagchi@purdue.edu</EmailAddress>
<PI_PHON>7654941741</PI_PHON>
<NSF_ID>000309372</NSF_ID>
<StartDate>07/17/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072035</ZipCode>
<StreetAddress><![CDATA[465 Northwestern Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~49891</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We collected user input for an annotated modern comprehensive dataset for supercomputing systems to facilitate advances in resilience research. We then started our effort at creating such a dataset, which is publicly accessible. Such a repository helps the community in multiple ways:</p> <p>&bull;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to characterize faults, in extreme-scale systems, based on root or most probable cause, likelihood of detection, frequency of occurrence, timescales for resultant system impact, and efficiency of error recovery.</p> <p>&bull;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to determine new instrumentation, to support fault detection and recovery as well as a means of improving the quality of data collected by the system.</p> <p>&bull;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to recommend at what levels of the system hierarchy (e.g., hardware infrastructure, operating system, runtime systems, and/or application software) one should place cost-effective error detection and/or recovery mechanisms.</p> <p>Through our requirements gathering exercise &ndash; through online surveys and the Bird of Feather session at Supercomputing 2015 &ndash; we attempted to collect answers to various questions including:</p> <p>1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What examples can you bring that demonstrate use of failure data analysis to guide design of future systems?</p> <p>2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What insights would you expect to get from analyzing field failure data?</p> <p>3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What kinds of data analysis tools would you find beneficial for analyzing failure and system usage data?</p> <p>We also created some tools to automate failure data preprocessing and analysis and some data analysis scripts to bring out important metrics and insights from them. As an example the UIUC team in the project developed LogDiver, an open source tool developed at UIUC to facilitate analysis and measurement of system- and application-level resiliency in extreme-scale environments. The LogDiver approach is to create a unique dataset encapsulating events that are central in conducting resiliency and performability measurements. The tool allows precise identification of the reasons behind application termination, relates system errors and failures (e.g., network fabric errors, GPU errors, and file-system failures) to application failures, and provides a unified representation of the workload/error/failure logs, permitting workload-failure analysis and computation of a range of quantitative performance and dependability metrics.</p><br> <p>            Last Modified: 10/10/2016<br>      Modified by: Saurabh&nbsp;Bagchi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We collected user input for an annotated modern comprehensive dataset for supercomputing systems to facilitate advances in resilience research. We then started our effort at creating such a dataset, which is publicly accessible. Such a repository helps the community in multiple ways:  &bull;             to characterize faults, in extreme-scale systems, based on root or most probable cause, likelihood of detection, frequency of occurrence, timescales for resultant system impact, and efficiency of error recovery.  &bull;             to determine new instrumentation, to support fault detection and recovery as well as a means of improving the quality of data collected by the system.  &bull;             to recommend at what levels of the system hierarchy (e.g., hardware infrastructure, operating system, runtime systems, and/or application software) one should place cost-effective error detection and/or recovery mechanisms.  Through our requirements gathering exercise &ndash; through online surveys and the Bird of Feather session at Supercomputing 2015 &ndash; we attempted to collect answers to various questions including:  1.            What examples can you bring that demonstrate use of failure data analysis to guide design of future systems?  2.            What insights would you expect to get from analyzing field failure data?  3.            What kinds of data analysis tools would you find beneficial for analyzing failure and system usage data?  We also created some tools to automate failure data preprocessing and analysis and some data analysis scripts to bring out important metrics and insights from them. As an example the UIUC team in the project developed LogDiver, an open source tool developed at UIUC to facilitate analysis and measurement of system- and application-level resiliency in extreme-scale environments. The LogDiver approach is to create a unique dataset encapsulating events that are central in conducting resiliency and performability measurements. The tool allows precise identification of the reasons behind application termination, relates system errors and failures (e.g., network fabric errors, GPU errors, and file-system failures) to application failures, and provides a unified representation of the workload/error/failure logs, permitting workload-failure analysis and computation of a range of quantitative performance and dependability metrics.       Last Modified: 10/10/2016       Submitted by: Saurabh Bagchi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
