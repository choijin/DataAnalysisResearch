<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Using Humans in the Loop to Collect High-quality Annotations from Images and Time-lapse Videos of Cells</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>10/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>370151.00</AwardTotalIntnAmount>
<AwardAmount>370151</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Sequences of microscopy images of live cells are analyzed by cell biologists to understand cellular processes, for example, to prevent cancer or design bio-materials for wound healing.  Research progress is slowed or compromised when scientists find the image analysis efforts too labor-intensive to do themselves and the automation methods too numerous, unreliable, or difficult to use.  The project develops image-analysis software to leverage human and computer resources together, in particular on the internet, to create high-quality image interpretations.  Live-cell imaging studies support basic research to understand cellular processes and design biomaterials. The work on statistically significant performance evaluation can have broad impact on the research methodology in computer vision.&lt;br/&gt;&lt;br/&gt;The research explores how human and computer resources can be leveraged together, in particular on the internet, to interpret images and videos of cells.  Initially, an expansive benchmark study of detection, segmentation, and tracking algorithms for analyzing images of live cells is conducted. Computer-vision approaches to address the major challenges for existing algorithms are then developed, for example, to interpret the emergence of new cells due to mitosis in time-lapse microscopy videos. Methods are designed for quantifying the quality of automatically and manually obtained annotations and the variability between multiple annotations.  A tool is built to effectively and efficiently use the expertise of domain specialists, in particular, cell biologists, to judge and select automated methods that analyze cell images.  Crowd-sourcing experiments in which internet workers analyze images are designed and conducted.  The quality of these lay workers' annotations is compared to the quality of annotations by domain experts and automated methods.  Finally, a machine learning system is developed that automatically determines which types of cell images or videos can be analyzed accurately with or without human involvement.</AbstractNarration>
<MinAmdLetterDate>07/23/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/26/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421943</AwardID>
<Investigator>
<FirstName>Margrit</FirstName>
<LastName>Betke</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Margrit Betke</PI_FULL_NAME>
<EmailAddress>betke@cs.bu.edu</EmailAddress>
<PI_PHON>6173536412</PI_PHON>
<NSF_ID>000096058</NSF_ID>
<StartDate>07/23/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dept. of Computer Science, Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022152411</ZipCode>
<StreetAddress><![CDATA[111 Cummington Mall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1165</Code>
<Text>ADVANCES IN BIO INFORMATICS</Text>
</ProgramElement>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7275</Code>
<Text>Cross-BIO Activities</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8750</Code>
<Text>Bio &amp; Comp Shared Princ (BCSP)</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~200000</FUND_OBLG>
<FUND_OBLG>2015~170151</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project addressed image analysis problems that are difficult for a computer to solve automatically and extremely time consuming for an expert to solve manually.&nbsp;&nbsp;The project developed methods for combining computing resources with expert or non-expert work to interpret single images and image sequences of living cells. Non-experts who work with crowdsourcing platforms on the internet participated in experiments with phase contrast microscopy and fluorescence microscopy images of cells. The project developed several systems.&nbsp;&nbsp;&nbsp;One system automatically decides, for a batch of images, when to replace humans with computers to create coarse outlines of cells, which are required to initialize automated tools. Another system decides when to replace computers with humans to create final, fine-grained cell outlines.&nbsp;Experiments demonstrated the advantage of relying on a mix of human and computer efforts over relying on either resource alone for annotating objects in various diverse datasets.&nbsp; The project also showed how the allocations of the number of internet workers to an annotation task can be computed optimally based on task features alone, without using worker profiles.&nbsp; A machine learning system was trained to predict an optimal number of crowd workers needed to maximize the accuracy of the annotations.&nbsp; The computed allocation can yield large savings in the crowdsourcing budget (up to 49 percent points) while maintaining labeling accuracy.</p><br> <p>            Last Modified: 03/06/2019<br>      Modified by: Margrit&nbsp;Betke</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1421943/1421943_10322278_1551909790159_Betke-to-NSF-March-6-2019--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1421943/1421943_10322278_1551909790159_Betke-to-NSF-March-6-2019--rgov-800width.jpg" title="Predicting how difficult it is to label cell image outlines"><img src="/por/images/Reports/POR/2019/1421943/1421943_10322278_1551909790159_Betke-to-NSF-March-6-2019--rgov-66x44.jpg" alt="Predicting how difficult it is to label cell image outlines"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Two original cell images and their crowd-sourced annotations are shown.  The machine learning system accurately predicts that the cell in the image on the left is easier to annotate by a crowd worker than the cell on the right.</div> <div class="imageCredit">Margrit Betke and her research team</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Margrit&nbsp;Betke</div> <div class="imageTitle">Predicting how difficult it is to label cell image outlines</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project addressed image analysis problems that are difficult for a computer to solve automatically and extremely time consuming for an expert to solve manually.  The project developed methods for combining computing resources with expert or non-expert work to interpret single images and image sequences of living cells. Non-experts who work with crowdsourcing platforms on the internet participated in experiments with phase contrast microscopy and fluorescence microscopy images of cells. The project developed several systems.   One system automatically decides, for a batch of images, when to replace humans with computers to create coarse outlines of cells, which are required to initialize automated tools. Another system decides when to replace computers with humans to create final, fine-grained cell outlines. Experiments demonstrated the advantage of relying on a mix of human and computer efforts over relying on either resource alone for annotating objects in various diverse datasets.  The project also showed how the allocations of the number of internet workers to an annotation task can be computed optimally based on task features alone, without using worker profiles.  A machine learning system was trained to predict an optimal number of crowd workers needed to maximize the accuracy of the annotations.  The computed allocation can yield large savings in the crowdsourcing budget (up to 49 percent points) while maintaining labeling accuracy.       Last Modified: 03/06/2019       Submitted by: Margrit Betke]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
