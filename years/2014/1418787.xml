<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Dynamical Systems on Tensor Approximations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>210000.00</AwardTotalIntnAmount>
<AwardAmount>210000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Functions of many variables arise in numerous mathematical, statistical, and scientific problems; a particularly notable example is the multiparticle Schrodinger equation in quantum mechanics. The effort required to compute in a straightforward way with such functions grows extremely rapidly as the number of variables increases, and soon becomes prohibitive. Mathematical methods have been developed that in some cases allow one to compute without this rapid growth, but crucial parts of the method are poorly understood and unreliable. This project seeks to understand and then fix these crucial parts. Students will be actively involved in the project and so learn mathematics and how to conduct mathematical research; they will also develop skills in writing, presenting seminars and posters, and software development and usage.  &lt;br/&gt;&lt;br/&gt;A mathematical study will be conducted on the approximation of tensors using sums of separable tensors and the approximation of multivariate functions using sums of separable functions.  The objectives are to understand (1) how such approximations behave and (2) how such approximations can be effectively computed. The method is to consider iterative tensor approximation algorithms as dynamical systems to probe the set of sum-of-separable tensors and to understand the behavior of the algorithm within this set.  The approximation of tensors by sums of separable tensors enables a promising computational paradigm for bypassing the curse of dimensionality when working with functions of many variables. This project addresses a bottleneck, in understanding and in computation, that prevents the computational paradigm from achieving its full potential.</AbstractNarration>
<MinAmdLetterDate>07/27/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1418787</AwardID>
<Investigator>
<FirstName>Todd</FirstName>
<LastName>Young</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Todd R Young</PI_FULL_NAME>
<EmailAddress>youngt@ohio.edu</EmailAddress>
<PI_PHON>7405931277</PI_PHON>
<NSF_ID>000344465</NSF_ID>
<StartDate>07/27/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Martin</FirstName>
<LastName>Mohlenkamp</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Martin J Mohlenkamp</PI_FULL_NAME>
<EmailAddress>mohlenka@ohio.edu</EmailAddress>
<PI_PHON>7405931259</PI_PHON>
<NSF_ID>000279936</NSF_ID>
<StartDate>07/27/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio University</Name>
<CityName>ATHENS</CityName>
<ZipCode>457012979</ZipCode>
<PhoneNumber>7405932857</PhoneNumber>
<StreetAddress>108 CUTLER HL</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>15</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH15</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041077983</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041077983</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio University]]></Name>
<CityName>Athens</CityName>
<StateCode>OH</StateCode>
<ZipCode>457012979</ZipCode>
<StreetAddress><![CDATA[1 Ohio University]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>15</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH15</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~210000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project helped develop the next generation of Mathematicians by<br />providing research opportunities for 3 doctoral students and 10<br />Master's students in Mathematics. Participation helped develop student<br />skills in Mathematics itself, the process of conducting research,<br />mathematical writing and presentation, and software development.<br /><br />Progress in understanding tensor approximations has been hampered by<br />lack of appropriate tools. In particular, the standard tools in<br />optimization do not help in understanding the transient dynamics<br />observed in tensor approximation algorithms. We have developed an<br />analysis framework to provide appropriate tools and measures.<br />The key to understanding the transient dynamics is to look at both how<br />fast the error decreases (measured by the norm of the gradient) and<br />the shape of the error perpendicular to the downhill direction<br />(measured by the eigenvalues of the Hessian projected transverse to<br />the gradient). When the error decreases slowly (the gradient has small<br />norm) and the shape is a valley with steep sides (the eigenvalues are<br />positive with some large) then algorithms will slowly zig-zag down the<br />valley.<br /><br />We have completed an in-depth analysis of the two simplest non-trivial<br />cases of tensor approximation: a rank-2 tensor approximated by a<br />rank-1 tensor and by a rank-2 tensor. Among the many results of this<br />analysis, two especially deserve highlighting:<br /><br />(1) For a range of parameter values, the problem exhibits minima<br />embedded within long, gradually-descending, steep-sided valleys. As<br />noted above, such valleys slow algorithms by causing zig-zag<br />behavior. Thus one should choose algorithms specifically designed to<br />work well in valleys.<br /><br />(2) For a range of parameter values, the problem exhibits a novel<br />feature that creates valleys that are more gradual in descent and more<br />steeply-sided than is normally possible in optimization problems.&nbsp; The<br />feature is saddle-like in that from some starting points the downhill<br />direction leads very close to the feature and then turns and leads<br />away from it. At the feature, the error function is discontinuous<br />(with an essential singularity), which causes the sides of the valley<br />to become infinitely steep.&nbsp; This feature explains the great mystery in<br />tensor approximation algorithms: the presence and prevalence of<br />``transient swamps'', when an algorithm reduces the error by minuscule<br />amounts for many iterations and then converges rapidly.</p><br> <p>            Last Modified: 10/06/2017<br>      Modified by: Martin&nbsp;J&nbsp;Mohlenkamp</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1418787/1418787_10324076_1507233494378_transientoutcomes--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1418787/1418787_10324076_1507233494378_transientoutcomes--rgov-800width.jpg" title="View of a feature that can cause a transient swamp."><img src="/por/images/Reports/POR/2017/1418787/1418787_10324076_1507233494378_transientoutcomes--rgov-66x44.jpg" alt="View of a feature that can cause a transient swamp."></a> <div class="imageCaptionContainer"> <div class="imageCaption">View of a feature that can cause a transient swamp. From starting points in the red, and from many directions out of the plotting plane, the downhill direction leads into the blue valleys, which become infinitely steep in the center of the plot.</div> <div class="imageCredit">Martin J. Mohlenkamp</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Martin&nbsp;J&nbsp;Mohlenkamp</div> <div class="imageTitle">View of a feature that can cause a transient swamp.</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project helped develop the next generation of Mathematicians by providing research opportunities for 3 doctoral students and 10 Master's students in Mathematics. Participation helped develop student skills in Mathematics itself, the process of conducting research, mathematical writing and presentation, and software development.  Progress in understanding tensor approximations has been hampered by lack of appropriate tools. In particular, the standard tools in optimization do not help in understanding the transient dynamics observed in tensor approximation algorithms. We have developed an analysis framework to provide appropriate tools and measures. The key to understanding the transient dynamics is to look at both how fast the error decreases (measured by the norm of the gradient) and the shape of the error perpendicular to the downhill direction (measured by the eigenvalues of the Hessian projected transverse to the gradient). When the error decreases slowly (the gradient has small norm) and the shape is a valley with steep sides (the eigenvalues are positive with some large) then algorithms will slowly zig-zag down the valley.  We have completed an in-depth analysis of the two simplest non-trivial cases of tensor approximation: a rank-2 tensor approximated by a rank-1 tensor and by a rank-2 tensor. Among the many results of this analysis, two especially deserve highlighting:  (1) For a range of parameter values, the problem exhibits minima embedded within long, gradually-descending, steep-sided valleys. As noted above, such valleys slow algorithms by causing zig-zag behavior. Thus one should choose algorithms specifically designed to work well in valleys.  (2) For a range of parameter values, the problem exhibits a novel feature that creates valleys that are more gradual in descent and more steeply-sided than is normally possible in optimization problems.  The feature is saddle-like in that from some starting points the downhill direction leads very close to the feature and then turns and leads away from it. At the feature, the error function is discontinuous (with an essential singularity), which causes the sides of the valley to become infinitely steep.  This feature explains the great mystery in tensor approximation algorithms: the presence and prevalence of ``transient swamps'', when an algorithm reduces the error by minuscule amounts for many iterations and then converges rapidly.       Last Modified: 10/06/2017       Submitted by: Martin J Mohlenkamp]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
