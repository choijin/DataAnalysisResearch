<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: BodyVis: Advancing New Science Learning and Inquiry Experiences via Custom Designed Wearable On-Body Sensing and Visualization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>549990.00</AwardTotalIntnAmount>
<AwardAmount>549990</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amy Baylor</SignBlockName>
<PO_EMAI>abaylor@nsf.gov</PO_EMAI>
<PO_PHON>7032925126</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by building examples and studying their possibilities for fostering learning as well as challenges to using them well. As technologies become smaller and more portable, the possibility of wearable computing becomes more and more realistic. This proposal takes advantage of this possibility to help elementary school aged children learn about anatomy and physiology by making clothing with sensors and displays to help kids see how their own bodies work. For example, a life-sized pair of lungs on a shirt might light up to show how air flows in and out of a child's lungs in time with their own breathing.   &lt;br/&gt;&lt;br/&gt;The project has interconnected research and design activities. A formative inquiry phase will document what kids do and do not understand about their bodies through surveys, interviews, and a "body map" approach, while in-service elementary school teachers in a STEM education Master's degree program will be probed as to learning goals for kids in this domain. An iterative, participatory and informant design process will then be used to refine e-textile shirts and associated learning activities in two contexts that host underserved youth: the CASA de Maryland, and the Boys and Girls Club of Hartford County. Co-design will also be undertaken with teachers. Finally, learning studies will be done on children in schools and informal settings to probe students' pre-post gains in physiology and anatomy knowledge, and knowledge of how everyday activities change health and biological processes in the body. Video observation and logfiles will be used to study the learning activities themselves, and coded using Chinn and Malhotra's framework for scientific inquiry. Finally, the technology designs themselves and relevant activities will be disseminated through the use of online portals such as Instructables, so that other educators can build or experiment with similar health education wearables.</AbstractNarration>
<MinAmdLetterDate>08/18/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1441184</AwardID>
<Investigator>
<FirstName>Tamara</FirstName>
<LastName>Clegg</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tamara L Clegg</PI_FULL_NAME>
<EmailAddress>tclegg@umd.edu</EmailAddress>
<PI_PHON>3014052037</PI_PHON>
<NSF_ID>000586403</NSF_ID>
<StartDate>08/18/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jon</FirstName>
<LastName>Froehlich</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jon Froehlich</PI_FULL_NAME>
<EmailAddress>jonf@cs.washington.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000630231</NSF_ID>
<StartDate>08/18/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7645</Code>
<Text>Discovery Research K-12</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~549990</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Have you ever wondered: "<em>How do our bodies change when we engage in different activities like running, reading, or standing?"</em>&nbsp;or "<em>How does my breathing rate compare to my friends and why may this be?"</em>&nbsp;or "<em>Why does my heart beat faster when I am exercising?"&nbsp;</em>Our NSF-funded work helps children ask and answer these types of questions using new wearable computing and electronic textile (e-textile) approaches. Our overarching research aim was to develop new wearable learning tools that used the human body and body movement as the primary source of inquiry--to support children's scientific inquiry skills, to help children design and conduct life-relevant experiments using their own body data, and to provide a new way to learn about human anatomy and physiology. Grounded in embodied learning theory, which emphasizes the role of the body in facilitating learning, our work aligns with Next Generation Science Standards (NGSS) and the National Research Council's (NRC) efforts to make science learning more personal and inquiry driven.</p> <p>During the funding award period, we designed, built, and evaluated three different types of learning tools and corresponding learning activities, collaborated with a diverse set of computer and learning scientists, and worked with our local communities. Our tools include:</p> <ul> <li><em>BodyVis</em>, an e-textile shirt that combine embedded sensing and interactive visualization to reveal otherwise "invisible" parts and functions of the human body [CHI'15]. As the wearer engages in an activity, physiological phenomena are manifested on the wearable visualization in real-time.<br /><br /></li> <li>To allow learners to explore, analyze, and graph their body data--important aspects of scientific inquiry--we created and evaluated a complementary tool called <em>SharedPhys </em>[IDC'16]. SharedPhys integrates live-streaming wearable physiological sensors, whole-body interaction, and real-time large-screen visualizations to create a novel mixed-reality learning environment. With SharedPhys, children interact physically--both explicitly via body movement, gesture, and position as well as implicitly via their changing physiology and can observe different representations of their body data in real-time.<br /><br /> </li> <li>Finally, to engage children in creating their own complex interactive systems, we developed and conducted multi-day workshops using the littleBits electronic prototyping platform [in progress] and developed and evaluated a prototyping tool, called <em>PrototypAR</em>, that uses augmented reality to scaffold the design, test, and iteration process [IDC'19].</li> </ul> <p>We developed these tools using a design method called <em>participatory design</em>, which engaged elementary school teachers, informal science learning staff, and children directly in our design process. We evaluated our tools and learning activities with over ~200 children in both informal and formal learning environments, including children's museums, afterschool clubs, and partnering elementary schools [ICLS'16; CHI'17]. In addition, we worked with local elementary school teachers to co-develop a one-week curriculum using our BodyVis and SharedPhys tools, which we iteratively implemented both in Years 3 and 4 of the award in six elementary school classrooms [ICLS'18]. Below, we summarize our key achievements.</p> <p><strong>Key Achievements</strong></p> <ul> <li>The development of custom <em>Live Physiological Sensing </em>and <em>Visualization Tools </em>(LPSV) for life-relevant and collaborative STEM learning, including: <a href="https://makeabilitylab.cs.washington.edu/project/BodyVis/">BodyVis</a> [CHI'15]<em>, </em><a href="https://makeabilitylab.cs.washington.edu/project/sharedphys/">SharedPhys</a> [IDC'16], and <a href="https://makeabilitylab.cs.washington.edu/project/prototypar/">PrototypAR</a> [CHI'19]. Our findings suggest that the tight coupling between physical interaction, sensing, and visualization in a multi-user environment helps promote engagement, allows children to easily explore cause-and-effect relationships, supports and shapes social interactions, and promotes playful experiences.<br /><br /></li> <li>The implementation and development of age-appropriate LPSV learning scaffolds to support scientific inquiry for elementary aged learners related to question development, procedure design, data interpretation, and theory building as well as general scaffolds for helping children understand scientific inquiry terms and concepts related to the body and data. [ICLS'18]<br /><br /></li> <li>An activity-theory based analysis of our multi-day LPSV deployments in local elementary schools, highlighting the importance of integrating model-based representations for supporting explorations, analytic representations for scaffolding scientific inquiry, and the complex interconnections between space, teachers, curriculum, and tool use [CHI'17].<br /><br /></li> <li>To more broadly communicate our work, we produced two videos for the NSF Video Showcase: one for BodyVis (<a href="https://stemforall2016.videohall.com/presentations/768">link</a>) and the other for PrototypAR (<a href="https://stemforall2019.videohall.com/presentations/1567">link</a>)--both received <em>Facilitator Choice Awards</em> and, together, over 6500 views. We also created project pages, accessible here: https://makeabilitylab.cs.washington.edu/projects/<br /><br /></li> <li>We engaged with local partners, often in underserved communities, including Boys and Girls Clubs in Baltimore and Prince Georges County elementary schools where we deployed our tools and ran our STEM-based studies.<br /><br /></li> <li>PI Froehlich and Co-PI Clegg involved and mentored a diverse set of students from high school to undergraduate to graduate students, including students from Computer Science, the College of Information Studies, Math, and the College of Education. Of the 15 student collaborators, three were underrepresented minorities and ten were female. </li> </ul> <p>&nbsp;</p><br> <p>            Last Modified: 12/16/2019<br>      Modified by: Jon&nbsp;Froehlich</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526738009_IMG_4330--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526738009_IMG_4330--rgov-800width.jpg" title="Early BodyVis Prototype"><img src="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526738009_IMG_4330--rgov-66x44.jpg" alt="Early BodyVis Prototype"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An initial BodyVis prototype with plush, interactive e-textiles.</div> <div class="imageCredit">Jon E. Froehlich</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jon&nbsp;Froehlich</div> <div class="imageTitle">Early BodyVis Prototype</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526808697_IMG_5240--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526808697_IMG_5240--rgov-800width.jpg" title="BodyVis at a Maker Faire"><img src="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526808697_IMG_5240--rgov-66x44.jpg" alt="BodyVis at a Maker Faire"></a> <div class="imageCaptionContainer"> <div class="imageCaption">We demonstrated BodyVis at a local Maker Faire</div> <div class="imageCredit">Jon E. Froehlich</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jon&nbsp;Froehlich</div> <div class="imageTitle">BodyVis at a Maker Faire</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526880527_IMG_8584--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526880527_IMG_8584--rgov-800width.jpg" title="BodyVis in use at local after school club"><img src="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526880527_IMG_8584--rgov-66x44.jpg" alt="BodyVis in use at local after school club"></a> <div class="imageCaptionContainer"> <div class="imageCaption">We deployed and studied BodyVis in a variety of formal and informal learning environment, including the one shown in this image</div> <div class="imageCredit">BodyVis Team</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jon&nbsp;Froehlich</div> <div class="imageTitle">BodyVis in use at local after school club</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526947003_Picture1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526947003_Picture1--rgov-800width.jpg" title="BodyVis at a local elementary school"><img src="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576526947003_Picture1--rgov-66x44.jpg" alt="BodyVis at a local elementary school"></a> <div class="imageCaptionContainer"> <div class="imageCaption">We evaluated a multi-day BodyVis and SharedPhys curriculum at a local elementary school.</div> <div class="imageCredit">BodyVis Team</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jon&nbsp;Froehlich</div> <div class="imageTitle">BodyVis at a local elementary school</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576527016851_m(6)_v4--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576527016851_m(6)_v4--rgov-800width.jpg" title="Children using SharedPhys"><img src="/por/images/Reports/POR/2019/1441184/1441184_10334038_1576527016851_m(6)_v4--rgov-66x44.jpg" alt="Children using SharedPhys"></a> <div class="imageCaptionContainer"> <div class="imageCaption">With SharedPhys children could design and test out experiments to achieve increased heart rates.</div> <div class="imageCredit">SharedPhys Team</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jon&nbsp;Froehlich</div> <div class="imageTitle">Children using SharedPhys</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Have you ever wondered: "How do our bodies change when we engage in different activities like running, reading, or standing?" or "How does my breathing rate compare to my friends and why may this be?" or "Why does my heart beat faster when I am exercising?" Our NSF-funded work helps children ask and answer these types of questions using new wearable computing and electronic textile (e-textile) approaches. Our overarching research aim was to develop new wearable learning tools that used the human body and body movement as the primary source of inquiry--to support children's scientific inquiry skills, to help children design and conduct life-relevant experiments using their own body data, and to provide a new way to learn about human anatomy and physiology. Grounded in embodied learning theory, which emphasizes the role of the body in facilitating learning, our work aligns with Next Generation Science Standards (NGSS) and the National Research Council's (NRC) efforts to make science learning more personal and inquiry driven.  During the funding award period, we designed, built, and evaluated three different types of learning tools and corresponding learning activities, collaborated with a diverse set of computer and learning scientists, and worked with our local communities. Our tools include:  BodyVis, an e-textile shirt that combine embedded sensing and interactive visualization to reveal otherwise "invisible" parts and functions of the human body [CHI'15]. As the wearer engages in an activity, physiological phenomena are manifested on the wearable visualization in real-time.   To allow learners to explore, analyze, and graph their body data--important aspects of scientific inquiry--we created and evaluated a complementary tool called SharedPhys [IDC'16]. SharedPhys integrates live-streaming wearable physiological sensors, whole-body interaction, and real-time large-screen visualizations to create a novel mixed-reality learning environment. With SharedPhys, children interact physically--both explicitly via body movement, gesture, and position as well as implicitly via their changing physiology and can observe different representations of their body data in real-time.    Finally, to engage children in creating their own complex interactive systems, we developed and conducted multi-day workshops using the littleBits electronic prototyping platform [in progress] and developed and evaluated a prototyping tool, called PrototypAR, that uses augmented reality to scaffold the design, test, and iteration process [IDC'19].   We developed these tools using a design method called participatory design, which engaged elementary school teachers, informal science learning staff, and children directly in our design process. We evaluated our tools and learning activities with over ~200 children in both informal and formal learning environments, including children's museums, afterschool clubs, and partnering elementary schools [ICLS'16; CHI'17]. In addition, we worked with local elementary school teachers to co-develop a one-week curriculum using our BodyVis and SharedPhys tools, which we iteratively implemented both in Years 3 and 4 of the award in six elementary school classrooms [ICLS'18]. Below, we summarize our key achievements.  Key Achievements  The development of custom Live Physiological Sensing and Visualization Tools (LPSV) for life-relevant and collaborative STEM learning, including: BodyVis [CHI'15], SharedPhys [IDC'16], and PrototypAR [CHI'19]. Our findings suggest that the tight coupling between physical interaction, sensing, and visualization in a multi-user environment helps promote engagement, allows children to easily explore cause-and-effect relationships, supports and shapes social interactions, and promotes playful experiences.   The implementation and development of age-appropriate LPSV learning scaffolds to support scientific inquiry for elementary aged learners related to question development, procedure design, data interpretation, and theory building as well as general scaffolds for helping children understand scientific inquiry terms and concepts related to the body and data. [ICLS'18]   An activity-theory based analysis of our multi-day LPSV deployments in local elementary schools, highlighting the importance of integrating model-based representations for supporting explorations, analytic representations for scaffolding scientific inquiry, and the complex interconnections between space, teachers, curriculum, and tool use [CHI'17].   To more broadly communicate our work, we produced two videos for the NSF Video Showcase: one for BodyVis (link) and the other for PrototypAR (link)--both received Facilitator Choice Awards and, together, over 6500 views. We also created project pages, accessible here: https://makeabilitylab.cs.washington.edu/projects/   We engaged with local partners, often in underserved communities, including Boys and Girls Clubs in Baltimore and Prince Georges County elementary schools where we deployed our tools and ran our STEM-based studies.   PI Froehlich and Co-PI Clegg involved and mentored a diverse set of students from high school to undergraduate to graduate students, including students from Computer Science, the College of Information Studies, Math, and the College of Education. Of the 15 student collaborators, three were underrepresented minorities and ten were female.            Last Modified: 12/16/2019       Submitted by: Jon Froehlich]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
