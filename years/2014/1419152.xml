<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Chameleon: A Large-Scale, Reconfigurable Experimental Environment for Cloud Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>5713454.00</AwardTotalIntnAmount>
<AwardAmount>5763454</AwardAmount>
<AwardInstrument>
<Value>Cooperative Agreement</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Brassil</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>A persistent problem facing academic cloud research is the lack of infrastructure and data to perform experimental research: large-scale hardware is needed to investigate the scalability of cloud infrastructure and applications, heterogeneous hardware is needed to investigate algorithmic and implementation tradeoffs, fully-configurable software environments are needed to investigate the performance of virtualization techniques and the differences between cloud software stacks, and data about how clouds are used is needed to evaluate virtual machine scheduling and data placement algorithms. &lt;br/&gt;&lt;br/&gt;The Chameleon project will addresses these needs by providing a large-scale, fully configurable experimental testbed driven by the needs of the cloud research and education communities. The testbed, and the ecosystem associated with it, will enable researchers to explore a range of cloud research challenges, from large scale to small scale, including exploring low-level problems in hardware architecture, systems research, network configuration, and software design, or at higher levels of abstraction looking at cloud scheduling, cloud platforms, and cloud applications. &lt;br/&gt;&lt;br/&gt;Chameleon will significantly enhance the ability of the computing research community to understand the behavior of Internet scale cloud systems, and to develop new software, ideas and algorithms for the cloud environment. As the tremendous shift to cloud as the primary means of providing computing infrastructure continues, a large-scale testbed tailored to researchers' needs is essential to the continued relevance of a large fraction of computing research. &lt;br/&gt;&lt;br/&gt;The project is led by the University of Chicago and includes partners from the Texas Advanced Computing Center (TACC), Northwestern University, the Ohio State University, and the University of Texas at San Antonio, comprising a highly qualified and experienced team, with research leaders from the cloud and networking world blended with providers of production quality cyberinfrastructure.  The team includes members from the NSF-supported FutureGrid project and from the GENI community, both forerunners of the NSFCloud solicitation under which this project is funded. &lt;br/&gt;&lt;br/&gt;The Chameleon testbed, will be deployed at the University of Chicago (UC) and the Texas Advanced Computing Center (TACC) and will consist of 650 multi-core cloud nodes, 5PB of total disk space, and leverage 100 Gbps connection between the sites. While a large part of the testbed will consist of homogenous hardware to support large-scale experiments, a portion of it will support heterogeneous units allowing experimentation with high-memory, large-disk, low-power, GPU, and co-processor units. The project will also leverage existing FutureGrid hardware at UC and TACC in its first year to provide a transition period for the existing FutureGrid community of experimental users. &lt;br/&gt;&lt;br/&gt;To support a broad range of experiments emphasizing a range of requirements ranging from a high degree of control to ease of use the project will support a graduated configuration system allowing full user configurability of the stack, from provisioning of bare metal and network interconnects to delivery of fully functioning cloud environments. In addition, to facilitate experiments, Chameleon will support a set of services designed to meet researchers needs, including support for experimental management, reproducibility, and repositories of trace and workload data of production cloud workloads. &lt;br/&gt;&lt;br/&gt;To facilitate the latter, the project will form a set of partnerships with commercial as well as academic clouds, such as Rackspace and Open Science Data Cloud (OSDC). It will also partner with other testbeds, notably GENI and INRIA's Grid5000 testbed, and reach out to the user community to shape the policy an direction of the testbed. &lt;br/&gt;&lt;br/&gt;The Chameleon project will bring a new dimension and scale of resources to the CS community who wish to educate their students about design, implementation, operation and applications of cloud computing, a critical skillset for future computing professionals. It will enhance the understanding and application of experimental methodology in computer science and generate new educational materials and resources, with the participation of, and for, Minority Serving Institution (MSI) students.</AbstractNarration>
<MinAmdLetterDate>08/19/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/21/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>CoopAgrmnt</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1419152</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Stanzione</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Jr.</PI_SUFX_NAME>
<PI_FULL_NAME>Daniel Stanzione</PI_FULL_NAME>
<EmailAddress>dan@tacc.utexas.edu</EmailAddress>
<PI_PHON>5124759411</PI_PHON>
<NSF_ID>000193108</NSF_ID>
<StartDate>08/19/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>Cockerill</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy M Cockerill</PI_FULL_NAME>
<EmailAddress>cockerill@tacc.utexas.edu</EmailAddress>
<PI_PHON>5124718197</PI_PHON>
<NSF_ID>000299304</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Warren</FirstName>
<LastName>Smith</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Warren W Smith</PI_FULL_NAME>
<EmailAddress>Warren.Smith@ll.mit.edu</EmailAddress>
<PI_PHON>7819811509</PI_PHON>
<NSF_ID>000221973</NSF_ID>
<StartDate>08/19/2014</StartDate>
<EndDate>08/04/2015</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121523</ZipCode>
<StreetAddress><![CDATA[101 E. 27th Street, Suite 5.300]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>2890</Code>
<Text>CISE Research Resources</Text>
</ProgramElement>
<ProgramReference>
<Code>7363</Code>
<Text>RES IN NETWORKING TECH &amp; SYS</Text>
</ProgramReference>
<ProgramReference>
<Code>8002</Code>
<Text>CISE Research Resources</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~2496487</FUND_OBLG>
<FUND_OBLG>2015~3266967</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 15.0px Menlo; color: #000000; background-color: #ffffff} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 15.0px Menlo; color: #000000; background-color: #ffffff; min-height: 18.0px} span.s1 {font-variant-ligatures: no-common-ligatures} --> <p class="p1"><span class="s1">The Chameleon project deployed a successful large-scale distributed testbed for research into cloud computing.<span>&nbsp; </span>The shift of computing to the cloud is one of the more fundamental transformations of information technology in recent years, and effects not only research in computing, but a wide array of business functions for enterprises at all scale, the way consumers interact with technology, and is having profound implications on the economy and evey day life.<span>&nbsp; </span>Chameleon differs substantially from other NSF computing resources in that it is directly focused on research in computer science.<span>&nbsp; </span>While other scientific computing resources provide tremendous computing power for engineering and science research, as production systems, the computers themselves and their system software components can not be changed by the end user.<span>&nbsp; </span>Chameleon, in contrast, provided tremendous flexibility to computing researchers to deploy alternate software stacks; users could start with "bare metal" allocations (computers on which they deploy the operating software of their choice), or select from a libray of pre-configured virtual machine images. In addition to flexibility in software, Chameleon also offered users a range of different hardware types, including a variety of processors, accelerators, networks, and storage devices. <span>&nbsp; </span>Chameleon also physically existed at multiple sites (in Austin, Texas and Chicago, Illinois) to allow researchers to replicate the multi-datacenter conditions that exist in most production cloud environments.</span></p> <p class="p1"><span class="s1">In addition to the hardware itself, the Chameleon project created the software, training, and user support to complete the testbed ecosystem.<span>&nbsp; </span>A full-featured portal was created that allowed the operation of the cluster through the popular OpenStack framework for managing open clouds.<span>&nbsp; </span>The Chameleon project made substantial contributions to the OpenStack framework that were in turn released open source to the community.</span></p> <p class="p1"><span class="s1">Chameleon supported nearly 2,000 users across hundreds of projects and more than 30 research disciplines during the grant. Research was performed in cybersecurity, scalable cloud operating system software, cloud application performance, machine learning, and many other critical areas of computing research.<span>&nbsp; </span>The Chameleon infrastructure lives on and continues to support the community through a renewal grant.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 01/19/2018<br>      Modified by: Daniel&nbsp;Stanzione</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Chameleon project deployed a successful large-scale distributed testbed for research into cloud computing.  The shift of computing to the cloud is one of the more fundamental transformations of information technology in recent years, and effects not only research in computing, but a wide array of business functions for enterprises at all scale, the way consumers interact with technology, and is having profound implications on the economy and evey day life.  Chameleon differs substantially from other NSF computing resources in that it is directly focused on research in computer science.  While other scientific computing resources provide tremendous computing power for engineering and science research, as production systems, the computers themselves and their system software components can not be changed by the end user.  Chameleon, in contrast, provided tremendous flexibility to computing researchers to deploy alternate software stacks; users could start with "bare metal" allocations (computers on which they deploy the operating software of their choice), or select from a libray of pre-configured virtual machine images. In addition to flexibility in software, Chameleon also offered users a range of different hardware types, including a variety of processors, accelerators, networks, and storage devices.   Chameleon also physically existed at multiple sites (in Austin, Texas and Chicago, Illinois) to allow researchers to replicate the multi-datacenter conditions that exist in most production cloud environments. In addition to the hardware itself, the Chameleon project created the software, training, and user support to complete the testbed ecosystem.  A full-featured portal was created that allowed the operation of the cluster through the popular OpenStack framework for managing open clouds.  The Chameleon project made substantial contributions to the OpenStack framework that were in turn released open source to the community. Chameleon supported nearly 2,000 users across hundreds of projects and more than 30 research disciplines during the grant. Research was performed in cybersecurity, scalable cloud operating system software, cloud application performance, machine learning, and many other critical areas of computing research.  The Chameleon infrastructure lives on and continues to support the community through a renewal grant.          Last Modified: 01/19/2018       Submitted by: Daniel Stanzione]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
