<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Collaborative Research: Research into Worst-Case Large Deviation Theory for Network Algorithmics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The design and analysis of network algorithmics, namely, techniques and principles behind the software and hardware systems running on high-speed Internet routers, has become a rich area of research. In general, network operators would like routers to deliver robust performance under a wide variety of, often unforeseen, operating conditions.  To address this need, this project takes a first look into network algorithmics solutions that can guarantee a certain level of performance, not only under typical or average parameter settings as in prior studies, but also under all admissible parameter settings. Toward this goal, PIs propose to develop a novel mathematical approach, called worst-case large deviation theory that is needed to prove such universal lower bounds on performance. &lt;br/&gt;&lt;br/&gt;This project consists of three closely connected research threads.   First, the principal investigators (PIs) will develop solutions for distributed data streaming problems that can guarantee a certain level of performance, under all possible ways a given data set is partitioned into distributed subsets.  Second, they will develop a rich family of load-balanced switching solutions that can guarantee high throughput and reasonably low delay under all admissible traffic workloads.  Third, they will build mathematical connections between worst-case large deviation techniques they developed in the past several years for deriving such universal performance bounds in prior network algorithmics solutions, which they expect will shed light on the new mathematical problems they will encounter in the first two research threads.&lt;br/&gt;&lt;br/&gt;This project will engage both graduate and undergraduate students through integrated classroom curriculum and research training that span multiple disciplines, from fundamental mathematics, algorithm design, to hardware implementation.  The results will be broadly disseminated through publications, invited talks, tutorials, and open-sourcing of software developed for this project in accordance with the policies of each institution.  The PIs will work closely with leading networking and systems solution providers to facilitate technology transfers.  Further, both PIs are committed to outreach efforts at their corresponding campuses to broaden the participation of under-represented groups in research and higher education.</AbstractNarration>
<MinAmdLetterDate>09/17/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/17/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422286</AwardID>
<Investigator>
<FirstName>Bill</FirstName>
<LastName>Lin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bill Lin</PI_FULL_NAME>
<EmailAddress>billlin@ece.ucsd.edu</EmailAddress>
<PI_PHON>8588221383</PI_PHON>
<NSF_ID>000441658</NSF_ID>
<StartDate>09/17/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major goal of this project is develop scalable switch architectures that are robust under a wide variety of operating conditions. This robustness demands solutions that are well-behaved in the worst-case, not just in typical cases. In particular, we consider a class of scalable switch architectures called load-balanced switches that can scale to very high capacities by load-balancing incoming packets to a set of intermediate nodes, which are then forwarded to the final outputs. Although load-balanced switches are known to be scalable in size and speed, they have the critical problem that packet departures can be badly missequenced. This is detrimental to Internet traffic since the widely used TCP protocol falsely regards out-of-order packets as indications of congestion and packet loss. To remedy this, a large body of subsequent work has proposed a variety of modifications for ensuring packet ordering, but existing approaches tend to increase packet delay or complexity significantly in comparison to the basic load-balanced switch.</p> <p>In this project, we developed three new load-balanced switch architectures that retain the scalability properties of load-balanced switches, but yet can also guarantee packet ordering with easy-to-implement mechanisms. Each architecture advances the state-of-the-art in its own ways. In conjunction with these architectural developments, we also developed new mathematical machinery for the analysis of worst-case stochastic behaviors of networking solutions under arbitrary workloads, including stability analysis and the bounding of workloads. The new machinery provides a unified coherent framework for shared common mathematical structures in worst-case large deviation problems that arise in various networking problems in general. These common mathematical structures include exchangeability, Schur-convexity, convex and stochastic ordering, and negative association.</p> <p>In particular, we first developed a new load-balanced switch called Sprinklers. Sprinklers generalizes a technique called Uniform Frame Spreading (UFS) in which a frame of N packets for the same switch flow must first be accumulated before they are uniformly spread to the set of N intermediate nodes. This approach ensures packet ordering by ensuring that each intermediate node receives exactly the same number of packets that are destined to the same output port. That is, UFS guarantees perfect load-balancing, but the accumulation of full-frames of N packets incurs huge delays in practice (cubic delay in the worst-case). Sprinklers generalizes the UFS approach by only requiring the accumulation of small stripes rather than full frames. Packet ordering is ensured by forcing all packets within the same switch flow to traverse the same "fat path" through the switch (i.e., the same set of intermediate nodes where the set size is equal to the stripe size). At the core of Sprinklers are two key innovations: a randomized way to determine the "fat path" for each switch flow, and a way to determine its "fatness" roughly in proportion to the rate of the switch flow. These innovations enable Sprinklers to achieve near-perfect load-balancing under arbitrary admissible traffic.</p> <p>Second, we developed another load-balanced switch architecture based on packet-level randomized load-balancing. We show that the amount of packet reordering that can occur with the load-balanced switch is actually quite limited, which means that packet reordering can simply be rectified by employing reordering buffers at the switch outputs. In particular, we formally bound the worst-case amount of time that a packet has to wait in these output reordering buffers before it is guaranteed to be ready for in-order departure with high probability, and we prove that this bound is linear with respect to the switch size. This linear bound is significant because previous approaches can add quadratic or cubic delays to the load-balanced switch. In addition, we use a hash-grouping method that further reduces resequencing delays significantly. Although simple and intuitive, our evaluations show that our output packet reordering approach substantially outperforms existing designs.</p> <p>Finally, we developed a third design called a Safe Randomization Switch (SRS). In this work, load-balancing occurs by randomized load-balancing at the "application-flow" level. In particular, a well-known simple solution to the packet ordering problem is to route all packets that belong to the same application flow through the same intermediate port and hence the same path through the switch. Randomized load-balancing is achieved by randomly choosing the intermediate port based on the hashing of the packet header. This technique is commonly known as "TCP-hashing." Although simple, this method of load-balancing can unfortunately lead to instability, depending on the mix of flow sizes and durations in the group of flows that gets randomly assigned to route through the same intermediate node. To remedy this, we show that TCP-hashing can be enhanced to provably guarantee both stability and packet ordering by extending the approach with safety mechanisms that can uniformly diffuse packets across the switch whenever there is a build-up of packets waiting to route through some intermediate node. Although simple and intuitive, SRS outperforms existing load-balanced switch architectures.</p><br> <p>            Last Modified: 12/30/2017<br>      Modified by: Bill&nbsp;Lin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goal of this project is develop scalable switch architectures that are robust under a wide variety of operating conditions. This robustness demands solutions that are well-behaved in the worst-case, not just in typical cases. In particular, we consider a class of scalable switch architectures called load-balanced switches that can scale to very high capacities by load-balancing incoming packets to a set of intermediate nodes, which are then forwarded to the final outputs. Although load-balanced switches are known to be scalable in size and speed, they have the critical problem that packet departures can be badly missequenced. This is detrimental to Internet traffic since the widely used TCP protocol falsely regards out-of-order packets as indications of congestion and packet loss. To remedy this, a large body of subsequent work has proposed a variety of modifications for ensuring packet ordering, but existing approaches tend to increase packet delay or complexity significantly in comparison to the basic load-balanced switch.  In this project, we developed three new load-balanced switch architectures that retain the scalability properties of load-balanced switches, but yet can also guarantee packet ordering with easy-to-implement mechanisms. Each architecture advances the state-of-the-art in its own ways. In conjunction with these architectural developments, we also developed new mathematical machinery for the analysis of worst-case stochastic behaviors of networking solutions under arbitrary workloads, including stability analysis and the bounding of workloads. The new machinery provides a unified coherent framework for shared common mathematical structures in worst-case large deviation problems that arise in various networking problems in general. These common mathematical structures include exchangeability, Schur-convexity, convex and stochastic ordering, and negative association.  In particular, we first developed a new load-balanced switch called Sprinklers. Sprinklers generalizes a technique called Uniform Frame Spreading (UFS) in which a frame of N packets for the same switch flow must first be accumulated before they are uniformly spread to the set of N intermediate nodes. This approach ensures packet ordering by ensuring that each intermediate node receives exactly the same number of packets that are destined to the same output port. That is, UFS guarantees perfect load-balancing, but the accumulation of full-frames of N packets incurs huge delays in practice (cubic delay in the worst-case). Sprinklers generalizes the UFS approach by only requiring the accumulation of small stripes rather than full frames. Packet ordering is ensured by forcing all packets within the same switch flow to traverse the same "fat path" through the switch (i.e., the same set of intermediate nodes where the set size is equal to the stripe size). At the core of Sprinklers are two key innovations: a randomized way to determine the "fat path" for each switch flow, and a way to determine its "fatness" roughly in proportion to the rate of the switch flow. These innovations enable Sprinklers to achieve near-perfect load-balancing under arbitrary admissible traffic.  Second, we developed another load-balanced switch architecture based on packet-level randomized load-balancing. We show that the amount of packet reordering that can occur with the load-balanced switch is actually quite limited, which means that packet reordering can simply be rectified by employing reordering buffers at the switch outputs. In particular, we formally bound the worst-case amount of time that a packet has to wait in these output reordering buffers before it is guaranteed to be ready for in-order departure with high probability, and we prove that this bound is linear with respect to the switch size. This linear bound is significant because previous approaches can add quadratic or cubic delays to the load-balanced switch. In addition, we use a hash-grouping method that further reduces resequencing delays significantly. Although simple and intuitive, our evaluations show that our output packet reordering approach substantially outperforms existing designs.  Finally, we developed a third design called a Safe Randomization Switch (SRS). In this work, load-balancing occurs by randomized load-balancing at the "application-flow" level. In particular, a well-known simple solution to the packet ordering problem is to route all packets that belong to the same application flow through the same intermediate port and hence the same path through the switch. Randomized load-balancing is achieved by randomly choosing the intermediate port based on the hashing of the packet header. This technique is commonly known as "TCP-hashing." Although simple, this method of load-balancing can unfortunately lead to instability, depending on the mix of flow sizes and durations in the group of flows that gets randomly assigned to route through the same intermediate node. To remedy this, we show that TCP-hashing can be enhanced to provably guarantee both stability and packet ordering by extending the approach with safety mechanisms that can uniformly diffuse packets across the switch whenever there is a build-up of packets waiting to route through some intermediate node. Although simple and intuitive, SRS outperforms existing load-balanced switch architectures.       Last Modified: 12/30/2017       Submitted by: Bill Lin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
