<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Medium: Collaborative Research: Estimating simultaneously structured models: from phase retrieval to network coding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>500005.00</AwardTotalIntnAmount>
<AwardAmount>500005</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In modern data-intensive science and engineering, researchers are faced with estimating models where available observations are far fewer than the dimension of the model to be estimated. The key to the success of compressed sensing, matrix completion, and other problems of this type, is to properly exploit knowledge about the "structure" of the model. While structures such as sparsity have been separately studied, the problem of "simultaneous structures" has been neglected, since it is implicitly assumed by practitioners that simply combining known results for each structure would solve the joint problem. Interestingly, the PIs recently proved that this approach can result in a significant gap.&lt;br/&gt;&lt;br/&gt;This proposal will develop theory and computationally tractable methods for estimating simultaneously structured models with minimal observations. It combines (1) a top-down approach to understand the fundamental limitations based on the geometry of how structures interact, and (2) a problem-specific, bottom-up approach to exploit domain knowledge in constructing appropriate penalties. This work addresses a variety of applications including (1) sparse principal component analysis, a central problem in statistics seeking approximate but sparse eigenvectors, (2) sparse phase retrieval and quadratic compressed sensing in signal processing, and (3) code design for communications and network coding.&lt;br/&gt;&lt;br/&gt;The ability to systematically derive structured models from data will have far-reaching impact on engineering challenges in the era of Big Data and ubiquitous computing. Handling models with multiple structures poses deep theoretical and computational challenges that this proposal focuses on. Applications in machine learning, signal processing, and network coding are discussed. The PIs will incorporate research results in their teaching, organize technical workshops to bring together mathematicians and engineers, and seek the involvement of undergraduate students in this work through summer research programs.</AbstractNarration>
<MinAmdLetterDate>08/14/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/05/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1409836</AwardID>
<Investigator>
<FirstName>Maryam</FirstName>
<LastName>Fazel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Maryam Fazel</PI_FULL_NAME>
<EmailAddress>mfazel@uw.edu</EmailAddress>
<PI_PHON>2066164781</PI_PHON>
<NSF_ID>000488519</NSF_ID>
<StartDate>08/14/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981952500</ZipCode>
<StreetAddress><![CDATA[Box 352500]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~261408</FUND_OBLG>
<FUND_OBLG>2017~238597</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-7da8d460-7fff-98ac-06d4-c8f04340bfa5"> </span></p> <p dir="ltr"><span>With advances in both sensing technologies and huge-scale computing, and with the wide adoption of data science techniques in science and society, researchers in almost all disciplines face the challenge of "learning from data": modeling, analyzing, and identifying behaviors from high-dimensional data and observations. Recent research has aimed to develop theory and algorithms that make these tasks possible, despite highly incomplete and noisy information, by exploiting assumptions about underlying structure. This is enabled by a technique called "regularization", i.e., adding an appropriate penalty function to the estimation error to be minimized.</span></p> <p dir="ltr"><span>Regularization plays important and distinct roles in learning and optimization. This project started off by examining the role of regularization for learning in the presence of </span><span>multiple structures</span><span>. Such cases arise in many applications: in communications (signals that are simultaneously sparse and finite alphabet), in sparse phase retrieval (matrices that are simultaneously sparse and rank one), in machine learning (matrices that are low-rank and sparse, such as in sparse Principal Component Analysis), and in network coding (matrices that are simultaneously low rank and finite field). While a general theory on how to recover models with a single structure (sparse, low rank, piecewise constant, etc.) from limited measurements had emerged, the case of multiple structures had not been examined theoretically, though practitioners long assumed that all one needs to do is to simply use a combination of the individual regularizers. The first contribution of this project was to provide a general analysis that challenged this prevalent approach, and revealed that it can be highly suboptimal in terms of sample-efficiency.</span></p> <p dir="ltr"><span>&nbsp;</span>Another contribution was to propose sample-efficient measurement and recovery methods that work for specific multi-structured models, such as the sparse phase retrieval problem (a central problem in optics and vision) under certain assumptions, and rare feature selection and aggregation (statistical regression problem seeking sparse and clustered coefficients).</p> <p dir="ltr"><span>The project also resulted in the design of new regularizers for learning graphical models with node-based structures, including hub networks, and joint learning of several networks with shared structures, e.g., networks with a few perturbed nodes. Applied to a cancer gene expression data sets, our approach was demonstrated to help identify regulatory genes (hubs), genes mutated across different conditions (perturbed nodes), and co-active genes (co-hubs).</span></p> <p dir="ltr"><span>&nbsp;</span>Beyond signals and static models, the project also provided new statistical guarantees for learning a low-order dynamical system from input-output (or time series) data, using regularized regression with an appropriate regularizer.</p> <p dir="ltr"><span>Beyond its role in structure learning as discussed above, regularization is also employed for algorithmic efficiency, by modifying a problem instance so that algorithms perform better on it (similar to the idea of ?pre-conditioning? in optimization). A class of problems studied in this project is online optimization with budgets: sequentially allocating resources in response to online demands, with resource constraints that couple the decisions across time. Such problems arise in operations research (revenue management), computer science (online packing and covering), and e-commerce. This project examined primal-dual algorithms with a focus on the (worst-case) competitive ratio, and showed how certain smoothing (or dual-regularization) can improve this ratio, and how to seek the optimal regularization by solving a convex problem. This approach allows the design of an effective regularizer customized to a given cost function. This framework was also extended to certain semidefinite programs, such as online D-optimal and A-optimal experiment design problems.</span></p> <p><span>In summary, the natural evolution of this project led&nbsp; to a broader premise of examining the distinct roles that a "regularizer" (added convex penalty functions) plays in estimation and optimization. It started from structure learning and in particular the case of multiple structures, and progressed to view regularization in a broader context and to begin to address fundamental questions such as,</span><span> </span><span>how to choose or design appropriate regularizers, and how to quantify their effect. In addition, the project highlighted how the core topic of regularization bridges machine learning, signal processing, optimization, and control theory. The project resulted in broader impacts in education, where the results of the project appeared in several lectures, summer schools, and workshops. A female undergraduate student was mentored and participated in research on structured graphical models---her research won internal UW awards as well as an NSF GRFP and she is currently a PhD student at Caltech. The project supported training for graduate students across UW and Caltech, in particular through a shared postdoctoral scholar who spent time in both locations, as well as virtual and in-person research meeting fostering collaborations between graduate students, as evidenced by joint papers. </span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/23/2020<br>      Modified by: Maryam&nbsp;Fazel</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   With advances in both sensing technologies and huge-scale computing, and with the wide adoption of data science techniques in science and society, researchers in almost all disciplines face the challenge of "learning from data": modeling, analyzing, and identifying behaviors from high-dimensional data and observations. Recent research has aimed to develop theory and algorithms that make these tasks possible, despite highly incomplete and noisy information, by exploiting assumptions about underlying structure. This is enabled by a technique called "regularization", i.e., adding an appropriate penalty function to the estimation error to be minimized. Regularization plays important and distinct roles in learning and optimization. This project started off by examining the role of regularization for learning in the presence of multiple structures. Such cases arise in many applications: in communications (signals that are simultaneously sparse and finite alphabet), in sparse phase retrieval (matrices that are simultaneously sparse and rank one), in machine learning (matrices that are low-rank and sparse, such as in sparse Principal Component Analysis), and in network coding (matrices that are simultaneously low rank and finite field). While a general theory on how to recover models with a single structure (sparse, low rank, piecewise constant, etc.) from limited measurements had emerged, the case of multiple structures had not been examined theoretically, though practitioners long assumed that all one needs to do is to simply use a combination of the individual regularizers. The first contribution of this project was to provide a general analysis that challenged this prevalent approach, and revealed that it can be highly suboptimal in terms of sample-efficiency.  Another contribution was to propose sample-efficient measurement and recovery methods that work for specific multi-structured models, such as the sparse phase retrieval problem (a central problem in optics and vision) under certain assumptions, and rare feature selection and aggregation (statistical regression problem seeking sparse and clustered coefficients). The project also resulted in the design of new regularizers for learning graphical models with node-based structures, including hub networks, and joint learning of several networks with shared structures, e.g., networks with a few perturbed nodes. Applied to a cancer gene expression data sets, our approach was demonstrated to help identify regulatory genes (hubs), genes mutated across different conditions (perturbed nodes), and co-active genes (co-hubs).  Beyond signals and static models, the project also provided new statistical guarantees for learning a low-order dynamical system from input-output (or time series) data, using regularized regression with an appropriate regularizer. Beyond its role in structure learning as discussed above, regularization is also employed for algorithmic efficiency, by modifying a problem instance so that algorithms perform better on it (similar to the idea of ?pre-conditioning? in optimization). A class of problems studied in this project is online optimization with budgets: sequentially allocating resources in response to online demands, with resource constraints that couple the decisions across time. Such problems arise in operations research (revenue management), computer science (online packing and covering), and e-commerce. This project examined primal-dual algorithms with a focus on the (worst-case) competitive ratio, and showed how certain smoothing (or dual-regularization) can improve this ratio, and how to seek the optimal regularization by solving a convex problem. This approach allows the design of an effective regularizer customized to a given cost function. This framework was also extended to certain semidefinite programs, such as online D-optimal and A-optimal experiment design problems.  In summary, the natural evolution of this project led  to a broader premise of examining the distinct roles that a "regularizer" (added convex penalty functions) plays in estimation and optimization. It started from structure learning and in particular the case of multiple structures, and progressed to view regularization in a broader context and to begin to address fundamental questions such as, how to choose or design appropriate regularizers, and how to quantify their effect. In addition, the project highlighted how the core topic of regularization bridges machine learning, signal processing, optimization, and control theory. The project resulted in broader impacts in education, where the results of the project appeared in several lectures, summer schools, and workshops. A female undergraduate student was mentored and participated in research on structured graphical models---her research won internal UW awards as well as an NSF GRFP and she is currently a PhD student at Caltech. The project supported training for graduate students across UW and Caltech, in particular through a shared postdoctoral scholar who spent time in both locations, as well as virtual and in-person research meeting fostering collaborations between graduate students, as evidenced by joint papers.              Last Modified: 06/23/2020       Submitted by: Maryam Fazel]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
