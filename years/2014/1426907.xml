<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Formal Methods for Motion Planning and Control with Human-in-the-Loop</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>488644.00</AwardTotalIntnAmount>
<AwardAmount>488644</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Miller</SignBlockName>
<PO_EMAI>damiller@nsf.gov</PO_EMAI>
<PO_PHON>7032924914</PO_PHON>
</ProgramOfficer>
<AbstractNarration>How much autonomy should a robotic system have in a safety critical application? The proposed project addresses this fundamental question. Consider a disaster relief scenario in which an autonomous aerial vehicle (a robot) is required to monitor some areas of interest, while fighting fires and searching for survivors. The survivors should be provided medical assistance and the fires should be extinguished, with priority given to stabilizing and extracting survivors. During the mission, the aerial vehicle should stay away from areas where explosions are likely, so it can continue to do its job. An emergency medical technician (EMT) and firefighter specify the robot?s mission in a way that can be easily understood by the robot.  During the execution, depending on what is discovered, the robot makes decisions on its own as long as the high-level specification is not violated. If this is not the case (e.g., there is an obstacle blocking the access to a survivor), the system initiates a dialog with the firefighter and EMT, who provide instructions to help the robot safely cope with the unexpected situation.  The research plan of this project is integrated with an education and outreach plan that includes a rich spectrum of robotic-related activities for university and high-school students. &lt;br/&gt;&lt;br/&gt;This research project combines ideas and techniques from robot motion planning, formal verification, and control theory to provide a rigorous answer to the question of how much autonomy a robot should be given. A specification language inspired by temporal logics is used to communicate the mission to the robot, whose motions are directed by a hierarchical controller. At the top level, automata game techniques and two discretization schemes, one based on cellular decomposition and the other one on randomized sampling, are used. At the low level, input-output linearization combined with path and vector field following are used to implement the high level plans in quadrotors and differential drive ground vehicles. The human-robot negotiation process is based on the internal representation of temporal logic formulas and their quantitative semantics. While directed at robotics, the project impacts a number of safety critical areas, such as cyber physical systems (construction of correct-by-design systems), air traffic control (design of safe minimum-energy paths for airplanes taking off and landing in a crowded airport), etc.</AbstractNarration>
<MinAmdLetterDate>08/04/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1426907</AwardID>
<Investigator>
<FirstName>Calin</FirstName>
<LastName>Belta</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Calin A Belta</PI_FULL_NAME>
<EmailAddress>cbelta@bu.edu</EmailAddress>
<PI_PHON>6173539586</PI_PHON>
<NSF_ID>000360411</NSF_ID>
<StartDate>08/04/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022150001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~488644</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;How much autonomy should a robotic system have in a safety critical application? This is the fundamental question that we addressed in this recently completed project. Our goal was to place the human operator as high as possible in the decision making hierarchy. The missions were described in high-level, user-friendly languages that captured only what was important from the user's point of view. As part of this project, we defined a variety of such specification languages.&nbsp;</p> <p>They were all inspired from temporal logics, traditionally used in formal methods to specify the correctness of computer programs and digital circuits. Among these languages, some were time-abstract (e.g., &ldquo;keep on visiting A and then B and then C) and some allowed for specific deadlines (e.g., &ldquo;go to A and then to B within 10 min&rdquo;). For stochastic robot model, our specification languages captured the probability of satisfaction (e.g., &ldquo;maximize the probability of going to B if A was visited&rdquo;, or &ldquo;go to A with probability at least 0.9&rdquo;).&nbsp;</p> <p>&nbsp;Once a specification is given in such a formal language, the autonomous system chooses (optimally) among the many satisfying behaviors, and initiates an interaction with the user only when absolutely necessary. In this project, we developed methods for automatic synthesis of robot control strategies from specifications given in temporal logic. The technical approach combines ideas and techniques from robot motion planning, formal methods, control theory, and games. The robot control architecture is hierarchical. At the top level, automata game techniques and two discretization schemes, one based on cellular decomposition and the other one on randomized sampling, are used. At the low level, input-output linearization combined with path and vector field following are used to implement the high-level plans in quadrotors and differential drive ground vehicles. The human-robot negotiation process is based on the internal representation of temporal logic formulas and their quantitative semantics.&nbsp;</p> <p>&nbsp;Consider, for example, a disaster relief scenario in which an autonomous aerial vehicle is required to monitor some areas of interest and react to locally sensed features, such as survivors and fires. The survivors should be provided medical assistance and the fires should be extinguished, with priority given to survivors. At the same time, the vehicle should stay away from areas where explosions are likely. Using the framework developed in this project, the user specifies this complex mission as a formula in a particular logic, called Linear Temporal Logic (LTL). During the execution, depending on what is discovered in the area, the robot makes decisions on its own as long as the high-level specification is not violated. If this is not the case (e.g., there is an obstacle blocking the access to a survivor), the system initiates a dialog with the user.&nbsp;</p> <p>While directed at robotics, the project impacts a number of safety critical areas, such as cyber physical systems (construction of correct-by-design systems), air traffic control (design of safe minimum-energy paths for airplanes taking off and landing in a crowded airport), etc. The research plan was integrated with an education and outreach plan that included a rich spectrum of robotic-related activities for undergraduate and high-school students. Specifically, we established a close collaboration withthe BU Academy (a small, independent, coeducational high school located in the BU, and we hosted numerous visits form high schools in the Boston area campus). We were actively involved with high school students supported by ResearchInternships in Science and Engineering (RISE) and Discovery Internships. We actively participated in the&nbsp;Technology Innovation Scholars Program (TISP) at BU.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/09/2019<br>      Modified by: Calin&nbsp;A&nbsp;Belta</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  How much autonomy should a robotic system have in a safety critical application? This is the fundamental question that we addressed in this recently completed project. Our goal was to place the human operator as high as possible in the decision making hierarchy. The missions were described in high-level, user-friendly languages that captured only what was important from the user's point of view. As part of this project, we defined a variety of such specification languages.   They were all inspired from temporal logics, traditionally used in formal methods to specify the correctness of computer programs and digital circuits. Among these languages, some were time-abstract (e.g., "keep on visiting A and then B and then C) and some allowed for specific deadlines (e.g., "go to A and then to B within 10 min"). For stochastic robot model, our specification languages captured the probability of satisfaction (e.g., "maximize the probability of going to B if A was visited", or "go to A with probability at least 0.9").    Once a specification is given in such a formal language, the autonomous system chooses (optimally) among the many satisfying behaviors, and initiates an interaction with the user only when absolutely necessary. In this project, we developed methods for automatic synthesis of robot control strategies from specifications given in temporal logic. The technical approach combines ideas and techniques from robot motion planning, formal methods, control theory, and games. The robot control architecture is hierarchical. At the top level, automata game techniques and two discretization schemes, one based on cellular decomposition and the other one on randomized sampling, are used. At the low level, input-output linearization combined with path and vector field following are used to implement the high-level plans in quadrotors and differential drive ground vehicles. The human-robot negotiation process is based on the internal representation of temporal logic formulas and their quantitative semantics.    Consider, for example, a disaster relief scenario in which an autonomous aerial vehicle is required to monitor some areas of interest and react to locally sensed features, such as survivors and fires. The survivors should be provided medical assistance and the fires should be extinguished, with priority given to survivors. At the same time, the vehicle should stay away from areas where explosions are likely. Using the framework developed in this project, the user specifies this complex mission as a formula in a particular logic, called Linear Temporal Logic (LTL). During the execution, depending on what is discovered in the area, the robot makes decisions on its own as long as the high-level specification is not violated. If this is not the case (e.g., there is an obstacle blocking the access to a survivor), the system initiates a dialog with the user.   While directed at robotics, the project impacts a number of safety critical areas, such as cyber physical systems (construction of correct-by-design systems), air traffic control (design of safe minimum-energy paths for airplanes taking off and landing in a crowded airport), etc. The research plan was integrated with an education and outreach plan that included a rich spectrum of robotic-related activities for undergraduate and high-school students. Specifically, we established a close collaboration withthe BU Academy (a small, independent, coeducational high school located in the BU, and we hosted numerous visits form high schools in the Boston area campus). We were actively involved with high school students supported by ResearchInternships in Science and Engineering (RISE) and Discovery Internships. We actively participated in the Technology Innovation Scholars Program (TISP) at BU.          Last Modified: 12/09/2019       Submitted by: Calin A Belta]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
