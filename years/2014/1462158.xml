<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Learning Graphical Models: Hardness and Tractability</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>03/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Georgia-Ann Klutke</SignBlockName>
<PO_EMAI>gaklutke@nsf.gov</PO_EMAI>
<PO_PHON>7032922443</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Graphical models provide means to capture uncertainty present in complex, unstructured data in a succinct manner. They are particularly suited for performing inference computation at scale. They hold potential to become primary way to model uncertainty in modern data-driven decision-making tasks. This project will enable this by developing efficient methods to learn graphical model representation from observations. The outcome of this project will have wide ranging impact in society and industry. This will include, but not restricted to, our ability to understand human behavior in social networks, processing information captured in biological experiments, automated language and speech processing as well as capturing inter-relationship between various financial instruments. &lt;br/&gt;&lt;br/&gt;A generic application of Graphical model requires solving two basic tasks.  First, given data, what is an appropriate graphical model? And second, given a graphical model, how does one perform inference from partial observations? Historically, domain knowledge was used to choose the model, for example Hidden Markov Models in speech processing. Therefore, a significant amount of effort has been devoted to the second problem, of developing inference algorithms (for example, Belief propagation). However, it is not at all clear what type of model to use for most modern applications. Thus for modern applications the first problem of learning the model is paramount. The goal of this project is to develop understanding, both conceptual and algorithmic, of the problem of learning GMs from observed data. One aspect of the project is to derive new lower bounds in order to understand the interplay between fundamental statistical and computational limits. Informed by these lower bounds, the project will seek to determine new and relevant model subclasses for which learning is tractable accompanied by efficient learning algorithms.</AbstractNarration>
<MinAmdLetterDate>02/25/2015</MinAmdLetterDate>
<MaxAmdLetterDate>02/25/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1462158</AwardID>
<Investigator>
<FirstName>Devavrat</FirstName>
<LastName>Shah</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Devavrat Shah</PI_FULL_NAME>
<EmailAddress>devavrat@mit.edu</EmailAddress>
<PI_PHON>6172534670</PI_PHON>
<NSF_ID>000488392</NSF_ID>
<StartDate>02/25/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Gamarnik</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David Gamarnik</PI_FULL_NAME>
<EmailAddress>gamarnik@mit.edu</EmailAddress>
<PI_PHON>6172531000</PI_PHON>
<NSF_ID>000136664</NSF_ID>
<StartDate>02/25/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394703</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5514</Code>
<Text>OPERATIONS RESEARCH</Text>
</ProgramElement>
<ProgramReference>
<Code>072E</Code>
<Text>NETWORKS &amp; QUEUING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>073E</Code>
<Text>OPTIMIZATION &amp; DECISION MAKING</Text>
</ProgramReference>
<ProgramReference>
<Code>077E</Code>
<Text>SIMULATION MODELS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">The problem of recommendation systems provides an excellent surrogate to develop methods for learning graphical models with latent variables. Learning graphical models with latent variables, though extremely useful in practice, have limited theoretical foundations. For example, the classical Expectation-Maximization (EM) algorithm has been proposed since 1970s (by Dempster, Laird and Rubin), has been extremely well utilized in practice, but theoretical understanding of it's success is very limited.</p> <p class="p1">The fundamental challenge lies in actually defining the goal itself. In the standard setting, the goal is laid out at the ability learn the precise model. But that is fundamentally ill-defined in most settings with latent variables. Using recommendation systems as an example, it helps us overcome this challenge by concretely defining a well-posed question.&nbsp;&nbsp;</p> <p class="p1">Precisely, we view the question of recommendation systems as ``matrix estimation'' problem wherein there is an unknown ground-truth matrix. We observe a small subset of this entries. Each observed entry is a noisy version of the ground-truth matrix entry such that on average (with respect to noise distribution), it is equal to the ground-truth matrix entry. On one hand, this setup captures the classical recommendation system setting where we observe ratings of movies provided by users and thus the matrix is effectively the matrix of ratings with rows corresponding to users and columns corresponding to movies. The goal here is to estimate the missing rating entries between user-movie pairs, as well as de-noise the observed rating entries.&nbsp;</p> <p class="p1">On the other hand, this is exactly the model that describes the ``universal'' graph respresentations, also known as ``Graphons'' -- the matrix is the adjacency matrix, i.e. rows and column correspond to nodes of the graph and entries are 1 if there is an edge between pair of nodes and 0 otherwise (e.g. diagonal entries are all 0 if we assume there are no self-edges / loops). In the graphon setting, the model states that the edge is present between a pair of nodes with some probability and the goal is to precisely recover these edge probability simply by observing one instance of a graph.&nbsp;</p> <p class="p1">The matrix estimation setup, as described above is quite general and ability to solve it has much broader implications. The goal is not to recover the latent function or the latent features, but only recover the entries of the ground truth matrix faithfully. This makes the problem well-posed instead of ill-posed.&nbsp;&nbsp;</p> <p class="p1"><strong>Intellectual Merit.<span>&nbsp; </span></strong>In this project, we have developed `non-parametric? statistical framework for matrix estimation problem that has been missing in the literature. It has address the computational and statistical tradeoffs. In the process, we have explained why a popular recommendation algorithm, collaborative filtering, works well.<span>&nbsp;</span></p> <p class="p1"><strong>Broader Impact. </strong>The outcomes of this project has led to understanding of popular algorithm utilized in practice for more than three decades. This understanding, as a consequence, has led to systematic improvement of this algorithm. And thus resulting into impacting the practice of recommendation systems that is effectively everywhere in the modern online information processing systems.<span>&nbsp;</span></p> <p class="p1">The (female) advisees who participated in this project are professors at prestigious universities. The outcomes of the project has been disseminated through publications in conferences and journals, invited colloquiums and invited tutorials at premier venues (ISIT and NeurIPS).<span>&nbsp;</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 08/12/2020<br>      Modified by: Devavrat&nbsp;Shah</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The problem of recommendation systems provides an excellent surrogate to develop methods for learning graphical models with latent variables. Learning graphical models with latent variables, though extremely useful in practice, have limited theoretical foundations. For example, the classical Expectation-Maximization (EM) algorithm has been proposed since 1970s (by Dempster, Laird and Rubin), has been extremely well utilized in practice, but theoretical understanding of it's success is very limited. The fundamental challenge lies in actually defining the goal itself. In the standard setting, the goal is laid out at the ability learn the precise model. But that is fundamentally ill-defined in most settings with latent variables. Using recommendation systems as an example, it helps us overcome this challenge by concretely defining a well-posed question.   Precisely, we view the question of recommendation systems as ``matrix estimation'' problem wherein there is an unknown ground-truth matrix. We observe a small subset of this entries. Each observed entry is a noisy version of the ground-truth matrix entry such that on average (with respect to noise distribution), it is equal to the ground-truth matrix entry. On one hand, this setup captures the classical recommendation system setting where we observe ratings of movies provided by users and thus the matrix is effectively the matrix of ratings with rows corresponding to users and columns corresponding to movies. The goal here is to estimate the missing rating entries between user-movie pairs, as well as de-noise the observed rating entries.  On the other hand, this is exactly the model that describes the ``universal'' graph respresentations, also known as ``Graphons'' -- the matrix is the adjacency matrix, i.e. rows and column correspond to nodes of the graph and entries are 1 if there is an edge between pair of nodes and 0 otherwise (e.g. diagonal entries are all 0 if we assume there are no self-edges / loops). In the graphon setting, the model states that the edge is present between a pair of nodes with some probability and the goal is to precisely recover these edge probability simply by observing one instance of a graph.  The matrix estimation setup, as described above is quite general and ability to solve it has much broader implications. The goal is not to recover the latent function or the latent features, but only recover the entries of the ground truth matrix faithfully. This makes the problem well-posed instead of ill-posed.   Intellectual Merit.  In this project, we have developed `non-parametric? statistical framework for matrix estimation problem that has been missing in the literature. It has address the computational and statistical tradeoffs. In the process, we have explained why a popular recommendation algorithm, collaborative filtering, works well.  Broader Impact. The outcomes of this project has led to understanding of popular algorithm utilized in practice for more than three decades. This understanding, as a consequence, has led to systematic improvement of this algorithm. And thus resulting into impacting the practice of recommendation systems that is effectively everywhere in the modern online information processing systems.  The (female) advisees who participated in this project are professors at prestigious universities. The outcomes of the project has been disseminated through publications in conferences and journals, invited colloquiums and invited tutorials at premier venues (ISIT and NeurIPS).           Last Modified: 08/12/2020       Submitted by: Devavrat Shah]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
