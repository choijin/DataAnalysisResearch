<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER-DynamicData: Collaborative Research: Data-driven morphing of parsimonious models for the description of transient dynamics in complex systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>75000.00</AwardTotalIntnAmount>
<AwardAmount>75000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anthony Kuh</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Predicting and quantifying the behavior of complex systems in engineering and science is a topic of critical importance for many areas such as design, optimization, and safety. Even more critical is the forecast of extreme responses of these systems. Rare responses that can lead to catastrophic events manifest themselves in a wide range of systems such as geophysical phenomena, power and communication networks, and epileptic incidents in brain activity, just to mention a few. In all of these cases, accurate predictions are hampered by the fact that the exact dynamics of the system in nature is often poorly understood. This poor understanding is due to the large number of essentially coupled mechanisms that operate at different temporal and spatial scales. Although it is not always essential to predict the system with high accuracy over all these different levels, it is important to understand and model the effect of the unresolved mechanisms to the degrees of freedom we want to predict. This requires a reliable knowledge of the descriptive laws for these mechanisms as well as their coupling to the degrees-of-freedom of interest and this is clearly not always (well) done. This incomplete modeling of the dynamics leads to inevitable model error that is essential to be taken into account for reliable predictions. An obvious way that this can be done is by the utilization of available and dynamically incoming data. The goal of this work is the development of methods and algorithms to extend the capability for data-driven morphing (that is, data-driven adaptation) of parsimonious models. These will be able to adequately capture the instantaneously most significant dynamics of the system and utilize them to inexpensively perform informative prediction and uncertainty quantification. Such a development will be of critical importance for many fields where the modeling and predictive capacity is limited by the inadequate understanding of the underlying physical mechanisms.&lt;br/&gt;&lt;br/&gt;The aim of this proposal is to link machine learning with model reduction in a data-stream-driven environment, in order to formulate fundamentally novel methods for the probabilistic forecast of complex stochastic systems. Of particular interest is the quantification and prediction of extreme responses, by relying exclusively on the utilization of available data and with the minimum use of equations (or high fidelity solvers), if these are available. The effort is driven by the presence of serious obstacles associated with the prediction of such features in complex dynamical systems: non-negligible model error in the descriptive laws (if these are available), prohibitive cost for real time computations, sparse data or data with non-negligible error, and transient dynamics. These difficulties are manifest at a time when there is a great need for understanding and prediction of extreme responses in contexts such as climate dynamics, nonlinear waves, and networks of high dimensionality. The aim is to address several of theses challenges by constructing new stochastic prediction methods that will extend the existing state-of-the-art for data-driven modeling and prediction through the implementation (and appropriate extension) of machine learning / data mining techniques and the combination with stochastic order reduction and uncertainty quantification methods that dynamically adapt the reduced order subspace according to the dynamics. These efforts will be guided by a proof-of-concept application involving prediction of extreme, localized events in nonlinear waves. Adaptive reduced order models driven by data will be a key element for the inference of critical dynamical properties, which are otherwise "buried" in the complex responses. By linking machine learning techniques to adaptive reduced order models our research will catalyze new domains of numerical/mathematical analysis and it will extend the reach of more conventional mathematics-assisted modeling beyond some of its current limits.</AbstractNarration>
<MinAmdLetterDate>09/11/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1462241</AwardID>
<Investigator>
<FirstName>Yannis</FirstName>
<LastName>Kevrekidis</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yannis G Kevrekidis</PI_FULL_NAME>
<EmailAddress>yannis@princeton.edu</EmailAddress>
<PI_PHON>6092582818</PI_PHON>
<NSF_ID>000383357</NSF_ID>
<StartDate>09/11/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Trustees of Princeton University]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress><![CDATA[A319 Engineering Quadrangle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramElement>
<Code>O395</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>153E</Code>
<Text>Wireless comm &amp; sig processing</Text>
</ProgramReference>
<ProgramReference>
<Code>5384</Code>
<Text>DATA AND DATA SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~75000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Scientific computation lies at the core of our ability to predict the dynamics of physical and engineering systems, and thus to attempt to control and design them. Yet the complexity of many of these models (from drug molecules to weather patterns) their multiscale structure in both space and time, as well as their uncertainty, makes this computation often infeasible. The main idea of this proposal is to enhance our ability to perform these computations, and, in effect, to accelerate them to the level that they can become feasible, by linking the modeling with modern machine learning and data mining. If the <em>local</em> behavior of the models in space and time is relatively effectively simple, then modern manifold learning techniques, like diffusion maps, can be used to simplify the computations &ldquo;on the fly&rdquo; &ndash; one can use streams of incoming data (whether the data from the complicated computation itself, or data from physical measurements) to find locally simpler, good descriptors of the dynamics, and allow us to make predictions with these &ldquo;on the fly&rdquo; constructed, effectively simple surrogate models.&nbsp; And while the promise is there, the caveat is that these &ldquo;on demand&rdquo; constructed local simplifications that allow us to explore the behavior faster/better/simpler &ndash; they are useful mathematically, but not easy to understand physically. In effect, we create local useful transformations of the data that allow us to predict easier &ndash; but we lose often the physical, mechanistic understanding of this accurate prediction.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An area where model complexity becomes a major bottleneck to prediction, but also to engineering design and optimization, is the case of rare events: cases where the transition of interest (the folding of a protein, an extreme weather event, a rogue wave) occurs very infrequently, and having good statistics, or even acceptable predictors of it, becomes extremely computationally time-consuming. It is in cases like these that we have been able to use recently developed machine learning techniques to process the data produced &ldquo;on the fly&rdquo; by our simulations, create locally meaningful surrogate models, and then exploited these models to &ldquo;guide&rdquo; or &ldquo;bias&rdquo; the simulation towards regions that are more informative <em>for the task we are interested in</em>, e.g. for the prediction of protein folding. This linking, on the fly, of traditional modeling and scientific computation with modern manifold learning/machine learning tools is, we believe, a path that will become increasingly important in modern mathematical/physical modeling &ndash; it is both liberating in what it enables us to predict, and at the same time worrisome, since it &ldquo;does away&rdquo; with detailed physical understanding. In our work in this proposal we were able to demonstrate useful combinations of this &ldquo;traditional modeling linked with machine learning&rdquo; in accelerating molecular dynamics and kinetic Monte Carlo simulations of rare events. The training of a new generation of modelers, combining domain science knowledge, &ldquo;traditional&rdquo; state of the art computational methods and modern machine learning tools, which was in some measure realized in this work, will &ndash;we expect- become a hallmark of the training of our next generation of physical and engineering modelers.</p><br> <p>            Last Modified: 03/21/2019<br>      Modified by: Yannis&nbsp;G&nbsp;Kevrekidis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Scientific computation lies at the core of our ability to predict the dynamics of physical and engineering systems, and thus to attempt to control and design them. Yet the complexity of many of these models (from drug molecules to weather patterns) their multiscale structure in both space and time, as well as their uncertainty, makes this computation often infeasible. The main idea of this proposal is to enhance our ability to perform these computations, and, in effect, to accelerate them to the level that they can become feasible, by linking the modeling with modern machine learning and data mining. If the local behavior of the models in space and time is relatively effectively simple, then modern manifold learning techniques, like diffusion maps, can be used to simplify the computations "on the fly" &ndash; one can use streams of incoming data (whether the data from the complicated computation itself, or data from physical measurements) to find locally simpler, good descriptors of the dynamics, and allow us to make predictions with these "on the fly" constructed, effectively simple surrogate models.  And while the promise is there, the caveat is that these "on demand" constructed local simplifications that allow us to explore the behavior faster/better/simpler &ndash; they are useful mathematically, but not easy to understand physically. In effect, we create local useful transformations of the data that allow us to predict easier &ndash; but we lose often the physical, mechanistic understanding of this accurate prediction.                  An area where model complexity becomes a major bottleneck to prediction, but also to engineering design and optimization, is the case of rare events: cases where the transition of interest (the folding of a protein, an extreme weather event, a rogue wave) occurs very infrequently, and having good statistics, or even acceptable predictors of it, becomes extremely computationally time-consuming. It is in cases like these that we have been able to use recently developed machine learning techniques to process the data produced "on the fly" by our simulations, create locally meaningful surrogate models, and then exploited these models to "guide" or "bias" the simulation towards regions that are more informative for the task we are interested in, e.g. for the prediction of protein folding. This linking, on the fly, of traditional modeling and scientific computation with modern manifold learning/machine learning tools is, we believe, a path that will become increasingly important in modern mathematical/physical modeling &ndash; it is both liberating in what it enables us to predict, and at the same time worrisome, since it "does away" with detailed physical understanding. In our work in this proposal we were able to demonstrate useful combinations of this "traditional modeling linked with machine learning" in accelerating molecular dynamics and kinetic Monte Carlo simulations of rare events. The training of a new generation of modelers, combining domain science knowledge, "traditional" state of the art computational methods and modern machine learning tools, which was in some measure realized in this work, will &ndash;we expect- become a hallmark of the training of our next generation of physical and engineering modelers.       Last Modified: 03/21/2019       Submitted by: Yannis G Kevrekidis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
