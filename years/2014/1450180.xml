<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: SI2-SSI: Big Weather Web: A Common and Sustainable Big Data Infrastructure in Support of Weather Prediction Research and Education in Universities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>98702.00</AwardTotalIntnAmount>
<AwardAmount>98702</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Bogdan Mihaila</SignBlockName>
<PO_EMAI>bmihaila@nsf.gov</PO_EMAI>
<PO_PHON>7032928235</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Earth science communities need to rely on access to large and growing amounts of curated data to make progress in research and provide adequate education. Existing infrastructures pose significant barriers to this access, especially for small to mid-size research groups and primarily undergraduate institutions: cloud services disappear when funding runs out to pay for them and therefore do not provide the long-term availability required for curated data. Similarly, in-house IT infrastructure is maintenance-intensive and requires dedicated resources for which long-term funding is often unavailable. The goal of the Big Weather Web is to make in-house IT infrastructure affordable by combining the application of three recent technologies: virtualization, federated smart storage, and big data management. Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution. Due to virtualization, it can easily take advantage of cloud services whenever they become available, and it can run on in-house IT infrastructure using significantly reduced maintenance resources. The Big Weather Web will be developed in the context of numerical weather prediction with the expectation that the resulting infrastructure can be easily adapted to other data-intensive scientific communities.&lt;br/&gt;&lt;br/&gt;The volume, variety, and velocity of scientific data generated is growing exponentially. Small to mid-size research groups and especially primarily undergraduate institutions (PUIs) do not have the resources to manage large amounts of data locally and share their data products globally at high availability. This lack of resources has a number of consequences in education and research that have been well-documented in recent EarthCube workshops: (1) data-intensive scientific results are not easily reproducible, whether in the context of research or education, (2) limited or non-existent availability of intermediate results causes a lot of unnecessary duplication of work and makes learning curves unnecessarily steep, and consequently (3) scientific communities of practice are falling behind technological innovations. This Big Weather Web project focuses on the numerical weather prediction community. Numerical weather models produce terabytes of output per day, comprising a wealth of information that can be used for research and education, but this amount of data is difficult to transfer, store, or analyze for most universities. The Big Weather Web addresses this situation with the design, implementation, and deployment of "nuclei," which are shared artifacts that enable reliable and efficient access and sharing of data, encode best practices, and are sustainably maintained and improved by the community. These nuclei use existing and well-established technologies, but the integration of these technologies will significantly reduce the resource burden mentioned above. Nucleus 1 is a large ensemble distributed over seven universities. Nucleus 2 is a common storage, linking, and cataloging methodology implemented as an appliance-like Data Investigation and Sharing Environment (DISE) that is extremely easy to maintain and that automatically ensures data availability and safety. Nucleus 3 is a versioned virtualization and container technology for easy deployment and reproducibility of computational environments. Together, these nuclei will advance discovery and understanding through sharing of data products and methods to replicate scientific results while promoting teaching, training, and learning by creating a shared environment for scientific communities of practice. These shared environments are particularly important for underrepresented groups who otherwise have limited access to knowledge that is primarily propagated by social means. Our approach is a significant step towards improving reproducibility in the complex computational environments found in many scientific communities.</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1450180</AwardID>
<Investigator>
<FirstName>Mohan</FirstName>
<LastName>Ramamurthy</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mohan K Ramamurthy</PI_FULL_NAME>
<EmailAddress>mohan@ucar.edu</EmailAddress>
<PI_PHON>3034978661</PI_PHON>
<NSF_ID>000362575</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University Corporation For Atmospheric Res</Name>
<CityName>Boulder</CityName>
<ZipCode>803012252</ZipCode>
<PhoneNumber>3034971000</PhoneNumber>
<StreetAddress>3090 Center Green Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078339587</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY CORPORATION FOR ATMOSPHERIC RESEARCH</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>078339587</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University Corporation For Atmospheric Res]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803055602</ZipCode>
<StreetAddress><![CDATA[1850 Table Mesa]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1525</Code>
<Text>Physical &amp; Dynamic Meteorology</Text>
</ProgramElement>
<ProgramElement>
<Code>8004</Code>
<Text>Software Institutes</Text>
</ProgramElement>
<ProgramElement>
<Code>8074</Code>
<Text>EarthCube</Text>
</ProgramElement>
<ProgramReference>
<Code>4444</Code>
<Text>INTERDISCIPLINARY PROPOSALS</Text>
</ProgramReference>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8009</Code>
<Text>Scientifc Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~98702</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the Big Weather Web project is to make big data infrastructure affordable and adequate for university researchers and educators in the Numerical Weather Prediction community by combining the application of recent technologies: computing and storage infrastructure, including data and software as a service, virtualization, and big data management.&nbsp;</p> <p>Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone&rsquo;s contribution.&nbsp;</p> <p>Our work during the period of performance of the project focused on the continued development of the big data infrastructure and associated components in a cloud environment. As data volumes grow rapidly, it is important to reduce data movement and bring processing and computations to the data. Data providers also need to give scientists an ecosystem that includes data, tools, and workflows. Instead of moving data to processing systems near users, Unidata has been working to bring analysis and visualization to data &ndash; so called data proximate modeling, analysis and visualization capabilities.</p> <p>In executing its current plan, we developed data-driven scientific workflows using cloud computing technologies for accessing, analyzing, and visualizing geoscience data. To that end, the Unidata Science Gateway (http://science-gateway.unidata.ucar.edu) was implemented on the NSF-funded Jetstream (https://jetstream-cloud.org) cloud facility. Through the Science Gateway, researchers can make use of well-integrated resources either directly in their browser or using one of the client applications.</p> <p>Currently, the Unidata Gateway provides the following functionalities:</p> <ol> <li>Access to large volumes of meteorological data, via several application program interfaces and protocols, including access to subsets of data</li> <li>Data transformation and format conversion tools</li> <li>Extensive data analysis capabilities</li> <li>Visualization of data provided by the gateway</li> <li>Access to a collection of Jupyter Notebooks and Docker containers for data analysis</li> <li>Access to Advanced Weather Information Processing System data server from a client application</li> </ol> <p>Real-time data from over 30 meteorological data streams, in excess of 1.5 TB/day, flow into the Gateway data servers via the Local Data Manager software, a TCP/IP-based data transfer technology. Those data include radar, satellite, surface, upper-air, ship, aircraft and other observations as well as forecast model output from operational weather prediction centers.</p> <p>Through the above efforts, the project developed techniques that combine robust access to well-documented datasets with easy-to-use tools, using workflow technologies such as JupyterHub. In addition to fostering the adoption of technologies like Jupyter notebooks and other computational and analytic methods are enabled through &ldquo;Software as a Service&rdquo; and &ldquo;Data as a Service&rdquo; techniques via the deployment of several tools. The collective impact of these services and tools is to advance the goals of Reproducibility of Science, Open Science, and truly enable &ldquo;Science as a Service&rdquo;.</p> <p>As a complement to the Big Weather Web project goals, the Unidata Program Center organized a community workshop on &ldquo;Data-Driven Geoscience: Applications, Opportunities, Trends, and Challenges&rdquo; on June 22-25, 2015. The aforementioned theme was chosen to encourage workshop participants become more aware of emerging technologies and workflows loosely grouped under the topics of: Python, big data, cloud computing, and data management. Bringing together participants from academia, federal agencies, the commercial sector, and the Big Weather Web project personnel, the workshop aimed to provide instruction, hands-on experience, and discussion touching on all of the workshop topics. Selected community members were invited to share their knowledge and experience with the workshop participants, providing a true community forum for discussion of ways to take advantage of new technologies to improve research and education.</p><br> <p>            Last Modified: 10/15/2019<br>      Modified by: Mohan&nbsp;K&nbsp;Ramamurthy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the Big Weather Web project is to make big data infrastructure affordable and adequate for university researchers and educators in the Numerical Weather Prediction community by combining the application of recent technologies: computing and storage infrastructure, including data and software as a service, virtualization, and big data management.   Virtualization allows push-button deployment and maintenance of complex systems, smart storage provides automatic, community-wide data availability guarantees, and big data management allows for easy curation of data and its products. The combination of these three technologies allows communities to create a standard community-specific computational environment and efficiently refine it with minimal repetition of work, introducing a high degree of reproducibility in research and education. This reproducibility accelerates learning and amplifies everyone?s contribution.   Our work during the period of performance of the project focused on the continued development of the big data infrastructure and associated components in a cloud environment. As data volumes grow rapidly, it is important to reduce data movement and bring processing and computations to the data. Data providers also need to give scientists an ecosystem that includes data, tools, and workflows. Instead of moving data to processing systems near users, Unidata has been working to bring analysis and visualization to data &ndash; so called data proximate modeling, analysis and visualization capabilities.  In executing its current plan, we developed data-driven scientific workflows using cloud computing technologies for accessing, analyzing, and visualizing geoscience data. To that end, the Unidata Science Gateway (http://science-gateway.unidata.ucar.edu) was implemented on the NSF-funded Jetstream (https://jetstream-cloud.org) cloud facility. Through the Science Gateway, researchers can make use of well-integrated resources either directly in their browser or using one of the client applications.  Currently, the Unidata Gateway provides the following functionalities:  Access to large volumes of meteorological data, via several application program interfaces and protocols, including access to subsets of data Data transformation and format conversion tools Extensive data analysis capabilities Visualization of data provided by the gateway Access to a collection of Jupyter Notebooks and Docker containers for data analysis Access to Advanced Weather Information Processing System data server from a client application   Real-time data from over 30 meteorological data streams, in excess of 1.5 TB/day, flow into the Gateway data servers via the Local Data Manager software, a TCP/IP-based data transfer technology. Those data include radar, satellite, surface, upper-air, ship, aircraft and other observations as well as forecast model output from operational weather prediction centers.  Through the above efforts, the project developed techniques that combine robust access to well-documented datasets with easy-to-use tools, using workflow technologies such as JupyterHub. In addition to fostering the adoption of technologies like Jupyter notebooks and other computational and analytic methods are enabled through "Software as a Service" and "Data as a Service" techniques via the deployment of several tools. The collective impact of these services and tools is to advance the goals of Reproducibility of Science, Open Science, and truly enable "Science as a Service".  As a complement to the Big Weather Web project goals, the Unidata Program Center organized a community workshop on "Data-Driven Geoscience: Applications, Opportunities, Trends, and Challenges" on June 22-25, 2015. The aforementioned theme was chosen to encourage workshop participants become more aware of emerging technologies and workflows loosely grouped under the topics of: Python, big data, cloud computing, and data management. Bringing together participants from academia, federal agencies, the commercial sector, and the Big Weather Web project personnel, the workshop aimed to provide instruction, hands-on experience, and discussion touching on all of the workshop topics. Selected community members were invited to share their knowledge and experience with the workshop participants, providing a true community forum for discussion of ways to take advantage of new technologies to improve research and education.       Last Modified: 10/15/2019       Submitted by: Mohan K Ramamurthy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
