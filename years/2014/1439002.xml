<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS: EXPL: CCA: Collaborative Research: Nixing Scale Bugs in HPC Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>166000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Large-scale simulation is a fundamental component of modern science and engineering. Unfortunately, programs written to perform simulations on large-scale parallel computers frequently suffer from software defects that result from the sheer scale and the variety of parallelization approaches employed. Especially egregious are software bugs that occur when large resource allocations (e.g., memory requests) are made. Formally based active-testing techniques are essential to locate such defects. However, these testing tools are themselves seldom run on parallel machines, let alone at large scale, making it difficult and very time consuming to find scale bugs with high assurance. &lt;br/&gt;&lt;br/&gt;Efforts to parallelize verification tools should reuse existing technology for easy parallelization, result collection, and fault handling. Key innovations of this project include the insight that large-scale verification runs can be described through work-flows, which makes it possible to take advantage of already available distributed computing platforms, in particular Swift/T from Argonne. The complementary backgrounds of the PIs are well matched with the need to push both formal aspects and distributed verification in the context of three widely-used concurrency models, namely MPI, OpenMP, and CUDA. &lt;br/&gt;&lt;br/&gt;This work will help create a public distributed formal active testing framework. The tools and case-study software driving this research will be maintained by the PIs and released freely under open-source licenses through websites and repositories. They will facilitate large-scale debugging of scientific simulation codes by researchers and software developers in academia, government labs, and industry. &lt;br/&gt;&lt;br/&gt;The project will also generate pedagogical material and best practices, helping educate students in the use of existing work-flow based problem solving approaches. It will help train present and future scientists, engineers, and programmers, thus assisting in maintaining our nation's leadership in computing, homeland and energy security, and STEM education.</AbstractNarration>
<MinAmdLetterDate>08/06/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/06/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1439002</AwardID>
<Investigator>
<FirstName>Ganesh</FirstName>
<LastName>Gopalakrishnan</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ganesh L Gopalakrishnan</PI_FULL_NAME>
<EmailAddress>ganesh@cs.utah.edu</EmailAddress>
<PI_PHON>8015813568</PI_PHON>
<NSF_ID>000160895</NSF_ID>
<StartDate>08/06/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<StreetAddress2><![CDATA[Second Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009095365</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF UTAH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009095365</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Utah]]></Name>
<CityName/>
<StateCode>UT</StateCode>
<ZipCode>841129205</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<ProgramReference>
<Code>8206</Code>
<Text>Formal Methods and Verification</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~150000</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>It is widely acknowledged that in the coming years leading up to exascale computing, the increase and scale in heterogeneity of parallel computing systems will exacerbate the difficulty of debugging. While solutions are being developed to detect specific types of bugs, the need to run an entire application in order to bring out sufficient information to narrow down the likely type of bug and find its root-cause in a large code base will vastly increase overall debugging time. It will also result in wasted compute resources whose allocations are expensive.</p> <p>This project takes a clean slate design wherein trace collection is proposed to be almost always enabled. To reduce the cost of such tracing, we employ binary instrumentation and also trace compression methods that are adaptive and learned through training.</p> <p>One of the key results of this work has been the demonstration of such binary tracing methods. Another key contribution we make is the analysis of the traces to narrow down the likely set of processes as well as their internal actions responsible for the bug. For this purpose, we develop two approaches: similarity finding methods based onconcept-lattice that help detect outlier executions, and the mining of execution loops within processes and representing themas regular expressions.</p> <p>Key intellectual contributions include binary tracing, flexible concept lattice computations based on a varity of attributes, and scalable loop mining and construction of regular expressions for sharply characterizing execution differences.&nbsp; Key broader impacts include increased programmer productivity through rapid bug-finding. The project has been vital for the training of a PhD student who will, in about year, be part of the workforce we need to tame the complexity of parallel and concurrent computing systems.<br /><br /></p><br> <p>            Last Modified: 12/21/2018<br>      Modified by: Ganesh&nbsp;L&nbsp;Gopalakrishnan</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1439002/1439002_10329164_1545370983604_similarity-matrices--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1439002/1439002_10329164_1545370983604_similarity-matrices--rgov-800width.jpg" title="Similarity matrices of MPI processes"><img src="/por/images/Reports/POR/2018/1439002/1439002_10329164_1545370983604_similarity-matrices--rgov-66x44.jpg" alt="Similarity matrices of MPI processes"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Similarity matrices between all pairs of processes</div> <div class="imageCredit">Saeed Taheri</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div> <div class="imageTitle">Similarity matrices of MPI processes</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1439002/1439002_10329164_1545371124874_diff-mrr--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1439002/1439002_10329164_1545371124874_diff-mrr--rgov-800width.jpg" title="Difference between repetitive patterns"><img src="/por/images/Reports/POR/2018/1439002/1439002_10329164_1545371124874_diff-mrr--rgov-66x44.jpg" alt="Difference between repetitive patterns"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Difference between two processes where we highlight the differences between repetitive structures.</div> <div class="imageCredit">Saeed Taheri</div> <div class="imageSubmitted">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div> <div class="imageTitle">Difference between repetitive patterns</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ It is widely acknowledged that in the coming years leading up to exascale computing, the increase and scale in heterogeneity of parallel computing systems will exacerbate the difficulty of debugging. While solutions are being developed to detect specific types of bugs, the need to run an entire application in order to bring out sufficient information to narrow down the likely type of bug and find its root-cause in a large code base will vastly increase overall debugging time. It will also result in wasted compute resources whose allocations are expensive.  This project takes a clean slate design wherein trace collection is proposed to be almost always enabled. To reduce the cost of such tracing, we employ binary instrumentation and also trace compression methods that are adaptive and learned through training.  One of the key results of this work has been the demonstration of such binary tracing methods. Another key contribution we make is the analysis of the traces to narrow down the likely set of processes as well as their internal actions responsible for the bug. For this purpose, we develop two approaches: similarity finding methods based onconcept-lattice that help detect outlier executions, and the mining of execution loops within processes and representing themas regular expressions.  Key intellectual contributions include binary tracing, flexible concept lattice computations based on a varity of attributes, and scalable loop mining and construction of regular expressions for sharply characterizing execution differences.  Key broader impacts include increased programmer productivity through rapid bug-finding. The project has been vital for the training of a PhD student who will, in about year, be part of the workforce we need to tame the complexity of parallel and concurrent computing systems.         Last Modified: 12/21/2018       Submitted by: Ganesh L Gopalakrishnan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
