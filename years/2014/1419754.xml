<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Inference After Predictor Selection</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>139999.00</AwardTotalIntnAmount>
<AwardAmount>139999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>There are three goals for this project.  The first goal is to develop data-driven assessments of the complexity of data generators and data-driven assessments of the complexity of the predictive techniques to be used for a data generator and then relate them to each other.   It is expected that a complexity matching principle between data generators and their predictors will be established.  The motivation is to speed the search for predictors that have low generalization error.  The second goal is to develop techniques to derive modeling information from good predictors.  The motivation is to be able to make statements about the data generator beyond numerical prediction.  The third goal is to use these techniques on a complex data set for which a predictive approach is essential because the extreme complexity of the data means it defies conventional modeling.  The motivation is to verify that the complexity based techniques give reliable inferences for an important question such as `which of those who have suffered a traumatic event are likely to get post- traumatic stress disorder'.&lt;br/&gt;&lt;br/&gt;The motivation for the overall project is to find ways to get information out of data that is so complex conventional techniques are ineffective.   Such data is becoming increasingly common as the number of data types increases and as data bases become more comprehensive.  The problem with conventional techniques seems to be that they assume a model that means something physically before there is a strong enough basis even to propose one.   The approach here is significant because it is overtly predictive:  Instead of proposing models, one can propose predictors that are easier to test and then study the predictors to make statements about whatever it was that generated the data.  This reverses the usual approach in which one models first and then predicts.</AbstractNarration>
<MinAmdLetterDate>01/27/2014</MinAmdLetterDate>
<MaxAmdLetterDate>01/27/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1419754</AwardID>
<Investigator>
<FirstName>BERTRAND</FirstName>
<LastName>CLARKE</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>BERTRAND CLARKE</PI_FULL_NAME>
<EmailAddress>bclarke3@unl.edu</EmailAddress>
<PI_PHON>4024725574</PI_PHON>
<NSF_ID>000577074</NSF_ID>
<StartDate>01/27/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Nebraska-Lincoln</Name>
<CityName>Lincoln</CityName>
<ZipCode>685031435</ZipCode>
<PhoneNumber>4024723171</PhoneNumber>
<StreetAddress>151 Prem S. Paul Research Center</StreetAddress>
<StreetAddress2><![CDATA[2200 Vine St]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<StateCode>NE</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NE01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555456995</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BOARD OF REGENTS OF THE UNIVERSITY OF NEBRASKA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068662618</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Nebraska-Lincoln]]></Name>
<CityName/>
<StateCode>NE</StateCode>
<ZipCode>685880430</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NE01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~139999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>The goal of this project was to develop and evaluate predictors from a</p> <p>complexity perspective and study their interpretability.&nbsp; This is important</p> <p>because usually the best predictors are complex and do not readily admit an</p> <p>interpretation, i.e., there is a tradeoff berween interpretability and</p> <p>performance.</p> <p>&nbsp;</p> <p>The single biggest outcome was to the development of a technique to</p> <p>select a model because models are often used can to give predictions.&nbsp;</p> <p>The technique is based on a form of complexity called the Vapnik-</p> <p>Chervonenkis dimension that arises from statistical theory. &nbsp; We operationalize</p> <p>its use and show it is effective in numerous problems.&nbsp;</p> <p>&nbsp;</p> <p>Another major outcome was showing that many of the best and most used</p> <p>predictors can be regarded as instances of a `Bayes model averge' or `Bayes</p> <p>classifier'.&nbsp; Both of these are optimal in various senses.&nbsp; This sort of result</p> <p>is useful because it identifies and narrrows the class of predictors that has</p> <p>to be searched to find a good one.&nbsp;&nbsp; This is important because many</p> <p>of the best predictors are ensemble predictors that pool the</p> <p>predictions from a variety of predictors, hopefully in an optimal way.&nbsp; Thus, in</p> <p>many cases, the process of finding a predictor may be simplified.</p> <p>&nbsp;</p> <p>We also established properties of specific predictor classes.&nbsp; For the Shtarkov</p> <p>predictor, we showed it often outperforms a variety of other predictors in</p> <p>empirical error, sometimes by a wide margin.&nbsp; Interestingly, this complexity</p> <p>based predictor often performs worse when `too much' information, including</p> <p>extraneous information, is used to form it.&nbsp; We also established conceptual</p> <p>interpretations for it.&nbsp;&nbsp; The value of these contributions rests on future</p> <p>research.</p> <p>&nbsp;</p> <p>Stacking is another ensemble predictor.&nbsp; It is distinctive because of its</p> <p>generality -- it can be used to pool the predictions from any class of</p> <p>predictors and the weights it assigns to the predictions are more</p> <p>data-driven than for other predictors.&nbsp; We have shown a variety of</p> <p>results on this class of predictors providing conditions under which they</p> <p>are optimal, and showing that the weights, although flexible, are also</p> <p>optimal in a specific sense.</p> <p>&nbsp;</p> <p>For `kernel' based predictors, we first showed they behave well in the sense</p> <p>of giving good prediction when sample size increases.&nbsp; Then, we were</p> <p>able to show that they could be expressed in terms of functions derived</p> <p>from the kernels and therefore could be well-approximated in many cases</p> <p>by routine methods.&nbsp; We hope that practitioners who are reluctant to use</p> <p>techniques they cannot interpret (such as kernel based predictors) will</p> <p>recognize that our results provide an approximate interpretation.&nbsp; Thus,</p> <p>practitioners will be more willing to use this class of predictors that often</p> <p>gives extremely good performance.</p> <p>&nbsp;</p> <p>We have a variety of other results of a similar nature for other predictors.</p> <p>&nbsp;</p> <p>Taken together, our results show that not only is predictive performance</p> <p>a good criterion to invoke in statistical analyses, it is computationally feasible,</p> <p>often permits interpretation i.e., often permits at least a partial physical</p> <p>understanding of the problem being addressed, and can be conceptually</p> <p>understood in terms of familiar quantities.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/06/2017<br>      Modified by: Bertrand&nbsp;Clarke</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    The goal of this project was to develop and evaluate predictors from a  complexity perspective and study their interpretability.  This is important  because usually the best predictors are complex and do not readily admit an  interpretation, i.e., there is a tradeoff berween interpretability and  performance.     The single biggest outcome was to the development of a technique to  select a model because models are often used can to give predictions.   The technique is based on a form of complexity called the Vapnik-  Chervonenkis dimension that arises from statistical theory.   We operationalize  its use and show it is effective in numerous problems.      Another major outcome was showing that many of the best and most used  predictors can be regarded as instances of a `Bayes model averge' or `Bayes  classifier'.  Both of these are optimal in various senses.  This sort of result  is useful because it identifies and narrrows the class of predictors that has  to be searched to find a good one.   This is important because many  of the best predictors are ensemble predictors that pool the  predictions from a variety of predictors, hopefully in an optimal way.  Thus, in  many cases, the process of finding a predictor may be simplified.     We also established properties of specific predictor classes.  For the Shtarkov  predictor, we showed it often outperforms a variety of other predictors in  empirical error, sometimes by a wide margin.  Interestingly, this complexity  based predictor often performs worse when `too much' information, including  extraneous information, is used to form it.  We also established conceptual  interpretations for it.   The value of these contributions rests on future  research.     Stacking is another ensemble predictor.  It is distinctive because of its  generality -- it can be used to pool the predictions from any class of  predictors and the weights it assigns to the predictions are more  data-driven than for other predictors.  We have shown a variety of  results on this class of predictors providing conditions under which they  are optimal, and showing that the weights, although flexible, are also  optimal in a specific sense.     For `kernel' based predictors, we first showed they behave well in the sense  of giving good prediction when sample size increases.  Then, we were  able to show that they could be expressed in terms of functions derived  from the kernels and therefore could be well-approximated in many cases  by routine methods.  We hope that practitioners who are reluctant to use  techniques they cannot interpret (such as kernel based predictors) will  recognize that our results provide an approximate interpretation.  Thus,  practitioners will be more willing to use this class of predictors that often  gives extremely good performance.     We have a variety of other results of a similar nature for other predictors.     Taken together, our results show that not only is predictive performance  a good criterion to invoke in statistical analyses, it is computationally feasible,  often permits interpretation i.e., often permits at least a partial physical  understanding of the problem being addressed, and can be conceptually  understood in terms of familiar quantities.                         Last Modified: 08/06/2017       Submitted by: Bertrand Clarke]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
