<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Cognitive modeling of strategies for dealing with errors in mobile touch interfaces</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>281076.00</AwardTotalIntnAmount>
<AwardAmount>281076</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Touch interfaces on mobile phones and tablets are notoriously error prone. One plausible reason for slow progress in improving the usability of touchscreen devices is that research and design efforts in human-computer interaction take a relatively narrow focus on identifying, understanding, and eliminating human error, focusing primarily on the specific individual touch interactions rather than the broader task knowledge that a person needs to use a device to do a real-world task. This project takes a different perspective, suggesting that usage errors represent breakdowns in a person's efforts to adapt to the complexity of the tasks and devices, and that many of these problems can be traced to interface designers not inadequately considering the cognitive task knowledge that a user will need to do a task. Many touchscreen design guidelines are arbitrary and based on common practice and established user expectations. This project aims to change the shape of research and practice for touch interaction on mobile devices by introducing sound scientific principles of cognitive task analysis and error analysis to the design and analysis of such interfaces. This project could benefit society by dramatically improving the user interface design of touchscreen interfaces.&lt;br/&gt;&lt;br/&gt;The project will develop cognitive models, which are computer programs that behave in some way like humans. The project will specifically develop cognitive models of touch interaction that could be used by designers when designing new touchscreen interfaces, to identify where users are likely to encounter problems with the new interface. The project includes three stages. The first stage will develop a small set of instrumented interfaces on mobile platforms to collect human data for error-prone tasks. The experiments will examine the variation of the probability of error at specific points during a sequence, the visual feedback provided for specific actions, and the user knowledge of error recovery and avoidance actions. The second stage will follow other successful efforts in cognitive modeling to analyze user data from our exploratory experiment with the goal of developing a representation of the strategies we have observed. An automated process will explore a search space of plausible cognitive strategies to identify models that explain the performance data collected during the first stage. The third stage will validate the hypotheses pertaining to the cognitive strategies that contribute to the successful and unsuccessful use of touchscreen devices that are established during the first two stages. The results will have much wider implications than current models of touch accuracy (which produce little more than target size and spacing guidelines) by focusing on the bigger picture of expertise and failure. The project takes a large step into the cognitive modeling of pervasive but not-yet-unexplored interface problems.</AbstractNarration>
<MinAmdLetterDate>08/21/2014</MinAmdLetterDate>
<MaxAmdLetterDate>10/26/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1451172</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>St. Amant</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert A St. Amant</PI_FULL_NAME>
<EmailAddress>stamant@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195157938</PI_PHON>
<NSF_ID>000451837</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate>02/23/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Laurie</FirstName>
<LastName>Williams</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Laurie Williams</PI_FULL_NAME>
<EmailAddress>williams@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195134151</PI_PHON>
<NSF_ID>000193117</NSF_ID>
<StartDate>10/26/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Emerson</FirstName>
<LastName>Murphy-Hill</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emerson R Murphy-Hill</PI_FULL_NAME>
<EmailAddress>emerson@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195152444</PI_PHON>
<NSF_ID>000578912</NSF_ID>
<StartDate>02/23/2017</StartDate>
<EndDate>10/26/2018</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Emerson</FirstName>
<LastName>Murphy-Hill</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emerson R Murphy-Hill</PI_FULL_NAME>
<EmailAddress>emerson@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195152444</PI_PHON>
<NSF_ID>000578912</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate>02/23/2017</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276958206</ZipCode>
<StreetAddress><![CDATA[Box 8206]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~281076</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Touchscreens have seen widespread adoption in the last decade due to the rise of smartphones, tablets, and touchscreen laptops. New interaction techniques have emerged that match the capabilities of touch interfaces, with advantages for usability, but one problem has worsened: the probability that an error will occur in the basic task of choosing interface elements has significantly increased over point-and-click interactions. The limits of the human motor system have been documented extensively, and fingers are not precise input devices. Our approach is to develop cognitive models of users&rsquo; actions in this context. Computational modeling is a staple in cognitive science, an interdisciplinary field that integrates theories from psychology, physiology, and computation, in order to explore human cognition.</p> <p>Researchers in human-computer interaction increasingly see the value of being able to predict user performance on a given task, by use of a model, before conducting user studies.&nbsp; Models derived from observed user behavior can also shed light on the cognitive strategies and microstrategies that may generalize to other domains, a topic of interest among cognitive scientists.</p> <p>The dissertation supported by this work makes three contributions. First, we present an extension to Cogulator, an open source cognitive modeling program, that allows for probabilistic branching and looping behavior in Goals, Operators, Methods, and Selection Rules (GOMS) models. Second, we used that extension to identify and model the low level cognitive strategies that users apply in recovering from touch-screen target selection errors. Cognitive modelers interested in touchscreen interactions can use this information to better simulate real human performance. Lastly, we developed interaction guidelines for visual feedback that can assist users in recovering more quickly.&nbsp; These guidelines are as follows:</p> <ul> </ul> <ul> <li>Layout should have a logical order so that future actions can be predicted.</li> <li>Prevent users from completing subsequent actions without first correcting errors.</li> <li>Provide undo functionality.</li> <li>Visual feedback should be shown when target selection errors occur.</li> <li>Do not violate previously held expectations.</li> <li>Avoid forcing the user to context switch.</li> <li>Place visual feedback for target selection errors in the user&rsquo;s field of attention.</li> </ul> <ul> </ul><br> <p>            Last Modified: 12/04/2019<br>      Modified by: Laurie&nbsp;Williams</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Touchscreens have seen widespread adoption in the last decade due to the rise of smartphones, tablets, and touchscreen laptops. New interaction techniques have emerged that match the capabilities of touch interfaces, with advantages for usability, but one problem has worsened: the probability that an error will occur in the basic task of choosing interface elements has significantly increased over point-and-click interactions. The limits of the human motor system have been documented extensively, and fingers are not precise input devices. Our approach is to develop cognitive models of users’ actions in this context. Computational modeling is a staple in cognitive science, an interdisciplinary field that integrates theories from psychology, physiology, and computation, in order to explore human cognition.  Researchers in human-computer interaction increasingly see the value of being able to predict user performance on a given task, by use of a model, before conducting user studies.  Models derived from observed user behavior can also shed light on the cognitive strategies and microstrategies that may generalize to other domains, a topic of interest among cognitive scientists.  The dissertation supported by this work makes three contributions. First, we present an extension to Cogulator, an open source cognitive modeling program, that allows for probabilistic branching and looping behavior in Goals, Operators, Methods, and Selection Rules (GOMS) models. Second, we used that extension to identify and model the low level cognitive strategies that users apply in recovering from touch-screen target selection errors. Cognitive modelers interested in touchscreen interactions can use this information to better simulate real human performance. Lastly, we developed interaction guidelines for visual feedback that can assist users in recovering more quickly.  These guidelines are as follows:    Layout should have a logical order so that future actions can be predicted. Prevent users from completing subsequent actions without first correcting errors. Provide undo functionality. Visual feedback should be shown when target selection errors occur. Do not violate previously held expectations. Avoid forcing the user to context switch. Place visual feedback for target selection errors in the user’s field of attention.          Last Modified: 12/04/2019       Submitted by: Laurie Williams]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
