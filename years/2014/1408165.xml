<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RUI: CCSS: Collaborative Research: Cooperative Unmanned Aerial Vehicles Enabled Scalable Mobile Panoramic Video Surveillance</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>221826.00</AwardTotalIntnAmount>
<AwardAmount>237826</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jenshan Lin</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project investigates a cyber-physical system (CPS) in which cooperative unmanned aerial vehicles (UAVs) are used to enable scalable mobile panoramic video surveillance. This system generates mobile real-time video panorama by flying a fleet of cooperative UAVs. It is an interdisciplinary collaborative effort that synthesizes the expertise of Computer Science and Aerospace Engineering. This project demonstrates a convergence of sensing, control and communication. The project will generate outcomes including distributed video stitching algorithms, scalable distributed systems, and cooperative optimal flight control algorithms. This project significantly improves the performance such as delay and error in video panorama results. It advances the frontiers of both video processing and control theory. This interdisciplinary effort will promote and contribute to crosscutting collaborations between two research communities: computer science and aerospace engineering. The project aims to improve the education of underrepresented student populations by involving them in the proposed research activities and enhancing course curriculum. Results of this project have broad applications to areas such as remote sensing, environmental sampling and monitoring, homeland security, etc.  &lt;br/&gt;&lt;br/&gt;The project has three research thrusts: 1) distributed hierarchical video stitching to generate mobile video panorama across cooperative UAVs with high scalability, 2) integrated optimal cooperative control of UAV formation flying to support the distributed video stitching, and 3) integration, interfacing and communication to unite the distributed hierarchical video stitching and the cooperative control of formation flying. A prototype system will be developed for evaluation. It has four salient merits. First, the distributed hierarchical architecture is scalable to mobile cameras and fault-tolerant. Second, it exploits the temporal and spatial features of video frames for efficient computation. Third, the integrated optimal cooperative flight control addresses the multiple cooperative objectives in one unified framework, and provides a computationally efficient, distributed and control. Forth, the unification of distributed video stitching and cooperative control of UAV facilitates the generation of mobile video panorama. In particular, the distributed video stitching minimizes the stress of intensive computation required in stitching. It maintains high synchronization among video frames by pushing the stitching to the front close to the cameras. The proposed hierarchical video stitching significantly contributes to distributed system theory and algorithms. In addition, the stitching algorithms exploit the spatial and temporal correlation among UAV videos, yielding a novel contribution to computer graphics/vision. The proposed optimal cooperative control method will significantly advance the cooperative control of multi-vehicle or multi-agent systems. It integrates many challenging cooperative problems into one unified optimization framework.  This method enables a number of desired capabilities: closed-form, distributed and local information based control law, synchronous formation, cooperative tracking, and obstacle/collision avoidance. These integrated features not only make precise and real-time cooperative surveillance possible, but also move forward the cooperative control theory to a new horizon for a wide range of cooperative missions.</AbstractNarration>
<MinAmdLetterDate>08/19/2014</MinAmdLetterDate>
<MaxAmdLetterDate>01/05/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1408165</AwardID>
<Investigator>
<FirstName>Shaoen</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shaoen Wu</PI_FULL_NAME>
<EmailAddress>swu1235@ilstu.edu</EmailAddress>
<PI_PHON>3094383240</PI_PHON>
<NSF_ID>000562895</NSF_ID>
<StartDate>08/19/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ball State University</Name>
<CityName>Muncie</CityName>
<ZipCode>473060155</ZipCode>
<PhoneNumber>7652851600</PhoneNumber>
<StreetAddress>2000 West University Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>065540726</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BALL STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>065540726</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ball State University]]></Name>
<CityName/>
<StateCode>IN</StateCode>
<ZipCode>473061022</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>092E</Code>
<Text>Control systems &amp; applications</Text>
</ProgramReference>
<ProgramReference>
<Code>152E</Code>
<Text>Cyber-Physical Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>153E</Code>
<Text>Wireless comm &amp; sig processing</Text>
</ProgramReference>
<ProgramReference>
<Code>154E</Code>
<Text>Computat systems &amp; security</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~221826</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we performed research on three subdomains in computing from various angels to contribute to the autonomous flying of cooperative drones: intelligent and secure wireless communications, panoramic video stitching, and deep learning based end-to-end autonomous navigation. In intelligent and secure wireless communications, we studied the machine learning based self-cancellation to enable full-duplex communication with three publications resulted. In panoramic video stitching, we developed a hierarchical stitching flight coordination simulator and designed a realtime panoramic video stitching algorithm that exploits the spatiotemporal features in a video. This effort generates two honor thesis and one publication. In the autonomous navigation, we have designed a couple of deep imitation learning based robotic navigation solutions and tested them in an indoor environment. Three publications have been produced from this effort.&nbsp;</p> <p>&nbsp;</p> <p>Four undergraduates and four graduate students have been involved as research assistants in this project. Three of them are women honor students, one of which went to graduate school with the inspiration in this project. Four graduate students decided to pursue their PhD studies after this project. The project also supported two undergraduates in the form of REU supplemental. The autonomous navigation has been demonstrated to the public at Ball State University centennial celebration events and a research center showcase. The research outcomes in form of publications have been presented at more than five international conferences. The project also leads to course enhancements offered to more than 200 undergraduate and graduate students.&nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/18/2018<br>      Modified by: Shaoen&nbsp;Wu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we performed research on three subdomains in computing from various angels to contribute to the autonomous flying of cooperative drones: intelligent and secure wireless communications, panoramic video stitching, and deep learning based end-to-end autonomous navigation. In intelligent and secure wireless communications, we studied the machine learning based self-cancellation to enable full-duplex communication with three publications resulted. In panoramic video stitching, we developed a hierarchical stitching flight coordination simulator and designed a realtime panoramic video stitching algorithm that exploits the spatiotemporal features in a video. This effort generates two honor thesis and one publication. In the autonomous navigation, we have designed a couple of deep imitation learning based robotic navigation solutions and tested them in an indoor environment. Three publications have been produced from this effort.      Four undergraduates and four graduate students have been involved as research assistants in this project. Three of them are women honor students, one of which went to graduate school with the inspiration in this project. Four graduate students decided to pursue their PhD studies after this project. The project also supported two undergraduates in the form of REU supplemental. The autonomous navigation has been demonstrated to the public at Ball State University centennial celebration events and a research center showcase. The research outcomes in form of publications have been presented at more than five international conferences. The project also leads to course enhancements offered to more than 200 undergraduate and graduate students.            Last Modified: 10/18/2018       Submitted by: Shaoen Wu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
