<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Medium: Collaborative Research: On the Power of Mathematical Programming in Combinatorial Optimization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>366166.00</AwardTotalIntnAmount>
<AwardAmount>366166</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Mathematical programming is a powerful tool for attacking combinatorial problems.  One transforms a discrete task into a related continuous one by casting it as optimization over a convex body.  Linear and semi-definite programming (LP and SDP) form important special cases and are central tools in the theory and practice of combinatorial optimization. These approaches have achieved spectacular success in computing approximately optimal solutions for problems where finding exact solutions is computationally intractable.&lt;br/&gt;&lt;br/&gt;While there are very strong bounds known on the efficacy of particular families of relaxations, it remains possible that adding a small number of variables or constraints could lead to drastically improved solutions.  We propose the development of a theory to unconditionally capture the power of LPs and SDPs without any complexity-theoretic assumptions.  Our approach has the potential to show something remarkable:  For many well-known problems, the basic LP or SDP is optimal among a very large class of algorithms.  More concretely, we suggest a method that could rigorously characterize the power of polynomial-size LPs and SDPs for a variety of combinatorial optimization tasks.   This involves deep issues at the intersection of many areas of mathematics and computer science, with the ultimate goal of significantly extending our understanding of efficient computation.&lt;br/&gt;&lt;br/&gt;Mathematical programming is of major importance to many fields---this is especially true for computer science and operations research.  These methods have also seen dramatically increasing use in the analysis of "big data" from across the scientific spectrum.  From a different perspective, LPs and SDPs can be thought of as rich proof systems, and characterizing their power is a basic problem in the theory of proof complexity. Thus the outcomes of the proposed research are of interest to a broad community of scientists, mathematicians, and practitioners.</AbstractNarration>
<MinAmdLetterDate>06/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1408673</AwardID>
<Investigator>
<FirstName>Eva</FirstName>
<LastName>Tardos</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eva Tardos</PI_FULL_NAME>
<EmailAddress>eva@cs.cornell.edu</EmailAddress>
<PI_PHON>6072550984</PI_PHON>
<NSF_ID>000443465</NSF_ID>
<StartDate>08/02/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Steurer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David Steurer</PI_FULL_NAME>
<EmailAddress>dsteurer@cs.cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000649461</NSF_ID>
<StartDate>06/20/2014</StartDate>
<EndDate>08/02/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148537501</ZipCode>
<StreetAddress><![CDATA[4130 Upson Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7927</Code>
<Text>COMPLEXITY &amp; CRYPTOGRAPHY</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~96056</FUND_OBLG>
<FUND_OBLG>2015~99175</FUND_OBLG>
<FUND_OBLG>2016~84116</FUND_OBLG>
<FUND_OBLG>2017~86819</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Default">The original goal of the project was to develop a theory to characterize the power of linear programming and semidefinite programming based algorithms for discrete optimization problems. These kind of algorithms capture and generalize the best-known algorithms for a wide range of problems. In contrast to the more traditional approach for understanding the power of algorithms via reductions, the theory we aim to develop would not rely on complexity-theoretic assumptions. &nbsp;As an example, we studied polynomial time algorithms for estimating the mean of a heavy-tailed multivariate random vector. When estimating means of heavy-tailed random processes via empirical means, the resulting confidence intervals are large, and hence the estimate imprecise. We offer the first polynomial time algorithm to estimate the mean with compact confidence intervals under mild assumptions. Our algorithm is based on a new semidefinite programming relaxation of a high-dimensional median. Previous estimators are only known to be computable via brute-force search procedures requiring time exponential in the dimension.</p> <p class="Default">&nbsp;</p> <p>In the last two years the focus of the project was switched (by approval from NSF) to understand learning strategies that can be effective as a form of learning for players in repeated games. The idea is to develop strategies that work well in adversarial environment. Two different objectives were considered:</p> <p>(1)&nbsp;&nbsp; the objective of how well the individual player is doing measured by regret: the performance compared to the single best strategy with hindsight</p> <p>(2)&nbsp;&nbsp; the overall performance in a game setting when all players follow a learning strategy</p> <p class="Default">&nbsp;</p> <p class="Default">The main project on learning considers a queuing system where the queues use no-regret learning algorithms to selfishly optimize for their own performance. When players selfishly compete, the outcome can be worse than what is possible by coordinated optimization. The price of anarchy measures the damage to social welfare due to selfish behavior of the participants. In this work, we study this phenomenon in the context of a game modeling queuing systems: routers compete for servers, where packets that do not get service will be resent at future rounds, resulting in a system where the number of packets at each round depends on the success of the routers in the previous rounds. Most modern systems use machine learning algorithms, when optimizing system performance. We study the outcome of a process when each queue optimizes its own performance using machine learning.</p> <p class="Default">&nbsp;</p> <p class="Default">The carryover effect caused by packets remaining in this system makes learning in our context result in a highly dependent random process. We analyze this random process, and show with somewhat increased capacity all packets served even with double the packet arrival rate, and queues use no-regret learning algorithms, then the expected number of packets in the queues will remain bounded throughout time, assuming older packets have priority. This paper is the first to study the effect of selfish learning in a queuing system, where the learners compete for resources, but rounds are not all independent: the number of packets to be routed at each round depends on the success of the routers in the previous rounds.</p> <p>&nbsp;</p> <p>People's opinions are shaped by their interactions with others. The resulting process of opinion dynamics --- the interplay between opinion formation and the network structure of these interactions --- has been of great interest in the political science, sociology, economics, and computer science communities among others. We study the connections between network structure, opinion dynamics, and an adversary's power to artificially induce disagreements. We approach these questions by extending models of opinion formation in the mathematical social sciences to represent scenarios, familiar from recent events, in which external actors have sought to destabilize communities through sophisticated information warfare tactics via fake news and bots. In many instances, the intrinsic goals of these efforts are not necessarily to shift the overall sentiment of the network towards a particular policy, but rather to induce discord. These perturbations will diffuse via opinion dynamics on the underlying network, through mechanisms that have been analyzed and abstracted through work in computer science and the social sciences.</p> <p class="Default">&nbsp;</p> <p>&nbsp;We investigate the properties of such attacks, considering optimal strategies both for the adversary seeking to create disagreement and for the entities tasked with defending the network from attack. By employing techniques from spectral graph theory, we show that for different formulations of these types of objectives, different regimes of the spectral structure of the network will limit the adversary's capacity to sow discord. Via the strong connections between spectral and structural properties of graphs, we are able to qualitatively describe which networks are most vulnerable or resilient against these perturbations. We also consider the algorithmic task of a network defender to mitigate these sorts of adversarial attacks by insulating nodes heterogeneously; we show that, by considering the geometry of this problem, this optimization task can be efficiently solved via convex programming.</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/13/2021<br>      Modified by: Eva&nbsp;Tardos</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The original goal of the project was to develop a theory to characterize the power of linear programming and semidefinite programming based algorithms for discrete optimization problems. These kind of algorithms capture and generalize the best-known algorithms for a wide range of problems. In contrast to the more traditional approach for understanding the power of algorithms via reductions, the theory we aim to develop would not rely on complexity-theoretic assumptions.  As an example, we studied polynomial time algorithms for estimating the mean of a heavy-tailed multivariate random vector. When estimating means of heavy-tailed random processes via empirical means, the resulting confidence intervals are large, and hence the estimate imprecise. We offer the first polynomial time algorithm to estimate the mean with compact confidence intervals under mild assumptions. Our algorithm is based on a new semidefinite programming relaxation of a high-dimensional median. Previous estimators are only known to be computable via brute-force search procedures requiring time exponential in the dimension.    In the last two years the focus of the project was switched (by approval from NSF) to understand learning strategies that can be effective as a form of learning for players in repeated games. The idea is to develop strategies that work well in adversarial environment. Two different objectives were considered:  (1)   the objective of how well the individual player is doing measured by regret: the performance compared to the single best strategy with hindsight  (2)   the overall performance in a game setting when all players follow a learning strategy   The main project on learning considers a queuing system where the queues use no-regret learning algorithms to selfishly optimize for their own performance. When players selfishly compete, the outcome can be worse than what is possible by coordinated optimization. The price of anarchy measures the damage to social welfare due to selfish behavior of the participants. In this work, we study this phenomenon in the context of a game modeling queuing systems: routers compete for servers, where packets that do not get service will be resent at future rounds, resulting in a system where the number of packets at each round depends on the success of the routers in the previous rounds. Most modern systems use machine learning algorithms, when optimizing system performance. We study the outcome of a process when each queue optimizes its own performance using machine learning.   The carryover effect caused by packets remaining in this system makes learning in our context result in a highly dependent random process. We analyze this random process, and show with somewhat increased capacity all packets served even with double the packet arrival rate, and queues use no-regret learning algorithms, then the expected number of packets in the queues will remain bounded throughout time, assuming older packets have priority. This paper is the first to study the effect of selfish learning in a queuing system, where the learners compete for resources, but rounds are not all independent: the number of packets to be routed at each round depends on the success of the routers in the previous rounds.     People's opinions are shaped by their interactions with others. The resulting process of opinion dynamics --- the interplay between opinion formation and the network structure of these interactions --- has been of great interest in the political science, sociology, economics, and computer science communities among others. We study the connections between network structure, opinion dynamics, and an adversary's power to artificially induce disagreements. We approach these questions by extending models of opinion formation in the mathematical social sciences to represent scenarios, familiar from recent events, in which external actors have sought to destabilize communities through sophisticated information warfare tactics via fake news and bots. In many instances, the intrinsic goals of these efforts are not necessarily to shift the overall sentiment of the network towards a particular policy, but rather to induce discord. These perturbations will diffuse via opinion dynamics on the underlying network, through mechanisms that have been analyzed and abstracted through work in computer science and the social sciences.     We investigate the properties of such attacks, considering optimal strategies both for the adversary seeking to create disagreement and for the entities tasked with defending the network from attack. By employing techniques from spectral graph theory, we show that for different formulations of these types of objectives, different regimes of the spectral structure of the network will limit the adversary's capacity to sow discord. Via the strong connections between spectral and structural properties of graphs, we are able to qualitatively describe which networks are most vulnerable or resilient against these perturbations. We also consider the algorithmic task of a network defender to mitigate these sorts of adversarial attacks by insulating nodes heterogeneously; we show that, by considering the geometry of this problem, this optimization task can be efficiently solved via convex programming.          Last Modified: 01/13/2021       Submitted by: Eva Tardos]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
