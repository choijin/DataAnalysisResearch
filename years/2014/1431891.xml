<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Assessing by design: Unpacking the role of formative assessment in student learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2015</AwardEffectiveDate>
<AwardExpirationDate>12/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>500716.00</AwardTotalIntnAmount>
<AwardAmount>500716</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040200</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jennifer Lewis</SignBlockName>
<PO_EMAI>jenlewis@nsf.gov</PO_EMAI>
<PO_PHON>7032922938</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is a carefully designed empirical study of the relationship between formative assessment, instructor-generated feedback, and student learning. It is widely believed on the basis of theory and prior local studies that formative assessment is one of the most effective instructional interventions to impact student learning, but the supporting empirical evidence is still thin in some respects.  With the full cooperation of participating faculty, this study will generate a robust stream of empirical data from both face-to-face and online courses in biology and psychology in order to:&lt;br/&gt;1. Characterize the formative assessment prompts,&lt;br/&gt;2. Describe the nature of instructor-generated feedback to students,&lt;br/&gt;3. Describe how students use instructor-generated feedback, including identifying the types of feedback students use, and how frequently and consistently they use it.  &lt;br/&gt;4. Ultimately describe the relationship between formative assessment and student learning.  &lt;br/&gt;&lt;br/&gt;This is a design-based research project. Classroom modules will be randomly assigned to either experimental class sessions (that provide formative assessment and feedback opportunities) or control class sessions (that do not provide formative assessment and feedback opportunities).  In this manner, all students will participate in both control and experimental groups at some point during their course. Student learning will be measured through gains in learning using items drawn from validated concept inventories (where appropriate) or instructor-generated assessment items, and the self-report instrument Students Assessment of their Learning Gains (available at SALGsite.org).   &lt;br/&gt;&lt;br/&gt;The maintained hypothesis is that students who regularly access and use feedback opportunities will show greater learning gains and have higher course grades. The study will collect demographic variables (e.g., gender, GPA, ACT scores) and administer the Revised Study Process Questionnaire (Biggs et al. 2001) and the 12-item GRIT scale (Duckworth et al. 2007) to support the creation of an empirically-driven model to describe the contexts in which formative assessment and feedback are most useful to learners. The project seeks to predict for whom and in what classroom situations formative assessment and feedback are most useful.</AbstractNarration>
<MinAmdLetterDate>07/26/2014</MinAmdLetterDate>
<MaxAmdLetterDate>12/16/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1431891</AwardID>
<Investigator>
<FirstName>Jennifer</FirstName>
<LastName>Momsen</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jennifer L Momsen</PI_FULL_NAME>
<EmailAddress>jennifer.momsen@ndsu.edu</EmailAddress>
<PI_PHON>7012315560</PI_PHON>
<NSF_ID>000160883</NSF_ID>
<StartDate>07/26/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Boyer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeffrey Boyer</PI_FULL_NAME>
<EmailAddress>jeffrey.boyer@ndsu.edu</EmailAddress>
<PI_PHON>7012315953</PI_PHON>
<NSF_ID>000617021</NSF_ID>
<StartDate>07/26/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Erika</FirstName>
<LastName>Offerdahl</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Erika G Offerdahl</PI_FULL_NAME>
<EmailAddress>eofferdahl@vetmed.wsu.edu</EmailAddress>
<PI_PHON>5093358751</PI_PHON>
<NSF_ID>000503619</NSF_ID>
<StartDate>07/26/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Dakota State University Fargo</Name>
<CityName>FARGO</CityName>
<ZipCode>581086050</ZipCode>
<PhoneNumber>7012318045</PhoneNumber>
<StreetAddress>Dept 4000 - PO Box 6050</StreetAddress>
<StreetAddress2><![CDATA[1735 Research Park Drive]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Dakota</StateName>
<StateCode>ND</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>ND00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>803882299</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH DAKOTA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>803882299</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Dakota State University Fargo]]></Name>
<CityName>Fargo</CityName>
<StateCode>ND</StateCode>
<ZipCode>581086050</ZipCode>
<StreetAddress><![CDATA[Dept 4000 - PO Box 6050]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Dakota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>ND00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1536</Code>
<Text>S-STEM-Schlr Sci Tech Eng&amp;Math</Text>
</ProgramElement>
<ProgramElement>
<Code>1998</Code>
<Text>IUSE</Text>
</ProgramElement>
<ProgramReference>
<Code>8209</Code>
<Text>Improv Undergrad STEM Ed(IUSE)</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>13XX</Code>
<Name>H-1B FUND, EHR, NSF</Name>
<APP_SYMB_ID>045176</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~500716</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-95c68ea4-7fff-3bea-da5e-0776b137cd66">&nbsp;</span><strong>Intellectual Merit</strong></p> <p dir="ltr"><span>This project sought to clarify the role of formative assessment (FA) in supporting student learning by examining the FA practices in large-enrollment introductory undergraduate biology. FA is the process through which instructors elicit evidence of students? understanding of a concept and provide feedback to improve their in-progress learning. As a high-impact instructional practice, FA is a hallmark of learner-centered classrooms. Historically, studies that have quantified the effects of FA on student learning have reported positive results, but the magnitude of these effects have varied significantly. It is unclear whether the variability is due to the effectiveness of FA as an instructional practice in and of itself, differences in how FA was enacted across studies and contexts, or other mitigating factors.&nbsp;</span></p> <p dir="ltr">We conducted a systematic literature review to determine the critical components of FA, that is the ?key ingredients? of the FA process that support student learning. We investigated three of these critical components in greater detail:&nbsp; FA prompts, instructor-generated feedback, and students? use of feedback.</p> <p dir="ltr"><em>Formative assessment (FA) prompts.</em> We extracted all FA prompts from four semesters of large-lecture introductory biology, classified them according to cognitive level, delivery method (e.g., clicker question), and function (e.g., content reinforcement, connection making). The majority of prompts targeted knowledge, comprehension, and lower-level application skills independent of instructor or biology topic. Not surprisingly, individual instructors were consistent from day to day in their use of prompts and we observed variation in practice between instructors when controlling for content. Interestingly, we did detect an increase in both the frequency and cognitive level of the FA prompts utilized by an individual instructor when they transitioned from a fixed-seating lecture hall to a SCALE-UP active learning classroom. This observation is consistent with work by Allen and Tanner (2005) in biology and recent work by Stains and colleagues across STEM that suggests that the physical layout of a classroom can be a barrier to some instructors for implementing high-impact instructional practices.</p> <p dir="ltr"><em>Instructor-generated feedback. </em>We focused on describing instructor-generated feedback within the context of assessment conversations, defined as whole-class discussions facilitated by the teacher and intended to provide opportunities to listen and respond to student thinking, and for students to listen and respond to each other. Importantly, while we observed variation in the types of fFA prompts used by individual instructors, the nature of instructor-generated feedback is very similar between instructors. Notably, independent of instructors? teaching experience or classroom environment (stadium-style seating vs SCALE-UP) there is a paucity of certain types of feedback, particularly those that are most likely to positively affect student learning. This was surprising as we had employed a purposive sampling strategy to select for instructors who would create ?formative assessment-rich? environments. We crafted a survey whereby students retrospectively watched video excerpts of class and indicated whether or not they had received feedback from the instructor. Students were unable to discern feedback from instruction. The implications of the presence or absence of particular types of feedback on student learning remains unclear.&nbsp;</p> <p dir="ltr"><em>Student use of feedback.</em> We collected data from two large sections of introductory biology taught in a SCALE-UP classroom. Thematic analysis of repeated stimulated recall interviews with 15 students (72 total interviews) uncovered three main categories of feedback effects that students perceived. Feedback (1) assured students they were using correct reasoning, (2) alerted students to an error or gap in their knowledge, or (3) added new information, instruction, or guidance. Repeated stimulated recall surveys with a larger student population (262 students) further confirmed the assure, alert, and add feedback themes. Feedback also changed how students? prepared for exams, directly impacting study strategies. These results provide instructors with language that enables them to think more deliberately about the feedback they provide to students and by extension, can support students? use of feedback.</p> <p dir="ltr"><span id="docs-internal-guid-eef160ae-7fff-ba22-17cb-051ececd05fc"><span>There is a growing need for valid and reliable measures of undergraduate instruction. The Classroom Observation Protocol for Undergraduate Science (COPUS) has been used to characterize instruction as one of three styles (didactic, interactive lecture, student-centered). We were unable to detect differences in FA behaviors between the styles suggesting that COPUS styles may not reliably distinguish differences in FA practices. These results are important given the tacit assumption that moving from didactic to interactive lecture to student-centered instruction is a desirable trajectory.&nbsp;</span></span></p> <p dir="ltr"><strong>Broader Impacts</strong></p> <p dir="ltr"><span>The potential of FA and instructor-generated feedback is profound, but a truly mechanistic understanding of how it can be used to transform undergraduate science learning and instruction remains limited. This project advanced efforts by developing instruments and protocols that can be used across undergraduate STEM contexts to improve students? recognition and use of feedback for learning. This has significant implications for improving pathways into the STEM workforce, as large-lecture courses in particular tend to serve as off-ramps for students out of STEM disciplines.</span></p><br> <p>            Last Modified: 04/23/2021<br>      Modified by: Jennifer&nbsp;L&nbsp;Momsen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Intellectual Merit This project sought to clarify the role of formative assessment (FA) in supporting student learning by examining the FA practices in large-enrollment introductory undergraduate biology. FA is the process through which instructors elicit evidence of students? understanding of a concept and provide feedback to improve their in-progress learning. As a high-impact instructional practice, FA is a hallmark of learner-centered classrooms. Historically, studies that have quantified the effects of FA on student learning have reported positive results, but the magnitude of these effects have varied significantly. It is unclear whether the variability is due to the effectiveness of FA as an instructional practice in and of itself, differences in how FA was enacted across studies and contexts, or other mitigating factors.  We conducted a systematic literature review to determine the critical components of FA, that is the ?key ingredients? of the FA process that support student learning. We investigated three of these critical components in greater detail:  FA prompts, instructor-generated feedback, and students? use of feedback. Formative assessment (FA) prompts. We extracted all FA prompts from four semesters of large-lecture introductory biology, classified them according to cognitive level, delivery method (e.g., clicker question), and function (e.g., content reinforcement, connection making). The majority of prompts targeted knowledge, comprehension, and lower-level application skills independent of instructor or biology topic. Not surprisingly, individual instructors were consistent from day to day in their use of prompts and we observed variation in practice between instructors when controlling for content. Interestingly, we did detect an increase in both the frequency and cognitive level of the FA prompts utilized by an individual instructor when they transitioned from a fixed-seating lecture hall to a SCALE-UP active learning classroom. This observation is consistent with work by Allen and Tanner (2005) in biology and recent work by Stains and colleagues across STEM that suggests that the physical layout of a classroom can be a barrier to some instructors for implementing high-impact instructional practices. Instructor-generated feedback. We focused on describing instructor-generated feedback within the context of assessment conversations, defined as whole-class discussions facilitated by the teacher and intended to provide opportunities to listen and respond to student thinking, and for students to listen and respond to each other. Importantly, while we observed variation in the types of fFA prompts used by individual instructors, the nature of instructor-generated feedback is very similar between instructors. Notably, independent of instructors? teaching experience or classroom environment (stadium-style seating vs SCALE-UP) there is a paucity of certain types of feedback, particularly those that are most likely to positively affect student learning. This was surprising as we had employed a purposive sampling strategy to select for instructors who would create ?formative assessment-rich? environments. We crafted a survey whereby students retrospectively watched video excerpts of class and indicated whether or not they had received feedback from the instructor. Students were unable to discern feedback from instruction. The implications of the presence or absence of particular types of feedback on student learning remains unclear.  Student use of feedback. We collected data from two large sections of introductory biology taught in a SCALE-UP classroom. Thematic analysis of repeated stimulated recall interviews with 15 students (72 total interviews) uncovered three main categories of feedback effects that students perceived. Feedback (1) assured students they were using correct reasoning, (2) alerted students to an error or gap in their knowledge, or (3) added new information, instruction, or guidance. Repeated stimulated recall surveys with a larger student population (262 students) further confirmed the assure, alert, and add feedback themes. Feedback also changed how students? prepared for exams, directly impacting study strategies. These results provide instructors with language that enables them to think more deliberately about the feedback they provide to students and by extension, can support students? use of feedback. There is a growing need for valid and reliable measures of undergraduate instruction. The Classroom Observation Protocol for Undergraduate Science (COPUS) has been used to characterize instruction as one of three styles (didactic, interactive lecture, student-centered). We were unable to detect differences in FA behaviors between the styles suggesting that COPUS styles may not reliably distinguish differences in FA practices. These results are important given the tacit assumption that moving from didactic to interactive lecture to student-centered instruction is a desirable trajectory.  Broader Impacts The potential of FA and instructor-generated feedback is profound, but a truly mechanistic understanding of how it can be used to transform undergraduate science learning and instruction remains limited. This project advanced efforts by developing instruments and protocols that can be used across undergraduate STEM contexts to improve students? recognition and use of feedback for learning. This has significant implications for improving pathways into the STEM workforce, as large-lecture courses in particular tend to serve as off-ramps for students out of STEM disciplines.       Last Modified: 04/23/2021       Submitted by: Jennifer L Momsen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
