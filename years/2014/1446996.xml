<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Collaborative Research: Scaling Up Discriminative Learning for Natural Language Understanding and Translation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>129053.00</AwardTotalIntnAmount>
<AwardAmount>129053</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This EArly Grant for Exploratory Research aims to improve automatic understanding of natural language by machines, and automatic translation between languages such as Chinese and English. In the realm of understanding, the project develops methods for syntactically and semantically analyzing, or parsing, sentences. Improved parsing can help in accessing the enormous amount of information available in unstructured text on the web and in databases of newspapers and scanned books. Improved translation between languages increases opportunities for trade as well as for dissemination of information generally between nations and cultures. Machine translation is widely used today despite its generally poor quality, and any improvement in quality will improve access to information for millions of people.  This project aims to exploit the power of machine learning algorithms that are designed to discriminate between correct and incorrect outputs by numerically optimizing mathematical functions that are defined in terms of the data available for training.  Discriminative structured prediction algorithms have witnessed great success in the field of natural language processing (NLP) over the past decade, generally surpassing their generative counterparts. However, there remain two major problems which prevent discriminative methods from scaling to very large datasets: first, they typically assume exact search (over a prohibitively large search space), which is rarely possible in practice for problems such as parsing and translation. Secondly, they normally assume the data is completely annotated, whereas many naturally occurring datasets are only partially annotated: for example a parallel text in machine translation includes the source and target sentence pairs but not the derivation between them. As a result of these two problems, the current methods are not taking full advantage of the enormous and ever increasing amount of text data available to us.&lt;br/&gt;&lt;br/&gt;This EArly Grant ofr Exploratory Research (EAGER) aims to: &lt;br/&gt;- Develop a linear-time structured learning framework specifically tailored for inexact search, which hopefully retains theoretical properties of structured learning (e.g. convergence) under exact search.  &lt;br/&gt;- Extend this framework to handle latent variables, such as derivations in machine translation, syntactic structures in semantic parsing, and semantic representations in question answering.  &lt;br/&gt;If the exploratory extension to latent variable frameworks is sucessful, it will enable longer-term research to: &lt;br/&gt;- Apply these efficient learning algorithms to discriminative training of machine translation systems over the entire training dataset rather than only on a small development set.  &lt;br/&gt;- Apply these efficient learning algorithms to discriminative training for syntactic and semantic parsing, with the goal of scaling up semantic parsing to enable web-scale knowledge extraction.</AbstractNarration>
<MinAmdLetterDate>08/13/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1446996</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Gildea</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Gildea</PI_FULL_NAME>
<EmailAddress>gildea@cs.rochester.edu</EmailAddress>
<PI_PHON>5852757230</PI_PHON>
<NSF_ID>000449779</NSF_ID>
<StartDate>08/13/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>146270140</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~129053</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project aimed to learn directly the correspondence between words in English<br />and objects and action in video.&nbsp; We worked with videos of experiments<br />in a biology laboratory, along with experimental protocols that describe the <br />steps of the experiment in English.&nbsp; This work could ultimately be used<br />automatically analyze videos of experiments, with the long-term goal<br />of recognizing possible errors or small discrepancies in experimental<br />protocols, and ultimately increasing the reproducibility of<br />scientific experiments.&nbsp; Our model assumes no knowledge of English <br />vocabulary, and aims to learn the interpretation of the English<br />words in the protocol by finding correspondences between the <br />sentences in the text and the temporal sequence of the video.<br />This unsupervised approach reduces the need for annotation of data<br />and hand-built domain-specific resources.&nbsp; It is also interesting <br />from the general viewpoint of language learning because it is<br />similar to the scenario in which a baby begins to learn its <br />native language by observing the world around it.<br /><br />Using techniques from statistical machine translation, we model <br />the alignment of sentences of the text to frames of the video<br />by using a Hidden Markov Model.&nbsp; Within each sentence-to-frame<br />correspondence, we model the alignment of objects in the image<br />to words in the sentence with the standard bag-of-words IBM Model 1. <br />This approach was able to learn the correspondence between<br />words and objects, and to align video to text.&nbsp; <br />More recently, we have extended<br />the model to allow discriminative training with arbitrary features.<br />It is common in machine learning for discriminative <br />models to perform better by virtue of being trained to directly optimize<br />the error criterion on which they are evaluated.&nbsp; <br />This experiment was interesting from a machine learning perspective<br />in that it showed the benefits of discriminative training<br />even in an unsupervised setting: we obtained improved<br />alignments despite the fact that the system never observes<br />the true correspondence between text and video.<br /><br />We have also experimented with our model in other <br />text-to-video domains; we have obtained promising <br />results in learning the correspondence between faces and names<br />in movie scripts.</p><br> <p>            Last Modified: 02/09/2017<br>      Modified by: Daniel&nbsp;Gildea</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project aimed to learn directly the correspondence between words in English and objects and action in video.  We worked with videos of experiments in a biology laboratory, along with experimental protocols that describe the  steps of the experiment in English.  This work could ultimately be used automatically analyze videos of experiments, with the long-term goal of recognizing possible errors or small discrepancies in experimental protocols, and ultimately increasing the reproducibility of scientific experiments.  Our model assumes no knowledge of English  vocabulary, and aims to learn the interpretation of the English words in the protocol by finding correspondences between the  sentences in the text and the temporal sequence of the video. This unsupervised approach reduces the need for annotation of data and hand-built domain-specific resources.  It is also interesting  from the general viewpoint of language learning because it is similar to the scenario in which a baby begins to learn its  native language by observing the world around it.  Using techniques from statistical machine translation, we model  the alignment of sentences of the text to frames of the video by using a Hidden Markov Model.  Within each sentence-to-frame correspondence, we model the alignment of objects in the image to words in the sentence with the standard bag-of-words IBM Model 1.  This approach was able to learn the correspondence between words and objects, and to align video to text.   More recently, we have extended the model to allow discriminative training with arbitrary features. It is common in machine learning for discriminative  models to perform better by virtue of being trained to directly optimize the error criterion on which they are evaluated.   This experiment was interesting from a machine learning perspective in that it showed the benefits of discriminative training even in an unsupervised setting: we obtained improved alignments despite the fact that the system never observes the true correspondence between text and video.  We have also experimented with our model in other  text-to-video domains; we have obtained promising  results in learning the correspondence between faces and names in movie scripts.       Last Modified: 02/09/2017       Submitted by: Daniel Gildea]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
