<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Medium: Collaborative Research: Enabling Mobile Safety Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>350000.00</AwardTotalIntnAmount>
<AwardAmount>350000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>To date, safety services are typically constructed as dedicated stovepipe systems focusing on high reliability and a specific area of risk (e.g., automotive safety systems). Usage of&amp;#8232; such services remains limited since they require a dedicated investment for each system. This project trades off the ultra-high reliability of dedicated systems for the much more &amp;#8232;rapid adoption of safety services that comes with integrating them directly into mobiles and wearables. By demonstrating the feasibility of this approach, this project can contribute to saving lives, such as some of the more than 30,000 traffic fatalities in the United States each year. It can also inform regulatory policy for safety services &amp;#8232;at the CPSC, NHTSA, or FCC. Moreover, the PIs will not only train graduate students to conduct the research but also actively include undergraduates and high school students through research internship programs. Results will be disseminated through scholarly publications, active outreach to the wireless and mobile industry through WINLAB's industry events and connections.&lt;br/&gt;&lt;br/&gt;This project seeks to demonstrate that the mobile devices we carry and wear can provide effective safety services. This is particularly relevant where our devices contribute to dangers by causing distractions for drivers and pedestrians. This project therefore pursues the vision of a system that offsets such unsafe use by continually sensing our activities and surroundings, identifying potentially dangerous situations, and mitigating them through appropriate interventions. At a technical level, the primary challenge lies not only in designing precise sensing techniques but in understanding and managing the level of confidence provided by these techniques. A key observation is that there are usually multiple possible interventions of varying levels of intrusiveness and tolerance to false positives. It is therefore important to match interventions to the confidence level provided by the sensors. To address this challenge, the project develops system support and a toolkit to help developers track and manage mobile&amp;#8232; sensing uncertainty. It explores crowdsourcing failure and relevance data&amp;#8232; from a large user population and automatically estimating the confidence provided&amp;#8232; by internal sensing and activity recognition components. The toolkit can further use the obtained metrics to help adapt sensing or application behavior. The system might conserve energy by switching one context sensor to a fallback mode from a diversity mode; or, the system could&amp;#8232; switch to a different intervention if the level of confidence has changed. System validation includes prototyping two application use cases, which sense and mitigate mobile device distractions for drivers and pedestrians. Together, these techniques form the system, which supports development of many other effective safety services on mobile devices.</AbstractNarration>
<MinAmdLetterDate>08/21/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/29/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1409811</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Martin</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard P Martin</PI_FULL_NAME>
<EmailAddress>Rmartin@cs.Rutgers.Edu</EmailAddress>
<PI_PHON>7324452768</PI_PHON>
<NSF_ID>000086200</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marco</FirstName>
<LastName>Gruteser</LastName>
<PI_MID_INIT>O</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marco O Gruteser</PI_FULL_NAME>
<EmailAddress>gruteser@winlab.rutgers.edu</EmailAddress>
<PI_PHON>8489320993</PI_PHON>
<NSF_ID>000493624</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[WINLAB Rutgers University]]></Name>
<CityName>North Brunswick</CityName>
<StateCode>NJ</StateCode>
<ZipCode>089023390</ZipCode>
<StreetAddress><![CDATA[671 US Route 1]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~230609</FUND_OBLG>
<FUND_OBLG>2016~119391</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The objective of this project was to demonstrate that the mobile devices we carry and wear can provide effective safety services. This is particularly relevant where our devices contribute to dangers by causing distractions for drivers and pedestrians. This project, therefore, pursued the vision of a system that offsets such unsafe use by continually sensing our activities and surroundings, identifying potentially dangerous situations, and mitigating them through appropriate interventions. Specifically, the project focused on the following specific goals: (1) developing precise driver phone use sensing technologies that can distinguish drivers, (2) developing sensing systems for pedestrian safety applications, and (3) using mobile and wearable&nbsp; devices to collect data on vehicular traffic conditions, which then be used to further build and test machine-learning based vehicular control and safety systems.&nbsp;</p> <p><br />The project's phone-use sensing technology used the embedded sensors in smartphones, i.e., accelerometers and gyroscopes, to capture differences in centripetal acceleration due to vehicle dynamics. The project demonstrated that these differences, combined with angular speed, can determine whether the phone is on the left or right side of the vehicle. Extensive experiments conducted with two vehicles in two different cities showed that the approach is robust to real driving environments. Despite noisy sensor readings from smartphones, it achieved a classification accuracy of driver vs. passenger of over 90 percent, with a false positive rate of a few percent. Combining the sensing results in a few turns improved the accuracy to 95 percent, with a lower false positive rate. The project also investigated exploiting the electromagnetic field measurement inside a vehicle to complement vehicle dynamics for driver phone sensing under the scenarios when little vehicle dynamics are present, for example, when driving straight on highways or standing at roadsides.</p> <p><br />With the increasing popularity of wearable devices, the project also explored the potential to use wearables for steering and driver tracking. Such a capability would enable novel mobile safety applications without relying on sensors in the vehicle, thus making it more portable and accessible. In particular, the research investigated how wrist-mounted inertial sensors, such as those in smart watches and fitness trackers, can track steering wheel usage and angle. Tracking steering wheel usage and turning angle provided additional, fundamental techniques to improve driving detection, enhanced vehicle motion tracking by mobile devices and helped identify unsafe driving.</p> <p><br />We also investigated using wearables to detect road crossings when a person is walking. Using the positioning information from only a smartphone, we were able to detect 85 percent of all pedestrian crossing events in suburban environments. Owing to degraded GPS performance in urban environments, we also used the inertial sensors on a foot-mounted unit to identify when a pedestrian is entering the street. In densely populated urban environments, we achieved a 90 percent detection rate with a less than 1 percent false positive rate.&nbsp;</p> <p>Recognizing that automated driving promises some of the largest traffic safety gains, the project then branched out to harness mobile sensing devices to collect data about unusual driving scenarios. Most existing efforts to collect driving data build on a small fleet of tens of highly instrumented vehicles that are continuously operated with test drivers. In terms of miles recorded, it is challenging to accumulate a sufficiently large dataset with this approach. We took an alternate approach where a large set of minimally instrumented vehicles collect the training data needed for machine learning approaches for self-driving and safety applications. The major advantage of our approach is that it provides a minimum-effort solution for self-driving companies and researchers, who want to collect large datasets of ready-to-use driving data in the real world without concerns of different vehicle types and driving behaviors. We evaluated the accuracy of collected internal and external data using over 140 real-driving trips collected in a 3-month time period. Results show that our approach accurately estimated the steering wheel angle with 0.69 degree median error, and derived the vehicle speed with 0.65 km/h deviation. The approach was also able to determine wet vs. dry road conditions with 95 percent accuracy by capturing a small number of brakes.&nbsp;</p> <p>The project provided students with important research mentoring and experience in&nbsp;experiment design, prototyping, and data analysis. One Ph.D. student completed his dissertation research from this project, and two gained significant results. Three additional graduate students and three undergraduate students also participated through a related undergraduate engineering capstone project. Research results were disseminated through publication in conference proceedings and journals across the fields of mobile computing and computer networking. Results were also shared with industry at our laboratory&rsquo;s industry day, through invited talks, and through personal contacts at relevant companies.&nbsp;The project has contributed to improving the methods used for the large data collection, on the order of billions of miles, needed for safety and self-driving applications.&nbsp;<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></p><br> <p>            Last Modified: 02/14/2018<br>      Modified by: Marco&nbsp;O&nbsp;Gruteser</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The objective of this project was to demonstrate that the mobile devices we carry and wear can provide effective safety services. This is particularly relevant where our devices contribute to dangers by causing distractions for drivers and pedestrians. This project, therefore, pursued the vision of a system that offsets such unsafe use by continually sensing our activities and surroundings, identifying potentially dangerous situations, and mitigating them through appropriate interventions. Specifically, the project focused on the following specific goals: (1) developing precise driver phone use sensing technologies that can distinguish drivers, (2) developing sensing systems for pedestrian safety applications, and (3) using mobile and wearable  devices to collect data on vehicular traffic conditions, which then be used to further build and test machine-learning based vehicular control and safety systems.    The project's phone-use sensing technology used the embedded sensors in smartphones, i.e., accelerometers and gyroscopes, to capture differences in centripetal acceleration due to vehicle dynamics. The project demonstrated that these differences, combined with angular speed, can determine whether the phone is on the left or right side of the vehicle. Extensive experiments conducted with two vehicles in two different cities showed that the approach is robust to real driving environments. Despite noisy sensor readings from smartphones, it achieved a classification accuracy of driver vs. passenger of over 90 percent, with a false positive rate of a few percent. Combining the sensing results in a few turns improved the accuracy to 95 percent, with a lower false positive rate. The project also investigated exploiting the electromagnetic field measurement inside a vehicle to complement vehicle dynamics for driver phone sensing under the scenarios when little vehicle dynamics are present, for example, when driving straight on highways or standing at roadsides.   With the increasing popularity of wearable devices, the project also explored the potential to use wearables for steering and driver tracking. Such a capability would enable novel mobile safety applications without relying on sensors in the vehicle, thus making it more portable and accessible. In particular, the research investigated how wrist-mounted inertial sensors, such as those in smart watches and fitness trackers, can track steering wheel usage and angle. Tracking steering wheel usage and turning angle provided additional, fundamental techniques to improve driving detection, enhanced vehicle motion tracking by mobile devices and helped identify unsafe driving.   We also investigated using wearables to detect road crossings when a person is walking. Using the positioning information from only a smartphone, we were able to detect 85 percent of all pedestrian crossing events in suburban environments. Owing to degraded GPS performance in urban environments, we also used the inertial sensors on a foot-mounted unit to identify when a pedestrian is entering the street. In densely populated urban environments, we achieved a 90 percent detection rate with a less than 1 percent false positive rate.   Recognizing that automated driving promises some of the largest traffic safety gains, the project then branched out to harness mobile sensing devices to collect data about unusual driving scenarios. Most existing efforts to collect driving data build on a small fleet of tens of highly instrumented vehicles that are continuously operated with test drivers. In terms of miles recorded, it is challenging to accumulate a sufficiently large dataset with this approach. We took an alternate approach where a large set of minimally instrumented vehicles collect the training data needed for machine learning approaches for self-driving and safety applications. The major advantage of our approach is that it provides a minimum-effort solution for self-driving companies and researchers, who want to collect large datasets of ready-to-use driving data in the real world without concerns of different vehicle types and driving behaviors. We evaluated the accuracy of collected internal and external data using over 140 real-driving trips collected in a 3-month time period. Results show that our approach accurately estimated the steering wheel angle with 0.69 degree median error, and derived the vehicle speed with 0.65 km/h deviation. The approach was also able to determine wet vs. dry road conditions with 95 percent accuracy by capturing a small number of brakes.   The project provided students with important research mentoring and experience in experiment design, prototyping, and data analysis. One Ph.D. student completed his dissertation research from this project, and two gained significant results. Three additional graduate students and three undergraduate students also participated through a related undergraduate engineering capstone project. Research results were disseminated through publication in conference proceedings and journals across the fields of mobile computing and computer networking. Results were also shared with industry at our laboratory?s industry day, through invited talks, and through personal contacts at relevant companies. The project has contributed to improving the methods used for the large data collection, on the order of billions of miles, needed for safety and self-driving applications.                        Last Modified: 02/14/2018       Submitted by: Marco O Gruteser]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
