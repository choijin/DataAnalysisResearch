<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Transforming Natural Language to Programming Languages</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>249985.00</AwardTotalIntnAmount>
<AwardAmount>249985</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Just a few years ago, the majority of our computational input was confined to the traditional  computer keyboard.  Now, with the advent of ubiquitous computational devices in our hands, pockets, televisions, cars, and glasses, more fluid, natural, and less distracting methods of input are desirable.  Besides the inherent limitations of the traditional keyboard, a more fundamental cost is the number of injuries sustained by repeated and long-term keyboard use.  Carpal Tunnel Sydrome (CTS) alone affected nearly 5 million US workers in 2010. CTS and Cubital Tunnel Syndrome (CBTS) together account for $1 of every $3 spent for workers? compensation. Besides these economic costs, these syndromes severely limit the ability of sufferers to access computational technology, locking them out of professions such as computer programming.&lt;br/&gt;&lt;br/&gt;This project aims to develop spoken language interfaces for computer programming.  The immediate goal is to create a spoken language dictation system for the popular Java programming language, which removes the need for the programmer to dictate difficult-to-verbalize syntactic elements such as parentheses, brackets, punctuation, and word casing.  Instead, the system will employ stochastic models to infer the intended program with high fidelity from the ambiguous speech stream of the user.  This project lays the groundwork for a more general framework for relating ambiguous natural human language to the various formal languages and systems that drive the functioning of the computer.&lt;br/&gt;&lt;br/&gt;The key technical innovations of this project lie in the development of stochastic models for computer programs.  Such models have met with much success in recent years for inferring the structure, meaning, and translations of human languages.  While traditional programming languages are designed as deterministic grammars, any speech input in a more natural human language idiom will perforce involve ambiguity.  This ambiguity may only be resolved by developing accurate and predictive probability models over computer programs.  The models to be explored in this project include traditional n-gram language models as well as syntactic language models that make use of the programming language's grammar in order to more accurately assign likelihood to various interpretations of the speech input.  In the long term, this research lays the groundwork for the development of robust speech toolkits for a wide variety of computational languages, such as domain-specific languages for cars and entertainment devices and database query languages.</AbstractNarration>
<MinAmdLetterDate>07/31/2014</MinAmdLetterDate>
<MaxAmdLetterDate>01/09/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1423237</AwardID>
<Investigator>
<FirstName>Thomas</FirstName>
<LastName>Reps</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thomas W Reps</PI_FULL_NAME>
<EmailAddress>reps@cs.wisc.edu</EmailAddress>
<PI_PHON>6082622091</PI_PHON>
<NSF_ID>000134593</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiaojin</FirstName>
<LastName>Zhu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaojin Zhu</PI_FULL_NAME>
<EmailAddress>jerryzhu@cs.wisc.edu</EmailAddress>
<PI_PHON>6088900129</PI_PHON>
<NSF_ID>000211108</NSF_ID>
<StartDate>01/09/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Liblit</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin R Liblit</PI_FULL_NAME>
<EmailAddress>liblit@cs.wisc.edu</EmailAddress>
<PI_PHON>6082626617</PI_PHON>
<NSF_ID>000203014</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Snyder</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin Snyder</PI_FULL_NAME>
<EmailAddress>bsnyder@cs.wisc.edu</EmailAddress>
<PI_PHON>8577566253</PI_PHON>
<NSF_ID>000581495</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate>01/09/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Wisconsin-Madison</Name>
<CityName>MADISON</CityName>
<ZipCode>537151218</ZipCode>
<PhoneNumber>6082623822</PhoneNumber>
<StreetAddress>21 North Park Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 6401]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>161202122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WISCONSIN SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041188822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Wisconsin-Madison]]></Name>
<CityName/>
<StateCode>WI</StateCode>
<ZipCode>537151218</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~249985</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The goal of the project is to develop technology for spoken language programming. Specifically, we aim to create methods that take noisy and ambiguous speech input and predict the most likely interpretation as a program in a particular programming language. Besides the direct utility of this application for hands-free programming for those with RSI and other disabilities, the stochastic modeling techniques we develop will help lay the foundation for improvements in program analysis, synthesis, error checking, and intelligent IDE's.</span></p> <p><span>&nbsp;</span></p> <p><span>With a team of undergraduate and graduate students, we have constructed a software platform, using techniques in speech recognition, natural language processing, and machine learning.&nbsp; </span><span>We</span><span> built a prototype speech programming system for entry-level visual programing languages such as Scratch and Google Blockly, where speech drives the visual placement of blocks.&nbsp; In addition, we studied program synthesis from imprecise specifications.&nbsp; Program synthesis is the process of automatically translating a specification into computer code. Traditional synthesis settings require a formal, precise specification. Motivated by computer education applications where a student learns to code simple turtle-style drawing programs, we study a novel synthesis setting where only a noisy user-intention drawing is specified. This allows students to sketch their intended output, optionally together with their own speech-generated incomplete program, to automatically produce a completed program. </span><span>We</span><span> formulate this synthesis problem as search in the space of programs, with the score of a state being the Hausdorff distance between the program output and the user drawing. </span><span>We</span><span> compare several search algorithms on a corpus consisting of real user drawings and the corresponding programs, and demonstrate that our algorithms can synthesize programs optimally satisfying the specification.&nbsp; As an example in the figure, our algorithms allow students to draw a picture that they intend their program to produce, such as the star in (a).&nbsp; The student might have already produced a partial and incorrect program (b).&nbsp; Our system will automatically complete or correct the students' partial code to produce the correct program that best matches the intended picture (c).</span></p> <p><span>&nbsp;</span></p> <p><span>The project has provided training for a computer science PhD student and four undergraduate students at University of Wisconsin-Madison.&nbsp; They learned to work as a team on a software project.&nbsp; In addition to scholarly publications, our group shared its research findings with legislators, state leaders, UW alumni and others during Research in the Rotunda at the Wisconsin State Capitol in 2018.&nbsp; The outreach event allows students and faculty advisors from across the UW System to connect and spread their knowledge.</span></p> <div><span><br /></span></div> <p>&nbsp;</p><br> <p>            Last Modified: 11/10/2018<br>      Modified by: Xiaojin&nbsp;Zhu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1423237/1423237_10326288_1541870926800_speechprogram--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423237/1423237_10326288_1541870926800_speechprogram--rgov-800width.jpg" title="spoken language programming"><img src="/por/images/Reports/POR/2018/1423237/1423237_10326288_1541870926800_speechprogram--rgov-66x44.jpg" alt="spoken language programming"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An example of spoken language programming</div> <div class="imageCredit">Xiaojin Zhu</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Xiaojin&nbsp;Zhu</div> <div class="imageTitle">spoken language programming</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the project is to develop technology for spoken language programming. Specifically, we aim to create methods that take noisy and ambiguous speech input and predict the most likely interpretation as a program in a particular programming language. Besides the direct utility of this application for hands-free programming for those with RSI and other disabilities, the stochastic modeling techniques we develop will help lay the foundation for improvements in program analysis, synthesis, error checking, and intelligent IDE's.     With a team of undergraduate and graduate students, we have constructed a software platform, using techniques in speech recognition, natural language processing, and machine learning.  We built a prototype speech programming system for entry-level visual programing languages such as Scratch and Google Blockly, where speech drives the visual placement of blocks.  In addition, we studied program synthesis from imprecise specifications.  Program synthesis is the process of automatically translating a specification into computer code. Traditional synthesis settings require a formal, precise specification. Motivated by computer education applications where a student learns to code simple turtle-style drawing programs, we study a novel synthesis setting where only a noisy user-intention drawing is specified. This allows students to sketch their intended output, optionally together with their own speech-generated incomplete program, to automatically produce a completed program. We formulate this synthesis problem as search in the space of programs, with the score of a state being the Hausdorff distance between the program output and the user drawing. We compare several search algorithms on a corpus consisting of real user drawings and the corresponding programs, and demonstrate that our algorithms can synthesize programs optimally satisfying the specification.  As an example in the figure, our algorithms allow students to draw a picture that they intend their program to produce, such as the star in (a).  The student might have already produced a partial and incorrect program (b).  Our system will automatically complete or correct the students' partial code to produce the correct program that best matches the intended picture (c).     The project has provided training for a computer science PhD student and four undergraduate students at University of Wisconsin-Madison.  They learned to work as a team on a software project.  In addition to scholarly publications, our group shared its research findings with legislators, state leaders, UW alumni and others during Research in the Rotunda at the Wisconsin State Capitol in 2018.  The outreach event allows students and faculty advisors from across the UW System to connect and spread their knowledge.            Last Modified: 11/10/2018       Submitted by: Xiaojin Zhu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
