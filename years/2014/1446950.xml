<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Reconfigurable Network Hardware for Message-Driven Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>75600.00</AwardTotalIntnAmount>
<AwardAmount>75600</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Message passing has long been known as a powerful tool for structuring parallel and distributed computation.   Systems dating back more than 30 years have been built around message passing as the fundamental interprocess communications primitive.   However, the use of message passing has been restricted to relatively coarse-grained application architectures due to message passing overhead.  This project provides hardware to support an initial demonstration of coupling programmable network interfaces (10 Gbps NetFPGAs) into process scheduling in support of fine-grained message passing.&lt;br/&gt;&lt;br/&gt;The project explores novel hardware and software support for message-driven computation based on the concept of futures, a nearly 40 year old concept from programming languages. It also builds on both the NetFPGA platform and the memory models made available by the PCI-E bus and processors such as the latest Intel Xeon E5 series processors.   Using the hardware support for locks and transactional memory as well as Data-Direct I/O into the cache in combination with a process execution model based on futures, this new approach to futures and message-driven scheduling revisits powerful historical approaches like dataflow in a realistic framework that stands to have impact in high-performance parallel computing and scalable network service architectures.</AbstractNarration>
<MinAmdLetterDate>08/21/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1446950</AwardID>
<Investigator>
<FirstName>Douglas</FirstName>
<LastName>Swany</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>Douglas M Swany</PI_FULL_NAME>
<EmailAddress>swany@iu.edu</EmailAddress>
<PI_PHON>8128567795</PI_PHON>
<NSF_ID>000347755</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474057104</ZipCode>
<StreetAddress><![CDATA[150 S. Woodlawn Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~75600</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">Messaging passing performance is critical across domains. The ability to do efficient message&nbsp;passing in a single system allows for module isolation with the example of message-based microkernels&nbsp;embodying this approach. In distributed computing and high-performance parallel computing&nbsp;the performance of data movement is also critical. High performance message passing enables&nbsp;the parallel programming model of communicating sequential processes, and messaging drives&nbsp;major network service architectures as well.</p> <p class="p1">As parallelism becomes greater, it becomes more difficult to manage. When applications&nbsp;are purely data parallel, parallel schedules can be precomputed. With large numbers of potentially&nbsp;heterogeneous elements, managing scheduling becomes more complicated. As applications become&nbsp;more and more data-driven and less regular, the problem is exacerbated. Harkening back to&nbsp;dataflow architectures, dynamic scheduling based on data dependence is increasingly relevant.</p> <p class="p1">Our specific concern was an attempt to revisit message-driven computation with dramatically&nbsp;reduced overhead by employing a novel synthesis of protocol and programmable network interfaces.&nbsp;The key metric that we have optimized is the number of instructions that must be executed&nbsp;to process a message and to begin executing on it.</p> <p class="p1">Our specific approach was to take advantage of the concept of "futures". In our model&nbsp;are data regions or variables that are bound to memory, and potentially bound to producer&nbsp;or consumer code. When a future is bound to a consumer, the consumer will wait for the value&nbsp;to be filled, and this provides a natural notion of dependence for scheduling. This is conceptually a form of dataflow-based computing. When futures are filled by messages,&nbsp;it creates a powerful model for efficient message-driven computation.</p> <p class="p1">In our work, we've activated futures with logic in the NetFPGA by updating memory&nbsp;and directly providing the scheduler activation necessary to indicate that the execution,&nbsp;blocked on a dependence, can proceed. This essentially allows messages to drive the&nbsp;operating system or user-level thread scheduler. This truly message-driven computation has significant impact on large scale parallel computing as well as on event-driven network&nbsp;services.</p> <p class="p1">This work is transformative to both large-scale parallel systems and network-oriented&nbsp;processing. We have obtained a sufficient test platform to enable initial prototype&nbsp;development and study.</p> <p class="p2">Intellectual Merit :</p> <p class="p1">The intellectual merit of this project is the exploration of novel hard- ware and software&nbsp;support for message-driven computation based on the concept of futures. This new approach&nbsp;to futures and message-driven scheduling revisits powerful historical approaches like dataflow&nbsp;in a realistic framework that stands to have impact in high-performance parallel computing&nbsp;and scalable network service architectures.</p> <p class="p2">Broader Impacts :</p> <p class="p1">The broader impact of this work lies in both computing environments and in the pedagogy of&nbsp;computer systems. Effective high-performance computing remains an open topic in computational&nbsp;science domains and improvements in the performance of large-scale parallel computing are&nbsp;continually sought in domains like environmental science, materials science and physics. We&nbsp;are working with groups in each of these areas to apply our approaches to improve the performance&nbsp;and scalability of their computations. In teaching, the implications of performance and scalability&nbsp;span operating systems, networking and programming languages. This research has already had&nbsp;an impact on curriculum development...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Messaging passing performance is critical across domains. The ability to do efficient message passing in a single system allows for module isolation with the example of message-based microkernels embodying this approach. In distributed computing and high-performance parallel computing the performance of data movement is also critical. High performance message passing enables the parallel programming model of communicating sequential processes, and messaging drives major network service architectures as well. As parallelism becomes greater, it becomes more difficult to manage. When applications are purely data parallel, parallel schedules can be precomputed. With large numbers of potentially heterogeneous elements, managing scheduling becomes more complicated. As applications become more and more data-driven and less regular, the problem is exacerbated. Harkening back to dataflow architectures, dynamic scheduling based on data dependence is increasingly relevant. Our specific concern was an attempt to revisit message-driven computation with dramatically reduced overhead by employing a novel synthesis of protocol and programmable network interfaces. The key metric that we have optimized is the number of instructions that must be executed to process a message and to begin executing on it. Our specific approach was to take advantage of the concept of "futures". In our model are data regions or variables that are bound to memory, and potentially bound to producer or consumer code. When a future is bound to a consumer, the consumer will wait for the value to be filled, and this provides a natural notion of dependence for scheduling. This is conceptually a form of dataflow-based computing. When futures are filled by messages, it creates a powerful model for efficient message-driven computation. In our work, we've activated futures with logic in the NetFPGA by updating memory and directly providing the scheduler activation necessary to indicate that the execution, blocked on a dependence, can proceed. This essentially allows messages to drive the operating system or user-level thread scheduler. This truly message-driven computation has significant impact on large scale parallel computing as well as on event-driven network services. This work is transformative to both large-scale parallel systems and network-oriented processing. We have obtained a sufficient test platform to enable initial prototype development and study. Intellectual Merit : The intellectual merit of this project is the exploration of novel hard- ware and software support for message-driven computation based on the concept of futures. This new approach to futures and message-driven scheduling revisits powerful historical approaches like dataflow in a realistic framework that stands to have impact in high-performance parallel computing and scalable network service architectures. Broader Impacts : The broader impact of this work lies in both computing environments and in the pedagogy of computer systems. Effective high-performance computing remains an open topic in computational science domains and improvements in the performance of large-scale parallel computing are continually sought in domains like environmental science, materials science and physics. We are working with groups in each of these areas to apply our approaches to improve the performance and scalability of their computations. In teaching, the implications of performance and scalability span operating systems, networking and programming languages. This research has already had an impact on curriculum development in our courses, and that has been expanded by this project.          Last Modified: 02/19/2016       Submitted by: Douglas M Swany]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
