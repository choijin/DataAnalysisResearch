<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Leveraging Structure to Realize the Promise of Transfer Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>97000.00</AwardTotalIntnAmount>
<AwardAmount>97000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The success of statistical machine learning relies critically on having access to a large amount of data for training. Learning algorithms become much less effective in data-poor situations. Examples of such challenges are recognizing uncommon visual categories from their images, understanding rare languages where both text and audio corpora are expensive to collect, adapting and personalizing assistive robots to new environments and owners, and identifying rare forms of diseases.  Transfer learning has been emerging as an appealing framework to address the challenge of being poor in data. The essential idea behind transfer learning is to leverage a cohort of related tasks, whose training data are abundant, to help to learn target tasks. The research project has several broader impacts. The most recent advances in transfer learning will be incorporated and integrated with the PI's teaching and research activities for graduate and undergraduate students from diverse scientific backgrounds. The project will actively engage undergraduate students in research. The results of the planned research will be rapidly and broadly disseminated to scientific communities via tutorials, review articles/surveys, invited talks and open-source software.&lt;br/&gt;&lt;br/&gt;Despite progress, transfer learning methods are largely limited to classification tasks where the goal is to learn  a labeling function for data samples represented as points in the Euclidean space.  In contrast, data in many application problems are complex and rich in structure.  Examples include complex visual scenes where there are strong contextual dependency among object categories, and multimodal data where each modality is complementary to the others. Effectively exploiting the dependency and structures in such data will likely improve the effectiveness of transfer learning relative to methods that ignore them. This project develops statistical methods for structured transfer learning, with applications to problems in computer vision and robotics.  The project focuses on two directions: (1) transfer learning for structured prediction problems, and (2) cross-modal transfer learning.  The research develops new statistical learning methods that deepen understanding and invents practical statistical algorithm to tackle transfer learning problems for data with complex types.  Secondly, the invented methods are applied to practical applications problems in computer vision and robotic perceptions. The project will show that proper of structure in data advances the state-of-the-art of intelligent and autonomous systems in perceiving complex and challenging real-world environments.</AbstractNarration>
<MinAmdLetterDate>08/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1451412</AwardID>
<Investigator>
<FirstName>Fei</FirstName>
<LastName>Sha</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fei Sha</PI_FULL_NAME>
<EmailAddress>feisha@usc.edu</EmailAddress>
<PI_PHON>2137405924</PI_PHON>
<NSF_ID>000510744</NSF_ID>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900890001</ZipCode>
<StreetAddress><![CDATA[3720 S. Flower St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~97000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>During this project, the PI and his research teams and collaborators have studied two important problems in computer vision and machine learning, towards the goal of building artificial intelligence agents.</p> <p>We have studied the problem of video summarization, ie, how to summarize a long video using a much fewer number of frames yet to convey the same amount of information as the original video.&nbsp; The key insight is that the summarization represents the structural relationship among video frames. Thus learning to extract such relationship enables transferring known summarization results on some videos to others.&nbsp; To this end, we have proposed new machine learning models and algorithms. Our methods have attained state-of-the-art results on standard benchmark datasets.&nbsp;</p> <p>We have also studied the problem of zero-shot learning, ie, how to recognize visual objects without using being given annotated learning samples. The key insight is that the names of new visual object categories are semantically related to the names of the visual object categories whose training samples are given. We develop new learning algorithms that learn to transfer from one type of visual object categories to another.&nbsp; Our work has attained&nbsp;&nbsp;state-of-the-art results on large-scale zero-shot learning, enhancing our capability in building robust vision systems.&nbsp;</p><br> <p>            Last Modified: 02/11/2018<br>      Modified by: Fei&nbsp;Sha</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ During this project, the PI and his research teams and collaborators have studied two important problems in computer vision and machine learning, towards the goal of building artificial intelligence agents.  We have studied the problem of video summarization, ie, how to summarize a long video using a much fewer number of frames yet to convey the same amount of information as the original video.  The key insight is that the summarization represents the structural relationship among video frames. Thus learning to extract such relationship enables transferring known summarization results on some videos to others.  To this end, we have proposed new machine learning models and algorithms. Our methods have attained state-of-the-art results on standard benchmark datasets.   We have also studied the problem of zero-shot learning, ie, how to recognize visual objects without using being given annotated learning samples. The key insight is that the names of new visual object categories are semantically related to the names of the visual object categories whose training samples are given. We develop new learning algorithms that learn to transfer from one type of visual object categories to another.  Our work has attained  state-of-the-art results on large-scale zero-shot learning, enhancing our capability in building robust vision systems.        Last Modified: 02/11/2018       Submitted by: Fei Sha]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
