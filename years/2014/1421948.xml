<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: A Hybrid Brain-Computer Interface for Behaviorally Non-Responsive Patients</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>499894.00</AwardTotalIntnAmount>
<AwardAmount>499894</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Brain-computer interfaces (BCIs) have been explored for several years in an effort to provide communication for "locked in" users who have the desire and mental capacity to communicate but are unable to speak, type, or use conventional assistive technologies due to severe motor disabilities, and a lot of work has gone into making this initially crude technology more practical, usable, accurate, and flexible (e.g., by improving speed of performance and providing virtual reality feedback and/or advanced device control).  In this project the PI and his team turn their attention to a group with even greater need: patients who have been misdiagnosed as vegetative or minimally conscious, and without the mental ability to form messages or respond to questions.  These individuals are not only unable to move but also unable to see, and are at risk of being euthanized based on the mistaken assumption that they are effectively "brain dead" whereas it has been shown by European colleagues, using methods and equipment comparable to American hospitals, that 17-42% of such patients were in fact able to use a BCI to respond to questions.  The PI worries that severely injured veterans and others might sometimes be misdiagnosed, potentially able to communicate with friends and loved ones if only some technology could more effectively assess their brain activity.  The PI's goal in this project is to extend current BCI technologies to focus on assessing consciousness in this vulnerable patient population and provide, where possible, the ability to communicate.&lt;br/&gt;&lt;br/&gt;The PI's approach is to adapt and extend conventional BCI protocols and feedback environments to work with people who cannot see and must instead rely on other modalities of stimulation.  The work will involve three thrusts.  First, the PI and his team will improve methods to identify brain response based only on tactile and auditory stimuli, by determining the best tactile stimulation frequency for each subject.  Second, they will use "hybrid" BCIs combining P300s and steady state somatosensory evoked potentials (SSSEPs) to elicit two different kinds of EEG signals that could improve accuracy.  Finally, they will develop a new six choice BCI system tailored for these users; at present the best BCIs for these patient groups allow just two or three choices, whereas a six choice system could lead to faster communication and broader control options.  Across all three of these thrusts, the team will also explore signal processing methods to improve accuracy.  Human subjects experiments will be conducted across three groups: healthy blindfolded users, healthy blind persons, and patients who have been labeled as nonresponsive.  Project outcomes, which will include useful non-visual BCIs that have been tested with blind persons and new methods for combining different EEG signals to improve performance, will be broadly disseminated both to the scientific community and to those involved with nonresponsive patient care at all levels.</AbstractNarration>
<MinAmdLetterDate>07/31/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421948</AwardID>
<Investigator>
<FirstName>Chang</FirstName>
<LastName>Nam</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chang S Nam</PI_FULL_NAME>
<EmailAddress>csnam@ncsu.edu</EmailAddress>
<PI_PHON>9195158140</PI_PHON>
<NSF_ID>000149436</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dean</FirstName>
<LastName>Krusienski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dean Krusienski</PI_FULL_NAME>
<EmailAddress>djkrusienski@vcu.edu</EmailAddress>
<PI_PHON>8048271890</PI_PHON>
<NSF_ID>000500739</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName/>
<StateCode>NC</StateCode>
<ZipCode>276957906</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7327</Code>
<Text>CRCNS-Computation Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~499894</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Disclaimer</p> <p>This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.</p> <p>We received this award to improve current BCI technologies for patients who have been misdiagnosed as vegetative or minimally conscious, without the mental ability to form messages or respond to questions. This effort required adapting conventional BCI protocols and feedback environments to work with people who cannot see, and improving accuracy based on tactile stimulation. With some notable exceptions, nearly all BCIs rely on visual environments to elicit relevant brain activity and/or provide feedback, and BCIs that do not rely in visual stimuli in any way have not been well researched. In addition, most BCI work focuses on maximizing performance, advanced applications and devices, and/or immersive feedback, rather than simply determining whether someone can communicate through protocols focused on people who may be mentally unable to communicate.</p> <p>First, we&nbsp; developed and validated various methods to identify brain responses based only on tactile and auditory stimuli, by determining the best tactile stimulation frequency for each subject. These methods can be used to develp a&nbsp;hybrid BCI paradigm that can elicit two kinds of EEG signals &ndash; P300s and steady state somatosensory evoked potentials (SSSEPs) &ndash; to provide two different signals that could improve accuracy and reduce BCI illiteracy. Second, a novel algorithm, namely temporally constrained sparse group spatial pattern (TSGSP), was developed for the simultaneous optimization of filter bands and time window within CSP to further boost classification accuracy of MI EEG. Third,&nbsp;we performed an empirical evaluation of performance for a 4-class SSVEP-based BCI when the spatial frequency of the individual checkerboard stimuli is varied over a continuum ranging from a solid background to single-pixel checkerboard patterns. The results indicated that a spatial frequency of 2.4 cycles per degree can maximize the information transfer rate with a reduction in subjective visual irritation compared to lower spatial frequencies. This important finding on stimulus design can lead to improved performance and usability of SSVEP-based BCIs. In addition, we assessed EEG&nbsp;<span>features that correlate with successful BCI performance during home use with the goal of improving BCI for people with neuromuscular disorders.&nbsp;<span>These results should inform studies focused on improved BCI reliability for people with neuromuscular disorders.</span></span></p> <p>These outcomes should be beneficial for research and academic community who want to develop&nbsp;many other categories of BCI applications, helping to bridge the gap between BCI research and real-world applications</p> <p>Over its duration, this grant has supported research by five PhD students, two MS students, and more than dozen undergraduate researchers. Indirectly, this grant has enabled work by several other professors, students and researchers who co-authored several peer-reviewed journal articles, conference proceedings, book chapters, posters, and presentations at companies and domestic as well as international research and academic institutions.</p><br> <p>            Last Modified: 08/09/2019<br>      Modified by: Chang&nbsp;S&nbsp;Nam</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Disclaimer  This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.  We received this award to improve current BCI technologies for patients who have been misdiagnosed as vegetative or minimally conscious, without the mental ability to form messages or respond to questions. This effort required adapting conventional BCI protocols and feedback environments to work with people who cannot see, and improving accuracy based on tactile stimulation. With some notable exceptions, nearly all BCIs rely on visual environments to elicit relevant brain activity and/or provide feedback, and BCIs that do not rely in visual stimuli in any way have not been well researched. In addition, most BCI work focuses on maximizing performance, advanced applications and devices, and/or immersive feedback, rather than simply determining whether someone can communicate through protocols focused on people who may be mentally unable to communicate.  First, we  developed and validated various methods to identify brain responses based only on tactile and auditory stimuli, by determining the best tactile stimulation frequency for each subject. These methods can be used to develp a hybrid BCI paradigm that can elicit two kinds of EEG signals &ndash; P300s and steady state somatosensory evoked potentials (SSSEPs) &ndash; to provide two different signals that could improve accuracy and reduce BCI illiteracy. Second, a novel algorithm, namely temporally constrained sparse group spatial pattern (TSGSP), was developed for the simultaneous optimization of filter bands and time window within CSP to further boost classification accuracy of MI EEG. Third, we performed an empirical evaluation of performance for a 4-class SSVEP-based BCI when the spatial frequency of the individual checkerboard stimuli is varied over a continuum ranging from a solid background to single-pixel checkerboard patterns. The results indicated that a spatial frequency of 2.4 cycles per degree can maximize the information transfer rate with a reduction in subjective visual irritation compared to lower spatial frequencies. This important finding on stimulus design can lead to improved performance and usability of SSVEP-based BCIs. In addition, we assessed EEG features that correlate with successful BCI performance during home use with the goal of improving BCI for people with neuromuscular disorders. These results should inform studies focused on improved BCI reliability for people with neuromuscular disorders.  These outcomes should be beneficial for research and academic community who want to develop many other categories of BCI applications, helping to bridge the gap between BCI research and real-world applications  Over its duration, this grant has supported research by five PhD students, two MS students, and more than dozen undergraduate researchers. Indirectly, this grant has enabled work by several other professors, students and researchers who co-authored several peer-reviewed journal articles, conference proceedings, book chapters, posters, and presentations at companies and domestic as well as international research and academic institutions.       Last Modified: 08/09/2019       Submitted by: Chang S Nam]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
