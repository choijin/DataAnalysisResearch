<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Leverage Subsampling for Regression and Dimension Reduction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>238040.00</AwardTotalIntnAmount>
<AwardAmount>238040</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927902</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research proposal consists of two related research thrusts, both of which center around the common goal of an integrated treatment of statistical and computational issues.  The first research thrust focuses on studying the statistical properties of the subsampling estimation using the statistical leverage scores in linear regression. The second research thrust generalizes the theory and methods to nonlinear regression and dimension reduction models. The proposed theory and methods serve as an inspiration for new ideas to push statistical methodology development forward. The research provides new insight into the existing algorithms, produces innovative methodologies for analyzing large-scale data, inspires new lines of quantitative investigations in interdisciplinary research and offers a unique educational experience.&lt;br/&gt;&lt;br/&gt;As a result of rapid advances in information technology, massive datasets are being generated in all fields of science, engineering, social science, business, and government. Useful information is often extracted from these data through statistical model fitting, e.g., through regression models. These models are useful for describing relationships between predictor variables and a response variable. Given a set of n data elements and p predictors, p and/or n can be large in much modern massive data set applications.  In these cases, conventional algorithms often face severe computational challenges. Subsampling of rows and/or columns of a data matrix have traditionally been employed as a heuristic to reduce the size of large data sets, thus enabling computations to run more quickly. Recently, however, an innovative sampling methodology that uses the empirical statistical leverage scores of the data matrix as a nonuniform importance sampling distribution has been proposed.  This has been applied to the ordinary least squares (OLS) problem and other related problems, and this leverage-based nonuniform sampling procedure gives a very good approximation to the OLS based on full data (when p is small and n is large) more rapidly than traditional methods, both in worst-case theory and in high-quality numerical implementations. As of yet, however, the statistical properties of these algorithms are unexplored.  Understanding these properties is of interest for both fundamental and very practical reasons; and the investigators' work addresses these problems.  The investigators consider both statistical theory as well as the evaluation of that theory with high-quality numerical implementations on large real-world data.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/25/2014</MinAmdLetterDate>
<MaxAmdLetterDate>04/25/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1440038</AwardID>
<Investigator>
<FirstName>Wenxuan</FirstName>
<LastName>Zhong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wenxuan Zhong</PI_FULL_NAME>
<EmailAddress>wenxuan@uga.edu</EmailAddress>
<PI_PHON>7065420120</PI_PHON>
<NSF_ID>000274904</NSF_ID>
<StartDate>04/25/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Georgia Research Foundation Inc</Name>
<CityName>ATHENS</CityName>
<ZipCode>306021589</ZipCode>
<PhoneNumber>7065425939</PhoneNumber>
<StreetAddress>310 East Campus Rd</StreetAddress>
<StreetAddress2><![CDATA[Tucker Hall Room 409]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004315578</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Georgia]]></Name>
<CityName>athens</CityName>
<StateCode>GA</StateCode>
<ZipCode>306025016</ZipCode>
<StreetAddress><![CDATA[101 cedar street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~238040</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>(1) In this project, we provide the first interpretation of algorithmic leveraging paradigm from a statistical analysis point of view. Both theoretical and empirical results are generated for current and newly proposed estimators based on statistical leveraging.</p> <p>(2) We provide a speeded up algorithm for a more scalable computation in the multivariate case by evaluating the smoothing spline using a smaller set of basis functions, according to the slicing along the range of the response variable.</p> <p>(3) We develop a simple and efficient matrix classification method, matrix discriminant analysis (MDA), as well as a penalized version, PMDA to improve the classification sensitivity and specificity of colorimetric sensor array (CSA) data.</p> <p>(4) We provide a gamma conversion method, where we first fit a gamma distribution to the data and then, via moment matching, estimate bi-exponential parameters to single-molecule fluorescence lifetime experiments data.</p> <p><span lang="EN-US">(5)&nbsp;We propose a weighted leverage score based on both U(i) and V(j) for variable screening in a very general sufficient dimension reduction models that will be introduced in next section. To ease the presentation, we assume that the average of each column of X is normalized to have mean zero without loss of generality. We briefly review the general framework of sliced inverse regression and introduce the weighted leverage score for variable screening, illustrates the asymptotic behavior and rank consistency of weighted leverage score and do some simulation studies and real data applications.</span></p> <p><span lang="EN-US">(6) We propose a reference-free and distribution-free binning method, MetaGen, which makes use of the relative abundance information from multiple samples to cluster contigs into different species bins and the Bayesian information criterion (BIC) to determine the number of species in the samples. Compared with existing unsupervised binning methods, MetaGen not only clusters short contigs accurately for samples with low coverage but also has the ability to distinguish species with high sequence similarities. In addition, MetaGen can estimate the relative abundance of cultured and uncultured species simultaneously, which provides a way to study distributional changes of microbial colony dynamically and spatially. Moreover, MetaGen is not susceptible to sequencing biases, which gives it an important advantage over many existing methods. MetaGen is also computationally more efficient than existing k-mer methods and can easily handle large data sets with more than 500,000 contigs.</span></p> <p>(7) We consider a streaming time series data, which, for simplicity, is assumed to come from a non-explosive p-th order autoregressive (AR(p)) model with p&gt;=1 and work out a unified statistical inference for parameters of such models using a subsample of random size drawn sequentially from the streaming data based on a stopping rule.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/28/2016<br>      Modified by: Wenxuan&nbsp;Zhong</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ (1) In this project, we provide the first interpretation of algorithmic leveraging paradigm from a statistical analysis point of view. Both theoretical and empirical results are generated for current and newly proposed estimators based on statistical leveraging.  (2) We provide a speeded up algorithm for a more scalable computation in the multivariate case by evaluating the smoothing spline using a smaller set of basis functions, according to the slicing along the range of the response variable.  (3) We develop a simple and efficient matrix classification method, matrix discriminant analysis (MDA), as well as a penalized version, PMDA to improve the classification sensitivity and specificity of colorimetric sensor array (CSA) data.  (4) We provide a gamma conversion method, where we first fit a gamma distribution to the data and then, via moment matching, estimate bi-exponential parameters to single-molecule fluorescence lifetime experiments data.  (5) We propose a weighted leverage score based on both U(i) and V(j) for variable screening in a very general sufficient dimension reduction models that will be introduced in next section. To ease the presentation, we assume that the average of each column of X is normalized to have mean zero without loss of generality. We briefly review the general framework of sliced inverse regression and introduce the weighted leverage score for variable screening, illustrates the asymptotic behavior and rank consistency of weighted leverage score and do some simulation studies and real data applications.  (6) We propose a reference-free and distribution-free binning method, MetaGen, which makes use of the relative abundance information from multiple samples to cluster contigs into different species bins and the Bayesian information criterion (BIC) to determine the number of species in the samples. Compared with existing unsupervised binning methods, MetaGen not only clusters short contigs accurately for samples with low coverage but also has the ability to distinguish species with high sequence similarities. In addition, MetaGen can estimate the relative abundance of cultured and uncultured species simultaneously, which provides a way to study distributional changes of microbial colony dynamically and spatially. Moreover, MetaGen is not susceptible to sequencing biases, which gives it an important advantage over many existing methods. MetaGen is also computationally more efficient than existing k-mer methods and can easily handle large data sets with more than 500,000 contigs.  (7) We consider a streaming time series data, which, for simplicity, is assumed to come from a non-explosive p-th order autoregressive (AR(p)) model with p&gt;=1 and work out a unified statistical inference for parameters of such models using a subsample of random size drawn sequentially from the streaming data based on a stopping rule.                         Last Modified: 11/28/2016       Submitted by: Wenxuan Zhong]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
