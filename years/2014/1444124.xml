<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Efficient Data Reduction and Summarization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/16/2014</AwardEffectiveDate>
<AwardExpirationDate>02/28/2015</AwardExpirationDate>
<AwardTotalIntnAmount>104922.00</AwardTotalIntnAmount>
<AwardAmount>104922</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tie Luo</SignBlockName>
<PO_EMAI>tluo@nsf.gov</PO_EMAI>
<PO_PHON>7032928448</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ubiquitous phenomenon of massive data (including data streams) imposes considerable challenges in data visualization and exploratory data analysis. About 15 years ago, terabyte datasets were still considered `ridiculous.' However, modern datasets managed by Stanford Linear Acceleration Center (SLAC), NASA, NSA, etc. have reached the perabyte scale or larger. Corporations such as Amazon, Wal-Mart, Ebay, and search engine firms are also major generators and users of massive data. The general theme of data reduction and summarization has become an active and highly inter-disciplinary area of research. This project proposes to develop various approximation techniques, which generate a "fingerprint" or "sketch" of the massive data by transforming the original data. These `sketches' are reasonably small (hence easy to store) and can provide approximate answers which are usually good enough for practical purposes. &lt;br/&gt;&lt;br/&gt;This proposal concerns the fundamental problems of processing/transforming massive (possibly dynamic) data. In particular, it focuses on (A) developing systematic fundamental tools for effective data reduction and efficient data summarization; (B) applying these tools to improve numerical analysis, visualization, and exploratory data analysis.  Two lines of theoretically sound techniques for data reduction and summarization will be developed and further improved: (1) the method of stable random projections (SRP), effective in heavy-tailed data; (2) the method of Conditional Random Sampling (CRS), mainly for sparse data. Concrete applications of SRP and CRS will be investigated. Widely-used basic numerical algorithms can be rewritten by taking advantage of SRP or CRS. Popular methods/tools for exploratory data analysis will also benefit considerably from the development of data reduction techniques.</AbstractNarration>
<MinAmdLetterDate>08/05/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1444124</AwardID>
<Investigator>
<FirstName>Ping</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ping Li</PI_FULL_NAME>
<EmailAddress>pingli@stat.rutgers.edu</EmailAddress>
<PI_PHON>8484457667</PI_PHON>
<NSF_ID>000083097</NSF_ID>
<StartDate>08/05/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName/>
<StateCode>NJ</StateCode>
<ZipCode>089018559</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<ProgramElement>
<Code>7703</Code>
<Text>FOUNDATIONS VISUAL ANALYTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~104921</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In numerous modern practical scenarios in the era of &nbsp;"big data", &nbsp;efficient&nbsp;&nbsp;techniques for data reduction and summarization can be crucial. Practical data are often massive and extremely high-dimensional, making efficient data computations, visualization, storage, transmission, and retrieval difficult. Applying routine statistical machine learning methods on massive data &nbsp;can also become very challenging. The goal of this project is to develop practical and mathematically rigorous algorithms for achieving highly efficient data reduction, to ease the use of massive data for machine learning, data mining, databases, information retrieval, etc. &nbsp;In particular, the focus is on novel algorithms based on stable random projections, &nbsp;minwise hashing, one permutation hashing, and&nbsp;conditional random sampling. &nbsp; The project has been successful in that quite a few novel data reduction algorithms have been developed and tested. These methods have attracted attention from industry and it is expected that some of them will become standard industry practice for search and learning. The research activities have also been generalized to matrix &amp; vector recovery, matrix competition, nonnegative regression, and hashing. The project has (partially) supported multiple Ph.D. students and postdoctoral researchers. Some of them have started (or landed) tenure-track faculty positions to continue the research on data reduction techniques.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/13/2015<br>      Modified by: Ping&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In numerous modern practical scenarios in the era of  "big data",  efficient  techniques for data reduction and summarization can be crucial. Practical data are often massive and extremely high-dimensional, making efficient data computations, visualization, storage, transmission, and retrieval difficult. Applying routine statistical machine learning methods on massive data  can also become very challenging. The goal of this project is to develop practical and mathematically rigorous algorithms for achieving highly efficient data reduction, to ease the use of massive data for machine learning, data mining, databases, information retrieval, etc.  In particular, the focus is on novel algorithms based on stable random projections,  minwise hashing, one permutation hashing, and conditional random sampling.   The project has been successful in that quite a few novel data reduction algorithms have been developed and tested. These methods have attracted attention from industry and it is expected that some of them will become standard industry practice for search and learning. The research activities have also been generalized to matrix &amp; vector recovery, matrix competition, nonnegative regression, and hashing. The project has (partially) supported multiple Ph.D. students and postdoctoral researchers. Some of them have started (or landed) tenure-track faculty positions to continue the research on data reduction techniques.           Last Modified: 06/13/2015       Submitted by: Ping Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
