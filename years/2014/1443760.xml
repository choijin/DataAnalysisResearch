<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Closed-Loop Crowd Support for People with Disabilities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/31/2013</AwardEffectiveDate>
<AwardExpirationDate>01/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>340379.00</AwardTotalIntnAmount>
<AwardAmount>398379</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>To overcome accessibility problems, people with disabilities have traditionally relied upon the support of others in their community.  For instance, a volunteer may offer a few minutes of her time to read a blind person's mail aloud, or a fellow traveler may answer a quick question at the bus stop (e.g., "Is that the 45 coming?").  Professionals such as sign language interpreters and narrators of audio descriptions convert sensory information into alternative forms that enable a deaf student to participate in a conventional lecture and a blind person to enjoy a movie.  Internet connectivity has dramatically expanded the pool of potential human supporters, but finding reliable assistance on demand remains difficult.  The PI's goal in this project is to enable dynamic and diverse groups of people reachable via the Web ("the crowd") to interactively support people with disabilities.  The crowd is whoever happens to be available, from paid workers recruited on burgeoning micro-task marketplaces, to friends and family recruited via existing social networks, to volunteers willing to give a few minutes of their time.  While someone is always available, the crowd is dynamic and individual workers can be unreliable.  Thus, developing interactive systems to support people with disabilities presents numerous challenges, including how to enable crowd support that is real-time and high-quality, how to design interfaces that provide effective feedback even when an individual's directions may not be followed, and how to support collaboration among individual crowd workers without subverting methods of ensuring reliability.  To these ends, the PI will explore closed-loop crowd support with a number of applications.  VizWiz Stream will enable blind users to engage in an interactive conversation with the crowd about their visual environment.  AudioWiz Stream will provide nearly real-time transcription of aural speech.  And Legion and Legion VM will enable the crowd to collectively assume control of the keyboard and mouse to complete a user-specified task on existing desktop interfaces (whereas research in human-computer interaction usually assumes either a single user or a group of users collaborating in the same virtual space each in control of a personal cursor, this project will advance a new model in which a diverse and dynamic group collectively acts as a single operator).  These applications will inform a common model for closed-loop crowd support, and will be iteratively improved and evaluated in lab studies and field deployments with blind and deaf users.&lt;br/&gt;&lt;br/&gt;Broader Impacts:   Project outcomes will enable people with disabilities to overcome more accessibility problems independently and on demand.  The PI will release the software tools developed as part of this research as open source code, thereby enabling other researchers to build on his results.  Although initially intended for use by blind and deaf people, the tools will likely prove useful as well to people with other disabilities such as cognitive or motor impairments, and people without disabilities may want to outsource interactive tasks which they cannot do, do not want to do, or think the crowd may do better.  The PI will conduct annual summer programs in which blind and deaf high school students will develop tools for closed-loop crowd support, and also serve as supporters for people with different disabilities; these activities may encourage some of the participants with disabilities to pursue careers in computing, and the undergraduate students who help develop and run these activities will gain  personal exposure to accessible computing and the challenges people with disabilities face in computing that they will carry with them into their careers.</AbstractNarration>
<MinAmdLetterDate>06/10/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/25/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1443760</AwardID>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Bigham</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeffrey Bigham</PI_FULL_NAME>
<EmailAddress>jbigham@cmu.edu</EmailAddress>
<PI_PHON>5852754031</PI_PHON>
<NSF_ID>000541549</NSF_ID>
<StartDate>06/10/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7233</Code>
<Text>RES EXPERIENCE FOR TEACHERS(RET)-SUPPLEM</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~14584</FUND_OBLG>
<FUND_OBLG>2014~134301</FUND_OBLG>
<FUND_OBLG>2015~223494</FUND_OBLG>
<FUND_OBLG>2016~26000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>People with disabilities have relied on the support of people in their communities to overcome accessibility problems for centuries. For instance, a volunteer may offer a few minutes of her time to read a blind person&rsquo;s mail aloud, or a fellow traveler may answer a quick question at the bus stop, e.g., &ldquo;Is that the 45 coming?&rdquo; Professional workers, such as sign language interpretors and audio descriptionists, convert sensory information into alternative forms, enabling a deaf student to participate in a traditional lecture and a blind person to enjoy (or learn from) a movie. Internet connectivity has dramatically expanded the pool of potential human supporters, but finding reliable assistance on-demand remains difficult. </span></p> <p><span>This project developed general mechanisms enabling a dynamic and diverse groups of people reachable via the Web (</span><span>the crowd</span><span>) to interactively support people with disabilities. The crowd is whoever happens to be available &mdash; from paid workers recruited on burgeoning micro-task marketplaces like Amazon Mechanical Turk, to friends and family recruited via existing social networks, to volunteers willing to give a few minutes of their time. While someone is always available, the crowd is dynamic and individual workers can be unreliable. The results of this research help to allow the crowd to reliably support people with disabilities in real-time, in the real world.</span></p> </div> </div> </div> <p><span>Work in human-computer interaction usually assumes either a s single user, or groups of users collaborating in the same virtual space, each in control of a personal cursor. This work has advanced a new model in which a diverse and dynamic group (the crowd) collectively acts as a single operator. To be useful in the everyday lives of people with disabilities, crowd support needs to be interactive, but human computation (computation in which some steps are outsourced to people) was previously slow. Introducing redundancy and layering into tasks so that multiple workers contribute and verify results at each stage increases latency. Developing interactive systems to support people with disabilities required addressing numerous research challenges, including (i) how to enable crowd support that is real-time and high-quality, (ii) how to design interfaces that provide effective feedback even when an individual&rsquo;s directions may not be followed, and (iii) how to support collaboration between individual crowd workers without subverting methods of ensuring reliability.<br /><br />This project not only advanced human computation methods, but also built and tested several applications of them. For insance, VizWiz and the more recent VizLens, help blind people answer visual questions and help blind people use inaccessible interfaces, respectively. As another example, Scribe allows a group to convert speech to text to make it accessible to deaf and hard of hearing individuals with less than 5 second latency. These explorations into applications led to a number of new research problems in, for instance, helping blind people take better photographs, combining automated speech recognition and human input, and structuring social media to get answers back in a scalable and affordable way.<br /><br />This award had a number of broader impacts. First, it helped to fund PhD and undergraduate students, who received research training, and have gone to contribute at various companies and universities. It helped to fund several summer programs for students with disabilities, in which high school students with disabilities were introduced to computer science. Finally, it has led to a new course at Carnegie Mellon University on Crowd Computation, which has been offered three times thus far. Materials have been posted on the Web and used to help develop similar courses at several other institutions.</span></p> </div> </div> </div><br> <p>            Last Modified: 04/08/2017<br>      Modified by: Jeffrey&nbsp;Bigham</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[       People with disabilities have relied on the support of people in their communities to overcome accessibility problems for centuries. For instance, a volunteer may offer a few minutes of her time to read a blind person?s mail aloud, or a fellow traveler may answer a quick question at the bus stop, e.g., "Is that the 45 coming?" Professional workers, such as sign language interpretors and audio descriptionists, convert sensory information into alternative forms, enabling a deaf student to participate in a traditional lecture and a blind person to enjoy (or learn from) a movie. Internet connectivity has dramatically expanded the pool of potential human supporters, but finding reliable assistance on-demand remains difficult.   This project developed general mechanisms enabling a dynamic and diverse groups of people reachable via the Web (the crowd) to interactively support people with disabilities. The crowd is whoever happens to be available &mdash; from paid workers recruited on burgeoning micro-task marketplaces like Amazon Mechanical Turk, to friends and family recruited via existing social networks, to volunteers willing to give a few minutes of their time. While someone is always available, the crowd is dynamic and individual workers can be unreliable. The results of this research help to allow the crowd to reliably support people with disabilities in real-time, in the real world.     Work in human-computer interaction usually assumes either a s single user, or groups of users collaborating in the same virtual space, each in control of a personal cursor. This work has advanced a new model in which a diverse and dynamic group (the crowd) collectively acts as a single operator. To be useful in the everyday lives of people with disabilities, crowd support needs to be interactive, but human computation (computation in which some steps are outsourced to people) was previously slow. Introducing redundancy and layering into tasks so that multiple workers contribute and verify results at each stage increases latency. Developing interactive systems to support people with disabilities required addressing numerous research challenges, including (i) how to enable crowd support that is real-time and high-quality, (ii) how to design interfaces that provide effective feedback even when an individual?s directions may not be followed, and (iii) how to support collaboration between individual crowd workers without subverting methods of ensuring reliability.  This project not only advanced human computation methods, but also built and tested several applications of them. For insance, VizWiz and the more recent VizLens, help blind people answer visual questions and help blind people use inaccessible interfaces, respectively. As another example, Scribe allows a group to convert speech to text to make it accessible to deaf and hard of hearing individuals with less than 5 second latency. These explorations into applications led to a number of new research problems in, for instance, helping blind people take better photographs, combining automated speech recognition and human input, and structuring social media to get answers back in a scalable and affordable way.  This award had a number of broader impacts. First, it helped to fund PhD and undergraduate students, who received research training, and have gone to contribute at various companies and universities. It helped to fund several summer programs for students with disabilities, in which high school students with disabilities were introduced to computer science. Finally, it has led to a new course at Carnegie Mellon University on Crowd Computation, which has been offered three times thus far. Materials have been posted on the Web and used to help develop similar courses at several other institutions.          Last Modified: 04/08/2017       Submitted by: Jeffrey Bigham]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
