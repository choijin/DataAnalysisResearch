<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: BaaS: Benchmarking-As-A-Service for Improved Visibility, Diagnosis, and Control of Modern Data Analytics Platforms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>449998.00</AwardTotalIntnAmount>
<AwardAmount>449998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>System benchmarking is a critical technique used by application developers and system administrators to help them decide how best to perform a wide spectrum of system management tasks. These tasks range from design-time aspects such as picking which system to use for an application, to all pre-deployment aspects of testing and tuning the applications and system, and to production aspects such as reliability assurance and problem diagnosis. However, the reality today is that the massive potential of benchmarking is seldom harnessed satisfactorily by application developers and system administrators. Benchmarking is very human-effort-intensive. Users may not be aware of or follow correct benchmarking methodology.  Often corners are cut to reduce either time or cost without full awareness of the implications of doing so. Repeatability and reuse of benchmarking results are often unattainable. The results of a benchmarking effort may be misinterpreted, leading to incorrect or suboptimal decisions.&lt;br/&gt;&lt;br/&gt;This project combines new research with recent technology trends in order to make the power of benchmarking accessible to a diverse community of users. The project is building a Benchmarking-as-a-Service (BaaS) platform that runs on top of an Infrastructure-as-a-Service or Platform-as-a-Service cloud platform. A BaaS provides four integrated services to simplify the overall benchmarking process, while addressing a number of novel technical challenges:  1. Design: Helps the user create the workloads and data that best meet her specific benchmarking needs, using the concept of benchmark design as a search problem; 2. Execute: Helps the user run the selected workloads on appropriate data, system configurations, and hardware and software resources in a timely and cost-efficient manner; 3. Interpret: Helps the user interpret the results of the benchmark correctly since many users who run benchmarks on systems are far from being experts on these systems (many challenges arise here due to the large volume, variety, and velocity of system monitoring data); and 4. Build: Helps the user build new system management services on top of the BaaS. For example, BaaS enables the automatic tuning of production database instances running on cloud platforms like Amazon Web Services and SQL Azure. BaaS is being prototyped and opportunities for deploying it in real-world settings will be pursued. The prototype will be used to evaluate the transformative capabilities of BaaS towards increasing the productivity of humans and systems, and in avoiding wrong decisions involving mission-critical systems.</AbstractNarration>
<MinAmdLetterDate>08/06/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1423128</AwardID>
<Investigator>
<FirstName>Shivnath</FirstName>
<LastName>Babu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shivnath Babu</PI_FULL_NAME>
<EmailAddress>shivnath@cs.duke.edu</EmailAddress>
<PI_PHON>9196606579</PI_PHON>
<NSF_ID>000488390</NSF_ID>
<StartDate>08/06/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName/>
<StateCode>NC</StateCode>
<ZipCode>277054010</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~449998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 15.0px Menlo} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 15.0px Menlo; min-height: 18.0px} span.s1 {font-variant-ligatures: no-common-ligatures} --> <p class="p1"><span class="s1">System benchmarking is critical technique used by&nbsp;</span></p> <p class="p1"><span class="s1">application developers and system administrators&nbsp;</span></p> <p class="p1"><span class="s1">to help them decide how best to perform a wide&nbsp;</span></p> <p class="p1"><span class="s1">spectrum of system management tasks. These tasks range</span></p> <p class="p1"><span class="s1">from design-time aspects such as picking which system to&nbsp;</span></p> <p class="p1"><span class="s1">use for an application,&nbsp;</span></p> <p class="p1"><span class="s1">to all pre-deployment aspects of testing and tuning&nbsp;</span></p> <p class="p1"><span class="s1">the applications and system, and to production aspects such as&nbsp;</span></p> <p class="p1"><span class="s1">SLA maintenance, reliability assurance, and problem diagnosis.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">However, the reality today is that the massive potential&nbsp;</span></p> <p class="p1"><span class="s1">of benchmarking is seldom harnessed satisfactorily</span></p> <p class="p1"><span class="s1">by application developers and system administrators.&nbsp;</span></p> <p class="p1"><span class="s1">Benchmarking is very human-effort-intensive. Users may not</span></p> <p class="p1"><span class="s1">be aware of or follow correct benchmarking methodology.&nbsp;</span></p> <p class="p1"><span class="s1">Often corners are cut either to reduce time or cost without</span></p> <p class="p1"><span class="s1">being fully aware of the implications of doing so.</span></p> <p class="p1"><span class="s1">Repeatability and reuse of benchmarking results are often&nbsp;</span></p> <p class="p1"><span class="s1">unattainable. The results of a benchmarking effort may be&nbsp;</span></p> <p class="p1"><span class="s1">misinterpreted, possibly leading to incorrect or suboptimal decisions.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">This project combined new research with recent technology trends in order to make the power of benchmarking accessible to a diverse community of users. The project is developed&nbsp; a Benchmarking-as-a-Service (BaaS) platform that runs on top of an Infrastructure-as-a-Service (IaaS) or Platform-as-a-Service (PaaS) cloud platform. A BaaS provides four integrated services to simplify the overall benchmarking process, while addressing a number of novel technical challenges:</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">1. Design: Help the user create the workloads and data that best meet her specific benchmarking needs. The proposal introduced&nbsp; the concept of benchmark design as a search problem.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">2. Execute: Help the user run the selected workloads on appropriate data, system configurations, and hardware and software resources in a timely and cost-efficient fashion.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">3. Interpret: Help the user interpret the results of the benchmark correctly. Many challenges in handling the large volume, variety, and velocity of system monitoring data arise here. This part is particularly important since the people who run benchmarks on systems are often far from being experts on these systems.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">4. Build: Help the user build new system management services on top of the BaaS. For example, BaaS enables services that automatically tune production database instances running on cloud platforms like Amazon Web Services or SQL Azure.</span></p> <p class="p2"><span class="s1">&nbsp;</span></p> <p class="p1"><span class="s1">BaaS was prototyped in this project. Opportunities for deploying it in real-world settings were pursued. The prototype was used to evaluate the transformative capabilities of BaaS towards</span></p> <p class="p1"><span class="s1">increasing the productivity of humans and systems, and in avoiding wrong decisions involving mission-critical systems.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 07/10/2017<br>      Modified by: Shivnath&nbsp;Babu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ System benchmarking is critical technique used by  application developers and system administrators  to help them decide how best to perform a wide  spectrum of system management tasks. These tasks range from design-time aspects such as picking which system to  use for an application,  to all pre-deployment aspects of testing and tuning  the applications and system, and to production aspects such as  SLA maintenance, reliability assurance, and problem diagnosis.   However, the reality today is that the massive potential  of benchmarking is seldom harnessed satisfactorily by application developers and system administrators.  Benchmarking is very human-effort-intensive. Users may not be aware of or follow correct benchmarking methodology.  Often corners are cut either to reduce time or cost without being fully aware of the implications of doing so. Repeatability and reuse of benchmarking results are often  unattainable. The results of a benchmarking effort may be  misinterpreted, possibly leading to incorrect or suboptimal decisions.   This project combined new research with recent technology trends in order to make the power of benchmarking accessible to a diverse community of users. The project is developed  a Benchmarking-as-a-Service (BaaS) platform that runs on top of an Infrastructure-as-a-Service (IaaS) or Platform-as-a-Service (PaaS) cloud platform. A BaaS provides four integrated services to simplify the overall benchmarking process, while addressing a number of novel technical challenges:   1. Design: Help the user create the workloads and data that best meet her specific benchmarking needs. The proposal introduced  the concept of benchmark design as a search problem.   2. Execute: Help the user run the selected workloads on appropriate data, system configurations, and hardware and software resources in a timely and cost-efficient fashion.   3. Interpret: Help the user interpret the results of the benchmark correctly. Many challenges in handling the large volume, variety, and velocity of system monitoring data arise here. This part is particularly important since the people who run benchmarks on systems are often far from being experts on these systems.   4. Build: Help the user build new system management services on top of the BaaS. For example, BaaS enables services that automatically tune production database instances running on cloud platforms like Amazon Web Services or SQL Azure.   BaaS was prototyped in this project. Opportunities for deploying it in real-world settings were pursued. The prototype was used to evaluate the transformative capabilities of BaaS towards increasing the productivity of humans and systems, and in avoiding wrong decisions involving mission-critical systems.          Last Modified: 07/10/2017       Submitted by: Shivnath Babu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
