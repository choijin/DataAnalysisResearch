<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Crowd-Sourcing the World: Scalable Methods for Dynamic Structure from Motion</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>477428.00</AwardTotalIntnAmount>
<AwardAmount>477428</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project enables global-scale dynamic reconstructions that can scale to eventually encompass all of the world's 3D data, to which any user may contribute new visual data, thereby ensuring a more complete, up-to-date model and a better experience for users of applications that rely on such data. The abundance of publicly available imagery from a variety of sources (consumer, industry, and government) and the proliferation of networked mobile devices equipped with cameras provide an opportunity to build large-scale 3D models that cover the entire world. Such global 3D models are invaluable to a wide range of applications that require real-time access to environment structure, such as providing assistance to the visually impaired, exploring dangerous areas for search-and rescue operations, urban planning, self-driving cars, and virtual tourism. &lt;br/&gt;&lt;br/&gt;The key research question driving this work is how to efficiently and accurately update a global-scale 3D reconstruction in order to support a dynamic global model. The research uses structure from motion (SfM) techniques to acquire global context for 3D modeling and then propagate local 3D reconstructions and other visual data back to the global model via a new technique called "globalization." The project addresses a major gap in large-scale SfM: rapidly extending and updating reconstructions to promote real-time use. The project is built on preliminary work in large-scale image matching, localization, and 3D reconstruction. The research team carries out extensive data collection and experimentation to benchmark the performance of the developed techniques and to assess the progress of the project and the utility of the methods. The project is developing a prototype mobile system for contributing imagery and browsing and updating models for public use once it is available.</AbstractNarration>
<MinAmdLetterDate>08/14/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1423676</AwardID>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Turk</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew Turk</PI_FULL_NAME>
<EmailAddress>mturk@cs.ucsb.edu</EmailAddress>
<PI_PHON>8058934236</PI_PHON>
<NSF_ID>000245931</NSF_ID>
<StartDate>08/14/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tobias</FirstName>
<LastName>Hollerer</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tobias H Hollerer</PI_FULL_NAME>
<EmailAddress>holl@cs.ucsb.edu</EmailAddress>
<PI_PHON>8058938759</PI_PHON>
<NSF_ID>000166428</NSF_ID>
<StartDate>08/14/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Santa Barbara</Name>
<CityName>Santa Barbara</CityName>
<ZipCode>931062050</ZipCode>
<PhoneNumber>8058934188</PhoneNumber>
<StreetAddress>Office of Research</StreetAddress>
<StreetAddress2><![CDATA[Rm 3227 Cheadle Hall]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA24</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>094878394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SANTA BARBARA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Santa Barbara]]></Name>
<CityName>Santa Barbara</CityName>
<StateCode>CA</StateCode>
<ZipCode>931065110</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA24</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~147287</FUND_OBLG>
<FUND_OBLG>2015~330141</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The project developed new methods for modeling large-scale 3D structures such as buildings, outdoor areas, and equipment and making such reconstructions useful in virtual exploration and navigation. Building on existing structure from motion (SfM) methods, the project aimed to enable efficient and effective large-scale reconstructions that can be extended via multiple data sources (e.g., by crowdsourcing), and to make the reconstructions useful for remote interaction applications. The project resulted in new algorithms and prototypes for 3D imaging and interaction, several publications (and awards) in top research venues, the training of several undergraduate and graduate students, and impacting the success of a startup company that was eventually acquired for its key technology and people.</p> <p>&nbsp;</p> <p>Initial work in the project focused on advances toward a multi-user, collaborative augmented reality system that will collectively extend and enhance reconstructions of (possibly large) urban environments. This led to the concept of ?globalization,? which allows for continuous updating of 3D models with visual data from live users, filling coverage gaps common in 3D reconstruction. A core component of this consisted of advances in modeling and calibrating the distributed camera model, which treats all samples from a collection of camera views as a single meta-camera. New results were achieved in distributed camera localization (estimating the pose and scale of all camera perspectives) and SfM based on merging distributed camera models. Continued work focused on making sense of the generated large-scale models to use for interactive purposes, such as virtual exploration, and providing advanced tools for navigating and annotating image-based 3D reconstructed scenes. In addition to algorithmic advances, this resulted in user studies that advanced our understanding of the human side of the equation.</p> <p>&nbsp;</p> <p>The project supported research leading to an ISMAR 2015 best short paper award, a 3DUI 2016 best paper honorable mention, winning the 2015 ACM Multimedia Open Source Software Competition, a successful NSF Graduate Fellowship award, and development of the Theia open-source library for fast and scalable multi-view geometry computations, which has been widely used.</p> <p>&nbsp;</p> <p>Two PhD students focused on these challenges for their dissertation work, and others were involved in various capacities over the course of the project. The work has been widely disseminated via peer-reviewed papers, talks, the lab?s website, course lectures, and in a variety of outreach events (to high school students, underrepresented groups, and the general public) at UC Santa Barbara and in the local community. A local innovation museum continues to indicate interest in using some of the results in a museum showcase. The startup company that spun out from the lab?s research on this (and another) NSF-funded topic provided new opportunities and experiences for some of the personnel and allowed for direct transfer of the research to a widely-used commercial system.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/29/2018<br>      Modified by: Matthew&nbsp;Turk</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831741521_Anexampleofincomplete3Dstructurefromimagesensing--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831741521_Anexampleofincomplete3Dstructurefromimagesensing--rgov-800width.jpg" title="Figure 5"><img src="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831741521_Anexampleofincomplete3Dstructurefromimagesensing--rgov-66x44.jpg" alt="Figure 5"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An example of incomplete 3D structure from image sensing</div> <div class="imageCredit">Ben Nuernberger</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthew&nbsp;Turk</div> <div class="imageTitle">Figure 5</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831274524_ThecoreBestViewmethodtodeterminewheretocollectmoredata--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831274524_ThecoreBestViewmethodtodeterminewheretocollectmoredata--rgov-800width.jpg" title="Figure 3"><img src="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831274524_ThecoreBestViewmethodtodeterminewheretocollectmoredata--rgov-66x44.jpg" alt="Figure 3"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The core Best View method to determine where to collect more data</div> <div class="imageCredit">Chris Sweeney</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthew&nbsp;Turk</div> <div class="imageTitle">Figure 3</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831164380_Distributedcameracalibration--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831164380_Distributedcameracalibration--rgov-800width.jpg" title="Figure 1"><img src="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831164380_Distributedcameracalibration--rgov-66x44.jpg" alt="Figure 1"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Distributed camera calibration</div> <div class="imageCredit">Chris Sweeney</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthew&nbsp;Turk</div> <div class="imageTitle">Figure 1</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831210444_Distributedcameraposeresults--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831210444_Distributedcameraposeresults--rgov-800width.jpg" title="Figure 2"><img src="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831210444_Distributedcameraposeresults--rgov-66x44.jpg" alt="Figure 2"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Distributed camera pose results</div> <div class="imageCredit">Chris Sweeney</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthew&nbsp;Turk</div> <div class="imageTitle">Figure 2</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831882374_Interpretingincomplete3Dmodelsfromimagery--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831882374_Interpretingincomplete3Dmodelsfromimagery--rgov-800width.jpg" title="Figure 4"><img src="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540831882374_Interpretingincomplete3Dmodelsfromimagery--rgov-66x44.jpg" alt="Figure 4"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Interpreting incomplete 3D models from imagery</div> <div class="imageCredit">Ben Nuernberger</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthew&nbsp;Turk</div> <div class="imageTitle">Figure 4</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540832003821_Anexampleofuserinteractiontodetermineusefulgeometricinformationfromimage-basedmodels--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540832003821_Anexampleofuserinteractiontodetermineusefulgeometricinformationfromimage-basedmodels--rgov-800width.jpg" title="Figure 6"><img src="/por/images/Reports/POR/2018/1423676/1423676_10332471_1540832003821_Anexampleofuserinteractiontodetermineusefulgeometricinformationfromimage-basedmodels--rgov-66x44.jpg" alt="Figure 6"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An example of user interaction to determine useful geometric information from image-based models</div> <div class="imageCredit">Ben Nuernberger</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthew&nbsp;Turk</div> <div class="imageTitle">Figure 6</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project developed new methods for modeling large-scale 3D structures such as buildings, outdoor areas, and equipment and making such reconstructions useful in virtual exploration and navigation. Building on existing structure from motion (SfM) methods, the project aimed to enable efficient and effective large-scale reconstructions that can be extended via multiple data sources (e.g., by crowdsourcing), and to make the reconstructions useful for remote interaction applications. The project resulted in new algorithms and prototypes for 3D imaging and interaction, several publications (and awards) in top research venues, the training of several undergraduate and graduate students, and impacting the success of a startup company that was eventually acquired for its key technology and people.     Initial work in the project focused on advances toward a multi-user, collaborative augmented reality system that will collectively extend and enhance reconstructions of (possibly large) urban environments. This led to the concept of ?globalization,? which allows for continuous updating of 3D models with visual data from live users, filling coverage gaps common in 3D reconstruction. A core component of this consisted of advances in modeling and calibrating the distributed camera model, which treats all samples from a collection of camera views as a single meta-camera. New results were achieved in distributed camera localization (estimating the pose and scale of all camera perspectives) and SfM based on merging distributed camera models. Continued work focused on making sense of the generated large-scale models to use for interactive purposes, such as virtual exploration, and providing advanced tools for navigating and annotating image-based 3D reconstructed scenes. In addition to algorithmic advances, this resulted in user studies that advanced our understanding of the human side of the equation.     The project supported research leading to an ISMAR 2015 best short paper award, a 3DUI 2016 best paper honorable mention, winning the 2015 ACM Multimedia Open Source Software Competition, a successful NSF Graduate Fellowship award, and development of the Theia open-source library for fast and scalable multi-view geometry computations, which has been widely used.     Two PhD students focused on these challenges for their dissertation work, and others were involved in various capacities over the course of the project. The work has been widely disseminated via peer-reviewed papers, talks, the lab?s website, course lectures, and in a variety of outreach events (to high school students, underrepresented groups, and the general public) at UC Santa Barbara and in the local community. A local innovation museum continues to indicate interest in using some of the results in a museum showcase. The startup company that spun out from the lab?s research on this (and another) NSF-funded topic provided new opportunities and experiences for some of the personnel and allowed for direct transfer of the research to a widely-used commercial system.          Last Modified: 10/29/2018       Submitted by: Matthew Turk]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
