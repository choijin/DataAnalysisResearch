<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Global, Stable Descriptors of Visual Motion</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2014</AwardEffectiveDate>
<AwardExpirationDate>12/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>450044.00</AwardTotalIntnAmount>
<AwardAmount>458044</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project studies the fundamental mathematics of how to describe the motions visible in a video recording. The developed techniques allow accurately delineating the boundaries between image regions that move differently from each other. The resulting description of motion can be used as input for recognizing activities in video. Applications include surveillance, traffic monitoring, video retrieval, robot navigation, assistance to human vehicle drivers, medical diagnosis of movement pathology, assessment of performance in sports or other activities, sign language recognition, and automatic video annotation.&lt;br/&gt;&lt;br/&gt;Current approaches define visual motion as a point-to-point mapping across video frames. However, image data in poorly textured areas constrain point motion weakly if at all. Since these areas are pervasive, computing point-to-point motion requires strong and often arbitrary assumptions about the scene. This project redefines image motion as a curve-to-curve mapping. The curves in question are iso-contours, that is, the curves in each video frame along which image brightness is constant. Techniques from computational topology are used and extended to describe how iso-contours in one frame connect to those in the next, forming surfaces in spacetime. The concept of persistence from computational topology, together with a new notion of feature longevity, allow separating ephemeral changes caused by image noise or lighting artifacts from features that reoccur consistently over time. The research can provide a global, topological, stable description of image motion. The research team evaluates the techniques on both existing video and on sequences newly recorded with specialized cameras to isolate different technical challenges in turn. Other researchers can use these sequences for further experimentation when they are ready to be published.</AbstractNarration>
<MinAmdLetterDate>07/11/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/06/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1420894</AwardID>
<Investigator>
<FirstName>Carlo</FirstName>
<LastName>Tomasi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Carlo Tomasi</PI_FULL_NAME>
<EmailAddress>tomasi@cs.duke.edu</EmailAddress>
<PI_PHON>9196606539</PI_PHON>
<NSF_ID>000107168</NSF_ID>
<StartDate>07/11/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<StateCode>NC</StateCode>
<ZipCode>277080129</ZipCode>
<StreetAddress><![CDATA[Computer Science Department]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~450044</FUND_OBLG>
<FUND_OBLG>2015~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>This project resulted in theoretical and practical advances in the computerized analysis of video. A wide array of applications depends on these automatic analysis methods, including systems that retrieve video from large repositories used by the public or by scientists; employ cameras to monitor areas and buildings for security; aid in controlling traffic on highways or crowded pedestrian areas; help in the understanding of people's activities in military scenarios; and much more.</span></p> <p><span>The project focused in large part on the analysis of video of people walking in some area such as a shopping mall, an airport, or a university campus, where it is often of interest to know who is where at all times in order to detect anomalous behavior, manage traffic, or ensure public safety. Concepts developed under this effort led to video analysis systems that outperformed the state of the art by significant margins. As an example, one system was able to track people with an accuracy that is 17.6 percent better than the previously-best system using multiple, complex video sequences taken by many cameras looking at different parts of some geographic area.</span></p> <p><span>To support their experimental work, the investigators built the largest video database available to date for the training and performance evaluation of multi-camera systems that track multiple people. This database required several person-years of manual annotation, in which experts used software tools written for this purpose to identify every person in every frame of every video recorded over 85 minutes from several static cameras deployed on the Duke University campus. This video involved more than two million frames and about 2,700 distinct individuals. All data collection was carried out under the supervision of the Internal Review Board at Duke University, which examined and approved all experimental protocols and ensured that all privacy concerns were met.</span></p> <p><span>All this annotated data has been made available for free through a web site to any individuals and organizations who wish to work on video analysis. The data was the basis for two competitions organized under this effort in connection with two scientific workshops on multi-camera, multi-person tracking. Several papers have already been published by researchers around the world that used data developed under this grant, and more publications are expected in the future.</span></p> <p><span>Concepts and techniques developed under this effort have been incorporated into educational materials used in a graduate course in computer vision and a newly-developed undergraduate course in machine learning at Duke University. These materials are available online, and have been used at other institutions as well.</span></p> <p><span>Three graduate students and four undergraduates have been directly involved with this research for extended periods of time. Two of the graduate students have completed their PhDs with theses based on their research for this grant, and a third is on her way to a PhD degree. One of the undergraduates is now a PhD student in computer science at a different university. Four of these seven students are women, and all are pursuing careers in computer science.</span></p> <p><span><br /></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 02/24/2019<br>      Modified by: Carlo&nbsp;Tomasi</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1420894/1420894_10317861_1551037409257_DukeDataSet--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1420894/1420894_10317861_1551037409257_DukeDataSet--rgov-800width.jpg" title="Sample frames from the DukeMTMC database"><img src="/por/images/Reports/POR/2019/1420894/1420894_10317861_1551037409257_DukeDataSet--rgov-66x44.jpg" alt="Sample frames from the DukeMTMC database"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Sample frames from the 2-million-frame annotated video database developed under this effort for the training and performance evaluation of video analysis systems. The dataset involves 2,700 people observed through several cameras as they walk on the Duke University campus.</div> <div class="imageCredit">Ergys Ristani</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Carlo&nbsp;Tomasi</div> <div class="imageTitle">Sample frames from the DukeMTMC database</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project resulted in theoretical and practical advances in the computerized analysis of video. A wide array of applications depends on these automatic analysis methods, including systems that retrieve video from large repositories used by the public or by scientists; employ cameras to monitor areas and buildings for security; aid in controlling traffic on highways or crowded pedestrian areas; help in the understanding of people's activities in military scenarios; and much more.  The project focused in large part on the analysis of video of people walking in some area such as a shopping mall, an airport, or a university campus, where it is often of interest to know who is where at all times in order to detect anomalous behavior, manage traffic, or ensure public safety. Concepts developed under this effort led to video analysis systems that outperformed the state of the art by significant margins. As an example, one system was able to track people with an accuracy that is 17.6 percent better than the previously-best system using multiple, complex video sequences taken by many cameras looking at different parts of some geographic area.  To support their experimental work, the investigators built the largest video database available to date for the training and performance evaluation of multi-camera systems that track multiple people. This database required several person-years of manual annotation, in which experts used software tools written for this purpose to identify every person in every frame of every video recorded over 85 minutes from several static cameras deployed on the Duke University campus. This video involved more than two million frames and about 2,700 distinct individuals. All data collection was carried out under the supervision of the Internal Review Board at Duke University, which examined and approved all experimental protocols and ensured that all privacy concerns were met.  All this annotated data has been made available for free through a web site to any individuals and organizations who wish to work on video analysis. The data was the basis for two competitions organized under this effort in connection with two scientific workshops on multi-camera, multi-person tracking. Several papers have already been published by researchers around the world that used data developed under this grant, and more publications are expected in the future.  Concepts and techniques developed under this effort have been incorporated into educational materials used in a graduate course in computer vision and a newly-developed undergraduate course in machine learning at Duke University. These materials are available online, and have been used at other institutions as well.  Three graduate students and four undergraduates have been directly involved with this research for extended periods of time. Two of the graduate students have completed their PhDs with theses based on their research for this grant, and a third is on her way to a PhD degree. One of the undergraduates is now a PhD student in computer science at a different university. Four of these seven students are women, and all are pursuing careers in computer science.             Last Modified: 02/24/2019       Submitted by: Carlo Tomasi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
