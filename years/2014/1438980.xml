<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS: FULL: CCA: Collaborative Research: CASH: Cost-aware Adaptation of Software and Hardware</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Programming for and leveraging the benefits of scalable and highly&lt;br/&gt;parallel computer architectures is becoming increasingly&lt;br/&gt;challenging. In order to ease programmer and user effort in achieving&lt;br/&gt;efficient use of parallel architectures and to enable optimal usage of&lt;br/&gt;parallel hardware both within a single chip and across a data center,&lt;br/&gt;this project explores the co-design of a fine-grain configurable (down&lt;br/&gt;to the ALU, FPU, Cache bank, fetch unit, etc) architecture along with&lt;br/&gt;a software optimizing runtime system which controls the architecture's&lt;br/&gt;configuration. This runtime management system understands high-level&lt;br/&gt;goals and constraints such as optimizing for power, latency, cost, or&lt;br/&gt;complex mixed-goals and dynamically allocates fine-grain resources to&lt;br/&gt;meet the constraints. This project will evaluate and design a configurable&lt;br/&gt;manycore-inspired architecture and a self-adapting runtime system.&lt;br/&gt;&lt;br/&gt;This project will investigate the creation of a complete, scalable,&lt;br/&gt;self-adaptive computing system; and will push the boundaries of&lt;br/&gt;adapting systems by utilizing hardware that is configurable and&lt;br/&gt;monitorable below the processor core level. By providing such a&lt;br/&gt;flexible and highly monitored architecture to the adaptation runtime,&lt;br/&gt;this project will explore the scalability of adaptive runtime&lt;br/&gt;algorithms to handle a game-changing increase in the number of&lt;br/&gt;controllable parameters. This project will explore the extent to&lt;br/&gt;which it is fruitful to configure a parallel architecture.</AbstractNarration>
<MinAmdLetterDate>08/08/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/08/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1438980</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Wentzlaff</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David M Wentzlaff</PI_FULL_NAME>
<EmailAddress>wentzlaf@princeton.edu</EmailAddress>
<PI_PHON>6092587781</PI_PHON>
<NSF_ID>000602658</NSF_ID>
<StartDate>08/08/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress><![CDATA[87 Prospect Avenue, 2nd Floor]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8283</Code>
<Text>Exploiting Parallel&amp;Scalabilty</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>This work has developed novel computer architectures that can be reconfigured at a very fine-grain level and software optimization systems that can choose how best to configure the sub-components of the processors at a very fine-grain. &nbsp;These computer hardware designs are reconfigurable below that size of the processor core and can have the number of Arithmetic Logic Units (ALUs) and cache bank (temporary memory) dynamically reconfigured at runtime. &nbsp;By dynamically changing the hardware and optimizing the design to the program that is running and the need of the user, the architecture can improve performance, save energy, and optimize for other goals of the user such as completing a task by a certain time or computing a result within a certain cost budget. &nbsp;An important component of this work is the co-design of a software and hardware system together. &nbsp;In this work, we created a novel optimizing software framework that we have shown surpasses traditional schemes for optimizing computation. &nbsp;We studied this in the context of both Infrastructure as a Service (IaaS) cloud computing systems as well as in other non-cloud applications. &nbsp;</span></p> <p><span>We expanded our work and investigated different pricing models in cloud computing with different optimization strategies in this work and showed different ways for cloud computing users to be incentivized to use cloud computing infrastructure as the cloud provider wanted.</span></p> <p><span>This work&rsquo;s has had broader impacts by helping create an open source manycore processor integrating some of the ideas from this work.&nbsp; Also, this work has helped fund tutorials at major conference venues on this work to enable other researchers to use the results of this work.&nbsp; This work has had broader impacts by funding students to travel to top conferences in the field.&nbsp; Last, during this work, the PI of the program has refined and continued to teach a Massively Open Online Course (MOOC) in Computer Architecture which has enabled many people to learn computer architecture outside of a formal university setting.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 03/03/2019<br>      Modified by: David&nbsp;M&nbsp;Wentzlaff</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This work has developed novel computer architectures that can be reconfigured at a very fine-grain level and software optimization systems that can choose how best to configure the sub-components of the processors at a very fine-grain.  These computer hardware designs are reconfigurable below that size of the processor core and can have the number of Arithmetic Logic Units (ALUs) and cache bank (temporary memory) dynamically reconfigured at runtime.  By dynamically changing the hardware and optimizing the design to the program that is running and the need of the user, the architecture can improve performance, save energy, and optimize for other goals of the user such as completing a task by a certain time or computing a result within a certain cost budget.  An important component of this work is the co-design of a software and hardware system together.  In this work, we created a novel optimizing software framework that we have shown surpasses traditional schemes for optimizing computation.  We studied this in the context of both Infrastructure as a Service (IaaS) cloud computing systems as well as in other non-cloud applications.    We expanded our work and investigated different pricing models in cloud computing with different optimization strategies in this work and showed different ways for cloud computing users to be incentivized to use cloud computing infrastructure as the cloud provider wanted.  This work?s has had broader impacts by helping create an open source manycore processor integrating some of the ideas from this work.  Also, this work has helped fund tutorials at major conference venues on this work to enable other researchers to use the results of this work.  This work has had broader impacts by funding students to travel to top conferences in the field.  Last, during this work, the PI of the program has refined and continued to teach a Massively Open Online Course (MOOC) in Computer Architecture which has enabled many people to learn computer architecture outside of a formal university setting.          Last Modified: 03/03/2019       Submitted by: David M Wentzlaff]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
