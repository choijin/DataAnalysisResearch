<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Bayesian Analysis and Interfaces</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>599996.00</AwardTotalIntnAmount>
<AwardAmount>599996</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many of today's most challenging problems in Big Data involve dealing with the problem of multiple testing, including microarray and other bioinformatic analyses, syndromic surveillance, high-throughput screening, and many others. The challenge when simultaneously conducting thousands or millions of tests is to develop testing methodology that can detect true signals but prevent false discoveries. Crucial contexts for this research include subgroup analysis (searching for a treatment effect in subgroups of the entire population) and multiple endpoint analysis (simultaneously looking for different treatment effects), in interfaces with the pharmaceutical industry and with partial focus on personalized medicine. Development of computer models is crucial in understanding complex processes, as is understanding the interfaces of the computer models with data and uncertainty, often named Uncertainty Quantification. The immediate science applications of the research on Uncertainty Quantification will be to prediction of geophysical hazard probabilities and to models of wind fields. Two of the most significant reasons for the recent concern over reproducibility of science are the failure to control for multiplicities and the common misinterpretation of p-values. In addition to the earlier mentioned multiplicity control, the project will investigate the possibility of converting p-values to more interpretable quantities, such as the odds of the null to the alternative hypothesis.&lt;br/&gt; &lt;br/&gt;The Bayesian approach to multiple testing has the attraction that it is optimally powered for detection, even in the face of highly dependent data or tests statistics, while exerting strong control to prevent false discoveries. The barriers to its implementation are in developing the appropriate prior probability structures and carrying out the computation. While numerous aspects of Uncertainty Quantification will be investigated, the project will particularly focus on the crucially needed development of emulators (approximations) to complex computer models which output massive space-time data fields. Finding situations in which optimal Bayesian and optimal frequentist procedures agree has major benefits, both foundational and practical. Such new agreements typically arise through development of new conditional frequentist procedures. This will be done in the context of two methodologies, study of the odds of correct to false discovery and multiple endpoint testing. This will also be generalized to more general model uncertainty problems, using robust Bayesian analysis.</AbstractNarration>
<MinAmdLetterDate>07/03/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/09/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1407775</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Berger</LastName>
<PI_MID_INIT>O</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James O Berger</PI_FULL_NAME>
<EmailAddress>berger@stat.duke.edu</EmailAddress>
<PI_PHON>9196844531</PI_PHON>
<NSF_ID>000386956</NSF_ID>
<StartDate>07/03/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName/>
<StateCode>NC</StateCode>
<ZipCode>277080251</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~144322</FUND_OBLG>
<FUND_OBLG>2015~147268</FUND_OBLG>
<FUND_OBLG>2016~151919</FUND_OBLG>
<FUND_OBLG>2017~156487</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The research focused on four research areas in Bayesian statistical analysis, involving theory, methodology and application: hypothesis testing and model selection, objective Bayesian analysis, adjustment for multiple testing and analysis of complex computer models.</p> <p>Hypothesis testing is the most used (and misused) statistical procedure. Research under the grant included a new methodological approach to testing using "rejection odds," an approach that prevents misinterpretation of test results and which is simultaneously justified from the two main philosophies of statistics, the frequentist and Bayesian approaches. In another paper, three simple recommendations were given that would drastically improve the interpretation of p-values, clearing up much of the problem with modern testing.</p> <p>Many of the significant scientific problems today (such as much of climate change research) involve some type of assimilation of data and physical modeling. This interface, called Uncertainty Quantification, was a major focus of the research project. In particular, the research focused on emulation (approximation) of expensive-to-run computer models of processes, and remarkably improved emulators were obtained. This work is of direct use in prediction of probabilistic hazards of pyroclastic flow.</p> <p>Research in objective Bayesian analysis focused on the development of objective priors, together with their computational implementation. In particular, such prior distributions were found for any hierarchical normal model, a very common and powerful type of statistical analysis.</p> <p>Many of today's most challenging problems - including microarray and other bioinformatic analyses, syndromic surveillance, high-throughput screening for drug discovery, and many others - involve consideration of multiple-testing with a huge number of possible tests, and require major multiplicity adjustments. A major part of this research project was studying the Bayesian approach to multiplicity correction, for two reasons. First, the Bayesian approach retains full power for discovery, even when the test statistics of the multiple tests are highly dependent, as is common in many problems such as subgroup analysis (detecting a subgroup of a population that, e.g., exhibits a treatment effect); in contrast standard non-Bayesian multiplicity correction techniques lose most of their detection power in the face of test statistic dependency. The second attraction of the Bayesian approach is that differing probability assignments can be made which allow extra weight to be given to hypotheses that are viewed as being scientifically more likely to be true. Progress in this area was made in terms of foundations, finding that Bayesian multiple testing procedures have excellent frequentist properties and studying control for multiple testing with minimal assumptions.</p> <p>Under the research project there was also significant development of researchers in statistics and data science more generally. The Ph.D. students involved with the project have extensively developed their skills in research through the project. Most have also been heavily involved with interdisciplinary research.</p><br> <p>            Last Modified: 09/28/2019<br>      Modified by: James&nbsp;O&nbsp;Berger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The research focused on four research areas in Bayesian statistical analysis, involving theory, methodology and application: hypothesis testing and model selection, objective Bayesian analysis, adjustment for multiple testing and analysis of complex computer models.  Hypothesis testing is the most used (and misused) statistical procedure. Research under the grant included a new methodological approach to testing using "rejection odds," an approach that prevents misinterpretation of test results and which is simultaneously justified from the two main philosophies of statistics, the frequentist and Bayesian approaches. In another paper, three simple recommendations were given that would drastically improve the interpretation of p-values, clearing up much of the problem with modern testing.  Many of the significant scientific problems today (such as much of climate change research) involve some type of assimilation of data and physical modeling. This interface, called Uncertainty Quantification, was a major focus of the research project. In particular, the research focused on emulation (approximation) of expensive-to-run computer models of processes, and remarkably improved emulators were obtained. This work is of direct use in prediction of probabilistic hazards of pyroclastic flow.  Research in objective Bayesian analysis focused on the development of objective priors, together with their computational implementation. In particular, such prior distributions were found for any hierarchical normal model, a very common and powerful type of statistical analysis.  Many of today's most challenging problems - including microarray and other bioinformatic analyses, syndromic surveillance, high-throughput screening for drug discovery, and many others - involve consideration of multiple-testing with a huge number of possible tests, and require major multiplicity adjustments. A major part of this research project was studying the Bayesian approach to multiplicity correction, for two reasons. First, the Bayesian approach retains full power for discovery, even when the test statistics of the multiple tests are highly dependent, as is common in many problems such as subgroup analysis (detecting a subgroup of a population that, e.g., exhibits a treatment effect); in contrast standard non-Bayesian multiplicity correction techniques lose most of their detection power in the face of test statistic dependency. The second attraction of the Bayesian approach is that differing probability assignments can be made which allow extra weight to be given to hypotheses that are viewed as being scientifically more likely to be true. Progress in this area was made in terms of foundations, finding that Bayesian multiple testing procedures have excellent frequentist properties and studying control for multiple testing with minimal assumptions.  Under the research project there was also significant development of researchers in statistics and data science more generally. The Ph.D. students involved with the project have extensively developed their skills in research through the project. Most have also been heavily involved with interdisciplinary research.       Last Modified: 09/28/2019       Submitted by: James O Berger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
