<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Dynamically Reconfigurable Architectures for Time-Varying Image Constraints (DRASTIC) Based on Local Modeling and User Constraint Prediction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>459870.00</AwardTotalIntnAmount>
<AwardAmount>459870</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The use of digital video in embedded and communications systems has risen dramatically in recent years. User needs and interests in digital video vary based on video content and available computing resources such as battery life and communications bandwidth. Thus, there is a strong need to develop methods that can dynamically reconfigure hardware and software resources in real-time to respond to changing video content, user needs, or available computing resources. The proposed research will develop methods that will provide run-time management of hardware and software resources for video processing and communications that are jointly optimal in terms of energy, bandwidth, and throughput.&lt;br/&gt;&lt;br/&gt;Digital video processing and communication often consumes the majority of computing resources and bandwidth. With the emergence of the High-Efficiency Video Coding (HEVC) standard, there is a focus on the development of parallel architecture solutions that can effectively provide real-time coding of high-resolution video while reducing the bandwidth requirements up to 50% from the previous coding standard (H.264/AVC). However, the HEVC's focus on rate-distortion optimization does not consider how computing architectures should adapt to time-varying energy constraints. The proposed research will be focused on the development of Dynamically Reconfigurable Architecture Systems for satisfying Time-varying Image processing Constraints (DRASTIC) that optimize computing resources to satisfy time-varying constraints on energy, bandwidth, and image quality for HEVC and video analysis based on 2D/3D filterbanks. The research is transformative in two different ways: (i) it supports the automatic generation of real-time varying constraints based on video content and available energy while eliminating the need for user inputs, and (ii) it uses a local model to significantly reduce the requirements for estimating large Pareto fronts over a large space of videos. These transformative approaches can significantly expand the applicability of the proposed system and methods.</AbstractNarration>
<MinAmdLetterDate>08/25/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/10/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422031</AwardID>
<Investigator>
<FirstName>Marios</FirstName>
<LastName>Pattichis</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marios S Pattichis</PI_FULL_NAME>
<EmailAddress>pattichi@unm.edu</EmailAddress>
<PI_PHON>5052770486</PI_PHON>
<NSF_ID>000475187</NSF_ID>
<StartDate>08/25/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Llamocca</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel R Llamocca</PI_FULL_NAME>
<EmailAddress>llamocca@oakland.edu</EmailAddress>
<PI_PHON>2483704042</PI_PHON>
<NSF_ID>000628838</NSF_ID>
<StartDate>08/25/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of New Mexico</Name>
<CityName>Albuquerque</CityName>
<ZipCode>871310001</ZipCode>
<PhoneNumber>5052774186</PhoneNumber>
<StreetAddress>1700 Lomas Blvd. NE, Suite 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<StateCode>NM</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NM01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>868853094</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NEW MEXICO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>784121725</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of New Mexico]]></Name>
<CityName/>
<StateCode>NM</StateCode>
<ZipCode>871310001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NM01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~459870</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Digital videos are everywhere. Digital video communications dominate internet traffic. Digital image and video analysis has become an essential component to many industries. Current applications include applications to self-driving cars and computer aided diagnosis of human diseases. More importantly, there is a strong need to develop the computing technologies to support effective video communications and the wider adoption of video analysis technologies.</p> <p>The DRASTIC project developed effective computing architectures and software models for digital video processing and communications. A distinguishing characteristic of the DRASTIC family of architectures is that they are optimal as measured in terms of power/energy and performance. In other words, DRASTIC allows us to select the best possible architecture by balancing requirements on power/energy and performance. As an example, if more power/energy associated with more hardware resources is available, DRASTIC will provide an architecture that will yield a better performance. DRASTIC showed that a large number of hardware-software configurations can be summarized with simple mathematical equations that can be used to provide real-time adaptation to different needs.</p> <p>There are significant practical implications associated with the DRASTIC project outcomes. For example, for real-time video communications using mobile devices, DRASTIC can select an architecture that minimizes energy consumption while still compressing videos in real-time. DRASTIC demonstrated a critical application of the technology in stroke ultrasound video communications where the mathematical models allow us to adapt video encoding to different network constraints without sacrificing clinical diagnostic quality. The results imply that DRASTIC can enable effective communications of stroke ultrasound videos from a fast moving ambulance during emergency events.</p> <p>For image and video analysis applications, the DRASTIC project developed a new family of filtering architectures based on separable approximations and the Discrete Periodic Radon Transform (DPRT). As an example, DRASTIC provides efficient hardware architectures for object tracking using cross-correlation. Similarly, DRASTIC provides efficient hardware architectures for filter bank-based feature extraction. Overall, given the fact that the most time-consuming image analysis methods are made of 2D cross-correlations and convolutions, DRASTIC has provided methods that can significantly speed up most image and video analysis systems.</p> <p>The broader impacts of the project include the development of new courses, teaching middle-school students from under-represented groups, conference presentations, and the support of several undergraduate and graduate students. DRASTIC supported the Advancing Out-of-School Learning in Mathematics and Engineering (AOLME) project, an after-school program for an urban and a rural middle-school. In level I, AOLME taught the basics of Computer Architecture and Python programming using the Raspberry Pi, how to represent numbers using binary representations and hexadecimals, and how to create complex images and videos using cartesian coordinate systems. In level II, AOLME focused on image transformations, sprites, histograms, and the traveling salesman person problem. The AOLME project impacted 44 middle-school students, 16 undergraduate and graduate student facilitators, and 4 teachers. DRASTIC also supported the research of two Ph.D. students and two M.Sc. thesis students.</p> <p>To further disseminate the research, the project supported the creation of detailed tutorials at Oakland University and the University of New Mexico. DRASTIC developed openly available tutorials on dynamic partial reconfiguration and how to implement digital image processing cores using modern devices. For graduate courses in image and video processing, DRASTIC provided an overview of the mathematical models and the hardware and software implementations of the image and video processing and communications methods.</p> <p>The DRASTIC research findings were disseminated in high-quality publications. The project resulted in journal publications in the IEEE Transactions on Image Processing, ACM Transactions on Reconfigurable Technology and Systems (TRETS), the IEEE Journal of Biomedical and Health Informatics, and the Journal of Real-time Image Processing. The research was also presented in the Data Compression Conference, IEEE EMBS, IEEE SSIAI, GlobalSip, IEEE ICASSP and published in the Conference proceedings. The lessons learned from teaching middle-school students was published in chapter of the book on <em>Access and equity: Promoting high-quality Mathematics in grades 6-8</em>, published by the National Council of Teachers of Mathematics.</p> <p>Lastly, current efforts are focused on commercializing DRASTIC technology. There are currently three pending patents associated with the video communications research, the DPRT, and the hardware cores for fast 2D convolutions and cross-correlations. The PI co-founded a startup, ClearStream Technologies, that has currently licensed the pending patent on video communications. ClearStream Technologies was a USA finalist for the 2017 Creative Business Cup and is currently looking for funding and partnerships to commercialize the technology.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/27/2017<br>      Modified by: Marios&nbsp;S&nbsp;Pattichis</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1422031/1422031_10337672_1514394272898_DRASTIC--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1422031/1422031_10337672_1514394272898_DRASTIC--rgov-800width.jpg" title="DRASTIC: Dynamically Reconfigurable Architecture Systems for Time-Varying Image Constraints"><img src="/por/images/Reports/POR/2017/1422031/1422031_10337672_1514394272898_DRASTIC--rgov-66x44.jpg" alt="DRASTIC: Dynamically Reconfigurable Architecture Systems for Time-Varying Image Constraints"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A system diagram demonstrating several concepts associated with the DRASTIC project. In real-time, the software and hardware is adapted to deliver optimal video processing and communications. DRASTIC provided new methods for dynamic video encoding, 2D convolutions, and cross-correlations.</div> <div class="imageCredit">U.S. Pattent 9,111,059 B2.</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Marios&nbsp;S&nbsp;Pattichis</div> <div class="imageTitle">DRASTIC: Dynamically Reconfigurable Architecture Systems for Time-Varying Image Constraints</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Digital videos are everywhere. Digital video communications dominate internet traffic. Digital image and video analysis has become an essential component to many industries. Current applications include applications to self-driving cars and computer aided diagnosis of human diseases. More importantly, there is a strong need to develop the computing technologies to support effective video communications and the wider adoption of video analysis technologies.  The DRASTIC project developed effective computing architectures and software models for digital video processing and communications. A distinguishing characteristic of the DRASTIC family of architectures is that they are optimal as measured in terms of power/energy and performance. In other words, DRASTIC allows us to select the best possible architecture by balancing requirements on power/energy and performance. As an example, if more power/energy associated with more hardware resources is available, DRASTIC will provide an architecture that will yield a better performance. DRASTIC showed that a large number of hardware-software configurations can be summarized with simple mathematical equations that can be used to provide real-time adaptation to different needs.  There are significant practical implications associated with the DRASTIC project outcomes. For example, for real-time video communications using mobile devices, DRASTIC can select an architecture that minimizes energy consumption while still compressing videos in real-time. DRASTIC demonstrated a critical application of the technology in stroke ultrasound video communications where the mathematical models allow us to adapt video encoding to different network constraints without sacrificing clinical diagnostic quality. The results imply that DRASTIC can enable effective communications of stroke ultrasound videos from a fast moving ambulance during emergency events.  For image and video analysis applications, the DRASTIC project developed a new family of filtering architectures based on separable approximations and the Discrete Periodic Radon Transform (DPRT). As an example, DRASTIC provides efficient hardware architectures for object tracking using cross-correlation. Similarly, DRASTIC provides efficient hardware architectures for filter bank-based feature extraction. Overall, given the fact that the most time-consuming image analysis methods are made of 2D cross-correlations and convolutions, DRASTIC has provided methods that can significantly speed up most image and video analysis systems.  The broader impacts of the project include the development of new courses, teaching middle-school students from under-represented groups, conference presentations, and the support of several undergraduate and graduate students. DRASTIC supported the Advancing Out-of-School Learning in Mathematics and Engineering (AOLME) project, an after-school program for an urban and a rural middle-school. In level I, AOLME taught the basics of Computer Architecture and Python programming using the Raspberry Pi, how to represent numbers using binary representations and hexadecimals, and how to create complex images and videos using cartesian coordinate systems. In level II, AOLME focused on image transformations, sprites, histograms, and the traveling salesman person problem. The AOLME project impacted 44 middle-school students, 16 undergraduate and graduate student facilitators, and 4 teachers. DRASTIC also supported the research of two Ph.D. students and two M.Sc. thesis students.  To further disseminate the research, the project supported the creation of detailed tutorials at Oakland University and the University of New Mexico. DRASTIC developed openly available tutorials on dynamic partial reconfiguration and how to implement digital image processing cores using modern devices. For graduate courses in image and video processing, DRASTIC provided an overview of the mathematical models and the hardware and software implementations of the image and video processing and communications methods.  The DRASTIC research findings were disseminated in high-quality publications. The project resulted in journal publications in the IEEE Transactions on Image Processing, ACM Transactions on Reconfigurable Technology and Systems (TRETS), the IEEE Journal of Biomedical and Health Informatics, and the Journal of Real-time Image Processing. The research was also presented in the Data Compression Conference, IEEE EMBS, IEEE SSIAI, GlobalSip, IEEE ICASSP and published in the Conference proceedings. The lessons learned from teaching middle-school students was published in chapter of the book on Access and equity: Promoting high-quality Mathematics in grades 6-8, published by the National Council of Teachers of Mathematics.  Lastly, current efforts are focused on commercializing DRASTIC technology. There are currently three pending patents associated with the video communications research, the DPRT, and the hardware cores for fast 2D convolutions and cross-correlations. The PI co-founded a startup, ClearStream Technologies, that has currently licensed the pending patent on video communications. ClearStream Technologies was a USA finalist for the 2017 Creative Business Cup and is currently looking for funding and partnerships to commercialize the technology.             Last Modified: 12/27/2017       Submitted by: Marios S Pattichis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
