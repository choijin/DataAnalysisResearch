<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CHS: Remote Paper Prototype Testing for Mobile Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2015</AwardEffectiveDate>
<AwardExpirationDate>02/28/2019</AwardExpirationDate>
<AwardTotalIntnAmount>147536.00</AwardTotalIntnAmount>
<AwardAmount>147536</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to establish a research program to enable mobile app designers to conduct user testing on low fidelity or paper prototypes in realistic environments. Mobile app usage now accounts for over half of all time spent on digital media.  Current practice is that realistic testing of new apps tends to occur only after the development of high-fidelity prototypes, which can take weeks or months to implement.  The PI will build and evaluate tools, and develop methodologies, for remote paper prototype testing that will enable designers to facilitate testing sessions from the lab while users remotely interact (via a Wizard-of-Oz mechanism) with a low-fidelity prototype that can be generated in just a few hours.  The PI's goal is to accelerate mobile app development by making it possible for designers to observe and gather valuable feedback from users in realistic scenarios early in the design process; as a consequence, designers will be empowered to test multiple ideas and iterate on them quickly, with the potential for order-of-magnitude increases in the rate of innovation at lower cost in terms of both monetary and human resources.  The PI will make his tools available to a wide community of researchers and design practitioners by releasing all software artifacts to the general public under open source and creative commons licenses, and by providing implementations that rely only on existing, off-the-shell technologies.&lt;br/&gt;&lt;br/&gt;The PI will design, implement, and evaluate remote paper prototype testing tools that preserve and extend the affordances of paper prototyping to the mobile setting while supporting the design goals of testing mobile apps in realistic locations and situations of use, of facilitating a testing session and wizarding a paper prototype remotely, and providing location-based and situational context.  For example, users will test a paper prototype out of the lab while a designer wizards from afar.  A paper prototype placed under a video camera in the lab streams an audio-visual feed to the tester's mobile device, while a device on the user streams an audio-visual-data feed to the facilitator and wizard, including the user's first-person perspective, their talk-aloud, and other relevant data, such as their location.  To operate the prototype from afar, a wizard responds to the user's actions and situational context based on the live stream from the user.  Any alerts or updates to the prototype are streamed to the test user's mobile device.  The PI will collaborate in this research within Northwestern University with the Segal Institute of Design, the Design, Technology, and Research program, Design for America, and the NUvention program.  Effectiveness of the developed methods and tools will be evaluated through controlled experiments and field deployments.  Project outcomes will contribute to our understanding of low-fidelity prototyping and wizard-based techniques for remote testing.</AbstractNarration>
<MinAmdLetterDate>03/10/2015</MinAmdLetterDate>
<MaxAmdLetterDate>03/06/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1464315</AwardID>
<Investigator>
<FirstName>Haoqi</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Haoqi Zhang</PI_FULL_NAME>
<EmailAddress>hq@northwestern.edu</EmailAddress>
<PI_PHON>9174452626</PI_PHON>
<NSF_ID>000647177</NSF_ID>
<StartDate>03/10/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602080886</ZipCode>
<StreetAddress><![CDATA[2145 Sheridan Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~76672</FUND_OBLG>
<FUND_OBLG>2016~70864</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to establish a research program to enable mobile app designers to conduct user testing on low fidelity or paper prototypes in realistic environments. Mobile app usage now accounts for over half of all time spent on digital media. Current practice is that realistic testing of new apps tends to occur only after the development of high-fidelity prototypes, which can take weeks or months to implement. The PI and team built and evaluated tools, and develop methodologies, for remote paper prototype testing (RPPT) that enable designers to facilitate testing sessions from the lab while users remotely interact (via a Wizard-of-Oz mechanism) with a low-fidelity prototype that can be generated in just a few hours. The developed methodologies and technologies can be used to accelerate mobile app development by making it possible for designers to observe and gather valuable feedback from users in realistic scenarios early in the design process; as a consequence, designers will be empowered to test multiple ideas and iterate on them quickly, with the potential for order-of-magnitude increases in the rate of innovation at lower cost in terms of both monetary and human resources.&nbsp;</p> <p><br />Specifically, the project led to three key technological and methodological milestones:</p> <p>1) We developed a remote paper prototyping tool (RPPT) that facilitates testing a low-fi, paper-based prototype of a mobile application in realistic, dynamic scenarios in actual situations of use.&nbsp;</p> <p><br />2) We developed mixed fidelity remote prototype testing (MF-RPT), which provides a solution that preserves the flexibility of paper, but allows for digital elements to be added to a prototype that can function alongside paper elements. While RPPT was limited to the fidelities of paper, MF-RPT &nbsp;enables the prototyping and testing of sensor-rich, context-aware applications. We developed McGonagall, a MF-RPT-based prototyping tool that allows designers to make paper prototypes that are "transfigured" into interactive context-aware mixed-fidelity prototypes on testers' mobile devices that are manipulated by the designer via remote wizard-of-oz.</p> <p><br />3) We developed Lake, a digital wizard of oz prototyping tool that embodies the core ideas of the MF-RPT approach but avoids a cumbersome, paper-based setup. With Lake, anyone with a tablet and mobile phone can now use the MF-RPT approach to test complex, context-aware mobile app prototypes in realistic situations of use. In other words, Lake provides a scalable, readily-available method of prototyping that can be used to prototype mobile applications in minimal time for testing realistic context-aware interactions in actual situations of use.</p> <p><br />Our evaluation work demonstrated the effectiveness of the RPPT and MF-RPT approaches. Specifically, we conducted user studies on RPPT, McGonagall, and Lake, that collectively provide evidence for how such tools can support designers in prototyping a diverse set of rich, mobile app interactions; and that facilitating testing complex mobile app interactions in realistic situations of use allowed designers to gather in-context feedback from testers. These findings suggest that designers are able to test prototypes that would not have been possible without significant effort to create, and that testers are able to provide in-context feedback of context aware features in realistic situations of use, allowing designers to identify key usability and design issues that would have been difficult to notice without testing actual, context-aware interactions in realistic use cases out of the lab.</p><br> <p>            Last Modified: 06/10/2019<br>      Modified by: Haoqi&nbsp;Zhang</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1464315/1464315_10353373_1558632035818_ScreenShot2019-05-23at12.17.20PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1464315/1464315_10353373_1558632035818_ScreenShot2019-05-23at12.17.20PM--rgov-800width.jpg" title="Translating across representations"><img src="/por/images/Reports/POR/2019/1464315/1464315_10353373_1558632035818_ScreenShot2019-05-23at12.17.20PM--rgov-66x44.jpg" alt="Translating across representations"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An illustration of the MF-RPT approach for translating between representations of a prototype to allow designers to wizard-of-oz from afar while tester's interact with  context-aware prototypes in actual situations of use.</div> <div class="imageCredit">CHI 2019 SRC Poster on Lake</div> <div class="imageSubmitted">Haoqi&nbsp;Zhang</div> <div class="imageTitle">Translating across representations</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to establish a research program to enable mobile app designers to conduct user testing on low fidelity or paper prototypes in realistic environments. Mobile app usage now accounts for over half of all time spent on digital media. Current practice is that realistic testing of new apps tends to occur only after the development of high-fidelity prototypes, which can take weeks or months to implement. The PI and team built and evaluated tools, and develop methodologies, for remote paper prototype testing (RPPT) that enable designers to facilitate testing sessions from the lab while users remotely interact (via a Wizard-of-Oz mechanism) with a low-fidelity prototype that can be generated in just a few hours. The developed methodologies and technologies can be used to accelerate mobile app development by making it possible for designers to observe and gather valuable feedback from users in realistic scenarios early in the design process; as a consequence, designers will be empowered to test multiple ideas and iterate on them quickly, with the potential for order-of-magnitude increases in the rate of innovation at lower cost in terms of both monetary and human resources.    Specifically, the project led to three key technological and methodological milestones:  1) We developed a remote paper prototyping tool (RPPT) that facilitates testing a low-fi, paper-based prototype of a mobile application in realistic, dynamic scenarios in actual situations of use.    2) We developed mixed fidelity remote prototype testing (MF-RPT), which provides a solution that preserves the flexibility of paper, but allows for digital elements to be added to a prototype that can function alongside paper elements. While RPPT was limited to the fidelities of paper, MF-RPT  enables the prototyping and testing of sensor-rich, context-aware applications. We developed McGonagall, a MF-RPT-based prototyping tool that allows designers to make paper prototypes that are "transfigured" into interactive context-aware mixed-fidelity prototypes on testers' mobile devices that are manipulated by the designer via remote wizard-of-oz.   3) We developed Lake, a digital wizard of oz prototyping tool that embodies the core ideas of the MF-RPT approach but avoids a cumbersome, paper-based setup. With Lake, anyone with a tablet and mobile phone can now use the MF-RPT approach to test complex, context-aware mobile app prototypes in realistic situations of use. In other words, Lake provides a scalable, readily-available method of prototyping that can be used to prototype mobile applications in minimal time for testing realistic context-aware interactions in actual situations of use.   Our evaluation work demonstrated the effectiveness of the RPPT and MF-RPT approaches. Specifically, we conducted user studies on RPPT, McGonagall, and Lake, that collectively provide evidence for how such tools can support designers in prototyping a diverse set of rich, mobile app interactions; and that facilitating testing complex mobile app interactions in realistic situations of use allowed designers to gather in-context feedback from testers. These findings suggest that designers are able to test prototypes that would not have been possible without significant effort to create, and that testers are able to provide in-context feedback of context aware features in realistic situations of use, allowing designers to identify key usability and design issues that would have been difficult to notice without testing actual, context-aware interactions in realistic use cases out of the lab.       Last Modified: 06/10/2019       Submitted by: Haoqi Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
