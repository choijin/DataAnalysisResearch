<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Discovery of Segmental Sub-Word Structure in Speech</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2014</AwardEffectiveDate>
<AwardExpirationDate>02/28/2015</AwardExpirationDate>
<AwardTotalIntnAmount>99911.00</AwardTotalIntnAmount>
<AwardAmount>99911</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This EArly Concept Grant for Exploratory Research (EAGER) investigates new machine learning techniques for discovering sub-word units in speech for use in automatic speech recognition (ASR).  The representation of this EArly Concept Grant for Exploratory Research investigates new machine learning techniques for discovering sub-word units in speech for use in automatic speech recognition (ASR).  The representation of words in terms of sub-word units is rarely learned from data, despite significant disagreement among linguists as to the sub-word unit inventory.  This project represents exploratory work toward a larger goal of making all aspects of ASR learnable, using scientific insights while being discriminatively trained.&lt;br/&gt;&lt;br/&gt;In contrast with prior work, speech segments are clustered into units using discriminatively learned segmental similarities, rather than via dynamic time warping or hidden Markov models.  Rather than pre-supposing phoneme-like units, multiple heterogeneous unit types&lt;br/&gt;are learned.  The project also leverages multi-modal (video, articulatory, and so on) data to improve unit discovery by sharing&lt;br/&gt;information across modalities.  In this exploratory work, the learned units are used in a discriminative model that rescores initial outputs from a standard phone-based recognizer, and the experiments focus on small-/medium-vocabulary recognition.&lt;br/&gt;&lt;br/&gt;This project explores new ways of discovering the basic units of speech.  Beyond improvements to speech recognition, this project has&lt;br/&gt;the potential for broad impact on other research areas involving sequences with segmental sub-structure (such as text, video,&lt;br/&gt;biological data, and financial data) or involving clustering.  The results may also include new representations for the study of speech&lt;br/&gt;in linguistics and speech science.  From a societal perspective, in the long term making speech recognition more learnable will enable&lt;br/&gt;improved porting of the technology to under-served linguistic communities, which do not have the benefit of large data sets or other resources.</AbstractNarration>
<MinAmdLetterDate>03/04/2014</MinAmdLetterDate>
<MaxAmdLetterDate>03/04/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1433485</AwardID>
<Investigator>
<FirstName>Karen</FirstName>
<LastName>Livescu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Karen Livescu</PI_FULL_NAME>
<EmailAddress>klivescu@ttic.edu</EmailAddress>
<PI_PHON>7738342549</PI_PHON>
<NSF_ID>000512036</NSF_ID>
<StartDate>03/04/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Toyota Technological Institute at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372803</ZipCode>
<PhoneNumber>7738340409</PhoneNumber>
<StreetAddress>6045 S Kenwood Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>127228927</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TOYOTA TECHNOLOGICAL INSTITUTE AT CHICAGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Toyota Technological Institute at Chicago]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>606372902</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~99911</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This EAGER project investigates new machine learning techniques for automatically discovering units of speech from data.&nbsp; The project focuses on sub-word units, that is units that combine to form words, and their use in automatic speech recognition.&nbsp; Most aspects of speech recognition systems are now learned from data using machine learning techniques, but the inventory of sub-word units and the way they combine to form words typically are not.&nbsp; This is despite significant disagreement among linguists as to the correct sub-word unit inventory, and the fact that for many languages there are few linguistic resources at all.&nbsp; This project represents exploratory work toward a larger goal of making all aspects of speech recognition learnable, using scientific insights while being trained to optimize performance on the recognition task.<br /><br />Prior work has begun to address some aspects of this goal, typically using techniques based on hidden Markov models, in which segments of speech are modeled as sequences of very short, uniform-duration "frames".&nbsp; In contrast, this project seeks to directly model entire segments of speech and group them into clusters corresponding to distinct speech units.&nbsp; One part of the project focused on representing segments with fixed-length vectors, in order to facilitate computations of similarity between them.&nbsp; In this sub-project, new fixed-length representations were developed, and were found in preliminary experiments to improve over traditional representations for the task of clustering for unit discovery.&nbsp; Another part of the project focused on using the discovered units in speech recognition, using segmental statistical models for recognition.&nbsp; In this sub-project, our preliminary results indicate that adding such automatically discovered units to traditional phonetic units improves over the traditional ones alone.&nbsp;</p> <p>&nbsp;</p> <p>In order to make further work possible, the project also involved improving segmental speech recognition models with new training and decoding techniques.&nbsp; This work has resulted in faster and better training, and in new training algorithms that may also be applicable to traditional speech recognition systems or other artificial intelligence tasks.&nbsp; A major outcome is a new version of TTI-Chicago's software toolkit for segmental models, which improves over previously available toolkits and is publicly available for other researchers and developers to use.&nbsp; The toolkit is applicable to a variety of tasks in speech and language processing, as well as sequential data processing applications throughout artificial intelligence.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/01/2015<br>      Modified by: Karen&nbsp;Livescu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This EAGER project investigates new machine learning techniques for automatically discovering units of speech from data.  The project focuses on sub-word units, that is units that combine to form words, and their use in automatic speech recognition.  Most aspects of speech recognition systems are now learned from data using machine learning techniques, but the inventory of sub-word units and the way they combine to form words typically are not.  This is despite significant disagreement among linguists as to the correct sub-word unit inventory, and the fact that for many languages there are few linguistic resources at all.  This project represents exploratory work toward a larger goal of making all aspects of speech recognition learnable, using scientific insights while being trained to optimize performance on the recognition task.  Prior work has begun to address some aspects of this goal, typically using techniques based on hidden Markov models, in which segments of speech are modeled as sequences of very short, uniform-duration "frames".  In contrast, this project seeks to directly model entire segments of speech and group them into clusters corresponding to distinct speech units.  One part of the project focused on representing segments with fixed-length vectors, in order to facilitate computations of similarity between them.  In this sub-project, new fixed-length representations were developed, and were found in preliminary experiments to improve over traditional representations for the task of clustering for unit discovery.  Another part of the project focused on using the discovered units in speech recognition, using segmental statistical models for recognition.  In this sub-project, our preliminary results indicate that adding such automatically discovered units to traditional phonetic units improves over the traditional ones alone.      In order to make further work possible, the project also involved improving segmental speech recognition models with new training and decoding techniques.  This work has resulted in faster and better training, and in new training algorithms that may also be applicable to traditional speech recognition systems or other artificial intelligence tasks.  A major outcome is a new version of TTI-Chicago's software toolkit for segmental models, which improves over previously available toolkits and is publicly available for other researchers and developers to use.  The toolkit is applicable to a variety of tasks in speech and language processing, as well as sequential data processing applications throughout artificial intelligence.          Last Modified: 06/01/2015       Submitted by: Karen Livescu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
