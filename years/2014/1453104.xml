<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:  Scaling Source Separation to Big Audio Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>549863.00</AwardTotalIntnAmount>
<AwardAmount>549863</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The world we live in is composed out of mixed signals. It is practically impossible to easily obtain a clean recording of speech, music, environmental, mechanical, underwater, or biomedical sounds. This, in turn, complicates any further processing due to the presence of unwanted elements (e.g. background noise in speech recognition). We traditionally address this issue by using source separation and denoising methods that allow us to extract only a desired signal from a mixture. Unfortunately such methods do not scale at ?big data? levels, which means that most of the audio data we gather today remains at a state unsuitable for automatic content analysis or further processing. This project addresses the use of source separation methods when confronted with very large data sets. It considers use of modern data analysis methods to efficiently process large amounts of data, and also the effects of training on large signal corpora in order to improve source separation performance. The ultimate goals are to improve source separation performance by leveraging large signal collections, and to enable large-scale signal analysis by making modern source separation algorithms more efficient.&lt;br/&gt;&lt;br/&gt;In order to enable processing at such large scales, this project takes advantage of recent developments in manifold structure analysis, deflation methods for spectral decompositions, hashing strategies, and quantization. Using a quantized manifold representation, large signal data sets can be approximated using a compact and efficiently accessible structure. Such representations can then be used as priors to a source separation algorithm and help guide it to extract signals that match them. Applying such models on large data to perform source separation is further accelerated by making use of a deflation method. Instead of performing the textbook (and computationally intensive) model matching process, this project uses a greedy approach to quickly extract target components while bypassing many unnecessary calculations. Finally, given the latest research on unifying multiple models of source separation, this project considers the application of such concepts to multiple data analysis models at once (such as HMM models, continuous dynamical systems, etc.), thereby becoming relevant to a wide range of signals and mixing situations.</AbstractNarration>
<MinAmdLetterDate>03/03/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/12/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1453104</AwardID>
<Investigator>
<FirstName>Paris</FirstName>
<LastName>Smaragdis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Paris Smaragdis</PI_FULL_NAME>
<EmailAddress>paris@illinois.edu</EmailAddress>
<PI_PHON>2172656893</PI_PHON>
<NSF_ID>000573387</NSF_ID>
<StartDate>03/03/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~97746</FUND_OBLG>
<FUND_OBLG>2016~98306</FUND_OBLG>
<FUND_OBLG>2017~100920</FUND_OBLG>
<FUND_OBLG>2018~117553</FUND_OBLG>
<FUND_OBLG>2019~135338</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Source separation is the task of isolating signals of interest from complex mixtures, such as one's voice in a busy sound scene, or the sound of an individual machine in a busy factory. This task has seen significant performance advances in the last 15 years once we started training machine learning systems to do so. And as with most machine learning systems, there was the hunch that using more data for training should result in better performance.</p> <p>This project examined exactly this question. Can we get better results with more training data? And how do we scale our algorithms to do deal with a scale that is many times bigger than before? In the process of exploring these questions we developed a set of techniques that have found wide adoption and have broadened our understanding of this problem.</p> <p>Before this project, algorithms to perform source separation were based on complex computations that did not scale well with large training data sizes. Our work introduced a set of techniques that allowed existing methods to be reformulated using building blocks that scale well and made the use of large training data feasible. In the process of doing so, we introduced some ideas that have now become standard components in the state of the art systems (such as adaptive front-ends, differentiable perceptual cost functions, and establishing relationships between well-known signal processing primitives to modern machine learning ones).</p> <p>All of these contributions have helped us learn models from large training data that are able to extract sounds from mixtures with much better performance than ever before (boosting their ability to suppress competing sounds by more than a factor of 10 than previously). Simultaneously we reused our performance enhancement methods in order to make these algorithms fast enough to run on consumer equipment.&nbsp;</p> <p>This means that now we can look forward to teleconferencing systems, headphones and mics, as well as scientific instruments that are able to suppress unwanted sounds, and produce cleaner and crisper recordings than before. &nbsp;Some of this work has already found itself in the market (e.g. better denoising for teleconferencing), and more based on our work is now in the product pipeline as well. As we move forward we hope to apply our insights from this project to more areas that encounter mixed time-series.</p><br> <p>            Last Modified: 02/08/2021<br>      Modified by: Paris&nbsp;Smaragdis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Source separation is the task of isolating signals of interest from complex mixtures, such as one's voice in a busy sound scene, or the sound of an individual machine in a busy factory. This task has seen significant performance advances in the last 15 years once we started training machine learning systems to do so. And as with most machine learning systems, there was the hunch that using more data for training should result in better performance.  This project examined exactly this question. Can we get better results with more training data? And how do we scale our algorithms to do deal with a scale that is many times bigger than before? In the process of exploring these questions we developed a set of techniques that have found wide adoption and have broadened our understanding of this problem.  Before this project, algorithms to perform source separation were based on complex computations that did not scale well with large training data sizes. Our work introduced a set of techniques that allowed existing methods to be reformulated using building blocks that scale well and made the use of large training data feasible. In the process of doing so, we introduced some ideas that have now become standard components in the state of the art systems (such as adaptive front-ends, differentiable perceptual cost functions, and establishing relationships between well-known signal processing primitives to modern machine learning ones).  All of these contributions have helped us learn models from large training data that are able to extract sounds from mixtures with much better performance than ever before (boosting their ability to suppress competing sounds by more than a factor of 10 than previously). Simultaneously we reused our performance enhancement methods in order to make these algorithms fast enough to run on consumer equipment.   This means that now we can look forward to teleconferencing systems, headphones and mics, as well as scientific instruments that are able to suppress unwanted sounds, and produce cleaner and crisper recordings than before.  Some of this work has already found itself in the market (e.g. better denoising for teleconferencing), and more based on our work is now in the product pipeline as well. As we move forward we hope to apply our insights from this project to more areas that encounter mixed time-series.       Last Modified: 02/08/2021       Submitted by: Paris Smaragdis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
