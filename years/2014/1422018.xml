<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TWC: Small: CrowdVerify: Using the Crowd to Summarize Web Site Privacy Policies and Terms of Use Policies</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>499290.00</AwardTotalIntnAmount>
<AwardAmount>515290</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Everyday web users have little guidance in handling the growing number of privacy issues they face when they go online. Many web sites - some legitimate, some less so - have behaviors many would consider unexpected or undesirable. These include popular and well-known web sites, as well as web sites that aim to dupe customers with "free" trials.  These kinds of sites often detail their behaviors in privacy policies and terms of use pages, but these policies are rarely read, hard to understand, and sometimes intentionally obfuscated with legal jargon, small text, and pale fonts. The goal of this research is to develop new techniques to pinpoint and summarize the most surprising and most important parts of policies. The results of this research will be made publicly available on a web site and through web browser extensions.&lt;br/&gt;&lt;br/&gt;The major research activity for this research will be to design, implement, and evaluate CrowdVerify, a system that combines crowdsourcing with machine learning techniques to flag the most important and unexpected behaviors of web sites. The core idea is to slice up a given policy into smaller text segments, have crowd workers compare different segments, and then aggregate the results together. A number of competitor scoring systems will also be evaluated for rating the importance of segments, including ELO, Glicko, and TrueSkill. Using these results, computational models will be built that can predict what people find most surprising as well as most important in web policies.</AbstractNarration>
<MinAmdLetterDate>09/05/2014</MinAmdLetterDate>
<MaxAmdLetterDate>03/24/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422018</AwardID>
<Investigator>
<FirstName>Jason</FirstName>
<LastName>Hong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jason Hong</PI_FULL_NAME>
<EmailAddress>jasonh@cs.cmu.edu</EmailAddress>
<PI_PHON>4122681295</PI_PHON>
<NSF_ID>000255506</NSF_ID>
<StartDate>09/05/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~499290</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The goal of this project is to develop new techniques to analyze and summarize terms and conditions policies on web sites, making it easy for consumers to see the most important statements. These policies tend to be long and difficult to read, with important information buried in long tracts of text.</span></p> <p>Our team has been examining how to use crowd-based techniques to gather information about what people feel is important in these policies. More specifically,&nbsp;we slice a given policy into individual sentences and then show pairs of sentences at a time to crowd workers, asking them to choose which statement is more important. Using this data, we have been building language models that can be used on terms and conditions policies that we have not yet seen, to help predict what people will view as important.</p> <p>To date, we have collected crowd data on 20 different ecommerce web site policies. We have also used machine learning techniques to build some language models. We are currently in the process of applying these language models to thousands of web policies that we have crawled, and organizing these into a web site that consumers can use to quickly see what are the most important things they should know about a site.</p> <p>From a scientific and intellectual perspective, the main contribution of our work are in developing new techniques for having crowd workers analyze policies. We have also investigated techniques for optimizing the amount of work needed by crowd workers, and analyzed what categories of statements people find most important in terms and conditions. Lastly, our data set is available on our web site.&nbsp;</p> <p>From a broader contributions perspective, our work has the potential to help consumers quickly understand the most important items in lengthy terms and conditions policies. Our work also has the potential to help consumer advocates, in terms of understanding what consumers are most worried about as well as pinpointing unusual statements in these policies. Lastly, our work may be of interest to journalists and to the companies whose policies are being analyzed.</p><br> <p>            Last Modified: 04/09/2018<br>      Modified by: Jason&nbsp;Hong</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project is to develop new techniques to analyze and summarize terms and conditions policies on web sites, making it easy for consumers to see the most important statements. These policies tend to be long and difficult to read, with important information buried in long tracts of text.  Our team has been examining how to use crowd-based techniques to gather information about what people feel is important in these policies. More specifically, we slice a given policy into individual sentences and then show pairs of sentences at a time to crowd workers, asking them to choose which statement is more important. Using this data, we have been building language models that can be used on terms and conditions policies that we have not yet seen, to help predict what people will view as important.  To date, we have collected crowd data on 20 different ecommerce web site policies. We have also used machine learning techniques to build some language models. We are currently in the process of applying these language models to thousands of web policies that we have crawled, and organizing these into a web site that consumers can use to quickly see what are the most important things they should know about a site.  From a scientific and intellectual perspective, the main contribution of our work are in developing new techniques for having crowd workers analyze policies. We have also investigated techniques for optimizing the amount of work needed by crowd workers, and analyzed what categories of statements people find most important in terms and conditions. Lastly, our data set is available on our web site.   From a broader contributions perspective, our work has the potential to help consumers quickly understand the most important items in lengthy terms and conditions policies. Our work also has the potential to help consumer advocates, in terms of understanding what consumers are most worried about as well as pinpointing unusual statements in these policies. Lastly, our work may be of interest to journalists and to the companies whose policies are being analyzed.       Last Modified: 04/09/2018       Submitted by: Jason Hong]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
