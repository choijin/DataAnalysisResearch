<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Investigating the Impact of Co-Learning Systems in Providing Customized, Real-Time Student Feedback</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>12/01/2014</AwardEffectiveDate>
<AwardExpirationDate>11/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>287990.00</AwardTotalIntnAmount>
<AwardAmount>287990</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040200</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Heather Watson</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>A current frontier in STEM education is the development of individualized learning environments that can help students learn challenging topics. The need is especially acute during active learning sessions and laboratory activities.  This project will develop co-learning systems to enhance student performance in STEM laboratory activities. Co-learning systems consist of computer systems equipped with sensors. These systems can learn from humans and in turn interact with humans providing them with customized, real-time performance feedback.  The lessons learned from the project can also be applied in other areas of STEM education such as the K-12 environment where co-learning robotic laboratory tutors could help alleviate some of the demands on the time and attention of science teachers.&lt;br/&gt;&lt;br/&gt;The specific research objective of this Improving Undergraduate STEM Education (IUSE) project is to test the hypothesis that co-learning systems are able to enhance student performance in undergraduate STEM laboratory activities by providing them with customized, real-time performance feedback. The project will utilize existing commercial, off-the-shelf technologies in development of the systems.  Sensor input will consist of audio, video, depth, skeletal, and 3D mesh data collected using a multimodal sensing device. The co-learning systems will be integrated into the laboratory environments to capture and translate data pertaining to STEM classroom environments and student interactions during laboratory activities. The type of data will include audio data pertaining to student verbal queries, skeletal data pertaining to student gesture patterns, and the content of student work.  The project will investigate machine learning algorithms suitable for discovering knowledge pertaining to student learning during STEM laboratory activities.  Work will assess the students' perception of co-learning systems and evaluate the ability of co-learning systems to improve performance during laboratories. The investigators will compare student learning outcomes between comparable student groups subject to different amounts of interaction with the co-learning systems. These results will provide information about the potential of co-learning systems to augment traditional teaching and provide an effective, automated, personal STEM learning environment.</AbstractNarration>
<MinAmdLetterDate>08/21/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1449650</AwardID>
<Investigator>
<FirstName>Soundar</FirstName>
<LastName>Kumara</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Soundar R Kumara</PI_FULL_NAME>
<EmailAddress>skumara@psu.edu</EmailAddress>
<PI_PHON>8148632359</PI_PHON>
<NSF_ID>000288942</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Conrad</FirstName>
<LastName>Tucker</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Conrad S Tucker</PI_FULL_NAME>
<EmailAddress>conradt@andrew.cmu.edu</EmailAddress>
<PI_PHON>8148657580</PI_PHON>
<NSF_ID>000612280</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1536</Code>
<Text>S-STEM-Schlr Sci Tech Eng&amp;Math</Text>
</ProgramElement>
<ProgramElement>
<Code>1998</Code>
<Text>IUSE</Text>
</ProgramElement>
<ProgramReference>
<Code>8209</Code>
<Text>Improv Undergrad STEM Ed(IUSE)</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>13XX</Code>
<Name>H-1B FUND, EHR, NSF</Name>
<APP_SYMB_ID>045176</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~287990</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This NSF project has resulted in a fundamental leap forward in our understanding of how machines and humans learn together, towards the successful completion of a task. From the machine&rsquo;s perspective, understanding when to provide students with feedback, would enable it to help improve students&rsquo; learning outcomes. From students&rsquo; perspective, gaining a fundamental understanding of how they perform a task, would enable them to self reflect on trouble areas, and seek additional help from an instructor if needed. From an instructor&rsquo;s perspective, a fundamental understanding of how each and every one of their students performs on a laboratory task, would enable them to identify students who were struggling and propose intervention mechanisms aimed at improving students retention in the course and ultimately, students&rsquo; retention in STEM. Key outcomes of this project include:<br /><br />i)&nbsp;&nbsp;&nbsp; <strong>The ability to use low cost, commercial, off-the-shelf technologies to achieve highly complex tasks such as capturing students&rsquo; performance in real time: </strong>These capabilities were once out of the reach of the typical educational institution that may have been budget constrained. The broader impacts of this work mean that low-income students and students from underserved populations can have access to similar technological capabilities, all for a price of less than a typical smart phone.</p> <p><br />ii)&nbsp;&nbsp;&nbsp; <strong>The ability to capture multiple data streams and systematically utilize them to achieve an overall understanding of students and laboratory environments:</strong> In the past, if researchers wanted to capture multiple data types such as audio, video, depth, skeletal, etc., multiple sensors had to be purchased. The availability of multimodal sensors such as the Kinect, reduce this burden by providing a single system that is able to capture and synthesize these different data types.</p> <p><br />iii)&nbsp;&nbsp;&nbsp; <strong>Ability to quantify students&rsquo; struggles during laboratory tasks: </strong>The proposed machine learning algorithms were able to successfully quantify which students were struggling on a given laboratory task. This outcome enables both the student and instructor to learn from these mistakes, towards a better understanding of tasks and what makes students succeed/fail at them.</p><br> <p>            Last Modified: 02/24/2019<br>      Modified by: Conrad&nbsp;S&nbsp;Tucker</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This NSF project has resulted in a fundamental leap forward in our understanding of how machines and humans learn together, towards the successful completion of a task. From the machine?s perspective, understanding when to provide students with feedback, would enable it to help improve students? learning outcomes. From students? perspective, gaining a fundamental understanding of how they perform a task, would enable them to self reflect on trouble areas, and seek additional help from an instructor if needed. From an instructor?s perspective, a fundamental understanding of how each and every one of their students performs on a laboratory task, would enable them to identify students who were struggling and propose intervention mechanisms aimed at improving students retention in the course and ultimately, students? retention in STEM. Key outcomes of this project include:  i)    The ability to use low cost, commercial, off-the-shelf technologies to achieve highly complex tasks such as capturing students? performance in real time: These capabilities were once out of the reach of the typical educational institution that may have been budget constrained. The broader impacts of this work mean that low-income students and students from underserved populations can have access to similar technological capabilities, all for a price of less than a typical smart phone.   ii)    The ability to capture multiple data streams and systematically utilize them to achieve an overall understanding of students and laboratory environments: In the past, if researchers wanted to capture multiple data types such as audio, video, depth, skeletal, etc., multiple sensors had to be purchased. The availability of multimodal sensors such as the Kinect, reduce this burden by providing a single system that is able to capture and synthesize these different data types.   iii)    Ability to quantify students? struggles during laboratory tasks: The proposed machine learning algorithms were able to successfully quantify which students were struggling on a given laboratory task. This outcome enables both the student and instructor to learn from these mistakes, towards a better understanding of tasks and what makes students succeed/fail at them.       Last Modified: 02/24/2019       Submitted by: Conrad S Tucker]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
