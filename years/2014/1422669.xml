<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Engineering and Learning Visual Representations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>456617.00</AwardTotalIntnAmount>
<AwardAmount>456617</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Visual data, including video imagery, conveys "information" about objects of interest within the scene: Shape, material, identity, relations, etc. However, it is also highly redundant, and subject to variability that has little to do with the properties of the scene of interest, but instead depend on the sensor, the vantage point, and the nature of the illuminant, etc. This project addresses the question of determining what function of imaging data should be inferred and stored, that is, as "informative" as possible for a class of tasks such as object or scene detection, localization, recognition and categorization, and at the same time as "compressed" as possible, and insensitive to nuisance variability. Such a function is called a Representation. This research has pedagogical value, by framing seemingly unrelated methods as different approximations of an ideal Representation, thus facilitating the educational process in Computer Vision. This is further expected to facilitate the design of better Representations, and therefore improved algorithms for visual recognition (detection, localization, recognition, and categorization) systems, with impact in a range of applications from autonomy (e.g., robotic navigation and surveillance) to interaction (e.g., assisted surgery and augmented reality).&lt;br/&gt;&lt;br/&gt;The project frames the problem of inferring optimal task-specific Representations in terms of the Information Bottleneck Principle, and addresses issues of computability, approximation, and dimensionality reduction within this framework. It also addresses questions of "learnability," to determine whether a generic learning architecture can approximate an optimal representation. The Information Bottleneck is a generalization and relaxation of the notion of minimal sufficient statistic, where complexity constraints and task relevance are explicitly taken into account. The challenge is that modeling the generative process for visual data entails complex geometry (surface shape), topology (occlusions), photometry (material reflection, illumination), and dynamics (motion) with the object of interest living in infinite-dimensional spaces. Thus, the Information Bottleneck is difficult to even formalize, let alone instantiate, compute, and optimize. The project focuses on developing approximations of the Information Bottleneck that are tractable and yet enjoy performance guarantees.</AbstractNarration>
<MinAmdLetterDate>07/14/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/14/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422669</AwardID>
<Investigator>
<FirstName>Stefano</FirstName>
<LastName>Soatto</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stefano Soatto</PI_FULL_NAME>
<EmailAddress>soatto@ucla.edu</EmailAddress>
<PI_PHON>3108254840</PI_PHON>
<NSF_ID>000489719</NSF_ID>
<StartDate>07/14/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA Computer Science]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951596</ZipCode>
<StreetAddress><![CDATA[420 Westwood Plaza, 3531D BH]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~456617</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The objective of the project was to develop analytical and computational tools to design and learn visual representations. These are functions of visual data that support decision and control tasks. They include decision tasks such as detection, localization, recognition and categorization of objects and scenes. The original goal was to formalize the notion of &ldquo;representation&rdquo; in the context of the Information Bottleneck Principle, to address questions of computability and approximation in the design and learning of representations from visual data.&nbsp;<br />During the course of the program, tools from functional approximation with classes of universal models such as deep neural networks have surged in popularity, driven by widespread empirical evidence of their effectiveness as measured by benchmark datasets. These tools have been adopted during the course of the project, but more importantly an effort has commenced to connect defining properties of representations, which stem from fundamental principles such as minimality, sufficiency, invariance, and independence, and the practice of training deep neural networks. While these at face value do not have any direct connections, work in this project has been functional to the development of the Emergence Theory of Deep Learning, that establishes the first known bounds between the training loss of deep neural network (a function of past, or training, data) and invariance properties of the resulting representation (a function of test, or future, data).&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/08/2018<br>      Modified by: Stefano&nbsp;Soatto</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The objective of the project was to develop analytical and computational tools to design and learn visual representations. These are functions of visual data that support decision and control tasks. They include decision tasks such as detection, localization, recognition and categorization of objects and scenes. The original goal was to formalize the notion of "representation" in the context of the Information Bottleneck Principle, to address questions of computability and approximation in the design and learning of representations from visual data.  During the course of the program, tools from functional approximation with classes of universal models such as deep neural networks have surged in popularity, driven by widespread empirical evidence of their effectiveness as measured by benchmark datasets. These tools have been adopted during the course of the project, but more importantly an effort has commenced to connect defining properties of representations, which stem from fundamental principles such as minimality, sufficiency, invariance, and independence, and the practice of training deep neural networks. While these at face value do not have any direct connections, work in this project has been functional to the development of the Emergence Theory of Deep Learning, that establishes the first known bounds between the training loss of deep neural network (a function of past, or training, data) and invariance properties of the resulting representation (a function of test, or future, data).           Last Modified: 10/08/2018       Submitted by: Stefano Soatto]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
