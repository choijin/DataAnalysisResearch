<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Medium: Availability-Consistency Tradeoffs in Key-Value and NoSQL Storage Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>584508.00</AwardTotalIntnAmount>
<AwardAmount>584508</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Key-value/NoSQL storage systems are a key component of the cloud computing revolution. Today's key-value/NoSQL storage systems lie at different points on the tradeoff spectrum of availability (i.e., fast reads and writes) vs. data consistency (across multiple clients) vs. partition-tolerance. This project will better characterize what is achievable along this spectrum, to make these systems dynamically adapt along the spectrum to meet application requirements, and to benchmark the actual availability and consistency achieved by real systems under real conditions.&lt;br/&gt;&lt;br/&gt;The project will follow two synergistic thrusts. The first thrust will use probabilistic models for availability, consistency, and partitions to analyze the tradeoffs among these. Then it will design adaptive techniques to meet an SLA (Service Level Agreement) or SLO (Service Level Objective) which specifies either an availability constraint or a consistency constraint, while optimizing the other metric. Finally, these techniques will be implemented in some of the leading key-value/NoSQL storage systems in use today in industry. Our second thrust will apply the large body of formal verification research to key-value/NoSQL systems. The work herein includes use of a formal modeling language to specify models for key-value/NoSQL stores, and use of standard as well as statistical model-checking to analyze and characterize the behavior of these systems.&lt;br/&gt;&lt;br/&gt;This work will imbue existing key-value/NoSQL storage systems with the ability to adapt to the tradeoffs between consistency, availability, and partition-tolerance, as a function of provider and customer requirements, at run-time. It will lead to better SLAs and SLOs that combine both consistency models and availability models in a practical and achievable way. Thus, the project will directly impact the large developer and user communities of key-value/NoSQL storage systems. The project will produce open software and meaningful datasets.</AbstractNarration>
<MinAmdLetterDate>09/11/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1409416</AwardID>
<Investigator>
<FirstName>Jose</FirstName>
<LastName>Meseguer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jose Meseguer</PI_FULL_NAME>
<EmailAddress>meseguer@cs.uiuc.edu</EmailAddress>
<PI_PHON>2173336733</PI_PHON>
<NSF_ID>000170952</NSF_ID>
<StartDate>09/11/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Nitin</FirstName>
<LastName>Vaidya</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nitin H Vaidya</PI_FULL_NAME>
<EmailAddress>nv198@georgetown.edu</EmailAddress>
<PI_PHON>2026870317</PI_PHON>
<NSF_ID>000101142</NSF_ID>
<StartDate>09/11/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Indranil</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Indranil Gupta</PI_FULL_NAME>
<EmailAddress>indy@illinois.edu</EmailAddress>
<PI_PHON>2172655517</PI_PHON>
<NSF_ID>000148881</NSF_ID>
<StartDate>09/11/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Urbana</CityName>
<StateCode>IL</StateCode>
<ZipCode>618013620</ZipCode>
<StreetAddress><![CDATA[506 S. Wright Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~584508</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-17943f1a-7fff-696c-5d48-4d48185b61d3"> </span></p> <p dir="ltr"><span>Distributed systems are the engine powering the technological world around us. Software running in datacenters across the world store and process the large amounts of data that humans generate and consume in social media, the Web, and broadly the internet. The designers and creators of such distributed systems have to make a hard choice between offering low latency to users vs. offering high consistency of data (what one user writes is available immediately to other users elsewhere in the world).</span></p> <p dir="ltr"><span>This project turns this tradeoff into a soft choice, and one that can be made flexibly by developers, as per the application and deployment needs. We have designed systems that support developer-specified Service Level Agreements/Objectives (SLAs/SLOs), which can specify latency, and/or throughput, and/or consistency requirements, etc. Our systems allow developers to "move" along the tradeoff curve between latency and consistency (to the sweet spot for their particular application), rather than be stuck to a hard choice. We have built new techniques and written code for, as well as experimented in real clusters, distributed systems that support such SLAs/SLOs for distributed storage, distributed stream processing, and distributed graph processing--these are the three largest areas of distributed systems today in industry, spanning both large companies and startups.</span></p> <p dir="ltr"><span>Our intellectual contributions span both: i) new algorithmic techniques (along with their analysis, implementation, and experimentation), ii) as well as formal verification of the existing designs of distributed storage and transaction systems, focusing on consistency and performance (latency, throughput). The broader impact from this work spans: i) our implementations in and modifications to, multiple popular open-source distributed systems software that are used widely in industry today, and ii) two production systems that run inside LinkedIn--Ambry, a system to store multimedia blobs of data, with over 500 Million users today, and Apache Samza a stream processing system in use by over 20 companies today (both are open-source systems). The project has produced 3 PhD theses (1 woman), 7 MS thesis, and has 5 ongoing PhD theses (2 women).</span></p> <p><span id="docs-internal-guid-344143ad-7fff-b1fa-891e-937656f8d176"><span>On the educational front, this project has led to the creation of the world?s largest course on cloud computing. Called Cloud Computing Concepts (Parts 1 and 2), this course is offered by PI Gupta on Coursera and is annually taken by over 150K students from around 198 countries.</span></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/14/2018<br>      Modified by: Indranil&nbsp;Gupta</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Distributed systems are the engine powering the technological world around us. Software running in datacenters across the world store and process the large amounts of data that humans generate and consume in social media, the Web, and broadly the internet. The designers and creators of such distributed systems have to make a hard choice between offering low latency to users vs. offering high consistency of data (what one user writes is available immediately to other users elsewhere in the world). This project turns this tradeoff into a soft choice, and one that can be made flexibly by developers, as per the application and deployment needs. We have designed systems that support developer-specified Service Level Agreements/Objectives (SLAs/SLOs), which can specify latency, and/or throughput, and/or consistency requirements, etc. Our systems allow developers to "move" along the tradeoff curve between latency and consistency (to the sweet spot for their particular application), rather than be stuck to a hard choice. We have built new techniques and written code for, as well as experimented in real clusters, distributed systems that support such SLAs/SLOs for distributed storage, distributed stream processing, and distributed graph processing--these are the three largest areas of distributed systems today in industry, spanning both large companies and startups. Our intellectual contributions span both: i) new algorithmic techniques (along with their analysis, implementation, and experimentation), ii) as well as formal verification of the existing designs of distributed storage and transaction systems, focusing on consistency and performance (latency, throughput). The broader impact from this work spans: i) our implementations in and modifications to, multiple popular open-source distributed systems software that are used widely in industry today, and ii) two production systems that run inside LinkedIn--Ambry, a system to store multimedia blobs of data, with over 500 Million users today, and Apache Samza a stream processing system in use by over 20 companies today (both are open-source systems). The project has produced 3 PhD theses (1 woman), 7 MS thesis, and has 5 ongoing PhD theses (2 women).  On the educational front, this project has led to the creation of the world?s largest course on cloud computing. Called Cloud Computing Concepts (Parts 1 and 2), this course is offered by PI Gupta on Coursera and is annually taken by over 150K students from around 198 countries.          Last Modified: 11/14/2018       Submitted by: Indranil Gupta]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
