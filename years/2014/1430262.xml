<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRCNS US-French Research Proposal: Bayesian Models of Sensory Integration, Adaptation and Calibration</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>498020.00</AwardTotalIntnAmount>
<AwardAmount>498020</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Gottlob</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>A fundamental question in perceptual and cognitive science concerns how decisions about incoming sensory information unfold over time. The influx of available sensory information must be balanced across time with the need for quickness versus accuracy in making a decision. Sensory systems are flexible in response to changing context, resulting in several dynamic aspects of perception at multiple time scales, including the trade-off between speed and accuracy in decisions or actions, adaptation for repeated sensory stimuli, and long-term recalibration in response to a consistent change in stimulation or error. This proposal attempts to advance theoretical understanding of these processes by unifying disparate threads in modern perceptual theory while developing models of the dynamics of sensory integration and decision-making. The research could ultimately have implications for the design of virtual reality systems, lighting and sound systems, visual displays, and artificial vision and sound processing systems. &lt;br/&gt;&lt;br/&gt;A large literature on multiple cue integration, or how observers integrate multiple sources of information for making a perceptual decision, suggests that human behavior compares favorably with the predictions of optimal Bayesian models for combining multiple sources of information (including prior knowledge). However, this literature examines decisions under static conditions. There is a mostly distinct literature on speeded decision-making that instead asks how information is accumulated over time, leading to the combined decision of both what response to make and when to make that response. The novelty of the proposed research is to unify these two threads of perceptual theory by developing and testing a model that incorporates both a dynamic decision-making model for evidence accumulation (a diffusion process) and multiple-cue integration. Each cue contributes independently to the dynamic process of evidence accumulation. The experimental work proposed to test the model covers a wide range of sensory decision-making phenomena and thus is expected to have a strong impact on the field of perceptual science. However, the wider impact will result from the unifying models to be developed, as the combination of optimal cue integration with dynamic decision-making models has extremely wide applicability in cognitive science generally. A companion project is being funded by the French National Research Agency (ANR).</AbstractNarration>
<MinAmdLetterDate>09/02/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/02/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1430262</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Landy</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael S Landy</PI_FULL_NAME>
<EmailAddress>msl1@nyu.edu</EmailAddress>
<PI_PHON>2129987857</PI_PHON>
<NSF_ID>000585559</NSF_ID>
<StartDate>09/02/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100122331</ZipCode>
<StreetAddress><![CDATA[665 Broadway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1321</Code>
<Text>Decision, Risk &amp; Mgmt Sci</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1321</Code>
<Text>DECISION RISK &amp; MANAGEMENT SCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7327</Code>
<Text>CRCNS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~498020</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="font-size: 10.000000pt; font-family: 'ArialMT';">The goals of this project were to better understand how humans combine information over time in perceptual and motor tasks. There were various sub-projects, but here I concentrate on one in particular. </span></p> <p><span style="font-size: 10.000000pt; font-family: 'ArialMT';">Suppose you are asked to perform a perceptual discrimination. For example, you look at a difficult visual display (low contrast, noisy, or otherwise set up to make your task difficult. Your task is a simple perceptual discrimination such as localization (Is this noisy, hard-to-see&nbsp; blob to the right or left of the center of the display?), orientation discrimination (Is this stretched-out blob oriented clockwise or counterclockwise of vertical?) or direction discrimination (Is this random collection of moving objects mostly moving rightward or leftward?). The instructions tell you to be as fast as possible, while maintaining high accuracy in the task.<br /></span></p> <p><span style="font-size: 10.000000pt; font-family: 'ArialMT';">The standard model of such tasks, called drift-diffusion, suggests that at each moment in time you summarize the evidence for the two alternatives with a single number, the "evidence" (e.g., a positive number is evidence for "rightward" and a negative number is evidence for "leftward"). This evidence is summed over time, and when the accumulated evidence is large enough, you report your answer (based on the sign of the accumulated evidence). We can derive a simple prediction from this model: performance should depend on a combination of <em>signal </em>(e.g., how different are the two locations, orientations or motion directions that you are forced to compare) and <em>noise </em>(how low is the contrast on the screen or how difficult is it to estimate the stimulus location, orientation or direction). In drift-diffusion, those two parameters should interact, by which I mean that the effect of changing the signal on reaction time will depend on the level of noise.</span></p> <p><span style="font-size: 10.000000pt; font-family: 'ArialMT';">What we found in several experiments was that the two parameters generally did not interact. Rather, the amount by which a decrease in signal slowed down your responses was independent of the noise level. We developed an alternative, two-stage model that was consistent with this behavior, and verified several of its predictions for behavior. Given that drift-diffusion is the dominant model of performance in such reaction-time tasks and is also used as a model of neural responses during such tasks, these results should have wide impact, forcing us to reinterpret such neural data.</span></p> <p><span style="font-size: 10.000000pt; font-family: 'ArialMT';">In addition to&nbsp; this work, we also investigated the integration of information across time and over multiple sensory cues for other tasks including discrimination of the rate of events, where events could be auditory ("clicks"), visual ("flashes") or both. We also looked at judgments of confidence, i.e., your own estimate of how well you just performed, either on a perceptual discrimination or on a perceptual-motor task (tracking a moving stimulus using a mouse). In each case, as with the analysis of reaction-time tasks, we combined measurements of human performance in these tasks with computational models of how the task might be performed by the brain.<br /></span></p><br> <p>            Last Modified: 10/26/2017<br>      Modified by: Michael&nbsp;S&nbsp;Landy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goals of this project were to better understand how humans combine information over time in perceptual and motor tasks. There were various sub-projects, but here I concentrate on one in particular.   Suppose you are asked to perform a perceptual discrimination. For example, you look at a difficult visual display (low contrast, noisy, or otherwise set up to make your task difficult. Your task is a simple perceptual discrimination such as localization (Is this noisy, hard-to-see  blob to the right or left of the center of the display?), orientation discrimination (Is this stretched-out blob oriented clockwise or counterclockwise of vertical?) or direction discrimination (Is this random collection of moving objects mostly moving rightward or leftward?). The instructions tell you to be as fast as possible, while maintaining high accuracy in the task.   The standard model of such tasks, called drift-diffusion, suggests that at each moment in time you summarize the evidence for the two alternatives with a single number, the "evidence" (e.g., a positive number is evidence for "rightward" and a negative number is evidence for "leftward"). This evidence is summed over time, and when the accumulated evidence is large enough, you report your answer (based on the sign of the accumulated evidence). We can derive a simple prediction from this model: performance should depend on a combination of signal (e.g., how different are the two locations, orientations or motion directions that you are forced to compare) and noise (how low is the contrast on the screen or how difficult is it to estimate the stimulus location, orientation or direction). In drift-diffusion, those two parameters should interact, by which I mean that the effect of changing the signal on reaction time will depend on the level of noise.  What we found in several experiments was that the two parameters generally did not interact. Rather, the amount by which a decrease in signal slowed down your responses was independent of the noise level. We developed an alternative, two-stage model that was consistent with this behavior, and verified several of its predictions for behavior. Given that drift-diffusion is the dominant model of performance in such reaction-time tasks and is also used as a model of neural responses during such tasks, these results should have wide impact, forcing us to reinterpret such neural data.  In addition to  this work, we also investigated the integration of information across time and over multiple sensory cues for other tasks including discrimination of the rate of events, where events could be auditory ("clicks"), visual ("flashes") or both. We also looked at judgments of confidence, i.e., your own estimate of how well you just performed, either on a perceptual discrimination or on a perceptual-motor task (tracking a moving stimulus using a mouse). In each case, as with the analysis of reaction-time tasks, we combined measurements of human performance in these tasks with computational models of how the task might be performed by the brain.        Last Modified: 10/26/2017       Submitted by: Michael S Landy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
