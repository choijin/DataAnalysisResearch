<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: A User-centric Architecture for Ad-hoc Analytical Processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Aidong Zhang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Given the growing demand for interactive data exploration using cloud-based infrastructure, the PIs propose a user-centric architecture designed specifically for cost-effective, ad-hoc, real-time analytical processing. The proposed architecture will use answer approximation techniques and distributed in-memory query evaluation to offer a fluid data interaction experience to the end user. The user-centric interaction paradigm has the potential to revolutionize future data processing platforms, and rapidly accelerate data-driven discovery and decision making in areas such as business management, bioinformatics, astronomy, finance, and more.&lt;br/&gt;&lt;br/&gt;The PIs propose a novel interactive faceted exploration paradigm for analyzing multi-dimensional data cubes. By tightly integrating faceted exploration of data cubes within a distributed, main-memory interactive query engine, this project investigates three complementary avenues: cube exploration models geared towards interaction, query evaluation strategies for interactive main-memory online analytical processing (OLAP), and distributed architectures for parallel analysis that trade accuracy to meet user-defined response time constraints. The PIs will investigate a unique combination of techniques such as speculative execution, shared scans and sampling to serve user-centric aspects of OLAP workloads. The simultaneous design of faceted exploration models and underlying database engine primitives allows data exploration tasks to be performed in an intuitive and interactive manner, while leveraging modern hardware features for performance. By focusing on the user, this project will rethink aspects of database architectures for interactively exploring large datasets.&lt;br/&gt;&lt;br/&gt;For further information, see the project web site at: http://go.osu.edu/userolap</AbstractNarration>
<MinAmdLetterDate>08/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422977</AwardID>
<Investigator>
<FirstName>Arnab</FirstName>
<LastName>Nandi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arnab Nandi</PI_FULL_NAME>
<EmailAddress>arnab@cse.ohio-state.edu</EmailAddress>
<PI_PHON>6142923805</PI_PHON>
<NSF_ID>000623779</NSF_ID>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Spyros</FirstName>
<LastName>Blanas</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Spyros Blanas</PI_FULL_NAME>
<EmailAddress>blanas.2@osu.edu</EmailAddress>
<PI_PHON>6142926381</PI_PHON>
<NSF_ID>000652382</NSF_ID>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101063</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p id="docs-internal-guid-f3c82b7b-7fff-20d3-a4f6-fcdc71545060" style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The goal of the project was to develop a new, user-centric architecture for ad-hoc analytical data processing. Our motivation of supporting <span>interactive visual analytics </span>comes from scientific and industrial settings. Our research has advanced the state of the art along two orthogonal problems: (1) approximation techniques that trade accuracy for latency, (2) acceleration techniques that improve efficiency and process more data in less time. Overall, this project looked into multiple approaches to fulfil its vision, at the single-node-, distributed-, and shared-memory contexts.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">At the single-node level, we explored the concept of bounded-time querying, in the context of rapidly changing, or "in flux" queries. The observation in this case was that while the data being inspected is the same, the query itself can rapidly change. Thus, we investigated the use of cyclic scan-based execution to scan tables continually, with in flux queries registering with the scan for a bounded amount of time, yielding approximate-but-interactive results.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">From a distributed architecture design perspective, we investigated the co-designing of the system based on both user needs, and system capabilities. By first analyzing real-world usage logs, we were able to model facet operators to traverse a data cube. Second, we observed that while users would like response-times to be instantaneous, they spent several seconds to minutes viewing the results: this motivated the introduction of speculative execution. Further, users were receptive to interactively trading off accuracy for improvements in response time, justifying the use of sampling over query-time definable subsets of data. By combining these strategies, we are able to provide a holistic, end-to-end approach towards using approximation for latency-bound, highly interactive analytics experience for the end-user.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">This speculative execution and caching model for interactive analytics opens up several opportunities for acceleration. In two specific and computationally expensive cases -- speculative querying in the presence of sampling, and error computation -- we developed novel strategies for result and error reuse across multiple queries. By caching reusable components of query results across the query session, we were able to outperform conventional sampled aggregation methods. Furthermore, our query rewrite-based approach means that we do not need to modify the underlying database system, allowing for its use on commodity database systems.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">During the investigation of error computation and reuse, we noticed several discrepancies in the implementation of the VARIANCE function across modern database systems, a core function used in the context of sampling. This led to a survey of statistical methods to calculate variance, and the development of guidelines and tradeoffs for database systems developers to consider when implementing VARIANCE in their own systems.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">In addition to sampling, the commoditization of high-performance networking has sparked research interest in rethinking the query processing paradigm. In particular, the RDMA mechanism of high-performance networks has generated substantial excitement due to the ability to directly access remote memory from within applications without involving the TCP/IP stack or the remote CPU. The established parallel data processing paradigm relies on function shipping, where a coordinator dispatches queries to worker nodes and then collects the results. RDMA makes data shipping possible, where the coordinator directly reads data in the workers' memory using RDMA while workers process other queries. We observed that data shipping can be up to 6.5X faster when performing clustered sampling with heavily-utilized workers.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Another outcome of this project was designing a data shuffling algorithm that uses RDMA to transfer data at line rate during query processing. The design space requires one to control (1) the number of open connections, (2) the contention for the shared network interface, (3) the RDMA transport function, and (4) how much memory should be reserved to exchange data between nodes during query processing. This project developed a data shuffling operator that uses the RDMA Send/Receive transport function over the Unreliable-Datagram transport service to transmit data up to 4X faster than an RDMA-capable MPI implementation in a 16-node cluster. By adopting this lower-level access interface to a fast network, the end-to-end query response time for TPC-H queries improves by as much as 2X.</span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The emergence of fast networks requires revisiting the query planning and optimization procedure of a database system. Cost models from prior work ignore unique properties of memory, including a performance asymmetry between read vs. write speeds and the impact of random accesses. We developed a memory-centric I/O cost model to identify good evaluation strategies for complex query plans with multiple hash-based equi-joins over memory-resident data. Our cost model was carefully validated for accuracy using three different systems to control for hardware-specific differences. The conventional wisdom from prior work in query optimization is that <span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">right-deep and bushy trees should be preferred for multi-join queries</span> due to their greater parallelization and pipelining potential. This project found that the conventional wisdom from shared-nothing disk-based systems does not always apply to the modern shared-everything local and distributed memory hierarchy.</span></p><br> <p>            Last Modified: 01/15/2019<br>      Modified by: Arnab&nbsp;Nandi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The goal of the project was to develop a new, user-centric architecture for ad-hoc analytical data processing. Our motivation of supporting interactive visual analytics comes from scientific and industrial settings. Our research has advanced the state of the art along two orthogonal problems: (1) approximation techniques that trade accuracy for latency, (2) acceleration techniques that improve efficiency and process more data in less time. Overall, this project looked into multiple approaches to fulfil its vision, at the single-node-, distributed-, and shared-memory contexts.   At the single-node level, we explored the concept of bounded-time querying, in the context of rapidly changing, or "in flux" queries. The observation in this case was that while the data being inspected is the same, the query itself can rapidly change. Thus, we investigated the use of cyclic scan-based execution to scan tables continually, with in flux queries registering with the scan for a bounded amount of time, yielding approximate-but-interactive results.   From a distributed architecture design perspective, we investigated the co-designing of the system based on both user needs, and system capabilities. By first analyzing real-world usage logs, we were able to model facet operators to traverse a data cube. Second, we observed that while users would like response-times to be instantaneous, they spent several seconds to minutes viewing the results: this motivated the introduction of speculative execution. Further, users were receptive to interactively trading off accuracy for improvements in response time, justifying the use of sampling over query-time definable subsets of data. By combining these strategies, we are able to provide a holistic, end-to-end approach towards using approximation for latency-bound, highly interactive analytics experience for the end-user.   This speculative execution and caching model for interactive analytics opens up several opportunities for acceleration. In two specific and computationally expensive cases -- speculative querying in the presence of sampling, and error computation -- we developed novel strategies for result and error reuse across multiple queries. By caching reusable components of query results across the query session, we were able to outperform conventional sampled aggregation methods. Furthermore, our query rewrite-based approach means that we do not need to modify the underlying database system, allowing for its use on commodity database systems.   During the investigation of error computation and reuse, we noticed several discrepancies in the implementation of the VARIANCE function across modern database systems, a core function used in the context of sampling. This led to a survey of statistical methods to calculate variance, and the development of guidelines and tradeoffs for database systems developers to consider when implementing VARIANCE in their own systems.   In addition to sampling, the commoditization of high-performance networking has sparked research interest in rethinking the query processing paradigm. In particular, the RDMA mechanism of high-performance networks has generated substantial excitement due to the ability to directly access remote memory from within applications without involving the TCP/IP stack or the remote CPU. The established parallel data processing paradigm relies on function shipping, where a coordinator dispatches queries to worker nodes and then collects the results. RDMA makes data shipping possible, where the coordinator directly reads data in the workers' memory using RDMA while workers process other queries. We observed that data shipping can be up to 6.5X faster when performing clustered sampling with heavily-utilized workers.   Another outcome of this project was designing a data shuffling algorithm that uses RDMA to transfer data at line rate during query processing. The design space requires one to control (1) the number of open connections, (2) the contention for the shared network interface, (3) the RDMA transport function, and (4) how much memory should be reserved to exchange data between nodes during query processing. This project developed a data shuffling operator that uses the RDMA Send/Receive transport function over the Unreliable-Datagram transport service to transmit data up to 4X faster than an RDMA-capable MPI implementation in a 16-node cluster. By adopting this lower-level access interface to a fast network, the end-to-end query response time for TPC-H queries improves by as much as 2X.   The emergence of fast networks requires revisiting the query planning and optimization procedure of a database system. Cost models from prior work ignore unique properties of memory, including a performance asymmetry between read vs. write speeds and the impact of random accesses. We developed a memory-centric I/O cost model to identify good evaluation strategies for complex query plans with multiple hash-based equi-joins over memory-resident data. Our cost model was carefully validated for accuracy using three different systems to control for hardware-specific differences. The conventional wisdom from prior work in query optimization is that right-deep and bushy trees should be preferred for multi-join queries due to their greater parallelization and pipelining potential. This project found that the conventional wisdom from shared-nothing disk-based systems does not always apply to the modern shared-everything local and distributed memory hierarchy.       Last Modified: 01/15/2019       Submitted by: Arnab Nandi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
