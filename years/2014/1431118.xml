<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Making words disappear or appear: A neurocognitive and behavioral investigation of effects of speech rate on spoken word perception</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>102214.00</AwardTotalIntnAmount>
<AwardAmount>102214</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Understanding how humans comprehend speech is an unsolved and challenging problem, in part because factors such as different speakers, dialects, and speaking rates introduce a great deal of temporal and spectral variability into the speech signal. The focus of this research is on the influence of temporal context on perception of segments, syllables, and words. Results of the research may offer insights into treatment of disorders that involve disruption of speech rate (e.g., dysarthria, stuttering, Parkinson's disease, and aphasia), inform approaches to improve speech technology applications (e.g., enhanced automatic speech recognition, more natural sounding computer-generated speech), and lead to new discoveries related to brain mechanisms involved in understanding spoken language. The investigators will also involve students in the research, including those from a primarily undergraduate institution collaborating on the project.&lt;br/&gt;&lt;br/&gt;The investigators will test different accounts of temporal phenomena in the perception of speech. They propose two interacting cognitive mechanisms controlling phenomena at lexical and phonetic levels, each driven by a different neural timing mechanism. The hypothesis is that effects of lexical rate primarily stem from top-down, speech-specific temporal expectancies, while phonetic rate effects originate in bottom-up, transient rhythmic expectations that are not specific to speech. This hypothesis will be assessed using psychoacoustic studies, non-invasive measures of brain activity, and theoretical modeling in order to identify the processing characteristics revealed by neural representations of temporal properties of speech.</AbstractNarration>
<MinAmdLetterDate>08/14/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/14/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1431118</AwardID>
<Investigator>
<FirstName>Lisa</FirstName>
<LastName>Sanders</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lisa D Sanders</PI_FULL_NAME>
<EmailAddress>lsanders@psych.umass.edu</EmailAddress>
<PI_PHON>4135450698</PI_PHON>
<NSF_ID>000650261</NSF_ID>
<StartDate>08/14/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039242</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~102214</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Understanding speech requires that listeners be able to adjust to a wide variety of talkers and listening conditions. As such, there are multiple influences of the speech a listener has already heard on how they process incoming speech signals. One such effect of heard speech on speech processing involves the timing of speech information; the rate of context speech influences whether listeners report hearing acoustically blended words (e.g., &ldquo;or&rdquo; in &ldquo;leisure or time&rdquo;). Competing hypotheses posited that 1) listeners formulate predictions about the timing of upcoming speech signals based on the rate of the preceding context and 2) speech rate information can influence lexical competition in a way that favors words that are consistent with context speech rate. To differentiate between these accounts, we conducted event-related potential (ERP) research that measured the electrical activity of the brain that is time locked to specific speech events. The neurophysiological response to blended function words in acoustically identical portions of speech streams differed based on context speech rate by 100 ms after onset. Specifically, the same speech sounds that failed to elicit ERPs associated with auditory onsets and function words when presented with fast, casual contexts did elicit these brain responses when presented with slowed contexts. The ERP results were consistent with transcriptions of the phrases. The acoustically blended function words were typically not reported in the faster context condition and typically were reported in the slowed context condition. The timing of the differences in the brain response indicates that distal speech rate affects early perceptual processing of speech sounds. This result is consistent with listeners formulating predictions about the timing of upcoming speech signals, and those predictions influencing perception of incoming speech signals.</p> <p>&nbsp;</p> <p>This research significantly expands our shared knowledge of the mechanism by which context influences speech processing. The finding that context speech rate affects early perceptual processing of speech sounds has important implications for models of speech processing. The results suggest that listeners automatically extract rate information from speech signals under typical listening conditions. Further, they demonstrate that predictions about the timing of speech sounds are typically employed when listening to speech for comprehension. Finally, the results show that factors which influence predictive processes can be functionally equivalent to acoustic modulations.</p> <p>&nbsp;</p> <p>This research involved the contributions of seven undergraduate students and two post-baccalaureate assistants, five of whom are under-represented minorities. The research experience on this project compelled six of those students (three under-represented minorities) to apply to graduate programs; four have already begun their graduate work. One of the students who has started her PhD program is an author on a manuscript describing this research that has been submitted for publication.</p><br> <p>            Last Modified: 10/30/2017<br>      Modified by: Lisa&nbsp;D&nbsp;Sanders</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Understanding speech requires that listeners be able to adjust to a wide variety of talkers and listening conditions. As such, there are multiple influences of the speech a listener has already heard on how they process incoming speech signals. One such effect of heard speech on speech processing involves the timing of speech information; the rate of context speech influences whether listeners report hearing acoustically blended words (e.g., "or" in "leisure or time"). Competing hypotheses posited that 1) listeners formulate predictions about the timing of upcoming speech signals based on the rate of the preceding context and 2) speech rate information can influence lexical competition in a way that favors words that are consistent with context speech rate. To differentiate between these accounts, we conducted event-related potential (ERP) research that measured the electrical activity of the brain that is time locked to specific speech events. The neurophysiological response to blended function words in acoustically identical portions of speech streams differed based on context speech rate by 100 ms after onset. Specifically, the same speech sounds that failed to elicit ERPs associated with auditory onsets and function words when presented with fast, casual contexts did elicit these brain responses when presented with slowed contexts. The ERP results were consistent with transcriptions of the phrases. The acoustically blended function words were typically not reported in the faster context condition and typically were reported in the slowed context condition. The timing of the differences in the brain response indicates that distal speech rate affects early perceptual processing of speech sounds. This result is consistent with listeners formulating predictions about the timing of upcoming speech signals, and those predictions influencing perception of incoming speech signals.     This research significantly expands our shared knowledge of the mechanism by which context influences speech processing. The finding that context speech rate affects early perceptual processing of speech sounds has important implications for models of speech processing. The results suggest that listeners automatically extract rate information from speech signals under typical listening conditions. Further, they demonstrate that predictions about the timing of speech sounds are typically employed when listening to speech for comprehension. Finally, the results show that factors which influence predictive processes can be functionally equivalent to acoustic modulations.     This research involved the contributions of seven undergraduate students and two post-baccalaureate assistants, five of whom are under-represented minorities. The research experience on this project compelled six of those students (three under-represented minorities) to apply to graduate programs; four have already begun their graduate work. One of the students who has started her PhD program is an author on a manuscript describing this research that has been submitted for publication.       Last Modified: 10/30/2017       Submitted by: Lisa D Sanders]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
