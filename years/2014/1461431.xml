<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: Examining Sequence of Contextualized Items in Science</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>15994.00</AwardTotalIntnAmount>
<AwardAmount>15994</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
<PO_EMAI>ceavey@nsf.gov</PO_EMAI>
<PO_PHON>7032927269</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Student performance on science tests often is substantially influenced by the context of individual test items.  This doctoral dissertation research project will systematically describe the sequence patterns used in science test-item contexts and obtain empirical evidence on how the sequence patterns of contextual information supports or hinders student performance on science tests.  Contextual information includes supplemental information, such as a vignette or selected background facts that precede or follow a test item.  The project will address three gaps in the literature on contextualized items by providing: a consistent theory-based framework for selecting test-item characteristics to be studied; new knowledge about how student performance is influenced by specific elements or features of the test items; and better understanding of subgroups of students and their performance to advance knowledge about how to achieve consistently equitable testing.  In particular, this project will produce both theory and empirical evidence regarding how the sequence of contextual information can be attributed to differential performance between English language learners (ELL) and non-ELL groups.  Findings from the ELL and non-ELL comparisons will lead to important improvements in how items are developed to ensure test fairness.  As a Doctoral Dissertation Research Improvement award, the project will enable a promising student to establish a strong, independent research career.&lt;br/&gt;&lt;br/&gt;The project's design and data analyses will be framed by three research questions:  (1) How is student performance associated with different dimensions of the sequence of contextual information for science test items?  (2) Controlling for different levels of linguistic complexity in contexts, how is the contextual sequence linked to science performance of ELLs and non-ELLs?  (3) How do different dimensions of sequence of context influence how students interpret and respond to tasks?  The project will include multiple facets of inquiry, including psychometrics, test-item creation, misconceptions, and cognitive diagnostic assessment.  The project will generate item-development guidelines based on dimensions of sequence of contextual information.  Items resulting from this process will evoke students' stored knowledge relevant to the content and/or process skills being assessed.  The newly developed science items then will be field tested with a diverse population of eighth graders.  A range of psychometric and statistical procedures will be applied to student test scores.  This activity will include both think-aloud and eye-tracking student cognitive interviews, with quantitative and qualitative analyses of the cognitive interview data.</AbstractNarration>
<MinAmdLetterDate>06/17/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/17/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1461431</AwardID>
<Investigator>
<FirstName>Min</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Min Li</PI_FULL_NAME>
<EmailAddress>minli@u.washington.edu</EmailAddress>
<PI_PHON>2066166305</PI_PHON>
<NSF_ID>000486022</NSF_ID>
<StartDate>06/17/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ting</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ting Wang</PI_FULL_NAME>
<EmailAddress>twang001@ets.org</EmailAddress>
<PI_PHON>6095248015</PI_PHON>
<NSF_ID>000651039</NSF_ID>
<StartDate>06/17/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981051016</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave. NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~15994</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Project Outcomes</strong></p> <p><strong>&nbsp;</strong></p> <p>This project investigates different sequence patterns provided in science item contexts. Real-world contexts have been the subject of considerable measurement research. However, the utility and realism of contexts used in items have been called into question. For example, the item&rsquo;s context may lead to differential understandings of what the item is intended to ask and different levels of difficulty for students to represent and solve the problem. We chose to focus on one characteristic presented in science item contexts: the sequence of contextual information. We asked three research questions: (1) How is student performance associated with different dimensions of the sequence of context presented in contextualized science test items? (2) Controlling for levels of linguistic demands in item contexts, how is sequence of context linked to English language learners' (ELLs') and non-ELLs' science performance? (3) How do different dimensions of sequence of context impact students&rsquo; understanding of and response to tasks?</p> <p>&nbsp;</p> <p>We hypothesized that specific sequences of information presented should allow students to make sense of and follow the logic of the item context rather than distracting them from scientific thinking. We defined the sequence of contextual information as the order of events or descriptions involved in contextualized items and conceptualize it into three dimensions: sequence of events (D1), sequence of intention and action (D2), and sequence of cause and effect (D3). We applied this theoretical framework to item selection and development so that the item sequences could be systematically varied for experimental purposes. Then, we conducted an experiment in which students in Grades 7-12 were randomly assigned to selected items. We selected 18 of these students to participate in cognitive interviews based on their performance on the field test items. We recruited an additional 12 students for an eye tracking study to test time spent on each question. We performed both qualitative and quantitative analyses with test scores, students&rsquo; cognitive interviews, and eye tracking data to study whether and how the sequence of contextual information impacts student performance. We also incorporated the linguistic demands of contexts in our item development and data analysis to understand whether and how linguistic demands of contexts mediate the relationship between sequence patterns and ELL and non-ELL student performance on items.</p> <p>&nbsp;</p> <p>Test scores showed that life science items including key words for sequential events were easier for students. However, adding an intention or cause in the context description did not significantly change the item difficulty; in other words, student scores did not differ between the experimental version (V1) and the control version (V2) of these items. Further, all contextualized science items developed in this study were easier for non-ELLs than ELLs. Last, items presented with higher linguistic demands tended to be harder for all students.</p> <p>&nbsp;</p> <p>Most interviewed students thought the added information &ndash; key words, explaining the intention of an investigation, or explaining the cause of a phenomenon &ndash; &nbsp;in the experimental version (V1) would make the item easier than in the control version (V2), although student test scores supported only the perception about key words. Interviewed students thought V1 was easier than V2 overall. One explanation for this was revealed in data from the eye tracking study, which showed students spent, on average, 10% longer reading the item contexts in V1 than V2, suggesting students spent additional time attending to the manipulated part. We speculate that students spent those additional seconds engaging with high-level cognitive activities (e.g., making sense of the sequence manipulations, connecting science ideas, and making judgments) to better answer the question. In addition, eye tracking data led us to conclusions that would not have been apparent from either student test scores or cognitive interviews alone. For example, students tended to fixate on the additional scientific words in V1. This tendency may partially explain why students not only did better overall on such questions, but also reported in cognitive interviews that V1 was easier: the added sentence that included key scientific words to help explain the intention of an investigation or the cause of a phenomenon may have aided student comprehension. In addition, front loading the scientific words in a context may have helped students identify relevant factors in item contexts, potentially facilitating their thinking process.</p> <p>&nbsp;</p> <p>Findings from this project have important implications for practitioners and item writers. For instance, when presenting an investigation to students, teachers could introduce the steps by specifying the order, stating the intention of the investigation, and re-emphasizing the theory involved in the investigation. When writing assessment items for life science topics, item writers could consider presenting the event in an explicit sequence order to help student better understand the sequence of contextual information. Item writers could also consider increasing or decreasing the linguistic demands in item contexts to vary item difficulty for different subgroups.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/23/2017<br>      Modified by: Min&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Project Outcomes     This project investigates different sequence patterns provided in science item contexts. Real-world contexts have been the subject of considerable measurement research. However, the utility and realism of contexts used in items have been called into question. For example, the item?s context may lead to differential understandings of what the item is intended to ask and different levels of difficulty for students to represent and solve the problem. We chose to focus on one characteristic presented in science item contexts: the sequence of contextual information. We asked three research questions: (1) How is student performance associated with different dimensions of the sequence of context presented in contextualized science test items? (2) Controlling for levels of linguistic demands in item contexts, how is sequence of context linked to English language learners' (ELLs') and non-ELLs' science performance? (3) How do different dimensions of sequence of context impact students? understanding of and response to tasks?     We hypothesized that specific sequences of information presented should allow students to make sense of and follow the logic of the item context rather than distracting them from scientific thinking. We defined the sequence of contextual information as the order of events or descriptions involved in contextualized items and conceptualize it into three dimensions: sequence of events (D1), sequence of intention and action (D2), and sequence of cause and effect (D3). We applied this theoretical framework to item selection and development so that the item sequences could be systematically varied for experimental purposes. Then, we conducted an experiment in which students in Grades 7-12 were randomly assigned to selected items. We selected 18 of these students to participate in cognitive interviews based on their performance on the field test items. We recruited an additional 12 students for an eye tracking study to test time spent on each question. We performed both qualitative and quantitative analyses with test scores, students? cognitive interviews, and eye tracking data to study whether and how the sequence of contextual information impacts student performance. We also incorporated the linguistic demands of contexts in our item development and data analysis to understand whether and how linguistic demands of contexts mediate the relationship between sequence patterns and ELL and non-ELL student performance on items.     Test scores showed that life science items including key words for sequential events were easier for students. However, adding an intention or cause in the context description did not significantly change the item difficulty; in other words, student scores did not differ between the experimental version (V1) and the control version (V2) of these items. Further, all contextualized science items developed in this study were easier for non-ELLs than ELLs. Last, items presented with higher linguistic demands tended to be harder for all students.     Most interviewed students thought the added information &ndash; key words, explaining the intention of an investigation, or explaining the cause of a phenomenon &ndash;  in the experimental version (V1) would make the item easier than in the control version (V2), although student test scores supported only the perception about key words. Interviewed students thought V1 was easier than V2 overall. One explanation for this was revealed in data from the eye tracking study, which showed students spent, on average, 10% longer reading the item contexts in V1 than V2, suggesting students spent additional time attending to the manipulated part. We speculate that students spent those additional seconds engaging with high-level cognitive activities (e.g., making sense of the sequence manipulations, connecting science ideas, and making judgments) to better answer the question. In addition, eye tracking data led us to conclusions that would not have been apparent from either student test scores or cognitive interviews alone. For example, students tended to fixate on the additional scientific words in V1. This tendency may partially explain why students not only did better overall on such questions, but also reported in cognitive interviews that V1 was easier: the added sentence that included key scientific words to help explain the intention of an investigation or the cause of a phenomenon may have aided student comprehension. In addition, front loading the scientific words in a context may have helped students identify relevant factors in item contexts, potentially facilitating their thinking process.     Findings from this project have important implications for practitioners and item writers. For instance, when presenting an investigation to students, teachers could introduce the steps by specifying the order, stating the intention of the investigation, and re-emphasizing the theory involved in the investigation. When writing assessment items for life science topics, item writers could consider presenting the event in an explicit sequence order to help student better understand the sequence of contextual information. Item writers could also consider increasing or decreasing the linguistic demands in item contexts to vary item difficulty for different subgroups.          Last Modified: 10/23/2017       Submitted by: Min Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
