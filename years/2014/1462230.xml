<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER-DynamicData: Generative Statistical Modeling for Dynamic and Distributed Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>akbar sayeed</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project will develop a novel paradigm of generative modeling for decentralized data. In the big data era, the enormous volume, and high variety and velocity of data raise new technical challenges. What can be substantially strengthened is in the area of statistical learning under the limitations imposed by distributed data collections, communication networks, and decentralized computing platforms. As an example, the size of the data can be so large in many engineering applications that a single computer cannot handle. Typical learning methods, however, expect training data to be static and can be handled by one computer. The generative modeling framework has been shown to be effective in incorporating prior knowledge and capturing statistical dependence among data residing on structured domains, e.g., time sequences for signals and spatial grids for images. These advantages suit well with data arising from natural phenomena and the needs of engineering systems. The project addresses constraints in storage and communication capacity, as well as the speed requirement of real-time analysis by advancing multi-scale statistical modeling consisting of a layer of data-level learning and a layer of model-level learning. Two doctoral students will be supported to conduct research at the interface of engineering and statistics. They will develop core methodologies, as well as practical algorithms and tools useful in a wide range of engineering disciplines.&lt;br/&gt;&lt;br/&gt;The goal of this project is to propose new approaches in statistical learning for distributed and dynamic data subject to constraints of communication networks and the decentralized architecture of computing platforms. In particular, multi-scale statistical modeling for learning from distributed and dynamic data will be advanced. At the data-level, modeling is performed at decentralized computing sites. These models serve as a highly compact description of the data, retaining key information for learning. To consolidate the models acquired at distributed sites, only the models are communicated to a primary computer node. At the primary node, learning is performed directly on the models without regenerating data.  An integrated investigation will be conducted on trade-offs between data and various computing resources such as CPU and storage. This project is transformative because of the fundamental nature of the problems, the unusual formulation of problems, and the interdisciplinary approaches. The usual paradigm of learning directly from data is transformed to multi-scale learning where statistical models become learning objects themselves.  A suite of tools integrating methodologies in statistics and engineering will be developed and made available.</AbstractNarration>
<MinAmdLetterDate>09/01/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/01/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1462230</AwardID>
<Investigator>
<FirstName>Jia</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>Jia Li</PI_FULL_NAME>
<EmailAddress>jiali@psu.edu</EmailAddress>
<PI_PHON>8148633074</PI_PHON>
<NSF_ID>000486811</NSF_ID>
<StartDate>09/01/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramElement>
<Code>O395</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>153E</Code>
<Text>Wireless comm &amp; sig processing</Text>
</ProgramReference>
<ProgramReference>
<Code>5384</Code>
<Text>DATA AND DATA SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><h3><span style="color: #000000; font-weight: normal;">The goal of this project is to develop a new paradigm in statistical learning for distributed and dynamic&nbsp;</span><span style="color: #000000; font-weight: normal;">data subject to constraints of communication networks and the decentralized architecture of computing&nbsp;</span><span style="color: #000000; font-weight: normal;">platforms.&nbsp;</span><span style="color: #000000; font-weight: normal;">Specifically, we propose multiscale generative statistical modeling consisted of a layer of data-level&nbsp;</span><span style="color: #000000; font-weight: normal;">learning and a layer of model-level learning. At the data-level, modeling is performed at decentralized&nbsp;</span><span style="color: #000000; font-weight: normal;">computing sites. These models serve as a highly compact description of the data, retaining key information&nbsp;for learning. To consolidate the models acquired at distributed sites, we communicate only the models to&nbsp;a master computer. At the master site, learning is performed directly on the models without regenerating&nbsp;data, although this can be done if allowed by the computing resources. At this level of analysis, stochastic models become the learning objects, posing a range of unique technical challenges. We have explored three popular stochastic models: discrete distributions with dynamic support, Gaussian mixture model, and Hidden Markov model. We used the Wasserstein metric and optimal transport to set up optimization objectives and developed new algorithms to solve the problems. In the mean time, we have also addressed the baseline technical challenge of clustering very high dimensional data. Applications to biomedical data analysis and meteorology have been pursued.</span></h3> <p><strong>Intellectual Merits:</strong></p> <p>We have developed fundamental methods for comparing and learning from entities represented by statistical models. Given the popularity of discrete distributions, hidden Markov models, and Gaussian mixture models in signal processing as well as machine learning, we expect the work to have impact on many supervised and unsupervised learning problems for physical signals such as images and speech.</p> <p>Clustering of high-dimensional data remains a challenge for machine learning and data mining. We have developed fundamental methods based on HMM-VB and mode association to tackle this difficulty problem.&nbsp;<span>The clustering method based on HMM-VB is likely to become a useful tool for single-cell data analysis, which is an emerging area in biomedical reesearch with various applications including vaccine development.&nbsp;</span></p> <p>We have explored applications to meteorology. The GEM toolkit we developed for summarizing and visualizing large collections of ensemble images produced by different weather models has the potential to help meteorologists make better decisions when forecasting extreme weather conditions. Better forecasting of weather conditions such as hurricane has enormous impact on economy as well as safety of people.<strong><br /></strong></p> <p><strong>Broader Impact:</strong></p> <p><span>This project supported 5 graduate students including one female student to conduct interdisciplinary research on statistical/machine learning, computational linguistics, and satellite image analysis. In addition, this project provided opportunity for the PI to collaborate with her colleagues on single-cell data analysis, an important area in bioinformatics, and meteorology.</span></p> <p><span><span>We have developed software packages that have been deposited at GitHub site or as R CRAN packages. These fundamental tools for clustering high dimensional and complex data can be useful for wide range of scientific domains. We have in particular explored biomedical research and meteorology ourselves, but expect the applicability to be much broader.</span><br /></span></p> <h3><strong style="color: #000000;">Published Journal or Refereed Conference papers:</strong></h3> <ol> <li class="bottomSpacing"> <p class="indentedCitation">Jia Li and Fuqing Zhang&nbsp;(2018).&nbsp;Geometry-sensitive ensemble mean based on Wasserstein barycenters: proof-of-concept on cloud simulations.&nbsp;&nbsp;<em>Journal of Computational and Graphical Statistics</em>. &nbsp;&nbsp;</p> </li> <li class="bottomSpacing"> <p class="indentedCitation">Jia Li and Lin Lin&nbsp;(2017).&nbsp;Baum-Welch algorithm on directed acyclic graph for mixtures with latent Bayesian networks.&nbsp;&nbsp;<em>Stat</em>.&nbsp;6&nbsp;(1), &nbsp;303.&nbsp;</p> </li> <li class="bottomSpacing"> <p class="indentedCitation">Jianbo Ye, James Z. Wang, Jia Li&nbsp;(2017).&nbsp;A Simulated Annealing Based Inexact Oracle for Wasserstein Loss Minimization.&nbsp;&nbsp;<em>Proc. International Conference on Machine Learning</em>. &nbsp;</p> </li> <li class="bottomSpacing"> <p class="indentedCitation">Jianbo Ye, Yanran Li, Zhaohui Wu, James Z. Wang, Wenjie Li, Jia Li&nbsp;(2017).&nbsp;Determining gains acquired from word embedding quantitatively using discrete distribution clustering.&nbsp;&nbsp;<em>Proc. Annual Meeting of the Association for Computational Linguistics (ACL)</em>.&nbsp; &nbsp;.</p> </li> <li>Lin Lin and Jia Li&nbsp;(2017).&nbsp;Clustering with Hidden Markov Models on Variable Blocks and Theoretical Generalization to Mixtures with Latent Bayesian Networks.&nbsp;&nbsp;<em>Journal of Machine Learning Research</em>.</li> <li>Yukun Chen, Jianbo Ye, Jia Li&nbsp;(2016).&nbsp;A distance for HMMs based on aggregated Wasserstein metric and state registration.&nbsp;&nbsp;<em>Proc. European Conf. on Computer Vision (ECCV)</em>. &nbsp;&nbsp;</li> </ol> <ul> <li class="bottomSpacing"> <p class="indentedCitation">&nbsp;</p> </li> </ul> <p class="indentedCitation"><strong>Software Packages:</strong></p> <p>An R CRAN software package for clustering very high dimensional data based on HMM-VB. The core is written in C. R serves as the wrapper.&nbsp;</p> <p>The package HDclust was released on CRAN:<br /><a rel="nofollow" href="https://cran.r-project.org/web/packages/HDclust/index.html" target="_blank">https://cran.r-project.org/web/packages/HDclust/index.html</a></p> <p class="indentedCitation"><strong><br /></strong></p><br> <p>            Last Modified: 09/17/2018<br>      Modified by: Jia&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The goal of this project is to develop a new paradigm in statistical learning for distributed and dynamic data subject to constraints of communication networks and the decentralized architecture of computing platforms. Specifically, we propose multiscale generative statistical modeling consisted of a layer of data-level learning and a layer of model-level learning. At the data-level, modeling is performed at decentralized computing sites. These models serve as a highly compact description of the data, retaining key information for learning. To consolidate the models acquired at distributed sites, we communicate only the models to a master computer. At the master site, learning is performed directly on the models without regenerating data, although this can be done if allowed by the computing resources. At this level of analysis, stochastic models become the learning objects, posing a range of unique technical challenges. We have explored three popular stochastic models: discrete distributions with dynamic support, Gaussian mixture model, and Hidden Markov model. We used the Wasserstein metric and optimal transport to set up optimization objectives and developed new algorithms to solve the problems. In the mean time, we have also addressed the baseline technical challenge of clustering very high dimensional data. Applications to biomedical data analysis and meteorology have been pursued.  Intellectual Merits:  We have developed fundamental methods for comparing and learning from entities represented by statistical models. Given the popularity of discrete distributions, hidden Markov models, and Gaussian mixture models in signal processing as well as machine learning, we expect the work to have impact on many supervised and unsupervised learning problems for physical signals such as images and speech.  Clustering of high-dimensional data remains a challenge for machine learning and data mining. We have developed fundamental methods based on HMM-VB and mode association to tackle this difficulty problem. The clustering method based on HMM-VB is likely to become a useful tool for single-cell data analysis, which is an emerging area in biomedical reesearch with various applications including vaccine development.   We have explored applications to meteorology. The GEM toolkit we developed for summarizing and visualizing large collections of ensemble images produced by different weather models has the potential to help meteorologists make better decisions when forecasting extreme weather conditions. Better forecasting of weather conditions such as hurricane has enormous impact on economy as well as safety of people.   Broader Impact:  This project supported 5 graduate students including one female student to conduct interdisciplinary research on statistical/machine learning, computational linguistics, and satellite image analysis. In addition, this project provided opportunity for the PI to collaborate with her colleagues on single-cell data analysis, an important area in bioinformatics, and meteorology.  We have developed software packages that have been deposited at GitHub site or as R CRAN packages. These fundamental tools for clustering high dimensional and complex data can be useful for wide range of scientific domains. We have in particular explored biomedical research and meteorology ourselves, but expect the applicability to be much broader.  Published Journal or Refereed Conference papers:   Jia Li and Fuqing Zhang (2018). Geometry-sensitive ensemble mean based on Wasserstein barycenters: proof-of-concept on cloud simulations.  Journal of Computational and Graphical Statistics.      Jia Li and Lin Lin (2017). Baum-Welch algorithm on directed acyclic graph for mixtures with latent Bayesian networks.  Stat. 6 (1),  303.    Jianbo Ye, James Z. Wang, Jia Li (2017). A Simulated Annealing Based Inexact Oracle for Wasserstein Loss Minimization.  Proc. International Conference on Machine Learning.     Jianbo Ye, Yanran Li, Zhaohui Wu, James Z. Wang, Wenjie Li, Jia Li (2017). Determining gains acquired from word embedding quantitatively using discrete distribution clustering.  Proc. Annual Meeting of the Association for Computational Linguistics (ACL).   .  Lin Lin and Jia Li (2017). Clustering with Hidden Markov Models on Variable Blocks and Theoretical Generalization to Mixtures with Latent Bayesian Networks.  Journal of Machine Learning Research. Yukun Chen, Jianbo Ye, Jia Li (2016). A distance for HMMs based on aggregated Wasserstein metric and state registration.  Proc. European Conf. on Computer Vision (ECCV).           Software Packages:  An R CRAN software package for clustering very high dimensional data based on HMM-VB. The core is written in C. R serves as the wrapper.   The package HDclust was released on CRAN: https://cran.r-project.org/web/packages/HDclust/index.html         Last Modified: 09/17/2018       Submitted by: Jia Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
