<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Collaborative Research: Efficient Codes and their Performance Limits for Distributed Storage Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>299504.00</AwardTotalIntnAmount>
<AwardAmount>299504</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The explosive growth of data being generated and collected has rekindled interest in efficient means of storing such data.  Large data centers and distributed storage systems have become more widespread, playing an ever-increasing role in our everyday computational tasks.  While a data center should never lose data, disk failures occur on a daily basis as confirmed by the industry statistics. Methods and ideas from error correcting codes developed in this project enable the system to provide better guarantees against data loss as well as to reduce the amount of data that needs to be moved in order to enable recovery of information lost due to disk failures. Another related goal of this project is the reduction of storage overhead needed to support the recovery procedures. These goals are accomplished by relying on algebraic methods of constructing the data encoding procedures as well as on novel algorithms of data exchange and recovery. Overall the research performed in the course of this project contributes to the development of more efficient data management procedures in large-scale distributed storage systems.&lt;br/&gt;&lt;br/&gt;This project puts forward new algebraic procedures for data encoding and recovery that enables one to achieve tradeoff between overhead and repair bandwidth based on the concept of local recovery.  The project studies both the case of recovering from a single disk loss, which is the most frequent problem in systems, as well as from the failure of multiple disks, addressing the problem of correcting one erasure as well as multiple erasures in data encoding. New bounds on the distance of codes with the locality requirement derived in this research are attained with new constructions of optimal locally recoverable codes equipped with simple recovery procedures. The project also addresses the problem of simultaneous recovery of data from multiple locations, enhancing data availability in large-scale distributed storage systems which are a key backbone component of the 21st century economy.</AbstractNarration>
<MinAmdLetterDate>07/22/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422955</AwardID>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Barg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexander Barg</PI_FULL_NAME>
<EmailAddress>abarg@umd.edu</EmailAddress>
<PI_PHON>3014057135</PI_PHON>
<NSF_ID>000193827</NSF_ID>
<StartDate>07/22/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~299504</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Providers of large-scale shared platforms (Facebook, Instagram),  Indexing services/internet portals (Google, Yahoo), as well as cloud  storage and computing vendors (Amazon, Dropbox) rely on systems of  distributed storage to save and maintain large volumes of data involved  in their operation. Data centers used by these systems are formed of  thousands of storage nodes, and node failures occur on a daily basis and  have to be accounted for as a part of the normal system operation. To  recover the data stored on the failed nodes, most operators rely on data  replication or on the application of codes that correct lost (erased)  portions of the data. Both these solutions are not well suited for the  rapidly inreasing data volumes because they either require excessive  storage use, or involve large communication cost of data recovery.</p> <p>The goal of the project was to develop alternative solutions for erasure coding in distributed storage that have low complexity of recovery and utilize little overhead storage, while at the same time providing guarantees against data loss in the system. The efficiency of data recovery can be measured either by the number of storage nodes in the encoding block that need to be contacted to recover the failed node (<em>codes with locality constraints</em>) or by the total number of symbols communicated in the system before the recovery can be completed (such coding methods are known as codes with limited repair bandwidth, or <em>regenerating codes</em>). <br /><br />The project examined both codes with locality and regenerating codes, studying theoretical limits and efficient constructions of such codes.</p> <ol> <li>For codes with locality, this research established theoretical bounds on their parameters such as the number of different messages that can be encoded into blocks of a given length, and the maximum number of lost nodes that can be tolerated (similar bounds for regenerating codes were known from previous research). Advanced algebraic methods were used to design families of codes of both types that attain these theroretical limits. </li> <li>The project resulted in new families of algebraic codes with locality with flexible message rate and length of the encoding, covering a large range of possible parameters. The methods used to construct the codes rely on the theory of cyclic codes and on properties of algebraic curves.</li> <li>The project also resulted in families of regenerating codes that attain the theoretical bounds on the amount of communication needed for repair, which gave efficient and to a large extent complete solution of the construction problem for these codes. The constructed codes were implemented on Amazon cloud storage and compared to the existing solutions in industry, showing performance gains across several characteristics of the storage system. The code construction and the results of performance implementation were presented at a conference widely attended by system developers from all major companies designing distributed storage solutions (USENIX FAST 2018).</li> </ol><br> <p>            Last Modified: 12/08/2018<br>      Modified by: Alexander&nbsp;Barg</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Providers of large-scale shared platforms (Facebook, Instagram),  Indexing services/internet portals (Google, Yahoo), as well as cloud  storage and computing vendors (Amazon, Dropbox) rely on systems of  distributed storage to save and maintain large volumes of data involved  in their operation. Data centers used by these systems are formed of  thousands of storage nodes, and node failures occur on a daily basis and  have to be accounted for as a part of the normal system operation. To  recover the data stored on the failed nodes, most operators rely on data  replication or on the application of codes that correct lost (erased)  portions of the data. Both these solutions are not well suited for the  rapidly inreasing data volumes because they either require excessive  storage use, or involve large communication cost of data recovery.  The goal of the project was to develop alternative solutions for erasure coding in distributed storage that have low complexity of recovery and utilize little overhead storage, while at the same time providing guarantees against data loss in the system. The efficiency of data recovery can be measured either by the number of storage nodes in the encoding block that need to be contacted to recover the failed node (codes with locality constraints) or by the total number of symbols communicated in the system before the recovery can be completed (such coding methods are known as codes with limited repair bandwidth, or regenerating codes).   The project examined both codes with locality and regenerating codes, studying theoretical limits and efficient constructions of such codes.  For codes with locality, this research established theoretical bounds on their parameters such as the number of different messages that can be encoded into blocks of a given length, and the maximum number of lost nodes that can be tolerated (similar bounds for regenerating codes were known from previous research). Advanced algebraic methods were used to design families of codes of both types that attain these theroretical limits.  The project resulted in new families of algebraic codes with locality with flexible message rate and length of the encoding, covering a large range of possible parameters. The methods used to construct the codes rely on the theory of cyclic codes and on properties of algebraic curves. The project also resulted in families of regenerating codes that attain the theoretical bounds on the amount of communication needed for repair, which gave efficient and to a large extent complete solution of the construction problem for these codes. The constructed codes were implemented on Amazon cloud storage and compared to the existing solutions in industry, showing performance gains across several characteristics of the storage system. The code construction and the results of performance implementation were presented at a conference widely attended by system developers from all major companies designing distributed storage solutions (USENIX FAST 2018).        Last Modified: 12/08/2018       Submitted by: Alexander Barg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
