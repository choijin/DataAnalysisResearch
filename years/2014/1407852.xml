<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Modeling Complex Functional Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>337658.00</AwardTotalIntnAmount>
<AwardAmount>337658</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>There is increasing need for adequate statistical analysis methods for samples of time-dynamic and longitudinal data that include high-dimensional and other complex objects that are recorded over time. Such data arise in many areas of critical concern where adequate methodology to quantify changes of complex patterns over time is relevant to come to the right conclusions. This includes studies of environmental and climate change and the evolution of social networks over time. It also includes biological networks that are thought to operate between "hubs" in the brain and that are changing as a person ages. Such data are objects with a structure that defies established linear modeling approaches that have been previously developed in the statistical field of functional data analysis. The investigator and his research group are therefore developing new methods aimed at the analysis of such complex time-dynamic and longitudinal data. These techniques will lead to a better understanding of the underlying dynamics and the changes in the inherent patterns and interactions of the objects over time. Better understanding of time-dynamic phenomena will lead to better informed societal and individual decision making. The research also involves the training of students in upfront methodology and the creation of suitable fast algorithms to implement these new methods. &lt;br/&gt;&lt;br/&gt;The established field of Functional Data Analysis has been focused on linear methods such as functional linear principal component analysis. However, the applicability of these established  models for "next generation" functional data is quite limited. This is because such data are inherently nonlinear, i.e., they do not live in a linear space, and therefore are far more complex than linear data. Second generation functional data are generated across the sciences and e-commerce and by online and physical tracking devices that continuously record signals and trajectories, in on-line settings, monitoring and sensor systems. Important types of time-varying  "object data" are covariance matrices, densities or networks, and new methods will be developed to properly quantify the dynamics of such complex objects. Besides the non-Euclidean nature of these objects, additional challenges arise from the sparsity of available data in many longitudinal studies, due to missing data or irregular sampling schemes. This research addresses these issues and challenges and will lead to techniques to quantify the variability of complex dynamics by developing principled and theoretically supported methodology for the analysis of these more complex data types. This research will benefit the analysis and understanding of the time dynamics of social and biological networks, and of other time-indexed objects, as well as the analysis of high-dimensional functional data. The research includes novel methods for the classification of functional data, which is an increasingly important problem in itself. It also includes methodology for the analysis of short snippets of time-dynamic observations, due to the need to come to quick conclusions under limited observation time, which is a feature of many current longitudinal studies in biomedical fields.</AbstractNarration>
<MinAmdLetterDate>06/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/20/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1407852</AwardID>
<Investigator>
<FirstName>Hans-Georg</FirstName>
<LastName>Mueller</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hans-Georg Mueller</PI_FULL_NAME>
<EmailAddress>hgmueller@ucdavis.edu</EmailAddress>
<PI_PHON>5302191453</PI_PHON>
<NSF_ID>000448854</NSF_ID>
<StartDate>06/20/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Davis</Name>
<CityName>Davis</CityName>
<ZipCode>956186134</ZipCode>
<PhoneNumber>5307547700</PhoneNumber>
<StreetAddress>OR/Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1850 Research Park Dr., Ste 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>047120084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, DAVIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Davis]]></Name>
<CityName>Davis</CityName>
<StateCode>CA</StateCode>
<ZipCode>956168633</ZipCode>
<StreetAddress><![CDATA[One Shields Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~337658</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>New flexible statistical methods were developed for longitudinal and repeatedly observed time-indexed data. Such data arise whenever one studies temporal phenomena such as brain function in dependency on age for many subjects or age-at-death distributions as they change over calendar years for many countries. The results from this research led to optimal designs that can be leveraged for more efficient deployment of longitudinal studies when these designs are used. Often one has only observations over a short period for individuals but is interested in&nbsp; longer term trends, for example in Alzheimer's patients. The snippet analysis that was developed in the course of this research makes it possible to predict future trajectories for individuals from such short-term observations, using an autonomous differential equation model, under the assumption of monotone trajectories. Increasingly, one observes data that consist of entire distributions such as the frequency of baby names over years or the distribution of connectivity between voxels within brain regions. A transformation method was developed for such data, which makes it possible to apply common linear functional data analysis techniques to such complex data. For situations where one encounters distributions that are time-indexed such as the distribution of annually reported incomes, a new regression method was developed, the so-called Frechet regression. This method is a generalization of the now classical Frechet (1948) mean, essentially by providing an extension to a conditional Frechet mean. It can be implemented in the form of a linear model or in a local linear version. This approach has been developed for general metric spaces where one only has a distance but no algrbaric structure. It has promising mathematical and practical properties under mild assumptions on the underlying space and the random objects one considers. A major application is the case of distributions under the Wasserstein or earth mover's metric. Frechet regression has also proved to be useful for random objects that consist of time-indexed covariance matrices or time-varying networks. A related notion that resulted from this research and proved to be very useful for brain imaging and also as a theoretical tool is the novel notion of a Frechet integral.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/17/2018<br>      Modified by: Hans-Georg&nbsp;Mueller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ New flexible statistical methods were developed for longitudinal and repeatedly observed time-indexed data. Such data arise whenever one studies temporal phenomena such as brain function in dependency on age for many subjects or age-at-death distributions as they change over calendar years for many countries. The results from this research led to optimal designs that can be leveraged for more efficient deployment of longitudinal studies when these designs are used. Often one has only observations over a short period for individuals but is interested in  longer term trends, for example in Alzheimer's patients. The snippet analysis that was developed in the course of this research makes it possible to predict future trajectories for individuals from such short-term observations, using an autonomous differential equation model, under the assumption of monotone trajectories. Increasingly, one observes data that consist of entire distributions such as the frequency of baby names over years or the distribution of connectivity between voxels within brain regions. A transformation method was developed for such data, which makes it possible to apply common linear functional data analysis techniques to such complex data. For situations where one encounters distributions that are time-indexed such as the distribution of annually reported incomes, a new regression method was developed, the so-called Frechet regression. This method is a generalization of the now classical Frechet (1948) mean, essentially by providing an extension to a conditional Frechet mean. It can be implemented in the form of a linear model or in a local linear version. This approach has been developed for general metric spaces where one only has a distance but no algrbaric structure. It has promising mathematical and practical properties under mild assumptions on the underlying space and the random objects one considers. A major application is the case of distributions under the Wasserstein or earth mover's metric. Frechet regression has also proved to be useful for random objects that consist of time-indexed covariance matrices or time-varying networks. A related notion that resulted from this research and proved to be very useful for brain imaging and also as a theoretical tool is the novel notion of a Frechet integral.                   Last Modified: 08/17/2018       Submitted by: Hans-Georg Mueller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
