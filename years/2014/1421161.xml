<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF:Small:Scheduling and Routing: Algorithms with novel cost measures</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>417277.00</AwardTotalIntnAmount>
<AwardAmount>417277</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computers, computer systems and the computational infrastructure provided by the internet are now essential for many aspects of modern life.  It is well-known and well-documented that, even as computing power and network bandwidth increase at a rapid rate, users and applications increase their demand for computation and their use of networks at roughly the same pace.  Thus, no matter how much progress is made on the hardware and network ends, efficient algorithms to manage these resources are essential. These efficient algorithms will lead to tremendous savings in both time and money and will have a positive environmental impact. They will also contribute to the decisions that are being made presently about the next generation of the internet, in particular in the design of routing protocols and the management of data centers.&lt;br/&gt;&lt;br/&gt;It is now well-understood that time and space are not the only resources that need to be carefully managed.  For the past few decades, there has been a growing emphasis on other concerns such as accuracy of solution, availability of information, use of cache, management of disk, etc.  More recently, there has been a growing understanding that energy and power management are also resources that should be carefully managed.  In this project, the PI will study several algorithmic problems that arise in applications such as computer systems and networks.  For each of these, the PI will focus on algorithms for better managing the technologies, and that have objectives that go beyond time or solution quality.  In particular, the project will study energy consumption in both computers and networks, and we will also consider environments in which other resources must be managed, such as minimizing the number of changes to a solution over time. The problem areas studied include power management in routing, power management in scheduling, extending speed scaling to other domains, and online problems with a reassignment cost. The PI will design efficient solutions to important practical problems, and the research will have broader impact.</AbstractNarration>
<MinAmdLetterDate>08/14/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/14/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421161</AwardID>
<Investigator>
<FirstName>Clifford</FirstName>
<LastName>Stein</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Clifford S Stein</PI_FULL_NAME>
<EmailAddress>cliff@ieor.columbia.edu</EmailAddress>
<PI_PHON>2128545238</PI_PHON>
<NSF_ID>000193678</NSF_ID>
<StartDate>08/14/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100276902</ZipCode>
<StreetAddress><![CDATA[2960 Broadway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~417277</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project addressed several problems in scheduling, routing and related problems.&nbsp; The goal was to move beyond traditional measures of evaluating an algorithm by worst case performance on .a static input on one computer.&nbsp; We made progress on several fronts.&nbsp;&nbsp;</p> <p>&nbsp;</p> <p>One basic problem we studied is understanding how many machines are necessary in order to process a given amount of computation.&nbsp; Consider work that arrives over time, and each task has a deadline.&nbsp; One can ask how many machines are needed to complete all the tasks, or similarly, how many human workers would be needed to complete the tasks.&nbsp; The problem is complicated by not knowing the future -- one needs to provision enough machines or enough workers without knowing exactly when the work is coming.&nbsp; We show how to give significantly better estimates on the number of machines needed for such tasks.</p> <p>&nbsp;</p> <p>A second problem is to understand how to maintain networks as they evolve over time.&nbsp; If one considers a network, be it a network of devices, or a network of people (with connections representing human connections), it is common that this network evolves over time.&nbsp; As the network evolves, one must update information about the network.&nbsp; One basic problem is to maintain a matching, which is a pairing of related nodes.&nbsp; We show how to update a matching significantly faster than was previously known.</p> <p>&nbsp;</p> <p>We also consider computing matchings in extremely large graphs.&nbsp; When you have such a massive graph, you cannot store it on one machine, but rather, have to distribute the graph on multiple computers.&nbsp; Computation becomes much trickiers, as one has to coordinate the work of different computers and communicate betwen them.&nbsp; We give algorithms that use significantly less communication than previous ones.</p> <p>&nbsp;</p> <p>We also consider scheduling problems where communication occurs via posted prices.&nbsp; An example of such a mechanism are parking systems where the price varies over time, and is sensitive to congestion and demand.&nbsp; In our context,&nbsp; machines post jobs and jobs go to machines, making their decisions based on prices, and without a central coordination mechanism. &nbsp;We showed that having such an algorithm is actually equivalent to having an online algorithm that is immediate dispatch, that is, when a job arrives, it immediately assigns it to a machine.&nbsp; &nbsp;Using this equivalnce, we are able to schedule our systems more efficiently.&nbsp;</p><br> <p>            Last Modified: 12/06/2018<br>      Modified by: Clifford&nbsp;S&nbsp;Stein</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project addressed several problems in scheduling, routing and related problems.  The goal was to move beyond traditional measures of evaluating an algorithm by worst case performance on .a static input on one computer.  We made progress on several fronts.       One basic problem we studied is understanding how many machines are necessary in order to process a given amount of computation.  Consider work that arrives over time, and each task has a deadline.  One can ask how many machines are needed to complete all the tasks, or similarly, how many human workers would be needed to complete the tasks.  The problem is complicated by not knowing the future -- one needs to provision enough machines or enough workers without knowing exactly when the work is coming.  We show how to give significantly better estimates on the number of machines needed for such tasks.     A second problem is to understand how to maintain networks as they evolve over time.  If one considers a network, be it a network of devices, or a network of people (with connections representing human connections), it is common that this network evolves over time.  As the network evolves, one must update information about the network.  One basic problem is to maintain a matching, which is a pairing of related nodes.  We show how to update a matching significantly faster than was previously known.     We also consider computing matchings in extremely large graphs.  When you have such a massive graph, you cannot store it on one machine, but rather, have to distribute the graph on multiple computers.  Computation becomes much trickiers, as one has to coordinate the work of different computers and communicate betwen them.  We give algorithms that use significantly less communication than previous ones.     We also consider scheduling problems where communication occurs via posted prices.  An example of such a mechanism are parking systems where the price varies over time, and is sensitive to congestion and demand.  In our context,  machines post jobs and jobs go to machines, making their decisions based on prices, and without a central coordination mechanism.  We showed that having such an algorithm is actually equivalent to having an online algorithm that is immediate dispatch, that is, when a job arrives, it immediately assigns it to a machine.   Using this equivalnce, we are able to schedule our systems more efficiently.        Last Modified: 12/06/2018       Submitted by: Clifford S Stein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
