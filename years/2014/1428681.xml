<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI: Acquisition of a High-Resolution Stereoscopic Interactive Visualization System for Research and Education in Science, Engineering and the Humanities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>399720.00</AwardTotalIntnAmount>
<AwardAmount>399720</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Yellen</SignBlockName>
<PO_EMAI>jyellen@nsf.gov</PO_EMAI>
<PO_PHON>7032928759</PO_PHON>
</ProgramOfficer>
<AbstractNarration>High-resolution immersive interactive visualization systems allow users to explore and understand data from a first person perspective using natural techniques. Immersive visualization improves spatial understanding, enables training in safe yet realistic environments and allows the understanding of and interaction with data in an intuitive way. Particularly, researchers and students in engineering, science and the humanities can benefit from high-definition immersive visualization systems because many times the nature of the data in those disciplines is spatial and highly detailed. Within this context, this Major Research Instrumentation award allows Duke University to build the High-fidelity Duke immersive Virtual Environment (HiDiVE). Built on the success of the Duke immersive Virtual Environment (DiVE) over the past decade, the HiDiVE will consist of a six-sided room in the form of a cube, with two projectors for each surface, in a total resolution of 22.1 million pixels. This level of detail is roughly four times what the current DiVE system has and will allow for analysis of high-resolution data. Motion trackers will enable users to interact with data in the HiDiVE using natural and intuitive motions. This next generation system opens the possibility for research and education projects using high-definition data and computer graphics.&lt;br/&gt;&lt;br/&gt;Dr. Regis Kopper, along with co-investigators Dr. Kevin LaBar and Dr. Silvia Ferrari, six senior personnel and five users will initially use the HiDiVE in projects spanning several areas of knowledge, including cognitive neuroscience, intelligent systems and control, digital archeology and human-factors engineering. Specifically, the HiDiVE will support studies to understand human fear recovery and response to stress triggers. The HiDiVE will also be used for human-robot interaction experiments, particularly in the understanding of human-decision making to design robots that mimic human behavior and to validate robotic path planning. Another use of the HiDiVE will be in digital archeology, where users will be able to experience virtual dig sites, explore artifacts, stratigraphy, and conceptual reconstructions of pre-historic sites. In human-factors engineering, the HiDiVE will be a platform for studying the motions of humans doing repetitive work and how visual complexity may impact human mental workload. Apart from being a research facility, the HiDiVE will support educational and outreach activities. Students will use the system as a development platform for computer science and human-computer interaction courses. The HiDiVE will partner with the NSF IGERT on Wireless Intelligent Sensor Networks (WISeNet)to recruitand support minority students to engage in research activities and will be an inclusive environment with reach beyond the boundaries of the university, allowing visitors from schools and underrepresented groups to experience an advanced immersive virtual reality system.</AbstractNarration>
<MinAmdLetterDate>07/31/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1428681</AwardID>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>LaBar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin LaBar</PI_FULL_NAME>
<EmailAddress>klabar@duke.edu</EmailAddress>
<PI_PHON>9196810664</PI_PHON>
<NSF_ID>000206365</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Silvia</FirstName>
<LastName>Ferrari</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Silvia Ferrari</PI_FULL_NAME>
<EmailAddress>ferrari@cornell.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000484512</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Regis</FirstName>
<LastName>Kopper</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Regis A Kopper</PI_FULL_NAME>
<EmailAddress>kopper@uncg.edu</EmailAddress>
<PI_PHON>3362561112</PI_PHON>
<NSF_ID>000611558</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<StateCode>NC</StateCode>
<ZipCode>277080271</ZipCode>
<StreetAddress><![CDATA[101 Science Dr. 1617A CIEMAS Bld]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1189</Code>
<Text>Major Research Instrumentation</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~399720</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>With the support of an NSF Major Research Instrumentation award, Duke University has built the&nbsp;High-fidelity Duke immersive Virtual Environment (HiDiVE). Built on the success of the Duke immersive Virtual Environment (DiVE) over the past decade, the HiDiVE consists of a six-sided room in the form of a cube, with two projectors for each surface, in a total resolution of 22.1 million pixels and advanced realtime graphics capability. This level of detail is roughly four times what the previous DiVE system had and allows the analysis of high-resolution data. Motion trackers enables users to interact with data in the HiDiVE using natural and intuitive motions. This next generation system has opened the possibility for research and education projects using high-definition data and computer graphics.</p> <p>Since its launch in the spring of 2015, the HiDiVE has allowed the execution of several research projects, including a tangible interaction technique that allows users to interact with a physical object that contains a virtual object in it, studies to understand the effect of different video display techniques on selection&nbsp; performance of static and moving targets, and an experiment on the mechanics of motor learning of aimed actions. The HiDiVE has also supported interdisciplinary research, with projects coming from disciplines such as archeology, art history and visualization. One example is Dig@IT, a cyberarcheology project where users can experience the excavation of real archeological sites that have been scanned and translated into 3D models and are presented in the HiDiVE. Users are able to virtually "dig" a representation of the real site<span>, explore artifacts, stratigraphy, and conceptual reconstructions of pre-historic sites.</span></p> <p>Apart from being a research facility, the HiDiVE supports educational and outreach activities. Students have been using the system as a development platform for computer science, human-computer interaction and humanities courses. The HiDiVE has partnered with the NSF IGERT on Wireless Intelligent Sensor Networks (WISeNet) to recruit and support minority students and engage in research activities. It functions as an inclusive environment with reach beyond the boundaries of the university, allowing visitors from schools and underrepresented groups to experience this advanced immersive virtual reality system.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/02/2016<br>      Modified by: Regis&nbsp;A&nbsp;Kopper</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1428681/1428681_10327004_1478094036319_HiDiVE--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1428681/1428681_10327004_1478094036319_HiDiVE--rgov-800width.jpg" title="3D rendering of the HiDiVE"><img src="/por/images/Reports/POR/2016/1428681/1428681_10327004_1478094036319_HiDiVE--rgov-66x44.jpg" alt="3D rendering of the HiDiVE"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image shows the schematic representation of the HiDiVE. Not seen are the floor projectors, which are housed in the basements, aimed straight up.</div> <div class="imageCredit">Duke University</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Regis&nbsp;A&nbsp;Kopper</div> <div class="imageTitle">3D rendering of the HiDiVE</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With the support of an NSF Major Research Instrumentation award, Duke University has built the High-fidelity Duke immersive Virtual Environment (HiDiVE). Built on the success of the Duke immersive Virtual Environment (DiVE) over the past decade, the HiDiVE consists of a six-sided room in the form of a cube, with two projectors for each surface, in a total resolution of 22.1 million pixels and advanced realtime graphics capability. This level of detail is roughly four times what the previous DiVE system had and allows the analysis of high-resolution data. Motion trackers enables users to interact with data in the HiDiVE using natural and intuitive motions. This next generation system has opened the possibility for research and education projects using high-definition data and computer graphics.  Since its launch in the spring of 2015, the HiDiVE has allowed the execution of several research projects, including a tangible interaction technique that allows users to interact with a physical object that contains a virtual object in it, studies to understand the effect of different video display techniques on selection  performance of static and moving targets, and an experiment on the mechanics of motor learning of aimed actions. The HiDiVE has also supported interdisciplinary research, with projects coming from disciplines such as archeology, art history and visualization. One example is Dig@IT, a cyberarcheology project where users can experience the excavation of real archeological sites that have been scanned and translated into 3D models and are presented in the HiDiVE. Users are able to virtually "dig" a representation of the real site, explore artifacts, stratigraphy, and conceptual reconstructions of pre-historic sites.  Apart from being a research facility, the HiDiVE supports educational and outreach activities. Students have been using the system as a development platform for computer science, human-computer interaction and humanities courses. The HiDiVE has partnered with the NSF IGERT on Wireless Intelligent Sensor Networks (WISeNet) to recruit and support minority students and engage in research activities. It functions as an inclusive environment with reach beyond the boundaries of the university, allowing visitors from schools and underrepresented groups to experience this advanced immersive virtual reality system.                Last Modified: 11/02/2016       Submitted by: Regis A Kopper]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
