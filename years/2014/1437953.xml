<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Methods to Protect Privacy in State Longitudinal Data Systems Research Files</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>710614.00</AwardTotalIntnAmount>
<AwardAmount>710614</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11010000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DGE</Abbreviation>
<LongName>Division Of Graduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The expansion of federally funded state student longitudinal data systems (SLDS) provides a rich source of data that has great potential in STEM education research and evaluation. However, access to that data has been hampered by the requirements of the Family Education Rights and Privacy Act (FERPA). The researchers in this study will examine the ways in which two general approaches to statistical disclosure control will enable states to share data while still complying with the standards of FERPA. The researchers will use imputation and data masking of risk strata with the inclusion of cross tabulations of variables with data from five states that have agreed to authorize the use of their data. They will create protected datasets, study them to determine whether they protect against disclosure and carry out a number of analyses to determine whether they yield essentially the same answers as the corresponding analyses using the original data.&lt;br/&gt;&lt;br/&gt;Protecting against the loss of privacy is an essential component of the concerns about the ever-growing data that are being collected about all members of society. However, collecting data that are not available for legitimate research and evaluation decreases the value of that collection. States need better mechanisms to ensure privacy of data they collect.  At the same time they also need assurances that the findings from the data they release to researchers will provide valid answers to the research and evaluation questions posed. This project will build and test the data masking models that are the necessary infrastructure for the effective use of large scale state longitudinal data systems.</AbstractNarration>
<MinAmdLetterDate>08/15/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/17/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1437953</AwardID>
<Investigator>
<FirstName>Larry</FirstName>
<LastName>Hedges</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Larry V Hedges</PI_FULL_NAME>
<EmailAddress>l-hedges@northwestern.edu</EmailAddress>
<PI_PHON>8474918899</PI_PHON>
<NSF_ID>000514339</NSF_ID>
<StartDate>08/15/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Hedberg</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric C Hedberg</PI_FULL_NAME>
<EmailAddress>Eric_Hedberg@abtassoc.com</EmailAddress>
<PI_PHON>7739096801</PI_PHON>
<NSF_ID>000667752</NSF_ID>
<StartDate>08/15/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>National Opinion Research Center</Name>
<CityName>Chicago</CityName>
<ZipCode>606372745</ZipCode>
<PhoneNumber>7732566000</PhoneNumber>
<StreetAddress>1155 E. 60th Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>069512291</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NATIONAL OPINION RESEARCH CENTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>069512291</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[National Opinion Research Center]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606370001</ZipCode>
<StreetAddress><![CDATA[1155 East 60th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7261</Code>
<Text>Project &amp; Program Evaluation</Text>
</ProgramElement>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~710614</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Project Outcomes Report</strong></p> <p>&nbsp;</p> <p>The modern world is awash with data about which there are often confidentiality and privacy concerns.&nbsp; The fact that privacy of vulnerable populations of people (like children) needs to be protected is enshrined in laws like the Family Education Rights and Privacy Act (FERPA), which protects the privacy of educational data.&nbsp; At the same time, there has been tremendous progress in the development of new data resources that can inform better educational policy and practice.&nbsp; State Longitudinal Data Systems (SLDSs) are census data collections about every student in a state&rsquo;s K-12 (and in some cases pre-K-16) education systems. These SLDSs present important opportunities to understand the functioning of state&rsquo;s education systems, but also a great risk to the privacy of children.&nbsp; Moreover because these datasets can include information about families, protection of information about individuals may also be necessary to protect the privacy of their families..</p> <p>Methods for statistical disclosure control are designed to permit exploitation of the research opportunities presented by extensive data collections (like SLDSs) while protecting the privacy of children and their families.&nbsp; Methods of statistical disclosure control involves modifying the original dataset in ways that satisfy two competing objectives: 1) protecting against the possibility of disclosure of the identities of individuals involved, and 2) providing the same information to researchers (except the identity of the individuals involved) that would have been provided by the original dataset.&nbsp; Each of these objectives alone is easy to satisfy, but methods that are better at satisfying one of them are often worse at satisfying the other.&nbsp; This project evaluated several methods of disclosure control applied to the SLDSs of ten US states.</p> <p>Perhaps the most frequently used method of statistical disclosure control is suppression of microstrata.&nbsp; It works by identifying small subgroups that could be identified in the data and then deleting them from the dataset.&nbsp; For example, if there are only a small number of female Black students in a given grade in a given school, there might be a risk of discovering the identity of those Black females if the SLDS data were combined with data from other sources.&nbsp; Suppressing (deleting) all the data about those students removes the risk that their identity could be deduced (and other data connected with them could be revealed).&nbsp;</p> <p>We evaluated microsuppression using several state&rsquo;s SLDS and discovered surprising results.&nbsp; While suppressing data from subgroups with less than 5 members is effective in protecting against disclosure, it can systematically distort the results of statistical analyses and these distortions are not necessarily small.&nbsp; It leads to systematic loss of information about small population groups (e.g., ethnic, racial, or socio-economic minorities), which are often the groups of interest in educational studies.&nbsp; It can also lead to underestimation of measures of variation across subgroups.&nbsp; Understanding variation is often of interest in itself for research that attempts to understand diversity and its consequences.&nbsp; But variation is important in all statistical analyses because of its role in the assessing uncertainty of estimates and statistical significance.&nbsp; That is, microsuppression can lead to overestimates of precision and exaggeration of statistical significance in many statistical analyses.&nbsp;</p> <p>We evaluated other methods of disclosure control that were more satisfactory.&nbsp; One of these was population multiple imputation, which attempts to create multiple synthetic datasets that have the same structure as the original data.&nbsp;&nbsp;&nbsp; Because these synthetic populations contain none of the original data, the privacy of the individuals in the original dataset is preserved.&nbsp; The major difficulty is the technical problem of creating the synthetic datasets so that we can know have the same structure as the original dataset.&nbsp; We evaluated several technical procedures for creating synthetic datasets and compared analyses of the original and synthetic datasets to determine that analyses of the original and synthetic datasets produced essentially the same results.&nbsp; We also attempted to determine if we could somehow discover information about particular individuals from the synthetic datasets, and found that the chance of this was quite small.&nbsp; We concluded that this technology is a promising approach to making the information in SLDSs accessible to researchers without compromising the privacy of individuals or their families.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/15/2019<br>      Modified by: Eric&nbsp;C&nbsp;Hedberg</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Project Outcomes Report     The modern world is awash with data about which there are often confidentiality and privacy concerns.  The fact that privacy of vulnerable populations of people (like children) needs to be protected is enshrined in laws like the Family Education Rights and Privacy Act (FERPA), which protects the privacy of educational data.  At the same time, there has been tremendous progress in the development of new data resources that can inform better educational policy and practice.  State Longitudinal Data Systems (SLDSs) are census data collections about every student in a state’s K-12 (and in some cases pre-K-16) education systems. These SLDSs present important opportunities to understand the functioning of state’s education systems, but also a great risk to the privacy of children.  Moreover because these datasets can include information about families, protection of information about individuals may also be necessary to protect the privacy of their families..  Methods for statistical disclosure control are designed to permit exploitation of the research opportunities presented by extensive data collections (like SLDSs) while protecting the privacy of children and their families.  Methods of statistical disclosure control involves modifying the original dataset in ways that satisfy two competing objectives: 1) protecting against the possibility of disclosure of the identities of individuals involved, and 2) providing the same information to researchers (except the identity of the individuals involved) that would have been provided by the original dataset.  Each of these objectives alone is easy to satisfy, but methods that are better at satisfying one of them are often worse at satisfying the other.  This project evaluated several methods of disclosure control applied to the SLDSs of ten US states.  Perhaps the most frequently used method of statistical disclosure control is suppression of microstrata.  It works by identifying small subgroups that could be identified in the data and then deleting them from the dataset.  For example, if there are only a small number of female Black students in a given grade in a given school, there might be a risk of discovering the identity of those Black females if the SLDS data were combined with data from other sources.  Suppressing (deleting) all the data about those students removes the risk that their identity could be deduced (and other data connected with them could be revealed).   We evaluated microsuppression using several state’s SLDS and discovered surprising results.  While suppressing data from subgroups with less than 5 members is effective in protecting against disclosure, it can systematically distort the results of statistical analyses and these distortions are not necessarily small.  It leads to systematic loss of information about small population groups (e.g., ethnic, racial, or socio-economic minorities), which are often the groups of interest in educational studies.  It can also lead to underestimation of measures of variation across subgroups.  Understanding variation is often of interest in itself for research that attempts to understand diversity and its consequences.  But variation is important in all statistical analyses because of its role in the assessing uncertainty of estimates and statistical significance.  That is, microsuppression can lead to overestimates of precision and exaggeration of statistical significance in many statistical analyses.   We evaluated other methods of disclosure control that were more satisfactory.  One of these was population multiple imputation, which attempts to create multiple synthetic datasets that have the same structure as the original data.    Because these synthetic populations contain none of the original data, the privacy of the individuals in the original dataset is preserved.  The major difficulty is the technical problem of creating the synthetic datasets so that we can know have the same structure as the original dataset.  We evaluated several technical procedures for creating synthetic datasets and compared analyses of the original and synthetic datasets to determine that analyses of the original and synthetic datasets produced essentially the same results.  We also attempted to determine if we could somehow discover information about particular individuals from the synthetic datasets, and found that the chance of this was quite small.  We concluded that this technology is a promising approach to making the information in SLDSs accessible to researchers without compromising the privacy of individuals or their families.          Last Modified: 12/15/2019       Submitted by: Eric C Hedberg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
