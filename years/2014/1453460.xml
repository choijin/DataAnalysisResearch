<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Preliminary Study to Demonstrate the Performance and Power Advantages of FPGAs over GPUs for Deep Learning in Computer Vision</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>95000.00</AwardTotalIntnAmount>
<AwardAmount>95000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>We stand on the verge of dramatic advances in deep learning algorithms, which will soon enable widespread adoption of computer-vision-based object recognition in scientific inquiry, commercial applications, and everyday life. However, practical large-scale applications in this area are currently limited by the computational capabilities of conventional computer systems. In recent years, technological improvement in computer processors (CPUs) has considerably slowed. This has led to an increase in interest in using Graphics Processing Units (GPUs) to accelerate deep learning computer vision algorithms. Although GPUs can perform these tasks faster than CPUs, they suffer from inflexibility and very high power cost. An alternative technology called the Field-Programmable Gate Array (FPGA) is very attractive for problems in this domain thanks to its flexibility and power efficiency. However, FPGAs have been underutilized in this area, in large part due to unfamiliarity and misconceptions. The goal of this project is to demonstrate the power and performance advantages of FPGAs over GPUs for deep-learning-based computer vision problems via hard experimental evidence. The PIs will disseminate their findings to the research community at large with the goal of encouraging the use of FPGAs in ground-breaking work tackling the grand challenges of deep learning and computer vision.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This project consists of a three-stage research plan. First, the PIs will prepare and validate a state-of-the-art image detection application based on convolutional neural networks. This will utilize the popular Caffe library, which allows convolutional networks to be evaluated on CPU and GPU. Second, the PIs will perform a detailed characterization and profiling of the performance of this application on GPU, seeking to understand the performance characteristics and their underlying causes. Third, the PIs will implement portions of the algorithm on an FPGA, and perform an in-depth analysis to find and explain the advantages and disadvantages offered by the platform. The PIs anticipate demonstrating that the slowest portion of the algorithm on the GPU will achieve significant speedup on the FPGA, arising from the efficient support of irregular fine-grain parallelism. Meanwhile, the fastest portion of the algorithm on the GPU is anticipated to run with comparable performance on the FPGA, but at dramatically lower power consumption.&lt;br/&gt;&lt;br/&gt;This project will integrate research with graduate and undergraduate education. PhD students will be exposed to GPU optimization and application-specific high-performance FPGA design.  Masters and undergraduate students will gain valuable skills assisting the project through the Masters Advanced Project in Computer Science and the Undergraduate Senior Design Project in Electrical and Computer Engineering.  The results of the study will be published at prominent venues to ensure maximum exposure for the relevant research communities.</AbstractNarration>
<MinAmdLetterDate>08/06/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1453460</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Milder</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter Milder</PI_FULL_NAME>
<EmailAddress>peter.milder@stonybrook.edu</EmailAddress>
<PI_PHON>6316328407</PI_PHON>
<NSF_ID>000629904</NSF_ID>
<StartDate>08/06/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Ferdman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Ferdman</PI_FULL_NAME>
<EmailAddress>mferdman@cs.stonybrook.edu</EmailAddress>
<PI_PHON>6316328449</PI_PHON>
<NSF_ID>000634656</NSF_ID>
<StartDate>08/06/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>117944400</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~95000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Deep Learning is an extremely computationally-intensive problem of high importance in the fields of computer vision, natural language processing, fraud detection, bioinformatics, and many other areas that have a wide range of commercial and scientific applications. &nbsp;While it is clear that the computational capabilities for deep learning are within reach, it is equally clear that the required computational power cannot come from general-purpose processors and requires hardware acceleration. The major goal of this project was to quantitatively demonstrate the applicability of reconfigurable chips called field-programmable gate arrays (FPGAs) to accelerate deep learning, and to show the benefits FPGAs offer over another type of hardware accelerator called a graphics processing unit (GPU). The high level objectives of this work were (1) to perform a detailed characterization of deep learning on GPUs and (2) to construct an FPGA-based implementation of deep learning applications and perform a similar detailed characterization.</p> <p>The results of this project quantitatively demonstrate the ability of using FPGAs to provide fast and energy-efficient computation of deep learning algorithms. For example, measurements showed that although the FPGA's speed was close to the speed of the GPU, the FPGA was much more energy efficient: the GPU requires 13x more power, consuming 15x more energy per image than the FPGA.</p> <p>The broader impacts of this work include the dissemination of results through publications and the training of graduate and undergraduate students. Three PhD students (two full-time) and two MS students contributed to this research effort. Both of the MS students have graduated, beginning their professional careers working with deep learning technologies. The PhD students involved in this project obtained competitive related internships at top technology companies. Lastly, this research effort was integrated into undergraduate education, as the PIs advised a group of four students on a closely-related year-long senior design project.</p><br> <p>            Last Modified: 10/26/2016<br>      Modified by: Michael&nbsp;Ferdman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Deep Learning is an extremely computationally-intensive problem of high importance in the fields of computer vision, natural language processing, fraud detection, bioinformatics, and many other areas that have a wide range of commercial and scientific applications.  While it is clear that the computational capabilities for deep learning are within reach, it is equally clear that the required computational power cannot come from general-purpose processors and requires hardware acceleration. The major goal of this project was to quantitatively demonstrate the applicability of reconfigurable chips called field-programmable gate arrays (FPGAs) to accelerate deep learning, and to show the benefits FPGAs offer over another type of hardware accelerator called a graphics processing unit (GPU). The high level objectives of this work were (1) to perform a detailed characterization of deep learning on GPUs and (2) to construct an FPGA-based implementation of deep learning applications and perform a similar detailed characterization.  The results of this project quantitatively demonstrate the ability of using FPGAs to provide fast and energy-efficient computation of deep learning algorithms. For example, measurements showed that although the FPGA's speed was close to the speed of the GPU, the FPGA was much more energy efficient: the GPU requires 13x more power, consuming 15x more energy per image than the FPGA.  The broader impacts of this work include the dissemination of results through publications and the training of graduate and undergraduate students. Three PhD students (two full-time) and two MS students contributed to this research effort. Both of the MS students have graduated, beginning their professional careers working with deep learning technologies. The PhD students involved in this project obtained competitive related internships at top technology companies. Lastly, this research effort was integrated into undergraduate education, as the PIs advised a group of four students on a closely-related year-long senior design project.       Last Modified: 10/26/2016       Submitted by: Michael Ferdman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
