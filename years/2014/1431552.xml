<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>The Effectiveness of Intelligent Virtual Humans in Facilitating Self-Regulated Learning in STEM with MetaTutor</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>1365603.00</AwardTotalIntnAmount>
<AwardAmount>1365603</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregg Solomon</SignBlockName>
<PO_EMAI>gesolomo@nsf.gov</PO_EMAI>
<PO_PHON>7032928333</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The investigators will research how characteristics of intelligent virtual humans (IVHs) support the ability of students to reflect on and, therefore, improve their learning in undergraduate biology.  To date, research has shown mixed effectiveness when human avatars are used in learning technologies.  To remedy that, the researchers will first study how expert human tutors use verbal and facial cues in reacting to students' cognitive, affective, metacognitive, and motivational (CAMM) processes.   Then, they will use these data to build an enhanced intelligent virtual human tutor (by altering software called "MetaTutor").  The project will advance the field's ability to build more effective intelligent tutors and advance understanding of self-regulated learning.     &lt;br/&gt;&lt;br/&gt;The researchers propose to experimentally study the effectiveness of the enhanced IVHs on learners' self-regulatory processes and other learning outcomes.  Data will be collected on both a natural face and a natural face that has been morphed and presented as a virtual human. The facial and verbal expressions are meant to provide learners with an additional information source they can use to monitor and regulate their ongoing self-regulatory processes, including making accurate emotional appraisals.  In addition to the facial data, the researchers will collect self-report data, trace data using a variety of sensors, learning outcomes (e.g., pretest and posttest), and knowledge construction activities (e.g., summaries of content, notes, quizzes).   Finally, the project will be disseminated in the form of journal publications, conference presentations, and an enhanced version of MetaTutor.</AbstractNarration>
<MinAmdLetterDate>08/06/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1431552</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Lester</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James C Lester</PI_FULL_NAME>
<EmailAddress>lester@csc.ncsu.edu</EmailAddress>
<PI_PHON>9195157534</PI_PHON>
<NSF_ID>000365555</NSF_ID>
<StartDate>08/06/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Roger</FirstName>
<LastName>Azevedo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Roger Azevedo</PI_FULL_NAME>
<EmailAddress>roger.azevedo@ucf.edu</EmailAddress>
<PI_PHON>9193021867</PI_PHON>
<NSF_ID>000206946</NSF_ID>
<StartDate>08/06/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957103</ZipCode>
<StreetAddress><![CDATA[2310 Stinson Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~1365603</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Over the last four year our project focused on the effectiveness of intelligent virtual humans (IVHs) in facilitating college students? use of cognitive, affective, metacognitive, and motivational (CAMM) self-regulatory processes during science learning with MetaTutor. MetaTutor is an intelligent, multiagent hypermedia-based learning environment that fosters learning of human body systems. IVHs are realistic embodiments of humans that revolutionize the way advanced technologies foster self-regulated learning (SRL) and enhance science learning. Our interdisciplinary research was conducted with several versions of MetaTutor and examined: (1) Which multichannel data do expert human tutors attend to when observing learners monitoring and regulating their CAMM processes and how is this related to their facial and verbal expressions? (2) Can data and inferences from (1) be embodied in IVHs? If so, are IVHs more effective than human expert tutors as external regulating agents? Do different facial and verbal expressions displayed by the IVHs facilitate learners? ability to monitor and regulate their CAMM processes during learning, and will it lead to increases in science learning? (3) What is the optimal temporal synchronization when learners unfold SRL behaviors with MetaTutor? Are IVHs effective in facilitating learners? monitoring and regulation of SRL CAMM processes and overall science learning? Are there specific signatures for each CAMM process, and are they predictive of learning and shifts in the sophistication of CAMM process deployment? (4) To what extent do the experimental manipulations lead to differences in CAMM process deployment and learning? What is the nature of the temporal and dynamic unfolding of CAMM processes during learning? Our program of research used methods from learning and cognitive sciences and computer science to experimentally investigate the effectiveness of IVHs on learners? deployment of key CAMM SRL processes during complex science learning across several human body systems. </span></p> <p><span>The research made contributions to the science of learning, methodologies, and quantitative analyses of complex multichannel sensing data from human-IVH interactions for designing effective technologies for science learning. Several existing interdisciplinary theoretical models were used to understand the impact of IVHs on learners? SRL processes. The proposed research built a theoretically driven and empirically based comprehensive model of SRL by understanding how these processes are coordinated and integrated between learners and IVHs. Numerous interdisciplinary methodologies were fused to detect, track, model, and assess both the IVHs? verbal and nonverbal expressions and students? CAMM SRL processes when learning science with MetaTutor. This work advanced the science of learning and education research by: (1) enhancing current theoretical models of self-regulated learning and externally regulated learning with adaptive, IVH-based learning environments; (2) extending current research methods and analytical techniques from cognitive, learning, and affective sciences, computer science, data mining, and machine learning to detect, track, and model the complex nature of CAMM self-regulatory processes; and (3) examining the influence of experimental manipulations and fostering science learning with MetaTutor-like environments. </span></p> <p><span>In terms of broader impacts, we addressed several key learning issues. First, we have a better understanding of how to facilitate the acquisition of deep conceptual understanding of the complex science topics that learners need to learn and that form the foundation of future STEM careers. Second, we have a better understanding of how to design IVHs' facial expression to facilitate conceptual learning. We have also developed several tools (MetaTutorIVH, MetaMentor, and the data pipeline) that can be shared with other researchers and educators interested in fostering self-regulatory skill in students across disciplines and ages. Third, by sharing our tools with local, national, and international community of interdisciplinary researchers and educators it is likely to increase public scientific literacy and engagement in science and technology, especially rural and socioeconomically disadvantaged students, who often lack access to high-quality tutoring and cutting-edge technologies.</span></p> <p><strong>&nbsp;</strong><em>&nbsp;</em></p> <p>&nbsp;</p><br> <p>            Last Modified: 02/02/2019<br>      Modified by: Roger&nbsp;Azevedo</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1431552/1431552_10329476_1549151111446_MetaTutorIVH1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1431552/1431552_10329476_1549151111446_MetaTutorIVH1--rgov-800width.jpg" title="MetaTutor IVH"><img src="/por/images/Reports/POR/2019/1431552/1431552_10329476_1549151111446_MetaTutorIVH1--rgov-66x44.jpg" alt="MetaTutor IVH"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 1. Student interface for the MetaTutor IVH learning environment with embedded IVH tutor videos.</div> <div class="imageCredit">MetaTutor project</div> <div class="imageSubmitted">Roger&nbsp;Azevedo</div> <div class="imageTitle">MetaTutor IVH</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the last four year our project focused on the effectiveness of intelligent virtual humans (IVHs) in facilitating college students? use of cognitive, affective, metacognitive, and motivational (CAMM) self-regulatory processes during science learning with MetaTutor. MetaTutor is an intelligent, multiagent hypermedia-based learning environment that fosters learning of human body systems. IVHs are realistic embodiments of humans that revolutionize the way advanced technologies foster self-regulated learning (SRL) and enhance science learning. Our interdisciplinary research was conducted with several versions of MetaTutor and examined: (1) Which multichannel data do expert human tutors attend to when observing learners monitoring and regulating their CAMM processes and how is this related to their facial and verbal expressions? (2) Can data and inferences from (1) be embodied in IVHs? If so, are IVHs more effective than human expert tutors as external regulating agents? Do different facial and verbal expressions displayed by the IVHs facilitate learners? ability to monitor and regulate their CAMM processes during learning, and will it lead to increases in science learning? (3) What is the optimal temporal synchronization when learners unfold SRL behaviors with MetaTutor? Are IVHs effective in facilitating learners? monitoring and regulation of SRL CAMM processes and overall science learning? Are there specific signatures for each CAMM process, and are they predictive of learning and shifts in the sophistication of CAMM process deployment? (4) To what extent do the experimental manipulations lead to differences in CAMM process deployment and learning? What is the nature of the temporal and dynamic unfolding of CAMM processes during learning? Our program of research used methods from learning and cognitive sciences and computer science to experimentally investigate the effectiveness of IVHs on learners? deployment of key CAMM SRL processes during complex science learning across several human body systems.   The research made contributions to the science of learning, methodologies, and quantitative analyses of complex multichannel sensing data from human-IVH interactions for designing effective technologies for science learning. Several existing interdisciplinary theoretical models were used to understand the impact of IVHs on learners? SRL processes. The proposed research built a theoretically driven and empirically based comprehensive model of SRL by understanding how these processes are coordinated and integrated between learners and IVHs. Numerous interdisciplinary methodologies were fused to detect, track, model, and assess both the IVHs? verbal and nonverbal expressions and students? CAMM SRL processes when learning science with MetaTutor. This work advanced the science of learning and education research by: (1) enhancing current theoretical models of self-regulated learning and externally regulated learning with adaptive, IVH-based learning environments; (2) extending current research methods and analytical techniques from cognitive, learning, and affective sciences, computer science, data mining, and machine learning to detect, track, and model the complex nature of CAMM self-regulatory processes; and (3) examining the influence of experimental manipulations and fostering science learning with MetaTutor-like environments.   In terms of broader impacts, we addressed several key learning issues. First, we have a better understanding of how to facilitate the acquisition of deep conceptual understanding of the complex science topics that learners need to learn and that form the foundation of future STEM careers. Second, we have a better understanding of how to design IVHs' facial expression to facilitate conceptual learning. We have also developed several tools (MetaTutorIVH, MetaMentor, and the data pipeline) that can be shared with other researchers and educators interested in fostering self-regulatory skill in students across disciplines and ages. Third, by sharing our tools with local, national, and international community of interdisciplinary researchers and educators it is likely to increase public scientific literacy and engagement in science and technology, especially rural and socioeconomically disadvantaged students, who often lack access to high-quality tutoring and cutting-edge technologies.              Last Modified: 02/02/2019       Submitted by: Roger Azevedo]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
