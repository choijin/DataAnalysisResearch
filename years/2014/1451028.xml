<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Investigating the Neural Correlates of Musical Rhythms from Intracranial Recordings</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>149940.00</AwardTotalIntnAmount>
<AwardAmount>149940</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The project will develop an offline and then a real-time brain computer interface to detect rhythms that are imagined in people's heads, and translate these rhythms into actual sound. The project builds upon research breakthroughs in electrocorticographic (ECoG) recording technology to convert music that is imagined into synthesized sound. The project researchers will recruit from a specialized group of people for this project, specifically patients with intractable epilepsy who are currently undergoing clinical evaluation of their condition at the Mayo Clinic in Jacksonville, Florida, and are thus uniquely prepared to use brain-computer interfaces based on ECoG recording techniques. This is a highly multidisciplinary project that will make progress towards developing a "brain music synthesizer" which could have a significant impact in the neuroscience and musical domains, and lead to creative outlets and alternative communication devices and thus life improvements for people with severe disabilities.&lt;br/&gt;&lt;br/&gt;Most brain-computer interfaces (BCIs) use surface-recorded electrophysiological measurements such as surface-recorded electroencephalogram (EEG). However, while some useful signals can be extracted from such surface techniques, it is nearly impossible to accurately decode from such signals the intricate brain activity involved in activities such as language with the detail needed to achieve a natural, transparent translation of thought to device control. On the contrary, intracranial electrodes such as ECoG are closer to the source of the desired brain activity, and can produce signals that, compared to surface techniques, have superior spatial and spectral characteristics and signal-to-noise ratios. Research has already shown that intracranial signals can provide superior decoding capabilities for motor and language signals, and for BCI control. Because complex language and auditory signals (both perceived and imagined) have been decoded using intracranial activity, it is conceivable to decode perceived and imagined musical content from intracranial signals. This project will attempt to similarly use ECoG to decode perceived and imagined musical content from intracranial signals as has been done for language and auditory signals.</AbstractNarration>
<MinAmdLetterDate>08/21/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1451028</AwardID>
<Investigator>
<FirstName>Jerry</FirstName>
<LastName>Shih</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jerry J Shih</PI_FULL_NAME>
<EmailAddress>shih.jerry@mayo.edu</EmailAddress>
<PI_PHON>9049537104</PI_PHON>
<NSF_ID>000465859</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dean</FirstName>
<LastName>Krusienski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dean Krusienski</PI_FULL_NAME>
<EmailAddress>djkrusienski@vcu.edu</EmailAddress>
<PI_PHON>8048271890</PI_PHON>
<NSF_ID>000500739</NSF_ID>
<StartDate>08/21/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Old Dominion University Research Foundation</Name>
<CityName>Norfolk</CityName>
<ZipCode>235082561</ZipCode>
<PhoneNumber>7576834293</PhoneNumber>
<StreetAddress>4111 Monarch Way</StreetAddress>
<StreetAddress2><![CDATA[Suite 204]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>077945947</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OLD DOMINION UNIVERSITY RESEARCH FOUNDATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Old Dominion University]]></Name>
<CityName>Norfolk</CityName>
<StateCode>VA</StateCode>
<ZipCode>235290001</ZipCode>
<StreetAddress><![CDATA[231 Kaufman Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~149940</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary goal of this research is to better understand the electrical activity of the brain when perceiving, imagining, and tapping simple musical rhythms.&nbsp; This understanding facilitates the development of real-time decoding algorithms that aim to resynthesize such imaged musical rhythms directly from brain activity.&nbsp; It is envisioned that this technology can eventually provide new communication, creativity, and entertainment outlets for the severely disabled, and eventually the general population.</p> <p>Intellectual Merit:</p> <p>The major research thrusts of this project are: (1) the characterization of spatial, temporal, and spectral features of perceived, imagined, and tapped musical rhythms from invasive brain recordings, and (2) the development of real-time brain decoding and translation algorithms for reconstructing and synthesizing the musical rhythms into acoustic output.</p> <p>This is the first study to specifically examine the perception, imagination, and production of musical (drum) rhythms in&nbsp;intracranial&nbsp;recordings.&nbsp; This work produced a thorough characterization the spatio-temporal patterns of the brain activity with respect to three task conditions perception, imagination, and tapping of predefined musical rhythms.&nbsp;The results show that similar brain activations occur when perceiving and imagining the rhythms, which is an optimistic outcome for the design of neuroprosthetic devices.&nbsp; Additionally, the spatio-temporal patterns were also characterized within and across the three aforementioned task conditions with respect to beat tempo, complexity, and altering rhythmic patterns.&nbsp; The results were aggregated across subjects and common areas of activation have been identified, including areas that have not been previously reported or characterized in intracranial brain recordings.</p> <p>These findings were used to develop a classifier that predicts the occurrence of two types of acoustic beats (i.e., bass and snare drums) versus silence directly from the brain activity during perception with accuracy significantly above the chance level.&nbsp; This was further extended into the development and validation of a model that accurately reconstructs the temporal beat patterns directly from brain activity during perception in real-time.&nbsp; Analogous methods for analyzing speech activity in the brain were also developed with the intention of identifying common brain activations of rhythmic speech with musical rhythms.</p> <p>Broader Impacts:</p> <p>The methods developed for neural signal characterization and decoding are broadly applicable to other perceptual, motor, and cognitive brain research domains.&nbsp; For application in a brain-computer interface (BCI), the envisioned technology has the potential to enhance the quality of life for severely disabled patients, their families, and their caregivers by providing a new communication, creative, or recreational outlet.&nbsp; This multidisciplinary project supported and involved undergraduate and graduate students in electrical, computer, and biomedical engineering; computer science; biology; psychology; and music technology.&nbsp; All students have participated in developing and configuring various hardware and software components, designing and conducting human-subject BCI experiments, performing data analysis, coauthoring papers, and giving technical presentations.&nbsp; This project produced numerous presentations and publications, as well as a unique, annotated intracranial dataset collected from 13 patients that performed the musical rhythm perception imagination, and tapping tasks.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/09/2017<br>      Modified by: Dean&nbsp;Krusienski</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The primary goal of this research is to better understand the electrical activity of the brain when perceiving, imagining, and tapping simple musical rhythms.  This understanding facilitates the development of real-time decoding algorithms that aim to resynthesize such imaged musical rhythms directly from brain activity.  It is envisioned that this technology can eventually provide new communication, creativity, and entertainment outlets for the severely disabled, and eventually the general population.  Intellectual Merit:  The major research thrusts of this project are: (1) the characterization of spatial, temporal, and spectral features of perceived, imagined, and tapped musical rhythms from invasive brain recordings, and (2) the development of real-time brain decoding and translation algorithms for reconstructing and synthesizing the musical rhythms into acoustic output.  This is the first study to specifically examine the perception, imagination, and production of musical (drum) rhythms in intracranial recordings.  This work produced a thorough characterization the spatio-temporal patterns of the brain activity with respect to three task conditions perception, imagination, and tapping of predefined musical rhythms. The results show that similar brain activations occur when perceiving and imagining the rhythms, which is an optimistic outcome for the design of neuroprosthetic devices.  Additionally, the spatio-temporal patterns were also characterized within and across the three aforementioned task conditions with respect to beat tempo, complexity, and altering rhythmic patterns.  The results were aggregated across subjects and common areas of activation have been identified, including areas that have not been previously reported or characterized in intracranial brain recordings.  These findings were used to develop a classifier that predicts the occurrence of two types of acoustic beats (i.e., bass and snare drums) versus silence directly from the brain activity during perception with accuracy significantly above the chance level.  This was further extended into the development and validation of a model that accurately reconstructs the temporal beat patterns directly from brain activity during perception in real-time.  Analogous methods for analyzing speech activity in the brain were also developed with the intention of identifying common brain activations of rhythmic speech with musical rhythms.  Broader Impacts:  The methods developed for neural signal characterization and decoding are broadly applicable to other perceptual, motor, and cognitive brain research domains.  For application in a brain-computer interface (BCI), the envisioned technology has the potential to enhance the quality of life for severely disabled patients, their families, and their caregivers by providing a new communication, creative, or recreational outlet.  This multidisciplinary project supported and involved undergraduate and graduate students in electrical, computer, and biomedical engineering; computer science; biology; psychology; and music technology.  All students have participated in developing and configuring various hardware and software components, designing and conducting human-subject BCI experiments, performing data analysis, coauthoring papers, and giving technical presentations.  This project produced numerous presentations and publications, as well as a unique, annotated intracranial dataset collected from 13 patients that performed the musical rhythm perception imagination, and tapping tasks.           Last Modified: 11/09/2017       Submitted by: Dean Krusienski]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
