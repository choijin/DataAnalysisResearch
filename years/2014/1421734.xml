<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RUI: Intermediate-level Vision:  Grouping of generic features for image and video processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>187449.00</AwardTotalIntnAmount>
<AwardAmount>187449</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The human vision system is able to recognize objects and understand the scene from the boundary of the objects alone. It is astonishingly robust so that it can sustain this capability under distraction by non-boundary points and sparse sampling of the boundary points. How the system achieves this feat is largely unknown. This project investigates how a computer can replicate it algorithmically. The problem is fundamental and closely related to perceptual organization and intermediate level vision problems. Thus, this research has the potential to impact a wide range of computer vision applications. Since the input (a small set of isolated points) is small compared to the whole image and has no color information, the algorithm is efficient, robust against changes in illumination and contrast, and applicable to any imaging modalities.&lt;br/&gt;&lt;br/&gt;The main problem is to interpolate boundary points into a perceptually salient set of surfaces without being distracted by spurious non-boundary points. Interpolation by straight skeletons brings a time-reversible, multi-scale representation of a point set where salient boundary points tend to form a polygonal surface persistently while spurious non-boundary points tend to disappear quickly as the scale increases. Because of the time-reversible nature, a surface at each scale can be traced back to the original scale or the original point set. Thus, this technique can be used to form a set of salient surfaces from the original point set. This research develops a general purpose feature grouping algorithm using the straight skeleton interpolation and applies it to a number of intermediate vision problems in 2D and 3D domains. The investigator actively involves undergraduate students into the research and promotes STEM education in the northeastern part of the U.S.A through presentations, demonstrations, and outreach activities. The source code and toolboxes will be made publicly available and used to promote STEM education.</AbstractNarration>
<MinAmdLetterDate>08/07/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421734</AwardID>
<Investigator>
<FirstName>Toshiro</FirstName>
<LastName>Kubota</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Toshiro Kubota</PI_FULL_NAME>
<EmailAddress>kubota@susqu.edu</EmailAddress>
<PI_PHON>5703724469</PI_PHON>
<NSF_ID>000342748</NSF_ID>
<StartDate>08/07/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Susquehanna University</Name>
<CityName>Selinsgrove</CityName>
<ZipCode>178701164</ZipCode>
<PhoneNumber>5703724571</PhoneNumber>
<StreetAddress>514 University Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>069790426</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SUSQUEHANNA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>069790426</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Susquehanna University]]></Name>
<CityName>Selinsgrove</CityName>
<StateCode>PA</StateCode>
<ZipCode>178701164</ZipCode>
<StreetAddress><![CDATA[514 University Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~187449</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We were able to conduct ambitious high-impact research projects involving undergraduate students.&nbsp; Our efforts brought synergy with other researchers locally and initiated collaborative projects. Our research outcomes have been regularly presented at both regional and national conferences by the students and made accessible at our web site, <a href="http://comenius.susqu.edu/math/compvision">http://comenius.susqu.edu/math/compvision</a>. The projects can be divided into three categories: perceptual organization, applications, and AI focused pedagogy at liberal arts institutes.</p> <p>Under the perceptual grouping, we conducted various psycho-visual experiments: biological motion against various types of disturbance, scene interpretation from sparsely sampled motion signals, effects of grouping in depth perception, and use of the virtual reality technology for studying visual illusions. The biological motion experiments affirmed impressive capability of our vision as volunteers were able to recognize the actions presented in the biological motions under various types of severe disturbance. The scene interpretation experiments demonstrated our capability of recognizing animals and their actions from motion information alone. We were able to propose encoding of motions in a compact form for further processing. The depth perception experiments demonstrated that grouping precedes depth perception, which can be important in elucidating our 3D vision. The virtual reality experiments provided some examples of using the technology for visual experiments in the lab and attempted to explain the famous full moon illusion.</p> <p>Under the applications, we tackled various computer vision and AI problems including segmentation of human ventricles from 4D MRI data, reconstruction of 3D layouts of sparse markers from a hand held &nbsp;camera, EKG anomaly detection with a portable probe and a RaspberryPi, and 3D point cloud reconstruction from a mobile RGB-D camera. In particular, our ventricle segmentation algorithm provided excellent results on our data set for both left and right ventricles at both end-diastole and end-systolic cardiac phases. The project was in collaboration with the Cardiac Imaging Research Lab at the Geisinger Hospital.</p> <p>Our objective of the AI focused pedagogy was to study good practices for introducing AI technology to undergraduate students at liberal arts colleges. As the tech industries and business sectors rely more heavily on AI in their products and workflow, it will become essential for students to be familiar with the technology. Since the modern AI often requires a large amount of computing power and training data, teaching AI at a liberal arts college poses challenge. First, we may not be able to afford high-end computing resources in our class room. Second, we will be time-constrained to teach AI and its theory comprehensively. &nbsp;Third, we may find engaging the data collection and annotation process difficult, as it is laborious and time-consuming endeavor.</p> <p>To achieve the objective, we built custom high-performance LINUX workstations and conducted AI based research projects: bathymetry estimates from hyperspectral data, automated music composition, and image generation from text captions. Based on our experience, we came up with the following recommendations. First, we can save money by building a workstation ourselves with off-the-shelf components. The resulting system is computationally sufficient for undergraduate projects. The practice provides not only cost-saving but also valuable hands-on installation and administration experience to the students, hence provides advantages over cloud-based approaches. Second, thanks to open sourcing and public databases, it is quite feasible to implement and modify existing AI algorithms and their models, without thorough understanding of the theory and implementation logic behind them. However, students need to be mindful about the danger associated with deploying a powerful system without complete understanding of it. Third, data collection poses the biggest obstacle in introducing AI in the current form to the classroom. Annotation of a large amount of data does not provide enough merits pedagogically. Publicly available data sets often do not satisfy project specific requirements and conforming them to the requirements is still difficult and time-consuming.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/22/2018<br>      Modified by: Toshiro&nbsp;Kubota</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We were able to conduct ambitious high-impact research projects involving undergraduate students.  Our efforts brought synergy with other researchers locally and initiated collaborative projects. Our research outcomes have been regularly presented at both regional and national conferences by the students and made accessible at our web site, http://comenius.susqu.edu/math/compvision. The projects can be divided into three categories: perceptual organization, applications, and AI focused pedagogy at liberal arts institutes.  Under the perceptual grouping, we conducted various psycho-visual experiments: biological motion against various types of disturbance, scene interpretation from sparsely sampled motion signals, effects of grouping in depth perception, and use of the virtual reality technology for studying visual illusions. The biological motion experiments affirmed impressive capability of our vision as volunteers were able to recognize the actions presented in the biological motions under various types of severe disturbance. The scene interpretation experiments demonstrated our capability of recognizing animals and their actions from motion information alone. We were able to propose encoding of motions in a compact form for further processing. The depth perception experiments demonstrated that grouping precedes depth perception, which can be important in elucidating our 3D vision. The virtual reality experiments provided some examples of using the technology for visual experiments in the lab and attempted to explain the famous full moon illusion.  Under the applications, we tackled various computer vision and AI problems including segmentation of human ventricles from 4D MRI data, reconstruction of 3D layouts of sparse markers from a hand held  camera, EKG anomaly detection with a portable probe and a RaspberryPi, and 3D point cloud reconstruction from a mobile RGB-D camera. In particular, our ventricle segmentation algorithm provided excellent results on our data set for both left and right ventricles at both end-diastole and end-systolic cardiac phases. The project was in collaboration with the Cardiac Imaging Research Lab at the Geisinger Hospital.  Our objective of the AI focused pedagogy was to study good practices for introducing AI technology to undergraduate students at liberal arts colleges. As the tech industries and business sectors rely more heavily on AI in their products and workflow, it will become essential for students to be familiar with the technology. Since the modern AI often requires a large amount of computing power and training data, teaching AI at a liberal arts college poses challenge. First, we may not be able to afford high-end computing resources in our class room. Second, we will be time-constrained to teach AI and its theory comprehensively.  Third, we may find engaging the data collection and annotation process difficult, as it is laborious and time-consuming endeavor.  To achieve the objective, we built custom high-performance LINUX workstations and conducted AI based research projects: bathymetry estimates from hyperspectral data, automated music composition, and image generation from text captions. Based on our experience, we came up with the following recommendations. First, we can save money by building a workstation ourselves with off-the-shelf components. The resulting system is computationally sufficient for undergraduate projects. The practice provides not only cost-saving but also valuable hands-on installation and administration experience to the students, hence provides advantages over cloud-based approaches. Second, thanks to open sourcing and public databases, it is quite feasible to implement and modify existing AI algorithms and their models, without thorough understanding of the theory and implementation logic behind them. However, students need to be mindful about the danger associated with deploying a powerful system without complete understanding of it. Third, data collection poses the biggest obstacle in introducing AI in the current form to the classroom. Annotation of a large amount of data does not provide enough merits pedagogically. Publicly available data sets often do not satisfy project specific requirements and conforming them to the requirements is still difficult and time-consuming.          Last Modified: 10/22/2018       Submitted by: Toshiro Kubota]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
