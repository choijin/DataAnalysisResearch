<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Alternative Approaches to the Analysis of Complex Sample Survey Data: Applying State-of-the-Art Methods to NCSES Surveys</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>109575.00</AwardTotalIntnAmount>
<AwardAmount>109575</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04030000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>NCSE</Abbreviation>
<LongName>National Center For S&amp;E Statistics</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Mark Fiegener</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Many scientific fields conduct research using data collected from large-scale probability samples of individuals or establishments. Secondary analyses of these data can be complicated by the complex nature of the sampling strategies, which are employed for data collection efficiency. It is important that any secondary analyses employ appropriate analytic techniques that account for the complex sample designs. This concept can be described as examining analytic error within the broader framework of Total Survey Error (TSE), which is a very promising area of survey research. This project will begin by identifying and documenting potential analytic errors in several complex NCSES surveys. The next step will be to synthesize best practices for analyses of these data. In the principal focus of the project, these state-of-the-art methods will be compared and contrasted to existing analyses of NCSES data, and the implications that alternative approaches can have for the interpretation of the results. This research has the potential to improve the analytic uses of NCSES data, but also to make contributions to the more appropriate use of complex sample survey data in general.</AbstractNarration>
<MinAmdLetterDate>09/08/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/08/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1424081</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Sakshaug</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joseph Sakshaug</PI_FULL_NAME>
<EmailAddress>joesaks@umich.edu</EmailAddress>
<PI_PHON>7347641817</PI_PHON>
<NSF_ID>000519924</NSF_ID>
<StartDate>09/08/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brady T.</FirstName>
<LastName>West</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brady T. West</PI_FULL_NAME>
<EmailAddress>bwest@umich.edu</EmailAddress>
<PI_PHON>7346474615</PI_PHON>
<NSF_ID>000614418</NSF_ID>
<StartDate>09/08/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091274</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8800</Code>
<Text>SCIENCE RESOURCES STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~109575</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This NSF-funded project had three primary objectives. The first objective was to understand and evaluate the analytic approaches that researchers working with public-use data sets arising from surveys fielded by the National Center for Science and Engineering Statistics (NCSES) were using when analyzing the survey data, and determine whether these approaches were consistent with recognized best practices. The second objective was to synthesize the published literature on current best practices for analyzing survey data, in addition to current software tools that allow researchers to implement these best practices. The third objective was to assess the implications of applying theoretically incorrect approaches to analyses of NCSES survey data for the quality of the estimates and population inferences produced.</p> <p>With regard to the first objective, we found that a significant number of research studies using NCSES data sets (both published and unpublished) appeared to be using incorrect approaches when analyzing the survey data, particularly with regard to estimating the sampling variance (and thus margin of error) of survey estimates. We identified potential data dissemination issues that may be preventing NCSES data users from applying theoretically correct approaches, and made recommendations for improving the peer review process, in terms of making sure that researchers are using correct approaches for the analysis of survey data (specifically for NCSES data and public-use survey data more generally). These findings and recommendations are communicated in a recent <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0158120"><em>PLoS ONE </em>peer-reviewed publication</a>&nbsp;and Chapter 22 of a <a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-1119041678.html">recently published edited Wiley volume on Total Survey Error in Practice</a>. We also disseminated these findings at multiple international conferences on survey research methodology.</p> <p>With regard to the second objective, we have produced an original manuscript that&nbsp;reviews current state-of-the art software enabling statisticians to apply design-based, model-based, and so-called &ldquo;hybrid&rdquo; approaches to the analysis of survey data. This manuscript presents brief overviews of the similarities and differences between these alternative analytic approaches, and then focuses on state-of-the-art software tools that are presently available for implementing each approach. The manuscript concludes with a summary of directions for future software development in this area. The manuscript is currently undergoing peer review at the <em>Journal of Official Statistics</em>.</p> <p>With regard to the third objective, we found that a failure to apply theoretically correct approaches when analyzing NCSES survey data sets can have severe implications for the quality of the estimates that researchers might produce when working with the data collected by these publically-funded surveys. Specifically, a failure to use the NCSES survey weights in estimation, which was found to occur in roughly 50% of the publications using NCSES data that we reviewed, can have a substantial impact on the important estimates produced by these surveys (e.g., how many college students have science and engineering degrees), and a failure to use appropriate variance estimation methods can lead to substantially different inferences about population features of interest. These results are also included in our recent&nbsp;<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0158120"><em>PLoS ONE&nbsp;</em>peer-reviewed publication</a>, and we are currently drafting a third manuscript designed to evaluate similar implications of incorrect analysis approaches for data from one of NCSES's restricted-use establishment surveys (BRDIS).&nbsp;</p> <p>Collectively, this NSF-funded research has shown that clear communication of appropriate approaches for analyzing survey data to researchers working with data from large national surveys is essential for making sure that the estimates produced by the researchers are not misleading consumers of that research about features of the target populations. Analyses of public-use survey data sets that are not performed correctly can effectively negate all of the federal resources dedicated to the collection of high-quality survey data, and this research has not only disseminated the potential dangers associated with this poor research practice, but also best practices for researchers and guidelines for data producers and peer reviewers alike for making sure that best practices are actually employed by researchers using survey data.</p> <p>Any questions about the products of this research should be directed to Brady T. West (bwest@umich.edu).</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/08/2017<br>      Modified by: Brady T.&nbsp;West</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This NSF-funded project had three primary objectives. The first objective was to understand and evaluate the analytic approaches that researchers working with public-use data sets arising from surveys fielded by the National Center for Science and Engineering Statistics (NCSES) were using when analyzing the survey data, and determine whether these approaches were consistent with recognized best practices. The second objective was to synthesize the published literature on current best practices for analyzing survey data, in addition to current software tools that allow researchers to implement these best practices. The third objective was to assess the implications of applying theoretically incorrect approaches to analyses of NCSES survey data for the quality of the estimates and population inferences produced.  With regard to the first objective, we found that a significant number of research studies using NCSES data sets (both published and unpublished) appeared to be using incorrect approaches when analyzing the survey data, particularly with regard to estimating the sampling variance (and thus margin of error) of survey estimates. We identified potential data dissemination issues that may be preventing NCSES data users from applying theoretically correct approaches, and made recommendations for improving the peer review process, in terms of making sure that researchers are using correct approaches for the analysis of survey data (specifically for NCSES data and public-use survey data more generally). These findings and recommendations are communicated in a recent PLoS ONE peer-reviewed publication and Chapter 22 of a recently published edited Wiley volume on Total Survey Error in Practice. We also disseminated these findings at multiple international conferences on survey research methodology.  With regard to the second objective, we have produced an original manuscript that reviews current state-of-the art software enabling statisticians to apply design-based, model-based, and so-called "hybrid" approaches to the analysis of survey data. This manuscript presents brief overviews of the similarities and differences between these alternative analytic approaches, and then focuses on state-of-the-art software tools that are presently available for implementing each approach. The manuscript concludes with a summary of directions for future software development in this area. The manuscript is currently undergoing peer review at the Journal of Official Statistics.  With regard to the third objective, we found that a failure to apply theoretically correct approaches when analyzing NCSES survey data sets can have severe implications for the quality of the estimates that researchers might produce when working with the data collected by these publically-funded surveys. Specifically, a failure to use the NCSES survey weights in estimation, which was found to occur in roughly 50% of the publications using NCSES data that we reviewed, can have a substantial impact on the important estimates produced by these surveys (e.g., how many college students have science and engineering degrees), and a failure to use appropriate variance estimation methods can lead to substantially different inferences about population features of interest. These results are also included in our recent PLoS ONE peer-reviewed publication, and we are currently drafting a third manuscript designed to evaluate similar implications of incorrect analysis approaches for data from one of NCSES's restricted-use establishment surveys (BRDIS).   Collectively, this NSF-funded research has shown that clear communication of appropriate approaches for analyzing survey data to researchers working with data from large national surveys is essential for making sure that the estimates produced by the researchers are not misleading consumers of that research about features of the target populations. Analyses of public-use survey data sets that are not performed correctly can effectively negate all of the federal resources dedicated to the collection of high-quality survey data, and this research has not only disseminated the potential dangers associated with this poor research practice, but also best practices for researchers and guidelines for data producers and peer reviewers alike for making sure that best practices are actually employed by researchers using survey data.  Any questions about the products of this research should be directed to Brady T. West (bwest@umich.edu).          Last Modified: 09/08/2017       Submitted by: Brady T. West]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
