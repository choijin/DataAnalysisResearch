<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SCH: EXP: Collaborative Research: Hierarchical Capacitive Sensing for Environmental Control and Physical Therapy for Patients with Paralysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>145417.00</AwardTotalIntnAmount>
<AwardAmount>145417</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>An estimated 1.5 million individuals in the United States are hospitalized each year because of strokes, brain injuries and spinal cord injuries. Severe impairment such as paralysis, paresis, weakness and limited range of motion are common sequels resulting from these injuries, requiring extensive rehabilitation. This project is developing invisible sensing systems embedded into bed sheets, pillows, wheelchair pads, and clothing, for environmental control and physical therapy for such paralysis patients. The system detects gestures regardless of evolving environmental and patient conditions and provides explicit real-time feedback to the user. Through the use of low-cost and ultra-low power capacitive sensing, the system reduces hospital visits and therapy costs. &lt;br/&gt;&lt;br/&gt;The proposed system addresses the limitations of existing assistive care sensors through three novel technical contributions: (1) The use of a self-sustainable hierarchy of sensors; textile-based capacitive sensor arrays (CSA) and inertial sensors on the human body; to improve the accuracy of gesture recognition while consuming minimal energy. The inertial sensors train the capacitive sensor arrays for different body positions; (2) A self-learning algorithm that determines gestures automatically regardless of the position of the patient's body and conditions using templates of gestures and patient conditions over time; and (3) Seamless integration of the patient in the feedback loop using amplification and animation to provide explicit real-time feedback to the user on how she/he is performing on his/her physical therapy, and how the system is interpreting his/her gestures. Additionally, the PIs are developing a cross-disciplinary undergraduate and graduate course that focuses on developing sensing systems while being cognizant of the actual needs in a rehabilitation hospital. The PIs are also using local university initiatives to engage minority and women researchers in the project.</AbstractNarration>
<MinAmdLetterDate>07/31/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1407035</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Parkerson</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James P Parkerson</PI_FULL_NAME>
<EmailAddress>jparkers@uark.edu</EmailAddress>
<PI_PHON>4795756039</PI_PHON>
<NSF_ID>000357062</NSF_ID>
<StartDate>07/31/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arkansas</Name>
<CityName>Fayetteville</CityName>
<ZipCode>727013124</ZipCode>
<PhoneNumber>4795753845</PhoneNumber>
<StreetAddress>1125 W. Maple Street</StreetAddress>
<StreetAddress2><![CDATA[316 Administration Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arkansas</StateName>
<StateCode>AR</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AR03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>191429745</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARKANSAS SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>055600001</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arkansas]]></Name>
<CityName>Fayetteville</CityName>
<StateCode>AR</StateCode>
<ZipCode>727011201</ZipCode>
<StreetAddress><![CDATA[504 J B Hunt Transportation Ctr.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arkansas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8061</Code>
<Text>SCH Type I:  EXP</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~145417</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>1. Capacitive Sensor Design</strong></p> <p>The developed capacitive sensor arrays used for locality tracking in assistive technologies are fabricated with copper tape, indium tin oxide (ITO) coated polyethylene terephthalate (PET) sheets, and printed circuit boards (PCBs). We explored Manhattan, diamond, and comb-shaped mutual capacitive sensor array designs and achieved robust capacitive sensing results.</p> <p><strong>2. Remote Rehabilitation Monitoring with Capacitive Sensor Array</strong></p> <p>Two versions of remote rehabilitation monitoring systems were designed. The second version achieved a higher resolution for capacitive touch sensing with a performing area of 40 X 40 cm<sup>2</sup>.</p> <p>2.1. Web- and app-based rehabilitation monitoring system</p> <p>2.1.1. Hardware design</p> <p>A rehabilitation assistant system equipped with a capacitor sensor array (CSA) for persons exhibiting upper-extremity motor impairments was constructed. The CSA utilizes mutual capacitance to quantize patients&rsquo; hand motions on a rehabilitation activity board. The rehabilitation board is equipped with an accelerometer to measure the slope of the activity board, since different inclinations of motions may affect the motor quality. An MSP430FR2633 MCU is used to measure capacitance changes. A secondary microcontroller, an ATmega 328P, is used to retrieve capacitive sensor and accelerometer data, and transfer data via Bluetooth to a web-capable edge device, Raspberry Pi. The edge device hosts a webpage displaying the patient's hand positions and the slope position of the activity board to enable visual feedback.</p> <p>&nbsp;</p> <p>2.1.2. Android mobile app-based graphical user interface (GUI)</p> <p>Rehabilitation research app is an android application that allows patients to connect their rehabilitation devices to their mobile phone to have a more interactive way of performing rehabilitation exercise. The app shows the user how they should move their hands by illuminating the sensors they should touch, and it shows how the user is performing the actions.</p> <p>&nbsp;</p> <p>2.2. Processing-based rehabilitation monitoring system</p> <p>2.2.1. Hardware system structure</p> <p>The hardware of the second version of the capacitive sensing based rehabilitation system contains an 8 X 8 CSA, a Raspberry Pi, a capacitive sensing circuit, and a host microcontroller. This system was shipped to Madonna Rehabilitation Hospital for further evaluation.</p> <p>&nbsp;</p> <p>2.2.2. Processing based user interface and remote access</p> <p>To visualize the hand motion performed over the constructed mutual capacitive sensor array, a Java-based graphical user interface (GUI) was designed. This is achieved by utilizing a &nbsp;microcontroller as a host controller to obtain the capacitance changes from the capacitance-to-digital converter through I2C communication protocol and pass the data to a Raspberry Pi via serial communication.</p> <p>To communicate the data collected from the FR2676 MCU, the raspberry pi requires knowing which port the communication occurs. Therefore, a python script was written to automatically choose the serial port and enable to communication between the RPi and the MCU without any issue. A Wi-Fi hotspot functionally is added to the Raspberry Pi to make it easier for physicians to have access to the Raspberry pi user interface. This removes the need to handle firewall protection from the medical institution while giving the physicians all access to the system potential and data control.&nbsp;&nbsp;&nbsp;</p> <p><strong>&nbsp;</strong></p> <p><strong>3. Capacitance-to-Digital Circuit Designs</strong></p> <p>To utilize the capacitive sensor array for gesture tracking and dynamic gesture classification, capacitance-to-digital converters from Texas Instruments, MSP430FR26XX are adopted. These converters are essentially 16-bit microcontrollers with dedicated capacitance-to-digital conversion modules using charge transfer technology. Two development boards, respectively featuring MSP430FR2633 and MSP430FR2676, are designed for measuring the capacitance changes of the capacitive sensors. The designed bare-bone FR2633 development board is tested to achieve lower power consumption by only preserving the capacitive sensing and serial communication functionalities, compared to the Captivate-FR2633 device. The development board based on MSP430FR2676 requires further investigation since they are just received from a manufacturer.</p> <p>&nbsp;</p> <p><strong>4. Gesture Recognition with Deep Learning Technique</strong></p> <p>4.1. Long short-term memory (LSTM) neural network</p> <p>LSTM models are trained in Matlab to obtain learnable parameters of the neural networks. The LSTM based gesture recognition intervention algorithm is implemented in a digital signal processor, to realize real-time gesture classification. A display is used to show the corresponding hand position with respect to the rehabilitation table. The four LEDs representing a binary coded decimal indicate real-time classification results.</p> <p>&nbsp;</p> <p>4.2. Convolutional LSTM (C-LSTM) Method</p> <p>For gesture recognition, a convolutional long short-term memory (C-LSTM) neural network structure is investigated and hyper-parameters are varied to determine what resources are necessary to perform classification tasks. Hand motions cause changes in the electric field that is quantified through electrodes. To identify low computation cost models for the C-LSTM neural network, we evaluated different numbers of capacitor sensors, kernels, convolutional layers, and hidden nodes. Six subjects performed four pre-defined bimanual gestures 50 times per gesture, and the accuracy metrics are calculated using five-fold cross-validation. This work lays groundwork to establish a sufficient number of parameters for building a standalone real-time gesture classification system, which could be deployed in a rehabilitative setting to validate that patients are compliant and performing motions correctly.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/08/2019<br>      Modified by: James&nbsp;P&nbsp;Parkerson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ 1. Capacitive Sensor Design  The developed capacitive sensor arrays used for locality tracking in assistive technologies are fabricated with copper tape, indium tin oxide (ITO) coated polyethylene terephthalate (PET) sheets, and printed circuit boards (PCBs). We explored Manhattan, diamond, and comb-shaped mutual capacitive sensor array designs and achieved robust capacitive sensing results.  2. Remote Rehabilitation Monitoring with Capacitive Sensor Array  Two versions of remote rehabilitation monitoring systems were designed. The second version achieved a higher resolution for capacitive touch sensing with a performing area of 40 X 40 cm2.  2.1. Web- and app-based rehabilitation monitoring system  2.1.1. Hardware design  A rehabilitation assistant system equipped with a capacitor sensor array (CSA) for persons exhibiting upper-extremity motor impairments was constructed. The CSA utilizes mutual capacitance to quantize patients? hand motions on a rehabilitation activity board. The rehabilitation board is equipped with an accelerometer to measure the slope of the activity board, since different inclinations of motions may affect the motor quality. An MSP430FR2633 MCU is used to measure capacitance changes. A secondary microcontroller, an ATmega 328P, is used to retrieve capacitive sensor and accelerometer data, and transfer data via Bluetooth to a web-capable edge device, Raspberry Pi. The edge device hosts a webpage displaying the patient's hand positions and the slope position of the activity board to enable visual feedback.     2.1.2. Android mobile app-based graphical user interface (GUI)  Rehabilitation research app is an android application that allows patients to connect their rehabilitation devices to their mobile phone to have a more interactive way of performing rehabilitation exercise. The app shows the user how they should move their hands by illuminating the sensors they should touch, and it shows how the user is performing the actions.     2.2. Processing-based rehabilitation monitoring system  2.2.1. Hardware system structure  The hardware of the second version of the capacitive sensing based rehabilitation system contains an 8 X 8 CSA, a Raspberry Pi, a capacitive sensing circuit, and a host microcontroller. This system was shipped to Madonna Rehabilitation Hospital for further evaluation.     2.2.2. Processing based user interface and remote access  To visualize the hand motion performed over the constructed mutual capacitive sensor array, a Java-based graphical user interface (GUI) was designed. This is achieved by utilizing a  microcontroller as a host controller to obtain the capacitance changes from the capacitance-to-digital converter through I2C communication protocol and pass the data to a Raspberry Pi via serial communication.  To communicate the data collected from the FR2676 MCU, the raspberry pi requires knowing which port the communication occurs. Therefore, a python script was written to automatically choose the serial port and enable to communication between the RPi and the MCU without any issue. A Wi-Fi hotspot functionally is added to the Raspberry Pi to make it easier for physicians to have access to the Raspberry pi user interface. This removes the need to handle firewall protection from the medical institution while giving the physicians all access to the system potential and data control.        3. Capacitance-to-Digital Circuit Designs  To utilize the capacitive sensor array for gesture tracking and dynamic gesture classification, capacitance-to-digital converters from Texas Instruments, MSP430FR26XX are adopted. These converters are essentially 16-bit microcontrollers with dedicated capacitance-to-digital conversion modules using charge transfer technology. Two development boards, respectively featuring MSP430FR2633 and MSP430FR2676, are designed for measuring the capacitance changes of the capacitive sensors. The designed bare-bone FR2633 development board is tested to achieve lower power consumption by only preserving the capacitive sensing and serial communication functionalities, compared to the Captivate-FR2633 device. The development board based on MSP430FR2676 requires further investigation since they are just received from a manufacturer.     4. Gesture Recognition with Deep Learning Technique  4.1. Long short-term memory (LSTM) neural network  LSTM models are trained in Matlab to obtain learnable parameters of the neural networks. The LSTM based gesture recognition intervention algorithm is implemented in a digital signal processor, to realize real-time gesture classification. A display is used to show the corresponding hand position with respect to the rehabilitation table. The four LEDs representing a binary coded decimal indicate real-time classification results.     4.2. Convolutional LSTM (C-LSTM) Method  For gesture recognition, a convolutional long short-term memory (C-LSTM) neural network structure is investigated and hyper-parameters are varied to determine what resources are necessary to perform classification tasks. Hand motions cause changes in the electric field that is quantified through electrodes. To identify low computation cost models for the C-LSTM neural network, we evaluated different numbers of capacitor sensors, kernels, convolutional layers, and hidden nodes. Six subjects performed four pre-defined bimanual gestures 50 times per gesture, and the accuracy metrics are calculated using five-fold cross-validation. This work lays groundwork to establish a sufficient number of parameters for building a standalone real-time gesture classification system, which could be deployed in a rehabilitative setting to validate that patients are compliant and performing motions correctly.             Last Modified: 10/08/2019       Submitted by: James P Parkerson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
