<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Strong Consistency for Personal and Collaborative Object Stores</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The objective of this proposal is to provide users of multiple, possibly mobile, devices with storage systems that provide strong consistency guarantees for replicated data.  When users access their data through multiple devices it is important that data updates made through one device are reflected in the data viewed through others.  The project will study and implement consistency and consensus protocols to enable these guarantees for individuals and collaborative groups.&lt;br/&gt;&lt;br/&gt;The work includes several major components including the definition, validation, and parameterization of a user model; the definition of a system structure allowing strong separation of layers while ensuring key system properties; and the design and optimization of new protocols. The potential audience for this work includes users of online storage systems and related stand-alone tools for replicating work across multiple devices.</AbstractNarration>
<MinAmdLetterDate>08/04/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422578</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Keleher</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter J Keleher</PI_FULL_NAME>
<EmailAddress>keleher@cs.umd.edu</EmailAddress>
<PI_PHON>3014050345</PI_PHON>
<NSF_ID>000278516</NSF_ID>
<StartDate>08/04/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The first part of our work on this grant is in describing "federated consistency", which allows construction of large heterogeneous systems. Federated replicas implement different consistency protocols in response to local policies and requirements.&nbsp;We have shown that a federated consistency protocol can find a middle ground in the trade-off between performance and consistency, particularly between an eventually consistent system implemented via gossip-based anti-entropy and a sequential consistency model implemented by the Raft consensus protocol.&nbsp;</p> <p>The second major thrust of this work was in designing an approach to providing linearizable ordering to geo-replicated systems through Hierarchical Consensus (HC). One use of HC is for the inner core of a federated system. We consider the problem of using distributed consensus to support linearizable access orderings for objects stores or global file systems. Our target environments include geo-replicated machines across the Internet with no guarantees on bandwidth, latency, or lack of partitions. We further wish to accommodate replicas with heterogeneous capabilities and usage modalities, such as systems including both highly-provisioned servers and mobile devices. This problem space is important, as it encompasses a wide variety of usages, from agglomerations of the environments assumed by previous systems down to ad hoc systems of local and personal devices.<br />We propose another approach to building large systems. Rather than relying on a few replicas to provide consensus to many clients, we propose to run a consensus protocol across replicas running at or near all of those locations. The key insight of this work is that large problem spaces can often be partitioned into mostly disjoint sets of activity without violating consistency. We exploit this decomposition property by making our consensus protocol hierarchical, and individual consensus groups fast by ensuring they are small. We exploit locality by building designing the protocol to have subquorums made from co-located replicas, and locating subquorums near clients they serve.</p> <p>INTELLECTUAL MERIT</p> <ol> <li>&nbsp;We describe how to federate systems with different consistency requirements.1) We describe Hierarchical Consensus, a two-tiered consensus structure that allows high throughput, localization, agility, and linearizable access to a shared namespace.&nbsp;</li> <li>We show how to use delegation to build large consensus groups that retain their fault tolerance properties while performing like small groups.</li> <li>We describe the use of fuzzy epoch transitions to allow global re-configurations across multiple consensus groups without forcing them into lockstep.</li> <li>We describe how to build a linearizable key-value store whose consensus group makeup and object namespace can be rapidly re-assigned across the entire group.</li> <li>We build a sequentially-consistent replicated log from geo-replicated subquorum logs.</li> </ol> <p>&nbsp;</p> <p>BROADER IMPACT</p> <p>Federated consistency and hierarchical consensus provide a foundation for building large-scale systems across dynamic and heterogeneous environments, not just curated data centers.</p><br> <p>            Last Modified: 12/29/2017<br>      Modified by: Peter&nbsp;J&nbsp;Keleher</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The first part of our work on this grant is in describing "federated consistency", which allows construction of large heterogeneous systems. Federated replicas implement different consistency protocols in response to local policies and requirements. We have shown that a federated consistency protocol can find a middle ground in the trade-off between performance and consistency, particularly between an eventually consistent system implemented via gossip-based anti-entropy and a sequential consistency model implemented by the Raft consensus protocol.   The second major thrust of this work was in designing an approach to providing linearizable ordering to geo-replicated systems through Hierarchical Consensus (HC). One use of HC is for the inner core of a federated system. We consider the problem of using distributed consensus to support linearizable access orderings for objects stores or global file systems. Our target environments include geo-replicated machines across the Internet with no guarantees on bandwidth, latency, or lack of partitions. We further wish to accommodate replicas with heterogeneous capabilities and usage modalities, such as systems including both highly-provisioned servers and mobile devices. This problem space is important, as it encompasses a wide variety of usages, from agglomerations of the environments assumed by previous systems down to ad hoc systems of local and personal devices. We propose another approach to building large systems. Rather than relying on a few replicas to provide consensus to many clients, we propose to run a consensus protocol across replicas running at or near all of those locations. The key insight of this work is that large problem spaces can often be partitioned into mostly disjoint sets of activity without violating consistency. We exploit this decomposition property by making our consensus protocol hierarchical, and individual consensus groups fast by ensuring they are small. We exploit locality by building designing the protocol to have subquorums made from co-located replicas, and locating subquorums near clients they serve.  INTELLECTUAL MERIT   We describe how to federate systems with different consistency requirements.1) We describe Hierarchical Consensus, a two-tiered consensus structure that allows high throughput, localization, agility, and linearizable access to a shared namespace.  We show how to use delegation to build large consensus groups that retain their fault tolerance properties while performing like small groups. We describe the use of fuzzy epoch transitions to allow global re-configurations across multiple consensus groups without forcing them into lockstep. We describe how to build a linearizable key-value store whose consensus group makeup and object namespace can be rapidly re-assigned across the entire group. We build a sequentially-consistent replicated log from geo-replicated subquorum logs.      BROADER IMPACT  Federated consistency and hierarchical consensus provide a foundation for building large-scale systems across dynamic and heterogeneous environments, not just curated data centers.       Last Modified: 12/29/2017       Submitted by: Peter J Keleher]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
