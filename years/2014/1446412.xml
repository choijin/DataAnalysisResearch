<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Exploring the Foundations of High-Level Programming Models for GPUs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>274660.00</AwardTotalIntnAmount>
<AwardAmount>274660</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Modern Graphics-Processor Units (GPUs) are capable of performance that, just a few years ago, would have been classified as supercomputer-level. With the trend of integrating GPU cores into heterogeneous multicore processors, GPUs are becoming an important source of future performance growth in mainstream processors.  Unfortunately, GPUs are notoriously hard to program.  The standard languages for programming GPUs expose low-level architectural details, such as an explicit memory hierarchy, which the programmer must exploit to maximize performance. Furthermore, GPU hardware evolves rapidly, with successive generations of hardware having different performance characteristics, which means that application code must be constantly revised to achieve optimal performance.&lt;br/&gt;&lt;br/&gt;To make the power of GPUs, accelerators, and heterogeneous architectures more widely applicable, programming models need to lift the level of abstraction away from the details of the hardware threading and memory models.  This EAGER project identifies common abstractions and implementation techniques that can provide a foundation for supporting irregular computations on accelerator and heterogeneous architectures.  A key focus of the project is the design of a core calculus of heterogeneity that can model programs that run on heterogeneous systems, such as CPU/GPU combinations, and provide a foundation for future work in both the semantics and implementation of parallel programming languages for GPUs. The results of the project broaden the applicability of GPUs to a wider range of computational problems and, in turn, will help make GPUs useful to a broader community of users by supporting higher-level programming models for GPUs that are easier to use than existing languages.</AbstractNarration>
<MinAmdLetterDate>08/26/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1446412</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Reppy</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John H Reppy</PI_FULL_NAME>
<EmailAddress>jhr@cs.uchicago.edu</EmailAddress>
<PI_PHON>7737025534</PI_PHON>
<NSF_ID>000115461</NSF_ID>
<StartDate>08/26/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Todd</FirstName>
<LastName>Dupont</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Todd F Dupont</PI_FULL_NAME>
<EmailAddress>dupont@cs.uchicago.edu</EmailAddress>
<PI_PHON>7737023485</PI_PHON>
<NSF_ID>000374690</NSF_ID>
<StartDate>08/26/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606375418</ZipCode>
<StreetAddress><![CDATA[5734 S. University Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7798</Code>
<Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~274660</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This EAGER project was focused on exploring foundational ideas for making GPUs easier to program. &nbsp;GPUs provide super-computer-level performance at commodity prices, but programming them requires significant effort in tuning algorithms to perform well on their complicated programming model. &nbsp;The approach of the project was to focus on restricted programming models that could be be effectively targeted to efficient GPU execution, while, at the same time, lift the level of abstraction for programmers. &nbsp;The project explored three lines of research involving two domain-specific language (DSL) models, which can be effectively targeted to GPUS, and a lambda-calculus intermediate representation, which can support compiling nested data parallelism to GPUs.</p> <p>The first was Tesel, a language for interactive 3D graphics embedded into Apple's Swift language. &nbsp;Tesel's design was based on the concepts of functional-reactive programming (FRP) and extended the FRP programming paradigm to better support applications with very dynamic numbers of reactive components executing in parallel. Tesel is compiled to a mix of Swift and Metal (Apple's GPU programming language).</p> <p>The second line of research was compiler intermediate representations (IRs) for very-high-level mathematical languages. &nbsp;The project partially supported the development of an IR that allows compact representation of tensor computations. &nbsp;This work was done in the Diderot complier. &nbsp;Diderot is a DSL that supports a computational model based on tensor fields and tensors. &nbsp;This new IR has enabled a much more expressive programming model than before, with general support for higher-order expressions (<em>i.e.</em>, computations on tensor fields, rather than on first-order tensor values).</p> <p>The third line of research focused on compiler techniques for nested data parallelism on GPUs. &nbsp;Specifically, we developed a new IR for representing such programs that is based on second-order array combinators. &nbsp;This IR is a concise design that supports both a rich set of surface-language operations and an effective collection of kernel fusions and other optimizations. &nbsp;Furthermore, it promises to be "future proof" in that we believe that it can handle a number of optimization techniques that we have identified as promising, but have not yet implemented.</p> <p>Over the course of the project, three graduate students, including two from under-represented groups were involved. &nbsp;This EAGER has provided the foundation for two continuing NSF-funded research projects (one focused on Diderot and the other on nested data parallelism for GPUs).</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/18/2018<br>      Modified by: John&nbsp;H&nbsp;Reppy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This EAGER project was focused on exploring foundational ideas for making GPUs easier to program.  GPUs provide super-computer-level performance at commodity prices, but programming them requires significant effort in tuning algorithms to perform well on their complicated programming model.  The approach of the project was to focus on restricted programming models that could be be effectively targeted to efficient GPU execution, while, at the same time, lift the level of abstraction for programmers.  The project explored three lines of research involving two domain-specific language (DSL) models, which can be effectively targeted to GPUS, and a lambda-calculus intermediate representation, which can support compiling nested data parallelism to GPUs.  The first was Tesel, a language for interactive 3D graphics embedded into Apple's Swift language.  Tesel's design was based on the concepts of functional-reactive programming (FRP) and extended the FRP programming paradigm to better support applications with very dynamic numbers of reactive components executing in parallel. Tesel is compiled to a mix of Swift and Metal (Apple's GPU programming language).  The second line of research was compiler intermediate representations (IRs) for very-high-level mathematical languages.  The project partially supported the development of an IR that allows compact representation of tensor computations.  This work was done in the Diderot complier.  Diderot is a DSL that supports a computational model based on tensor fields and tensors.  This new IR has enabled a much more expressive programming model than before, with general support for higher-order expressions (i.e., computations on tensor fields, rather than on first-order tensor values).  The third line of research focused on compiler techniques for nested data parallelism on GPUs.  Specifically, we developed a new IR for representing such programs that is based on second-order array combinators.  This IR is a concise design that supports both a rich set of surface-language operations and an effective collection of kernel fusions and other optimizations.  Furthermore, it promises to be "future proof" in that we believe that it can handle a number of optimization techniques that we have identified as promising, but have not yet implemented.  Over the course of the project, three graduate students, including two from under-represented groups were involved.  This EAGER has provided the foundation for two continuing NSF-funded research projects (one focused on Diderot and the other on nested data parallelism for GPUs).                Last Modified: 01/18/2018       Submitted by: John H Reppy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
