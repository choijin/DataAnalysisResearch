<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Assistive Digital Vision for the Blind</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>172500</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project seeks to implement state-of-the art image processing algorithms designed to identify objects amidst a complex background, which currently require high power computer processing resources, onto an embedded device, which would allow the capability to be used in small, portable, and affordable devices. The project further aims to include an obstacle avoidance algorithm to identify objects within a specific range. This high-risk research promises wide-ranging benefits, with the focus to be on creation of an assistive digital vision technology. The main objectives of the proposed effort include: 1) integrating a camera and sonar onto a commercially available embedded device; 2) development of an obstacle detection/avoidance algorithm for the sonar sensor and successfully implementing it into the embedded device; 3) customization of object identification / recognition algorithms for the camera sensor to implement them into the embedded device. Success will be evaluated by measuring performance of the resultant breadboard device in its ability to detect objects at various distances, and to recognize three common objects against a cluttered background. The goal and expected result is to exceed a probability of detection of 80%.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project is enabling blind people to develop a more comprehensive mental picture of their surrounding and improving their situational awareness. There are 39 million visually impaired people living around the world. Guide dogs and white canes are the preferred mobility aids, but there is little else available to them that is both user-friendly and affordable. The envisaged technology will be compatible with the white cane and will alert the user to the presence of above ground obstacles, such as traffic and sign poles and overhanging objects. In addition, the object identification will further allow the user to develop a more comprehensive mental picture of his surroundings and improve his mobility. While other navigation support products are in the high hundreds to thousands of dollars, the technology proposed herein is expected to be commercialized in a product available for less than $200, thus allowing it to make a broad impact to the wide population of the visually impaired. The resultant technology that contains embedded camera and sonar technologies in a portable device may also contribute to the field of robotics and artificial intelligence, wherein a better understanding of the environment will support new decision-making algorithms.</AbstractNarration>
<MinAmdLetterDate>05/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>12/17/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1415653</AwardID>
<Investigator>
<FirstName>Arman</FirstName>
<LastName>Ghodousi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arman Ghodousi</PI_FULL_NAME>
<EmailAddress>arman@g-technologygroup.com</EmailAddress>
<PI_PHON>4805443192</PI_PHON>
<NSF_ID>000660677</NSF_ID>
<StartDate>05/20/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ghodousi LLC</Name>
<CityName>Alexandria</CityName>
<ZipCode>223120000</ZipCode>
<PhoneNumber>4805443192</PhoneNumber>
<StreetAddress>5702 General Washington DR.</StreetAddress>
<StreetAddress2><![CDATA[Suite G]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079168015</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GHODOUSI, LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ghodousi LLC]]></Name>
<CityName>Alexandria</CityName>
<StateCode>VA</StateCode>
<ZipCode>223102656</ZipCode>
<StreetAddress><![CDATA[6803 Oregano Ln]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>163E</Code>
<Text>SBIR Phase IB</Text>
</ProgramReference>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~150000</FUND_OBLG>
<FUND_OBLG>2015~22500</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Research in the field of digital vision has resulted in a breadboard system capable of detecting obstacles and recognizing objects in an embedded device.&nbsp; Obstacle detection is achieved with an integrated sonar device that operates on the principle of echolocation.&nbsp; Two object recognition software platforms were investigated to identify one that would most efficiently conform to the small size, and limited computing power and storage capacity typical of embedded devices.&nbsp; The effort required specifically developing and tailoring the algorithms for an embedded device and testing recognition accuracies for a variety of objects.&nbsp; Recognition accuracies as high as 98% were achieved, and results may be augmented by increasing camera resolution for objects further away from the camera.&nbsp; In addition, the high recognition accuracies attained for some objects may be obtained for others through more robust algorithm training, without compromising processing times.&nbsp; Processing times, currently around 40 seconds, may be increased by an order of magnitude with further refinements to the algorithm, which will be one focus of the next research phase.&nbsp; Currently 59 general classes of objects can be identified using the breadboard system, and the ease of expandability and generalization of multiple classes of interest suggest the system represents a highly versatile platform that can quickly and efficiently transitioned into products requiring object recognition in embedded devices.&nbsp; The research has contributed to the field of digital vision, particularly in applications requiring portability, and may further contribute to other fields such as artificial intelligence, robotics, and homeland security.</p><br> <p>            Last Modified: 07/02/2015<br>      Modified by: Arman&nbsp;Ghodousi</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2015/1415653/1415653_10303975_1435889246249_2070dogs-top--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1415653/1415653_10303975_1435889246249_2070dogs-top--rgov-800width.jpg" title="Object recognition algorithm performance"><img src="/por/images/Reports/POR/2015/1415653/1415653_10303975_1435889246249_2070dogs-top--rgov-66x44.jpg" alt="Object recognition algorithm performance"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Left: Original Image;   Middle: Given (true) labels;   Right: Highest confidence net output</div> <div class="imageCredit">Ghodousi Technologies</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Arman&nbsp;Ghodousi</div> <div class="imageTitle">Object recognition algorithm performance</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Research in the field of digital vision has resulted in a breadboard system capable of detecting obstacles and recognizing objects in an embedded device.  Obstacle detection is achieved with an integrated sonar device that operates on the principle of echolocation.  Two object recognition software platforms were investigated to identify one that would most efficiently conform to the small size, and limited computing power and storage capacity typical of embedded devices.  The effort required specifically developing and tailoring the algorithms for an embedded device and testing recognition accuracies for a variety of objects.  Recognition accuracies as high as 98% were achieved, and results may be augmented by increasing camera resolution for objects further away from the camera.  In addition, the high recognition accuracies attained for some objects may be obtained for others through more robust algorithm training, without compromising processing times.  Processing times, currently around 40 seconds, may be increased by an order of magnitude with further refinements to the algorithm, which will be one focus of the next research phase.  Currently 59 general classes of objects can be identified using the breadboard system, and the ease of expandability and generalization of multiple classes of interest suggest the system represents a highly versatile platform that can quickly and efficiently transitioned into products requiring object recognition in embedded devices.  The research has contributed to the field of digital vision, particularly in applications requiring portability, and may further contribute to other fields such as artificial intelligence, robotics, and homeland security.       Last Modified: 07/02/2015       Submitted by: Arman Ghodousi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
