<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collective behavior of human crowds</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>396935.00</AwardTotalIntnAmount>
<AwardAmount>416735</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Whether walking down a busy sidewalk or a crowded mall, we effortlessly coordinate our movements with other pedestrians.  Sometimes we weave through the crowd, dodging our neighbors; at other times we merge into a coherent "swarm," much like a flock of birds or a school of fish, and may spontaneously form lanes in opposite directions, similar to columns of ants.  Where do these basic traffic patterns come from?  It is generally believed that collective behavior in humans and animals emerges from local interactions between neighbors, rather than from a central plan or leader, but the actual mechanisms are unclear.  By studying the perceptual-motor "rules" that govern interactions between neighbors, the investigator aims to determine whether crowd behavior can be explained by local interactions.  The resulting model will enable realistic simulation of pedestrian traffic flow. Its potential broader impacts are  to architectural design, evacuation planning, computer animation, and the development of assistive technology for blind and low-vision users. &lt;br/&gt;&lt;br/&gt;There are many models of collective swarm behavior in fields ranging from physics and computer science to animal behavior and urban planning, yet they are based on little experimental data.  The key weakness of existing theories is a dearth of knowledge about the visual coupling between neighbors -- the perceptual-motor rules, forces, or control laws that govern pedestrian interactions. The goal of this project is to develop a cognitively grounded pedestrian model and test the hypothesis that global crowd behavior emerges from these local interactions.  An innovative research program combines (a) a local-to-global approach, in which the visual coupling is mapped out in experiments with virtual crowds, and used to predict crowd behavior in multi-agent simulations, and (b) a global-to-local approach, in which experiments on real crowds are analyzed and used to test the model. The aim is to account for pedestrian and crowd dynamics and elucidate the relation between "micro" and "macro" levels of collective behavior.</AbstractNarration>
<MinAmdLetterDate>08/08/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1431406</AwardID>
<Investigator>
<FirstName>William</FirstName>
<LastName>Warren</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME>Jr.</PI_SUFX_NAME>
<PI_FULL_NAME>William H Warren</PI_FULL_NAME>
<EmailAddress>Bill_Warren@brown.edu</EmailAddress>
<PI_PHON>4018633980</PI_PHON>
<NSF_ID>000271218</NSF_ID>
<StartDate>08/08/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129093</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Projects]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~396935</FUND_OBLG>
<FUND_OBLG>2016~19800</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><em>Intellectual Merit</em></p> <p>It is often said that the collective behavior of human crowds emerges from local interactions between pedestrians, but the nature of these interactions has been unknown. This project developed the first models of collective crowd motion based on human experiments, which account for both individual trajectories and crowd dynamics.</p> <p>We began by building a ?behavioral model? that predicts the walking direction and speed of a pedestrian based on the movement of surrounding neighbors.&nbsp; Using Virtual Reality (VR) experiments in which a real human participant walked in crowd of virtual avatars, we identified two <em>rules of interaction:</em>&nbsp; a pedestrian tends to match the direction and speed of their neighbors.&nbsp; We then mapped the zone over which these rules operate, the <em>neighborhood of interaction</em>, and discovered that a pedestrian is influenced by:</p> <ul> <li>Neighbors within a 180&#730; field of view</li> <li>All neighbors within a fixed distance (a ?metric? neighborhood), not by a fixed number of neighbors (a ?topological? neighborhood)</li> <li>But this influence decreases with neighbor distance</li> <li>With a gradual decay <em>to</em> the nearest neighbor in the crowd, and a faster decay <em>within</em> the crowd (a ?donut? neighborhood)</li> </ul> <p>Based on these findings, we modeled the neighborhood using a <em>weighted average</em> of neighbors, where the weight decays exponentially with distance.&nbsp; The model successfully simulated data from our VR experiments, and predicted individual trajectories in data on real crowds.&nbsp; Importantly, the model implies a mechanism of self-organization: a pedestrian more strongly aligns with neighbors who are more closely aligned with each other, providing a positive feedback that generates collective motion.&nbsp; Simulations of the model generate coherent motion over a wide range of conditions.</p> <p>And yet pedestrians interact by means of vision, so a better model would be based on the visual information available to a pedestrian embedded in a crowd.&nbsp; Further VR experiments identified the optical variables used by a pedestrian to control their walking speed and direction:</p> <ul> <li>The visual expansion/contraction of each neighbor in the field of view </li> <li>The angular velocity of each neighbor in the field of view</li> <li>The influence of each variable on walking speed and walking direction trades off, depending on the neighbor?s position in the field of view (eccentricity)</li> </ul> <p>Based on these results, we created a ?visual model? that simply <em>averages</em> these variables for all neighbors, as a function of neighbor eccentricity.&nbsp; The visual model not only fits the human data as well or better than the behavioral model, it also explains the decrease of neighbor influence with distance (the ?donut?) for free:</p> <ul> <li>The gradual decay to the nearest neighbor is a consequence of the law of perspective</li> <li>The faster decay within a crowd is due to an added effect of visual occlusion of far neighbors by near neighbors</li> </ul> <p>Our experiment-driven approach thus generated the first realistic behavioral model of self-organized collective motion, and the first visual model of crowd motion grounded in human perceptual-motor control.&nbsp;</p> <p><em>Broader Impacts</em></p> <p>A better understanding of crowd behavior has many practical benefits to society.&nbsp; A particularly important area of impact is emergency evacuations.&nbsp; To study evacuation behavior experimentally, we developed a VR paradigm that puts the participant in a virtual emergency without compromising their safety.&nbsp; This research yielded the first experimental tests of anecdotal observations about social and familiarity effects:</p> <ul> <li>In a fire evacuation, people tend to follow their neighbors to an exit ? more strongly as the number of neighbors increases (social influence)</li> <li>People tend to egress through the door by which they entered (familiarity)</li> <li>These two tendencies are additive, suggesting that exit jams could be reduced by making use of multiple entrances</li> <li>When two exits are visible, people tend to follow the majority of the crowd to one exit, unless 100% of the crowd forms a visible jam at that exit</li> <li>People prefer to egress to green exit signs, compared to other colors ? even though they believe exit signs should be red and signs in their state are red</li> </ul> <p>A realistic model of crowd behavior would significantly improve evacuation planning by simulating pedestrian traffic flow in potential emergency situations.&nbsp; Such a model could also be used in architecture and urban planning to test alternative designs by simulating pedestrian traffic in buildings and public spaces.&nbsp; We presented our model at the NSF Workshop on Human-Building Interaction (USC, June 2019), where computer scientists and architects discussed the use of pedestrian models in architecture and planning.</p> <p>Another area of impact is the design of new assistive technology.&nbsp; People who are blind or have low vision report mobility as one of the most difficult challenges of daily life, particularly walking in crowds and using public transportation.&nbsp; We recently received funding from the National Eye Institute to develop a navigation system that would apply our pedestrian model to guide the user through complex environments and crowds by means of a vibrotactile belt.</p><br> <p>            Last Modified: 10/27/2019<br>      Modified by: William&nbsp;H&nbsp;Warren</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572209379878_Swarm_Heading_HeatMaps--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572209379878_Swarm_Heading_HeatMaps--rgov-800width.jpg" title="Heat Maps of Human 'Swarm'"><img src="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572209379878_Swarm_Heading_HeatMaps--rgov-66x44.jpg" alt="Heat Maps of Human 'Swarm'"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Mean difference in walking direction (deg) between central participant and each neighbor, as they walked around randomly while staying together. Left: High density (1m interpersonal distance).  Right: Low density (2 m).  Three groups (N=10, 16, 20), 6 min of data total.</div> <div class="imageCredit">William H. Warren</div> <div class="imageSubmitted">William&nbsp;H&nbsp;Warren</div> <div class="imageTitle">Heat Maps of Human 'Swarm'</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572208916261_Neighborhood_BehavModel--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572208916261_Neighborhood_BehavModel--rgov-800width.jpg" title="Behavioral Model of Neighborhood"><img src="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572208916261_Neighborhood_BehavModel--rgov-66x44.jpg" alt="Behavioral Model of Neighborhood"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A pedestrian is influenced by all neighbors within the field of view, where influence decreases exponentially with distance out to 4-5 m.</div> <div class="imageCredit">Proceedings of the Royal Society, 2018</div> <div class="imageSubmitted">William&nbsp;H&nbsp;Warren</div> <div class="imageTitle">Behavioral Model of Neighborhood</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572209899826_Swarm_Trial_seg15_BehavioralModel--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572209899826_Swarm_Trial_seg15_BehavioralModel--rgov-800width.jpg" title="Behavioral Model Predicts Trajectory in Swarm"><img src="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572209899826_Swarm_Trial_seg15_BehavioralModel--rgov-66x44.jpg" alt="Behavioral Model Predicts Trajectory in Swarm"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Simulation (blue) of individual trajectory (red) in human crowd data, treating neighbors (black) as input to the model.  Left: path in space.  Center: time series of walking speed.  Right: time series of walking direction.</div> <div class="imageCredit">Proceedings of the Royal Society, 2018</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">William&nbsp;H&nbsp;Warren</div> <div class="imageTitle">Behavioral Model Predicts Trajectory in Swarm</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572210039265_Neighborhood_VisionModel_diag--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572210039265_Neighborhood_VisionModel_diag--rgov-800width.jpg" title="Visual Model of Neighborhood"><img src="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572210039265_Neighborhood_VisionModel_diag--rgov-66x44.jpg" alt="Visual Model of Neighborhood"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Pedestrian is influenced by the optical expansion and angular velocity of all neighbors in field of view.  These variables are used to control walking speed or direction, depending on the neighbor's eccentricity.</div> <div class="imageCredit">William H. Warren</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">William&nbsp;H&nbsp;Warren</div> <div class="imageTitle">Visual Model of Neighborhood</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572210138093_Swarm_Trial1_VisionModel3--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572210138093_Swarm_Trial1_VisionModel3--rgov-800width.jpg" title="Vision Model Predicts Trajectory in Swarm"><img src="/por/images/Reports/POR/2019/1431406/1431406_10330463_1572210138093_Swarm_Trial1_VisionModel3--rgov-66x44.jpg" alt="Vision Model Predicts Trajectory in Swarm"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Simulation (blue) of individual trajectory (red) in human crowd data, treating neighbors (black) as input to the vision model.  Left: path in space.  Center: time series of walking speed.  Right: time series of walking direction.</div> <div class="imageCredit">William H. Warren</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">William&nbsp;H&nbsp;Warren</div> <div class="imageTitle">Vision Model Predicts Trajectory in Swarm</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit  It is often said that the collective behavior of human crowds emerges from local interactions between pedestrians, but the nature of these interactions has been unknown. This project developed the first models of collective crowd motion based on human experiments, which account for both individual trajectories and crowd dynamics.  We began by building a ?behavioral model? that predicts the walking direction and speed of a pedestrian based on the movement of surrounding neighbors.  Using Virtual Reality (VR) experiments in which a real human participant walked in crowd of virtual avatars, we identified two rules of interaction:  a pedestrian tends to match the direction and speed of their neighbors.  We then mapped the zone over which these rules operate, the neighborhood of interaction, and discovered that a pedestrian is influenced by:  Neighbors within a 180&#730; field of view All neighbors within a fixed distance (a ?metric? neighborhood), not by a fixed number of neighbors (a ?topological? neighborhood) But this influence decreases with neighbor distance With a gradual decay to the nearest neighbor in the crowd, and a faster decay within the crowd (a ?donut? neighborhood)   Based on these findings, we modeled the neighborhood using a weighted average of neighbors, where the weight decays exponentially with distance.  The model successfully simulated data from our VR experiments, and predicted individual trajectories in data on real crowds.  Importantly, the model implies a mechanism of self-organization: a pedestrian more strongly aligns with neighbors who are more closely aligned with each other, providing a positive feedback that generates collective motion.  Simulations of the model generate coherent motion over a wide range of conditions.  And yet pedestrians interact by means of vision, so a better model would be based on the visual information available to a pedestrian embedded in a crowd.  Further VR experiments identified the optical variables used by a pedestrian to control their walking speed and direction:  The visual expansion/contraction of each neighbor in the field of view  The angular velocity of each neighbor in the field of view The influence of each variable on walking speed and walking direction trades off, depending on the neighbor?s position in the field of view (eccentricity)   Based on these results, we created a ?visual model? that simply averages these variables for all neighbors, as a function of neighbor eccentricity.  The visual model not only fits the human data as well or better than the behavioral model, it also explains the decrease of neighbor influence with distance (the ?donut?) for free:  The gradual decay to the nearest neighbor is a consequence of the law of perspective The faster decay within a crowd is due to an added effect of visual occlusion of far neighbors by near neighbors   Our experiment-driven approach thus generated the first realistic behavioral model of self-organized collective motion, and the first visual model of crowd motion grounded in human perceptual-motor control.   Broader Impacts  A better understanding of crowd behavior has many practical benefits to society.  A particularly important area of impact is emergency evacuations.  To study evacuation behavior experimentally, we developed a VR paradigm that puts the participant in a virtual emergency without compromising their safety.  This research yielded the first experimental tests of anecdotal observations about social and familiarity effects:  In a fire evacuation, people tend to follow their neighbors to an exit ? more strongly as the number of neighbors increases (social influence) People tend to egress through the door by which they entered (familiarity) These two tendencies are additive, suggesting that exit jams could be reduced by making use of multiple entrances When two exits are visible, people tend to follow the majority of the crowd to one exit, unless 100% of the crowd forms a visible jam at that exit People prefer to egress to green exit signs, compared to other colors ? even though they believe exit signs should be red and signs in their state are red   A realistic model of crowd behavior would significantly improve evacuation planning by simulating pedestrian traffic flow in potential emergency situations.  Such a model could also be used in architecture and urban planning to test alternative designs by simulating pedestrian traffic in buildings and public spaces.  We presented our model at the NSF Workshop on Human-Building Interaction (USC, June 2019), where computer scientists and architects discussed the use of pedestrian models in architecture and planning.  Another area of impact is the design of new assistive technology.  People who are blind or have low vision report mobility as one of the most difficult challenges of daily life, particularly walking in crowds and using public transportation.  We recently received funding from the National Eye Institute to develop a navigation system that would apply our pedestrian model to guide the user through complex environments and crowds by means of a vibrotactile belt.       Last Modified: 10/27/2019       Submitted by: William H Warren]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
