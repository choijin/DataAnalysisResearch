<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Robust Estimation for Structured Covariance Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>119999.00</AwardTotalIntnAmount>
<AwardAmount>119999</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The need to analyze multivariate data arises in many diverse disciplines, such as computer science and engineering, signal processing, psychology, meteorology, chemometrics, sociology, and biology. Due to the changing methods for collecting data, the number of variables or attributes measured in a single observation or for a single subject are becoming exceptionally large, and they can be considerably larger than the number of observations or subjects themselves. Such data sets are commonly referred to as large sparse data sets. For such data sets, the possibility of recording bad data points or outliers is increasingly likely. Outliers tend to have a disproportionate impact on the interpretation of the data unless one uses robust methods, that is, methods that can accommodate bad data. Developing methods to analyze large sparse data sets has become a major research topic within the field of statistics. There has been, however, relatively little attention given to the development of robust methods for large sparse data sets, which is the primary goal of this research project. The research project aims to produce fundamental results, theoretical approaches and statistical methods applicable to the robust analysis of large sparse data sets, upon which other researchers can build.&lt;br/&gt;&lt;br/&gt;Most robust multivariate statistical methods are mainly applicable whenever the sample size is considerably larger than the number of variables, and are not particularly applicable to large sparse data sets. In particular, for sample sizes that are modest relative to the number of variables, robust affine equivariant estimates of multivariate location and scatter are similar in performance to the classical sample mean vector and sample covariance matrix, and consequently do not yield robust results for such data sets. Analyzing relatively sparse multivariate data tends to require either presuming certain covariance structures, such as those arising in graphical models, factor analysis or other reduced rank models, or developing methods which give preference to certain covariance structures via regularization methods. These special covariance structures are usually not considered in most robust multivariate methods. To address this shortcoming, the research project aims to develop robust methods which take into account a presumed covariance structure, and in particular to develop and study direct M-estimation methods and S-estimation methods for structured covariance models, as well as to develop and study penalized M-estimates of the covariance matrix. Addressing robustness issues for structured covariance models and for penalization methods are fundamental problems which is more mathematically and computationally challenging than in the classical setting or in the unrestricted robust estimation setting. Here, some recent work on geodesic convexity within the signal processing community is expected to play an important role in addressing these problems.</AbstractNarration>
<MinAmdLetterDate>08/07/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1407751</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Tyler</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David E Tyler</PI_FULL_NAME>
<EmailAddress>david.tyler@rutgers.edu</EmailAddress>
<PI_PHON>7324452691</PI_PHON>
<NSF_ID>000223188</NSF_ID>
<StartDate>08/07/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName/>
<StateCode>NJ</StateCode>
<ZipCode>089018559</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~43668</FUND_OBLG>
<FUND_OBLG>2015~37736</FUND_OBLG>
<FUND_OBLG>2016~38595</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The need to analyze multivariate data arises in many diverse disciplines, such as computer science, engineering, meteorology, chemometrics, psychology, sociology, biology, and genetics, among others. A primary goal of multivariate statistical analysis is to model and understand the complex interrelationships between different measurements or variables. With current trends in the sciences, an increasingly common occurrence is the collection of large amounts of information on each individual sample point or experimental unit, even though the number of sample points or experimental units themselves may remain relatively small. This results in an extremely large number of parameters or interrelationships between variables to consider, but with insufficient data to adequately estimate these relationships using standard multivariate methods. One outcome of this research project was the introduction of novel estimation methods for such high dimensional data under the aforementioned setting.</p> <p>Another issue which arises when many measurements are recorded on each sample point is that large errors or outliers may occur in the measurements. This makes the conclusion based on classical statistical methods suspect if the outliers are not detected. &nbsp;For high dimensional data, though, detecting outliers is known to be problematic, and so an alternative is to use robust statistical methods, i.e. methods which produce valid conclusions even if the data contains bad data points. Previously existing robust methods, however, are not particularly effective in higher dimensions whenever the sample size is limited. Consequently, another important outcome of the research project was the developments of robust statistical methods for high dimensional data which are applicable even when the sample size is relatively small.&nbsp;</p> <p>In developing these above noted methods, new theoretical tools and results were obtained, and efficient algorithms were developed for computing the proposed statistical methods. &nbsp;Application of these methods to problems in signal processing has been successfully demonstrated within the research project. Finally, the theory and computational algorithms for these methods relied heavily on the mathematical concept of geodesic convexity. To obtain some of the outcomes in the research project, new mathematical results on geodesic convexity were also proven.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/26/2018<br>      Modified by: David&nbsp;E&nbsp;Tyler</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The need to analyze multivariate data arises in many diverse disciplines, such as computer science, engineering, meteorology, chemometrics, psychology, sociology, biology, and genetics, among others. A primary goal of multivariate statistical analysis is to model and understand the complex interrelationships between different measurements or variables. With current trends in the sciences, an increasingly common occurrence is the collection of large amounts of information on each individual sample point or experimental unit, even though the number of sample points or experimental units themselves may remain relatively small. This results in an extremely large number of parameters or interrelationships between variables to consider, but with insufficient data to adequately estimate these relationships using standard multivariate methods. One outcome of this research project was the introduction of novel estimation methods for such high dimensional data under the aforementioned setting.  Another issue which arises when many measurements are recorded on each sample point is that large errors or outliers may occur in the measurements. This makes the conclusion based on classical statistical methods suspect if the outliers are not detected.  For high dimensional data, though, detecting outliers is known to be problematic, and so an alternative is to use robust statistical methods, i.e. methods which produce valid conclusions even if the data contains bad data points. Previously existing robust methods, however, are not particularly effective in higher dimensions whenever the sample size is limited. Consequently, another important outcome of the research project was the developments of robust statistical methods for high dimensional data which are applicable even when the sample size is relatively small.   In developing these above noted methods, new theoretical tools and results were obtained, and efficient algorithms were developed for computing the proposed statistical methods.  Application of these methods to problems in signal processing has been successfully demonstrated within the research project. Finally, the theory and computational algorithms for these methods relied heavily on the mathematical concept of geodesic convexity. To obtain some of the outcomes in the research project, new mathematical results on geodesic convexity were also proven.          Last Modified: 11/26/2018       Submitted by: David E Tyler]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
