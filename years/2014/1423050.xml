<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: EvalFest (Evaluation Use, Value and Learning through Festivals of Science and Technology)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>178995.00</AwardTotalIntnAmount>
<AwardAmount>202752</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Russell</SignBlockName>
<PO_EMAI>rlrussel@nsf.gov</PO_EMAI>
<PO_PHON>7032922995</PO_PHON>
</ProgramOfficer>
<AbstractNarration>EvalFest (Evaluation Use, Value, and Learning through Festivals of Science and Technology) will test innovative evaluation methods in science festivals that are being held across the country and assess in what ways and how effectively they are used. Morehead Planetarium and Science Center (at the University of North Carolina-Chapel Hill) and the University of California, San Francisco, in collaboration with over twenty science festivals, will (1) investigate whether a multisite evaluation approach is an effective model for creating common metrics for informal STEM education, (2) develop common methods to measure the effects of Festivals, (3) create a query-able database of 50,000 Festival attendees to share with the informal STEM learning field, and (4) document whether these efforts also result in new knowledge related to informal STEM education. &lt;br/&gt;&lt;br/&gt;The project will develop the Enterprise Feedback Management (EFM) system and query-able database for the festival community. EFMs are systems, including processes and software, that enable groups (such as the festival network) to collect, organize, analyze and share data. The EFM system will be designed to integrate data across sites and to allow users to extract data of interest. The project will refine evaluation tools currently used within the Science Festival Alliance that assess self-reported festival learning, and the effects of festival attendance, motivation, and future science participation. It will collect economic impact data and longitudinal festival attendee data. The project will also develop some new evaluation tools such as secret shopper observational protocols. Data from festival attendees will be collected onsite at participating festivals.</AbstractNarration>
<MinAmdLetterDate>08/05/2014</MinAmdLetterDate>
<MaxAmdLetterDate>09/10/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1423050</AwardID>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Nielsen</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katherine M Nielsen</PI_FULL_NAME>
<EmailAddress>katherine.nielsen@ucsf.edu</EmailAddress>
<PI_PHON>4155025137</PI_PHON>
<NSF_ID>000460409</NSF_ID>
<StartDate>08/05/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Francisco</Name>
<CityName>San Francisco</CityName>
<ZipCode>941034249</ZipCode>
<PhoneNumber>4154762977</PhoneNumber>
<StreetAddress>1855 Folsom St Ste 425</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>094878337</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, SAN FRANCISCO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Francisco]]></Name>
<CityName>San Francisco</CityName>
<StateCode>CA</StateCode>
<ZipCode>941432200</ZipCode>
<StreetAddress><![CDATA[100 Medical Center Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7259</Code>
<Text>AISL</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0418</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~68683</FUND_OBLG>
<FUND_OBLG>2016~72614</FUND_OBLG>
<FUND_OBLG>2018~61455</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The Morehead Planetarium and Science Center (UNC-Chapel Hill), University of California at San Francisco and Karen Peterman Consulting led EvalFest (Evaluation Use, Value, and Learning through Festivals of Science and Technology), an AISL project for Research in&#8232; Service to Practice. EvalFest created a community of practice that developed, tested, and shared evaluation approaches for science festivals and other public science events. Over the five-year award, 25 festivals participated; 22 festivals were a part of the community for all five years.</p> <p>EvalFest sought to answer three research questions. One, how are evaluations used in relation to science festivals and how does evaluation use change within the context of a community of practice that creates its own multisite evaluation? Two, which methods and reporting formats are associated with the greatest value in building capacity of individual festivals? And, finally, in what ways can a community-created multisite evaluation yield additional learning about public science events in particular and informal science education events in general?</p> <p>When EvalFest began in 2014, there were approximately 30 science festivals in the Science Festival Alliance and thus the EvalFest community composed the majority of US science festivals. EvalFest was designed and timed to support the development of evaluation practice within the festival field, when the field was beginning to grow in the US.</p> <p>EvalFest has contributed significantly to the science festival, informal science, and evaluation fields. The EvalFest team has made 17 conference presentations, published five articles and has others in process, and has been invited to support efforts led by the American Association for the Advancement of Science (AAAS), Center for Advancement of Informal Science Education (CAISE), American Academy of Arts and Science, and the Association of Science &amp; Technology Centers, among others.</p> <p>EvalFest has also developed and shared a suite of resources designed to support evaluation in informal science settings. These resources include instruments, checklists and guides for visually representing data, Survey Monkey and QuickTap tutorials, and sample consent forms. &nbsp;Training videos have also been developed. These brief, easily accessible videos cover a range of topics such as survey collection, consent, observation and interview methods, data management, statistics, and data analysis. All resources are available for free on the EvalFest website.</p><br> <p>            Last Modified: 12/18/2019<br>      Modified by: Katherine&nbsp;M&nbsp;Nielsen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Morehead Planetarium and Science Center (UNC-Chapel Hill), University of California at San Francisco and Karen Peterman Consulting led EvalFest (Evaluation Use, Value, and Learning through Festivals of Science and Technology), an AISL project for Research in&#8232; Service to Practice. EvalFest created a community of practice that developed, tested, and shared evaluation approaches for science festivals and other public science events. Over the five-year award, 25 festivals participated; 22 festivals were a part of the community for all five years.  EvalFest sought to answer three research questions. One, how are evaluations used in relation to science festivals and how does evaluation use change within the context of a community of practice that creates its own multisite evaluation? Two, which methods and reporting formats are associated with the greatest value in building capacity of individual festivals? And, finally, in what ways can a community-created multisite evaluation yield additional learning about public science events in particular and informal science education events in general?  When EvalFest began in 2014, there were approximately 30 science festivals in the Science Festival Alliance and thus the EvalFest community composed the majority of US science festivals. EvalFest was designed and timed to support the development of evaluation practice within the festival field, when the field was beginning to grow in the US.  EvalFest has contributed significantly to the science festival, informal science, and evaluation fields. The EvalFest team has made 17 conference presentations, published five articles and has others in process, and has been invited to support efforts led by the American Association for the Advancement of Science (AAAS), Center for Advancement of Informal Science Education (CAISE), American Academy of Arts and Science, and the Association of Science &amp; Technology Centers, among others.  EvalFest has also developed and shared a suite of resources designed to support evaluation in informal science settings. These resources include instruments, checklists and guides for visually representing data, Survey Monkey and QuickTap tutorials, and sample consent forms.  Training videos have also been developed. These brief, easily accessible videos cover a range of topics such as survey collection, consent, observation and interview methods, data management, statistics, and data analysis. All resources are available for free on the EvalFest website.       Last Modified: 12/18/2019       Submitted by: Katherine M Nielsen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
