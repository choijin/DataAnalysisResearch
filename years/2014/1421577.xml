<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: A Time-Predictable Integrated CPU-GPU Architecture for Hard Real-Time Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>607000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Massive and energy-efficient computation capability, coupled with the enhanced programmability, makes Graphics Processing Units (GPUs) a desirable platform to accelerate a variety of data-intensive hard real-time applications such as medical data processing, autonomous auto navigation, and vision-based aircraft controls. The computer industry has already delivered several GPUs for embedded computing applications. However, none of these GPUs can guarantee time predictability, which is crucial for hard real-time systems. The integration of the CPU and the GPU on the same die makes it even more challenging to attain time predictability.  The goal of this project is to fill this need, though investigation of the design of time-predictable integrated CPU-GPU architectures that can also offer high performance and energy efficiency.&lt;br/&gt;&lt;br/&gt;The project addresses this problem by: (i) systematic analysis and evaluation of time-unpredictability of GPUs and integrated CPU-GPUs; (ii) exploration of time-predictable and heterogeneous last-level cache (LLC) architectures for integrated CPU-GPUs, including private, partitioned, and locked LLCs; (iii) design of time-predictable and heterogeneous on-chip interconnection networks that can efficiently support communications within and across the CPUs and GPU; (iv) design of time-predictable memory controllers to enable scalable, safe, and tight WCET (Worst-Case Execution Time) estimation; (v) development of the first WCET analyzer for the proposed integrated CPU-GPU processor to support hard real-time computing.  Other project activities include efforts to transition the results of the research to industry, integration of topics and projects related to the research in courses, and open-source distribution of software.</AbstractNarration>
<MinAmdLetterDate>09/02/2014</MinAmdLetterDate>
<MaxAmdLetterDate>11/20/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421577</AwardID>
<Investigator>
<FirstName>Wei</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wei Zhang</PI_FULL_NAME>
<EmailAddress>wei.zhang@louisville.edu</EmailAddress>
<PI_PHON>5028520715</PI_PHON>
<NSF_ID>000227345</NSF_ID>
<StartDate>09/02/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Commonwealth University</Name>
<CityName>RICHMOND</CityName>
<ZipCode>232980568</ZipCode>
<PhoneNumber>8048286772</PhoneNumber>
<StreetAddress>P.O. Box 980568</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>105300446</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VIRGINIA COMMONWEALTH UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>105300446</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Virginia Commonwealth University]]></Name>
<CityName/>
<StateCode>VA</StateCode>
<ZipCode>232843072</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~500000</FUND_OBLG>
<FUND_OBLG>2016~91000</FUND_OBLG>
<FUND_OBLG>2019~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we have studied the time predictability as well as the energy efficiency of the integrated CPU-GPU architecture for hard real-time computing. Due to the massive parallel computing capability, GPUs are increasingly used in hard real-time data parallel processing. However, to meet the safety and stringent real-time requirements, it is imperative to estimate the worst-case execution time (WCET) safely and accurately. The current GPU architectural trend towards the integrated CPU-GPU introduces inter-core interferences between CPU and GPU cores, which further complicates the WCET analysis and time predictability. Moreover, it is important to conduct energy-efficient GPU computing for real-time applications that are typically under energy or battery constraints.</p> <p>To mitigate the inter-core interferences between CPU and GPU on the shared last-level cache and on-chip network, this project&nbsp;studies a probability-based&nbsp;cache control, which can be used in conjunction with the virtual channel partitioning to reduce the&nbsp;impact of GPU interferences on CPU performance and its time predictability. This project also explores&nbsp;several novel&nbsp;GPU cache bypassing and cache hierarchy management approaches for the integrated CPU-GPU architecture. To mitigate the complexity of GPU timing analysis,&nbsp;this project also examines the time-predictable execution model and architectural support for GPUs. Moreover, this project also studies several efficient energy management techniques&nbsp;to reduce the leakage and dynamic energy of GPU register files, functional units, and cache memories. This project has involved both graduate&nbsp;and undergraduate students, and the results&nbsp;have&nbsp;been published in numerous refereed journals and conference proceedings.&nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/20/2019<br>      Modified by: Wei&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we have studied the time predictability as well as the energy efficiency of the integrated CPU-GPU architecture for hard real-time computing. Due to the massive parallel computing capability, GPUs are increasingly used in hard real-time data parallel processing. However, to meet the safety and stringent real-time requirements, it is imperative to estimate the worst-case execution time (WCET) safely and accurately. The current GPU architectural trend towards the integrated CPU-GPU introduces inter-core interferences between CPU and GPU cores, which further complicates the WCET analysis and time predictability. Moreover, it is important to conduct energy-efficient GPU computing for real-time applications that are typically under energy or battery constraints.  To mitigate the inter-core interferences between CPU and GPU on the shared last-level cache and on-chip network, this project studies a probability-based cache control, which can be used in conjunction with the virtual channel partitioning to reduce the impact of GPU interferences on CPU performance and its time predictability. This project also explores several novel GPU cache bypassing and cache hierarchy management approaches for the integrated CPU-GPU architecture. To mitigate the complexity of GPU timing analysis, this project also examines the time-predictable execution model and architectural support for GPUs. Moreover, this project also studies several efficient energy management techniques to reduce the leakage and dynamic energy of GPU register files, functional units, and cache memories. This project has involved both graduate and undergraduate students, and the results have been published in numerous refereed journals and conference proceedings.            Last Modified: 10/20/2019       Submitted by: Wei Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
