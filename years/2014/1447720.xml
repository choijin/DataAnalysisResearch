<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: F: DKM: Collaborative Research: Making Big Data Active: From Petabytes to Megafolks in Milliseconds</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>784380.00</AwardTotalIntnAmount>
<AwardAmount>784380</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A wealth of digital information is being generated daily through social networks, blogs, online communities, news sources, and mobile applications in an increasingly sensed world. Organizations and researchers recognize that tremendous value and insight can be gained by capturing this emerging data and making it available for querying and analysis. First-generation Big Data management efforts have been passive in nature -- queries, updates, and/or analysis tasks were mainly scaled to handle very large volumes of data. In contrast, this project will develop new techniques for continuously and reliably capturing Big Data collections (arising from social, mobile, Web, and sensed data sources) and will enable timely delivery of the right information to the relevant end users. In short, this project will provide a scalable foundation for moving from Big Passive Data to Big Active Data. Techniques should be developed to enable the accumulation and monitoring of petabytes of data of potential interest to millions of end users; when "interesting" new data appears, it should be delivered to end users in a time frame measured in (100's of) milliseconds. This project will build such an Active Big Data Management system and make it available as open source to the community. Students will be trained in technologies related to Big Active Data management and applications; such training is critical to addressing the information explosion that social media and the mobile Web are driving today. The general-purpose foundation for active information dissemination from Big Data will have broader impacts in areas such as public safety and public health. &lt;br/&gt;&lt;br/&gt;There are many challenges involved in building a foundation for Big Active Data. On the "data in" side, these include resource management in very large scale, LSM-based storage systems and the provision of a highly available, elastic facility for fast data ingestion. On the "data processing" side, challenges include the parallel evaluation of a large number of declarative data subscriptions over multiple) highly partitioned data sets. Amplifying this challenge is a need to efficiently support spatial, temporal, and similarity predicates in data subscriptions. Big Data also makes result ranking and diversification techniques critical in order for large result sets to be manageable. On the "data out" side, challenges include the reliable and timely dissemination of data of interest to a sometimes-connected subscriber base of unprecedented scale. As a software base, this project will be jump-started by using AsterixDB(http://asterixdb.ics.uci.edu/), an open-source Big Data Management System that supports the scalable storage, searching, and analysis of mass quantities of semi-structured data. &lt;br/&gt;&lt;br/&gt;For further information see the project web sites at https://www.ics.uci.edu/BigActiveData and http://www.cs.ucr.edu/~tsotras/BigActiveData</AbstractNarration>
<MinAmdLetterDate>08/26/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1447720</AwardID>
<Investigator>
<FirstName>Nalini</FirstName>
<LastName>Venkatasubramanian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nalini Venkatasubramanian</PI_FULL_NAME>
<EmailAddress>nalini@ics.uci.edu</EmailAddress>
<PI_PHON>9498245898</PI_PHON>
<NSF_ID>000315745</NSF_ID>
<StartDate>08/26/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Carey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Carey</PI_FULL_NAME>
<EmailAddress>mjcarey@ics.uci.edu</EmailAddress>
<PI_PHON>4083156414</PI_PHON>
<NSF_ID>000512443</NSF_ID>
<StartDate>08/26/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926173067</ZipCode>
<StreetAddress><![CDATA[4199 Campus Dr Ste 300 (CompSci)]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramReference>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~784380</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>First-generation Big Data management efforts brought frameworks such as Hadoop and Spark that focus on after-the-fact data analytics, document stores that provide scalable key-based record storage and retrieval, and a handful of specialized systems for problems like graph analytics and data stream analysis. The BAD project has aimed to continuously and reliably capture Big Data arising from social, mobile, Web, and sensed data sources and enable timely delivery of information to users with indicated interests. Our aim was to develop techniques to enable the accumulation and monitoring of petabytes of data of potential interest to millions of end users; when "interesting" new data appears, it should be delivered to end users in a timeframe measured in (100's of) milliseconds. The effort involved challenges related to parallel databases, Big Data platforms, stream data management, and publish/subscribe systems. It required scaling out solutions to individual problems as well as creating a coherent overall software architecture.</p> <p>A priori requirements driving the project were:</p> <ul> <li>Incoming data items might not be important in isolation, but in their relationship(s) to other items in the data. Subscriptions must therefore consider data in context, not just the newly arriving items' content.</li> <li>Important information may be missing in the incoming items, instead existing elsewhere within the data as a whole. Results delivered to users must be enriched with other data to provide actionable information to each user.</li> <li>Historical queries and analyses over collected data often yields important insights. Retrospective Big Data analytics must therefore be supported as well.</li> </ul> <p>Based on those requirements, we designed, built, and evaluated components of a BAD Platform prototype - based on extending Apache AsterixDB - including:</p> <ul> <li>A user model and language based on parameterized, query-based channels that actively deliver data of interest to interested channel subscribers.</li> <li>Optimizations to AsterixDB to support rapid continuous data ingestion, and development of an "Active Toolkit" to extend AsterixDB with additional capabilities to support BAD, including richer data feeds and a variety of optimizations to support a scalable subscriber base.</li> <li>A distributed Broker Network that coordinates and manages a large volume of end-user data subscriptions and results, including caching and load balancing mechanisms to support a highly scalable user base.</li> </ul> <p>To summarize the project's technology contributions, we have championed a novel Big Data paradigm, Big Active Data, that merges Big Data Management with active data handling capabilities. We built a BAD system prototype, starting from a modern Big Data Platform (Apache AsterixDB), and have demonstrated that it can outperform passive Big Data by an order (or two) of magnitude in practical scenarios. The BAD system is able to consider data in context and to enrich results in ways unavailable in other platforms, and in addition allows for retrospective Big Data analytics. The code (over 20,000 LOC) is available as an open-source Apache project.</p> <p>Big Data and information dissemination technologies like BAD are crucial for the next generation of computer science students. Working on this project, and with the artifacts that it has produced, has enabled such training at UCI, UCR, and elsewhere.&nbsp; Multiple undergraduate and graduate students have gone on to jobs in industry (at Google, Amazon, Facebook, LinkedIn, and others) and the BAD postdoctoral researcher is now an Assistant Professor of CS at a US research university. In terms of society, the technology developed in this project has potential societal benefits for usage in domains such as public health, national security, and public safety.</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/22/2019<br>      Modified by: Michael&nbsp;Carey</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1447720/1447720_10338412_1569186295159_sys--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1447720/1447720_10338412_1569186295159_sys--rgov-800width.jpg" title="BAD Platform Overview"><img src="/por/images/Reports/POR/2019/1447720/1447720_10338412_1569186295159_sys--rgov-66x44.jpg" alt="BAD Platform Overview"></a> <div class="imageCaptionContainer"> <div class="imageCaption">BAD Platform components cover two areas of functionality -- Big Data monitoring and management, handled by the BAD Data Cluster, and user notification management and distribution, handled by the BAD Broker Network.</div> <div class="imageCredit">Co-PI Vagelis Hristidis</div> <div class="imageSubmitted">Michael&nbsp;Carey</div> <div class="imageTitle">BAD Platform Overview</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ First-generation Big Data management efforts brought frameworks such as Hadoop and Spark that focus on after-the-fact data analytics, document stores that provide scalable key-based record storage and retrieval, and a handful of specialized systems for problems like graph analytics and data stream analysis. The BAD project has aimed to continuously and reliably capture Big Data arising from social, mobile, Web, and sensed data sources and enable timely delivery of information to users with indicated interests. Our aim was to develop techniques to enable the accumulation and monitoring of petabytes of data of potential interest to millions of end users; when "interesting" new data appears, it should be delivered to end users in a timeframe measured in (100's of) milliseconds. The effort involved challenges related to parallel databases, Big Data platforms, stream data management, and publish/subscribe systems. It required scaling out solutions to individual problems as well as creating a coherent overall software architecture.  A priori requirements driving the project were:  Incoming data items might not be important in isolation, but in their relationship(s) to other items in the data. Subscriptions must therefore consider data in context, not just the newly arriving items' content. Important information may be missing in the incoming items, instead existing elsewhere within the data as a whole. Results delivered to users must be enriched with other data to provide actionable information to each user. Historical queries and analyses over collected data often yields important insights. Retrospective Big Data analytics must therefore be supported as well.   Based on those requirements, we designed, built, and evaluated components of a BAD Platform prototype - based on extending Apache AsterixDB - including:  A user model and language based on parameterized, query-based channels that actively deliver data of interest to interested channel subscribers. Optimizations to AsterixDB to support rapid continuous data ingestion, and development of an "Active Toolkit" to extend AsterixDB with additional capabilities to support BAD, including richer data feeds and a variety of optimizations to support a scalable subscriber base. A distributed Broker Network that coordinates and manages a large volume of end-user data subscriptions and results, including caching and load balancing mechanisms to support a highly scalable user base.   To summarize the project's technology contributions, we have championed a novel Big Data paradigm, Big Active Data, that merges Big Data Management with active data handling capabilities. We built a BAD system prototype, starting from a modern Big Data Platform (Apache AsterixDB), and have demonstrated that it can outperform passive Big Data by an order (or two) of magnitude in practical scenarios. The BAD system is able to consider data in context and to enrich results in ways unavailable in other platforms, and in addition allows for retrospective Big Data analytics. The code (over 20,000 LOC) is available as an open-source Apache project.  Big Data and information dissemination technologies like BAD are crucial for the next generation of computer science students. Working on this project, and with the artifacts that it has produced, has enabled such training at UCI, UCR, and elsewhere.  Multiple undergraduate and graduate students have gone on to jobs in industry (at Google, Amazon, Facebook, LinkedIn, and others) and the BAD postdoctoral researcher is now an Assistant Professor of CS at a US research university. In terms of society, the technology developed in this project has potential societal benefits for usage in domains such as public health, national security, and public safety.          Last Modified: 09/22/2019       Submitted by: Michael Carey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
