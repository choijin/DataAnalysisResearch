<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRCNS: Collaborative Research: Naturalistic computation and signaling by neural populations in the primate retina</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>99785.00</AwardTotalIntnAmount>
<AwardAmount>99785</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Vision begins in the retina, where light is converted into electrical signals, processed to extract and compress visual information, and transmitted through the optic nerve to the brain.  Despite decades of research, a full understanding of these transformations remains incomplete.  In particular, most studies have documented specific properties of the responses of single retinal cells in isolation, using specialized artificial visual stimuli.  The research performed under this grant aims to develop a full, unified computational model of retinal processing, including spatial and temporal filtering, nonlinear transformations, and adaptation to local luminance and contrast, in complete populations of neurons.  The model will be tested by comparing its predictions to data from large-scale multi-electrode recordings of primate retinal ganglion cells (RGCs), verifying that it can mimic known retinal responses, and critically, testing its ability to explain responses to natural visual images, including the effects of fixational and saccadic eye movements.  The resulting model will provide a compact encapsulation of the "neural code" of the retina, which will serve as a substrate for understanding all subsequent visual processing in the brain.  In addition, the model will provide an essential component in the development of high-acuity retinal prostheses for people blinded by diseases of photoreceptor degeneration.  Finally, the model will offer a useful tool for the development and testing of new display technologies.&lt;br/&gt;&lt;br/&gt;The research has two main aims:  (1) Develop and test a model of nonlinear subunits in RGC populations-- No current model captures the effects of nonlinear computations in a complete sensory neural circuit.  The researchers will develop a model incorporating nonlinear subunits that captures the stimulus encoding properties of complete populations of RGCs at the resolution of photoreceptors, and will quantify the implications of these nonlinearities for encoding naturally-occurring visual stimuli. The researchers will develop methods to reliably fit the model to RGC responses to targeted stimuli that stringently constrain model structure, and verify model predictions in closed-loop experiments.  (2) Incorporate adaptation; test model with targeted and naturalistic stimuli-- RGC responses adapt to luminance and stimulus contrast.  No current model of the RGC population response incorporates adaptation with subunit nonlinearities, natural scenes, and eye movements. The researchers will incorporate adaptation in the model, fit the adaptive model using stochastic stimuli with varying mean and contrast, and test the model using stimuli that produce adaptation within and across subunits.</AbstractNarration>
<MinAmdLetterDate>08/18/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1430252</AwardID>
<Investigator>
<FirstName>Eero</FirstName>
<LastName>Simoncelli</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eero Simoncelli</PI_FULL_NAME>
<EmailAddress>eero.simoncelli@nyu.edu</EmailAddress>
<PI_PHON>2129983938</PI_PHON>
<NSF_ID>000218182</NSF_ID>
<StartDate>08/18/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100036603</ZipCode>
<StreetAddress><![CDATA[2-4 Washington Place]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7327</Code>
<Text>CRCNS-Computation Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>7327</Code>
<Text>CRCNS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~99785</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We have developed, tested, and made use of new computational models describing the primate retina. The retina transforms visual input into the electrical activity of fibers in the optical nerve, which sends the information to the brain, forming a bottleneck for all we see. &nbsp;Our models describe this transformation using equations that can be simulated on a computer, or built from electronic components.&nbsp;We've fit &nbsp;these models to measured responses of populations of retinal cells in monkey, and shown that they can accurately capture the responses of the cells under a range of different conditions. This provides an imporant building block for our undertanding of vision, on which models for subsequent transformations and processing in the brain can be built. &nbsp;We've also used them to develop solutions to engineering problems, such as quantifying the visibility of distortions or errors in visual images, and optimizing the appearance of images that are presented on display devices such as LCD screens or printers. Finally, we've developed methods for decoding the information transmitted by these cells to the brain, which allows us not only to better understand and visualize&nbsp;how faithfully a population of neurons represents the visual image, but also provides an important step in building retinal prosthetics for the blind.</p><br> <p>            Last Modified: 02/24/2019<br>      Modified by: Eero&nbsp;Simoncelli</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We have developed, tested, and made use of new computational models describing the primate retina. The retina transforms visual input into the electrical activity of fibers in the optical nerve, which sends the information to the brain, forming a bottleneck for all we see.  Our models describe this transformation using equations that can be simulated on a computer, or built from electronic components. We've fit  these models to measured responses of populations of retinal cells in monkey, and shown that they can accurately capture the responses of the cells under a range of different conditions. This provides an imporant building block for our undertanding of vision, on which models for subsequent transformations and processing in the brain can be built.  We've also used them to develop solutions to engineering problems, such as quantifying the visibility of distortions or errors in visual images, and optimizing the appearance of images that are presented on display devices such as LCD screens or printers. Finally, we've developed methods for decoding the information transmitted by these cells to the brain, which allows us not only to better understand and visualize how faithfully a population of neurons represents the visual image, but also provides an important step in building retinal prosthetics for the blind.       Last Modified: 02/24/2019       Submitted by: Eero Simoncelli]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
