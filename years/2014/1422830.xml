<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Small: Geometry and High-dimensional Inference</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>01/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rahul Shah</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Data analysis is ubiquitous in a broad range of application fields, from computer graphics to geographic information systems, from sensor networks to social networks, from economics to medicine. It represents a fundamental problem in computational science. The project will advance the theoretical understanding of fundamental issues behind data analysis, and develop practical algorithms that will be useful for a broad range of problems in science and engineering.&lt;br/&gt;&lt;br/&gt;The project addresses the fundamental problem of reconstructing structure of probability distributions from sampled data. It will investigate the use of tensor-based and other higher order methods, in particular those that allow for efficient optimization. The project lies at the interface of theoretical computer science, machine learning, signal processing and statistics and will have potential impact in all of these fields. In recent years there has been a resurgence of interest in tensor methods in data analysis and inference, particularly in theoretical computer science. These methods will prove useful in a variety of applications in machine learning, signal processing and other fields.&lt;br/&gt;&lt;br/&gt;The project will develop algorithms for solving a range of problems including blind source separation, spectral clustering, inference in mixture models and estimating geometry of distributions. It will analyze the complexity of these and related problems. In particular, it will strive to understand the computational efficiency  and dependence on the dimension of the space, studying "the curses and blessings of dimensionality". It will also address a somewhat mysterious discrepancy between sample and algorithmic complexity in our understanding of many high dimensional inference problems.&lt;br/&gt;&lt;br/&gt;The results of this work will be disseminated to the broad scientific community through publications in journals, conferences and presentations in various venues, including tutorials. The goals of this project include to implement the practical algorithms and to make the software available online. The research results will also be incorporated in the curriculum of graduate classes taught by the PI and the co-PI. Graduate students supported by this project will receive extensive training in theory, algorithm development and applications.</AbstractNarration>
<MinAmdLetterDate>07/25/2014</MinAmdLetterDate>
<MaxAmdLetterDate>04/25/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1422830</AwardID>
<Investigator>
<FirstName>Mikhail</FirstName>
<LastName>Belkin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mikhail Belkin</PI_FULL_NAME>
<EmailAddress>mbelkin@ucsd.edu</EmailAddress>
<PI_PHON>6148053884</PI_PHON>
<NSF_ID>000107334</NSF_ID>
<StartDate>04/25/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mikhail</FirstName>
<LastName>Belkin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mikhail Belkin</PI_FULL_NAME>
<EmailAddress>mbelkin@ucsd.edu</EmailAddress>
<PI_PHON>6148053884</PI_PHON>
<NSF_ID>000107334</NSF_ID>
<StartDate>07/25/2014</StartDate>
<EndDate>04/25/2017</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Luis</FirstName>
<LastName>Rademacher</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Luis Rademacher</PI_FULL_NAME>
<EmailAddress>lrademac@ucdavis.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000558524</NSF_ID>
<StartDate>07/25/2014</StartDate>
<EndDate>04/25/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101063</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~450000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The amount of data that we generate and collect grows at an accelerated pace. If we want to extract useful information from this data, we need better and better tools. One source of difficulty is the growing number of attributes or dimensionality, which makes data analysis computationally expensive. This research project started with the aim of developing better tools for the analysis of high-dimensional data. The proposed method is to use geometry as a way of understanding the structure of data, namely, to answer the question: What is the shape of our data?</p> <p><br />A central problem in data analysis is to find an insightful representation of the data. The geometry of this problem can be seen in the following analogous situation: In order to understand the shape of a three-dimensional object by looking at it from a particular angle, we may need to choose a good orientation of the object. In real-world data the number of attributes is commonly many more than three. The representation problem tends to become more difficult and relevant as the number of attributes grows. One of the main outcomes of this project is a unified framework to discover a good representation of a dataset. Among the representations considered are representations where the attributes behave independently (known as Independent Component Analysis). We provided and analyzed simple, yet general methods that have strong theoretical guarantees even when the data is corrupted by noise. We have also developed practical algorithms for the important problem of clustering, i.e., grouping objects together based on the similarities between their attributes.</p><br> <p>            Last Modified: 06/11/2018<br>      Modified by: Mikhail&nbsp;Belkin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The amount of data that we generate and collect grows at an accelerated pace. If we want to extract useful information from this data, we need better and better tools. One source of difficulty is the growing number of attributes or dimensionality, which makes data analysis computationally expensive. This research project started with the aim of developing better tools for the analysis of high-dimensional data. The proposed method is to use geometry as a way of understanding the structure of data, namely, to answer the question: What is the shape of our data?   A central problem in data analysis is to find an insightful representation of the data. The geometry of this problem can be seen in the following analogous situation: In order to understand the shape of a three-dimensional object by looking at it from a particular angle, we may need to choose a good orientation of the object. In real-world data the number of attributes is commonly many more than three. The representation problem tends to become more difficult and relevant as the number of attributes grows. One of the main outcomes of this project is a unified framework to discover a good representation of a dataset. Among the representations considered are representations where the attributes behave independently (known as Independent Component Analysis). We provided and analyzed simple, yet general methods that have strong theoretical guarantees even when the data is corrupted by noise. We have also developed practical algorithms for the important problem of clustering, i.e., grouping objects together based on the similarities between their attributes.       Last Modified: 06/11/2018       Submitted by: Mikhail Belkin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
