<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Obtaining Unbiased Math and Science Achievement Effect Estimates from Nonrandomized Studies</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>233660.00</AwardTotalIntnAmount>
<AwardAmount>233660</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11010000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DGE</Abbreviation>
<LongName>Division Of Graduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The researchers in this project will use large longitudinal datasets that include rich arrays of descriptive variables as well as measures of science and mathematics achievement to identify promising covariates that may eliminate or greatly reduce selection bias in nonrandomized estimates of program effects in research and evaluations of interventions or programs for K-12 students.  Simulated nonrandomized intervention and comparison groups with selection bias will be created from a selection of data from five de-identified, publically available longitudinal datasets. The researchers will then create propensity scores for each simulation based on the examination of the magnitude of the multiple correlations between covariates and the outcome and use these scores to assess how much of the selection bias they might eliminate. The identification of covariates that sufficiently account for enough selection bias so that the remaining selection bias might be ignored will strengthen the use of quasi-experimental study design in STEM education.&lt;br/&gt;&lt;br/&gt;Randomized control designs in STEM education are well known as being the strongest causal design with the ability to provide unbiased estimates of the effects of programs or interventions on intended outcomes. With an adequate sample size to minimize the likelihood of chance differences, random assignment can be expected to equate the experimental groups on all baseline characteristics that might influence the outcomes of interest. However, randomized experiments are not always possible in situations where the effects of STEM education programs are of interest. For many practical and occasionally, ethical reasons, nonrandomized comparison group designs are frequently used in STEM education research and evaluation studies. The findings of this study will provide empirical evidence of what covariate data should be collected to reduce selection bias in quasi-experimental designs.</AbstractNarration>
<MinAmdLetterDate>08/05/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1438331</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Lipsey</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark W Lipsey</PI_FULL_NAME>
<EmailAddress>mark.lipsey@vanderbilt.edu</EmailAddress>
<PI_PHON>6153432696</PI_PHON>
<NSF_ID>000347899</NSF_ID>
<StartDate>08/05/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kimberly</FirstName>
<LastName>Nesbitt</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kimberly Nesbitt</PI_FULL_NAME>
<EmailAddress>kimberly.nesbitt@vanderbilt.edu</EmailAddress>
<PI_PHON>6158756070</PI_PHON>
<NSF_ID>000667479</NSF_ID>
<StartDate>08/05/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Vanderbilt University</Name>
<CityName>Nashville</CityName>
<ZipCode>372350002</ZipCode>
<PhoneNumber>6153222631</PhoneNumber>
<StreetAddress>Sponsored Programs Administratio</StreetAddress>
<StreetAddress2><![CDATA[PMB 407749 2301 Vanderbilt Place]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<StateCode>TN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>965717143</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VANDERBILT UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004413456</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Vanderbilt University]]></Name>
<CityName>Nashville</CityName>
<StateCode>TN</StateCode>
<ZipCode>372122809</ZipCode>
<StreetAddress><![CDATA[1400 18th Avenue South]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7261</Code>
<Text>Project &amp; Program Evaluation</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~233660</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Researchers studying the effectiveness of STEM educational programs in K-12 school settings often must use research designs that are not as rigorous as desired because of practical constraints. One such design involves comparing achievement outcomes for students receiving the intervention of interest with a comparison group that does not receive that intervention under circumstances where the groups may differ in ways that would bias estimates of the effects of the intervention. These are generally referred to as quasi-experimental designs in contrast to experimental designs in which participants are randomly assigned to the different comparison conditions, a procedure that generally ensures that the groups will be equivalent. The bias that can affect quasi-experimental designs is known as selection bias. Researchers who use such designs must employ statistical techniques to minimize any selection bias.</p> <p>This project used several existing longitudinal databases to generate simulations of different amounts of selection bias for students in different grades and for different math and science achievement outcomes. Those simulations were then used to explore the ability of different techniques for reducing or eliminating the selection bias. Those techniques included different statistical and matching methods and, in particular, they were used to investigate the effectiveness of different baseline pre-intervention data a researcher might collect for use with those techniques. The most important summary findings across all the selection bias variants and techniques for addressing them were threefold. First, pretest measures of the achievement outcomes provide the most important data for reducing selection bias across all techniques. Second, other kinds of data, e.g., demographic, cognitive, and behavioral characteristics of the students and family background, can augment the pretest measures for reducing selection bias, but their additional contributions are modest. However, in the absence of pretest measures, a sufficiently rich set of such variables can be used to achieve substantial bias reduction, though not as much as the pretest provides. Third, there was little difference in bias reduction capability across a wide range of statistical analytic techniques for using the available data to reduce bias. Basic conventional ordinary least squares regression techniques worked as well in this context as much more sophisticated approaches. The variables available for the analysis play a much more important role than the analytic method used for math and science achievement outcomes of K-12 educational programs.</p><br> <p>            Last Modified: 11/30/2017<br>      Modified by: Mark&nbsp;W&nbsp;Lipsey</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Researchers studying the effectiveness of STEM educational programs in K-12 school settings often must use research designs that are not as rigorous as desired because of practical constraints. One such design involves comparing achievement outcomes for students receiving the intervention of interest with a comparison group that does not receive that intervention under circumstances where the groups may differ in ways that would bias estimates of the effects of the intervention. These are generally referred to as quasi-experimental designs in contrast to experimental designs in which participants are randomly assigned to the different comparison conditions, a procedure that generally ensures that the groups will be equivalent. The bias that can affect quasi-experimental designs is known as selection bias. Researchers who use such designs must employ statistical techniques to minimize any selection bias.  This project used several existing longitudinal databases to generate simulations of different amounts of selection bias for students in different grades and for different math and science achievement outcomes. Those simulations were then used to explore the ability of different techniques for reducing or eliminating the selection bias. Those techniques included different statistical and matching methods and, in particular, they were used to investigate the effectiveness of different baseline pre-intervention data a researcher might collect for use with those techniques. The most important summary findings across all the selection bias variants and techniques for addressing them were threefold. First, pretest measures of the achievement outcomes provide the most important data for reducing selection bias across all techniques. Second, other kinds of data, e.g., demographic, cognitive, and behavioral characteristics of the students and family background, can augment the pretest measures for reducing selection bias, but their additional contributions are modest. However, in the absence of pretest measures, a sufficiently rich set of such variables can be used to achieve substantial bias reduction, though not as much as the pretest provides. Third, there was little difference in bias reduction capability across a wide range of statistical analytic techniques for using the available data to reduce bias. Basic conventional ordinary least squares regression techniques worked as well in this context as much more sophisticated approaches. The variables available for the analysis play a much more important role than the analytic method used for math and science achievement outcomes of K-12 educational programs.       Last Modified: 11/30/2017       Submitted by: Mark W Lipsey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
