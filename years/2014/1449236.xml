<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: By the People, For the People: Community Ratings for App Privacy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>10/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>148025.00</AwardTotalIntnAmount>
<AwardAmount>148025</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Application stores use sophisticated user interfaces to help users understand the permissions sought by applications. Unfortunately, these interfaces are complex and may fail to address their goal of helping users give informed consent. As a result, users may inadvertently surrender private information or open themselves up to security attacks.&lt;br/&gt;&lt;br/&gt;This project tackles the problem of improving the nature of information provided by these interfaces. It focuses both on new interface designs that will better represent this information, and on techniques to bootstrap the provision of that information. On the user interface side, it designs new interfaces that help untrained users recognize the security and privacy consequences of the sought permissions. To populate this information, it posits the use of crowdsourcing to obtain information at scale about the suitability of permissions. The goal is to eventually populate an application store with this information to encourage adoption and additional feedback from users. The project will study how effectively and accurately crowdsourcing can be used to gather this information.</AbstractNarration>
<MinAmdLetterDate>08/20/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1449236</AwardID>
<Investigator>
<FirstName>Shriram</FirstName>
<LastName>Krishnamurthi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shriram Krishnamurthi</PI_FULL_NAME>
<EmailAddress>sk+17@cs.brown.edu</EmailAddress>
<PI_PHON>4018637722</PI_PHON>
<NSF_ID>000280993</NSF_ID>
<StartDate>08/20/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129002</ZipCode>
<StreetAddress><![CDATA[BOX 1929]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~148025</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Every day, literally millions of users worldwide are asked to make decisions about apps and about individual apps' permissions, decisions that have significant impacts on their privacy and more broadly well-being. However, the motivating premise of asking users is false. Users are presented with information and asked to consent, but that is not the same as true informed consent. Not being experts in the meaning of these permissions or their consequences, and being worn down by decision fatigue, users are unable to make sound decisions.</p> <p>This project set out to accomplish two tasks. First, it intended to create a mechanism for end-users to provide informed consent to app permission settings on their devices (such as smartphones and tablets). Second, it intended to examine the potential for crowdsourcing to provide this information.</p> <p>The project has accomplished both ends. It has explored the use of crowdsourcing and found that the crowd is capable of providing reasonable quality information. This is a useful finding because only automation or the use of large numbers of people can scale the provision of this knowledge, and automation is poor at context and nuance.</p> <p>The project has also leveraged this information to build two tools for helping users make decisions about apps. One tool is a privacy-enabled app search engine that ranks apps higher if they are more privacy-protecting. The other is an aid for apps already installed, by indicating which permissions should be turned off. The combination covers both use-cases that a user might encounter.</p> <p>The project has also had useful findings that are sub-points to or augmentations of the above. For instance, it has substantially explored the design of user interfaces for presenting rating information about permissions. It finds numerous subtleties, including quite surprising ones, in the design of such an interface, and arrives at designs that pass user interface evaluations. It has also investigated factors that might impact how people perceive and rate apps, such as the role of brands in user perceptions.</p> <p>This work is entirely driven by its potential for broader impact. It observes a problem with real-world systems, and identifies two tasks that can help address those problems. It has successfully executed both tasks, resulting in working systems as the manifestation.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/02/2017<br>      Modified by: Shriram&nbsp;Krishnamurthi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Every day, literally millions of users worldwide are asked to make decisions about apps and about individual apps' permissions, decisions that have significant impacts on their privacy and more broadly well-being. However, the motivating premise of asking users is false. Users are presented with information and asked to consent, but that is not the same as true informed consent. Not being experts in the meaning of these permissions or their consequences, and being worn down by decision fatigue, users are unable to make sound decisions.  This project set out to accomplish two tasks. First, it intended to create a mechanism for end-users to provide informed consent to app permission settings on their devices (such as smartphones and tablets). Second, it intended to examine the potential for crowdsourcing to provide this information.  The project has accomplished both ends. It has explored the use of crowdsourcing and found that the crowd is capable of providing reasonable quality information. This is a useful finding because only automation or the use of large numbers of people can scale the provision of this knowledge, and automation is poor at context and nuance.  The project has also leveraged this information to build two tools for helping users make decisions about apps. One tool is a privacy-enabled app search engine that ranks apps higher if they are more privacy-protecting. The other is an aid for apps already installed, by indicating which permissions should be turned off. The combination covers both use-cases that a user might encounter.  The project has also had useful findings that are sub-points to or augmentations of the above. For instance, it has substantially explored the design of user interfaces for presenting rating information about permissions. It finds numerous subtleties, including quite surprising ones, in the design of such an interface, and arrives at designs that pass user interface evaluations. It has also investigated factors that might impact how people perceive and rate apps, such as the role of brands in user perceptions.  This work is entirely driven by its potential for broader impact. It observes a problem with real-world systems, and identifies two tasks that can help address those problems. It has successfully executed both tasks, resulting in working systems as the manifestation.          Last Modified: 12/02/2017       Submitted by: Shriram Krishnamurthi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
