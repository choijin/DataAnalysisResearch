<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Peer-to-Peer Human-Robot Coalitions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>521309.00</AwardTotalIntnAmount>
<AwardAmount>521309</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This research aims to create large-scale teams of human and robot peers that operate side-by-side in the same physical space, with each human and robot performing physical actions based upon their own skills and capabilities. The intent is to generate an interaction style that is not based on direct commands and controls from humans to robots, but rather on the idea that robots can implicitly infer the intent of human teammates through passive observation, and then take appropriate actions in the current context. In this interaction, humans perform tasks in a very natural manner, as he/she would when working with a human teammate, thus bypassing the difficulty of cognitive overload that occurs when humans are required to explicitly supervise the actions of several robot team members. This research can revolutionize how humans and robots work together in applications such as search and rescue, firefighting, security, defense, light construction, manufacturing, home assistance, and healthcare.&lt;br/&gt;&lt;br/&gt;This research focuses on two key challenges: (1) how robots can determine humans' current goals, intents, and activities via sensor observation only, and (2) how robots can respond appropriately to help humans with the ongoing task, consistent with the inferred human intent. Input to the robot system is a set of learned models, along with color and depth sensing. Models are learned using novel features for human perception and representation, including Depth of Interest features, 4-dimensional local spatio-temporal features, adaptive human-centered features, and simplex-based orientation descriptors. Learning techniques make use of novel maximum temporal certainty models for sequential activity recognition, and conditional random fields for environmental monitoring. Robot activity selection is achieved via a novel risk-aware cognitive model. The outcome of this research will be new software methodologies enabling robot cognition, learning, sensing, perception, and action selection for peer-to-peer human-robot teaming.</AbstractNarration>
<MinAmdLetterDate>07/21/2014</MinAmdLetterDate>
<MaxAmdLetterDate>03/03/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1427004</AwardID>
<Investigator>
<FirstName>Lynne</FirstName>
<LastName>Parker</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lynne E Parker</PI_FULL_NAME>
<EmailAddress>leparker@utk.edu</EmailAddress>
<PI_PHON>8659744394</PI_PHON>
<NSF_ID>000346469</NSF_ID>
<StartDate>03/03/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Leon</FirstName>
<LastName>Tolbert</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Leon M Tolbert</PI_FULL_NAME>
<EmailAddress>tolbert@utk.edu</EmailAddress>
<PI_PHON>8659743461</PI_PHON>
<NSF_ID>000356175</NSF_ID>
<StartDate>12/19/2014</StartDate>
<EndDate>03/03/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Tennessee Knoxville</Name>
<CityName>Knoxville</CityName>
<ZipCode>379163801</ZipCode>
<PhoneNumber>8659743466</PhoneNumber>
<StreetAddress>1331 CIR PARK DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<StateCode>TN</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TN02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003387891</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TENNESSEE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003387891</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Tennessee Knoxville]]></Name>
<CityName/>
<StateCode>TN</StateCode>
<ZipCode>379960003</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TN02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~521309</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our research has focused on the challenge of enabling robots to determine humans&rsquo; current goals, intents, and activities via sensor observation only, without requiring direct commands from the human. &nbsp;&nbsp;If robots can understand what humans are doing, then they can respond appropriately as helpful teammates by providing useful assistance to people in their ongoing tasks, consistent with the inferred human intent. This research targets a large user community, including applications in search and rescue, firefighting, security, defense, service, light construction, and manufacturing tasks, as well as education. Some aspects of the research are also appropriate for robots in the home and in healthcare, including smart homes. Indeed, any domain in which robots and humans can work together as peers can benefit from the research in progress.&nbsp; As a concrete example, hazardous search missions are an excellent application domain for human-robot teams because cost-effective robot systems could be leveraged to reduce total mission duration time, improve search space thoroughness, and reduce human exposure to danger. Efficiently pairing robotic agents with the experience and quick problem solving skills of human workers requires leveraging implicit communication when explicit techniques are either unavailable, socially unnatural, or impractical, such as is often the case with challenging search and rescue missions.</p> <p>Although successful implicit communication methods for robotics systems exist, such as gestural recognition, activity recognition, and gaze management, a full suite of effective natural communication skills remains an open problem in robotics, thus preventing human-robot team solutions from being more commonplace.&nbsp; In this project, we have created new approaches that allow robots to implicitly infer the intent of the humans and robots through passive observation, and then take the appropriate cooperative actions in the current context.&nbsp; In so doing, we create teams of peers. &nbsp;In peer-to-peer human-robot teaming, a primary objective is to create a style of cooperation between robot(s) and human(s) that is reminiscent of well-practiced human-only teams. &nbsp;In these human-only teams, the individuals have trained together, and understand intuitively how to interact with each other on the current task without the need for any explicit commands or conversations. &nbsp;In these teams, the robots implicitly observe the ongoing team activities and respond with appropriate actions to assist the team in achieving its objectives.&nbsp;&nbsp;The outcomes of this research include new software techniques enabling robot cognition, learning, sensing, perception, and action selection applicable to peer-to-peer human-robot teaming.&nbsp;</p> <p>We developed a method for modeling human spatio-temporal attention with a 3D heat map based on head pose trajectory tracking, and showed how it can be used to allow passively observing robot agents to determine a human teammate's objects of interest.&nbsp; We developed algorithms that enable robots to recognize sequential human activities that include temporal patterns.&nbsp; We showed how robot skills could be bootstrapped in human-robot teaming by enabling robots to automatically adapt their human-demonstrated skills to the current environment.&nbsp; We developed approaches for peer robots to work with non-expert human users, and the potential impact of peer teaming robots in educational applications. We introduced bio-inspired approaches to construct representations of people that can be used by robots to classify real-time activities.&nbsp; We developed algorithms for reasoning about gradual transitions between different human activities to achieve continuous human activity recognition.&nbsp; We explored the use of holograms overlaid in the human member&rsquo;s field of vision via an augmented reality headset to quickly and clearly communicate objects or areas the robot believes to be of interest.&nbsp; As a collection, these techniques provide a rich toolset for advancing the teaming of humans and robots as peers.</p> <p>This project has also provided excellent opportunities for training and professional development of students.&nbsp; In particular, this project provided training for six graduate students, as well as undergraduate researchers.&nbsp; These students have learned how to conduct research and how to present their work in papers and oral presentations.&nbsp; Further, the participation of the students in top international conferences has enabled them to network with other researchers in related fields, and to learn from other experts.&nbsp; The results have been disseminated via peer-reviewed publications, conference presentations, and seminars by the project investigators and graduate students.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/02/2018<br>      Modified by: Lynne&nbsp;E&nbsp;Parker</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our research has focused on the challenge of enabling robots to determine humans? current goals, intents, and activities via sensor observation only, without requiring direct commands from the human.   If robots can understand what humans are doing, then they can respond appropriately as helpful teammates by providing useful assistance to people in their ongoing tasks, consistent with the inferred human intent. This research targets a large user community, including applications in search and rescue, firefighting, security, defense, service, light construction, and manufacturing tasks, as well as education. Some aspects of the research are also appropriate for robots in the home and in healthcare, including smart homes. Indeed, any domain in which robots and humans can work together as peers can benefit from the research in progress.  As a concrete example, hazardous search missions are an excellent application domain for human-robot teams because cost-effective robot systems could be leveraged to reduce total mission duration time, improve search space thoroughness, and reduce human exposure to danger. Efficiently pairing robotic agents with the experience and quick problem solving skills of human workers requires leveraging implicit communication when explicit techniques are either unavailable, socially unnatural, or impractical, such as is often the case with challenging search and rescue missions.  Although successful implicit communication methods for robotics systems exist, such as gestural recognition, activity recognition, and gaze management, a full suite of effective natural communication skills remains an open problem in robotics, thus preventing human-robot team solutions from being more commonplace.  In this project, we have created new approaches that allow robots to implicitly infer the intent of the humans and robots through passive observation, and then take the appropriate cooperative actions in the current context.  In so doing, we create teams of peers.  In peer-to-peer human-robot teaming, a primary objective is to create a style of cooperation between robot(s) and human(s) that is reminiscent of well-practiced human-only teams.  In these human-only teams, the individuals have trained together, and understand intuitively how to interact with each other on the current task without the need for any explicit commands or conversations.  In these teams, the robots implicitly observe the ongoing team activities and respond with appropriate actions to assist the team in achieving its objectives.  The outcomes of this research include new software techniques enabling robot cognition, learning, sensing, perception, and action selection applicable to peer-to-peer human-robot teaming.   We developed a method for modeling human spatio-temporal attention with a 3D heat map based on head pose trajectory tracking, and showed how it can be used to allow passively observing robot agents to determine a human teammate's objects of interest.  We developed algorithms that enable robots to recognize sequential human activities that include temporal patterns.  We showed how robot skills could be bootstrapped in human-robot teaming by enabling robots to automatically adapt their human-demonstrated skills to the current environment.  We developed approaches for peer robots to work with non-expert human users, and the potential impact of peer teaming robots in educational applications. We introduced bio-inspired approaches to construct representations of people that can be used by robots to classify real-time activities.  We developed algorithms for reasoning about gradual transitions between different human activities to achieve continuous human activity recognition.  We explored the use of holograms overlaid in the human member?s field of vision via an augmented reality headset to quickly and clearly communicate objects or areas the robot believes to be of interest.  As a collection, these techniques provide a rich toolset for advancing the teaming of humans and robots as peers.  This project has also provided excellent opportunities for training and professional development of students.  In particular, this project provided training for six graduate students, as well as undergraduate researchers.  These students have learned how to conduct research and how to present their work in papers and oral presentations.  Further, the participation of the students in top international conferences has enabled them to network with other researchers in related fields, and to learn from other experts.  The results have been disseminated via peer-reviewed publications, conference presentations, and seminars by the project investigators and graduate students.          Last Modified: 08/02/2018       Submitted by: Lynne E Parker]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
