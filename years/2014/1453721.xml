<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Statistical Information Retrieval Modeling for Complex Search</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2015</AwardEffectiveDate>
<AwardExpirationDate>01/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>552012.00</AwardTotalIntnAmount>
<AwardAmount>552012</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei-Shinn Ku</SignBlockName>
<PO_EMAI>weiku@nsf.gov</PO_EMAI>
<PO_PHON>7032928318</PO_PHON>
</ProgramOfficer>
<AbstractNarration>With the increasing popularity of Web applications and users' deep involvement in the Web, search engines face great challenges with a new degree of complexity. For instance, location-based services collect more complex contextual information such as geo-locations, season, time and temperature. Users' search activities have become more complex and usually task-based generating a variety of feedback and engagement signals such as clicks, mouse movements, eye tracking results, and query reformulations.Â  Moreover, search is not only an individual user's personalized activity, but also activities shared by many users with similar information needs. Search engines are presented with the richest types of information and the largest amount of data ever and the complexity of the available information is tremendous. This demands that search engines be upgraded from retrieval systems that basically look for documents for single queries to decision engines that can pick the best choices for information seeking tasks. Through disseminating research results in papers and tools, the project will make three types of broad impact. First, the techniques developed in this project will benefit a broad population of everyday users and empower them to deal with complex, task-oriented web search. Second, the algorithms and software developed will provide fellow researchers and practitioners a handful of useful tools for solving IR problems incorporating dynamics. Third, the project will reach out to middle school girls and elementary school students. It will be easy for any search engine user to start using the proposed new search engine. However, to be an expert on IR, students need to be good at mathematics, natural language processing, user interface, artificial intelligence, and programming. This will be an excellent project to attract young people and minorities to these STEM disciplines.&lt;br/&gt;&lt;br/&gt;This project aims to create the next generation search engines, to be more specific, decision engines. The focus will be on designing, experimenting, and deploying statistical models for modeling the dynamics presented in the search process. The technical challenges are: (1) given the complexity of the available data, integrating a search engine appropriately into the right places in the larger context for the ultimate information seeking tasks; (2) providing theoretical and practical support to formal modeling of user engagement and other dynamics in retrieval models for better retrieval effectiveness; (3) modeling a user's exploration in the information space and optimizing a search engine's actions and algorithms; and (4) modeling interactions between a user and a search engine as well as interactions among multiple users, creating the dynamic environment for them all to interact and to game with each other and achieve a win-win optimization. The success of this project will start a new research field in IR: dynamic IR modeling. The results of this research will be highly influential with great impact on the next generation search engines. The work will build a foundation for future advances in the fields of reinforcement learning in IR and game theory in IR.</AbstractNarration>
<MinAmdLetterDate>01/26/2015</MinAmdLetterDate>
<MaxAmdLetterDate>02/15/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1453721</AwardID>
<Investigator>
<FirstName>Grace Hui</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Grace Hui Yang</PI_FULL_NAME>
<EmailAddress>huiyang@cs.georgetown.edu</EmailAddress>
<PI_PHON>2026876355</PI_PHON>
<NSF_ID>000604905</NSF_ID>
<StartDate>01/26/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgetown University</Name>
<CityName>Washington</CityName>
<ZipCode>200571789</ZipCode>
<PhoneNumber>2026250100</PhoneNumber>
<StreetAddress>37th &amp; O St N W</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049515844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGETOWN UNIVERSITY (THE)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049515844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgetown University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200571168</ZipCode>
<StreetAddress><![CDATA[37th & O Streets, NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~199431</FUND_OBLG>
<FUND_OBLG>2016~90830</FUND_OBLG>
<FUND_OBLG>2017~135858</FUND_OBLG>
<FUND_OBLG>2018~125893</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div> <p><span>Information-seeking is the ultimate goal for Information Retrieval (IR) research. This project aims to design and develop next-generation search engines that statistically model user and search engine interactions and help the user accomplish complex and dynamic search tasks. A variety of novel interactive search algorithms and solutions have been proposed. They range from dual-agent Q-learning, contextual bandits, policy gradient methods to model-based deep reinforcement learning (DRL). </span><span>Furthermore, our research can be applied to interactive Artificial Intelligence (AI) agents in general, such as chatbots, as long as they use retrieval to access information.</span></p> <p><span>Our research has addressed broad challenges: i) Deciding when and how a search engine can integrate itself appropriately in the multi-iteration problem-solving process. ii) Providing mathematical, theoretical, and practical support to formal modeling of dynamics in user behaviors and search engine algorithms. iii) Modeling user's exploration in information space and helping the user explore novel states. iv) Compressing large-scale text collection to grant end-to-end corpus-level exploration for deep reinforcement learning agents. v) Simulating learning environments for the search engine agents. vi) Diversifying the training simulations for robust and more engaging agents.</span></p> <p><span>Throughout this project, we have successfully achieved a few "firsts," won a student best paper, and made significant improvements over state-of-the-art systems:</span></p> <p><strong><span>- First Dual-Agent Model for Information-Seeking. </span></strong><span>Our dual-agent modeling views the human user and the search engine as two communicating and cooperating agents who work together to accomplish a complex goal. The human and the search engine agents carry out interactions between themselves as well as interact with the outside environment (document collection, location, time, etc.) that they both share. The communication between the two agents can be explicit, such as the human issuing queries and the search engine recommending solutions, or implicit, such as the human editing subsequent queries and the search engine putting certain documents on the top. Both agents share states, higher-level actions, and reward functions, except the human agent, is only partially observable. Their long-term search goal is optimized jointly to achieve a win-win.</span></p> <p><strong><span>- First Simulated Training &amp; Test Bed for Interactive Search. </span></strong>From 2015 to 2017, we organized the <a title="TREC DD" href="http://infosense.cs.georgetown.edu/trec_dd/index.html" target="_blank">Text REtrieval Conference (TREC) Dynamic Domain (DD) Tracks</a>. Evaluation of interactive search systems is a persistent research theme in IR. TREC DD is the first simulation-based standard testbed for interactive search, where a <a title="Simulated User" href="https://github.com/trec-dd/trec-dd-jig" target="_blank">simulated user</a> issues a starting query and provides feedback for all subsequent retrievals. We also proposed novel evaluation metrics that won a <a title="Best Paper" href="http://infosense.cs.georgetown.edu/publication/96.pdf" target="_blank">student best research paper</a> in ACM ICTIR 2017.</p> <p><strong><span>- First Deep Reinforcement Learning (DRL) Model for Interactive Search.</span></strong> In this work, we pointed out incompatibilities between current AI and IR. To address them, we show (1) the importance of keeping a global representation for all documents while searching, and (2) the necessity of differentiable retrieval functions for correct optimization. As a result, our proposed <a title="CE3" href="https://arxiv.org/abs/1912.00753" target="_blank">Corpus-level End-to-End Exploration (CE3)</a> framework is the first of its kind to employ modern AI solutions to this traditional IR task.</p> <p><strong><span>- Significant Performance Improvements by Domain Randomization and Diversification. </span></strong><span>We propose a novel domain randomization method to enhance an agent's training experiences. Our process automatically generates fake documents and reuses existing manual labels to create positive training data as many as needed. This method statistically significantly boosts the agent's effectiveness by 27%. The latest model, I-SEE, is a model-based DRL diversification method, which trains the agents with high-quality, diversified simulated trajectories and further improves the effectiveness by a significant 10% over top-performing systems.</span></p> <p>This research is disseminated in top-tier IR and AI conferences. In total, we published five journal, twenty conference, and fifteen workshop papers. In addition, our 2016 book "<a title="DIR Book" href="https://www.morganclaypool.com/doi/abs/10.2200/S00718ED1V01Y201605ICR049" target="_blank">Dynamic Information Retrieval Modeling</a>'' is a comprehensive <span>introduction to statistical modeling of dynamic IR systems. </span>Besides publications, we also reached out to the IR and the broader AI communities with evaluation campaigns, workshops, and tutorial lectures:</p> <p>- We organized the 2015-2017 <a title="TREC DD" href="http://infosense.cs.georgetown.edu/trec_dd/index.html" target="_blank">TREC DD</a> evaluation campaign with the National Institution of Standards and Technology. We also co-organized the 2018 Dynamic Search Lab at the European Conference and Labs of the Evaluation Forum (CLEF).</p> <p><span>- We gave tutorials on "Dynamic Information Retrieval Modeling'' in top conferences, including ACM SIGIR 2014 and ACM WSDM 2015.</span></p> <p><span>- We co-organized the <a title="DRL4IR Workshops" href="https://drl4ir.github.io/" target="_blank">Deep Reinforcement Learning for Information Retrieval (DRL4IR) workshop series </a>in ACM SIGIR 2020-2021. Our workshop was broadly welcomed by the research community and received more than 200 attendees in 2020.</span></p> <p>- We also released <a title="InfoSense Software Page" href="http://infosense.cs.georgetown.edu/software.html" target="_blank">software packages, programming codes, datasets, and annotations</a> to the general public.&nbsp;</p> </div> <p>We are very grateful for this NSF sponsorship, which has fully or partially supported three Ph.D., fifteen Master's, five undergraduate students, one programmer, and three post-doc researchers. Among them, six are from under-representative groups. We have also developed <a title="Courses" href="http://infosense.cs.georgetown.edu/courses.html" target="_blank">one undergraduate-level and four graduate-level courses</a> from this research.</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/13/2021<br>      Modified by: Grace Hui&nbsp;Yang</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748069049_ScreenShot2021-05-11at10.56.23AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748069049_ScreenShot2021-05-11at10.56.23AM--rgov-800width.jpg" title="Dual-Agent Stochastic Game"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748069049_ScreenShot2021-05-11at10.56.23AM--rgov-66x44.jpg" alt="Dual-Agent Stochastic Game"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image shows the interaction between the search engine and the user agents. In the cooperative game, they share the same belief state and goal, but take different actions. They react to environmental (documents) changes as well as act to communicate to each other.</div> <div class="imageCredit">Grace Hui Yang</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">Dual-Agent Stochastic Game</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620747789862_ScreenShot2021-05-11at11.35.01AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620747789862_ScreenShot2021-05-11at11.35.01AM--rgov-800width.jpg" title="Two-Way Communication Between Search Engine and User"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620747789862_ScreenShot2021-05-11at11.35.01AM--rgov-66x44.jpg" alt="Two-Way Communication Between Search Engine and User"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image shows a two-way communication between the search engine and the user. Here the search engine also "talks" back to the user by: (1) showing a ranked list of documents where the higher ranked ones are it believes to be relevant, and (2) diversifying the results to encourage  exploration.</div> <div class="imageCredit">Grace Hui Yang</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">Two-Way Communication Between Search Engine and User</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748734302_ScreenShot2021-05-11at11.52.54AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748734302_ScreenShot2021-05-11at11.52.54AM--rgov-800width.jpg" title="DeepTileBars: Segment-Based Neural Retrieval"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748734302_ScreenShot2021-05-11at11.52.54AM--rgov-66x44.jpg" alt="DeepTileBars: Segment-Based Neural Retrieval"></a> <div class="imageCaptionContainer"> <div class="imageCaption">DeepTileBars, our proposed highly-effective neural retrieval model, use word-to-segment matching at different granularitylevels. It effectively works as document retrieval with topic modeling.</div> <div class="imageCredit">Grace Hui Yang, Zhiwen Tang</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">DeepTileBars: Segment-Based Neural Retrieval</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748937535_ScreenShot2021-05-11at12.00.26PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748937535_ScreenShot2021-05-11at12.00.26PM--rgov-800width.jpg" title="CE3 System Architecture"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620748937535_ScreenShot2021-05-11at12.00.26PM--rgov-66x44.jpg" alt="CE3 System Architecture"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Corpus-Level End-to-End Exploration (CE3) method using deep reinforcement learning for dynamic search.</div> <div class="imageCredit">Zhiwen Tang</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">CE3 System Architecture</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750069046_dd2--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750069046_dd2--rgov-800width.jpg" title="TREC DD Task Illustration"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750069046_dd2--rgov-66x44.jpg" alt="TREC DD Task Illustration"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image illustrates the task for a search engine system in the Text REtrieval Conference (TREC) Dynamic Domain (DD) Tracks 2015-2017. A simulator is used to replace human users to interact with the search engine. The simulator outputs feedback at nugget-level to top returned documents.</div> <div class="imageCredit">Grace Hui Yang</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">TREC DD Task Illustration</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750745219_system--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750745219_system--rgov-800width.jpg" title="I-SEE: High Quality Dialogue Diversification"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750745219_system--rgov-66x44.jpg" alt="I-SEE: High Quality Dialogue Diversification"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image shows the system architecture of a model-based deep reinforcement learning method for dialogue diversification - Intermittent Short ExtensionEnsemble (I-SEE). It is designed for training dialogues agents in simulators with high quality diversified trajectories.</div> <div class="imageCredit">Grace Hui Yang, Zhiwen Tang</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">I-SEE: High Quality Dialogue Diversification</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750753857_system--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750753857_system--rgov-800width.jpg" title="I-SEE: High Quality Dialogue Diversification"><img src="/por/images/Reports/POR/2021/1453721/1453721_10348452_1620750753857_system--rgov-66x44.jpg" alt="I-SEE: High Quality Dialogue Diversification"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image shows the system architecture of a model-based deep reinforcement learning method for dialogue diversification - Intermittent Short Extension Ensemble (I-SEE). It is designed for training dialogues agents in simulators with high quality diversified trajectories.</div> <div class="imageCredit">Grace Hui Yang, Zhiwen Tang</div> <div class="imageSubmitted">Grace Hui&nbsp;Yang</div> <div class="imageTitle">I-SEE: High Quality Dialogue Diversification</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Information-seeking is the ultimate goal for Information Retrieval (IR) research. This project aims to design and develop next-generation search engines that statistically model user and search engine interactions and help the user accomplish complex and dynamic search tasks. A variety of novel interactive search algorithms and solutions have been proposed. They range from dual-agent Q-learning, contextual bandits, policy gradient methods to model-based deep reinforcement learning (DRL). Furthermore, our research can be applied to interactive Artificial Intelligence (AI) agents in general, such as chatbots, as long as they use retrieval to access information.  Our research has addressed broad challenges: i) Deciding when and how a search engine can integrate itself appropriately in the multi-iteration problem-solving process. ii) Providing mathematical, theoretical, and practical support to formal modeling of dynamics in user behaviors and search engine algorithms. iii) Modeling user's exploration in information space and helping the user explore novel states. iv) Compressing large-scale text collection to grant end-to-end corpus-level exploration for deep reinforcement learning agents. v) Simulating learning environments for the search engine agents. vi) Diversifying the training simulations for robust and more engaging agents.  Throughout this project, we have successfully achieved a few "firsts," won a student best paper, and made significant improvements over state-of-the-art systems:  - First Dual-Agent Model for Information-Seeking. Our dual-agent modeling views the human user and the search engine as two communicating and cooperating agents who work together to accomplish a complex goal. The human and the search engine agents carry out interactions between themselves as well as interact with the outside environment (document collection, location, time, etc.) that they both share. The communication between the two agents can be explicit, such as the human issuing queries and the search engine recommending solutions, or implicit, such as the human editing subsequent queries and the search engine putting certain documents on the top. Both agents share states, higher-level actions, and reward functions, except the human agent, is only partially observable. Their long-term search goal is optimized jointly to achieve a win-win.  - First Simulated Training &amp; Test Bed for Interactive Search. From 2015 to 2017, we organized the Text REtrieval Conference (TREC) Dynamic Domain (DD) Tracks. Evaluation of interactive search systems is a persistent research theme in IR. TREC DD is the first simulation-based standard testbed for interactive search, where a simulated user issues a starting query and provides feedback for all subsequent retrievals. We also proposed novel evaluation metrics that won a student best research paper in ACM ICTIR 2017.  - First Deep Reinforcement Learning (DRL) Model for Interactive Search. In this work, we pointed out incompatibilities between current AI and IR. To address them, we show (1) the importance of keeping a global representation for all documents while searching, and (2) the necessity of differentiable retrieval functions for correct optimization. As a result, our proposed Corpus-level End-to-End Exploration (CE3) framework is the first of its kind to employ modern AI solutions to this traditional IR task.  - Significant Performance Improvements by Domain Randomization and Diversification. We propose a novel domain randomization method to enhance an agent's training experiences. Our process automatically generates fake documents and reuses existing manual labels to create positive training data as many as needed. This method statistically significantly boosts the agent's effectiveness by 27%. The latest model, I-SEE, is a model-based DRL diversification method, which trains the agents with high-quality, diversified simulated trajectories and further improves the effectiveness by a significant 10% over top-performing systems.  This research is disseminated in top-tier IR and AI conferences. In total, we published five journal, twenty conference, and fifteen workshop papers. In addition, our 2016 book "Dynamic Information Retrieval Modeling'' is a comprehensive introduction to statistical modeling of dynamic IR systems. Besides publications, we also reached out to the IR and the broader AI communities with evaluation campaigns, workshops, and tutorial lectures:  - We organized the 2015-2017 TREC DD evaluation campaign with the National Institution of Standards and Technology. We also co-organized the 2018 Dynamic Search Lab at the European Conference and Labs of the Evaluation Forum (CLEF).  - We gave tutorials on "Dynamic Information Retrieval Modeling'' in top conferences, including ACM SIGIR 2014 and ACM WSDM 2015.  - We co-organized the Deep Reinforcement Learning for Information Retrieval (DRL4IR) workshop series in ACM SIGIR 2020-2021. Our workshop was broadly welcomed by the research community and received more than 200 attendees in 2020.  - We also released software packages, programming codes, datasets, and annotations to the general public.    We are very grateful for this NSF sponsorship, which has fully or partially supported three Ph.D., fifteen Master's, five undergraduate students, one programmer, and three post-doc researchers. Among them, six are from under-representative groups. We have also developed one undergraduate-level and four graduate-level courses from this research.          Last Modified: 05/13/2021       Submitted by: Grace Hui Yang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
