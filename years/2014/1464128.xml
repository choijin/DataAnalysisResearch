<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: III: Learning to Extract Events from Knowledge Base Revisions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>151299.00</AwardTotalIntnAmount>
<AwardAmount>151299</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Encyclopedic knowledge bases (KBs) such as Wikipedia and Freebase form the underlying intelligence behind Google's Knowledge Graph, Facebook's Graph Search, IBM's Watson and more.  These broad-coverage databases contain facts about entities, for example a person's employer or a city's mayor.  KBs should not simply be viewed as static snapshots, however, as we live in a constantly changing world.  For example, an election event can change the Leader of a country, or a divorce/wedding can change the Spouse of a person.  Today's knowledge bases rely on human editors to stay up-to-date; this works for prominent entities, such as celebrities or politicians, but manual editing will not scale to tracking the huge number of concepts covered by these massive KBs.  The project will therefore investigate methods to continuously track real-time text streams, including news and social media, and automatically update concepts in a KB, as soon as new information becomes available.  This will enable new kinds of intelligent systems that constantly read all the text that is publicly written each day, and maintain a detailed up-to-the-minute knowledge base describing the current state of the world. The expected results in weakly supervised information extraction techniques are expected to have a broad range of applications, including detecting cyber security events discussed on Twitter. The project will provide research training and educational experience for students at Ohio State University and beyond, as the research outcomes will be used in developing an open-source toolkit for weakly supervised information extraction that will be widely distributed. &lt;br/&gt;&lt;br/&gt;When important events occur, KB contributors often edit properties of affected entities in near-real-time, for instance on Wikipedia.  At the same time, many people discuss these events on social media and in the news.  Because the set of events that alter properties of KB entities is large and not fixed in advance, this project will investigate, implement and evaluate new models for learning text extractors from KB revisions.  The project will conduct experiments learning extractors for news and Twitter using Wikipedia infobox edits as distant supervision.  Rather than making the closed world assumption, which is common in previous work, the proposed methods will regularize the label distribution over events that do not match knowledge revisions towards a user-provided expectation.  It is expected that the results of this research will help to address the problem of false positives due to events that are not reflected in the revision history.  The approach's ability to automatically propose Wikipedia infobox edits in real-time will be tested as public knowledge of an event becomes available.  Previous studies on weakly supervised event extraction have mostly been conducted in limited domains.  In contrast, this work aims to scale up while simultaneously grounding events mentioned in text to revisions of an entity's properties in a knowledge base. The project web site (http://aritter.github.io/crii/) will include information on the project, links to publications, software and datasets produced as a result of this research.</AbstractNarration>
<MinAmdLetterDate>08/05/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1464128</AwardID>
<Investigator>
<FirstName>Alan</FirstName>
<LastName>Ritter</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alan Ritter</PI_FULL_NAME>
<EmailAddress>aritter34@gatech.edu</EmailAddress>
<PI_PHON>3608201090</PI_PHON>
<NSF_ID>000655595</NSF_ID>
<StartDate>08/05/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~151299</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Knowledge bases (KBs) form the underlying intelligence behind Google's Knowledge Graph, Facebook's Graph Search, IBM's Watson and more. These broad-coverage databases contain encyclopedic facts, for example a person's employer or a city's mayor. KBs should not simply be viewed as static snapshots, however, as we live in a constantly changing world. For example, an election event can change the leader of a country, or a wedding can change a person's spouse. Today's knowledge bases rely on human editors to stay up-to-date; this works fine for prominent entities, such as celebrities, but manual editing will not scale to tracking the huge number of concepts covered by these massive KBs.</span></p> <p>The work carried out as part of this project showed how it is possible to automatically detect changes to a knowledge base by scanning realtime news and social media feeds.&nbsp; For example, the sentence: "Chicago welcomes Rahm Emanuel as our  new mayor" provides evidence that the Leader attribute of the infobox on Chicago's Wikipedia page needs to be updated with the new value "Rahm Emanuel".&nbsp; To achieve this, we developed methods that learn to extract changes to a knowledge graph using the revision history of Wikipedia's infoboxes as a distant source of supervision.</p> <p>Taking this one step further, we developed new methods for forecasting changes to a knowledge graph by extracting users explicit predictions about future events from text.&nbsp; After analyzing users' online predictions toward 1,000 future events, we showed that our method significantly outperforms forecasting baselines based on sentiment analysis and message volume.&nbsp; These results support the feasibility of analyzing users' explicit predictions online as a general method for open-domain forecasting, without relying on historical data, which is needed for traditional, regression-based forecasting methods.</p> <p>In addition the project developed novel methods for normalizing time expressions (e.g. "next Friday").&nbsp; Rather than relying on expensive human supervision in the form of annotated data or rules, we showed how it is possible to learn to normalize time expressions using only a database of known events as distant supervision.</p><br> <p>            Last Modified: 09/23/2018<br>      Modified by: Alan&nbsp;Ritter</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1464128/1464128_10383824_1537557895124_figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1464128/1464128_10383824_1537557895124_figure1--rgov-800width.jpg" title="Figure 1"><img src="/por/images/Reports/POR/2018/1464128/1464128_10383824_1537557895124_figure1--rgov-66x44.jpg" alt="Figure 1"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Aligning Wikipedia?s infobox edits to events mentioned in text.</div> <div class="imageCredit">Alan L Ritter</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Alan&nbsp;Ritter</div> <div class="imageTitle">Figure 1</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Knowledge bases (KBs) form the underlying intelligence behind Google's Knowledge Graph, Facebook's Graph Search, IBM's Watson and more. These broad-coverage databases contain encyclopedic facts, for example a person's employer or a city's mayor. KBs should not simply be viewed as static snapshots, however, as we live in a constantly changing world. For example, an election event can change the leader of a country, or a wedding can change a person's spouse. Today's knowledge bases rely on human editors to stay up-to-date; this works fine for prominent entities, such as celebrities, but manual editing will not scale to tracking the huge number of concepts covered by these massive KBs.  The work carried out as part of this project showed how it is possible to automatically detect changes to a knowledge base by scanning realtime news and social media feeds.  For example, the sentence: "Chicago welcomes Rahm Emanuel as our  new mayor" provides evidence that the Leader attribute of the infobox on Chicago's Wikipedia page needs to be updated with the new value "Rahm Emanuel".  To achieve this, we developed methods that learn to extract changes to a knowledge graph using the revision history of Wikipedia's infoboxes as a distant source of supervision.  Taking this one step further, we developed new methods for forecasting changes to a knowledge graph by extracting users explicit predictions about future events from text.  After analyzing users' online predictions toward 1,000 future events, we showed that our method significantly outperforms forecasting baselines based on sentiment analysis and message volume.  These results support the feasibility of analyzing users' explicit predictions online as a general method for open-domain forecasting, without relying on historical data, which is needed for traditional, regression-based forecasting methods.  In addition the project developed novel methods for normalizing time expressions (e.g. "next Friday").  Rather than relying on expensive human supervision in the form of annotated data or rules, we showed how it is possible to learn to normalize time expressions using only a database of known events as distant supervision.       Last Modified: 09/23/2018       Submitted by: Alan Ritter]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
