<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Semantic Video Analysis for Video Summarization and Recommendation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>148754.00</AwardTotalIntnAmount>
<AwardAmount>148754</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is considerable because a variety of complementary new technologies is ushering in a new era in which visual messages are becoming a first-class media type along-side text and speech.  Today, both amateur and professional videographers still have to enter the virtual darkroom to sift through video, edit it, and produce engaging content.  Video creation is waiting for its Polaroid moment, when a technological solution will transform the post-production time required to create engaging video.  If successful, the technology developed in this project will greatly increase the utility of any video capture device and would have implications outside of Internet media in areas such as life recording and knowledge transfer. The countless video clips of important or memorable events that are today commonly archived and forgotten could instead be automatically summarized and made available in a usable and engaging format. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project aims to evaluate the technical viability of an automatic video summarization system based on neural networks and adapted to measurements of human psychology.  As people collectively record more videos than they can possibly consume (the video deluge problem), a technology that automatically turns raw videos into relevant and engaging summaries becomes increasingly critical.  The company's proposed platform would streamline video sharing, search, and viewing, all of which are staples of our online lives.  Scientifically we are at a unique time in the capabilities of artificial visual systems, with some systems rivaling human performance in limited domains.  Furthermore, the field of visual psychology has also seen recent progress in relating visual semantic information to cognitive phenomena, like memorability of images.  Taken together, it may now be possible to automatically predict the cognitive relevance of visual information and produce effective video summarizations.  This project combines deep neural networks for visual object recognition, recurrent networks for contextually embedded temporal information, and user measurement of interest, memorability, and uniqueness.  The primary technical objective is to determine whether a system can automatically predict human-produced video summarizations.</AbstractNarration>
<MinAmdLetterDate>05/12/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/12/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1416612</AwardID>
<Investigator>
<FirstName>Charles</FirstName>
<LastName>Cadieu</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Charles F Cadieu</PI_FULL_NAME>
<EmailAddress>mgmt@baylabs.io</EmailAddress>
<PI_PHON>5162200119</PI_PHON>
<NSF_ID>000533858</NSF_ID>
<StartDate>05/12/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Bay Labs, Inc.</Name>
<CityName>San Francisco</CityName>
<ZipCode>941033734</ZipCode>
<PhoneNumber>4154245616</PhoneNumber>
<StreetAddress>1479 Folsom Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079192179</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CAPTION HEALTH, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Bay Labs, Inc.]]></Name>
<CityName>San Francisco</CityName>
<StateCode>CA</StateCode>
<ZipCode>941322357</ZipCode>
<StreetAddress><![CDATA[9 Josepha Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA14</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~148754</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Since the commencement of the Phase I SBIR we changed the application of our video based deep learning technology to medical imaging.&nbsp; Based on market feedback and the suitability of the underlying technology, we refocused our effort on medical imaging using ultrasound.&nbsp; Ultrasound imaging has numerous benefits including real-time image acquisition, non-invasive scanning, low-cost devices, and no known side-effects (it is non-ionizing radiation).&nbsp; Despite these advantages, ultrasound remains difficult to use because it is inherently operator-dependent.&nbsp; Deep learning&rsquo;s adaptability to diverse forms of data and broad applicability to signal processing problems indicated that it may be suitable to address the limitations of ultrasound imaging.&nbsp; Specifically, deep learning technology may be useful to address the operator-dependence of ultrasound by providing assistance to sonographers during acquisition and interpretation.&nbsp; If successful, this technology would result in improved efficiency and quality of ultrasound examinations.&nbsp; As a result of this Phase I effort we evaluated the feasibility of applying deep learning to medical ultrasound.&nbsp; The outcome of our Phase I effort is a demonstration of a novel deep learning-based system that provides feedback during ultrasound acquisition and interpretation.&nbsp; We have shown that the system is accurate, fast, and runs on inexpensive computer systems.&nbsp; This innovation may impact future products that improve efficiency and quality during ultrasound examinations.</p><br> <p>            Last Modified: 09/28/2015<br>      Modified by: Charles&nbsp;F&nbsp;Cadieu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Since the commencement of the Phase I SBIR we changed the application of our video based deep learning technology to medical imaging.  Based on market feedback and the suitability of the underlying technology, we refocused our effort on medical imaging using ultrasound.  Ultrasound imaging has numerous benefits including real-time image acquisition, non-invasive scanning, low-cost devices, and no known side-effects (it is non-ionizing radiation).  Despite these advantages, ultrasound remains difficult to use because it is inherently operator-dependent.  Deep learningÃ†s adaptability to diverse forms of data and broad applicability to signal processing problems indicated that it may be suitable to address the limitations of ultrasound imaging.  Specifically, deep learning technology may be useful to address the operator-dependence of ultrasound by providing assistance to sonographers during acquisition and interpretation.  If successful, this technology would result in improved efficiency and quality of ultrasound examinations.  As a result of this Phase I effort we evaluated the feasibility of applying deep learning to medical ultrasound.  The outcome of our Phase I effort is a demonstration of a novel deep learning-based system that provides feedback during ultrasound acquisition and interpretation.  We have shown that the system is accurate, fast, and runs on inexpensive computer systems.  This innovation may impact future products that improve efficiency and quality during ultrasound examinations.       Last Modified: 09/28/2015       Submitted by: Charles F Cadieu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
