<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Computational and psycholinguistic investigations of covert dependencies</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2015</AwardEffectiveDate>
<AwardExpirationDate>12/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>318133.00</AwardTotalIntnAmount>
<AwardAmount>327133</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tyler Kendall</SignBlockName>
<PO_EMAI>tkendall@nsf.gov</PO_EMAI>
<PO_PHON>7032922434</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Language is a window into the inner working of the human mind. A great deal of previous work has examined how English speakers understand their mother tongue, and how English speaking children develop their reading, writing and conversational skills to become sufficient English users.  Comparatively little is known about whether speakers of different languages adopt qualitatively or quantitatively different strategies in language communication.  A good understanding of potential cross-linguistic differences bears directly upon a variety of important issues relevant for U.S. society, including the development of more efficient learning and teaching strategies for foreign languages, and of sophisticated technological tools to extract information from foreign text, websites, and written or spoken corpora. The language under investigation in this project is Mandarin Chinese, which, as the official language of China, is a language with significant national interest to the U.S., due to the growing influence of China's economic and political power.  Chinese immigrants also form one of the largest foreign-born groups living in the United States. &lt;br/&gt;&lt;br/&gt;The particular empirical domain of the current project is on the structure of questions in Chinese. The project consists of two major components. First, a series of behavioral experiments will investigate how Chinese speakers, conditioned by the particular grammatical properties of the Chinese language, make decisions about how to best memorize, recall and anticipate linguistic information encoded in Chinese questions. Second, detailed computational and statistical models will be developed to provide a framework to explain these behaviors. Technological tools will also be developed to work with Chinese corpora. The combination of the behavioral and computational methods makes it possible to answer questions about what differences exist between English and Chinese, and how language users adapt to these differences so as to maximize communicative efficiency in each language. A substantial part of the project also includes training students in cutting-edge research questions, methods, and establishing close international collaboration with leading language researchers and institutions in China.</AbstractNarration>
<MinAmdLetterDate>06/22/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1451635</AwardID>
<Investigator>
<FirstName>Ming</FirstName>
<LastName>Xiang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ming Xiang</PI_FULL_NAME>
<EmailAddress>mxiang@uchicago.edu</EmailAddress>
<PI_PHON>7737028602</PI_PHON>
<NSF_ID>000593094</NSF_ID>
<StartDate>06/22/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Suiping</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Suiping Wang</PI_FULL_NAME>
<EmailAddress>suipingscnu@gmail.com</EmailAddress>
<PI_PHON>7737028602</PI_PHON>
<NSF_ID>000623100</NSF_ID>
<StartDate>06/22/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gregory</FirstName>
<LastName>Kobele</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gregory M Kobele</PI_FULL_NAME>
<EmailAddress>kobele@uchicago.edu</EmailAddress>
<PI_PHON>7738344607</PI_PHON>
<NSF_ID>000610712</NSF_ID>
<StartDate>06/22/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>606375418</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~318133</FUND_OBLG>
<FUND_OBLG>2018~9000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>When we use language to communicate, we combine words together to express thoughts. Sentences we speak or hear are not just strings of words jumbled together randomly. When a reader or listener interprets a sentence, they first need to parse the string of words into a specific structure, then they interpret what that structure could mean. One important question for the scientific community is to understand how human mind parses sentences, and when and why difficulty (or processing cost) could arise during the parsing process. Two prominent classes of parsing models are the memory-based models and the expectation-based models. The memory-based models explain sentence comprehension difficulty by examining how our limited memory resources are allocated to deal with information encoding, maintenance and retrieval. Expectation-based models, on the other hand, focus primarily on how a language users' language experience can shape their probabilistic beliefs about what information is most likely to come up during incremental processing. &nbsp;The central goal of the current project "Computational and psycholinguistic investigations of covert dependencies" is to broaden our empirical and theoretical understanding of these two kinds of parsing mechanisms through conducting a cross-linguistic investigation. Our primary target language is Mandarin Chinese, but we also examined German, Hungarian and English.</p> <p>Each of these languages has its unique properties that can help our investigation. For example, Chinese is typologically different from English when it comes to forming a wh-question. An English question like "Which movie did John like most?" will be translated into a different word order in Chinese -- "John most liked which movie?" (note we used the English words but Chinese word order here). Different word orders between these two languages may lead to different processing strategies for English and Chinese native speakers. Similarly, German has an interesting determiner system; Hungarian has flexible word order and rich morphology. Each language provides a unique opportunity for us to precisely target some specific aspects of how working memory and probabilistic belief update shape language comprehension.</p> <p>Taking advantages of the specific properties of these languages, we conducted a set of reading experiments. The main findings of the current project can be briefly summarized as the following:</p> <p>a. We are one of the first to systematically investigate the type of wh-structures in Mandarin Chinese. Our results therefore filled in an important empirical gap in the literature. We found that despite surface differences between Chinese and English, processing Chinese wh-constructions involves constructing similar structural representations as processing English (Xiang, Wang and Cui 2015). We found clear effects of both memory-based and expectation-based mechanisms. The two mechanisms each independently contributes to sentence comprehension complexity in Mandarin, with no strong evidence that could indicate an interaction. We further showed in Kobele, He and Xiang (2020) that information theoretic complexity metrics such as surprisal and entropy reduction, when computed over abstract syntactic structures, are significant predictors of processing cost in Mandarin.</p> <p>b. When comparing cross-linguistic results from Mandarin, Hungarian (Ronai and Xiang, 2020, under review) and German (Schwab, Xiang and Liu, 2020, under review), we found each language presents a different picture in terms of the interaction between memory-based and expectation-based mechanisms. Although we found little evidence in Mandarin wh-structures to indicate an interaction between the two, in Hungarian relative clauses we found strong evidence for memory-based effects but not for expectation-based effects; and in German relative clauses we found strong evidence to support expectation-based mechanisms. This set of results suggest that the trade-off between memory and expectation-based mechanisms is highly sensitive to specific properties of the linguistic construction as well as the target language under investigation. Instead of a universal model, we need a processing model that can adapt to find-grained cross-linguistic variations.</p> <p>c. &nbsp;&nbsp;In addition to examining the parsing question, the current project also addressed the important theoretical question regarding the relationship between parsing the interpretation. A great amount of sentence processing work has focused on revealing how the parser incrementally integrates each incoming word into the current linguistic representation. It is often explicitly or implicitly assumed that the representation preferred by the parser would determine the ultimate interpretation of the sentence. In Xiang, Dai and Wang (2020, under review), we challenge this traditional view. Based on novel experimental data, we first demonstrated an empirical problem for this view. We then proposed a Bayesian pragmatic inference mechanism to address the problem. More generally, we propose that the outcome of structural parsing needs to be combined with pragmatic reasoning in order to arrive at the ultimate interpretation.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/01/2021<br>      Modified by: Ming&nbsp;Xiang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ When we use language to communicate, we combine words together to express thoughts. Sentences we speak or hear are not just strings of words jumbled together randomly. When a reader or listener interprets a sentence, they first need to parse the string of words into a specific structure, then they interpret what that structure could mean. One important question for the scientific community is to understand how human mind parses sentences, and when and why difficulty (or processing cost) could arise during the parsing process. Two prominent classes of parsing models are the memory-based models and the expectation-based models. The memory-based models explain sentence comprehension difficulty by examining how our limited memory resources are allocated to deal with information encoding, maintenance and retrieval. Expectation-based models, on the other hand, focus primarily on how a language users' language experience can shape their probabilistic beliefs about what information is most likely to come up during incremental processing.  The central goal of the current project "Computational and psycholinguistic investigations of covert dependencies" is to broaden our empirical and theoretical understanding of these two kinds of parsing mechanisms through conducting a cross-linguistic investigation. Our primary target language is Mandarin Chinese, but we also examined German, Hungarian and English.  Each of these languages has its unique properties that can help our investigation. For example, Chinese is typologically different from English when it comes to forming a wh-question. An English question like "Which movie did John like most?" will be translated into a different word order in Chinese -- "John most liked which movie?" (note we used the English words but Chinese word order here). Different word orders between these two languages may lead to different processing strategies for English and Chinese native speakers. Similarly, German has an interesting determiner system; Hungarian has flexible word order and rich morphology. Each language provides a unique opportunity for us to precisely target some specific aspects of how working memory and probabilistic belief update shape language comprehension.  Taking advantages of the specific properties of these languages, we conducted a set of reading experiments. The main findings of the current project can be briefly summarized as the following:  a. We are one of the first to systematically investigate the type of wh-structures in Mandarin Chinese. Our results therefore filled in an important empirical gap in the literature. We found that despite surface differences between Chinese and English, processing Chinese wh-constructions involves constructing similar structural representations as processing English (Xiang, Wang and Cui 2015). We found clear effects of both memory-based and expectation-based mechanisms. The two mechanisms each independently contributes to sentence comprehension complexity in Mandarin, with no strong evidence that could indicate an interaction. We further showed in Kobele, He and Xiang (2020) that information theoretic complexity metrics such as surprisal and entropy reduction, when computed over abstract syntactic structures, are significant predictors of processing cost in Mandarin.  b. When comparing cross-linguistic results from Mandarin, Hungarian (Ronai and Xiang, 2020, under review) and German (Schwab, Xiang and Liu, 2020, under review), we found each language presents a different picture in terms of the interaction between memory-based and expectation-based mechanisms. Although we found little evidence in Mandarin wh-structures to indicate an interaction between the two, in Hungarian relative clauses we found strong evidence for memory-based effects but not for expectation-based effects; and in German relative clauses we found strong evidence to support expectation-based mechanisms. This set of results suggest that the trade-off between memory and expectation-based mechanisms is highly sensitive to specific properties of the linguistic construction as well as the target language under investigation. Instead of a universal model, we need a processing model that can adapt to find-grained cross-linguistic variations.  c.   In addition to examining the parsing question, the current project also addressed the important theoretical question regarding the relationship between parsing the interpretation. A great amount of sentence processing work has focused on revealing how the parser incrementally integrates each incoming word into the current linguistic representation. It is often explicitly or implicitly assumed that the representation preferred by the parser would determine the ultimate interpretation of the sentence. In Xiang, Dai and Wang (2020, under review), we challenge this traditional view. Based on novel experimental data, we first demonstrated an empirical problem for this view. We then proposed a Bayesian pragmatic inference mechanism to address the problem. More generally, we propose that the outcome of structural parsing needs to be combined with pragmatic reasoning in order to arrive at the ultimate interpretation.                   Last Modified: 05/01/2021       Submitted by: Ming Xiang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
