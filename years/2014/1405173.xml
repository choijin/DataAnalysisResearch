<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>New Adaptive Dynamic Programming Structures From Neurocognitive Psychology and Graphical Games</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>370514.00</AwardTotalIntnAmount>
<AwardAmount>370514</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project brings together a top control engineer with a cognitive neuroscientist, in order to design a new family of control designs which would replicate and explain key capabilities of living brains which have never yet been achieved in engineering (or in the models used in computational neuroscience). This new work builds on previous work by Frank Lewis, in developing adaptive controllers (RLADP) which can maximize performance over time, in the face of nonlinearity and challenges which require foresight, such as the management of power grids. Here, the group will try to explain and replicate how brains can also handle challenges which require them to learn how to structure time, with multiple levels of decision with multiple time horizons, and how to handle complex structure in space, as we need to in managing complex infrastructure networks. These two challenges essentially address two of the three gaps between today's best RLADP and the highest capabilities of the mammal brain.  The new fundamental design work will feed into ongoing laboratory work in the control of electric power microgrids, which are important as building blocks for future electric power distribution networks capable of coping with large penetrations of plug-in hybrid cars or rooftop solar and the like. &lt;br/&gt;&lt;br/&gt;The previous work is reviewed in the Handbook of RLADP, from IEEE/Wiley, edited by Lewis and Liu. Spatial complexity will be addressed by considering optimal control of systems defined over graphs, such as power and communication networks. Game theoretic extensions, related to issues of distributed or collective intelligence, will also be considered. The work will also build on work by co-PI Levine on models of mechanisms in the brain involving the emotional gates in the amygdala and deliberative decisions in the anterior cingulate cortex.</AbstractNarration>
<MinAmdLetterDate>06/24/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1405173</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Levine</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel S Levine</PI_FULL_NAME>
<EmailAddress>levine@uta.edu</EmailAddress>
<PI_PHON>8172723598</PI_PHON>
<NSF_ID>000094847</NSF_ID>
<StartDate>06/24/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Frank</FirstName>
<LastName>Lewis</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Frank L Lewis</PI_FULL_NAME>
<EmailAddress>lewis@uta.edu</EmailAddress>
<PI_PHON>8172725972</PI_PHON>
<NSF_ID>000257326</NSF_ID>
<StartDate>06/24/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ali</FirstName>
<LastName>Davoudi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ali Davoudi</PI_FULL_NAME>
<EmailAddress>davoudi@uta.edu</EmailAddress>
<PI_PHON>8172722105</PI_PHON>
<NSF_ID>000565785</NSF_ID>
<StartDate>06/24/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Arlington</Name>
<CityName>Arlington</CityName>
<ZipCode>760190145</ZipCode>
<PhoneNumber>8172722105</PhoneNumber>
<StreetAddress>701 S Nedderman Dr, Box 19145</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>064234610</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT ARLINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Arlington]]></Name>
<CityName/>
<StateCode>TX</StateCode>
<ZipCode>760199800</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>155E</Code>
<Text>Electric power networks</Text>
</ProgramReference>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~370514</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Under this grant we developed new Adaptive control Reinforcement Learning (RL) structures that provide improved decision and feedback control methods for engineered systems and autonomous multi-agent teams.&nbsp; We used this new technology to design better more reliable control systems for electric power microgrids, aircraft, automobile engines, and teams of interacting autonomous aircraft and ground vehicles. The new RL architectures effectively bring together advanced methods from computer science machine intelligence and neurocognitive psychology to design better learning structures for automatic feedback control systems.&nbsp; We brought together discoveries in neurobiological learning, sociobiological systems, decision interactions in distributed groups of agents, optimal control, and differential games to design new algorithms for collective decision and feedback control in complex human engineered dynamical systems. Applications were made to cyber-physical design of electric power microgrid synchronization controllers.&nbsp;</p> <p><strong>Intellectual Merit.</strong>&nbsp; There were three Scientific Objectives.&nbsp; In Objective 1 we invented <strong>New Interacting Structures of RL Controllers based on Neurocognitive Psychology. </strong>These controllers are based on neural configurations in the human brain and have multi-level critic networks for decision poised above multiple interacting actor-critic networks in the control loop. Under this objective we published 30 journal papers, obtained 1 US Patent, and presented numerous papers in international conferences.&nbsp; 15 invited presentations were given internationally by the PIs.</p> <p>In Objective 2 we discovered<strong> New Techniques in Reinforcement Learning for Collective Intelligence, Optimization, and Control in Multi-agent Systems on Communication Graphs. </strong>We studied biologically inspired learning for multiple agents with unknown nonlinear agent dynamics interconnected by a communication graph.&nbsp; We found surprising new relations between Communication limitations and Control systems that must be considered to design effective local controllers for correct operation in internetworked teams.&nbsp; Applications were made to coordination of multiple unmanned aerial vehicles, teams of humans interacting with autonomous robots. &nbsp;Under this objective we published 44 journal papers, published 1 book, and presented numerous papers in international conferences.&nbsp; 14 invited presentations were given internationally by the PIs.</p> <p>In Objective 3 we developed<strong> </strong><strong>New distributed synchronization mechanisms for Electric Power Microgrid Cyberphysical systems.</strong> &nbsp;Our methods allow better integration of renewable energy resources into the existing power grid. Cooperative control results were applied to develop new more efficient, faster, and robust protocols for synchronizing frequency, power balance, and voltage support in distributed generation multi-agent systems. The US power grid is aging and it is difficult to incorporate new generation in terms of renewable energy resources, which are intermittent and require advanced control methods for reliable power quality and voltage support.&nbsp; In this grant, we developed new methods for microgrid control that are distributed in nature and so require less communication infrastructure, and are faster, more reliable, and more robust to single-point-of-failure.&nbsp;Under this objective we published 18 journal papers and won 3 Best Paper Awards from IEEE Power Systems journals and international conferences. A book was written.</p> <p><strong>&nbsp;</strong></p> <p><strong>Broader Impacts.</strong>&nbsp; Our research brought together results from two disciplines - computer science machine learning and automatic feedback control.&nbsp; We trained and graduated 10 PhD students under this grant, including 3 women.&nbsp; All now have top jobs.&nbsp; We trained 8 Master&rsquo;s Thesis and Undergraduate students in STEM fields, including 2 women and 3 minorities.&nbsp; Trained a further 15 students in the UTA Research Institute Autonomous Systems Lab, which provides hand on experience in robotics and multi-agent systems.&nbsp;</p> <p>We worked with numerous international institutions and universities in China, Italy, Hong Kong, Singapore, Mongolia, and Mexico.&nbsp; Research results were disseminated to the international community through 36 invited talks in China, Mongolia, Singapore, Hong Kong, Zagreb, Rome, and Bari Italy.&nbsp; PI Lewis gave 13 short courses in Asia and Singapore about reinforcement learning, multi-agent coordinated control, and power systems control.&nbsp; Overall 92 papers were published in top international scientific journals.&nbsp; Numerous conference papers and presentations resulted.&nbsp; Two books were written and 1 US patent received.&nbsp;</p> <p>We started an International Research Center at UTA that hosted 18 international visitors from China, Holland, Zagreb, Hong Kong, and elsewhere.&nbsp; Working with them, we developed new research ideas that helped many of them obtain PhD degrees from their home institutions.&nbsp; In 2017 we started a new conference titled International Symposium on Autonomous Systems (ISAS) that was held in Guangzhou, and run again in 2018 in Chongqing.&nbsp; We worked with the State Key Lab on Process Control at Northeastern University, China, to design new process controllers using Reinforcement Learning that significantly decreased pollution and increased productivity in a large Mineral Grinding Plant.&nbsp; For this work, PI Lewis received two top awards from Liaoning Province- the Foreign Friendship Award and the Science and Technology Award.&nbsp;</p> <p>We developed a new course under this research, &ldquo;Distributed Decision and Control&rsquo;.&nbsp; Developed new course material for other courses, including Nonlinear Control and Intelligent Control.&nbsp; All course notes were put online at <a href="http://www.uta.edu/utari/acs/">http://www.uta.edu/utari/acs/</a>.&nbsp; Software from all the research is also online linked to that webpage.&nbsp;</p><br> <p>            Last Modified: 09/18/2018<br>      Modified by: Frank&nbsp;L&nbsp;Lewis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Under this grant we developed new Adaptive control Reinforcement Learning (RL) structures that provide improved decision and feedback control methods for engineered systems and autonomous multi-agent teams.  We used this new technology to design better more reliable control systems for electric power microgrids, aircraft, automobile engines, and teams of interacting autonomous aircraft and ground vehicles. The new RL architectures effectively bring together advanced methods from computer science machine intelligence and neurocognitive psychology to design better learning structures for automatic feedback control systems.  We brought together discoveries in neurobiological learning, sociobiological systems, decision interactions in distributed groups of agents, optimal control, and differential games to design new algorithms for collective decision and feedback control in complex human engineered dynamical systems. Applications were made to cyber-physical design of electric power microgrid synchronization controllers.   Intellectual Merit.  There were three Scientific Objectives.  In Objective 1 we invented New Interacting Structures of RL Controllers based on Neurocognitive Psychology. These controllers are based on neural configurations in the human brain and have multi-level critic networks for decision poised above multiple interacting actor-critic networks in the control loop. Under this objective we published 30 journal papers, obtained 1 US Patent, and presented numerous papers in international conferences.  15 invited presentations were given internationally by the PIs.  In Objective 2 we discovered New Techniques in Reinforcement Learning for Collective Intelligence, Optimization, and Control in Multi-agent Systems on Communication Graphs. We studied biologically inspired learning for multiple agents with unknown nonlinear agent dynamics interconnected by a communication graph.  We found surprising new relations between Communication limitations and Control systems that must be considered to design effective local controllers for correct operation in internetworked teams.  Applications were made to coordination of multiple unmanned aerial vehicles, teams of humans interacting with autonomous robots.  Under this objective we published 44 journal papers, published 1 book, and presented numerous papers in international conferences.  14 invited presentations were given internationally by the PIs.  In Objective 3 we developed New distributed synchronization mechanisms for Electric Power Microgrid Cyberphysical systems.  Our methods allow better integration of renewable energy resources into the existing power grid. Cooperative control results were applied to develop new more efficient, faster, and robust protocols for synchronizing frequency, power balance, and voltage support in distributed generation multi-agent systems. The US power grid is aging and it is difficult to incorporate new generation in terms of renewable energy resources, which are intermittent and require advanced control methods for reliable power quality and voltage support.  In this grant, we developed new methods for microgrid control that are distributed in nature and so require less communication infrastructure, and are faster, more reliable, and more robust to single-point-of-failure. Under this objective we published 18 journal papers and won 3 Best Paper Awards from IEEE Power Systems journals and international conferences. A book was written.     Broader Impacts.  Our research brought together results from two disciplines - computer science machine learning and automatic feedback control.  We trained and graduated 10 PhD students under this grant, including 3 women.  All now have top jobs.  We trained 8 Master?s Thesis and Undergraduate students in STEM fields, including 2 women and 3 minorities.  Trained a further 15 students in the UTA Research Institute Autonomous Systems Lab, which provides hand on experience in robotics and multi-agent systems.   We worked with numerous international institutions and universities in China, Italy, Hong Kong, Singapore, Mongolia, and Mexico.  Research results were disseminated to the international community through 36 invited talks in China, Mongolia, Singapore, Hong Kong, Zagreb, Rome, and Bari Italy.  PI Lewis gave 13 short courses in Asia and Singapore about reinforcement learning, multi-agent coordinated control, and power systems control.  Overall 92 papers were published in top international scientific journals.  Numerous conference papers and presentations resulted.  Two books were written and 1 US patent received.   We started an International Research Center at UTA that hosted 18 international visitors from China, Holland, Zagreb, Hong Kong, and elsewhere.  Working with them, we developed new research ideas that helped many of them obtain PhD degrees from their home institutions.  In 2017 we started a new conference titled International Symposium on Autonomous Systems (ISAS) that was held in Guangzhou, and run again in 2018 in Chongqing.  We worked with the State Key Lab on Process Control at Northeastern University, China, to design new process controllers using Reinforcement Learning that significantly decreased pollution and increased productivity in a large Mineral Grinding Plant.  For this work, PI Lewis received two top awards from Liaoning Province- the Foreign Friendship Award and the Science and Technology Award.   We developed a new course under this research, "Distributed Decision and Control?.  Developed new course material for other courses, including Nonlinear Control and Intelligent Control.  All course notes were put online at http://www.uta.edu/utari/acs/.  Software from all the research is also online linked to that webpage.        Last Modified: 09/18/2018       Submitted by: Frank L Lewis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
