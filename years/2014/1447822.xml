<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: F: DKA: Learning a Union of Subspaces from Big and Corrupted Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>600000.00</AwardTotalIntnAmount>
<AwardAmount>608530</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project develops theory and algorithms for automatically discovering multiple low-dimensional structures in high-dimensional data, and evaluates these algorithms in image clustering applications. The developed techniques enhance our ability to handle big data problems from multiple sources and modalities, and advance the knowledge on how to interpret massive amounts of complex high-dimensional data. The techniques developed in this project can significantly broaden the applicability of existing results in sparse representation theory to subspace clustering problems, which have found widespread applications in image processing (e.g., image denoising, compression, representation, and segmentation), computer vision (e.g., motion segmentation and face clustering) and dynamical systems (e.g., hybrid system identification).&lt;br/&gt; &lt;br/&gt;This research develops provably correct and scalable algorithms for learning a union of low-dimensional subspaces from big and corrupted data. The algorithms are based on the so-called self-expressiveness property of the data, which states that an uncorrupted data point can be well approximated by an affine combination of other uncorrupted data points. This research shows that by imposing a structured sparse and low-rank prior on the coefficients, one can discover multiple structures in the data. In the case of uncorrupted data, the research team studies conditions on the data under which a perfect clustering is possible. In the case of data corrupted by outliers, the research team studies conditions under which perfect clustering and outlier rejection are possible. In the case of data with missing entries, the research team studies conditions under which perfect clustering and data completion are possible. The project also develops efficient and scalable algorithms that benefit from distributed and high-performance computing for solving the various subspace clustering problems. These algorithms enable solving large-scale problems in computer vision, including image clustering.</AbstractNarration>
<MinAmdLetterDate>08/25/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/01/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1447822</AwardID>
<Investigator>
<FirstName>Rene</FirstName>
<LastName>Vidal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rene Vidal</PI_FULL_NAME>
<EmailAddress>rvidal@cis.jhu.edu</EmailAddress>
<PI_PHON>4105167306</PI_PHON>
<NSF_ID>000486258</NSF_ID>
<StartDate>08/25/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Robinson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Robinson</PI_FULL_NAME>
<EmailAddress>dpr219@lehigh.edu</EmailAddress>
<PI_PHON>6107584039</PI_PHON>
<NSF_ID>000607397</NSF_ID>
<StartDate>08/25/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182608</ZipCode>
<StreetAddress><![CDATA[3400 N. Charles Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1253</Code>
<Text>OFFICE OF MULTIDISCIPLINARY AC</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<ProgramReference>
<Code>8251</Code>
<Text>Math Sci Innovation Incubator</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~600000</FUND_OBLG>
<FUND_OBLG>2017~8530</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Menlo; color: #000000} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Menlo; color: #000000; min-height: 15.0px} --> <p class="p1" style="text-align: center;"><strong>Project Outcomes</strong></p> <p class="p1">Discovering structure in high-dimensional data (e.g., images and videos) is an essential part of scientific discovery in many disciplines such as machine learning, computer vision, pattern recognition, and signal and image processing. Traditional methods for discovering structure in high-dimensional data rely on the assumption that high-dimensional data can be well approximated by a single low-dimensional manifold (e.g., a subspace). In practice, however, high-dimensional datasets are extremely complex with multiple low-dimensional structures, hence they are better modeled by a union of low-dimensional manifolds.</p> <p class="p1">The discovery of multiple low-dimensional manifolds in high-dimensional data faces many fundamental challenges. 1) The membership of data points to manifolds is often unknown, hence there is a need to learn the number of manifolds, cluster the data, and fit a low-dimensional manifold to each group. 2) Data are often contaminated by noise, missing entries, and outliers, hence methods that are robust to these corruptions are needed. 3) The associated optimization problems are often non-convex and NP hard, so that conditions under which convex relaxations provide the correct clustering are needed. 4) Modern datasets are massive, hence methods that scale up to the big data regime are needed.</p> <p class="p1">The research supported by this grant includes the design of new families of structured sparse and low-rank subspace clustering algorithms. The algorithms are based on a self-expressiveness property of the data, which states that an uncorrupted data point can be well approximated by a linear combination of other uncorrupted data points. We have shown that imposing structured sparse and low-rank regularization on the coefficients allows subspace-preserving representations to be found, from which subspace structures in the data may be discovered.&nbsp;</p> <p class="p2"><strong>Intellectual Merit.&nbsp;&nbsp;</strong>The following is a summary of the intellectual merit for this project. 1) Three new scalable approaches for subspace clustering were designed.&nbsp; The first is a greedy strategy for obtaining subspace-preserving representations.&nbsp; Being a greedy approach, the amount of computation performed may be bounded in advance, thus allowing for scalable implementations. The second uses the structure of the problem to formulate a new strategy for efficiently identifying subspace-preserving representations.&nbsp; The third is a divide-and-conquer strategy that can handle datasets distributed among multiple computers. Theoretical guarantees of correctness were established for the first two methods, and extensive testing on major applications in computer vision were performed (face clustering and image classification) for all methods. The results showed that all three methods perform better than prior state-of-the-art methods, and exhibit a trade-off between computational cost and clustering accuracy that may be leveraged. 2) We developed algorithms for handling corruptions in the data that include missing entries, random noise, and outliers. New modeling formulations were designed and analyzed to cope with missing entries. Conditions were established under which perfect clustering and data completion is possible. To handle random noise, a nonconvex extension of the basic modeling formulation was proposed and analyzed, and optimization approaches for solving the relevant optimization problems were introduced. To handle outliers, the sparse subspace clustering scheme was combined with a random walk procedure over a specific graph, designed to identify outliers in the dataset. We proved conditions under which perfect clustering and outlier detection is possible. 3) To improve clustering performance on imbalanced data, we used knowledge of the underlying subspace structure to design a novel data subset selection procedure called exemplar selection. &nbsp; The exemplars selected were proved theoretically and verified computationally to be balanced among the different subspaces, provided the dimensions of the subspaces were balanced. 4) To handle datasets that arise from affine spaces, an additional modeling constraint is commonly used.&nbsp; We established that, when the dimension of the ambient dimension is large relative to the dimension of the subspaces, the addition of the affine constraint has no significant impact on the clustering performance.&nbsp; In the complementary regime, our results show that the affine constraint may significantly improve the clustering performance.&nbsp;&nbsp;</p> <p class="p2"><strong>Broader Impacts.&nbsp;&nbsp;</strong>The techniques developed in this project significantly broaden the applicability of sparse representation theory to manifold clustering problems, which have widespread applications in image processing (image denoising, compression, representation and segmentation), computer vision (motion segmentation and face clustering) and dynamical systems (hybrid system identification). The findings impact methods for discovering connectivity in networks, which has broad applications in social networks, computational genomics, and beyond. The project supported diversity outreach activities, including ongoing REU programs and summer camps for K-12 outreach. The PIs also participated in the Robotic Systems Challenge, a competition where small robots are constructed by middle and high-school students from Baltimore, and the Women in Science and Engineering (WISE) program. Datasets and code are publicly accessible for research and educational purposes. In terms of student training and preparation, this project supported five PhD students and two undergraduate students, one of which was a female Research Experience for Undergraduate (REU) participant.</p><br> <p>            Last Modified: 04/25/2019<br>      Modified by: Daniel&nbsp;Robinson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Project Outcomes Discovering structure in high-dimensional data (e.g., images and videos) is an essential part of scientific discovery in many disciplines such as machine learning, computer vision, pattern recognition, and signal and image processing. Traditional methods for discovering structure in high-dimensional data rely on the assumption that high-dimensional data can be well approximated by a single low-dimensional manifold (e.g., a subspace). In practice, however, high-dimensional datasets are extremely complex with multiple low-dimensional structures, hence they are better modeled by a union of low-dimensional manifolds. The discovery of multiple low-dimensional manifolds in high-dimensional data faces many fundamental challenges. 1) The membership of data points to manifolds is often unknown, hence there is a need to learn the number of manifolds, cluster the data, and fit a low-dimensional manifold to each group. 2) Data are often contaminated by noise, missing entries, and outliers, hence methods that are robust to these corruptions are needed. 3) The associated optimization problems are often non-convex and NP hard, so that conditions under which convex relaxations provide the correct clustering are needed. 4) Modern datasets are massive, hence methods that scale up to the big data regime are needed. The research supported by this grant includes the design of new families of structured sparse and low-rank subspace clustering algorithms. The algorithms are based on a self-expressiveness property of the data, which states that an uncorrupted data point can be well approximated by a linear combination of other uncorrupted data points. We have shown that imposing structured sparse and low-rank regularization on the coefficients allows subspace-preserving representations to be found, from which subspace structures in the data may be discovered.  Intellectual Merit.  The following is a summary of the intellectual merit for this project. 1) Three new scalable approaches for subspace clustering were designed.  The first is a greedy strategy for obtaining subspace-preserving representations.  Being a greedy approach, the amount of computation performed may be bounded in advance, thus allowing for scalable implementations. The second uses the structure of the problem to formulate a new strategy for efficiently identifying subspace-preserving representations.  The third is a divide-and-conquer strategy that can handle datasets distributed among multiple computers. Theoretical guarantees of correctness were established for the first two methods, and extensive testing on major applications in computer vision were performed (face clustering and image classification) for all methods. The results showed that all three methods perform better than prior state-of-the-art methods, and exhibit a trade-off between computational cost and clustering accuracy that may be leveraged. 2) We developed algorithms for handling corruptions in the data that include missing entries, random noise, and outliers. New modeling formulations were designed and analyzed to cope with missing entries. Conditions were established under which perfect clustering and data completion is possible. To handle random noise, a nonconvex extension of the basic modeling formulation was proposed and analyzed, and optimization approaches for solving the relevant optimization problems were introduced. To handle outliers, the sparse subspace clustering scheme was combined with a random walk procedure over a specific graph, designed to identify outliers in the dataset. We proved conditions under which perfect clustering and outlier detection is possible. 3) To improve clustering performance on imbalanced data, we used knowledge of the underlying subspace structure to design a novel data subset selection procedure called exemplar selection.   The exemplars selected were proved theoretically and verified computationally to be balanced among the different subspaces, provided the dimensions of the subspaces were balanced. 4) To handle datasets that arise from affine spaces, an additional modeling constraint is commonly used.  We established that, when the dimension of the ambient dimension is large relative to the dimension of the subspaces, the addition of the affine constraint has no significant impact on the clustering performance.  In the complementary regime, our results show that the affine constraint may significantly improve the clustering performance.   Broader Impacts.  The techniques developed in this project significantly broaden the applicability of sparse representation theory to manifold clustering problems, which have widespread applications in image processing (image denoising, compression, representation and segmentation), computer vision (motion segmentation and face clustering) and dynamical systems (hybrid system identification). The findings impact methods for discovering connectivity in networks, which has broad applications in social networks, computational genomics, and beyond. The project supported diversity outreach activities, including ongoing REU programs and summer camps for K-12 outreach. The PIs also participated in the Robotic Systems Challenge, a competition where small robots are constructed by middle and high-school students from Baltimore, and the Women in Science and Engineering (WISE) program. Datasets and code are publicly accessible for research and educational purposes. In terms of student training and preparation, this project supported five PhD students and two undergraduate students, one of which was a female Research Experience for Undergraduate (REU) participant.       Last Modified: 04/25/2019       Submitted by: Daniel Robinson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
