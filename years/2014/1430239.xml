<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRCNS: Collaborative Research: Naturalistic computation and signaling by neural populations in the primate retina</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>414639.00</AwardTotalIntnAmount>
<AwardAmount>414639</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Vision begins in the retina, where light is converted into electrical signals, processed to extract and compress visual information, and transmitted through the optic nerve to the brain.  Despite decades of research, a full understanding of these transformations remains incomplete.  In particular, most studies have documented specific properties of the responses of single retinal cells in isolation, using specialized artificial visual stimuli.  The research performed under this grant aims to develop a full, unified computational model of retinal processing, including spatial and temporal filtering, nonlinear transformations, and adaptation to local luminance and contrast, in complete populations of neurons.  The model will be tested by comparing its predictions to data from large-scale multi-electrode recordings of primate retinal ganglion cells (RGCs), verifying that it can mimic known retinal responses, and critically, testing its ability to explain responses to natural visual images, including the effects of fixational and saccadic eye movements.  The resulting model will provide a compact encapsulation of the "neural code" of the retina, which will serve as a substrate for understanding all subsequent visual processing in the brain.  In addition, the model will provide an essential component in the development of high-acuity retinal prostheses for people blinded by diseases of photoreceptor degeneration.  Finally, the model will offer a useful tool for the development and testing of new display technologies.&lt;br/&gt;&lt;br/&gt;The research has two main aims:  (1) Develop and test a model of nonlinear subunits in RGC populations-- No current model captures the effects of nonlinear computations in a complete sensory neural circuit.  The researchers will develop a model incorporating nonlinear subunits that captures the stimulus encoding properties of complete populations of RGCs at the resolution of photoreceptors, and will quantify the implications of these nonlinearities for encoding naturally-occurring visual stimuli. The researchers will develop methods to reliably fit the model to RGC responses to targeted stimuli that stringently constrain model structure, and verify model predictions in closed-loop experiments.  (2) Incorporate adaptation; test model with targeted and naturalistic stimuli-- RGC responses adapt to luminance and stimulus contrast.  No current model of the RGC population response incorporates adaptation with subunit nonlinearities, natural scenes, and eye movements. The researchers will incorporate adaptation in the model, fit the adaptive model using stochastic stimuli with varying mean and contrast, and test the model using stimuli that produce adaptation within and across subunits.</AbstractNarration>
<MinAmdLetterDate>08/18/2014</MinAmdLetterDate>
<MaxAmdLetterDate>11/29/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1430239</AwardID>
<Investigator>
<FirstName>Liam</FirstName>
<LastName>Paninski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Liam Paninski</PI_FULL_NAME>
<EmailAddress>liam@stat.columbia.edu</EmailAddress>
<PI_PHON>2128512166</PI_PHON>
<NSF_ID>000440914</NSF_ID>
<StartDate>08/18/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>100277922</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7334</Code>
<Text>MATHEMATICAL BIOLOGY</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7327</Code>
<Text>CRCNS</Text>
</ProgramReference>
<ProgramReference>
<Code>8251</Code>
<Text>Math Sci Innovation Incubator</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~365575</FUND_OBLG>
<FUND_OBLG>2017~49064</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project led to significant improvements in the state of the art in three critical problems in statistical neuroscience: spike sorting, neural decoding, and neural activity prediction.</p> <p>&nbsp;</p> <p>We developed new spike sorting methods (&ldquo;YASS: Yet Another Spike Sorter applied to large-scale multi-electrode array recordings in primate retina&rdquo;; Lee et al 2020) that significantly improved on the state of the art, allowing us to extract more information from large, dense, multi-electrode array recordings in the retina.&nbsp; Spike sorting is a critical first step in extracting neural signals from large-scale multi-electrode array (MEA) data. (Lee et al 2020) presents several new techniques that make MEA spike sorting more robust and accurate. The proposed pipeline is based on an efficient multi-stage &ldquo;triage-then-cluster-then-pursuit&rdquo; approach that initially extracts only clean, high-quality waveforms from the electrophysiological time series by temporarily skipping noisy or &ldquo;collided&rdquo; events (representing two neurons firing synchronously). This is accomplished by developing a neural network detection and denoising method followed by efficient outlier triaging. The denoised spike waveforms are then used to infer the set of spike templates through nonparametric Bayesian clustering. We use a divide-and-conquer strategy to parallelize this clustering step. Finally, we recover collided waveforms with matching-pursuit deconvolution techniques, and perform further split-and-merge steps to estimate additional templates from the pool of recovered waveforms. We apply the new pipeline to data recorded in the primate retina, where high firing rates and highly-overlapping axonal units provide a challenging testbed for the deconvolution approach; in addition, the well-defined mosaic structure of receptive fields in this preparation provides a useful quality check on any spike sorting pipeline. We show that our pipeline improves on the state-of-the-art in spike sorting (and outperforms manual sorting) on both real and semi-simulated MEA data with &gt; 500 electrodes; open source code can be found at&nbsp;<a href="https://github.com/paninski-lab/yass">https://github.com/paninski-lab/yass</a>.</p> <p>&nbsp;</p> <p>These improvements in spike sorting, along with new neural network architectures for decoding, in turn led to significant improvements in our ability to decode images from retinal neural activity (&ldquo;Nonlinear decoding of natural images from large-scale primate retinal ganglion recordings&rdquo;; Kim et al 2020).&nbsp; Decoding sensory stimuli from neural activity can provide insight into how the nervous system might interpret the physical environment, and facilitates the development of brain-machine interfaces. Nevertheless, the neural decoding problem remains a significant open challenge. We developed an efficient nonlinear decoding approach for inferring natural scene stimuli from the spiking activities of retinal ganglion cells (RGCs). Our approach uses neural networks to improve upon existing decoders in both accuracy and scalability. Trained and validated on real retinal spike data from &gt; 1000 simultaneously recorded macaque RGC units, the decoder demonstrates the necessity of nonlinear computations for accurate decoding of the fine structures of visual stimuli. Specifically, high-pass spatial features of natural images can only be decoded using nonlinear techniques, while low-pass features can be extracted equally well by linear and nonlinear methods. Together, these results advance the state of the art in decoding natural stimuli from large populations of neurons.</p> <p>&nbsp;</p> <p>Finally, we developed new encoding models to predict the responses of populations of retinal ganglion cells to natural images (&ldquo;Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses&rdquo;; Batty et al 2017).&nbsp; Developing accurate predictive models of sensory neurons is vital to understanding sensory processing and brain computations. The current standard approach to modeling neurons is to start with simple models and to incrementally add interpretable features. An alternative approach is to start with a more complex model that captures responses accurately, and then probe the fitted model structure to understand the neural computations. We showed that a multitask recurrent neural network (RNN) framework provides the flexibility necessary to model complex computations of neurons that cannot be captured by previous methods. Specifically, multilayer recurrent neural networks that share features across neurons outperform generalized linear models (GLMs) in predicting the spiking responses of parasol ganglion cells in the primate retina to natural images. The networks achieve good predictive performance given modest amounts of experimental training data. Additionally, we present a novel GLM-RNN hybrid model with separate spatial and temporal processing components which provides insights into the aspects of retinal processing better captured by the recurrent neural networks.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/17/2021<br>      Modified by: Liam&nbsp;Paninski</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project led to significant improvements in the state of the art in three critical problems in statistical neuroscience: spike sorting, neural decoding, and neural activity prediction.     We developed new spike sorting methods ("YASS: Yet Another Spike Sorter applied to large-scale multi-electrode array recordings in primate retina"; Lee et al 2020) that significantly improved on the state of the art, allowing us to extract more information from large, dense, multi-electrode array recordings in the retina.  Spike sorting is a critical first step in extracting neural signals from large-scale multi-electrode array (MEA) data. (Lee et al 2020) presents several new techniques that make MEA spike sorting more robust and accurate. The proposed pipeline is based on an efficient multi-stage "triage-then-cluster-then-pursuit" approach that initially extracts only clean, high-quality waveforms from the electrophysiological time series by temporarily skipping noisy or "collided" events (representing two neurons firing synchronously). This is accomplished by developing a neural network detection and denoising method followed by efficient outlier triaging. The denoised spike waveforms are then used to infer the set of spike templates through nonparametric Bayesian clustering. We use a divide-and-conquer strategy to parallelize this clustering step. Finally, we recover collided waveforms with matching-pursuit deconvolution techniques, and perform further split-and-merge steps to estimate additional templates from the pool of recovered waveforms. We apply the new pipeline to data recorded in the primate retina, where high firing rates and highly-overlapping axonal units provide a challenging testbed for the deconvolution approach; in addition, the well-defined mosaic structure of receptive fields in this preparation provides a useful quality check on any spike sorting pipeline. We show that our pipeline improves on the state-of-the-art in spike sorting (and outperforms manual sorting) on both real and semi-simulated MEA data with &gt; 500 electrodes; open source code can be found at https://github.com/paninski-lab/yass.     These improvements in spike sorting, along with new neural network architectures for decoding, in turn led to significant improvements in our ability to decode images from retinal neural activity ("Nonlinear decoding of natural images from large-scale primate retinal ganglion recordings"; Kim et al 2020).  Decoding sensory stimuli from neural activity can provide insight into how the nervous system might interpret the physical environment, and facilitates the development of brain-machine interfaces. Nevertheless, the neural decoding problem remains a significant open challenge. We developed an efficient nonlinear decoding approach for inferring natural scene stimuli from the spiking activities of retinal ganglion cells (RGCs). Our approach uses neural networks to improve upon existing decoders in both accuracy and scalability. Trained and validated on real retinal spike data from &gt; 1000 simultaneously recorded macaque RGC units, the decoder demonstrates the necessity of nonlinear computations for accurate decoding of the fine structures of visual stimuli. Specifically, high-pass spatial features of natural images can only be decoded using nonlinear techniques, while low-pass features can be extracted equally well by linear and nonlinear methods. Together, these results advance the state of the art in decoding natural stimuli from large populations of neurons.     Finally, we developed new encoding models to predict the responses of populations of retinal ganglion cells to natural images ("Multilayer Recurrent Network Models of Primate Retinal Ganglion Cell Responses"; Batty et al 2017).  Developing accurate predictive models of sensory neurons is vital to understanding sensory processing and brain computations. The current standard approach to modeling neurons is to start with simple models and to incrementally add interpretable features. An alternative approach is to start with a more complex model that captures responses accurately, and then probe the fitted model structure to understand the neural computations. We showed that a multitask recurrent neural network (RNN) framework provides the flexibility necessary to model complex computations of neurons that cannot be captured by previous methods. Specifically, multilayer recurrent neural networks that share features across neurons outperform generalized linear models (GLMs) in predicting the spiking responses of parasol ganglion cells in the primate retina to natural images. The networks achieve good predictive performance given modest amounts of experimental training data. Additionally, we present a novel GLM-RNN hybrid model with separate spatial and temporal processing components which provides insights into the aspects of retinal processing better captured by the recurrent neural networks.             Last Modified: 03/17/2021       Submitted by: Liam Paninski]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
