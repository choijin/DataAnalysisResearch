<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RUI: CCSS: Collaborative Research: Cooperative Unmanned Aerial Vehicles Enabled Scalable Mobile Panoramic Video Surveillance</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>178174.00</AwardTotalIntnAmount>
<AwardAmount>178174</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jenshan Lin</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project investigates a cyber-physical system (CPS) in which cooperative unmanned aerial vehicles (UAVs) are used to enable scalable mobile panoramic video surveillance. This system generates mobile real-time video panorama by flying a fleet of cooperative UAVs. It is an interdisciplinary collaborative effort that synthesizes the expertise of Computer Science and Aerospace Engineering. This project demonstrates a convergence of sensing, control and communication. The project will generate outcomes including distributed video stitching algorithms, scalable distributed systems, and cooperative optimal flight control algorithms. This project significantly improves the performance such as delay and error in video panorama results. It advances the frontiers of both video processing and control theory. This interdisciplinary effort will promote and contribute to crosscutting collaborations between two research communities: computer science and aerospace engineering. The project aims to improve the education of underrepresented student populations by involving them in the proposed research activities and enhancing course curriculum. Results of this project have broad applications to areas such as remote sensing, environmental sampling and monitoring, homeland security, etc.  &lt;br/&gt;&lt;br/&gt;The project has three research thrusts: 1) distributed hierarchical video stitching to generate mobile video panorama across cooperative UAVs with high scalability, 2) integrated optimal cooperative control of UAV formation flying to support the distributed video stitching, and 3) integration, interfacing and communication to unite the distributed hierarchical video stitching and the cooperative control of formation flying. A prototype system will be developed for evaluation. It has four salient merits. First, the distributed hierarchical architecture is scalable to mobile cameras and fault-tolerant. Second, it exploits the temporal and spatial features of video frames for efficient computation. Third, the integrated optimal cooperative flight control addresses the multiple cooperative objectives in one unified framework, and provides a computationally efficient, distributed and control. Forth, the unification of distributed video stitching and cooperative control of UAV facilitates the generation of mobile video panorama. In particular, the distributed video stitching minimizes the stress of intensive computation required in stitching. It maintains high synchronization among video frames by pushing the stitching to the front close to the cameras. The proposed hierarchical video stitching significantly contributes to distributed system theory and algorithms. In addition, the stitching algorithms exploit the spatial and temporal correlation among UAV videos, yielding a novel contribution to computer graphics/vision. The proposed optimal cooperative control method will significantly advance the cooperative control of multi-vehicle or multi-agent systems. It integrates many challenging cooperative problems into one unified optimization framework.  This method enables a number of desired capabilities: closed-form, distributed and local information based control law, synchronous formation, cooperative tracking, and obstacle/collision avoidance. These integrated features not only make precise and real-time cooperative surveillance possible, but also move forward the cooperative control theory to a new horizon for a wide range of cooperative missions.</AbstractNarration>
<MinAmdLetterDate>08/19/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1407735</AwardID>
<Investigator>
<FirstName>Ming</FirstName>
<LastName>Xin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ming Xin</PI_FULL_NAME>
<EmailAddress>xin@missouri.edu</EmailAddress>
<PI_PHON>5738827933</PI_PHON>
<NSF_ID>000509254</NSF_ID>
<StartDate>08/19/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Missouri-Columbia</Name>
<CityName>COLUMBIA</CityName>
<ZipCode>652110001</ZipCode>
<PhoneNumber>5738827560</PhoneNumber>
<StreetAddress>115 Business Loop 70 W</StreetAddress>
<StreetAddress2><![CDATA[Mizzou North, Room 501]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153890272</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Missouri-Columbia]]></Name>
<CityName>Columbia</CityName>
<StateCode>MO</StateCode>
<ZipCode>652111230</ZipCode>
<StreetAddress><![CDATA[310 Jesse Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>092E</Code>
<Text>Control systems &amp; applications</Text>
</ProgramReference>
<ProgramReference>
<Code>152E</Code>
<Text>Cyber-Physical Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>153E</Code>
<Text>Wireless comm &amp; sig processing</Text>
</ProgramReference>
<ProgramReference>
<Code>154E</Code>
<Text>Computat systems &amp; security</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~178174</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The importance of sports safety and security cannot be overstated&ndash;millions of people attend sporting games every year. Video surveillance is an effective instrument for security and safety management by providing in-situ real-time multimedia information of the sport site. However, the traditional video surveillance simply takes the video streams from fixed cameras and displays them separately in segmented windows, which is inconvenient and unfriendly, and sometimes even distracts and confuses security staff when threats appear in multiple windows that cover the same overlapping areas. The immobile deployment of cameras is not effective in providing flexible surveillance, especially in collecting details of dynamic suspicious spots. To address this issue, this project aims to develop a real-time video surveillance system capable of providing a unified wide panorama based on a mobile sensing platform of a fleet of cooperative unmanned aerial vehicles (UAVs).<em>&nbsp;</em></p> <p>The outcomes of this project can be summarized as follows:</p> <p>1) A distributed hierarchical video stitching scheme to generate mobile video panorama across cooperative UAVs with high scalability was developed. It exploits the temporal and spatial correlations among video frames for efficient computation, which is a unique approach in this system. 2) A distributed nonlinear estimation scheme was designed for target tracking with a team of UAVs. Each UAV only communicates with its neighbors and the fusion of the estimates is achieved by a new high degree cubature information filter integrated with an average consensus algorithm. Extension to the distributed multiple sensor multiple target tracking was achieved by utilizing distributed cubature Gaussian mixture filter and an iterative diffusion strategy as well as a new high-degree cubature joint probabilistic data association information filter. 3) A novel Hermite polynomial uncorrelated conversion filter was developed to improve the target tracking performance under passive bearings-only measurement, which can effectively address the challenging estimation problem due to high nonlinearity and low observability. 4) An integrated optimal cooperative control of UAV formation flying was designed to support the distributed video stitching. A vision-feedback closed-loop formation control was employed to achieve improved performance. 5) The distributed hierarchical video stitching and the cooperative control of UAV formation flying were tightly integrated to facilitate the generation of mobile video panorama.</p> <p><strong>Intellectual Merit</strong>: This project is an example of emerging convergence of sensing, control and communication. The distributed video stitching minimizes the stress of intensive computation required in stitching. It maintains high synchronization among video frames by pushing the stitching to the frontier close to the cameras. Its hierarchical cluster-based architecture is scalable to the number of cameras because of the distributed feature. It is fully supported by the cooperative formation flying of UAVs. The proposed stitching algorithms exploiting the spatial and temporal correlation among UAV enabled videos make a novel contribution to computer graphics/vision. The developed optimal cooperative control method integrates many challenging cooperative problems into one unified optimization framework. It can achieve a number of desired capabilities such as closed-form, distributed, and local information based control law, synchronous formation, cooperative tracking, and obstacle/collision avoidance. These integrated features not only make possible precise and real-time cooperative surveillance, but also advance the cooperative control theory to a new horizon for a wide range of cooperative missions.</p> <p><strong>Broader Impacts</strong>: The innovative video surveillance by multiple UAVs has an immediate target at sports safety and security management and will benefit millions of sports spectators yearly. The proposed schemes can be easily extended to many other cooperative cyber-physical systems such as environmental sampling and monitoring, cooperative classification of targets, distributed aperture observing, remote sensing, and battle field assessment in which the Department of Homeland Security and Department of Defense are highly interested.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/08/2018<br>      Modified by: Ming&nbsp;Xin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The importance of sports safety and security cannot be overstated&ndash;millions of people attend sporting games every year. Video surveillance is an effective instrument for security and safety management by providing in-situ real-time multimedia information of the sport site. However, the traditional video surveillance simply takes the video streams from fixed cameras and displays them separately in segmented windows, which is inconvenient and unfriendly, and sometimes even distracts and confuses security staff when threats appear in multiple windows that cover the same overlapping areas. The immobile deployment of cameras is not effective in providing flexible surveillance, especially in collecting details of dynamic suspicious spots. To address this issue, this project aims to develop a real-time video surveillance system capable of providing a unified wide panorama based on a mobile sensing platform of a fleet of cooperative unmanned aerial vehicles (UAVs).   The outcomes of this project can be summarized as follows:  1) A distributed hierarchical video stitching scheme to generate mobile video panorama across cooperative UAVs with high scalability was developed. It exploits the temporal and spatial correlations among video frames for efficient computation, which is a unique approach in this system. 2) A distributed nonlinear estimation scheme was designed for target tracking with a team of UAVs. Each UAV only communicates with its neighbors and the fusion of the estimates is achieved by a new high degree cubature information filter integrated with an average consensus algorithm. Extension to the distributed multiple sensor multiple target tracking was achieved by utilizing distributed cubature Gaussian mixture filter and an iterative diffusion strategy as well as a new high-degree cubature joint probabilistic data association information filter. 3) A novel Hermite polynomial uncorrelated conversion filter was developed to improve the target tracking performance under passive bearings-only measurement, which can effectively address the challenging estimation problem due to high nonlinearity and low observability. 4) An integrated optimal cooperative control of UAV formation flying was designed to support the distributed video stitching. A vision-feedback closed-loop formation control was employed to achieve improved performance. 5) The distributed hierarchical video stitching and the cooperative control of UAV formation flying were tightly integrated to facilitate the generation of mobile video panorama.  Intellectual Merit: This project is an example of emerging convergence of sensing, control and communication. The distributed video stitching minimizes the stress of intensive computation required in stitching. It maintains high synchronization among video frames by pushing the stitching to the frontier close to the cameras. Its hierarchical cluster-based architecture is scalable to the number of cameras because of the distributed feature. It is fully supported by the cooperative formation flying of UAVs. The proposed stitching algorithms exploiting the spatial and temporal correlation among UAV enabled videos make a novel contribution to computer graphics/vision. The developed optimal cooperative control method integrates many challenging cooperative problems into one unified optimization framework. It can achieve a number of desired capabilities such as closed-form, distributed, and local information based control law, synchronous formation, cooperative tracking, and obstacle/collision avoidance. These integrated features not only make possible precise and real-time cooperative surveillance, but also advance the cooperative control theory to a new horizon for a wide range of cooperative missions.  Broader Impacts: The innovative video surveillance by multiple UAVs has an immediate target at sports safety and security management and will benefit millions of sports spectators yearly. The proposed schemes can be easily extended to many other cooperative cyber-physical systems such as environmental sampling and monitoring, cooperative classification of targets, distributed aperture observing, remote sensing, and battle field assessment in which the Department of Homeland Security and Department of Defense are highly interested.          Last Modified: 10/08/2018       Submitted by: Ming Xin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
