<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Core: Monotonic Retargeting: A Scalable Learning Framework for Determining Order</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>496167.00</AwardTotalIntnAmount>
<AwardAmount>496167</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Aidong Zhang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Determining preferences, or identifying and ordering items of most interest or relevance based on very limited information, is a fundamental problem in many disciplines.  While perhaps most obvious in search, the problem shows up in areas as diverse as economics and health informatics. This project is developing a broad methodology to address challenging learning problems that involve ordering, including determining top choices for recommendation, multi-label classification, and learning to rank-order a set of query results. The key insight is that if the objects to be ordered are given numeric scores, only the relative values of these scores affect their ranking, and not the actual values.  This project is using this insight to develop new and better learning algorithms for ranking.&lt;br/&gt;&lt;br/&gt;Specifically, the project is developing methods that can efficiently optimize over all possible monotonic (that is, order preserving) transformations of scores. Since these scores become the target values for regression, this class of approaches is being called monotonic retargeting. A systematic way of alternating between readjusting scores and updating the regression model is being developed, with nice properties for scalability and distributed implementation, as well as strong convergence guarantees. Themes common to different types of preference learning or ranking studies are being identified to help bring together the diverse communities, including students, that work on this topic. This wide coverage is possible as it easy to relate to the need to determine priorities and make choices in various walks of life. The applications and impacts of the project are expected to be wide and diverse as well.</AbstractNarration>
<MinAmdLetterDate>07/23/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1421729</AwardID>
<Investigator>
<FirstName>Joydeep</FirstName>
<LastName>Ghosh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joydeep Ghosh</PI_FULL_NAME>
<EmailAddress>jghosh@utexas.edu</EmailAddress>
<PI_PHON>5124718980</PI_PHON>
<NSF_ID>000446751</NSF_ID>
<StartDate>07/23/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121084</ZipCode>
<StreetAddress><![CDATA[1 Univ Station, C0803]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~164061</FUND_OBLG>
<FUND_OBLG>2015~165343</FUND_OBLG>
<FUND_OBLG>2016~166763</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project aimed to develop a broad methodology to address challenging learning problems that involve prioritizing or ordering, including determining top choices for recommendation, multi-label classification, and learning to rank-order a set of query results. The key insight was that if the objects to be ordered are given numeric scores, only the relative values of these scores affect their ranking, and not the actual values. This flexibility was used to develop new and better learning algorithms for ranking, using a new framework of monotonic retargeting. This framework provides methods that can efficiently optimize over all possible monotonic (that is, order preserving) transformations of scores that would then serve as target scores for a suitable regression model. A systematic way of alternating between readjusting scores and updating the regression model was developed, with nice properties for scalability and distributed implementation, as well as strong convergence guarantees. Overall, these advances led to development of accurate and scalable approaches to ranking which is one of the very popular applications of machine learning in industry, and is used, for example to prioritize search results or product recommendations.</p> <p>In addition, new formulations involving monotonic retargeting were invented for two broad application domains not conceived of in the original proposal: (i) reasoning and predictive modeling given aggregated data and (ii) combining rank aggregation approaches with Learning to Rank (LETOR) base approaches that can leverage both multiple black-box rankings as well as features of the objects to be ranked. Of particular note is the combination rank aggregation and ranking based approach, which unites concepts from two disparate communities and greatly generalizes preference learning to broader settings where both object features and multiple rankers are available.</p> <p>The monotonic retargeting framework to build predictive models was also extended to apply to situations where the dependent variable is available only in summarized histogram form. &nbsp;This &nbsp;opened &nbsp;a whole new range of applications where one is able to exploit supplementary information that is publicly available only in aggregated form (for privacy reasons), &nbsp;giving a positive perspective on the privacy-utility debate</p> <p>The research supported by this grant has been published in over 12 papers in the very top machine learning conferences and additional papers in other refereed venues. They have been presented at several invited talks by the PI as well. Companies such as Microsoft, Verizon and LinkedIn have shown great interest in these works, and it is likely that solutions inspired by the ideas supported by this grant will appear in industry in the near future. Moreover, since learning preference is a common problem across multiple disciplines including the social sciences, the outputs of this grant are expected to have broader impacts in academia beyond the immediate community as well.</p> <p>Of the personnel supported by this grant, one is now a tenure-track faculty member at the Univ. of Illinois, Urbana, and the second student has just joined UC Berkeley with the prestigious Simmons Post-doc fellowship. The third student will defend his PhD this semester and already has multiple job offers from industry.</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/01/2018<br>      Modified by: Joydeep&nbsp;Ghosh</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project aimed to develop a broad methodology to address challenging learning problems that involve prioritizing or ordering, including determining top choices for recommendation, multi-label classification, and learning to rank-order a set of query results. The key insight was that if the objects to be ordered are given numeric scores, only the relative values of these scores affect their ranking, and not the actual values. This flexibility was used to develop new and better learning algorithms for ranking, using a new framework of monotonic retargeting. This framework provides methods that can efficiently optimize over all possible monotonic (that is, order preserving) transformations of scores that would then serve as target scores for a suitable regression model. A systematic way of alternating between readjusting scores and updating the regression model was developed, with nice properties for scalability and distributed implementation, as well as strong convergence guarantees. Overall, these advances led to development of accurate and scalable approaches to ranking which is one of the very popular applications of machine learning in industry, and is used, for example to prioritize search results or product recommendations.  In addition, new formulations involving monotonic retargeting were invented for two broad application domains not conceived of in the original proposal: (i) reasoning and predictive modeling given aggregated data and (ii) combining rank aggregation approaches with Learning to Rank (LETOR) base approaches that can leverage both multiple black-box rankings as well as features of the objects to be ranked. Of particular note is the combination rank aggregation and ranking based approach, which unites concepts from two disparate communities and greatly generalizes preference learning to broader settings where both object features and multiple rankers are available.  The monotonic retargeting framework to build predictive models was also extended to apply to situations where the dependent variable is available only in summarized histogram form.  This  opened  a whole new range of applications where one is able to exploit supplementary information that is publicly available only in aggregated form (for privacy reasons),  giving a positive perspective on the privacy-utility debate  The research supported by this grant has been published in over 12 papers in the very top machine learning conferences and additional papers in other refereed venues. They have been presented at several invited talks by the PI as well. Companies such as Microsoft, Verizon and LinkedIn have shown great interest in these works, and it is likely that solutions inspired by the ideas supported by this grant will appear in industry in the near future. Moreover, since learning preference is a common problem across multiple disciplines including the social sciences, the outputs of this grant are expected to have broader impacts in academia beyond the immediate community as well.  Of the personnel supported by this grant, one is now a tenure-track faculty member at the Univ. of Illinois, Urbana, and the second student has just joined UC Berkeley with the prestigious Simmons Post-doc fellowship. The third student will defend his PhD this semester and already has multiple job offers from industry.          Last Modified: 09/01/2018       Submitted by: Joydeep Ghosh]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
