<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: The Power of Online Learning in Stochastic System Optimization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>376628.00</AwardTotalIntnAmount>
<AwardAmount>376628</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project considers a constrained optimization problem applied to a stochastic system with dynamic system states that have a stationary state distribution. At each state, an operation is implemented and a corresponding system cost occurs depending on the chosen action; the objective is to minimize the expected cost given service/demand constraints. Solving this problem is challenging and the main difficulty comes from the fact that the state distribution of the system is often unknown a priori and may change over time in practice. Known algorithms that handle this challenge, in particular, Backpressure algorithms, suffer from a slow convergence speed and poor short-term performance. This project instead investigates the value of online learning in optimal stochastic system control. Preliminary results have produced an online-learning technique called dual learning, along with two corresponding online-learning-aided control strategies. Lagrange multipliers form key quantities in solving a constrained optimization problem; the queue vector turns out to play the role of Lagrange multiplier, and thus one can utilize the information of the system dynamics for accelerating the learning of the control algorithm. Based on this insight, we systematically study the value of online learning in optimal stochastic system control in the following thrusts: 1) Fundamental Limits: We investigate the performance limits of the proposed online-learning-based-strategies, in particular, how fast is it possible for any control scheme to converge to the optimal and what is the corresponding utility-delay tradeoff? 2) Control with partially observable states: We study the practical scenario where one has uncertainty in the cost function of an action. We plan to not only develop efficient algorithms, but also conduct utility-delay tradeoff analysis and regret analysis for the proposed schemes. 3) Performance Evaluation: We evaluate the performance of the proposed algorithms under various settings and through trace-driven evaluations to compare their pros and cons.  &lt;br/&gt;&lt;br/&gt;Because the generality and importance of such stochastic system optimization problems, the proposed approaches have the potential to be applied in different areas, such  as display-advertisement allocation, wireless network control, and Smart Grids. We leverage on-going collaborations with industry to disseminate the research results in real applications. We continue the effort in recruiting and training undergraduate researchers and under-represented groups through this project.</AbstractNarration>
<MinAmdLetterDate>07/22/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1423542</AwardID>
<Investigator>
<FirstName>Xin</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xin Liu</PI_FULL_NAME>
<EmailAddress>liu@cs.ucdavis.edu</EmailAddress>
<PI_PHON>5307546907</PI_PHON>
<NSF_ID>000289050</NSF_ID>
<StartDate>07/22/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Davis</Name>
<CityName>Davis</CityName>
<ZipCode>956186134</ZipCode>
<PhoneNumber>5307547700</PhoneNumber>
<StreetAddress>OR/Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1850 Research Park Dr., Ste 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>047120084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, DAVIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Davis]]></Name>
<CityName>Davis</CityName>
<StateCode>CA</StateCode>
<ZipCode>956165270</ZipCode>
<StreetAddress><![CDATA[One Shields Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~376628</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>Intellectual merits:</p> <p>In this project, we investigate the power of online learning in stochastic network optimization with unknown system statistics a priori. We propose two Online Learning-Aided Control techniques, OLAC and OLAC2, that explicitly utilize the past system information in current system control via a learning procedure called dual learning. We prove strong performance guarantees of the proposed algorithms: the algorithms achieve near-optimal utility-delay tradeoff and faster convergence time. Building upon the theoretical foundation, we propose learning-aided scheduling algorithms for MNVOs and demonstrate their superior performance using simulations based on real network traces.</p> <p>We study the constrained contextual bandits (CCB) problem that integrates information learning and decision making with context and under budget. We propose an algorithm with both computational simplicity and theoretically optimal performance guarantees. In particular, the algorithm integrates a learning component (UCB) and a decision component (ALP) in a coherent manner so that they result in optimal actions, while maintaining a level of independence so that desirable properties of each component are retained. While the algorithm itself has a simplicity appeal, its performance analysis is highly involved that provides important insights in designing joint learning and decision algorithms. We also run an experiment on Amazon Mechanic Turk to evaluate the performance of the proposed algorithms.</p> <p>The dueling bandit problem is a variant of the classical multi-armed bandit (MAB) problem, where the feedback comes in the form of pairwise comparison. This model has attracted much attention as it can be applied to in many systems where preference information is easier to obtain and typically more stable. In this work, we propose a Double Thompson Sampling (D-TS) algorithm for dueling bandit problems. We prove strong theoretical guarantees of the proposed algorithm. Experiments based on both synthetic and real-world data demonstrate that D-TS significantly improves overall performance, in terms of regret and robustness.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>Broader Impact:</p> <p>The results of this project help the community better understand how to incorporate information and learning into system control techniques, and the fundamental benefits of doing so. Furthermore, this project is interdisciplinary in nature as it is closely related to both the machine learning community and the networking community. The results in this project can bring the researchers in the two communities closer and generate better understandings of how learning facilitates network control. Furthermore, our work was presented at a number of conferences and workshops with diverse audience in both the communication/networking community and the machine learning community. Such interdisciplinary communications are timely and much needed to bridge the two communities.</p> <p>Our project also contributes to the development of human resources. &nbsp;Dr. Huasen Wu and Dr. Xueying Guo, two postdoc researchers, have worked on this project. They both have gained significant amount of experience in terms of identifying problems, solving problem, and studying the practical implications of proposed techniques. They both have collaborated with other researchers, graduate students, and undergraduate researchers. They both have improved significantly in terms of collaboration, communication, and leadership skills. Mr. Xiaoxiao Wang and Mr. Shahbaz Rezaei, two PhD students, have worked on this project, one independently and one in collaboration with Dr. Xueying Guo. They have gained important research experience in terms of identifying problems, proposing solutions, and studying practical implications of proposed techniques. They have also gained communication and collaboration skills. Mr. Tianxiao Zhang, a MS graduate, has worked on this project, in collaboration with Dr. Huasen Wu. He has gained important research experience in terms of identifying problems, proposing solutions, and studying practical implications of proposed techniques. Two undergraduate students, Daniel Ruiz and Qingyang Wu, have worked with us on research. They have both gained good research experience, communication skills, collaboration skills, in addition to important technical skills.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/29/2018<br>      Modified by: Xin&nbsp;Liu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    Intellectual merits:  In this project, we investigate the power of online learning in stochastic network optimization with unknown system statistics a priori. We propose two Online Learning-Aided Control techniques, OLAC and OLAC2, that explicitly utilize the past system information in current system control via a learning procedure called dual learning. We prove strong performance guarantees of the proposed algorithms: the algorithms achieve near-optimal utility-delay tradeoff and faster convergence time. Building upon the theoretical foundation, we propose learning-aided scheduling algorithms for MNVOs and demonstrate their superior performance using simulations based on real network traces.  We study the constrained contextual bandits (CCB) problem that integrates information learning and decision making with context and under budget. We propose an algorithm with both computational simplicity and theoretically optimal performance guarantees. In particular, the algorithm integrates a learning component (UCB) and a decision component (ALP) in a coherent manner so that they result in optimal actions, while maintaining a level of independence so that desirable properties of each component are retained. While the algorithm itself has a simplicity appeal, its performance analysis is highly involved that provides important insights in designing joint learning and decision algorithms. We also run an experiment on Amazon Mechanic Turk to evaluate the performance of the proposed algorithms.  The dueling bandit problem is a variant of the classical multi-armed bandit (MAB) problem, where the feedback comes in the form of pairwise comparison. This model has attracted much attention as it can be applied to in many systems where preference information is easier to obtain and typically more stable. In this work, we propose a Double Thompson Sampling (D-TS) algorithm for dueling bandit problems. We prove strong theoretical guarantees of the proposed algorithm. Experiments based on both synthetic and real-world data demonstrate that D-TS significantly improves overall performance, in terms of regret and robustness.        Broader Impact:  The results of this project help the community better understand how to incorporate information and learning into system control techniques, and the fundamental benefits of doing so. Furthermore, this project is interdisciplinary in nature as it is closely related to both the machine learning community and the networking community. The results in this project can bring the researchers in the two communities closer and generate better understandings of how learning facilitates network control. Furthermore, our work was presented at a number of conferences and workshops with diverse audience in both the communication/networking community and the machine learning community. Such interdisciplinary communications are timely and much needed to bridge the two communities.  Our project also contributes to the development of human resources.  Dr. Huasen Wu and Dr. Xueying Guo, two postdoc researchers, have worked on this project. They both have gained significant amount of experience in terms of identifying problems, solving problem, and studying the practical implications of proposed techniques. They both have collaborated with other researchers, graduate students, and undergraduate researchers. They both have improved significantly in terms of collaboration, communication, and leadership skills. Mr. Xiaoxiao Wang and Mr. Shahbaz Rezaei, two PhD students, have worked on this project, one independently and one in collaboration with Dr. Xueying Guo. They have gained important research experience in terms of identifying problems, proposing solutions, and studying practical implications of proposed techniques. They have also gained communication and collaboration skills. Mr. Tianxiao Zhang, a MS graduate, has worked on this project, in collaboration with Dr. Huasen Wu. He has gained important research experience in terms of identifying problems, proposing solutions, and studying practical implications of proposed techniques. Two undergraduate students, Daniel Ruiz and Qingyang Wu, have worked with us on research. They have both gained good research experience, communication skills, collaboration skills, in addition to important technical skills.             Last Modified: 12/29/2018       Submitted by: Xin Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
