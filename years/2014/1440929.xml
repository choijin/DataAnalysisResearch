<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Model Driven Framework for Audio Forensics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2014</AwardEffectiveDate>
<AwardExpirationDate>11/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>70000.00</AwardTotalIntnAmount>
<AwardAmount>86000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Deborah Shands</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to investigate the reliability, robustness, and computationally efficiency of digital audio forensic methods under various adversarial conditions, e.g., lossy compression attack. We aim to identify and develop mathematical tools for modeling and characterizing of microphone nonlinearities (fingerprints), statistical methods for acoustic environment estimation, and system identification based framework for linking an acquisition device to the audio recording. More specifically, the project uses statistical modeling and extraction of microphone fingerprints by developing computationally efficient algorithms for nonlinear system identification and acoustic environment modeling and extraction using nonlinear filtering, and use them for linking a given recording to the acquisition device and to the acoustic environment. The algorithms developed through this project holds the potential for immediate effect in the area of digital audio forensic analysis, particularly in forensic analysis in compressed domain. &lt;br/&gt;&lt;br/&gt;The developed techniques will be evaluated for robustness, reliability, and computational complexity using datasets collected during this exploratory investigation and datasets available in the public domain. The expected outcomes also include datasets for performance evaluation of audio forensic methods and audio forensics tools robust to targeted attacks. The findings of this research, resulting audio forensic tools, and datasets will be made available to the research community via project webpage.</AbstractNarration>
<MinAmdLetterDate>04/23/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/11/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1440929</AwardID>
<Investigator>
<FirstName>Hafiz</FirstName>
<LastName>Malik</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hafiz Malik</PI_FULL_NAME>
<EmailAddress>hafiz@umich.edu</EmailAddress>
<PI_PHON>3135935677</PI_PHON>
<NSF_ID>000504526</NSF_ID>
<StartDate>04/23/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan - Dearborn]]></Name>
<CityName>Dearborn</CityName>
<StateCode>MI</StateCode>
<ZipCode>481282406</ZipCode>
<StreetAddress><![CDATA[4901 Evergreen Rd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~70000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The proliferation of powerful smart-computing devices (e.g., smartphones, surveillance systems) capable of multimedia production, editing, analysis, and sharing and technological advances have affected almost every aspect of our lives ranging from social networking to law enforcement, legal proceedings, and so on. Today, the use of digital multimedia (audio, video, and images) as evidence in every sector of litigation and criminal justice proceedings is becoming the norm. For digital media to be admitted as evidence into a court of law, its <strong>authenticity </strong>and<strong> integrity <span style="text-decoration: underline;">must be verified</span></strong>. This requirement is a challenging task, especially in the absence of helping data, such as <em>digital watermarks,</em> and if the media is post-processed with anti-forensic intent. The availability of powerful, sophisticated, and easy-to-use digital audio editing manipulation tools (e.g. Audacity, Adobe Audition, etc.) has made integrity authentication of digital audio even more difficult. The research effort supported by this award was aim to investigate:</p> <ul> <li><em>Is an evidentiary recording &lsquo;original&rsquo; or was it created by splicing multiple recordings?</em><em>&nbsp;</em></li> <li><em>Is it possible to link an evidentiary recording to <strong>&lsquo;the&rsquo; microphone</strong> used?</em><em></em></li> <li><em>As claimed, was the evidentiary recording captured using an acquisition device X at location L?</em><em></em></li> <li><em>Was the evidentiary recording made using acquisition device manufactured by vendor X or vendor Y?</em><em></em></li> <li><em>What is the performance of a given audio forensic method in the present of anti-forensic attack?</em><em></em></li> </ul> <p>The results of our experiments gave us a number of new insights into how audio integrity authentication can be achieved using microphone and acoustic environment distortions and impact of anti-forensic attacks on the performance of existing audio forensics methods. We have also learned existing forgery detection methods are vulnerable to anti-forensic attacks. We have learned that de-reverberation based attacks can be used to avoid forgery detection using environment signature-based audio forensic analysis methods. Similarly, existing learning based microphone classification method are susceptible to splicing attacks. We have also learned that anti-forensic attacks leave their artifacts in the resulting audio which can be used to detect presence of anti-forensics attack.</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/25/2017<br>      Modified by: Hafiz&nbsp;Malik</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The proliferation of powerful smart-computing devices (e.g., smartphones, surveillance systems) capable of multimedia production, editing, analysis, and sharing and technological advances have affected almost every aspect of our lives ranging from social networking to law enforcement, legal proceedings, and so on. Today, the use of digital multimedia (audio, video, and images) as evidence in every sector of litigation and criminal justice proceedings is becoming the norm. For digital media to be admitted as evidence into a court of law, its authenticity and integrity must be verified. This requirement is a challenging task, especially in the absence of helping data, such as digital watermarks, and if the media is post-processed with anti-forensic intent. The availability of powerful, sophisticated, and easy-to-use digital audio editing manipulation tools (e.g. Audacity, Adobe Audition, etc.) has made integrity authentication of digital audio even more difficult. The research effort supported by this award was aim to investigate:  Is an evidentiary recording ?original? or was it created by splicing multiple recordings?  Is it possible to link an evidentiary recording to ?the? microphone used? As claimed, was the evidentiary recording captured using an acquisition device X at location L? Was the evidentiary recording made using acquisition device manufactured by vendor X or vendor Y? What is the performance of a given audio forensic method in the present of anti-forensic attack?   The results of our experiments gave us a number of new insights into how audio integrity authentication can be achieved using microphone and acoustic environment distortions and impact of anti-forensic attacks on the performance of existing audio forensics methods. We have also learned existing forgery detection methods are vulnerable to anti-forensic attacks. We have learned that de-reverberation based attacks can be used to avoid forgery detection using environment signature-based audio forensic analysis methods. Similarly, existing learning based microphone classification method are susceptible to splicing attacks. We have also learned that anti-forensic attacks leave their artifacts in the resulting audio which can be used to detect presence of anti-forensics attack.          Last Modified: 03/25/2017       Submitted by: Hafiz Malik]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
