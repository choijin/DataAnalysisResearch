<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Collaborative Research: Human-Centered Modeling and Control of Cooperative Manipulation with Bimanual Robots</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>672719.00</AwardTotalIntnAmount>
<AwardAmount>672719</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This proposal addresses modeling and control aspects of human-robot interaction by considering constraints imposed by an individual's physiology. The project is motivated by increasing demand for automation in unstructured environments that require high-level cognitive processing and complex decision-making which cannot yet be fully automated. By taking human-centric approach, data-driven musculoskeletal models are incorporated into the robot interaction model to account for differences of individuals. &lt;br/&gt;&lt;br/&gt;Each cooperative activity is divided into action primitives requiring different control strategies while estimating human intent from various sensors. The framework is based on theory of hybrid systems that provides provable safety and stability criteria. The outcome of this research will facilitate methodology for safer and more reliable human-robot interaction and advance state-of-the-art in human movement analysis and control theory. The broader impacts of this research will be realized through new insights into understanding of human intent and haptic cooperation applicable to general human-machine interaction. With increasing interest in service robotics safe and reliable interaction will be the key to successful introduction of robots in human-occupied environments. The potential economic impact of robots engaged in services and manufacturing alongside humans are significant due to increased productivity and reduced costs. Another emerging area is rehabilitation and assistive robotics. The developed data-driven musculoskeletal models will also be applicable to quantification of physical impairments and estimation of muscular stress in healthcare and ergonomics. This interdisciplinary research provides excellent opportunities for undergraduate and graduate students to be engaged in analytical challenges, laboratory demonstrations of theoretical results, and experimental evaluations.</AbstractNarration>
<MinAmdLetterDate>08/10/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/10/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1427260</AwardID>
<Investigator>
<FirstName>Ruzena</FirstName>
<LastName>Bajcsy</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ruzena K Bajcsy</PI_FULL_NAME>
<EmailAddress>bajcsy@eecs.berkeley.edu</EmailAddress>
<PI_PHON>5106429423</PI_PHON>
<NSF_ID>000466345</NSF_ID>
<StartDate>08/10/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>947045940</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~672719</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Model-free robot control strategies for human-robot interaction cannot explicitly obtain physical constraints imposed by human physiology, which greatly limits their ability to adapt to the diverse interaction styles humans use. In contrast, model-based approaches provide detailed priors about what human actions are possible for a given human pose. In addition, model-features generalize across a wide variety of humans body structures, poses, and performed motor tasks. Our project focused on developing such detailed human models, and on using them to inform collaborative manipulation between robots and humans.</p> <p>To realize model-based human-robot collaboration, we developed a family of detailed magnetic resonance imaging (MRI) and ultrasound imaging based dynamic human musculoskeletal models. We developed algorithms that used the models to reconstruct as well as predict human motion for complex manipulation tasks. In particular, to obtain information that could help optimize robot control strategies related to gain adjustment, trajectory generation, and error reduction. We also developed computationally efficient parametric model-variation algorithms to efficiently capture variations in physiology across humans. This included differences in kinematics, such as range of motion and reachability, as well as dynamics and muscle distribution and contribution to tasks. We tuned our models using data collected from motion capture, Microsoft Kinect, force plate, electromyography (EMG), acoustic myography (AMG), and robot joint motion.</p> <p>Moving from human models to robots, we divided our robotics initiatives into three goal areas. First, we developed action primitives for robots, which allow autonomous operation for grasping, handoff, and object placement. Next, we developed human intent estimation methods that use dynamically consistent algorithms and probabilistic methods to determine potential future actions. We also developed methods to combine this with visual, tactile, and spoken communication channels between robots and humans to simplify interaction. Finally, we studied how human ergonomics and posture influenced human force generation ability and muscular effort, which can inform how robots should behave during collaborative behavior.</p> <p>Finally, we conducted several human subject experiments interacting with the Baxter robot, the Kuka LWR robot, the Kinova Jaco robot, and the Kuka IIWA robot. We realized fluid and safe human-robot collaboration. Our models helped analyze collaborative manipulation motion and force patterns and adjust robot responses to help reduce human effort.</p> <p>This project provided an outstanding opportunity for students to collaborate on multi-disciplinary research. Over the course of the project, we engaged two postdoctoral researchers, as well as several undergraduate students, who contributed to the design of control strategies, experimental design, data collection and analysis, and medical imaging segmentation. The project was featured at various official events at the participating universities to K-12 students and their parents, incoming undergraduate and graduate students, and various visitors from industry and academia. The results of this research were presented at several international venues, such as IROS, EMBC, ISER, ISRR and other academic conferences.</p> <p>The results of this research provide new insights into human-robot interaction that are relevant for close collaboration of human and robots in manufacturing, service robotics, and assistive robotics. By incorporating an individual&rsquo;s constraints and ergonomic requirements, more efficient and safe cooperation between human and robot can be achieved. Additionally, the developed methodologies for data-driven musculoskeletal modeling are widely applicable in the health sciences, in particular for the evaluation of musculoskeletal injuries in healthcare and sports medicine, and for estimation of muscular stress in manufacturing, sports, exercise and other activities to reduce injury and to optimize performance.</p><br> <p>            Last Modified: 10/03/2017<br>      Modified by: Ruzena&nbsp;K&nbsp;Bajcsy</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066331628_Figure2--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066331628_Figure2--rgov-800width.jpg" title="Task space sets of human grasp configurations for grasping two different objects.."><img src="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066331628_Figure2--rgov-66x44.jpg" alt="Task space sets of human grasp configurations for grasping two different objects.."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Task space sets of human grasp configurations pictured alongside the corresponding configuration space feasible sets. Notice a large configuration space for the bicycle handlebars and much more compact set for the bicycle lock.</div> <div class="imageCredit">Aaron Bestick</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ruzena&nbsp;K&nbsp;Bajcsy</div> <div class="imageTitle">Task space sets of human grasp configurations for grasping two different objects..</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066378819_Figure3--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066378819_Figure3--rgov-800width.jpg" title="Optimal Handover for Different Goal Poses."><img src="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066378819_Figure3--rgov-66x44.jpg" alt="Optimal Handover for Different Goal Poses."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Optimal Handover for Different Goal Poses. The different goal poses in our experiment lead to different optimal handover configurations for the robot, each selected to minimize expected total cost at the handover time and at that particular goal.</div> <div class="imageCredit">Aaron Bestick</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ruzena&nbsp;K&nbsp;Bajcsy</div> <div class="imageTitle">Optimal Handover for Different Goal Poses.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066434316_Figure4--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066434316_Figure4--rgov-800width.jpg" title="Subject-specific musculoskeletal model based on Magnetic Resonance Imaging (MRI) data."><img src="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066434316_Figure4--rgov-66x44.jpg" alt="Subject-specific musculoskeletal model based on Magnetic Resonance Imaging (MRI) data."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Subject-specific musculoskeletal model based on Magnetic Resonance Imaging (MRI) data.</div> <div class="imageCredit">Samir Menon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ruzena&nbsp;K&nbsp;Bajcsy</div> <div class="imageTitle">Subject-specific musculoskeletal model based on Magnetic Resonance Imaging (MRI) data.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066488000_Figure5--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066488000_Figure5--rgov-800width.jpg" title="Action primitives are used to facilitate human-robot collaboration and skill transfer."><img src="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066488000_Figure5--rgov-66x44.jpg" alt="Action primitives are used to facilitate human-robot collaboration and skill transfer."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Action primitives are used to facilitate human-robot collaboration and skill transfer for operation such as grasping, object handoff, and object placement.</div> <div class="imageCredit">Samir Menon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ruzena&nbsp;K&nbsp;Bajcsy</div> <div class="imageTitle">Action primitives are used to facilitate human-robot collaboration and skill transfer.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066568652_Figure6--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066568652_Figure6--rgov-800width.jpg" title="Motion primitives for high-level task and motion planning."><img src="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066568652_Figure6--rgov-66x44.jpg" alt="Motion primitives for high-level task and motion planning."></a> <div class="imageCaptionContainer"> <div class="imageCaption">High-level task and motion planning is decomposing tasks into primitives to allow sensor-guided control.</div> <div class="imageCredit">Samir Menon</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ruzena&nbsp;K&nbsp;Bajcsy</div> <div class="imageTitle">Motion primitives for high-level task and motion planning.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066264101_Figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066264101_Figure1--rgov-800width.jpg" title="Ultrasound based musculoskeletal model acquisition"><img src="/por/images/Reports/POR/2017/1427260/1427260_10330944_1507066264101_Figure1--rgov-66x44.jpg" alt="Ultrasound based musculoskeletal model acquisition"></a> <div class="imageCaptionContainer"> <div class="imageCaption">(a) Experimental Setup for the collection of upper extremity morphology data via tracked ultrasound. (b) Force associated deformations of the biceps brachii muscle under multiple loading conditions, as segmented from volumetric reconstruction of ultrasound data.</div> <div class="imageCredit">Laura Hallock</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ruzena&nbsp;K&nbsp;Bajcsy</div> <div class="imageTitle">Ultrasound based musculoskeletal model acquisition</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Model-free robot control strategies for human-robot interaction cannot explicitly obtain physical constraints imposed by human physiology, which greatly limits their ability to adapt to the diverse interaction styles humans use. In contrast, model-based approaches provide detailed priors about what human actions are possible for a given human pose. In addition, model-features generalize across a wide variety of humans body structures, poses, and performed motor tasks. Our project focused on developing such detailed human models, and on using them to inform collaborative manipulation between robots and humans.  To realize model-based human-robot collaboration, we developed a family of detailed magnetic resonance imaging (MRI) and ultrasound imaging based dynamic human musculoskeletal models. We developed algorithms that used the models to reconstruct as well as predict human motion for complex manipulation tasks. In particular, to obtain information that could help optimize robot control strategies related to gain adjustment, trajectory generation, and error reduction. We also developed computationally efficient parametric model-variation algorithms to efficiently capture variations in physiology across humans. This included differences in kinematics, such as range of motion and reachability, as well as dynamics and muscle distribution and contribution to tasks. We tuned our models using data collected from motion capture, Microsoft Kinect, force plate, electromyography (EMG), acoustic myography (AMG), and robot joint motion.  Moving from human models to robots, we divided our robotics initiatives into three goal areas. First, we developed action primitives for robots, which allow autonomous operation for grasping, handoff, and object placement. Next, we developed human intent estimation methods that use dynamically consistent algorithms and probabilistic methods to determine potential future actions. We also developed methods to combine this with visual, tactile, and spoken communication channels between robots and humans to simplify interaction. Finally, we studied how human ergonomics and posture influenced human force generation ability and muscular effort, which can inform how robots should behave during collaborative behavior.  Finally, we conducted several human subject experiments interacting with the Baxter robot, the Kuka LWR robot, the Kinova Jaco robot, and the Kuka IIWA robot. We realized fluid and safe human-robot collaboration. Our models helped analyze collaborative manipulation motion and force patterns and adjust robot responses to help reduce human effort.  This project provided an outstanding opportunity for students to collaborate on multi-disciplinary research. Over the course of the project, we engaged two postdoctoral researchers, as well as several undergraduate students, who contributed to the design of control strategies, experimental design, data collection and analysis, and medical imaging segmentation. The project was featured at various official events at the participating universities to K-12 students and their parents, incoming undergraduate and graduate students, and various visitors from industry and academia. The results of this research were presented at several international venues, such as IROS, EMBC, ISER, ISRR and other academic conferences.  The results of this research provide new insights into human-robot interaction that are relevant for close collaboration of human and robots in manufacturing, service robotics, and assistive robotics. By incorporating an individual?s constraints and ergonomic requirements, more efficient and safe cooperation between human and robot can be achieved. Additionally, the developed methodologies for data-driven musculoskeletal modeling are widely applicable in the health sciences, in particular for the evaluation of musculoskeletal injuries in healthcare and sports medicine, and for estimation of muscular stress in manufacturing, sports, exercise and other activities to reduce injury and to optimize performance.       Last Modified: 10/03/2017       Submitted by: Ruzena K Bajcsy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
