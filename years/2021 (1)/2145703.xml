<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Towards theoretical foundations of neural network based representation learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2022</AwardEffectiveDate>
<AwardExpirationDate>01/31/2027</AwardExpirationDate>
<AwardTotalIntnAmount>640872.00</AwardTotalIntnAmount>
<AwardAmount>120710</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>A. Funda Ergun</SignBlockName>
<PO_EMAI>fergun@nsf.gov</PO_EMAI>
<PO_PHON>7032922216</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Building up good representations of input data has always been a central ingredient in machine learning. In computer vision, for example, one would like to have features representing the main objects in the image. In natural language processing, one would like to have features indicating the relationship between different words.   A new paradigm shift in machine learning based on deep learning techniques has demonstrated the ability of machines to automatically learn good representations from the training data set without any prior knowledge. However, although these features are really useful for machines to learn the data set, are they actually  "good" according to human standards?  The project aims to contribute to the fundamental understanding of deep representation learning and inform the practical advancement of deep learning, improving its interpretability, robustness, and efficiency in large data regimes. The investigator will also develop a new graduate-level course and a public interactive software through the course of this project. &lt;br/&gt;&lt;br/&gt;The project aims to build a comprehensive theory for the new generation of neural-network-based representation-learning techniques. This includes the central questions of characterizing the statistical properties of the representations and how they are encoded in an actual neural network. This project has three major components. The first thrust is to characterize when would minimizing the training objective of the representation learning task leads to a unique representation in the neural network: leveraging the new theoretical development, the investigator will build up new training objectives that encourage such uniqueness. The second thrust is to theoretically study what representations can be efficiently learned by deep-learning models, and how are they encoded in the hidden weights of the neural networks after training. Finally, the investigator will study what statistical properties of the learned representations made them good for downstream tasks, which is critical to improving the interpretability of these neural network-based representations. Moreover, it will allow humans to better interact with deep-learning models for broader applications such as self-driving cars.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/27/2022</MinAmdLetterDate>
<MaxAmdLetterDate>01/27/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2145703</AwardID>
<Investigator>
<FirstName>Yuanzhi</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yuanzhi Li</PI_FULL_NAME>
<EmailAddress>yuanzhil@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122682000</PI_PHON>
<NSF_ID>000814734</NSF_ID>
<StartDate>01/27/2022</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~120710</FUND_OBLG>
</Award>
</rootTag>
