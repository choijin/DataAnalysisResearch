<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Excellence in Research:  Incorporating Attention into Computational Auditory Scene Analysis Using Spectral Clustering with Focal Templates</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2021</AwardEffectiveDate>
<AwardExpirationDate>05/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499027.00</AwardTotalIntnAmount>
<AwardAmount>499027</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jeffrey Forbes</SignBlockName>
<PO_EMAI>jforbes@nsf.gov</PO_EMAI>
<PO_PHON>7032925301</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Humans display an uncanny ability to focus on a sound of interest, even in the presence of interfering sounds or noise.  For instance, a childâ€™s voice may be immediately recognized and reacted-to in the context of parental protection, a bird-watcher may recognize and follow the call of a house finch, or business associates may discuss the latest events over lunch in a crowded diner.  In each of these examples, a person directs his or her attention to the sound source of interest.  Once attention is directed, a human can continue to focus on that sound, even to the degree that he or she may not perceive (or is able to passively ignore) other sounds.  Computational listening systems, at present, are unable to replicate that ability.  If such ability was possible, computational listening systems could contribute to an array of application domains.  Current hearing aid technology is woefully inadequate in group settings, where noise often overwhelms the listener and the listener is unable to compensate.  Those who suffer from hearing loss feel socially isolated, leading to a lower quality of life.  Performance of hearing aids, and the lives of those who rely on them, would improve drastically if these devices could automatically adapt to isolate and focus on salient sound sources.  Effective acoustic monitoring could be deployed to safety-related applications, such as automatically detecting slurred speech from someone suffering a stroke, or to alert the deaf to important loudspeaker announcements in a public place.  Autonomous devices (robots, drones, etc.) could employ enhanced listening techniques to guide their movements or actions, potentially better serving or protecting the public.  The ability to focus on a particular instrument within a musical ensemble could lead to improved automatic music transcription systems and enhanced tools for performance analysis and training.  The applications of computational listening systems exhibiting perceptually-based attention are boundless.&lt;br/&gt;&lt;br/&gt;This research will investigate the use of focal templates to incorporate attention into computational auditory scene analysis (CASA).  CASA attempts to reproduce (via computational algorithms and systems) the ability of humans to perceive an acoustic scene given only auditory input, and the underlying methods of CASA are modeled upon psychological principles of perception.  A focal template may be considered a type of dynamic time-frequency filter that passes only those auditory elements conforming to a pattern of interest.  Sound events of interest (if present in the audio) will be detected using spectral clustering, which has emerged as a useful technique for grouping "like" elements within a set; here, the goal is to group auditory elements that pass through the focal template.  This work will:  1) implement a model of attention into CASA through use of spectral clustering with focal templates,  2) measure the impact of incorporating attention on the performance of CASA systems in isolating particular sounds of interest, and  3) determine effective methods to develop focal templates while considering how to scale to the "general" listening case.  This project includes development of an academic minor in "Sound and Music Computing", a unique educational opportunity to prepare students to contribute to the research while integrating across STEM and non-STEM disciplines.  An outcome of this work is to build partnerships and strengthen the Computational Research on Music &amp; Audio Team of Interdisciplinary Collaborators (CRoMA-TIC).  Through these activities, the project will:  1) advance the state of the art in CASA,  2) foster collaborative relationships within this field,  3) develop a well-recognized area of expertise and research capacity at Lincoln University, and  4) develop a pipeline for undergraduate students leading to related careers or graduate study.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/04/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/04/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2100874</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Heise</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David Heise</PI_FULL_NAME>
<EmailAddress>heised@lincolnu.edu</EmailAddress>
<PI_PHON>5736815104</PI_PHON>
<NSF_ID>000601335</NSF_ID>
<StartDate>05/04/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Lincoln University</Name>
<CityName>Jefferson City</CityName>
<ZipCode>651020029</ZipCode>
<PhoneNumber>5736815030</PhoneNumber>
<StreetAddress>820 Chestnut</StreetAddress>
<StreetAddress2><![CDATA[203 Young Hall]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>071970164</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LINCOLN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071970164</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Lincoln University]]></Name>
<CityName>Jefferson City</CityName>
<StateCode>MO</StateCode>
<ZipCode>651020029</ZipCode>
<StreetAddress><![CDATA[820 Chestnut]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1594</Code>
<Text>Hist Black Colleges and Univ</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramReference>
<Code>041Z</Code>
<Text>HBCU-Strengthening Research Capacities</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0421</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>04002122DB</Code>
<Name><![CDATA[NSF Education & Human Resource]]></Name>
<FUND_SYMB_ID>040106</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~499027</FUND_OBLG>
</Award>
</rootTag>
