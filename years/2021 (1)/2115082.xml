<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CICI: SIVD: Discover and defend cyber vulnerabilities of deep learning medical diagnosis models to adversarial attacks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2021</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499338.00</AwardTotalIntnAmount>
<AwardAmount>499338</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Beverly</SignBlockName>
<PO_EMAI>rbeverly@nsf.gov</PO_EMAI>
<PO_PHON>7032927068</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to discover cyber vulnerabilities of deep learning-enabled medical imaging diagnosis tools against adversarial attacks and to develop defensive approaches in pursuit of safe artificial intelligence for healthcare. Artificial intelligence technologies, especially deep learning, have achieved remarkable success in the medical domain. Newly advanced adversarial attacks pose a new threat to cybersecurity of medical artificial intelligence diagnosis tools, but little is known about the characteristics and behaviors of this threat. While artificial intelligence tools are increasingly being incorporated in medical imaging informatics infrastructures, it is imminent to gain cybersecurity insights on medical context-motivated adversarial attacks for designing solutions to defend this threat. Medical adversarial attacks may lead to serious consequences including patient harm, liability of healthcare providers, and other ethical issues or crimes. It is imperative to study this emerging cybersecurity issue to mitigate the potential consequences and to ensure the safety of health care. This study contributes to providing safety evaluation and protective measures to medical imaging-based artificial intelligence diagnosis devices and clinical informatics infrastructures, and it sets the stage for researchers and regulatory agencies to investigate artificial intelligence-induced cybersecurity science and engineering issues in the medical domain. This study advances scientific discovery, clinical deployment, and practical applications of safe artificial intelligence medical systems, ultimately benefiting patient care, the general public, and society at large. &lt;br/&gt;&lt;br/&gt;The technical goal of this study is to investigate mechanisms of generative adversarial network-generated medical imaging adversarial attacks, analyze behaviors of an artificial intelligence diagnosis system under such attacks, and develop various defensive strategies and methods. Generative adversarial network models are customized to generate medical context-motivated adversarial samples by “inserting” or “removing” malignant lesions in a varying resolution of digital mammogram images while maintaining the manipulated images to be visually imperceptible to true images. Four representative defensive methods, including the strategy of combining computational algorithms and human expert knowledge, are examined for defending against adversarial attacks. This project contributes algorithms, educational materials, and critical insights to bolster further research activities along the line of medical artificial intelligence cybersecurity.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/11/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/11/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2115082</AwardID>
<Investigator>
<FirstName>Shandong</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shandong Wu</PI_FULL_NAME>
<EmailAddress>wus3@upmc.edu</EmailAddress>
<PI_PHON>4126412567</PI_PHON>
<NSF_ID>000827268</NSF_ID>
<StartDate>05/11/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<CountyName/>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<CountyName/>
<StateCode>PA</StateCode>
<ZipCode>152133110</ZipCode>
<StreetAddress><![CDATA[3240 Craft Place, Suite 316]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8027</Code>
<Text>Cybersecurity Innovation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8027</Code>
<Text>Cyber Secur - Cyberinfrastruc</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~499338</FUND_OBLG>
</Award>
</rootTag>
