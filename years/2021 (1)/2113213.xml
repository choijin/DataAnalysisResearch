<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRCNS Research Project: Multiply and Conquer: Replica-Mean-Field Limit for Neural Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>650000.00</AwardTotalIntnAmount>
<AwardAmount>650000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Zhilan Feng</SignBlockName>
<PO_EMAI>zfeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927523</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Artificial intelligence can now rival human performance in tasks such as speech or object recognition, language translation, and autonomous navigation. However, by contrast with artificial computations supported by fragile, hardwired circuits, biological computations appear to robustly emerge in noisy, disordered neural networks. Understanding how meaningful computations emerge from the seemingly random interactions of neural constituents remains a challenge. To solve this, one can hope to mine biological networks for their design principles. Unfortunately, such a task is hindered by the sheer complexity of neural circuits. Deciphering neural computations will only be achieved through the simplifying lens of a biophysically relevant theory. To date, neural computations have been studied theoretically in idealized models whereby an infinite number of neurons communicate via vanishingly small interactions. Such an approach neglects that neural computations are carried out by a finite number of cells interacting via a finite number of synapses. This approach precludes understanding how neural circuits reliably process information in spite of neural variability, which depends on these finite numbers. To remedy this point, the PIs will develop a novel theoretical framework allowing for the analysis of neural computations in neural circuits with finite-size structure. The PIs will leverage ideas from the theory of communication networks to understand how biophysically relevant neural network models can reliably process information via noisy, disordered circuits. This approach will provide the basis for categorizing distinct brain operating regimen based on their stability and will help designing strategies to stabilize neural systems in their healthy regime.&lt;br/&gt;&lt;br/&gt;In contrast to “divide and conquer” approaches, which equate a system with the mere sum of its parts, the PIs will decipher the activity of neural networks via a “multiply and conquer” approach. This approach considers limit networks made of infinitely many replicas with the same basic neural structure. The key point is that these so-called replica-mean-field networks are in fact simplified, tractable versions of neural networks that retain important features of the finite network structure of interest. The finite size of neuronal populations and synaptic interactions is a core determinant of neural activity, being responsible for non-zero correlation in the spiking activity and for finite transition rates between metastable neural states. Accounting for these finite-size phenomena is the core motivation for the development of the replica approach. The expected outcome is a mechanistic understanding of the constraints bearing on computations in finite-size neural circuits, especially in terms of their reliability, speed, and cost. This will involve characterizing the finite-structure dependence of: (i) the regime of spiking correlations, which is a fundamental determinant of the neural code and (ii) the transition rates between metastable neural states, which are thought to control the processing and gating of information. In both cases, the methodology will be based on the comparison between solutions to reduced functional equations, discrete-event simulations, and neural data sets. The ultimate goal will be to analyze biophysically detailed models in order to produce a fitting framework that is restrictive enough to formulate and validate experimental predictions.&lt;br/&gt;&lt;br/&gt;This award is being co-funded by the MPS Division of Mathematical Sciences and the CISE Information and Intelligent Systems (IIS) through the CRCNA and BRAIN Programs.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/29/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/29/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2113213</AwardID>
<Investigator>
<FirstName>Francois</FirstName>
<LastName>Baccelli</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Francois Baccelli</PI_FULL_NAME>
<EmailAddress>baccelli@math.utexas.edu</EmailAddress>
<PI_PHON>5124717028</PI_PHON>
<NSF_ID>000629847</NSF_ID>
<StartDate>07/29/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Thibaud</FirstName>
<LastName>Taillefumier</LastName>
<PI_MID_INIT>O</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thibaud O Taillefumier</PI_FULL_NAME>
<EmailAddress>ttaillef@austin.utexas.edu</EmailAddress>
<PI_PHON>6508628107</PI_PHON>
<NSF_ID>000788324</NSF_ID>
<StartDate>07/29/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName/>
<StateCode>TX</StateCode>
<ZipCode>787595316</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7327</Code>
<Text>CRCNS-Computation Neuroscience</Text>
</ProgramElement>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7327</Code>
<Text>CRCNS</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~650000</FUND_OBLG>
</Award>
</rootTag>
