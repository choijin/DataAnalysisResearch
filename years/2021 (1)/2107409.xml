<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Medium: Collaborative Research: Situated Visual Information Spaces</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>396506.00</AwardTotalIntnAmount>
<AwardAmount>160955</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The aim of this project is to enable people to effectively visualize information about the world in augmented reality. Augmented reality is potentially the next big social benefit from computer technologies, because it allows visual information to be embedded - or ‘situated’ - into the real world. This allows people using smartphones and smartglasses to see data around them in the correct real-world context. However, unlike when visualizing data on a regular computer or smartphone display, where a designer has complete control over how the application looks and feels, augmented reality visualizations are inherently overlaid on the real world. As such, visualizations must be capable of reacting to different real-world environments including dynamic scenes, and for there to be design recommendations that say how visualizations should react to different environments. This project will scientifically investigate visualization for augmented reality, study the efficacy of different approaches, create design recommendations, and then build a software system that can apply these recommendations to help design and run effective visualization applications. The proposed approach will be experimentally validated in the sports and healthcare domains.&lt;br/&gt;&lt;br/&gt;Situated visual information spaces fuse the digital information world with the physical world of objects, people, locations, and environments using augmented reality. To realize this, three scientific and design challenges will be tackled: (1) Situated visualization, interaction, and collaboration, which requires intuitive in-situ data visualizations, physical and digital interfaces for natural user interactions, and schemes for collaboration in augmented reality. Novel situated visual embedding methods will be studied for spatial and non-spatial data in dynamic environmental and situational contexts. These visualizations will automatically adapt to the physical environment, digital entities, users, and tasks while using perceptually and cognitively effective methods that do not overwhelm the user. (2) Design via constraints, where software reduces the increased complexity of creating visualizations that adapt to real-world environments. This software is aimed at visualization designers and evaluates guidelines as constraints, then balances these to provide recommendations for appropriate data and designs for the current environment. (3) Situated applications, where two wellness applications in healthcare and sports will be developed and evaluated in partnership with respective domain experts. Within them, these domains cover a spectrum of different techniques, tasks, and users. These applications will help to define an achievable research scope, drive it with motivated stakeholders, and present best-practices via use cases.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/07/2021</MinAmdLetterDate>
<MaxAmdLetterDate>09/21/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2107409</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Tompkin</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James H Tompkin</PI_FULL_NAME>
<EmailAddress>james_tompkin@brown.edu</EmailAddress>
<PI_PHON>4018632777</PI_PHON>
<NSF_ID>000732309</NSF_ID>
<StartDate>07/07/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University CS Dept]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129016</ZipCode>
<StreetAddress><![CDATA[115 Waterman Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~160955</FUND_OBLG>
</Award>
</rootTag>
