<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: New tools for studying structural and inductive bias in NLP models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>117747</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928729</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Modern natural language processing systems, based on neural networks trained using large amounts of text, are a key part of the infrastructure of the nation and the world. These systems  power practical tools like machine translation, web search, or automatic question answering, as well as research tools that help scientists and policy makers. These language processing models have made enormous progress in many ways, yet systems still fail unexpectedly, their successes cannot be explained, and their blind spots lead to biases. This project develops new tools for studying language models: why they work as well as they do, what their limitations are, and what distortions they introduce into language understanding, with the goal of improved systems and helping mitigate negative impacts on society.&lt;br/&gt;&lt;br/&gt;This project develops and investigates four kinds of new analytic tools for studying the inductive biases of language models - the structural tendencies that determine what they can learn. The structural transfer-learning paradigm involves training language models on artificial languages that can be manipulated, to see which structural aspects improve performance on natural language. The challenge-task paradigm brings humans in the loop to develop new evaluations to study why and how language processing systems fail, such as on aspect of language that change over time. The new theoretical framework of sensitivity models the complexity of language processing tasks by measuring how responsive the classification is to minor changes in the input, demonstrating which tasks or examples are easy or hard. And new tools are introduced to measure how embeddings of words introduce structural distortions - exaggerations or understatements in word relationships - that can cause models to fail. Understanding the limitations of technology and what makes one system better or one task or dataset harder than another is a crucial step toward building better language processing systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/30/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/30/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2128145</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Jurafsky</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel S Jurafsky</PI_FULL_NAME>
<EmailAddress>jurafsky@stanford.edu</EmailAddress>
<PI_PHON>6507230924</PI_PHON>
<NSF_ID>000140878</NSF_ID>
<StartDate>08/30/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943052004</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~117747</FUND_OBLG>
</Award>
</rootTag>
