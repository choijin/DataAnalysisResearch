<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Advancing Neuro-symbolic AI with Deep Knowledge-infused Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2021</AwardEffectiveDate>
<AwardExpirationDate>06/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>139999.00</AwardTotalIntnAmount>
<AwardAmount>139999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amarda Shehu</SignBlockName>
<PO_EMAI>ashehu@nsf.gov</PO_EMAI>
<PO_PHON>7032928191</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The first wave of AI termed symbolic AI, focused on explicit knowledge. The current second wave of AI is termed statistical AI. The deep learning techniques have been able to exploit large amounts of data and massive computational power to improve upon human levels of performance in narrowly defined tasks. Separately, knowledge graphs emerged as a powerful tool to capture and exploit an extensive amount and variety of explicit knowledge to make algorithms better understand the content, and enable the next generation of data processing, such as in semantic search. Now, we herald towards the third wave of AI built on what is termed as the neuro-symbolic approach that combines the strengths of statistical and symbolic AI. Combining the respective powers and benefits of using knowledge graphs and deep learning is particularly attractive. This has led to the development of an approach we have called knowledge-infused (deep) learning. This project will advance the currently limited forms of combining the knowledge graphs and deep learning, called shallow and semi-diffusion, with a more advanced form called deep-infusion, that will support stronger interleaving of more variety of knowledge at different levels of abstraction with layers in a deep learning architecture.&lt;br/&gt;&lt;br/&gt;This project will investigate the deep knowledge-infusion strategy in two substantial ways. The first is to infuse knowledge of different types from knowledge graphs in the deep learning pipeline. For example, in natural language processing, we will investigate the incorporation of linguistic, common sense, broad-based and domain-specific knowledge. The second is to infuse stratified knowledge representing different levels of abstractions, such as low levels of abstractions contained in raw data measurements that focus on the physical features of an object, and higher levels of abstractions that capture more conceptual aspects of the object, such as the object's functionality in an application. Each deep network layer may take a different type of knowledge representing the intended level of abstraction at that layer. For example in a transformer, we can reparameterize different transformer blocks (layers) such that the transformer block will take a different type of knowledge representing the intended level of abstraction at that layer. Furthermore, the deep infusion pipeline can generate explanations for the outcomes of the deep-learning pipeline from the knowledge graph at the appropriate layer leading to a clear picture of the contextual connection between parts of the input. Both layered abstraction and explanation modules would be highly significant contributions towards improving the state of machine intelligence.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/25/2021</MinAmdLetterDate>
<MaxAmdLetterDate>06/25/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2133842</AwardID>
<Investigator>
<FirstName>Amit</FirstName>
<LastName>Sheth</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amit Sheth</PI_FULL_NAME>
<EmailAddress>amit@sc.edu</EmailAddress>
<PI_PHON>8037772094</PI_PHON>
<NSF_ID>000272511</NSF_ID>
<StartDate>06/25/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of South Carolina at Columbia</Name>
<CityName>COLUMBIA</CityName>
<ZipCode>292080001</ZipCode>
<PhoneNumber>8037777093</PhoneNumber>
<StreetAddress>Sponsored Awards Management</StreetAddress>
<StreetAddress2><![CDATA[1600 Hampton Street, Suite 414]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>South Carolina</StateName>
<StateCode>SC</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>SC06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041387846</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTH CAROLINA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041387846</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of South Carolina at Columbia]]></Name>
<CityName/>
<StateCode>SC</StateCode>
<ZipCode>292080001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>South Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>SC06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~139999</FUND_OBLG>
</Award>
</rootTag>
