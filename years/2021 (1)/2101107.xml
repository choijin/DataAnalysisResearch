<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: RI: RUI: Generating Haptics in Telerobotics through Perception Complementarities during Physical Distancing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2021</AwardEffectiveDate>
<AwardExpirationDate>05/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>174386.00</AwardTotalIntnAmount>
<AwardAmount>174386</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Erion Plaku</SignBlockName>
<PO_EMAI>eplaku@nsf.gov</PO_EMAI>
<PO_PHON>7032928695</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Haptic feedback, the sense of touch and awareness of movement, is a fundamental sensory pathway for human everyday life and plays a particularly essential role in object manipulation. In a physically distanced or miniaturized world, telepresence using robot proxies can assist humans with remote tasks, yet an ongoing issue is the limited haptic capabilities due to the lack of high-fidelity, low-cost haptic interfaces or sensors. As a plethora of information exists in the digital age, mostly through images or video streams, the ability to interpret the sense of touch from vision enables new opportunities. This project explores software solutions that can estimate contact force/torque from visual data and train robots to replicate force sensitive soft body manipulation tasks. This software agent will be trained to transmit real-time force/torque estimation without the need for haptic sensors. Promising application domains include providing surgeons with vision-based haptic feedback during robot-assisted minimally invasive surgery, short term telepresence demand for emergencies or disaster response, and teleoperating a companion robot to perform a haptically enabled virtual hug or a remote handshake. The goal is to create a novel software solution that helps humans stay connected, complete remote tasks through intelligent touch estimation, and lower the barrier to entry for haptic teleoperation by reducing accessibility and hardware requirements. &lt;br/&gt;&lt;br/&gt;This project leverages preliminary endeavors in vision-based force estimation in robot assisted minimally invasive surgery (RMIS). Meanwhile, the technology will evaluate the accuracy of the artificial force, analyze added benefits or limitations of the artificial haptic information, explore the sim-to-real transfer learning capabilities of the proposed framework through Variational Autoencoder-Generative Adversarial Networks (VAE-GANs) and prioritize cross-robot support by ensuring software compatibility with Robot Operating System (ROS), Collaborative Robotics Toolkit (CRTK) and Asynchronous Multi-Body Framework (AMBF) for dynamic simulation and visualization. The wide spectrum of applications ensure significant potential of this forward looking research to impact telerobotics in soft object manipulation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/13/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/13/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2101107</AwardID>
<Investigator>
<FirstName>Yun-Hsuan</FirstName>
<LastName>Su</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yun-Hsuan Su</PI_FULL_NAME>
<EmailAddress>msu@mtholyoke.edu</EmailAddress>
<PI_PHON>2064842063</PI_PHON>
<NSF_ID>000830392</NSF_ID>
<StartDate>05/13/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Mount Holyoke College</Name>
<CityName>South Hadley</CityName>
<ZipCode>010756456</ZipCode>
<PhoneNumber>4135382000</PhoneNumber>
<StreetAddress>50 College Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066985714</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF MOUNT HOLYOKE COLLEGE, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>066985714</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Mount Holyoke College]]></Name>
<CityName>South Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010756456</ZipCode>
<StreetAddress><![CDATA[50 College Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~174386</FUND_OBLG>
</Award>
</rootTag>
