<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: SHF: Medium:  Analog EDA-Inspired Methods for Efficient and Robust Neural Network Design</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2021</AwardEffectiveDate>
<AwardExpirationDate>06/30/2025</AwardExpirationDate>
<AwardTotalIntnAmount>402939.00</AwardTotalIntnAmount>
<AwardAmount>194639</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
<PO_EMAI>sabasu@nsf.gov</PO_EMAI>
<PO_PHON>7032927843</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Deep neural networks have achieved great success in many engineering fields including, but not limited to, image classification, speech recognition, recommendation systems and autonomous driving. However, they suffer from two major challenges. Firstly, many neural network models are not robust, i.e. a neural network could produce inaccurate results when the input data experiences a very small amount of perturbation. Secondly, the huge cost of generating and deploying large-size neural networks limits their applications in resource-constrained platforms (e.g. mobile devices and robots). The research team notices that there is a strong mathematical connection between certain types of neural networks and analog integrated circuits. It is also known that the EDA (electronic design automation) field has 50 years of successful history of modeling, simulating, verifying and optimizing analog integrated circuits. Therefore, this project aims to substantially enrich the algorithms and theoretical understanding of neural networks by leveraging the principled approaches in the EDA community. This research will support the cross-disciplinary development of a diverse cohort of graduate and undergraduate students at the University of California at Santa Barbara, the University of California at San Diego, and the Massachusetts Institute of Technology. Several graduate-level courses on computational methods, data science and artificial intelligence are being created or enriched. The research team willis also collaborating with industry to ensure effective technology transfers.&lt;br/&gt;&lt;br/&gt;This project focuses on certain types of deep neural networks (e.g., residual neural networks, recurrent neural networks and normalizing flows) that can be described as ordinary differential equations. The technical aims of the project are divided into three thrusts. The first thrust investigates the training and compression algorithms of deep neural networks from circuit simulation and modeling perspectives. Specifically, parallel training algorithms are being developed for neural networks by borrowing the idea from parallel circuit simulation. Hardware-friendly neural-network compression algorithms are being developed from the perspective of circuit model order reduction, thereby enabling energy-efficient and real-time inference of deep neural networks. The second thrust investigates probabilistic and accurate verification techniques for the robustness of deep neural networks from circuit uncertainty quantification perspectives. Specifically, high-confidence and tighter verification bounds are being developed to describe the reachable set of a deep neural network by leveraging the hierarchical and non-Monte-Carlo techniques in analog circuit uncertainty quantification. The third thrust aims to improve the robustness of a deep neural network from the perspective of analog circuit yield optimization. In this final thrust, two ideas are being explored: (1) pre-silicon yield optimization techniques for robust neural network training, and (2) post-silicon self-healing techniques for robustness improvement of a trained neural network.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/30/2021</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2107189</AwardID>
<Investigator>
<FirstName>Tsui-Wei</FirstName>
<LastName>Weng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tsui-Wei Weng</PI_FULL_NAME>
<EmailAddress>lweng@ucsd.edu</EmailAddress>
<PI_PHON>6179496405</PI_PHON>
<NSF_ID>000842499</NSF_ID>
<StartDate>04/30/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~194639</FUND_OBLG>
</Award>
</rootTag>
