<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CompCog: Computational Models of Plasticity and Learning in Speech Perception</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2021</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>496805.00</AwardTotalIntnAmount>
<AwardAmount>496805</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When it comes to speech perception, listeners are lifelong learners.  Although infants’ perception becomes tuned to their native language in their first year of life, their speech sound categories continue to change well into childhood and adolescence.  Adults also continue to show substantial capacity for perceptual learning, particularly in settings that involve feedback or rewards.  This project uses computational modeling to investigate the learning mechanisms that allow listeners to adapt their speech perception to particular languages and environments.  By building theories of auditory perceptual learning, the project will contribute to our understanding of the difficulties that adults face when learning another language.  It could also provide a framework for understanding the difficulties faced by certain populations, such as children with cochlear implants, when learning their first language and may facilitate future development of treatments or interventions for these populations.&lt;br/&gt;&lt;br/&gt;Two types of computational models are developed based on adult perceptual learning data: probabilistic cue weighting models, which are designed to capture fast, trial-by-trial changes in listeners’ reliance on different parts of the speech signal, and reinforcement learning models, which are designed to capture longer term, implicit perceptual learning of speech sounds that occurs in response to a reward, such as points in a video game.  The models are tested on their ability to capture adults’ perceptual learning behavior in experimental settings.  A second series of simulations then explores whether and how these models that were developed on adult data can predict aspects of children’s perceptual learning of speech sound categories in laboratory discrimination tasks that involve rewards, such as exciting toys, and in naturalistic settings where the speech is more complex and there is a less obvious reward structure.  Results from the project are expected to provide insight into what types of speech representations children and adults have at different stages of development, as well as which perceptual learning strategies learners rely on at different ages and in different learning environments.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/28/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/28/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2120834</AwardID>
<Investigator>
<FirstName>Naomi</FirstName>
<LastName>Feldman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Naomi Feldman</PI_FULL_NAME>
<EmailAddress>nhf@umd.edu</EmailAddress>
<PI_PHON>3014056269</PI_PHON>
<NSF_ID>000622351</NSF_ID>
<StartDate>07/28/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207420001</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207421800</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~496805</FUND_OBLG>
</Award>
</rootTag>
