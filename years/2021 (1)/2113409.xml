<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Inference and Decentralized Computing for Quantile Regression and Other Non-Smooth Methods</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2021</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>173126.00</AwardTotalIntnAmount>
<AwardAmount>173126</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Huixia Wang</SignBlockName>
<PO_EMAI>huiwang@nsf.gov</PO_EMAI>
<PO_PHON>7032922279</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent years have witnessed the transition of statistical analysis from a small- or moderate-scale data environment to a world involving massive data on parallel and distributed computing platforms. However, such a transition poses significant statistical and computational challenges for many important methods with non-smooth loss functions. As a representative example, quantile regression methods are building blocks for many advanced methods in statistics and econometrics and are frequently used to model financial data and medical data. The computational inflexibility makes quantile regression less favorable among various branches of the statistical learning tool kit. The project aims to develop a unified framework for large-scale learning with non-smooth loss functions to address the aforementioned problems. The developed methods will be applied to analyze complex biomedical data subject to censoring or privacy protocol and large-scale public health data. Both graduate and undergraduate students will receive training through research involvement in the project, ranging from developing new methods and theory to open-source software under different platforms. &lt;br/&gt; &lt;br/&gt;The principal investigators will use a combination of tools from statistics, optimization, and probability to develop a unified convolution smoothing framework and establish rigorous theoretical and algorithmic foundations for a class of statistical methods with non-differentiable loss, typified by quantile regression and support vector machine. The former is indispensable for understanding pathways of dependence and heterogeneous effects irretrievable through standard conditional mean regression analysis. However, most existing computational methods for quantile regression are based on generic algorithms, which are not scalable in large-scale machine learning applications when the number of variables is large. Convolution smoothing admits fast calibrated gradient-based algorithms without compromising the estimates' quality, therefore offering a balanced trade-off between statistical accuracy and computational precision. It also extends the applicability of quantile regression, from low to high dimensions, fully to partially observed samples, and linear to nonlinear structures, in modern big data analytics. The first part of the project will focus on three statistical problems: (a) high-dimensional sparse quantile regression, (b) large-scale censored quantile regression, and (c) robust regression with redescending M-estimation. The second part of the research focuses on developing efficient decentralized algorithms for methods with non-smooth loss functions under two modern data types: (i) parallel and distributed data, and (ii) online streaming data.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/14/2021</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2113409</AwardID>
<Investigator>
<FirstName>Wenxin</FirstName>
<LastName>Zhou</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wenxin Zhou</PI_FULL_NAME>
<EmailAddress>wez243@ucsd.edu</EmailAddress>
<PI_PHON>8585342640</PI_PHON>
<NSF_ID>000754197</NSF_ID>
<StartDate>06/14/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~173126</FUND_OBLG>
</Award>
</rootTag>
