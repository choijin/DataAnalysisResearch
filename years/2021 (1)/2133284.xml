<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: SaTC: CORE: Small: Privacy and Fairness in Critical Decision Making</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>235000.00</AwardTotalIntnAmount>
<AwardAmount>235000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Joshi</SignBlockName>
<PO_EMAI>jjoshi@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many agencies or companies release statistics about groups of individuals that are then used as input to critical decision processes. For example, census data is used to allocate funds and distribute critical resources to states and jurisdictions. The resulting decisions can have significant societal and economic impacts for participating individuals. In many cases, the released data contain sensitive information whose privacy is strictly regulated and Differential Privacy (DP) has become the paradigm of choice for protecting data privacy. However, while differential privacy provides strong privacy guarantees on the released data, it has become apparent recently that it may induce biases and fairness issues in downstream decision processes, including the allotment of federal funds, apportionment of congressional seats, and distribution of vaccines and therapeutics. These biases and fairness issues may adversely affect the health, well-being, and sense of belonging of many individuals, and are poorly understood. This project addresses this knowledge gap at the intersection of privacy, fairness, bias, and decision processes. It will offer novel perspectives on differential privacy tools to address fairness and privacy jointly in critical decision processes. It will quantify the disparate impact arising in these applications and contribute novel mechanisms and mitigation techniques to overcome some of these issues. These contributions will be embedded in modeling and software tools to make the technology widely available and applicable.&lt;br/&gt;&lt;br/&gt;From a scientific standpoint, this project will develop a new generation of privacy-preserving tools that, by exploiting knowledge from differential privacy, optimization, and programming languages, will address biases and fairness issues in their designs, not as an afterthought. The project contributes new scientific knowledge along with five directions: (1) it identifies and understands the structure of downstream decision processes that may be subject to fairness issues when using DP data releases; (2) it identifies and understands the structure of DP mechanisms that may introduce biases; (3) it defines theoretical frameworks to characterize and reason about biases and fairness issues; (4) it designs mitigation measures that would remove or alleviate the biases and fairness issues, finding an appropriate tradeoff between privacy, accuracy, and fairness; (5) it develops modeling and software tools to automatically identify and explain biases and fairness issues, and derive mitigation measures from the specification of the decision process.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/25/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/25/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2133284</AwardID>
<Investigator>
<FirstName>Pascal</FirstName>
<LastName>Van Hentenryck</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pascal R Van Hentenryck</PI_FULL_NAME>
<EmailAddress>pvh@isye.gatech.edu</EmailAddress>
<PI_PHON>4013408822</PI_PHON>
<NSF_ID>000109104</NSF_ID>
<StartDate>08/25/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Altanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~235000</FUND_OBLG>
</Award>
</rootTag>
