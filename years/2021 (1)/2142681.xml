<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Collaborative Research: On the Theoretical Foundation of Recommendation System Evaluation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>19999.00</AwardTotalIntnAmount>
<AwardAmount>19999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei-Shinn Ku</SignBlockName>
<PO_EMAI>weiku@nsf.gov</PO_EMAI>
<PO_PHON>7032928318</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project develops a new theoretical foundation for evaluating the performance of recommendation systems (RS), a crucial component guiding online users and shoppers to navigate a sea of products and websites. Despite the Covid-19 pandemic, online retail sales in the US totaled nearly $1 trillion dollars in 2020. Since online purchasing is forecasted to increase, proper design of RS will improve shopping/browsing, help small online businesses to survive, and contribute to the nationâ€™s economy. Recent studies have noted the sizeable improvements obtained from deep learning-based recommendations. However, several studies suggest that these improvements may be spurious due to poorly designed experiments with ill-chosen baselines, cherry-picked datasets, inaccurate metrics of RS performance, and the use of ineffective evaluation protocols that result in performance discrepancies between evaluation and production environments. Recognizing that baseline and dataset problems can be addressed by using standard benchmarks, this project focuses on designing reliable new computation tools, metrics, and evaluation protocols for analyzing recommendation systems. The tools will include new ways to score an RS based on accurate statistical models of user behaviors and a suite of new algorithms that use fewer samples and computational resources that produce more accurate estimations of performance.&lt;br/&gt;&lt;br/&gt;From a technical standpoint, this project will develop theoretical tools to analyze evaluation metrics and protocols for RS based on statistical learning theory and stochastic processes. The project focuses on three tasks. First, designing efficient metrics estimation procedures that resolve the mismatch between sampling and top-K evaluation metrics (e.g., normalized discounted cumulative gain (nDCG) and Recall) by unifying two recently proposed ad hoc approaches for recovering the top-K metrics based on sampling and searching for an overall best estimator. Second, the develops methods to quantify the sensitivity and robustness of the top-K metrics, and design new item sampling procedures that improve the robustness of existing metrics, The finally, the project will analyze the performance gap between offline evaluations and production environments (the online settings), and proposing a new offline evaluation metrics that can better mimic online performance.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/07/2021</MinAmdLetterDate>
<MaxAmdLetterDate>09/07/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2142681</AwardID>
<Investigator>
<FirstName>Zhenming</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhenming Liu</PI_FULL_NAME>
<EmailAddress>zliu20@wm.edu</EmailAddress>
<PI_PHON>7572213470</PI_PHON>
<NSF_ID>000730307</NSF_ID>
<StartDate>09/07/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>College of William and Mary</Name>
<CityName>Williamsburg</CityName>
<ZipCode>231878795</ZipCode>
<PhoneNumber>7572213965</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 8795]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>074762238</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COLLEGE OF WILLIAM &amp; MARY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>074762238</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[College of William and Mary]]></Name>
<CityName/>
<StateCode>VA</StateCode>
<ZipCode>231878795</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7484</Code>
<Text>IIS SPECIAL PROJECTS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~19999</FUND_OBLG>
</Award>
</rootTag>
