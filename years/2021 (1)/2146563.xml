<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Reinforcement Learning for Recursive Markov Decision Processes and Beyond</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2022</AwardEffectiveDate>
<AwardExpirationDate>04/30/2027</AwardExpirationDate>
<AwardTotalIntnAmount>596554.00</AwardTotalIntnAmount>
<AwardAmount>114303</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).&lt;br/&gt;&lt;br/&gt;Reinforcement Learning (RL) is a sampling-based approach to optimization of Markov decision processes (MDPs), where agents rely on rewards to discover optimal solutions. When combined with powerful approximation schemes (e.g., deep neural networks), RL has been effective in highly complex tasks traditionally considered beyond reach of Artificial Intelligence. However, its sensitivity to the approximation parameters makes RL difficult to use (significant Machine Learning expertise is demanded of the programmer) and difficult to trust (manual approximations can invalidate guarantees). The vision of this project is to democratize RL by developing principled methodologies and powerful tools to improve the usability and trustworthiness of RL-based programming at scale. These research objectives are complemented by efforts to integrate the foundations of RL-based computability in CS education and to explore the role of RL-based programming in CS education.&lt;br/&gt;&lt;br/&gt;Approximation in RL is needed because RL algorithms with guaranteed convergence work on finite MDPs, and yet scale poorly. Approximation affects usability and trustworthiness. This proposal identifies two goals addressing both concerns: 1) to discover convergent RL beyond finite MDPs and 2) to develop abstraction-based approaches for RL with rigorous optimization guarantees. The success of the proposed approaches will be evaluated by their ability to handle systems at scale. The algorithms and datasets will be disseminated as open-source software.  The proposed research makes fundamental contributions to three disciplines: formal methods, machine learning, and control theory; at the same time, it takes fundamental, concrete steps towards broadening participation in computing by making RL-based programming easier and more inclusive.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/27/2022</MinAmdLetterDate>
<MaxAmdLetterDate>01/27/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2146563</AwardID>
<Investigator>
<FirstName>Ashutosh</FirstName>
<LastName>Trivedi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ashutosh Trivedi</PI_FULL_NAME>
<EmailAddress>ashutosh.trivedi@colorado.edu</EmailAddress>
<PI_PHON>3034927514</PI_PHON>
<NSF_ID>000724243</NSF_ID>
<StartDate>01/27/2022</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Boulder</Name>
<CityName>Boulder</CityName>
<ZipCode>803031058</ZipCode>
<PhoneNumber>3034926221</PhoneNumber>
<StreetAddress>3100 Marine Street, Room 481</StreetAddress>
<StreetAddress2><![CDATA[572 UCB]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>007431505</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF COLORADO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431505</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Regents of the University of Colorado]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803031058</ZipCode>
<StreetAddress><![CDATA[3100 Marine St, Room 481, 572 UC]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>102Z</Code>
<Text>COVID-Disproportionate Impcts Inst-Indiv</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>8206</Code>
<Text>Formal Methods and Verification</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>010V2122DB</Code>
<Name><![CDATA[R&RA ARP Act DEFC V]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~114303</FUND_OBLG>
</Award>
</rootTag>
