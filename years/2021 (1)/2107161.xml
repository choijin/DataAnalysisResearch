<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: RI: Medium: Robust Perception through End-User Adaptation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2025</AwardExpirationDate>
<AwardTotalIntnAmount>890000.00</AwardTotalIntnAmount>
<AwardAmount>890000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For an intelligent system (such as a robot or a self-driving car) to enter end-users' daily lives in a safe and reliable way, the system must generalize beyond the development laboratory to uncontrolled environments where it will be deployed. For instance, a self-driving car may be built and optimized for sunny weather but may be driven by the user in icy or snowy conditions. The state of the art in machine learning and perception cannot generalize or adapt to this sheer diversity of deployment scenarios. This project seeks to address this challenge by leveraging the fact that people are creatures of habit and tend to use their devices consistently and repeatedly in specific ways (for example, they drive their cars repeatedly over a small set of routes between their home, office, and the marketplace). Such repetitive usage provides ample opportunities for the intelligent system to adapt itself to the end-user's specific circumstances, no matter how challenging or different they are. This project builds upon this insight to design robust perceptual systems that will adapt to a diverse array of real-world challenging settings, including self-driving cars in different driving locations and various time and weather conditions. Guaranteeing that an intelligent system can operate reliably across such diverse settings is necessary to unlock the societal benefits that researchers in machine learning, computer vision, and robotics are striving to achieve. Beyond the research community, the project will contribute to education by training undergraduate and graduate students and by outreach to high-school students through workshops and summer programs, especially to benefit underrepresented minorities.&lt;br/&gt;&lt;br/&gt;This research project investigates the design and development of robust perceptual systems through adaptation, by exploiting a specific and well-known property of end-users: Humans are creatures of habit and tend to operate devices in specific ways and environments repeatedly and consistently. For example, most people drive their cars primarily along the same routes every day. In particular, the investigators explore three key ideas: (1) adapting the perceptual system by recording sensory input during usage, generating highly reliable pseudo-label annotations that incorporate physical constraints and cross-sensor consistency, and fine-tuning the system while it is offline via dual-task co-adaptation; (2) personalizing the system through repetition, by aligning playbacks over time to leverage deep neural networks' ability to memorize and by augmenting data for diverse settings through label propagation across recordings; (3) verifying adaptation by developing methods to detect and remove noisy labels using learning dynamics and active user verification. These three research aims will be complemented by a comprehensive evaluation plan to include multiple existing self-driving data sets, a newly collected data set by the team of investigators that captures diverse environments along a repeated route, and navigation in home robot scenarios. This research effort towards a much larger, more challenging adaptation problem will open the door to novel solutions in the intersection of computer vision, machine learning, and robotics, including but not limited to reasoning about physics, modeling the relationships between rich perceptual tasks, adapting to changing output distributions, and leveraging patterns in the provenance of the data itself.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/20/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2107161</AwardID>
<Investigator>
<FirstName>Bharath</FirstName>
<LastName>Hariharan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bharath Hariharan</PI_FULL_NAME>
<EmailAddress>bh497@cornell.edu</EmailAddress>
<PI_PHON>6072800008</PI_PHON>
<NSF_ID>000760500</NSF_ID>
<StartDate>07/20/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Campbell</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark E Campbell</PI_FULL_NAME>
<EmailAddress>mc288@cornell.edu</EmailAddress>
<PI_PHON>6072554268</PI_PHON>
<NSF_ID>000214501</NSF_ID>
<StartDate>07/20/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kilian</FirstName>
<LastName>Weinberger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kilian Weinberger</PI_FULL_NAME>
<EmailAddress>kilianweinberger@cornell.edu</EmailAddress>
<PI_PHON>6072550983</PI_PHON>
<NSF_ID>000576980</NSF_ID>
<StartDate>07/20/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>ITHACA</CityName>
<StateCode>NY</StateCode>
<ZipCode>148537501</ZipCode>
<StreetAddress><![CDATA[107 Hoy Rd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~890000</FUND_OBLG>
</Award>
</rootTag>
