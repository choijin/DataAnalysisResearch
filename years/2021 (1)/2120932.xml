<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Identifying multimodal dynamics of coordination to understand joint performance in diverse tasks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>349020.00</AwardTotalIntnAmount>
<AwardAmount>349020</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>People need to coordinate their actions in order to carry out a wide range of daily activities.  For example, cooking a meal together, moving a large couch, and working as a team in sport or business, all require coordination among the participants. Despite evidence that collaborating partners in these joint tasks adapt their behavior to one another in real time, it is unclear what features of coordination lead to the best outcomes. The aim of this project is to develop a framework for predicting optimal coordination among people across diverse settings and roles. Using a combination of empirical studies and dynamical computational modeling, the investigators will unpack issues surrounding the roles of dialogue, perspective-taking, and collaboration in successfully performing joint tasks. Understanding the principles that underlie successful coordination among people engaged in a joint task has potential commercial and societal impact in a wide variety of settings, including health care, education, aviation, military operations, and search-and-rescue scenarios.  The project will also contribute to the development of an interdisciplinary workforce by increasing opportunities to engage undergraduate and graduate students in cognitive science research at two academic institutions.&lt;br/&gt;&lt;br/&gt;A prominent view of how interpersonal coordination influences task performance is that when task partners align or match their behavior, their joint task performance improves.  Alignment of, for example, pronunciation, word choices, sentence structure, or movement has been documented in tasks that require partners to monitor each other’s perspective. However, it is unknown how different tasks may increase or decrease alignment for successful performance. In this project, the investigators will manipulate a number of task features: the goals of the task, the symmetry of the partners’ roles, and the number of perspectives that partners have to adopt. Eye movement measurements and dialogue transcripts will be analyzed in order to quantify how aligned partners are in their attention and language use. The aim is to evaluate and model how task performance is predicted by task features and by the degree of interpersonal coordination. For example, interpersonal alignment might increase and be more useful in tasks that require partners to monitor one another closely (e.g., when partners have asymmetrical roles because they hold distinct information). In tasks that require less monitoring, excessive alignment might be detrimental to task outcomes. A dynamical model of collaborative performance, which has parameters for task constraints and interpersonal coordination, will be evaluated against the experimental data and will be used to generate predictions about performance in new tasks.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/24/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2120932</AwardID>
<Investigator>
<FirstName>Rick</FirstName>
<LastName>Dale</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rick Dale</PI_FULL_NAME>
<EmailAddress>rdale@ucla.edu</EmailAddress>
<PI_PHON>3108251703</PI_PHON>
<NSF_ID>000316835</NSF_ID>
<StartDate>07/24/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alexia</FirstName>
<LastName>Galati</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexia Galati</PI_FULL_NAME>
<EmailAddress>agalati@uncc.edu</EmailAddress>
<PI_PHON>7046871343</PI_PHON>
<NSF_ID>000797334</NSF_ID>
<StartDate>07/24/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Charlotte</Name>
<CityName>CHARLOTTE</CityName>
<ZipCode>282230001</ZipCode>
<PhoneNumber>7046871888</PhoneNumber>
<StreetAddress>9201 University City Boulevard</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066300096</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Charlotte]]></Name>
<CityName>Charlotte</CityName>
<StateCode>NC</StateCode>
<ZipCode>282230001</ZipCode>
<StreetAddress><![CDATA[9201 University City Blvd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~349020</FUND_OBLG>
</Award>
</rootTag>
