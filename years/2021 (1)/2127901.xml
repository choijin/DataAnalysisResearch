<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: From Spatial Language to Spatial Data - a simulation-based approach</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>489141.00</AwardTotalIntnAmount>
<AwardAmount>489141</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>User experience related to spatial information is currently directly linked to the representation of the data; that is, geographic co-ordinates pinpoint locations on maps and routing algorithms determine the best route based on distance and time. In contrast, human interaction with the world is based on experience, learning and reasoning on qualitative factors, including spatial concepts, such as near/far, behind, next to, inside. Considering how spatial information is conveyed in natural language, there is no unique mapping between the spatial expressiveness and quantifiable spatial concepts. For the most part this is attributed to the highly contextualized nature of human language; that is, what human language is interpreted in part by who and where it was said and what other words surrounded the comment. The challenge in this project is on devising means to better understand people's perception of space by deciphering such spatial language terms. This will lead to novel text and audio-based interfaces for the consumption of geospatial data such as when asking for or giving directions in a way that is intuitive to people or for systems that more effectively assist the visually impaired.&lt;br/&gt;&lt;br/&gt;The technical aims of the project are divided into two thrusts. The first thrust develops a simulation to crowdsource geospatial language expression data by having users interact in a virtual environment. The spatial language expressions and interactions are captured using quantitative models. The second thrust then uses these user-generated descriptions to evaluate several modeling approaches that include (i) studying specific urban settings to identify contextual factors and (ii) exploring neural approaches to modeling the problem of grounding language to this spatial context. The resulting models can then be used to automatically translate language to geospatial information and, in the reverse direction, to train dialogue agents that can generate enriched, contextualized route and scene descriptions with natural, useful geospatial language expressions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/16/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2127901</AwardID>
<Investigator>
<FirstName>Dieter</FirstName>
<LastName>Pfoser</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dieter Pfoser</PI_FULL_NAME>
<EmailAddress>dpfoser@gmu.edu</EmailAddress>
<PI_PHON>7039936029</PI_PHON>
<NSF_ID>000654126</NSF_ID>
<StartDate>08/16/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Antonios</FirstName>
<LastName>Anastasopoulos</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Antonios Anastasopoulos</PI_FULL_NAME>
<EmailAddress>antonis@gmu.edu</EmailAddress>
<PI_PHON>5749931434</PI_PHON>
<NSF_ID>000832909</NSF_ID>
<StartDate>08/16/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>George Mason University</Name>
<CityName>FAIRFAX</CityName>
<ZipCode>220304422</ZipCode>
<PhoneNumber>7039932295</PhoneNumber>
<StreetAddress>4400 UNIVERSITY DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA11</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>077817450</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGE MASON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>077817450</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[George Mason University]]></Name>
<CityName>Fairfax</CityName>
<StateCode>VA</StateCode>
<ZipCode>220304444</ZipCode>
<StreetAddress><![CDATA[4400 University Dr.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA11</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~489141</FUND_OBLG>
</Award>
</rootTag>
