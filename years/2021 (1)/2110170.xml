<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>IIS:RI Theoretical Foundations of Reinforcement Learning: From Tabula Rasa to Function Approximation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Reinforcement learning, a technique that trains intelligent agents to make decisions, has become the central algorithmic paradigm for various applications, such as robotics, healthcare, manufacturing production, game playing, and transportation. However, reinforcement learning is equally infamous for demanding significant amounts of data and computing resources. This project aims to contribute to the fundamental understanding of reinforcement learning to reveal its inherent difficulties and develop efficient algorithms with strong theoretical guarantees. The results of the project are readily applicable to solving practical resource-hungry problems. The success of this project also requires new algorithmic techniques and mathematical tools in a variety of disciplines. An education plan is integrated into this project; the investigator will develop new courses, mentor students, organize workshops, and deliver lessons to high school students through the University of Washingtonâ€™s Partner School program.&lt;br/&gt;&lt;br/&gt;This project has two major components. The first thrust studies the most canonical setting, tabula rasa reinforcement learning. The investigator will identify fundamental limits and develop optimal algorithms for several problems of both theoretical and practical interests: worst-case complexity, adaptation to problem structure, and data collection for batch RL. The second thrust is motivated by the modern usage of RL, where function approximation is employed for generalization over a large state space. The investigator will systematically examine the necessary and sufficient conditions that permit efficient learning algorithms for three of the most popular function approximation schemes: value-based, policy-based, and model-based. For both thrusts, the investigator will utilize the inherent combinatorial structures of reinforcement learning to characterize its fundamental hardness and design efficient algorithms. In addition to theoretical developments, the project also aims to implement all algorithms developed as open-source software and evaluate them on benchmark simulation environments.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/26/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/26/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2110170</AwardID>
<Investigator>
<FirstName>Simon</FirstName>
<LastName>Du</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Simon Du</PI_FULL_NAME>
<EmailAddress>ssdu@cs.washington.edu</EmailAddress>
<PI_PHON>4089210192</PI_PHON>
<NSF_ID>000841729</NSF_ID>
<StartDate>07/26/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981950001</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~500000</FUND_OBLG>
</Award>
</rootTag>
