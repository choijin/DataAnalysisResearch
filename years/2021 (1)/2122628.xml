<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Small: Faster Algorithms for High-Dimensional Robust Statistics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2022</AwardEffectiveDate>
<AwardExpirationDate>12/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>390971.00</AwardTotalIntnAmount>
<AwardAmount>390971</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>A. Funda Ergun</SignBlockName>
<PO_EMAI>fergun@nsf.gov</PO_EMAI>
<PO_PHON>7032922216</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As machine learning plays a more prominent role in our society, there is a need for learning algorithms that are reliable and robust. In modern machine learning, one often needs to work with data that are high-dimensional and noisy. Recent work gave the first efficient robust estimators for several basic statistical problems, and since then, there has been a flurry of research that obtained efficient robust algorithms for many machine-learning problems. However, one major drawback of existing algorithms in the literature is that they tend to be much slower when compared to their non-robust counterparts, or they often involve parameters that require careful tuning. To address these issues, this project aims to (i) design faster and provably robust algorithms for a wide range of high-dimensional statistical and learning tasks, and (ii) explore non-convex formulations of robust estimation and analyze their optimization landscape. This project will advance the fields of computer science and statistics, and also potentially lead to useful tools for other areas. The pursuit of faster and simpler algorithms will help accelerate technology transfer into practice, stimulate systematic approaches to robustness, and provide a positive societal impact in the long run. The education plan of this project includes incorporating the materials generated from this project into graduate-level courses at the University of Illinois at Chicago (UIC), as well as training graduate and undergraduate students at UIC, which is an urban university with a diverse student population.&lt;br/&gt;&lt;br/&gt;Designing robust algorithms in high dimensions is a very challenging task. Even for the basic problem of mean estimation, when a small fraction of the input is adversarially corrupted, no efficient algorithms were known until recently. The first polynomial-time estimators with dimension-independent error guarantees were discovered in 2016. However, given the amount of data available today, polynomial-time no longer translates to scalability in practice. Motivated by the need for faster and more practical algorithms, this project focuses on two main thrusts to expand the area of algorithmic high-dimensional robust statistics. First, the investigator would like to speed up existing algorithms and develop new robust algorithms for a broader range of problems and richer families of distributions, with the ultimate goal of matching the runtime of the fastest non-robust algorithms. Second, the investigator wants to design robust estimators that can be computed via standard first-order optimization methods. The main challenge is to find an objective function whose gradient can be evaluated using basic matrix operations while proving the structural result that this objective has no bad local optima.  Concretely, the investigator plans to work on these two thrusts by targeting various aspects of the following problems: (1) robust stochastic optimization, (2) robust sparse mean estimation and sparse PCA, (3) robust covariance estimation, (4) list-decodable learning, and (5) robust learning of Bayesian networks. This project is interdisciplinary and will rely on intuition and techniques from statistics, probability, linear algebra, discrete and continuous optimization, and non-convex optimization.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/30/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/30/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2122628</AwardID>
<Investigator>
<FirstName>Yu</FirstName>
<LastName>Cheng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yu Cheng</PI_FULL_NAME>
<EmailAddress>yucheng2@uic.edu</EmailAddress>
<PI_PHON>3129962186</PI_PHON>
<NSF_ID>000808381</NSF_ID>
<StartDate>08/30/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606124305</ZipCode>
<PhoneNumber>3129962862</PhoneNumber>
<StreetAddress>809 S. Marshfield Avenue</StreetAddress>
<StreetAddress2><![CDATA[MB 502, M/C 551]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>098987217</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Chicago, MSCS Department]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606070045</ZipCode>
<StreetAddress><![CDATA[851 S Morgan; SEO; MC 249]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~390971</FUND_OBLG>
</Award>
</rootTag>
