<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: Creating Knowledge with All-Novel-Class Computer Vision</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2025</AwardExpirationDate>
<AwardTotalIntnAmount>1200000.00</AwardTotalIntnAmount>
<AwardAmount>685206</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer vision methods have had very high impact on science and industry, but this impact has been confined to cases where there is access to very large quantities of labelled data (i.e., objects are identified in the image), which have either been published, collected or purchased. This research will study computer vision methods that operate in areas where there are very little labelled data. This project builds on the natural model of the way humans and animals learn to label images. One core research goal is an object detection procedure that can be trained with all category data — there will be a small number of examples each from a large number of categories. Another core goal is a learning procedure that can share training examples across categories widely and effectively without explicit linking of the categories. A third core goal is linking learning of early vision tasks — for example, recovering shading and lighting from an image — to learning of classification and detection tasks, so that both tasks can be learned with very little labelled data. Successful completion of this research will unify apparently disparate areas of computer vision, by linking early vision and categorization directly, and will create novel methods for improving categorization performance in difficult circumstances. Furthermore, successful completion of this research will unlock many real-world applications that need all category methods. &lt;br/&gt;&lt;br/&gt;The all-novel-class problem occurs where there are a small number of examples each from a large number of classes and no class has many examples. This project addresses the all-novel-class issue by sharing of various kinds of information during training. Specifically, three kinds of sharing principles will be studied. The first is a cell consistency principle that uses a geometric and probabilistic analysis of class boundaries driven by feature generation to produce improvements in classification, by requiring that the cells in feature space associated with the similar classes. Second, a label consistency principle uses probabilistic reasoning to impute labels and confidence weights for unlabeled examples. Label consistency can be applied extensively, from category labels for individual examples to superclass labels that identify classes over which sharing will be helpful. Finally, a physical consistency principle requires that inferences from images are consistent with simple physics laws; this principle allows researchers to impute missing annotations for early vision data and links high level classes to early vision through an attribute theory.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/18/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2106825</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Forsyth</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David A Forsyth</PI_FULL_NAME>
<EmailAddress>daf@cs.uiuc.edu</EmailAddress>
<PI_PHON>2172656851</PI_PHON>
<NSF_ID>000391155</NSF_ID>
<StartDate>08/18/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yuxiong</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yuxiong Wang</PI_FULL_NAME>
<EmailAddress>yxw@illinois.edu</EmailAddress>
<PI_PHON>4129969769</PI_PHON>
<NSF_ID>000840929</NSF_ID>
<StartDate>08/18/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Schwing</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexander Schwing</PI_FULL_NAME>
<EmailAddress>aschwing@illinois.edu</EmailAddress>
<PI_PHON>2173332187</PI_PHON>
<NSF_ID>000734749</NSF_ID>
<StartDate>08/18/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Board of Trustees of the University of Illinois]]></Name>
<CityName>Urbana</CityName>
<StateCode>IL</StateCode>
<ZipCode>618013620</ZipCode>
<StreetAddress><![CDATA[506 S. Wright Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~685206</FUND_OBLG>
</Award>
</rootTag>
