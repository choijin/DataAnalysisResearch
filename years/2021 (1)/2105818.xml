<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF:Small: Theory and Methods for  Simultaneous Feature Auto-grouping and Dimension Reduction in Supervised Multivariate Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2021</AwardEffectiveDate>
<AwardExpirationDate>05/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>339656.00</AwardTotalIntnAmount>
<AwardAmount>339656</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Armand Makowski</SignBlockName>
<PO_EMAI>amakowsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928910</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Modern real-world applications have created an urgent need for analyzing and interpreting high-dimensional data with low-dimensional structures. In situations where a large number of response variables is present, very few features may be completely irrelevant to the entire set of responses; this leads to ineffective sparsity-based variable selection and to non-interpretable vanilla low-rank modeling. To address these issues, this project proposes grouping the features based on their contributions to the response variables, in a possibly low-dimensional subspace, in order to build a more parsimonious and interpretable model. In the context of multivariate learning, the intrinsic cost of searching for clusters and the potential adverse effect of high-dimensionality on signal recovery are not yet fully understood. Another critical challenge in the big-data era is to develop efficient optimization algorithms with rigorous convergence guarantees. The fact that the obtained algorithmic solutions may not be globally optimal, due to the non-convexity of the problem, makes the statistical error analysis nontrivial. The associated model-selection problem is another unsolved problem in the context of clustering, most notably when the number of features and/or the number of responses go beyond the sample size. To answer these questions, innovative and transformative statistical methods are being introduced, and the proposed algorithms are being analyzed to demonstrate their efficiency. The project covers potential applications in a wide range of areas such as machine learning, genomics, and macro-econometrics, and will help cross-fertilize ideas from statistics, operations research, economics, and bio-engineering. Education activities are tightly coupled with research, and include course development, student mentoring, outreach, and recruiting underrepresented students. &lt;br/&gt;&lt;br/&gt;The project proposes a novel clustered reduced-rank learning framework that utilizes joint matrix regularizations to relax the stringent assumption of sparsity-based learning and to gain interpretability as compared with vanilla low-rank modeling. Some universal information-theoretic limits are revealing the intrinsic cost of searching for clusters regardless of the estimator in use, as well as the benefit of accumulating a large number of response variables in multivariate learning. Efficient optimization algorithm that perform simultaneous subspace learning and clustering are being developed; the resulting fixed-point estimators, while not necessarily globally optimal, still enjoy the desired statistical accuracy beyond the standard likelihood setup. Finally, a new kind of information criterion for joint cluster and rank selection is being proposed, without assuming either infinite sample size or large signal-to-noise ratio. The research is creating a fusion between statistics, information theory, nonconvex optimization, and model selection, with real-world applications.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/17/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/17/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2105818</AwardID>
<Investigator>
<FirstName>Yiyuan</FirstName>
<LastName>She</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yiyuan She</PI_FULL_NAME>
<EmailAddress>yshe@stat.fsu.edu</EmailAddress>
<PI_PHON>8506443218</PI_PHON>
<NSF_ID>000549795</NSF_ID>
<StartDate>05/17/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida State University</Name>
<CityName>Tallahassee</CityName>
<ZipCode>323064166</ZipCode>
<PhoneNumber>8506445260</PhoneNumber>
<StreetAddress>874 Traditions Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790877419</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida State University]]></Name>
<CityName>Tallahassee</CityName>
<StateCode>FL</StateCode>
<ZipCode>323064330</ZipCode>
<StreetAddress><![CDATA[117 N Woodward Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7797</Code>
<Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~339656</FUND_OBLG>
</Award>
</rootTag>
