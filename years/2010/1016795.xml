<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC-GV: Small:  Generating Animal Avatar Animation with Specific Identifiable Traits Based Upon Viewer Perception of Real Animals</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>499952.00</AwardTotalIntnAmount>
<AwardAmount>499952</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computing devices have transformed person-to-person communication, dramatically altering how we present ourselves to the world.  As the use of computer character animation rapidly expands into 3D digital media in mobile devices, social networking, and massively multiplayer online games, the demand for distinctive personalized digital avatars is beyond the capacity of key-frame animation, beyond the range of motion capture, and beyond the expressive capability of rule-based animation.  The PI's goal in this project is to define a new framework that transforms biological locomotion into a content form, classified by identity-rich features which can be synthesized for use in animating animals, whether real or imagined.   The research focuses on how species, age, and weight are perceived by people viewing real animals, with the intention of making virtual animals, or humans representing themselves as animal avatars, more expressive.  Project outcomes will include a technique for procedural generation of animation for novel digital creatures that is capable of movement patterns signifying a specific animal species, age as young or old, and weight as heavy or light.  The PI argues that to develop this new way of creating and managing expressive animation, we need a better understanding of how we perceive motion itself.  To this end, the PI and his team will borrow from biological motion studies to determine what level of detail of motion information is required for recognition.  He will use eye tracking to determine where the information is found in animal motion, and will employ linear analysis to decompose the motion and re-inject the identity-laden elements into novel animal forms.  Thus, the work will combine three areas of research - perception of biological motion, eye tracking, and synthesis of gait patterns - to develop the foundation for a generative system for animal avatar animation.  &lt;br/&gt;&lt;br/&gt;Broader Impacts:  This project combines the use of computational systems to both analyze how we perceive motion and to synthesize new, novel motion.  The research will contribute to our understanding of human perception of biological motion, and expand the performance range and emotional impact of synthesized animation.  Techniques for isolating the spatio-temporal information that leads to recognition of identifiable traits will expand beyond the perception of humans and into the domain of animal motion, thereby opening the door to creating animal avatars that are expressive through motion in a variety of ways that communicate personality.  Project outcomes will thus be of interest to creators of digital content for games, immersive virtual worlds, and cinema.  The PI expects this work will lead to expansion of both the range of traits that can be procedurally applied to animation and the sophistication of novel gait generation methods.</AbstractNarration>
<MinAmdLetterDate>08/16/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/07/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1016795</AwardID>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>McLaughlin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy McLaughlin</PI_FULL_NAME>
<EmailAddress>timm@viz.tamu.edu</EmailAddress>
<PI_PHON>9798453465</PI_PHON>
<NSF_ID>000502118</NSF_ID>
<StartDate>08/16/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ann</FirstName>
<LastName>McNamara</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ann McNamara</PI_FULL_NAME>
<EmailAddress>ann@viz.tamu.edu</EmailAddress>
<PI_PHON>9798454715</PI_PHON>
<NSF_ID>000521199</NSF_ID>
<StartDate>08/16/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M Research Foundation</Name>
<CityName>College Station</CityName>
<ZipCode>778454375</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Parkway, S</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078592789</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A &amp; M RESEARCH FOUNDATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>078592789</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&amp;M University]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778454375</ZipCode>
<StreetAddress><![CDATA[400 Harvey Mitchell Pkwy South]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~170031</FUND_OBLG>
<FUND_OBLG>2011~329921</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Recent years have seen great strides in the development of computer-animated characters. Animated creatures ranging from Aslan the lion in the movie the <em>Chronicles of Narnia</em> to the slew of original avatars in games like <em>World of Warcraft</em>. To be successful these characters need to be designed in a manner that produces believable and expressive motion.</p> <p>&nbsp;</p> <p>While existing methods can produce realistic results, they are cumbersome, time consuming and require a lot of human input.<strong> A major outcome of this project is a comprehensive web based tool that automates believable character gait</strong> i.e. how characters walk, trot, and run. This tool enables novice users to create believable and expressive character motion because its foundation is a mathematical representation of real animals in motion. The tool is accessible to anyone with internet access and a web-browser, and is designed to be usable by untrained individuals.&nbsp; The tool provides an interface for constructing a wide range of body plans for quadruped animals and an interface for generating cycled walks, trots, and runs.&nbsp; Significantly, the characterization of these gaits can be altered to communicate weight, age, and danger. &nbsp;For instance, the movement of young animals is typically faster-paced and chaotic, whereas the movement of older animals is slower and smoother. Our research studied the motion of real animals to gain an understanding of how motion by itself communicated these qualities independent of an animal&rsquo;s form. The goal is to capture those traits and allow users to attach them to the animal.</p> <p>&nbsp;</p> <p>The web-based system for authoring animation is robust and comprehensive. There are three sliders that can be used with an intuitive level of control (weight, age, dangerous). There are preset characters included with the tool &ndash;such as horse, large cat, and giraffe -but users can define and use their own characters too. The system can be used by art and animation students worldwide as well as by enthusiasts for animation who are not in an academic environment. The web-based animation tool is provided free for public use. The framework could be adopted for the development of proprietary software by private companies, including animation and game studios. However, that step requires coordination and contractual engagement with the Texas A&amp;M University System</p> <p>&nbsp;</p> <p>We also developed a motion library containing 16 animal motions. These include walks, trots, and runs from four legged creatures. All of these motions are available in the web-based tool. The web-based tool can also transition between some of these motions successfully providing a wide range of motions to apply to virtual characters.</p> <p>&nbsp;</p> <p>Four graduate and three undergraduate students worked on this project.&nbsp; Six are now employed in the animation and visual effects industries and the seventh is in enterprise software development.&nbsp; These opportunities were made possible, at least in some way, by this project.&nbsp; The undergraduates graduated from the Bachelor of Science in Visualization program and the graduate students from the Master of Science in Visualization Program at Texas A&amp;M University.&nbsp; Their employers are Emerson Process Management in Austin, TX; Industrial Light &amp; Magic in San Francisco, CA; MPC, the Motion Picture Company in Montreal, Canada; Atomic Fiction in Oakland, CA; Method Studios in Los Angeles, CA; Oriental DreamWorks in Shanghei, China, and Pixar Animation Studio in Emeryville, CA.</p> <p>&nbsp;</p> <p>In summary this project developed a system for novice users to enable them to create complex and expressive walk, trot, and run cycles for digital characters.&nbsp; Users have full control of the animal&rsquo;s shape within the quadruped body plan.&nbsp;&nbsp; Future work could move...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Recent years have seen great strides in the development of computer-animated characters. Animated creatures ranging from Aslan the lion in the movie the Chronicles of Narnia to the slew of original avatars in games like World of Warcraft. To be successful these characters need to be designed in a manner that produces believable and expressive motion.     While existing methods can produce realistic results, they are cumbersome, time consuming and require a lot of human input. A major outcome of this project is a comprehensive web based tool that automates believable character gait i.e. how characters walk, trot, and run. This tool enables novice users to create believable and expressive character motion because its foundation is a mathematical representation of real animals in motion. The tool is accessible to anyone with internet access and a web-browser, and is designed to be usable by untrained individuals.  The tool provides an interface for constructing a wide range of body plans for quadruped animals and an interface for generating cycled walks, trots, and runs.  Significantly, the characterization of these gaits can be altered to communicate weight, age, and danger.  For instance, the movement of young animals is typically faster-paced and chaotic, whereas the movement of older animals is slower and smoother. Our research studied the motion of real animals to gain an understanding of how motion by itself communicated these qualities independent of an animalÆs form. The goal is to capture those traits and allow users to attach them to the animal.     The web-based system for authoring animation is robust and comprehensive. There are three sliders that can be used with an intuitive level of control (weight, age, dangerous). There are preset characters included with the tool &ndash;such as horse, large cat, and giraffe -but users can define and use their own characters too. The system can be used by art and animation students worldwide as well as by enthusiasts for animation who are not in an academic environment. The web-based animation tool is provided free for public use. The framework could be adopted for the development of proprietary software by private companies, including animation and game studios. However, that step requires coordination and contractual engagement with the Texas A&amp;M University System     We also developed a motion library containing 16 animal motions. These include walks, trots, and runs from four legged creatures. All of these motions are available in the web-based tool. The web-based tool can also transition between some of these motions successfully providing a wide range of motions to apply to virtual characters.     Four graduate and three undergraduate students worked on this project.  Six are now employed in the animation and visual effects industries and the seventh is in enterprise software development.  These opportunities were made possible, at least in some way, by this project.  The undergraduates graduated from the Bachelor of Science in Visualization program and the graduate students from the Master of Science in Visualization Program at Texas A&amp;M University.  Their employers are Emerson Process Management in Austin, TX; Industrial Light &amp; Magic in San Francisco, CA; MPC, the Motion Picture Company in Montreal, Canada; Atomic Fiction in Oakland, CA; Method Studios in Los Angeles, CA; Oriental DreamWorks in Shanghei, China, and Pixar Animation Studio in Emeryville, CA.     In summary this project developed a system for novice users to enable them to create complex and expressive walk, trot, and run cycles for digital characters.  Users have full control of the animalÆs shape within the quadruped body plan.   Future work could move this project toward use in animation control engines for massively multi-user on-line environments where expressive motion is important to user-to-user communication.               Last Modified: 04/08/2016       Submitted by: Timothy Mclaughl...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
