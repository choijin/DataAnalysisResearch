<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TC:  Large:  Collaborative Research:  Practical Privacy: Metrics and Methods for Protecting Record-level and Relational Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>1326660.00</AwardTotalIntnAmount>
<AwardAmount>1326660</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Fen Zhao</SignBlockName>
<PO_EMAI>fzhao@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Safely managing the release of data containing confidential information about individuals is a problem of great societal importance. Governments, institutions, and researchers collect data whose release can have enormous benefits to society by influencing public policy or advancing scientific knowledge. But dissemination of these data can only happen if the privacy of the respondents' data is preserved or if the amount of disclosure is limited.&lt;br/&gt;&lt;br/&gt;The goal of this research project is to bridge the gap between the statistics and computer science community and between theory and practice in limiting disclosure. The research focuses on limiting statistical disclosure using synthetic data, the most advanced method from the statistics community that enables the construction of public data sets with strong statistical properties; the research incorporates formal privacy guarantees from the computer science community into this approach.  Techniques focus on household data and relational data dealing with real problems motivated by the U.S. Census Bureau and related agencies.&lt;br/&gt;&lt;br/&gt;The approach of the team is based on the development of novel techniques for boosting the utility of synthetic data generation methods with formal privacy guarantees; novel formal privacy models that formalize attackers implicitly considered in the statistics literature, and new attacker models that allow an exploration of the space between weak and strong adversaries; and novel techniques designed for data from censuses or surveys about households which have a relational structure.&lt;br/&gt;&lt;br/&gt;The research has broad impact by influencing the methodology of statistical agencies around the world. The project also develops a open-source toolkit for limiting disclosure in data publishing with formal privacy guarantees; it integrates undergraduate students into research, and it creates educational material for material for practitioners responsible for safe data handling.&lt;br/&gt;&lt;br/&gt;For further information see the project web site at the URL:&lt;br/&gt;www.cs.cornell.edu/bigreddata/privacy</AbstractNarration>
<MinAmdLetterDate>07/14/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1012593</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Abowd</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John M Abowd</PI_FULL_NAME>
<EmailAddress>john.abowd@cornell.edu</EmailAddress>
<PI_PHON>6072558024</PI_PHON>
<NSF_ID>000332299</NSF_ID>
<StartDate>06/27/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>John</FirstName>
<LastName>Abowd</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John M Abowd</PI_FULL_NAME>
<EmailAddress>john.abowd@cornell.edu</EmailAddress>
<PI_PHON>6072558024</PI_PHON>
<NSF_ID>000332299</NSF_ID>
<StartDate>07/14/2010</StartDate>
<EndDate>12/09/2014</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Johannes</FirstName>
<LastName>Gehrke</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Johannes E Gehrke</PI_FULL_NAME>
<EmailAddress>johannes@cs.cornell.edu</EmailAddress>
<PI_PHON>6072551045</PI_PHON>
<NSF_ID>000492612</NSF_ID>
<StartDate>07/14/2010</StartDate>
<EndDate>12/09/2014</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lars</FirstName>
<LastName>Vilhuber</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lars Vilhuber</PI_FULL_NAME>
<EmailAddress>lars.vilhuber@cornell.edu</EmailAddress>
<PI_PHON>6073305743</PI_PHON>
<NSF_ID>000232977</NSF_ID>
<StartDate>06/27/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~249657</FUND_OBLG>
<FUND_OBLG>2011~257238</FUND_OBLG>
<FUND_OBLG>2012~265067</FUND_OBLG>
<FUND_OBLG>2013~554698</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the course of the grant, we have developed multiple algorithms to address privacy concerns. We developed a novel privacy definition called &ldquo;crowd-blending&rdquo;, which is easier to achieve than differential privacy, and allows the release of histograms with higher accuracy. MaskIT is a mechanism to defend against inference attacks from adversaries knowing temporal correlations in user behavior. We also worked on mechanisms to protect users in the context of ad-tracking.&nbsp;</p> <p><br />A critical duty of statistical agencies is to publish usable data. Confidentiality of respondent identities and attributes cannot ever be perfectly protected but these agencies must nevertheless publish data or cease to exist. The public benefit from the data publication has been inadequately modeled in most research on data privacy because only the private benefit to the respondent is balanced against the costs of privacy breaches. We have developed a framework for incorporating the public-good aspects of both data privacy and publication. The paper describing this analysis addresses a broad population of researchers in the social sciences.&nbsp;</p> <p><br />Taking this a step further, we have actively worked with the U.S. Census Bureau to investigate and implement differential privacy in a variety of products, including the American Community Survey, the Decennial Census, and the Economic Censuses. For cutting-edge formal privacy models, there had been very little effort in the academic literature to apply those methods in real-world settings with schema-complicated, large, messy data. We therefore brought together an expanded group of specialists from academia and government who could shed light on technical and subject matter challenges. They addressed the question of how data users might react to changes in data availability and publishing standards. The workshops brought many practitioners together to discuss, among other topics, the way that differential privacy can be brought to bear on these products while maintaining sufficient accuracy, and how to extend practical synthetic data algorithms to other contexts (different agencies, different data attributes). In part due to the efforts funded through this grant, differential privacy will be an integral part of the Census Bureau publication strategy for the Decennial Census, and likely to play a similar role in future ACS and Economic Census publications.</p> <p><br />Privacy-protecting but analytically valid synthetic data are being considered for tax data in the U.S, and are close to release in Canada, Germany, and Brazil, allowing U.S.-based researchers to conduct cross-border analyses on detailed firm or establishment data while allowing each country&rsquo;s statistical agency to preserve privacy.&nbsp;</p><br> <p>            Last Modified: 10/27/2017<br>      Modified by: Lars&nbsp;Vilhuber</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the course of the grant, we have developed multiple algorithms to address privacy concerns. We developed a novel privacy definition called "crowd-blending", which is easier to achieve than differential privacy, and allows the release of histograms with higher accuracy. MaskIT is a mechanism to defend against inference attacks from adversaries knowing temporal correlations in user behavior. We also worked on mechanisms to protect users in the context of ad-tracking.    A critical duty of statistical agencies is to publish usable data. Confidentiality of respondent identities and attributes cannot ever be perfectly protected but these agencies must nevertheless publish data or cease to exist. The public benefit from the data publication has been inadequately modeled in most research on data privacy because only the private benefit to the respondent is balanced against the costs of privacy breaches. We have developed a framework for incorporating the public-good aspects of both data privacy and publication. The paper describing this analysis addresses a broad population of researchers in the social sciences.    Taking this a step further, we have actively worked with the U.S. Census Bureau to investigate and implement differential privacy in a variety of products, including the American Community Survey, the Decennial Census, and the Economic Censuses. For cutting-edge formal privacy models, there had been very little effort in the academic literature to apply those methods in real-world settings with schema-complicated, large, messy data. We therefore brought together an expanded group of specialists from academia and government who could shed light on technical and subject matter challenges. They addressed the question of how data users might react to changes in data availability and publishing standards. The workshops brought many practitioners together to discuss, among other topics, the way that differential privacy can be brought to bear on these products while maintaining sufficient accuracy, and how to extend practical synthetic data algorithms to other contexts (different agencies, different data attributes). In part due to the efforts funded through this grant, differential privacy will be an integral part of the Census Bureau publication strategy for the Decennial Census, and likely to play a similar role in future ACS and Economic Census publications.   Privacy-protecting but analytically valid synthetic data are being considered for tax data in the U.S, and are close to release in Canada, Germany, and Brazil, allowing U.S.-based researchers to conduct cross-border analyses on detailed firm or establishment data while allowing each country?s statistical agency to preserve privacy.        Last Modified: 10/27/2017       Submitted by: Lars Vilhuber]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
