<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  CI-ADDO-EN:  Development of Publicly Available,  Easily Searchable, Linguistically Analyzed, Video Corpora for Sign Language and Gesture Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>92257.00</AwardTotalIntnAmount>
<AwardAmount>92257</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to create a linguistically annotated, publicly available, and easily searchable corpus of video from American Sign Language (ASL). This will constitute an important piece of infrastructure, enabling new kinds of research in both linguistics and vision-based recognition of ASL. In addition, a key goal is to make this corpus easily accessible to the broader ASL community, including users and learners of ASL. As a result of our long-term efforts, we have an extensive collection of linguistically annotated video data from native signers of ASL. However, the potential value of these corpora has been largely untapped, notwithstanding their extensive and productive use by our team and others. Existing limitations in our hardware and software infrastructure make it cumbersome to search and identify data of interest, and to share data among our institutions and with other researchers. In this project, we propose hardware and software innovations that will constitute a major qualitative upgrade in the organization, searchability, and public availability of the existing (and expanding) corpus.&lt;br/&gt; &lt;br/&gt;The enhancement and improved Web-accessibility of these corpora will be invaluable for linguistic research, enabling new kinds of discoveries and the testing of hypotheses that would otherwise have be difficult to investigate. On the computer vision side, the proposed new annotations will provide an extensive public dataset for training and benchmarking a variety of computer vision algorithms. This will facilitate research and expedite progress in gesture recognition, hand pose estimation, human tracking, and large vocabulary, and continuous ASL recognition. Furthermore, this dataset will be useful as training and benchmarking data for algorithms in the broader areas of computer vision, machine learning, and similarity-based indexing. &lt;br/&gt;&lt;br/&gt;The advances in linguistic knowledge about ASL and in computer-based ASL recognition that will be accelerated by the availability of resources of the kind proposed here will contribute to development of technologies for education and universal access. For example, tools for searching collections of ASL video for occurrences of specific signs, or converting ASL signing to English, are still far from attaining the level of functionality and usability to which users are accustomed for spoken/written languages. Our corpora will enable research that aims to bring such vision-based ASL recognition applications closer to reality. Moreover, these resources will afford important opportunities to individuals who would not otherwise be in a position to conduct such research (e.g., for lack of access to native ASL signers or high-quality synchronized video equipment, or lack of resources/expertise to carry out extensive linguistic annotations). Making our corpora available online will also allow the broader community of ASL users to access our data directly. Students of ASL will be able to retrieve video showing examples of a specific sign used in actual sentences, or examples of a grammatical construction. ASL instructors and teachers of the Deaf will also have easy access to video examples of lexical items and grammatical constructions as used by a variety of native signers for use in language instruction and evaluation. Thus, the proposed web interface to our data collection will be a useful educational resource for users, teachers, and learners of ASL.</AbstractNarration>
<MinAmdLetterDate>07/27/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1059221</AwardID>
<Investigator>
<FirstName>Christian</FirstName>
<LastName>Vogler</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christian Vogler</PI_FULL_NAME>
<EmailAddress>christian.vogler@gallaudet.edu</EmailAddress>
<PI_PHON>2022502795</PI_PHON>
<NSF_ID>000056369</NSF_ID>
<StartDate>08/20/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Bahan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin Bahan</PI_FULL_NAME>
<EmailAddress>benjamin.bahan@gallaudet.edu</EmailAddress>
<PI_PHON>2022502329</PI_PHON>
<NSF_ID>000570637</NSF_ID>
<StartDate>07/27/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Gallaudet University</Name>
<CityName>Washington</CityName>
<ZipCode>200023660</ZipCode>
<PhoneNumber>2026515497</PhoneNumber>
<StreetAddress>800 Florida Avenue, NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003259439</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GALLAUDET UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003259439</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Gallaudet University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200023660</ZipCode>
<StreetAddress><![CDATA[800 Florida Avenue, NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~92257</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>There has been an unmet demand for high-quality sign language corpora &ndash; annotated collections of sign language conversations, articles, stories and examples &ndash; that are easily accessible not just to sign language researchers, but also to researchers from other fields, as well as the community at large. Such corpora provide detailed annotations of the signs, as well as associated nonmanual markings, such as facial expressions and head movements. They have many applications, including but not limited to research into the linguistic structure of signed languages, developing sign language-based human-computer interaction, sign-to-text applications, text-to-sign applications, developing educational materials on sign language, and giving students of sign language the tools to engage into deeper studies of the language and improving their skills.</p> <p>Existing solutions have relied on specialized software to provide access to sign language corpora. This type of specialized software requires extensive training to use effectively, and poses a large barrier for most people to access content and apply it to their own work. There has been a need to lower this barrier make annotated sign language data, with a diverse collection of examples, easily accessible and searchable.</p> <p>The work on this project has resulted in a publicly available web-based database of American Sign Language (ASL) examples, as shown in the pictures. These examples consists of a mix of full-length stories and individual collection of sentences highlighting specific linguistic phenomena in ASL. This database is searchable by various criteria, such as the name or type of sign, and provides an easy-to-use interface even for non-subject matter experts. It is also possible to download the annotations and associated videos for further processing in other applications, such as sign-to-text research. The fully-annotated stories provide an especially rich collection of linguistic phenomena to study for sign language learners, as well. This database has also been linked with a large lexicon, called the ASL Lexicon Video Dataset, where variants in the production of signs can be looked up.</p> <p>Additionally, for the first time, academic ASL has been annotated in the form of a full-length article in the peer-reviewed Deaf Studies Digital Journal, as shown in the pictures. This allows interested parties to analyze how academic ASL differs from the ASL used every day and in stories, and study how academic discourse is structured in ASL. The annotations also provide a resource for students to bring their ASL skills up to expectations in academic settings.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/10/2017<br>      Modified by: Benjamin&nbsp;Bahan</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993213983_ScreenShot2016-12-22at3.22.49PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993213983_ScreenShot2016-12-22at3.22.49PM--rgov-800width.jpg" title="Database Access Interface Details and Video Screen"><img src="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993213983_ScreenShot2016-12-22at3.22.49PM--rgov-66x44.jpg" alt="Database Access Interface Details and Video Screen"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The video of a specific sign sentence is shown. The search term is highlighted in yellow, and the entire sentence and video show how a sign is to be used in context.</div> <div class="imageCredit">Carol Neidle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Christian&nbsp;Vogler</div> <div class="imageTitle">Database Access Interface Details and Video Screen</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1059221/1059221_10113900_1482357524655_SSscreenshot--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1059221/1059221_10113900_1482357524655_SSscreenshot--rgov-800width.jpg" title="Annotations of Deaf Studies Digital Journal"><img src="/por/images/Reports/POR/2016/1059221/1059221_10113900_1482357524655_SSscreenshot--rgov-66x44.jpg" alt="Annotations of Deaf Studies Digital Journal"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A video of a Deaf Studies Digital Journal is shown, with various tiers of annotations shown, including gloss, handshapes, and nonmanual markings.</div> <div class="imageCredit">Benajmin Bahan</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Christian&nbsp;Vogler</div> <div class="imageTitle">Annotations of Deaf Studies Digital Journal</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1059221/1059221_10113900_1482357748193_DAI-1--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1059221/1059221_10113900_1482357748193_DAI-1--rgov-800width.jpg" title="Database Access Interface Search Screen"><img src="/por/images/Reports/POR/2016/1059221/1059221_10113900_1482357748193_DAI-1--rgov-66x44.jpg" alt="Database Access Interface Search Screen"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The user can search by various features for specific signs or constructions.</div> <div class="imageCredit">Christian Vogler</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Christian&nbsp;Vogler</div> <div class="imageTitle">Database Access Interface Search Screen</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993324857_ScreenShot2016-12-22at3.21.48PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993324857_ScreenShot2016-12-22at3.21.48PM--rgov-800width.jpg" title="Database Search Results Screen"><img src="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993324857_ScreenShot2016-12-22at3.21.48PM--rgov-66x44.jpg" alt="Database Search Results Screen"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The image shows all signs and their variants that match a specific search, along with the people who have examples of this sign on video.</div> <div class="imageCredit">Carol Neidle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Christian&nbsp;Vogler</div> <div class="imageTitle">Database Search Results Screen</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993430405_ScreenShot2016-12-22at3.26.57PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993430405_ScreenShot2016-12-22at3.26.57PM--rgov-800width.jpg" title="ASL Lexicon Video Dataset Screen"><img src="/por/images/Reports/POR/2017/1059221/1059221_10113900_1483993430405_ScreenShot2016-12-22at3.26.57PM--rgov-66x44.jpg" alt="ASL Lexicon Video Dataset Screen"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The image shows the different variants in how the sign for FINISH can be produced. This lexicon is linked with the main corpus website.</div> <div class="imageCredit">Carol Neidle</div> <div class="imagePermisssions">Royalty-free (restricted use - cannot be shared)</div> <div class="imageSubmitted">Christian&nbsp;Vogler</div> <div class="imageTitle">ASL Lexicon Video Dataset Screen</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ There has been an unmet demand for high-quality sign language corpora &ndash; annotated collections of sign language conversations, articles, stories and examples &ndash; that are easily accessible not just to sign language researchers, but also to researchers from other fields, as well as the community at large. Such corpora provide detailed annotations of the signs, as well as associated nonmanual markings, such as facial expressions and head movements. They have many applications, including but not limited to research into the linguistic structure of signed languages, developing sign language-based human-computer interaction, sign-to-text applications, text-to-sign applications, developing educational materials on sign language, and giving students of sign language the tools to engage into deeper studies of the language and improving their skills.  Existing solutions have relied on specialized software to provide access to sign language corpora. This type of specialized software requires extensive training to use effectively, and poses a large barrier for most people to access content and apply it to their own work. There has been a need to lower this barrier make annotated sign language data, with a diverse collection of examples, easily accessible and searchable.  The work on this project has resulted in a publicly available web-based database of American Sign Language (ASL) examples, as shown in the pictures. These examples consists of a mix of full-length stories and individual collection of sentences highlighting specific linguistic phenomena in ASL. This database is searchable by various criteria, such as the name or type of sign, and provides an easy-to-use interface even for non-subject matter experts. It is also possible to download the annotations and associated videos for further processing in other applications, such as sign-to-text research. The fully-annotated stories provide an especially rich collection of linguistic phenomena to study for sign language learners, as well. This database has also been linked with a large lexicon, called the ASL Lexicon Video Dataset, where variants in the production of signs can be looked up.  Additionally, for the first time, academic ASL has been annotated in the form of a full-length article in the peer-reviewed Deaf Studies Digital Journal, as shown in the pictures. This allows interested parties to analyze how academic ASL differs from the ASL used every day and in stories, and study how academic discourse is structured in ASL. The annotations also provide a resource for students to bring their ASL skills up to expectations in academic settings.                Last Modified: 01/10/2017       Submitted by: Benjamin Bahan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
