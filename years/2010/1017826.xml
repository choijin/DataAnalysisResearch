<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: SMALL: Wearable computation and feedback for real-time movement training</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Movement is a basic feature of human existence and is intimately connected to our quality of life.  Movement training can prevent injury, improve athletic performance, delay musculoskeletal disease and accelerate rehabilitation.  Until now, training has been limited in scope to specialized training facilities and limited in effectiveness to the verbal recommendations of physical trainers.  In this project, the PI's goal is to expand the scope and effectiveness of human movement training in order to extend health and lifestyle benefits to the general public.  The primary outcome of this research at the intersection of robotics, biomechanics and human-computer interaction will be gait modeling software that integrates sensor data in real time to compute kinematics, kinetics and joint/tendon forces to predict adjustments to motion parameters to achieve an end goal.  The PI's hypothesis is that wearable computation can fundamentally change the way people move.  The miniaturization of computational hardware, as well as advances in movement analysis algorithms, wearable sensors and feedback devices, all serve as catalysts for a new level of human interaction.  The work will focus on everyday repetitive dynamic activities like walking, running and jumping, whose nature is that information gathered and analyzed during one cycle can be applied to subsequent cycles to achieve gradual improvement.  Feedback that builds upon advances in robotics, motion tracking and biomechanical modeling (that have led to efficient monitoring and simulation of complex multi-degree of freedom systems) will be provided in real time and will be adaptive, robust with respect to cycle-to-cycle variations, and user specific.  For maximum impact, movement training will be accessible to the average citizen instead of confined to the laboratory or clinic.  To this end, the PI will create a system that could be used while walking around the house, hiking outdoors or running in a gymnasium.  Preliminary experiments in motion tracking, dynamic analysis and wearable feedback for gait retraining to reduce knee loading associated with injury and arthritis will be extended to evaluate which types of sensing and feedback, in combination with algorithms to detect and analyze motion anomalies, are effective outside of the laboratory.   The PI will conduct a series of experiments to validate the portable solution, comparing it with results obtained in a fully instrumented laboratory setting and assessing how the effects of training are retained over time.  &lt;br/&gt;&lt;br/&gt;Broader Impacts:  The PI argues that with wearable retraining devices middle-aged women could be taught to walk in a way that slows or prevents osteoarthritis as well as injury at the hips, ankles, etc., college athletes could be trained to jump and land while playing volleyball so as to prevent ACL and other common sports-related injuries (while perhaps improving performance as well), and victims of stroke and other neurological disorders could be rehabilitated at home instead of at the clinic.  This project will focus initially on walking and knee joint loading, a problem of immediate importance for the aging U.S. population.  The PI will provide open source software (e.g., for monitoring sensors and predicting target gait parameters) and wearable hardware licensing to promote adaptation of project outcomes to other applications.</AbstractNarration>
<MinAmdLetterDate>08/01/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1017826</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Cutkosky</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark R Cutkosky</PI_FULL_NAME>
<EmailAddress>cutkosky@stanford.edu</EmailAddress>
<PI_PHON>6507219433</PI_PHON>
<NSF_ID>000213143</NSF_ID>
<StartDate>08/01/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Thor</FirstName>
<LastName>Besier</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thor Besier</PI_FULL_NAME>
<EmailAddress>besier@stanford.edu</EmailAddress>
<PI_PHON>6507369855</PI_PHON>
<NSF_ID>000555218</NSF_ID>
<StartDate>08/01/2010</StartDate>
<EndDate>07/06/2011</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943052004</ZipCode>
<StreetAddress><![CDATA[450 Jane Stanford Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual merit: The project on <em>Wearable computation and feedback for real-time movement training </em>focused on gait training for knee arthritis as an application. The goal was to show that with gait retraining, patients could reduce knee pain and potentially slow the progression of their arthritis. The project involved three main components:</p> <ul> <li>Monitor subjects as they walk, and characterize their walking gait in terms of a kinematic gait model to compute the knee adduction moment (KAM) at their knees. The knee adduction moment (Figure 1) is a measure of joint loading that is known to be associated with arthritis.</li> <li>&nbsp;Use a kinematic model of a subject's gait to suggest subtle gait modifications (e.g. turning one foot slightly outward or inward) that are predicted to reduce the subject's peak knee adduction moment. These gait modifications are subject-specific, which is why each subject must be monitored and analyzed individually. The modifications are relatively easy to most subjects to learn.</li> <li>&nbsp;Use small, wearable haptic feedback devices that impart vibration and/or skin deformation to provide patients with tactile cues about how to modify their gait. These cues do not require looking at a computer screen or listening to headphones, etc. Instead, they provide, for example, a gentle buzz to the ankle when a person's foot is angled too far outward.</li> </ul> <p>&nbsp;For most of the project, it was necessary for subjects to come to a motion capture facility so that their motions could be measured using stick-on markers and a visual tracking system as they walked on a force-sensing treadmill (Figure 2). In the final year of the project, we developed a wearable motion-tracking system that could be used outside the laboratory. This wearable system used a combination of small inertial measurement units (IMUs), compass and accelerometer data, in addition to GPS data when a person walks outside. Combining this information with knowledge about when the feet are in contact with the ground, it is possible to obtain a measurement of the subject's foot progression angle (an important gait parameter) with an accuracy that, while not as good as that from the full motion tracking system, is nonetheless adequate to inform a subject about gait variations.</p> <p>&nbsp;Broader Impact: Tests were conducted with healthy subjects and with clinical arthritis patients. In both cases it was possible to identify gait adjustments that could reduce the peak knee adduction moment. Moreover, patients found it relatively easy to use the haptic feedback to adjust their gait. Learned gait adjustments were retained over a period of several weeks, during which subjects made periodic return visits to the laboratory to monitor their progress. Clinical arthritis patients reported reduced pain.</p> <p>&nbsp;The wearable motion tracking and feedback system also paves the way for other applications involving repetitive motions (e.g. for mobility or sports) and to provide feedback to reduce pain, improve performance, etc.</p> <p>&nbsp;The results of the project are disseminated in several publications and two Ph.D. theses, listed on project website: (<a title="Gait Retraining website" href="http://bdml.stanford.edu/Main/GaitRetraining" target="_blank">http://bdml.stanford.edu/Main/GaitRetraining</a>). A good nontechnical description of the project and its results for some arthritis patients can be found in the NSF Science Nation video at <a href="http://www.nsf.gov/news/special_reports/science_nation/walkingright.jsp">http://www.nsf.gov/news/special_reports/science_nation/walkingright.jsp</a></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/12/2015<br>      Modified by: Mark&nbsp;R&nbsp;Cutkosky</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">    ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual merit: The project on Wearable computation and feedback for real-time movement training focused on gait training for knee arthritis as an application. The goal was to show that with gait retraining, patients could reduce knee pain and potentially slow the progression of their arthritis. The project involved three main components:  Monitor subjects as they walk, and characterize their walking gait in terms of a kinematic gait model to compute the knee adduction moment (KAM) at their knees. The knee adduction moment (Figure 1) is a measure of joint loading that is known to be associated with arthritis.  Use a kinematic model of a subject's gait to suggest subtle gait modifications (e.g. turning one foot slightly outward or inward) that are predicted to reduce the subject's peak knee adduction moment. These gait modifications are subject-specific, which is why each subject must be monitored and analyzed individually. The modifications are relatively easy to most subjects to learn.  Use small, wearable haptic feedback devices that impart vibration and/or skin deformation to provide patients with tactile cues about how to modify their gait. These cues do not require looking at a computer screen or listening to headphones, etc. Instead, they provide, for example, a gentle buzz to the ankle when a person's foot is angled too far outward.    For most of the project, it was necessary for subjects to come to a motion capture facility so that their motions could be measured using stick-on markers and a visual tracking system as they walked on a force-sensing treadmill (Figure 2). In the final year of the project, we developed a wearable motion-tracking system that could be used outside the laboratory. This wearable system used a combination of small inertial measurement units (IMUs), compass and accelerometer data, in addition to GPS data when a person walks outside. Combining this information with knowledge about when the feet are in contact with the ground, it is possible to obtain a measurement of the subject's foot progression angle (an important gait parameter) with an accuracy that, while not as good as that from the full motion tracking system, is nonetheless adequate to inform a subject about gait variations.   Broader Impact: Tests were conducted with healthy subjects and with clinical arthritis patients. In both cases it was possible to identify gait adjustments that could reduce the peak knee adduction moment. Moreover, patients found it relatively easy to use the haptic feedback to adjust their gait. Learned gait adjustments were retained over a period of several weeks, during which subjects made periodic return visits to the laboratory to monitor their progress. Clinical arthritis patients reported reduced pain.   The wearable motion tracking and feedback system also paves the way for other applications involving repetitive motions (e.g. for mobility or sports) and to provide feedback to reduce pain, improve performance, etc.   The results of the project are disseminated in several publications and two Ph.D. theses, listed on project website: (http://bdml.stanford.edu/Main/GaitRetraining). A good nontechnical description of the project and its results for some arthritis patients can be found in the NSF Science Nation video at http://www.nsf.gov/news/special_reports/science_nation/walkingright.jsp             Last Modified: 08/12/2015       Submitted by: Mark R Cutkosky]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
