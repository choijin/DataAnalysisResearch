<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Investigating Diversity in Online Community Filtering</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>95822.00</AwardTotalIntnAmount>
<AwardAmount>95822</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A transition is occurring from a world in which gatekeepers and editors filter content before it is published to a world full of user-generated content in which information filtering is done after publication. Today's online communities have developed a variety of community-based filtering and rating mechanisms to help maintain quality and manageability. However, it is an open question  whether these filtering mechanisms represent "the wisdom of crowds" or "the censoring mob."&lt;br/&gt;&lt;br/&gt;This project will apply statistical machine learning and ethnographic studies to understand the mechanisms by which online communities censor content from the bottom up. This understanding will provide insight into how values are and can be embedded into these large, socially intelligent systems. Ultimately, the goal is to design socially intelligent community filtering systems in which individuals, communities, and intelligent software agents collaborate, to explain the mechanisms behind social, bottom-up filtering, and expand the range of the possible in terms of the values these systems can reflect and the communities it can serve. This project will study the mechanisms through which the social construction of gender impacts community filtering systems. This will be done via an in-depth study of two online communities that have vigorous community policed comment filtering; one whose participants are predominantly male and another whose participants are predominantly female.&lt;br/&gt;&lt;br/&gt;Online communities are rapidly becoming the modern public square and community filtering has the potential to make the space vibrant and useful and/or degenerate into a form of censorship. The health of our civil society and its ability to address large challenges depends on the health of its public discourse. By creating systems for socially intelligent filtering that reflect the community we facilitate diversity, in that minority positions are protected and preserved, while at the same time majority positions have the opportunity to develop and refine cogent arguments necessary for a well reasoned debate.</AbstractNarration>
<MinAmdLetterDate>08/07/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1048515</AwardID>
<Investigator>
<FirstName>Rachel</FirstName>
<LastName>Greenstadt</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rachel Greenstadt</PI_FULL_NAME>
<EmailAddress>greenstadt@nyu.edu</EmailAddress>
<PI_PHON>8188250302</PI_PHON>
<NSF_ID>000514368</NSF_ID>
<StartDate>08/07/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jennifer</FirstName>
<LastName>Rode</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jennifer A Rode</PI_FULL_NAME>
<EmailAddress>jennifer.a.rode@drexel.edu</EmailAddress>
<PI_PHON>2158955849</PI_PHON>
<NSF_ID>000560223</NSF_ID>
<StartDate>08/07/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Drexel University</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191021119</ZipCode>
<PhoneNumber>2158956342</PhoneNumber>
<StreetAddress>1505 Race St, 10th Floor</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002604817</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DREXEL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002604817</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Drexel University]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191021119</ZipCode>
<StreetAddress><![CDATA[1505 Race St, 10th Floor]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~95822</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>With the rise of the social web, community discussion has become an integral part of the Internet. Most communities use human-driven community filtering approaches to assess comment quality which is inefficient and time consuming. Many machine learning based approaches have been proposed to augment the community filtering system. However, all previous works are done on technical forums with specific commenting structure and specific type of demography. There is no research that shows how these approaches would work on a community with different demographics and different commenting structure.&nbsp;</span></p> <p><span>&nbsp;</span></p> <p><span>We analyzed comments and user activities of an online community, Jezebel.com, which has very different demographics and commenting practices from any other commenting systems previously studied. We demonstrate the underlying similarities in online communities by comparing our approach with the other approaches that were used to study commenting systems on sites such as slashdot and digg. The novelty of our work is that we show how features used to predict comment quality in one community can be translated into predicting comment quality in another community, despite differences in community structure, commenter demographics and commenting practice. We also extend the comment prediction model to predict commenter reputation as that was found to be a salient feature in comment quality assessment in several online communities.&nbsp;</span></p> <p><span>&nbsp;</span></p> <p><span>We augmented this work with ethnographical studies of slashdot and jezebel to gain insight into feature selection and obtain a qualitative picture of the community filtering dynamics.&nbsp;</span></p> <p><span>&nbsp;</span></p> <p><span>Our research resulted in new insights into these filtering mechanisms and new statistical methods to help manage community discussions on the Internet.</span></p> <div><span><br /></span></div> <p>&nbsp;</p><br> <p>            Last Modified: 10/22/2012<br>      Modified by: Rachel&nbsp;Greenstadt</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With the rise of the social web, community discussion has become an integral part of the Internet. Most communities use human-driven community filtering approaches to assess comment quality which is inefficient and time consuming. Many machine learning based approaches have been proposed to augment the community filtering system. However, all previous works are done on technical forums with specific commenting structure and specific type of demography. There is no research that shows how these approaches would work on a community with different demographics and different commenting structure.      We analyzed comments and user activities of an online community, Jezebel.com, which has very different demographics and commenting practices from any other commenting systems previously studied. We demonstrate the underlying similarities in online communities by comparing our approach with the other approaches that were used to study commenting systems on sites such as slashdot and digg. The novelty of our work is that we show how features used to predict comment quality in one community can be translated into predicting comment quality in another community, despite differences in community structure, commenter demographics and commenting practice. We also extend the comment prediction model to predict commenter reputation as that was found to be a salient feature in comment quality assessment in several online communities.      We augmented this work with ethnographical studies of slashdot and jezebel to gain insight into feature selection and obtain a qualitative picture of the community filtering dynamics.      Our research resulted in new insights into these filtering mechanisms and new statistical methods to help manage community discussions on the Internet.            Last Modified: 10/22/2012       Submitted by: Rachel Greenstadt]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
