<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Avoiding Achilles' Heel in Exascale Computing with Distributed File Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>734170</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sushil K Prasad</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Exascale (i.e. 1018 operations/sec) computers will enable the unraveling of significant scientific mysteries, covering many domains (e.g. weather modeling, national security, energy, and drug discovery). Predictions are that exascales will be reached in 2019, with millions of compute-nodes and billions of threads of execution. The current state-of-the-art storage in high-end computing (HEC), in which storage is segregated from compute-nodes and connected by a network (e.g. parallel filesystems), will not scale with the expected exponential growth in concurrency. At exascales, basic functionality (e.g. booting, check-pointing, metadata/data access) at high concurrency levels will suffer poor performance, and combined with system mean-time-to-failure in hours, will lead to a performance collapse. &lt;br/&gt;&lt;br/&gt;The investigator envisions future HEC systems to be designed with non-volatile memory on every compute node, and every node to actively participate in the metadata and data management. This work aims to: 1) design, analyze, and implement a distributed data structure (D3) optimized for HEC, to be used for distributed metadata management; 2) design, analyze, and implement a distributed filesystem (FDFS) optimized for a subset of important high-performance computing (HPC) as well as many-task computing (MTC) workloads, and scalable to millions of nodes; and 3) evaluate work with real workloads, applications, and simulations up to exascales. The results of this work has the potential to make exascale computing more tractable, touching virtually all disciplines in HEC, fueling scientific discovery and economic development at the national level. The HEC knowledgebase will extend into commodity systems as the fastest machines generally become mainstream systems in five to seven years. This work can also open doors for research in radical parallel programming paradigms (e.g. MTC) that rely on scalable storage infrastructure.</AbstractNarration>
<MinAmdLetterDate>01/24/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1054974</AwardID>
<Investigator>
<FirstName>Ioan</FirstName>
<LastName>Raicu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ioan Raicu</PI_FULL_NAME>
<EmailAddress>iraicu@iit.edu</EmailAddress>
<PI_PHON>8477220876</PI_PHON>
<NSF_ID>000568594</NSF_ID>
<StartDate>01/24/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Illinois Institute of Technology</Name>
<CityName>Chicago</CityName>
<ZipCode>606163717</ZipCode>
<PhoneNumber>3125673035</PhoneNumber>
<StreetAddress>10 West 35th Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 7D71]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042084434</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ILLINOIS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042084434</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Illinois Institute of Technology]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606163717</ZipCode>
<StreetAddress><![CDATA[10 West 35th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7361</Code>
<Text>EDUCATION AND WORKFORCE</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>019Z</Code>
<Text>Grad Prep APG:Enhan. Experience</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~370000</FUND_OBLG>
<FUND_OBLG>2012~16625</FUND_OBLG>
<FUND_OBLG>2013~20270</FUND_OBLG>
<FUND_OBLG>2014~45045</FUND_OBLG>
<FUND_OBLG>2015~138060</FUND_OBLG>
<FUND_OBLG>2016~88000</FUND_OBLG>
<FUND_OBLG>2017~56170</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Extreme-scale computers have and will in the foreseeable future enable the unraveling of significant scientific mysteries.<strong>&nbsp;</strong>There are many scientific domains that have been making revolutionary advancements due to large-scale computing.<strong></strong>The state-of-the-art storage in High-End Computing (HEC), in which storage (e.g. parallel file systems) is segregated from compute nodes and connected by a network, will not scale with the expected exponential growth in concurrency; storage has the potential to be the Achilles heel of future extreme-scale systems.&nbsp;</p> <p>Back in 2010, the PI proposed that future large-scale systems should be designed with non-volatile solid-state memory on every compute node. Every compute node could actively participate in the metadata and data management, leveraging many-core processors and high bisection bandwidth in multi-dimensional networks. Distributed metadata management could be used, implemented in a distributed data-structure, tailored for HEC, supporting constant time operations by emphasizing trustworthy/reliable hardware, fast network interconnects, non-existent node "churn", low latencies, and scientific computing data-access patterns. The data would be partitioned and spread out over many nodes based on the data access patterns. Replication would be used to ensure data availability, cooperative caching would deliver high aggregate throughput, and data would be tracked with provenance information. There would be a variety of data-access semantics, from POSIX-like interfaces for generality and backwards compatibility, to relaxed semantics for increased scalability. This work's contribution lies in the revolutionary new storage architecture making extreme-scale compute systems viable.&nbsp;</p> <p>This proposal can be summarized in four research and educational activities:</p> <p>1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><em>Designed, Analyzed, and Implemented a Zero-Hop Distributed Hash Table (ZHT),&nbsp;</em></strong>a light-weight distributed hash table that dynamically allows nodes to join and leave, is fault tolerant through replication, is persistent, scalable, and supports lock-free concurrent key/value modifications.</p> <p>2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><em>Designed, Analyzed, and Implemented the Fusion Distributed File System (FusionFS),&nbsp;</em></strong>leveraging research from cooperative caching,<em></em>to scale to millions of nodes and billions of concurrent I/O requests, to address poor scaling workloads from parallel file systems.</p> <p>3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><em>Evaluated work&nbsp;</em></strong><em>through both simulations and real systems: 1) explored proposed work on&nbsp;</em>real workloads and applications at thousands of node scales and tens of thousands of core scales; and 2) explored proposed work through simulations at extreme-scale levels with millions of nodes.</p> <p>4)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong><em>Integrate research with education&nbsp;</em></strong>spanning high-school, undergrads, and graduate students; the PI has designing three new advanced courses: 1) Introduction to&nbsp;Parallel and Distributed Computing; 2) Data-Intensive Distributed Computing; and 3) Cloud Computing.</p> <p>The proposed shift in large-scale storage architecture design was seen as controversial back in 2010 when it was originally proposed by the PI as it required storage architectures in HEC to be redefined from their traditional architectures of the past several decades. This new approach was not feasible prior to being proposed due to the unreliable spinning disk technology that had dominated the persistent storage space since the dawn of supercomputing. However, the advancements in solid-state memory (with mean-time-to-failure of over millions of hours) opened up opportunities to rethink storage systems for HEC, distributing storage on every compute node, without sacrificing node reliability or power consumption. The benefits of this new distributed storage architecture enabled some workloads to scale near-linearly with systems scales by leveraging data locality and the full network bisection bandwidth.&nbsp;</p> <p>This award aimed to address the storage bottleneck in future high-end computing at extreme scales. The&nbsp;<strong><em>intellectual merit&nbsp;</em></strong>of this work is the radical storage architecture departing from traditional parallel file systems.&nbsp;In exploring fundamental research in storage architectures suitable for large-scale computing, the PI touches a diverse set of topics ranging from distributed file systems, distributed key/value storage, distributed relational databases, distributed metadata management, burst buffers, data provenance, erasure coding, cooperative caching, and data compression.&nbsp;The research conducted has shown through both simulations and real systems that distributed file systems are a viable and good solution at extreme scales for a variety of workloads.&nbsp;</p> <p>This work's&nbsp;<strong><em>broader impact&nbsp;</em></strong>has made extreme-scale computing more tractable, touching virtually all disciplines in high-end computing, fueling scientific discovery. This work has also funded the development and teaching of new coursework in distributed systems where research was intertwined to deliver cutting edge education to over one thousand students over the course of this award. This award has funded multiple female students, as well as domestic students in funded portions of this research; two PhD students were fully supported by this award, and seven additional PhD students were partially supported by this award. Overall, over 50 students (from high-school, undergraduate, master, and PhD students) were engaged in research related activities of this award. These students together with the PI collectively wrote over 100 technical articles, including 4 PhD dissertations, 1 MS thesis, 26 peer reviewed full-paper publications in conferences and journals, 26 peer reviewed short-paper publications in workshops and conferences, and 44 technical reports. More information can be found at&nbsp;<a href="http://datasys.cs.iit.edu/grants/NSF-CAREER/index.html">http://datasys.cs.iit.edu/grants/NSF-CAREER/index.html</a>.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/25/2018<br>      Modified by: Ioan&nbsp;Raicu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495057486_SC14--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495057486_SC14--rgov-800width.jpg" title="IEEE TCSC Young Achievers in Scalable Computing Award"><img src="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495057486_SC14--rgov-66x44.jpg" alt="IEEE TCSC Young Achievers in Scalable Computing Award"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Ioan Raicu receiving the IEEE TCSC Award for Young Achiever in Scalable Computing.?At the IEEE/ACM SC 2014 conf. This award recognizes individuals who have made outstanding, influential, and long-lasting contributions in the field of scalable computing within 5 years of receiving their PhD degree.</div> <div class="imageCredit">Ioan Raicu</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ioan&nbsp;Raicu</div> <div class="imageTitle">IEEE TCSC Young Achievers in Scalable Computing Award</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540494591866_CCGrid14--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540494591866_CCGrid14--rgov-800width.jpg" title="Outstanding Service Award at IEEE/ACM CCGrid 2014"><img src="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540494591866_CCGrid14--rgov-66x44.jpg" alt="Outstanding Service Award at IEEE/ACM CCGrid 2014"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Ioan Raicu receiving the Outstanding Service Award at IEEE/ACM CCGrid 2014 conference in Chicago Illinois. The award was given to Kyle Chard and Ioan Raicu by the conference General Chairs, Ian Foster and Xian-He Sun.</div> <div class="imageCredit">Ioan Raicu</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ioan&nbsp;Raicu</div> <div class="imageTitle">Outstanding Service Award at IEEE/ACM CCGrid 2014</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540494160013_DataSys14--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540494160013_DataSys14--rgov-800width.jpg" title="DataSys Lab at IIT 2014"><img src="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540494160013_DataSys14--rgov-66x44.jpg" alt="DataSys Lab at IIT 2014"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Ioan Raicu with DataSys Lab students in May 2014; four PhD students (all graduated in 2015-2016) and 6 undergraduate students (participated in Student Cluster Challenge at IEEE/ACM Supercomputing/SC 2014 competition) supported by NSF CAREER award are present.</div> <div class="imageCredit">Ioan Raicu</div> <div class="imageSubmitted">Ioan&nbsp;Raicu</div> <div class="imageTitle">DataSys Lab at IIT 2014</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495158070_picnic15--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495158070_picnic15--rgov-800width.jpg" title="DataSys Summer Picnic 2015"><img src="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495158070_picnic15--rgov-66x44.jpg" alt="DataSys Summer Picnic 2015"></a> <div class="imageCaptionContainer"> <div class="imageCaption">DataSys Lab summer 2015 picnic social activity joined by REU BigDataX and MEDIX summer programs.</div> <div class="imageCredit">Ioan Raicu</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ioan&nbsp;Raicu</div> <div class="imageTitle">DataSys Summer Picnic 2015</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495309951_TEDxIIT16--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495309951_TEDxIIT16--rgov-800width.jpg" title="TEDxIIT 2016 - The Big Bang of Computing"><img src="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495309951_TEDxIIT16--rgov-66x44.jpg" alt="TEDxIIT 2016 - The Big Bang of Computing"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Ioan Raicu delivering a TED talk at TEDxIIT on the explosive growth of the computing discipline in recent years, and painting a bright future for the new generation of potential computer scientists.</div> <div class="imageCredit">Ioan Raicu</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ioan&nbsp;Raicu</div> <div class="imageTitle">TEDxIIT 2016 - The Big Bang of Computing</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495455276_SCC@SC17--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495455276_SCC@SC17--rgov-800width.jpg" title="Chicago Fusion IIT Team at SCC@SC17"><img src="/por/images/Reports/POR/2018/1054974/1054974_10070039_1540495455276_SCC@SC17--rgov-66x44.jpg" alt="Chicago Fusion IIT Team at SCC@SC17"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Ioan Raicu with Chicago Fusion IIT Team sponsored in part by NSF CAREER award at IEEE/ACM Supercomputing/SC 2017 conference.</div> <div class="imageCredit">Ioan Raicu</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ioan&nbsp;Raicu</div> <div class="imageTitle">Chicago Fusion IIT Team at SCC@SC17</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Extreme-scale computers have and will in the foreseeable future enable the unraveling of significant scientific mysteries. There are many scientific domains that have been making revolutionary advancements due to large-scale computing.The state-of-the-art storage in High-End Computing (HEC), in which storage (e.g. parallel file systems) is segregated from compute nodes and connected by a network, will not scale with the expected exponential growth in concurrency; storage has the potential to be the Achilles heel of future extreme-scale systems.   Back in 2010, the PI proposed that future large-scale systems should be designed with non-volatile solid-state memory on every compute node. Every compute node could actively participate in the metadata and data management, leveraging many-core processors and high bisection bandwidth in multi-dimensional networks. Distributed metadata management could be used, implemented in a distributed data-structure, tailored for HEC, supporting constant time operations by emphasizing trustworthy/reliable hardware, fast network interconnects, non-existent node "churn", low latencies, and scientific computing data-access patterns. The data would be partitioned and spread out over many nodes based on the data access patterns. Replication would be used to ensure data availability, cooperative caching would deliver high aggregate throughput, and data would be tracked with provenance information. There would be a variety of data-access semantics, from POSIX-like interfaces for generality and backwards compatibility, to relaxed semantics for increased scalability. This work's contribution lies in the revolutionary new storage architecture making extreme-scale compute systems viable.   This proposal can be summarized in four research and educational activities:  1)     Designed, Analyzed, and Implemented a Zero-Hop Distributed Hash Table (ZHT), a light-weight distributed hash table that dynamically allows nodes to join and leave, is fault tolerant through replication, is persistent, scalable, and supports lock-free concurrent key/value modifications.  2)     Designed, Analyzed, and Implemented the Fusion Distributed File System (FusionFS), leveraging research from cooperative caching,to scale to millions of nodes and billions of concurrent I/O requests, to address poor scaling workloads from parallel file systems.  3)     Evaluated work through both simulations and real systems: 1) explored proposed work on real workloads and applications at thousands of node scales and tens of thousands of core scales; and 2) explored proposed work through simulations at extreme-scale levels with millions of nodes.  4)     Integrate research with education spanning high-school, undergrads, and graduate students; the PI has designing three new advanced courses: 1) Introduction to Parallel and Distributed Computing; 2) Data-Intensive Distributed Computing; and 3) Cloud Computing.  The proposed shift in large-scale storage architecture design was seen as controversial back in 2010 when it was originally proposed by the PI as it required storage architectures in HEC to be redefined from their traditional architectures of the past several decades. This new approach was not feasible prior to being proposed due to the unreliable spinning disk technology that had dominated the persistent storage space since the dawn of supercomputing. However, the advancements in solid-state memory (with mean-time-to-failure of over millions of hours) opened up opportunities to rethink storage systems for HEC, distributing storage on every compute node, without sacrificing node reliability or power consumption. The benefits of this new distributed storage architecture enabled some workloads to scale near-linearly with systems scales by leveraging data locality and the full network bisection bandwidth.   This award aimed to address the storage bottleneck in future high-end computing at extreme scales. The intellectual merit of this work is the radical storage architecture departing from traditional parallel file systems. In exploring fundamental research in storage architectures suitable for large-scale computing, the PI touches a diverse set of topics ranging from distributed file systems, distributed key/value storage, distributed relational databases, distributed metadata management, burst buffers, data provenance, erasure coding, cooperative caching, and data compression. The research conducted has shown through both simulations and real systems that distributed file systems are a viable and good solution at extreme scales for a variety of workloads.   This work's broader impact has made extreme-scale computing more tractable, touching virtually all disciplines in high-end computing, fueling scientific discovery. This work has also funded the development and teaching of new coursework in distributed systems where research was intertwined to deliver cutting edge education to over one thousand students over the course of this award. This award has funded multiple female students, as well as domestic students in funded portions of this research; two PhD students were fully supported by this award, and seven additional PhD students were partially supported by this award. Overall, over 50 students (from high-school, undergraduate, master, and PhD students) were engaged in research related activities of this award. These students together with the PI collectively wrote over 100 technical articles, including 4 PhD dissertations, 1 MS thesis, 26 peer reviewed full-paper publications in conferences and journals, 26 peer reviewed short-paper publications in workshops and conferences, and 44 technical reports. More information can be found at http://datasys.cs.iit.edu/grants/NSF-CAREER/index.html.          Last Modified: 10/25/2018       Submitted by: Ioan Raicu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
