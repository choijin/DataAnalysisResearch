<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Medium: Control of a Robotic Manipulator via a Brain-Computer Interface</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/06/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>607230.00</AwardTotalIntnAmount>
<AwardAmount>655425</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A brain-computer interface (BCI) is a system that allows users, especially individuals with severe neuromuscular disorders, to communicate and control devices using their brain waves.  There are over two million people in the United States afflicted by such disorders, many of whom could greatly benefit from assistive devices controlled by a BCI.  Over the past two years, it has been demonstrated that a non-invasive, scalp-recorded electroencephalography (EEG) based BCI paradigm can be used by a disabled individual for long-term, reliable control of a personal computer.  This BCI paradigm allows users to select from a set of symbols presented in a flashing visual matrix by classifying the resulting evoked brain responses.   One of the goals of this project is to establish that the same BCI paradigm and techniques used for the aforementioned demonstration can be straightforwardly implemented to generate high-level commands for controlling a robotic manipulator in three dimensions according to user intent, and that such a BCI can provide superior dimensional control over alternative BCI techniques currently available, as well as a wider variety of practical functions for performing everyday tasks.&lt;br/&gt;&lt;br/&gt;Electrocorticography (ECoG), electrical activity recorded directly from the surface of the brain, has been demonstrated in recent preliminary work to be another potentially viable control for a BCI.  ECoG has been shown to have superior signal-to-noise ratio, and spatial and spectral characteristics, compared to EEG.  But the EEG signals used at present to operate BCIs have not been characterized in ECoG.  The PI believes ECoG signals can be used to improve the speed and accuracy of BCI applications, including for example control of a robotic manipulator.  Thus, additional goals of this project are to characterize evoked responses obtained from ECoG, to use them as control signals to operate a simulated robotic manipulator, and to assess the level of control (speed and accuracy) between the two recording modalities and compare the results to competitive BCI techniques.  Because this is a collaborative effort with the Departments of Neurology and Neurosurgery at the Mayo Clinic in Jacksonville, the PI team will have access to a pool of ECoG grid patients from which to recruit participants for this study.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  This research will make a number of contributions in the emerging field of BCI and thus will serve as a step toward providing severely disabled individuals with a new level of autonomy for communicating with others and for performing everyday tasks, which will ultimately dramatically improve their quality of life.</AbstractNarration>
<MinAmdLetterDate>10/14/2010</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1064912</AwardID>
<Investigator>
<FirstName>Dean</FirstName>
<LastName>Krusienski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dean Krusienski</PI_FULL_NAME>
<EmailAddress>djkrusienski@vcu.edu</EmailAddress>
<PI_PHON>8048271890</PI_PHON>
<NSF_ID>000500739</NSF_ID>
<StartDate>10/14/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Old Dominion University Research Foundation</Name>
<CityName>Norfolk</CityName>
<ZipCode>235082561</ZipCode>
<PhoneNumber>7576834293</PhoneNumber>
<StreetAddress>4111 Monarch Way</StreetAddress>
<StreetAddress2><![CDATA[Suite 204]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>077945947</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OLD DOMINION UNIVERSITY RESEARCH FOUNDATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Old Dominion University]]></Name>
<CityName>Norfolk</CityName>
<StateCode>VA</StateCode>
<ZipCode>235290001</ZipCode>
<StreetAddress><![CDATA[5115 Hampton Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~607230</FUND_OBLG>
<FUND_OBLG>2013~48195</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major research thrusts of this project are (1) the identification and characterization of invasive and noninvasive electrophysiological brain activity for use in brain-computer interfaces (BCIs), (2) the development and evaluation of new BCI paradigms and control schemes, and (3) the application of 1 &amp; 2 in practical communication and environmental control contexts.&nbsp;</p> <p>Intellectual Merit:</p> <p>A visual BCI selection interface for robotic control using the noninvasive scalp electroencephalogram (EEG) was developed and demonstrated to achieve high-level goal-oriented control over a robotic manipulator for placing arbitrary objects in a workspace.&nbsp; The project also established that a similar visual BCI selection interface can be accurately controlled using invasive intracranial electrodes including cortical surface, hippocampal depth, and intraventricular locations in humans.&nbsp; Novel mathematical models were developed to relate these noninvasive recordings to the higher-fidelity invasive recordings during BCI use in order improve the understanding of the signal localization and propagation for improving the performance of noninvasive BCIs.&nbsp;</p> <p>Research was also conducted to characterize the neural correlates of noninvasive BCI performance in patients with amyotrophic lateral sclerosis (ALS).&nbsp; Consistent differences in conventional EEG-band power and peak amplitude latencies were found between successful and unsuccessful BCI sessions.&nbsp; These insights can lead to methods that help identify suitable candidates for long-term P300 BCI operation, or inform users about their BCI readiness on a given day. Such information may save significant time, effort, and frustration for users and caregivers; and may thereby improve BCI performance and increase satisfaction.</p> <p>Alternate BCI paradigms and a software-platform based on visual-evoked potentials were created that offer improved performance and usability.&nbsp; Such advances include the development and evaluation of a novel visual interface that reduces the number of potentially irritating visual stimuli for a given interface and further improves usability by not requiring direct gaze of these visual stimuli.&nbsp; Based on these developments, a turn-key visual BCI system was created that is user-configurable; requires no user or system training; minimal, unobtrusive electrodes and visual interface; and achieves near real-time control with high accuracy and reliability.&nbsp; This system was evaluated and demonstrated using a large number of na&iuml;ve BCI users for real-time control of a video game, robotic arm, and motorized wheelchair.</p> <p>This work was also extended to explore other emerging brain-signal decoding domains that have potential for BCI control and other diagnostic or therapeutic applications.&nbsp; Using intracranial brain activity, novel analysis produced the first detailed spatio-temporal evolution of neuronal population-level activity related to continuous overt speech, and identified those locations that shared activity characteristics across overt and covert speech.&nbsp; Similar intracranial recordings were used to decode elements of speech production including classification of phonemes.&nbsp; Specific spatiotemporal features were identified that aid such classification, which can guide future applications toward the development of speech neuroprosthetics.</p> <p>Another direction examined whether EEG auditory steady-state response (ASSR) deficits shown in humans with schizophrenia are also present in a mutant mouse model of schizophrenia, whose behavioral changes have shown schizophrenia-like endophenotypes.&nbsp; The ASSR is suggested as a quantitative biomarker for cross-species comparisons. From the results, signal analysis of ASSR power, phase-locking, and cortico-cortical connectivity were found to be reduced for respective frequency bands in...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major research thrusts of this project are (1) the identification and characterization of invasive and noninvasive electrophysiological brain activity for use in brain-computer interfaces (BCIs), (2) the development and evaluation of new BCI paradigms and control schemes, and (3) the application of 1 &amp; 2 in practical communication and environmental control contexts.   Intellectual Merit:  A visual BCI selection interface for robotic control using the noninvasive scalp electroencephalogram (EEG) was developed and demonstrated to achieve high-level goal-oriented control over a robotic manipulator for placing arbitrary objects in a workspace.  The project also established that a similar visual BCI selection interface can be accurately controlled using invasive intracranial electrodes including cortical surface, hippocampal depth, and intraventricular locations in humans.  Novel mathematical models were developed to relate these noninvasive recordings to the higher-fidelity invasive recordings during BCI use in order improve the understanding of the signal localization and propagation for improving the performance of noninvasive BCIs.   Research was also conducted to characterize the neural correlates of noninvasive BCI performance in patients with amyotrophic lateral sclerosis (ALS).  Consistent differences in conventional EEG-band power and peak amplitude latencies were found between successful and unsuccessful BCI sessions.  These insights can lead to methods that help identify suitable candidates for long-term P300 BCI operation, or inform users about their BCI readiness on a given day. Such information may save significant time, effort, and frustration for users and caregivers; and may thereby improve BCI performance and increase satisfaction.  Alternate BCI paradigms and a software-platform based on visual-evoked potentials were created that offer improved performance and usability.  Such advances include the development and evaluation of a novel visual interface that reduces the number of potentially irritating visual stimuli for a given interface and further improves usability by not requiring direct gaze of these visual stimuli.  Based on these developments, a turn-key visual BCI system was created that is user-configurable; requires no user or system training; minimal, unobtrusive electrodes and visual interface; and achieves near real-time control with high accuracy and reliability.  This system was evaluated and demonstrated using a large number of na&iuml;ve BCI users for real-time control of a video game, robotic arm, and motorized wheelchair.  This work was also extended to explore other emerging brain-signal decoding domains that have potential for BCI control and other diagnostic or therapeutic applications.  Using intracranial brain activity, novel analysis produced the first detailed spatio-temporal evolution of neuronal population-level activity related to continuous overt speech, and identified those locations that shared activity characteristics across overt and covert speech.  Similar intracranial recordings were used to decode elements of speech production including classification of phonemes.  Specific spatiotemporal features were identified that aid such classification, which can guide future applications toward the development of speech neuroprosthetics.  Another direction examined whether EEG auditory steady-state response (ASSR) deficits shown in humans with schizophrenia are also present in a mutant mouse model of schizophrenia, whose behavioral changes have shown schizophrenia-like endophenotypes.  The ASSR is suggested as a quantitative biomarker for cross-species comparisons. From the results, signal analysis of ASSR power, phase-locking, and cortico-cortical connectivity were found to be reduced for respective frequency bands in mutants compared to the control group.  These such characterization of these deficits can provide valuable insights about the pathogenesis of schizophrenia and re...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
