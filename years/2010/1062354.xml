<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>COLLABORATIVE RESEARCH: ABI Innovation: Computational and Informatics Tools for Supporting Collaborative Wildlife Monitoring and Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2011</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>842455.00</AwardTotalIntnAmount>
<AwardAmount>842455</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08080000</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DBI</Abbreviation>
<LongName>Div Of Biological Infrastructure</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anne Maglia</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The University of Missouri and the University of Illinois at Urbana-Champaign are awarded collaborative grants to develop advanced computational and informatics tools that will support wildlife data collection, analysis, and management at large scales.  Project objectives include investigation of 1) advanced computer vision methods for detecting and tracking animals in dynamic and cluttered environments; 2) adaptive classification, machine learning, and information fusion methods for recognizing animal species and individual ID; and 3) data summarization and database management schemes to support collaborative wildlife research.  The performance of these computational and informatics tools will be evaluated using existing camera trap datasets and field studies in terms of their potential to support collaborative wildlife research.  &lt;br/&gt;&lt;br/&gt;This project will broadly advance the state-of-the-art in computer vision, wildlife monitoring, ecology, and conservation research.  It will provide new methods and tools for automated processing and mining of massive wildlife monitoring data at large scales.  This will allow individual or coordinated networks of wildlife researchers to analyze and manage camera-trap data with minimum effort and compare and share data between research groups across different geographical regions.  Collaborative wildlife monitoring and tracking at large geographical and time scales will help us understand the complex dynamics of wildlife systems, evaluate the impact of human actions and environmental changes on wildlife species, and answer many important wildlife, ecological, and conservation research questions.  The database will be hosted by Smithsonian.  This will provide exciting interdisciplinary opportunities for mentoring graduate students and involving K-12 and undergraduate students into professionally guided research.  Software and results of this project will be available from the website http://videonet.ece.missouri.edu.</AbstractNarration>
<MinAmdLetterDate>05/06/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/05/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1062354</AwardID>
<Investigator>
<FirstName>Joshua</FirstName>
<LastName>Millspaugh</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joshua J Millspaugh</PI_FULL_NAME>
<EmailAddress>millspaughj@missouri.edu</EmailAddress>
<PI_PHON>5738829423</PI_PHON>
<NSF_ID>000138919</NSF_ID>
<StartDate>05/06/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zhihai</FirstName>
<LastName>He</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhihai He</PI_FULL_NAME>
<EmailAddress>hezhi@missouri.edu</EmailAddress>
<PI_PHON>5738823495</PI_PHON>
<NSF_ID>000388185</NSF_ID>
<StartDate>05/06/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tony</FirstName>
<LastName>Han</LastName>
<PI_MID_INIT>X</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tony X Han</PI_FULL_NAME>
<EmailAddress>hantx@missouri.edu</EmailAddress>
<PI_PHON>5738826630</PI_PHON>
<NSF_ID>000081430</NSF_ID>
<StartDate>05/06/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Missouri-Columbia</Name>
<CityName>COLUMBIA</CityName>
<ZipCode>652110001</ZipCode>
<PhoneNumber>5738827560</PhoneNumber>
<StreetAddress>115 Business Loop 70 W</StreetAddress>
<StreetAddress2><![CDATA[Mizzou North, Room 501]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153890272</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Missouri-Columbia]]></Name>
<CityName>COLUMBIA</CityName>
<StateCode>MO</StateCode>
<ZipCode>652110001</ZipCode>
<StreetAddress><![CDATA[115 Business Loop 70 W]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1165</Code>
<Text>ADVANCES IN BIO INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>1165</Code>
<Text>ADVANCES IN BIO INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~282208</FUND_OBLG>
<FUND_OBLG>2012~275757</FUND_OBLG>
<FUND_OBLG>2013~284490</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Wildlife monitoring at large geographical and time scales, based upon the collaborative efforts of large groups of citizen scientists, will provided the core data for countless scientific advances and conservation decisions, help us understand the dynamic behaviors of wildlife systems at large scales, and enable us to answer many important questions in wildlife, ecological and environmental research</p> <p>Engineering and wildlife ecology researchers from University of Missouri, UIUC, and North Carolina Natural Sciences Museum have developed an eMammal cyber-infrastructure with a suite of visual informatics tools for automated content analysis and management to support large-scale wildlife monitoring by citizen scientists. We have developed machine learning and computer vision methods and software tools for segmenting animals from the highly cluttered background in camera-trap images, track animals, recognizing animal species, and extracting biometric features of animals. We have achieved the state-of-the-art performance in animal object segmentation. We have achieved an average of 90% animal species recognition performance on camera-trap images for top 5 recommendations. The image analysis and computer vision algorithms developed in this project have been extensively tested, integrated into professionally designed software, and distributed to public.&nbsp; We have established the eMammal infrastructure for camera-trap data collection, uploading, archiving, processing, and management. This project has advanced the state-of-the-art in computer vision research, especially on object segmentation and classification in unstructured and cluttered natural environments. This new eMammal cyber-infrastructure has the potential to transform the practice of wildlife monitoring and will enable a host of new opportunities in conservation, ecological, and environmental research.</p> <p>We have recruited over 500 volunteers to monitor wildlife with camera traps run at &gt;2300 locations in 32 parks across 6 states. This represents &gt;130 camera-years of survey efforts and has recorded 2.6 million wildlife photos.</p> <p>This project involves citizen scientists to collect and annotate camera-trap data. It provides a unique education opportunity for the public on advanced image analysis research and its applications. Our graduate students, our technicians and post docs are developing and refining their skills through experiences in software development, field evaluations, and statistical data analysis. The camera-trap images captured by camera traps are often beautiful, dramatic, and captivating.&nbsp; These help to connect people with nature.&nbsp; The website we developed to share camera trap pictures with the public (Smithsonian Wild) has had over 600,000 visits in the past two years. Another measure of interest is the return rate of visitors, which at 36% for the website, is the highest measure of visitor loyalty for any website at Natural History Museum, and likely any across the Smithsonian.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/13/2015<br>      Modified by: Zhihai&nbsp;He</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2015/1062354/1062354_10089999_1439485945192_eMammal-snapshot--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1062354/1062354_10089999_1439485945192_eMammal-snapshot--rgov-800width.jpg" title="emammal snapshot"><img src="/por/images/Reports/POR/2015...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Wildlife monitoring at large geographical and time scales, based upon the collaborative efforts of large groups of citizen scientists, will provided the core data for countless scientific advances and conservation decisions, help us understand the dynamic behaviors of wildlife systems at large scales, and enable us to answer many important questions in wildlife, ecological and environmental research  Engineering and wildlife ecology researchers from University of Missouri, UIUC, and North Carolina Natural Sciences Museum have developed an eMammal cyber-infrastructure with a suite of visual informatics tools for automated content analysis and management to support large-scale wildlife monitoring by citizen scientists. We have developed machine learning and computer vision methods and software tools for segmenting animals from the highly cluttered background in camera-trap images, track animals, recognizing animal species, and extracting biometric features of animals. We have achieved the state-of-the-art performance in animal object segmentation. We have achieved an average of 90% animal species recognition performance on camera-trap images for top 5 recommendations. The image analysis and computer vision algorithms developed in this project have been extensively tested, integrated into professionally designed software, and distributed to public.  We have established the eMammal infrastructure for camera-trap data collection, uploading, archiving, processing, and management. This project has advanced the state-of-the-art in computer vision research, especially on object segmentation and classification in unstructured and cluttered natural environments. This new eMammal cyber-infrastructure has the potential to transform the practice of wildlife monitoring and will enable a host of new opportunities in conservation, ecological, and environmental research.  We have recruited over 500 volunteers to monitor wildlife with camera traps run at &gt;2300 locations in 32 parks across 6 states. This represents &gt;130 camera-years of survey efforts and has recorded 2.6 million wildlife photos.  This project involves citizen scientists to collect and annotate camera-trap data. It provides a unique education opportunity for the public on advanced image analysis research and its applications. Our graduate students, our technicians and post docs are developing and refining their skills through experiences in software development, field evaluations, and statistical data analysis. The camera-trap images captured by camera traps are often beautiful, dramatic, and captivating.  These help to connect people with nature.  The website we developed to share camera trap pictures with the public (Smithsonian Wild) has had over 600,000 visits in the past two years. Another measure of interest is the return rate of visitors, which at 36% for the website, is the highest measure of visitor loyalty for any website at Natural History Museum, and likely any across the Smithsonian.          Last Modified: 08/13/2015       Submitted by: Zhihai He]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
