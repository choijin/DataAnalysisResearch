<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Large: Collaborative Research:  Beyond Flat Images:  Acquiring, Processing and Fabricating Visually Rich Material Appearance</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>499381.00</AwardTotalIntnAmount>
<AwardAmount>499381</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Despite revolutionary advances in how images are recorded, manipulated, and reproduced, our ability to re-create the visual experience remains remarkably limited.  Few realistic computer models exist for the characteristic appearance of natural materials such as marble, wood, coral, or skin, or man-made ones such as color-shifting automotive paints.  Digitizing and creating realistic images of these substances involves reproducing their interaction with light:  the way light is reflected from surfaces, or scattered and absorbed within the materials.  Full reproducibility also involves "printing" a material as a real, physical object that modulates the light around us. However, it is currently impossible to output complex appearance the way we print color on a paper with fixed gloss, or create shapes using a 3D printer. This project encompasses a comprehensive, collaborative research agenda in computer graphics and related areas, to develop an end-to-end framework for acquiring, representing, and fabricating complex appearance, as well as to understand how it is perceived by the human visual system.&lt;br/&gt;&lt;br/&gt;The enabling technical idea of the project is to treat materials as thin three-dimensional volumes populated with general scattering sites. This is a radical departure from the hitherto standard approach in computer graphics, which has studied materials purely as surfaces.  The volumetric representation subsumes and generalizes the diverse set of conventional representations that currently exist in graphics, including surface-based notions such as bidirectional reflectance (BRDF), spatially varying BRDF, and subsurface scattering distributions (BSSRDF).  Moreover, it enables fundamentally improved approaches to efficient yet general acquisition, fast and realistic rendering, and fabrication of objects exhibiting phenomena beyond simple surface reflectance and spatially homogeneous subsurface scattering.</AbstractNarration>
<MinAmdLetterDate>08/20/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1012454</AwardID>
<Investigator>
<FirstName>Todd</FirstName>
<LastName>Zickler</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Todd Zickler</PI_FULL_NAME>
<EmailAddress>zickler@eecs.harvard.edu</EmailAddress>
<PI_PHON>6174954390</PI_PHON>
<NSF_ID>000118883</NSF_ID>
<StartDate>08/20/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021385369</ZipCode>
<StreetAddress><![CDATA[1033 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~377482</FUND_OBLG>
<FUND_OBLG>2013~121899</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-a1d7d814-2b46-385c-449f-ec026206edc1">&nbsp;</span></p> <p dir="ltr"><strong>Acquisition</strong></p> <p dir="ltr"><span>Measuring the optical properties of materials involves sending photons toward an object and using cameras to record where they arrive after interacting with the object. Photons take different paths, each undergoing a different combination of scattering, reflection, and refraction inside the object or at its surface. What makes measurement challenging is that each of a camera&rsquo;s pixels records a sum of many such photons: to recover the material properties, one must &ldquo;undo&rdquo; these per-pixel sums, determining which paths were travelled by the measured photons, and what events occurred along the paths.</span></p> <p dir="ltr"><span>In this project, in collaboration with colleagues at the Weizmann Institute of Science and at MIT, we established a foundation for solving these kinds of measurement problems, leading to papers in SIGGRAPH Asia 2013 and SIGGRAPH 2015. The first paper developed mathematical and computational tools for searching the space of possible material properties for those that match any acquired set of photographs. The second introduced an acquisition system that exploits the wave nature of light to produce a richer set of images than conventional photographs: images that not only record where photons arrive but also the precise length of the paths that they travel between source and camera. Together, our theory and acquisition system create opportunities for measuring optical material properties with unprecedented generality, precision, and accuracy.</span></p> <p dir="ltr"><span><br /></span></p> <p dir="ltr"><strong>Rendering</strong></p> <p dir="ltr"><span>The complex knit or woven structure of cloth creates appearances from smooth and shiny to rough and matte to thick and velvety. &nbsp;In this project we developed micro-appearance models, a new approach to fabric rendering that handles this full range of complexity by explicitly modeling the structure of the material. Using a micro CT scanner to capture micron-scale fiber structure, then simulating the interaction of light with this structure, we produced arguably the most realistic rendered fabrics to date. Through a series of four SIGGRAPH papers, our research first made richly detailed models of simple fabrics, then modeled complex fabrics directly from their weave patterns, and finally explored how to accelerate the rendering process and how to match the results to measurements of real fabrics.</span></p> <p dir="ltr"><span>Another appearance phenomenon in which small structures play a crucial role is that of glints and glitter: surfaces ranging from freshly fallen snow to car paints to sandblasted metal that display complex highlights that change with view and illumination. &nbsp;A collaborative team tackled this topic from two angles, producing a pair of methods reported in two SIGGRAPH papers. &nbsp;One provides an efficient procedural model for random surface structure; the other treats details generally and accurately using a high-resolution detail map. &nbsp;Both method efficiently produce renderings of glinty surfaces, even when illuminated by sharp lighting such as sunlight, which was formerly completely impractical.</span></p> <p dir="ltr"><span><br /></span></p> <p dir="ltr"><strong>Perception</strong></p> <p dir="ltr"><span>Our ability to effectively design, edit, and render translucent materials like milk, soap, and wax depends on our understanding of how humans perceive translucency. While it is clear that human observers care greatly about translucent appearance in many cases -- as when they distinguish milk from cream, or marble from Formica -- even basic questions about how this occurs remain unanswered.</span></p> <p dir="ltr"><span>During the award period we collaborated with colleagues at MIT to perform some of ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Acquisition Measuring the optical properties of materials involves sending photons toward an object and using cameras to record where they arrive after interacting with the object. Photons take different paths, each undergoing a different combination of scattering, reflection, and refraction inside the object or at its surface. What makes measurement challenging is that each of a cameraÃ†s pixels records a sum of many such photons: to recover the material properties, one must "undo" these per-pixel sums, determining which paths were travelled by the measured photons, and what events occurred along the paths. In this project, in collaboration with colleagues at the Weizmann Institute of Science and at MIT, we established a foundation for solving these kinds of measurement problems, leading to papers in SIGGRAPH Asia 2013 and SIGGRAPH 2015. The first paper developed mathematical and computational tools for searching the space of possible material properties for those that match any acquired set of photographs. The second introduced an acquisition system that exploits the wave nature of light to produce a richer set of images than conventional photographs: images that not only record where photons arrive but also the precise length of the paths that they travel between source and camera. Together, our theory and acquisition system create opportunities for measuring optical material properties with unprecedented generality, precision, and accuracy.   Rendering The complex knit or woven structure of cloth creates appearances from smooth and shiny to rough and matte to thick and velvety.  In this project we developed micro-appearance models, a new approach to fabric rendering that handles this full range of complexity by explicitly modeling the structure of the material. Using a micro CT scanner to capture micron-scale fiber structure, then simulating the interaction of light with this structure, we produced arguably the most realistic rendered fabrics to date. Through a series of four SIGGRAPH papers, our research first made richly detailed models of simple fabrics, then modeled complex fabrics directly from their weave patterns, and finally explored how to accelerate the rendering process and how to match the results to measurements of real fabrics. Another appearance phenomenon in which small structures play a crucial role is that of glints and glitter: surfaces ranging from freshly fallen snow to car paints to sandblasted metal that display complex highlights that change with view and illumination.  A collaborative team tackled this topic from two angles, producing a pair of methods reported in two SIGGRAPH papers.  One provides an efficient procedural model for random surface structure; the other treats details generally and accurately using a high-resolution detail map.  Both method efficiently produce renderings of glinty surfaces, even when illuminated by sharp lighting such as sunlight, which was formerly completely impractical.   Perception Our ability to effectively design, edit, and render translucent materials like milk, soap, and wax depends on our understanding of how humans perceive translucency. While it is clear that human observers care greatly about translucent appearance in many cases -- as when they distinguish milk from cream, or marble from Formica -- even basic questions about how this occurs remain unanswered. During the award period we collaborated with colleagues at MIT to perform some of the first qualitative and quantitative analyses of the perception of translucent materials. Using a unique combination of large-scale simulations, psychophysical experiments with human subjects, and data-mining, we studied the perception of objects that are composed of spatially-homogeneous material. We were able to unveil qualitative and quantitative models of how an objectÃ†s appearance is related to the physical properties of the material, and how both of these are related to perception. These results were published ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
