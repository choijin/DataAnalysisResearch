<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RUI: CRI: CI-ADDO-EN: Collaborative Research: MASC: A Community Resource For and By the People</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2011</AwardEffectiveDate>
<AwardExpirationDate>12/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>86183.00</AwardTotalIntnAmount>
<AwardAmount>86183</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Manually Annotated Sub-Corpus (MASC) is a shared corpus that supports research across&lt;br/&gt;several disciplines: linguistics, computational linguistics, psycholinguistics, sociolinguistics and&lt;br/&gt;machine learning. It includes a wide variety of present-day American English texts annotated for&lt;br/&gt;several linguistic phenomena. Because MASC provides a unique resource, considerable&lt;br/&gt;community momentum has grown up around it. This project builds upon this momentum to&lt;br/&gt;enable the corpus to grow on its own, and to address the need for additional annotations. The&lt;br/&gt;major activities are to : (1) provide web-based mechanisms to facilitate community contribution&lt;br/&gt;and use of MASC annotations; (2) develop means to more fully automate the annotation&lt;br/&gt;validation process; (3) extend the WordNet annotations to cover adjectives, to support research&lt;br/&gt;on evaluation of ?subjective? annotations and harmonization of WordNet with other resources;&lt;br/&gt;(3) promote use of MASC and new annotations by diverse groups, by sponsoring shared tasks&lt;br/&gt;that exploit the corpus? unique characteristics and supporting beta-testers of software, data, and&lt;br/&gt;annotations; and (4) aggressively develop an ?Open Language Data? community around MASC&lt;br/&gt;through workshops, tutorials, and active participation in relevant community activities.&lt;br/&gt;&lt;br/&gt;MASC provides an unparalleled resource for training and testing of tools for natural language&lt;br/&gt;processing, which can enable a major leap in the productivity of NLP research and ultimately&lt;br/&gt;impact the way people use and interact with computers. It is the first fully open, communitydriven&lt;br/&gt;resource in the field. All data and annotations are freely distributed in a manner that&lt;br/&gt;permits immediate and easy accessibility for users around the globe.</AbstractNarration>
<MinAmdLetterDate>02/14/2011</MinAmdLetterDate>
<MaxAmdLetterDate>05/14/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1059246</AwardID>
<Investigator>
<FirstName>Rebecca</FirstName>
<LastName>Passonneau</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rebecca J Passonneau</PI_FULL_NAME>
<EmailAddress>rjp49@psu.edu</EmailAddress>
<PI_PHON>8148659233</PI_PHON>
<NSF_ID>000306640</NSF_ID>
<StartDate>02/14/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName>NEW YORK</CityName>
<StateCode>NY</StateCode>
<ZipCode>100276902</ZipCode>
<StreetAddress><![CDATA[2960 Broadway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~86183</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Corpora, or collections of texts organized around one or more commonalities, are an important resource for studies of language use across disciplines, including natural language processing, information retrieval, cognitive science, information science, and machine learning. Annotations enhance the observed language with unobserved information that is apparent to people in their use of language. Thus annotaton facilitates the study of human language. Annotations can identify the distinct units that make up a word or sentence, larger units that correspond to general discourse goals, or properties of language units such as relations among them, their meanings, or their purposes. The MASC project, a collaborative project, extended and built upon a heterogenous corpus of post-1990s American English that now has twelve kinds of annotations on the full corpus. MASC also contains a companion corpus of word sense annotations on MASC sentences that use senses from WordNet, an extensive and widely used lexical resource of word meaning. The present award produced three kinds of results that advance our understanding of meaning in language use: the completion of the MASC word sense sentence corpus, a companion corpus using crowdsourced word sense labels, and a study of genre variation in the core MASC corpus.</p> <p>&nbsp;</p> <p>The MASC word sense corpus applies senses from WordNet, a large widely used lexical resource, to sense annotation of sentences drawn from the very heterogeneous MASC corpus. As a result, less common WordNet senses occur in the MASC corpus. Words to be annotated were selected by four researchers prominent for creating and evaluating lexical and corpus resources. 116 moderately polysemous words were selected (nouns, verbs and adjectives; 7-8 word senses each), yielding a total corpus size of well over 2 million words. This corpus increases our understanding of the issues involved in collecting high quality sense annotations. Despite a common view that it was not possible to get high agreement among annotators using fine-grained senses of more than 3 or so per word, MASC methods led to very high agreement on half the words. It thus serves as a valuable resource for further study of why some words lead to less agreement among annotators. It has already been used to create a multilingual resource, and to study alignment of word meaning in distinct lexical resources. Creation of lexical resources with word sense annotation within and across languages is increasingly useful given the growth of resources that are part of Linked Open Data (LOD). LOD contains concept names and relations, and work has already begun in several organizations to link word senses to concept names in these resources, and thus to make it possible to gather knowledge from text.</p> <p>&nbsp;</p> <p>The result that half of the words in the MASC word sense corpus had low agreement led us to develop a novel crowdsourced annotation method and the corresponding corpus. Untrained but highly motivated annotators were recruited so that many sense labels, rather than one, would be assigned to each annotated word. To convert the crowd's many labels into a single "correct" label, we applied a probabilistic model originally developed in the 1980s to decide on a true label for diagnostic data, such as radiology films, given opinions from many experts. Unlike conventional annotator reliability methods used in language annotation projects, this model assumes that different annotators have different degrees of accuracy, and it can estimate an annotator's accuracy given enough data from that annotator. This produces much better results than using majority voting in cases where a few minority annotators are more accurate than the majority annotators. We extended the original probabilistic model for binary class labels to handle many class labels (word senses) per word. The results demonstrated that highe...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Corpora, or collections of texts organized around one or more commonalities, are an important resource for studies of language use across disciplines, including natural language processing, information retrieval, cognitive science, information science, and machine learning. Annotations enhance the observed language with unobserved information that is apparent to people in their use of language. Thus annotaton facilitates the study of human language. Annotations can identify the distinct units that make up a word or sentence, larger units that correspond to general discourse goals, or properties of language units such as relations among them, their meanings, or their purposes. The MASC project, a collaborative project, extended and built upon a heterogenous corpus of post-1990s American English that now has twelve kinds of annotations on the full corpus. MASC also contains a companion corpus of word sense annotations on MASC sentences that use senses from WordNet, an extensive and widely used lexical resource of word meaning. The present award produced three kinds of results that advance our understanding of meaning in language use: the completion of the MASC word sense sentence corpus, a companion corpus using crowdsourced word sense labels, and a study of genre variation in the core MASC corpus.     The MASC word sense corpus applies senses from WordNet, a large widely used lexical resource, to sense annotation of sentences drawn from the very heterogeneous MASC corpus. As a result, less common WordNet senses occur in the MASC corpus. Words to be annotated were selected by four researchers prominent for creating and evaluating lexical and corpus resources. 116 moderately polysemous words were selected (nouns, verbs and adjectives; 7-8 word senses each), yielding a total corpus size of well over 2 million words. This corpus increases our understanding of the issues involved in collecting high quality sense annotations. Despite a common view that it was not possible to get high agreement among annotators using fine-grained senses of more than 3 or so per word, MASC methods led to very high agreement on half the words. It thus serves as a valuable resource for further study of why some words lead to less agreement among annotators. It has already been used to create a multilingual resource, and to study alignment of word meaning in distinct lexical resources. Creation of lexical resources with word sense annotation within and across languages is increasingly useful given the growth of resources that are part of Linked Open Data (LOD). LOD contains concept names and relations, and work has already begun in several organizations to link word senses to concept names in these resources, and thus to make it possible to gather knowledge from text.     The result that half of the words in the MASC word sense corpus had low agreement led us to develop a novel crowdsourced annotation method and the corresponding corpus. Untrained but highly motivated annotators were recruited so that many sense labels, rather than one, would be assigned to each annotated word. To convert the crowd's many labels into a single "correct" label, we applied a probabilistic model originally developed in the 1980s to decide on a true label for diagnostic data, such as radiology films, given opinions from many experts. Unlike conventional annotator reliability methods used in language annotation projects, this model assumes that different annotators have different degrees of accuracy, and it can estimate an annotator's accuracy given enough data from that annotator. This produces much better results than using majority voting in cases where a few minority annotators are more accurate than the majority annotators. We extended the original probabilistic model for binary class labels to handle many class labels (word senses) per word. The results demonstrated that higher quality annotations can be produced for a lower cost per "correct" label using crowdsourcing, ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
