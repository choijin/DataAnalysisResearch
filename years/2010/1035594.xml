<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS: Small: Virtually Transparent Epidermal Imagery</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>498945.00</AwardTotalIntnAmount>
<AwardAmount>510945</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The objective of this research is to develop a cyber-physical system capable of displaying the in vivo surgical area directly onto patients' skin in real-time high definition. This system will give surgeons an ?x-ray? vision experience, since they see directly through the skin, and remove a spatial bottleneck and additional scarring caused by laparoscopes  in minimally invasive surgery. The approach is to develop micro-cameras that: occupy no space required by surgical tools, produce no additional scarring to the patient, and transfer wireless high-definition video images. A virtual view generating system will project the panoramic videos from all cameras to the right spot on the patient?s body with geometry and color distortion compensation. A surgeon-camera-interaction system will be investigated to allow surgeons to control viewpoint with gesture recognition and finger tracking. Novel techniques will be developed for zero-latency high-definition wireless video transfer through the in vivo/ex vivo medium. Image viewpoint alignment and distortion compensation in real time will also be investigated. The results will be a potential paradigm shift in minimally invasive surgery.  &lt;br/&gt;&lt;br/&gt;The proposed work benefits the millions of surgeries capable of being performed through a single incision in the abdomen by providing virtually transparent skin to surgeons who will enjoy all the visual benefits of open-cavity surgery without all the associated risks to the patient. The goals of this research are extremely ?hands-on? and immediately applicable to outreach activities that can  excite youth, minority students, and others about the science, medicine a and engineering careers.</AbstractNarration>
<MinAmdLetterDate>09/07/2010</MinAmdLetterDate>
<MaxAmdLetterDate>05/24/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1035594</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Gitlin</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard D Gitlin</PI_FULL_NAME>
<EmailAddress>richgitlin@usf.edu</EmailAddress>
<PI_PHON>8139741321</PI_PHON>
<NSF_ID>000137554</NSF_ID>
<StartDate>02/18/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yu</FirstName>
<LastName>Sun</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yu Sun</PI_FULL_NAME>
<EmailAddress>yusun@mail.usf.edu</EmailAddress>
<PI_PHON>8139745465</PI_PHON>
<NSF_ID>000552980</NSF_ID>
<StartDate>09/07/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Anderson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam Anderson</PI_FULL_NAME>
<EmailAddress>aanderson@tntech.edu</EmailAddress>
<PI_PHON>9313723374</PI_PHON>
<NSF_ID>000606900</NSF_ID>
<StartDate>09/07/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of South Florida</Name>
<CityName>Tampa</CityName>
<ZipCode>336172008</ZipCode>
<PhoneNumber>8139742897</PhoneNumber>
<StreetAddress>4019 E. Fowler Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 100]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL14</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>069687242</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTH FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>069687242</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of South Florida]]></Name>
<CityName>Tampa</CityName>
<StateCode>FL</StateCode>
<ZipCode>336172008</ZipCode>
<StreetAddress><![CDATA[4019 E. Fowler Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL14</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~498945</FUND_OBLG>
<FUND_OBLG>2012~12000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>To achieve the objectives of the project, we have overcome several technical challenges and developed the following novel techniques.<span style="font-size: 12px;">&nbsp;</span></p> <p>1. To communicate with the micro wireless camera network efficiently, we have developed and evaluated a multiplexing scheme of analog video signals.&nbsp;<span style="font-size: 12px;">The most significant result is that multiple analog signals that are multiplexed in the proposed manner can, indeed, be separated using a special detection algorithm based on the phase-locked loop. This result is significant in that it can potentially lead to a new dimension of wireless communications that has not yet been exploited.</span></p> <p>2. To automatically track the micro wireless cameras mounted on the abdomen wall and an endoscope during a surgical procedure, we have designed efficient algorithms to detect image features of blood vessels that are robust and repeatable across different viewpoints and different lighting conditions. Two types of blood vessel features: branching points and branching segments, are detected using our novel branching point detector, ridgeness-based circle test (RBCT), and a novel branching segment detector. Our vessel feature detectors outperform the state of art feature point detectors having the highest average repeatability scores under camera translation and rotation.</p> <p>3. To overlay pre-operative data such as CT on the inter-operative video and provide accurate depth cue, we have developed a novel 3D surface reconstruction approach.&nbsp; First a novel vessel feature matching method is proposed and 3D positions of vessels can be recovered, and the 3D vessels from different views can be integrated together to obtain a large area 3D reconstruction. &nbsp;To generate a dense 3D reconstruction, we use the shadow generated by the surgical instruments as a weak structured pattern to recover the dense 3D surfaces of internal organs from the images of multiple cameras. Our 3D position error is usually around 0.5mm.</p> <p>4. To track the endoscopes and the wireless cameras and simultaneously construct the 3D in-vivo structure in real-time, we have adopted PTAM to utilize the stereo cameras on a stereoscope and develop both stereo tracking with deforming point detection and stereo mapping in our new stereoscope parallel Tracking and Mapping (SPTAM) that can run at speed of 15 &sim; 20fps with a regular desktop computer.</p> <p>5. To provides a larger field-of-view and contains more information for the surrounding areas, we have developed a new <em>in vivo </em>video visualization system is designed to enlarge the field of view of the original MIS video by augmenting the peripheral areas according to the obtained dense 3D model. The system is called &ldquo;periphery augmentation system.&rdquo; A user-evaluation system was designed to test whether it is useful to augment peripheral areas. Thirty subjects, including four surgeons with specialties on general surgeries, participated the test. Student&rsquo;s t-test was performed on the collected data and verified that the difference between with and without periphery information was statistically significant. The results concluded that the proposed periphery augmentation system improved users&rsquo; understanding and awareness of surgical scenes.</p> <p>In addition, we have designed and developed a Spatial Augmented Game Engine (SAGE) system that uses spatial augmented reality (SAR), which can leverage self-based psychological effects such as Self-Referential Encoding (SRE) and ownership by closely intertwining augmented body interactions with the self.&nbsp; The SAGE platform provides effective tools in education, entertainment, health awareness, and medical visualization. We have further explored benefits and limitations of generating ownership and SRE using the SAGE platform.&nbsp; We designed several usability te...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ To achieve the objectives of the project, we have overcome several technical challenges and developed the following novel techniques.   1. To communicate with the micro wireless camera network efficiently, we have developed and evaluated a multiplexing scheme of analog video signals. The most significant result is that multiple analog signals that are multiplexed in the proposed manner can, indeed, be separated using a special detection algorithm based on the phase-locked loop. This result is significant in that it can potentially lead to a new dimension of wireless communications that has not yet been exploited.  2. To automatically track the micro wireless cameras mounted on the abdomen wall and an endoscope during a surgical procedure, we have designed efficient algorithms to detect image features of blood vessels that are robust and repeatable across different viewpoints and different lighting conditions. Two types of blood vessel features: branching points and branching segments, are detected using our novel branching point detector, ridgeness-based circle test (RBCT), and a novel branching segment detector. Our vessel feature detectors outperform the state of art feature point detectors having the highest average repeatability scores under camera translation and rotation.  3. To overlay pre-operative data such as CT on the inter-operative video and provide accurate depth cue, we have developed a novel 3D surface reconstruction approach.  First a novel vessel feature matching method is proposed and 3D positions of vessels can be recovered, and the 3D vessels from different views can be integrated together to obtain a large area 3D reconstruction.  To generate a dense 3D reconstruction, we use the shadow generated by the surgical instruments as a weak structured pattern to recover the dense 3D surfaces of internal organs from the images of multiple cameras. Our 3D position error is usually around 0.5mm.  4. To track the endoscopes and the wireless cameras and simultaneously construct the 3D in-vivo structure in real-time, we have adopted PTAM to utilize the stereo cameras on a stereoscope and develop both stereo tracking with deforming point detection and stereo mapping in our new stereoscope parallel Tracking and Mapping (SPTAM) that can run at speed of 15 &sim; 20fps with a regular desktop computer.  5. To provides a larger field-of-view and contains more information for the surrounding areas, we have developed a new in vivo video visualization system is designed to enlarge the field of view of the original MIS video by augmenting the peripheral areas according to the obtained dense 3D model. The system is called "periphery augmentation system." A user-evaluation system was designed to test whether it is useful to augment peripheral areas. Thirty subjects, including four surgeons with specialties on general surgeries, participated the test. StudentÆs t-test was performed on the collected data and verified that the difference between with and without periphery information was statistically significant. The results concluded that the proposed periphery augmentation system improved usersÆ understanding and awareness of surgical scenes.  In addition, we have designed and developed a Spatial Augmented Game Engine (SAGE) system that uses spatial augmented reality (SAR), which can leverage self-based psychological effects such as Self-Referential Encoding (SRE) and ownership by closely intertwining augmented body interactions with the self.  The SAGE platform provides effective tools in education, entertainment, health awareness, and medical visualization. We have further explored benefits and limitations of generating ownership and SRE using the SAGE platform.  We designed several usability tests that use our Science, Technology, Engineering, and Mathematics (STEM) educational game entitled æAugmented AnatomyÆ designed for our proposed platform with teachers and a student population in US and China.  Results indicate that lea...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
