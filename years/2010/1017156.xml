<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Distributed Solutions to Smart Camera Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>395000.00</AwardTotalIntnAmount>
<AwardAmount>411000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Thyagarajan Nandagopal</SignBlockName>
<PO_EMAI>tnandago@nsf.gov</PO_EMAI>
<PO_PHON>7032924550</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Smart camera networks (SCNs) merge computer vision, distributed&lt;br/&gt;processing, and sensor network disciplines to solve problems in&lt;br/&gt;multi-camera applications by providing valuable information through&lt;br/&gt;distributed sensing and collaborative in-network processing.&lt;br/&gt;Collaboration in sensor networks is necessary not only to compensate&lt;br/&gt;for the processing, sensing, energy, and bandwidth limitations of each&lt;br/&gt;sensor node but also to improve the accuracy and robustness of the&lt;br/&gt;network. Collaborative processing in SCNs is more challenging than in&lt;br/&gt;conventional scalar sensor networks (SSNs) because of three unique&lt;br/&gt;features of cameras, including the extremely higher data rate, the&lt;br/&gt;directional sensing characteristics with limited field of view (FOV),&lt;br/&gt;and the existence of visual occlusion. An integrated research is&lt;br/&gt;carried out to tackle the unique challenges presented by SCNs where&lt;br/&gt;collaboration is the key. Three aspects of collaborative processing&lt;br/&gt;are investigated, 1) coverage estimation in the presence of visual&lt;br/&gt;occlusions to provide adequate redundancy in sensing coverage, and to&lt;br/&gt;enable collaboration where the statistics of visual coverage blends&lt;br/&gt;the statistics of camera nodes and targets, 2) clustering to&lt;br/&gt;schedule an efficient sleep-wakeup pattern among neighbor nodes formed&lt;br/&gt;by image comparison-based semantic neighbor selection algorithm for&lt;br/&gt;more efficient collaboration, and 3) distributed optimization, for&lt;br/&gt;in-network data processing that concerns how to effectively obtain&lt;br/&gt;robust and accurate integration results from multiple distributed&lt;br/&gt;sensors for challenging vision tasks like target detection,&lt;br/&gt;localization, and tracking in crowds.</AbstractNarration>
<MinAmdLetterDate>07/07/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/07/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1017156</AwardID>
<Investigator>
<FirstName>Hairong</FirstName>
<LastName>Qi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hairong Qi</PI_FULL_NAME>
<EmailAddress>hqi@utk.edu</EmailAddress>
<PI_PHON>8659748527</PI_PHON>
<NSF_ID>000253946</NSF_ID>
<StartDate>07/07/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Qing</FirstName>
<LastName>Cao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qing Cao</PI_FULL_NAME>
<EmailAddress>cao@utk.edu</EmailAddress>
<PI_PHON>8659745417</PI_PHON>
<NSF_ID>000537804</NSF_ID>
<StartDate>07/07/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Tennessee Knoxville</Name>
<CityName>Knoxville</CityName>
<ZipCode>379163801</ZipCode>
<PhoneNumber>8659743466</PhoneNumber>
<StreetAddress>1331 CIR PARK DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<StateCode>TN</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TN02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003387891</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TENNESSEE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003387891</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Tennessee Knoxville]]></Name>
<CityName>Knoxville</CityName>
<StateCode>TN</StateCode>
<ZipCode>379163801</ZipCode>
<StreetAddress><![CDATA[1331 CIR PARK DR]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TN02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7363</Code>
<Text>RES IN NETWORKING TECH &amp; SYS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~395000</FUND_OBLG>
<FUND_OBLG>2011~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Although vision is perhaps the most powerful of the human senses, conventional scalar sensor networks have not been able to exploit its potential due to the extremely constrained resources aside in the network.</p> <p>Smart camera networks (SCNs) merge computer vision, distributed processing, and sensor network disciplines to solve problems in multi-camera applications by providing valuable information through distributed sensing and collaborative in-network processing. Collaboration in sensor networks is necessary not only to compensate for the processing, sensing, energy, and bandwidth limitations of each sensor node but also to improve the accuracy and robustness of the network.</p> <p>Generally speaking, cameras, as a more complex sensing modality, possess three unique features that could hinder the practical deployment of any SCN applications, including the extremely higher data rate, the directional sensing characteristics with limited field of view (FOV), and the existence of visual occlusion. These unique features have brought up new challenging issues, including, for example, the challenges on bandwidth requirement in distributed computing, the challenges on designing light-weight algorithms for improved energy efficiency, and the challenges on fault-tolerance and collaborative processing.</p> <p>This project conducts comprehensive studies on the capabilities and limitations of smart camera networks. We have performed some groundbreaking works that help advance the development of SCNs to a great extent.</p> <p>The project studies the essential issue of visual coverage. Because of the presence of visual occlusions, the statistics of visual coverage blends the statistics of camera nodes and targets, and are extremely difficult to derive. For the first time, we are able to derive a closed-form solution to visual coverage estimation (i.e., estimate the probability that an arbitrary target in the field is visually covered by at least K sensor nodes). With the estimated coverage statistics, we can provide a more accurate estimation of the minimum node density that suffices to ensure a <strong>K</strong>-coverage across the field.</p> <p>In addition, we were able to provide theoretical bounds to practically solve the K-coverage problem in a barrier coverage context through the deployment of a hybrid sensor network where both static and mobile sensors are involved.</p> <p>The project also studies the issue of distributed optimization for &ldquo;in-network&rdquo; data processing among a subset of sensors. We tackle the challenging problem of target detection and localization in crowds through the discovery of a new target model as compared to existing schemes, where we resolve the certainty of target nonexistence instead of the traditional resolution of the uncertainty of target existence. This approach is lightweight, energy-efficient, and robust where not only each camera node transmits a very limited amount of data, but that a limited number of camera nodes is used.</p> <p>Finally, a suite of auxiliary services has been developed to facilitate the deployment of applications in smart camera networks. For example, Uno is the first distributed storage system that explicitly addresses the challenges to store privacy sensitive data of users; LIPS represents the first piece of work that exploits state-based models for link prediction in sensor networks; and EDAL presents a highly energy efficient data collection protocol in wireless sensor networks, where it generates routes that connect all source nodes with minimal total path cost, under the constraints of packet delay requirements and load balancing needs.</p> <p>In summary, the project has addressed the fundamental challenges on the capability of SCNs on coverage estimation, and provide pragmatic guidance in the design of distributed algorithms for performing various vision tasks.</p><br> <p>            Last Modif...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Although vision is perhaps the most powerful of the human senses, conventional scalar sensor networks have not been able to exploit its potential due to the extremely constrained resources aside in the network.  Smart camera networks (SCNs) merge computer vision, distributed processing, and sensor network disciplines to solve problems in multi-camera applications by providing valuable information through distributed sensing and collaborative in-network processing. Collaboration in sensor networks is necessary not only to compensate for the processing, sensing, energy, and bandwidth limitations of each sensor node but also to improve the accuracy and robustness of the network.  Generally speaking, cameras, as a more complex sensing modality, possess three unique features that could hinder the practical deployment of any SCN applications, including the extremely higher data rate, the directional sensing characteristics with limited field of view (FOV), and the existence of visual occlusion. These unique features have brought up new challenging issues, including, for example, the challenges on bandwidth requirement in distributed computing, the challenges on designing light-weight algorithms for improved energy efficiency, and the challenges on fault-tolerance and collaborative processing.  This project conducts comprehensive studies on the capabilities and limitations of smart camera networks. We have performed some groundbreaking works that help advance the development of SCNs to a great extent.  The project studies the essential issue of visual coverage. Because of the presence of visual occlusions, the statistics of visual coverage blends the statistics of camera nodes and targets, and are extremely difficult to derive. For the first time, we are able to derive a closed-form solution to visual coverage estimation (i.e., estimate the probability that an arbitrary target in the field is visually covered by at least K sensor nodes). With the estimated coverage statistics, we can provide a more accurate estimation of the minimum node density that suffices to ensure a K-coverage across the field.  In addition, we were able to provide theoretical bounds to practically solve the K-coverage problem in a barrier coverage context through the deployment of a hybrid sensor network where both static and mobile sensors are involved.  The project also studies the issue of distributed optimization for "in-network" data processing among a subset of sensors. We tackle the challenging problem of target detection and localization in crowds through the discovery of a new target model as compared to existing schemes, where we resolve the certainty of target nonexistence instead of the traditional resolution of the uncertainty of target existence. This approach is lightweight, energy-efficient, and robust where not only each camera node transmits a very limited amount of data, but that a limited number of camera nodes is used.  Finally, a suite of auxiliary services has been developed to facilitate the deployment of applications in smart camera networks. For example, Uno is the first distributed storage system that explicitly addresses the challenges to store privacy sensitive data of users; LIPS represents the first piece of work that exploits state-based models for link prediction in sensor networks; and EDAL presents a highly energy efficient data collection protocol in wireless sensor networks, where it generates routes that connect all source nodes with minimal total path cost, under the constraints of packet delay requirements and load balancing needs.  In summary, the project has addressed the fundamental challenges on the capability of SCNs on coverage estimation, and provide pragmatic guidance in the design of distributed algorithms for performing various vision tasks.       Last Modified: 11/07/2014       Submitted by: Hairong Qi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
