<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF:  Small:  Locally Decodable Codes and Space Bounded Computation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>346480.00</AwardTotalIntnAmount>
<AwardAmount>346480</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dmitri Maslov</SignBlockName>
<PO_EMAI>dmaslov@nsf.gov</PO_EMAI>
<PO_PHON>7032928910</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project focuses on questions related to bounding the space requirements of computation in various settings, and the relationship between computation time and space.&lt;br/&gt;&lt;br/&gt;Current computation tasks often involve very large data sets, for example data originating from the internet, biological or other scientific databases.  The size of input data in certain computational tasks requires special considerations and solutions that work with only small portions of the input at a time: manipulating all of the input at once would be prohibitive even with the latest computer technology.  Locally decodable codes and streaming algorithms are motivated by such applications.&lt;br/&gt;&lt;br/&gt;Locally decodable codes are error correcting codes with the extra property that in order to retrieve the correct value of one position of the input with high probability, it is sufficient to read just a small number of positions of the possibly corrupted codeword.  So far the known constructions of such codes with constant number of queries have very large length with respect to the input size, and there is a large gap between the known upper and lower bounds on the length of codewords, even in the case of 3-query codes.  The project further examines the relationship between the length necessary for the codewords, the number of queries allowed for decoding, and the error correcting properties of locally decodable codes.&lt;br/&gt;&lt;br/&gt;In addition, the project includes proving bounds on storage space in the cell probe model while limiting the number of positions accessed to answer questions about the data, and  bounding the space requirements of streaming algorithms.  Finally, the project addresses the relationship between the size and depth of Boolean circuits necessary to compute a given function.  This is directly related to the relationship between the time and space of computation.</AbstractNarration>
<MinAmdLetterDate>07/21/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1018060</AwardID>
<Investigator>
<FirstName>Anna</FirstName>
<LastName>Gal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anna Gal</PI_FULL_NAME>
<EmailAddress>panni@cs.utexas.edu</EmailAddress>
<PI_PHON>5124719539</PI_PHON>
<NSF_ID>000316297</NSF_ID>
<StartDate>07/21/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787595316</ZipCode>
<StreetAddress><![CDATA[3925 W Braker Lane, Ste 3.340]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7927</Code>
<Text>COMPLEXITY &amp; CRYPTOGRAPHY</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~346480</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main focus of the project was the study of space bounded computation in various contexts, motivated by current computational tasks involving large amounts of data. In addition to classical questions of computational complexity, aspects of space bounded computation were examined in the context of&nbsp; coding theory, in particular locally decodable codes.</p> <p>Locally decodable codes are error correcting codes with the extra property that it is sufficient to read just a small number of positions of a possibly corrupted codeword in order to recover any one position of the input. This property is useful when encoding very large data sets, for example patient records of a hospital. Traditional error correcting methods that provide good error tolerance against arbitrary errors would require processing the entire database (e.g. data of the entire hospital) even for recovering small amounts of information (e.g. individual patient records). Locally decodable codes allow reliable recovery of any individual record, by accessing not much larger amount of data then the desired information. The challenge is to achieve this even when any part of the database can be corrupted by adversarial errors.</p> <p>To achieve local decodability, it is necessary to use randomness in the&nbsp; decoding procedures. We refer to the probability of returning the correct answer as the correctness of the decoding algorithm. In joint work with Andrew Mills, we showed that&nbsp; achieving slightly larger correctness than the known subexponential length constructions requires exponential codeword length for 3-query codes. Previously, there were no larger than quadratic lower bounds known for&nbsp; locally decodable codes with more than 2 queries, even in the case of&nbsp; 3-query linear codes. Our lower bounds hold for linear codes over arbitrary finite fields and for binary nonlinear codes. We also obtained similar results for arbitrary number of queries, under certain assumptions on the decoding algorithm, that have been commonly used in previous constructions. Our results explain the limitations on correctness of these algorithms.</p> <p>Batch codes are closely related to the concept of local decodability, as well as to efficient use of storage space. Batch codes were introduced by Ishai, Kushilevitz, Ostrovsky and Sahai in 2004. A batch code specifies a method to encode a string x&nbsp; into an m-tuple of strings stored on m distinct servers, such that any subset of k symbols from x can be retrieved by reading at most t symbols from each server. The goal is to keep the "load" t small, while also minimizing the total storage space. The problem is motivated by applications to load balancing&nbsp; in distributed storage, private information retrieval and cryptographic protocols.<br />Combinatorial batch codes are purely replication based batch codes, where each server stores a subset of symbols of the string x. In joint work with Natalia Silberstein, we&nbsp; gave optimal constructions of combinatorial batch codes for a new range of parameters. Our constructions are based on block designs.<br /><br /><br />The depth of Boolean circuits is closely related to the space complexity of the corresponding functions. As part of this project, we studied questions of space bounded computation related to the size versus depth problem, in particular we considered tradeoffs between simultaneous time and&nbsp; space bounds in the context of Boolean circuit complexity, <br />In joint work with Jing-Tang Jang, we obtained significant improvements over the general bounds for the size versus&nbsp; depth problem for special classes of Boolean circuits.&nbsp; We showed that every layered Boolean circuit of size s can be simulated by a layered Boolean circuit of&nbsp; depth $O(\sqrt{s \log s})$.&nbsp; For planar circuits and synchronous circuits of size $s$, we obtained simulations of depth $O(\sqrt{s})$.&nbsp; Im...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main focus of the project was the study of space bounded computation in various contexts, motivated by current computational tasks involving large amounts of data. In addition to classical questions of computational complexity, aspects of space bounded computation were examined in the context of  coding theory, in particular locally decodable codes.  Locally decodable codes are error correcting codes with the extra property that it is sufficient to read just a small number of positions of a possibly corrupted codeword in order to recover any one position of the input. This property is useful when encoding very large data sets, for example patient records of a hospital. Traditional error correcting methods that provide good error tolerance against arbitrary errors would require processing the entire database (e.g. data of the entire hospital) even for recovering small amounts of information (e.g. individual patient records). Locally decodable codes allow reliable recovery of any individual record, by accessing not much larger amount of data then the desired information. The challenge is to achieve this even when any part of the database can be corrupted by adversarial errors.  To achieve local decodability, it is necessary to use randomness in the  decoding procedures. We refer to the probability of returning the correct answer as the correctness of the decoding algorithm. In joint work with Andrew Mills, we showed that  achieving slightly larger correctness than the known subexponential length constructions requires exponential codeword length for 3-query codes. Previously, there were no larger than quadratic lower bounds known for  locally decodable codes with more than 2 queries, even in the case of  3-query linear codes. Our lower bounds hold for linear codes over arbitrary finite fields and for binary nonlinear codes. We also obtained similar results for arbitrary number of queries, under certain assumptions on the decoding algorithm, that have been commonly used in previous constructions. Our results explain the limitations on correctness of these algorithms.  Batch codes are closely related to the concept of local decodability, as well as to efficient use of storage space. Batch codes were introduced by Ishai, Kushilevitz, Ostrovsky and Sahai in 2004. A batch code specifies a method to encode a string x  into an m-tuple of strings stored on m distinct servers, such that any subset of k symbols from x can be retrieved by reading at most t symbols from each server. The goal is to keep the "load" t small, while also minimizing the total storage space. The problem is motivated by applications to load balancing  in distributed storage, private information retrieval and cryptographic protocols. Combinatorial batch codes are purely replication based batch codes, where each server stores a subset of symbols of the string x. In joint work with Natalia Silberstein, we  gave optimal constructions of combinatorial batch codes for a new range of parameters. Our constructions are based on block designs.   The depth of Boolean circuits is closely related to the space complexity of the corresponding functions. As part of this project, we studied questions of space bounded computation related to the size versus depth problem, in particular we considered tradeoffs between simultaneous time and  space bounds in the context of Boolean circuit complexity,  In joint work with Jing-Tang Jang, we obtained significant improvements over the general bounds for the size versus  depth problem for special classes of Boolean circuits.  We showed that every layered Boolean circuit of size s can be simulated by a layered Boolean circuit of  depth $O(\sqrt{s \log s})$.  For planar circuits and synchronous circuits of size $s$, we obtained simulations of depth $O(\sqrt{s})$.  Improving any of the above results by polylog factors would immediately improve the bounds for general circuits. We also obtained results that imply that the class of languages ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
