<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDI-Type II: Collaborative Research: Joint Image-Text Parsing and Reasoning for Analyzing Social and Political News Events</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1299998.00</AwardTotalIntnAmount>
<AwardAmount>1299998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Fahmida Chowdhury</SignBlockName>
<PO_EMAI>fchowdhu@nsf.gov</PO_EMAI>
<PO_PHON>7032924672</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Summary: Rapidly changing technologies of multi-modal communication, from the global reach of international satellite TV, the proliferation of Internet news outlets, to YouTube, are transforming the news industry. In parallel, ?citizen journalism? is on the rise, enabled by smart phones, social networks, and blogs. The Internet is becoming a vast information ecosystem driven by mediated events ? elections, social movements, natural disasters, disease epidemics ? with rich heterogeneous data: text, image, and video. Meanwhile, the tools and methodologies for users and researchers are not keeping pace: it remains prohibitively labor-intensive to systematically access and study the vast amount of emerging news data.&lt;br/&gt;&lt;br/&gt;Leveraging UCLA's ongoing digital collection of 85,000 hours of news videos, including 8.1 billion image frames and 530 million words of closed captioning, the research team is developing a new computational paradigm for analyzing massive datasets of social and political news events: (i) Studying joint image-text parsing to categorize news by topics and events, and analyzing selection and presentation biases across networks and media spheres in a statistical and quantitative manner never before possible; (ii) Studying by joint image-text mining to reason the persuasion intents, and modeling the techniques of verbal and visual persuasions; (iii) Discovering spatio-temporal patterns in the interactions of multiple mediated events, and analyzing agenda setting patterns; and (iv) Developing an interactive multi-perspective news interface, vrNewsScape, for visualizing and interacting with our computational and statistical results.&lt;br/&gt;&lt;br/&gt;Intellectual merit: This interdisciplinary project makes innovative contributions to three disciplines. Transforming social science research. The project develops a data-driven paradigm for transforming communication research in the social sciences. By enabling quantitative studies of massive visual datasets, the research team identifies and characterizes large-scale patterns of news mediation and persuasion currently inaccessible to researchers, due to the prohibitive cost of manual analysis. The research team goes beyond traditional object detection, segmentation, and recognition by studying framing and persuasion techniques in images, an untouched topic in computer vision. The team studies semantic associations and meanings for object and scene categories in their social context. Also, the team is studying image parsing to fill the semantic gap ? a long standing technical barrier in image retrieval, and will generate narrative text descriptions from the parse trees so that they can be fused with the input text and closed captioning for topic mining.&lt;br/&gt;&lt;br/&gt;The research goes beyond conventional topic mining from text to perform integrative text-image mining, bias detection, and pattern discovery in the spatio-temporal evolution of mediated news events. The research detects and summarizes controversy and mine user-generated content for analyzing communicative intent and persuasive effects.&lt;br/&gt;&lt;br/&gt;Broader impacts: vrNewsScape is being made publicly available to researchers and graduate students. Because the news media report on events in multiple different expert domains ? including congressional and presidential politics, international relations, war and public uprisings, natural disasters and humanitarian aid missions, disease epidemics and health initiatives, criminal activity and court cases, celebrities and cultural events ? the analytical tools in development are not limited to a particular research domain in social, political and computer sciences, but permit for the first time a systematic and quantitative examination of the massive datasets required to understand today?s mediated society.&lt;br/&gt;&lt;br/&gt;In education, the project extends UCLA?s Digital Civic Learning initiative (dcl.sscnet.ucla.edu), a program involving college and high-school students in the analysis of news, thus delivering education benefits to potentially a huge number of students nationwide in Communication Studies (in 2004, 433,000 college students were enrolled in Communication and Journalism and 209,000 in Political Science[153]), exposing them to a new generation of high-level tools for handling multimodal data and inspiring them to pursue computational thinking, in line with the NSF?s objectives.</AbstractNarration>
<MinAmdLetterDate>09/09/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/09/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1028381</AwardID>
<Investigator>
<FirstName>Song-Chun</FirstName>
<LastName>Zhu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Song-Chun Zhu</PI_FULL_NAME>
<EmailAddress>sczhu@stat.ucla.edu</EmailAddress>
<PI_PHON>3102068693</PI_PHON>
<NSF_ID>000096074</NSF_ID>
<StartDate>09/09/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Francis</FirstName>
<LastName>Steen</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Francis F Steen</PI_FULL_NAME>
<EmailAddress>steen@comm.ucla.edu</EmailAddress>
<PI_PHON>3108253147</PI_PHON>
<NSF_ID>000427697</NSF_ID>
<StartDate>09/09/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tim</FirstName>
<LastName>Groeling</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tim J Groeling</PI_FULL_NAME>
<EmailAddress>groeling@ucla.edu</EmailAddress>
<PI_PHON>3107940102</PI_PHON>
<NSF_ID>000287814</NSF_ID>
<StartDate>09/09/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Los Angeles]]></Name>
<CityName>LOS ANGELES</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951406</ZipCode>
<StreetAddress><![CDATA[10889 Wilshire Boulevard]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7751</Code>
<Text>CDI TYPE II</Text>
</ProgramElement>
<ProgramReference>
<Code>7721</Code>
<Text>FROM DATA TO KNOWLEDGE</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~1299998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Monaco; color: #ffffff; background-color: #000000} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Monaco; color: #ffffff; background-color: #000000; min-height: 17.0px} span.s1 {font-variant-ligatures: no-common-ligatures} --> <p class="p1"><span class="s1">The vrNewsScape project has established an initial framework for research into massive multimodal datasets of human communication by collecting and systematizing hundreds&nbsp;</span><span class="s1">of thousands of hours of television news, by developing new computational techniques focused on communicative learning, and by building a community of researchers pooling&nbsp;</span>their expertise to achieve significant progress in a rapidly growing field.</p> <p class="p1"><span class="s1">The UCLA NewsScape Archive contains more than 400,000 programs of television news, current affairs and commentary, and thematic event collections. This amounts to 100&nbsp;</span><span class="s1">billion images, indexed and cross-referenced by four billion words of timestamped closed captioning, transcripts, online news, and microblog feeds. This news content&nbsp;</span>mediates the major social and political events of the local, national, and global community, and constitutes the main source of information of these events by the public.</p> <p class="p1"><span class="s1">Progress on the core objective of this project requires sustained attention to extending and enhancing the media dataset, and to ensure reliable capture, safe&nbsp;</span>warehousing, timely access, and efficient search interfaces.</p> <p class="p1"><span class="s1">We have built and deployed a joint textimage news topic discovery and tracking system that automatically parses and organizes the broadcast news data and the social media&nbsp;</span><span class="s1">data. Using the raw news videos, closed captions, and social media feed as inputs, the outputs of the system are news topic trajectories that describe the dynamic&nbsp;</span>relations of news sources over time and across locations.</p> <p class="p1"><span class="s1">This system includes several modules that preprocess the raw input data, including: (i) story segmentation which divides the news streams into stories, (ii) optical&nbsp;</span><span class="s1">character recognition (OCR) which extracts texts on video frames, (iii) conceptual frame detection using SEMAFOR and the ICSI FrameNet project, (iv) commercial detection&nbsp;</span>in the news closed captions, and (v) anchor/newscaster detection in the news videos.</p> <p class="p1"><span class="s1">The vrNewsScape project has successfully drawn attention to the importance of communicative intent in text-image data mining (Joo, Steen, &amp; Zhu 2015). This result&nbsp;</span>demonstrates the signal advantages of interdisciplinary collaboration, as promoted by the CDI program. The computer vision field has traditionally been focused almost exclusively on discovering the categorical facts of a picture of video, and its relation to some text. We successfully argued that images and text are used communicatively, and that their meaning therefore must consider communicative intent and communicative effect.</p> <p>&nbsp;</p><br> <p>            Last Modified: 02/27/2017<br>      Modified by: Francis&nbsp;F&nbsp;Steen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The vrNewsScape project has established an initial framework for research into massive multimodal datasets of human communication by collecting and systematizing hundreds of thousands of hours of television news, by developing new computational techniques focused on communicative learning, and by building a community of researchers pooling their expertise to achieve significant progress in a rapidly growing field. The UCLA NewsScape Archive contains more than 400,000 programs of television news, current affairs and commentary, and thematic event collections. This amounts to 100 billion images, indexed and cross-referenced by four billion words of timestamped closed captioning, transcripts, online news, and microblog feeds. This news content mediates the major social and political events of the local, national, and global community, and constitutes the main source of information of these events by the public. Progress on the core objective of this project requires sustained attention to extending and enhancing the media dataset, and to ensure reliable capture, safe warehousing, timely access, and efficient search interfaces. We have built and deployed a joint textimage news topic discovery and tracking system that automatically parses and organizes the broadcast news data and the social media data. Using the raw news videos, closed captions, and social media feed as inputs, the outputs of the system are news topic trajectories that describe the dynamic relations of news sources over time and across locations. This system includes several modules that preprocess the raw input data, including: (i) story segmentation which divides the news streams into stories, (ii) optical character recognition (OCR) which extracts texts on video frames, (iii) conceptual frame detection using SEMAFOR and the ICSI FrameNet project, (iv) commercial detection in the news closed captions, and (v) anchor/newscaster detection in the news videos. The vrNewsScape project has successfully drawn attention to the importance of communicative intent in text-image data mining (Joo, Steen, &amp; Zhu 2015). This result demonstrates the signal advantages of interdisciplinary collaboration, as promoted by the CDI program. The computer vision field has traditionally been focused almost exclusively on discovering the categorical facts of a picture of video, and its relation to some text. We successfully argued that images and text are used communicatively, and that their meaning therefore must consider communicative intent and communicative effect.          Last Modified: 02/27/2017       Submitted by: Francis F Steen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
