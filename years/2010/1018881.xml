<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF Small:  A Compiler-Based Auto-Tuning Framework for Many-Core Code Generation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>481050.00</AwardTotalIntnAmount>
<AwardAmount>481050</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project provides a compiler-based foundation for data-parallel optimization and code generation that can yield very high performance across a range of different multi-core and many-core architectures while increasing the productivity of application programmers.  The project is targeting two distinct architectures, a conventional quad-core microprocessor and a graphics processing unit (GPU) with 240 cores, as well as a heterogeneous system that combines both.  The technology represents a significant departure from the organization of contemporary compilers, automating as much of optimization as possible, but opening up the mapping process to provide savvy programmers the control they so often desire.  The unique features of the system include: (1) transformation recipes as a programmer's or high-level compiler's interface to optimization and code generation; (2) a polyhedral framework to mathematically represent code structures and optimizations for robust code generation; and (3) auto-tuning technology to compactly describe and systematically evaluate a range of possibleimplementations of a computation.  The most novel of these is the is the transformation recipe, which factors out the commonality of OpenMP, CUDA and OpenCL code generation, thus supporting the heterogeneous platform and facilitating late-binding decisions of which implementation to use.  The software system from previous work is being released, and has accelerated both libraries and scientific applications.  With the right transformation recipe for the auto-tuning system to evaluate, the resulting automatically-generated code yields high performance, in some cases competitive or even better than manually-coded implementations.  The PIs plan to expand this capability to a broader set of applications and architectural features.</AbstractNarration>
<MinAmdLetterDate>06/18/2010</MinAmdLetterDate>
<MaxAmdLetterDate>06/05/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1018881</AwardID>
<Investigator>
<FirstName>Mary</FirstName>
<LastName>Hall</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mary Hall</PI_FULL_NAME>
<EmailAddress>mhall@cs.utah.edu</EmailAddress>
<PI_PHON>8015851039</PI_PHON>
<NSF_ID>000367228</NSF_ID>
<StartDate>06/18/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Chun</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chun Chen</PI_FULL_NAME>
<EmailAddress>chunchen@cs.utah.edu</EmailAddress>
<PI_PHON>8015816903</PI_PHON>
<NSF_ID>000555727</NSF_ID>
<StartDate>06/18/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<StreetAddress2><![CDATA[Second Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009095365</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF UTAH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009095365</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Utah]]></Name>
<CityName>SALT LAKE CITY</CityName>
<StateCode>UT</StateCode>
<ZipCode>841128930</ZipCode>
<StreetAddress><![CDATA[75 S 2000 E]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~316052</FUND_OBLG>
<FUND_OBLG>2012~164998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>High-performance computer architectures must exploit new ways for continued performance gains while maintaining energy efficiency. The result is a diverse landscape of architectures, and achieving high performance requires sophisticated programmers that can rewrite their application for each new target architecture. &nbsp;It would greatly increase programmer productivity and improve portability of applications to different architectures if an automated system could take a programmer's high-level specification of a computation and map it to the specific features of different architectures. &nbsp;This project has developed such a system that employs autotuning compiler technology in the CHiLL framework. Autotuning explores a search space of different implementations of a computation to find the one that best matches a set of optimization criteria, usually performance. &nbsp;In CHiLL, this search space arises from different sequences of code transformations to be applied to the original high-level code. The CHiLL technology developed in this project represents a significant departure from&nbsp;the organization of contemporary compilers, automating as much of&nbsp;optimization as possible, but opening&nbsp;up the mapping process to provide savvy programmers the control they&nbsp;so often desire. &nbsp;&nbsp;In this project, we have developed technology that targets specific application domains, including dense linear algebra and related dense array computations, sparse matrix and graph algorithms, and tensor products.These novel aspects of the compiler --- programmer control, autotuning, support for challenging application domains, and focus on achieving very high performance --- have captured the interest of application programmers who are unsatisfied with the effectiveness of the programming tools we are currently using.&nbsp; We currently are working with application scientists, particularly in Department of Energy laboratories, to ensure that the tools we develop meet their needs. &nbsp;This project has demonstrated that compiler-optimized code from CHiLL can match or even outperform manually-tuned libraries and application code, using an approach that is more productive for the programmer, and portable to future architectures.</p> <p><span><br /></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 09/29/2015<br>      Modified by: Mary&nbsp;Hall</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ High-performance computer architectures must exploit new ways for continued performance gains while maintaining energy efficiency. The result is a diverse landscape of architectures, and achieving high performance requires sophisticated programmers that can rewrite their application for each new target architecture.  It would greatly increase programmer productivity and improve portability of applications to different architectures if an automated system could take a programmer's high-level specification of a computation and map it to the specific features of different architectures.  This project has developed such a system that employs autotuning compiler technology in the CHiLL framework. Autotuning explores a search space of different implementations of a computation to find the one that best matches a set of optimization criteria, usually performance.  In CHiLL, this search space arises from different sequences of code transformations to be applied to the original high-level code. The CHiLL technology developed in this project represents a significant departure from the organization of contemporary compilers, automating as much of optimization as possible, but opening up the mapping process to provide savvy programmers the control they so often desire.   In this project, we have developed technology that targets specific application domains, including dense linear algebra and related dense array computations, sparse matrix and graph algorithms, and tensor products.These novel aspects of the compiler --- programmer control, autotuning, support for challenging application domains, and focus on achieving very high performance --- have captured the interest of application programmers who are unsatisfied with the effectiveness of the programming tools we are currently using.  We currently are working with application scientists, particularly in Department of Energy laboratories, to ensure that the tools we develop meet their needs.  This project has demonstrated that compiler-optimized code from CHiLL can match or even outperform manually-tuned libraries and application code, using an approach that is more productive for the programmer, and portable to future architectures.             Last Modified: 09/29/2015       Submitted by: Mary Hall]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
