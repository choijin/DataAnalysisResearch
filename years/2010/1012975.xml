<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NetSE:Large:Collaborative Research: Exploiting Multi-modality for Tele-Immersion</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>2033790.00</AwardTotalIntnAmount>
<AwardAmount>2393425</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Providing an environment that offers both immersion and interaction is a tough research challenge. Ensuring a reasonable Quality of Experience (QoE) in using these environments installed in geographically distributed cities is even a tougher challenge. This project considers a collaborative, immersive, and interactive environment that not only supports 3D rendering of the participants? video but also other modalities such as Body Sensor Network (BSN) data that can offer highly precise data about a person?s physical movements (as well as physiological data). While creating this environment, one needs to consider the various bottlenecks that choke the data streams carrying the immersive and interactive information: reconstruction delay, ultra-high throughput needed, packet loss, and rendering delays. &lt;br/&gt;&lt;br/&gt;The main aim of this project is to design and develop collaborative, multi-modal immersive environments with higher frame rates and frame quality by carrying out research tasks that can take advantage of information from other modalities and handle these bottlenecks.&lt;br/&gt;&lt;br/&gt;In a typical tele-immersive environment, participants can see themselves in the locally rendered 3D view and see participants in the remote environments as well. Since the local rendering delays are much smaller, participants can see themselves earlier and in a more smooth fashion compared to the rendering of remote participants that suffers from communication delays and packet losses. This aspect of varying delays among the immersive participants can potentially cause problems during dynamic interactions and affect their QoE. Answers to questions such as what type of problems can be caused and how the participants handle them depend on the application domain of the immersive environments. To study the QoE and validate (with usability studies) the collaborative, immersive environment, a tele-rehabilitation application will be deployed in multiple cities: Berkeley, California; 2 sites in Dallas, Texas; and Urbana-Champaign, Illinois. &lt;br/&gt;&lt;br/&gt;Intellectual Merits of this project are (i) The resource adaptation framework for streaming multi-source, multi-destination, multi-rate, multi-modal data incorporates supervisory hybrid control theory based fine-grained resource management, multi-modal coarse-grained management, and a multi-modal multicasting approach. (ii) Graphics Processing Unit (GPU)-based 3D reconstruction and compression algorithms. These algorithms facilitate reconstruction of 3D data points based on 3D camera array data and compress them at a faster pace than their CPU-based counterparts. (iii) GPU-based rendering algorithm of 3D data on the receiver side. This algorithm will handle potential data loss in 3D camera data streams using skeletal information from BSN data streams. (iv) Identification and measurement of Quality of Experience (QoE) metrics and using those metrics to derive Quality of Service (QoS) parameters. The derived QoS parameters will then help the resource adaptation framework to modify its decisions at run-time. This project aims to have transformative aspects in the new set of algorithms that exploits multi-modality while incorporating a feedback based on Quality of Experience for functions such as streaming, 3D reconstruction, and rendering.&lt;br/&gt;&lt;br/&gt;Broader Impacts: This project promises significant impact in the fields of education and pervasive health care by providing augmented abilities to carry out intricate programs such as tele-rehabilitation with increased correctness and flexibility. This can also lead to improved productivity in the society considering the ability of health-care professionals to potentially handle a larger population (in remote places) as well as considering the possibility of the affected persons to become independent and productive faster. The project also ensures the results from the proposed research will be incorporated into the courses being taught. 3 women PhD students and 6 under-graduate students (2 are minority students) already working with the investigators of this project. Serious efforts will be undertaken to continue their involvement in this project. Apart from refereed conference and journal publications, the developed software, collected data, and research results will be shared with other researchers through a dedicated website (after ensuring satisfaction of HIPAA regulations).</AbstractNarration>
<MinAmdLetterDate>09/23/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1012975</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Spong</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark W Spong</PI_FULL_NAME>
<EmailAddress>mspong@utdallas.edu</EmailAddress>
<PI_PHON>9728832974</PI_PHON>
<NSF_ID>000286072</NSF_ID>
<StartDate>09/23/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Balakrishnan</FirstName>
<LastName>Prabhakaran</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Balakrishnan Prabhakaran</PI_FULL_NAME>
<EmailAddress>praba@utdallas.edu</EmailAddress>
<PI_PHON>9728834680</PI_PHON>
<NSF_ID>000230020</NSF_ID>
<StartDate>09/23/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Roozbeh</FirstName>
<LastName>Jafari</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Roozbeh Jafari</PI_FULL_NAME>
<EmailAddress>rjafari@tamu.edu</EmailAddress>
<PI_PHON>9798455532</PI_PHON>
<NSF_ID>000150786</NSF_ID>
<StartDate>09/23/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiaohu</FirstName>
<LastName>Guo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaohu Guo</PI_FULL_NAME>
<EmailAddress>xguo@utdallas.edu</EmailAddress>
<PI_PHON>9728834723</PI_PHON>
<NSF_ID>000178016</NSF_ID>
<StartDate>09/23/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Dallas</Name>
<CityName>Richardson</CityName>
<ZipCode>750803021</ZipCode>
<PhoneNumber>9728832313</PhoneNumber>
<StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX32</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>800188161</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT DALLAS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Dallas]]></Name>
<CityName>Richardson</CityName>
<StateCode>TX</StateCode>
<ZipCode>750803021</ZipCode>
<StreetAddress><![CDATA[800 W. Campbell Rd., AD15]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramElement>
<Code>7794</Code>
<Text>NETWORK SCIENCE &amp; ENGINEERING</Text>
</ProgramElement>
<ProgramElement>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramElement>
<ProgramReference>
<Code>7363</Code>
<Text>RES IN NETWORKING TECH &amp; SYS</Text>
</ProgramReference>
<ProgramReference>
<Code>7794</Code>
<Text>NETWORK SCIENCE &amp; ENGINEERING</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~323359</FUND_OBLG>
<FUND_OBLG>2011~451745</FUND_OBLG>
<FUND_OBLG>2012~427218</FUND_OBLG>
<FUND_OBLG>2013~432617</FUND_OBLG>
<FUND_OBLG>2014~737743</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<FUND_OBLG>2017~4743</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our&nbsp;<strong><em>main aim of this project&nbsp;</em></strong>was to design and develop collaborative, multi-modal immersive environments with higher frame rates and frame quality by carrying out the following research tasks that can take advantage of information from other modalities and handle these bottlenecks:&nbsp;</p> <ul> <li>Exploiting knowledge from these multiple modalities of data streams to manage resources, predict and/or compensate for data loss while streaming, so that the Quality of Experience (QoE) in using these distributed immersive environments is improved.&nbsp;</li> <li>Developing GPU-based acceleration methodologies for dynamic, real-time 3D reconstruction and rendering so that the environments can support a higher frame rate.&nbsp;</li> <li>Evaluating the QoE by conducting usability studies in which physical medicine and rehabilitation specialists will use the collaborative environments for evaluating and monitor patients requiring physical therapy or sports persons requiring physical evaluation and mentoring.&nbsp;</li> </ul> <p>&nbsp;Several significant research results were obtained while carrying out the above tasks. These results improved the state-of-the-art in multimodal tele-immersion in different ways such as: (i) incorporation of haptics as a new interaction medium in tele-immersion; (ii) ability to handle latencies and losses and provide better interaction and QoE; (iii) use of the multi-modal immersive platform for remote assessment of patients with upper arm disabilities. Specifically, few key results are:</p> <p><strong>a.&nbsp;&nbsp;&nbsp;&nbsp;</strong><strong>Quality of Experience in Tele-Rehabilitation System&nbsp;</strong></p> <p>Stroke afflicted patients using the 3D immersive tele-rehab system may lack the ability to provide written/oral feedback on their Quality of Experience (QoE). To address this, we developed a set of metrics that can be used to automatically track the stability and the quality of experience of the tele-rehab system, without using a Likert scale of subjective responses. This research was presented in the IEEE International Symposium on Multimedia (ISM) held in Taichung, Taiwan, in December 2014.&nbsp;</p> <p><strong>b.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</strong><strong>Middleware for Augmented/Mixed Reality</strong>:&nbsp;</p> <ol> </ol> <p>International Standards Organization (ISO) has been developing MPEG Media Transport (MMT) protocol for the new generation multimedia applications. We identified the features that need to be incorporated into MMT for supporting augmented and mixed reality applications. A middleware named, MMT+AR, incorporating these features into ISO-MMT was designed and presented in the ACM Multimedia Systems (MMSys) conference held in Portland, Oregon, USA in March 2015.&nbsp;</p> <p><strong>c.&nbsp;&nbsp;&nbsp;&nbsp;</strong><strong>Force enhancement and Delay compensation for Haptic Devices&nbsp;</strong></p> <ol> </ol> <p>We developed approaches for handling Just Noticeable Difference (JND) in force perception and for handling stochastic delay variations in Internet communication of haptic data. These approaches were integrated into a system, H-TIME (Haptic-enabled Tele-Immersive Musculoskeletal Examination). Research paper describing this approach and H-TIME was orally presented in ACM Multimedia 2017 and won the Best Student Paper Award for the year.&nbsp;</p> <p>Broader impacts of the project are in the field of pervasive health care by providing augmented abilities to carry out intricate programs such as tele-rehabilitation with increased correctness and flexibility. For instance,&nbsp;trials for using the above H-TIME system by upper-arm stroke afflicted patients were conducted in the Dallas Veterans Affairs Hospital. 5 healthy participants used the system first and their evaluations were used to fine tune the various aspects of the system. Then, 15 patients afflicted with upper arm disabilities (due to various reasons such as stroke or accident) were evaluated by 2 independent doctors. One doctor examined the patients in person and the other using H-TIME. The study showed a high degree of correlation in the diagnosis by the 2 doctors, demonstrating the ability of H-TIME for remote assessment of patients with upper-arm disabilities. Another system, MR. MAPP (Mixed Reality for MAnaging&nbsp;&nbsp;Phantom Pain) was developed for providing immersive mirror therapy for alleviating the phantom pain felt by amputees. This system is also being installed in-home for amputees by the Dallas Veterans Affairs Hospital.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/04/2018<br>      Modified by: Balakrishnan&nbsp;Prabhakaran</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1012975/1012975_10048514_1538703692062_Slide2--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1012975/1012975_10048514_1538703692062_Slide2--rgov-800width.jpg" title="H-TIME (Haptic-enabled Tele-immersive Musculoskeletal Examination) System"><img src="/por/images/Reports/POR/2018/1012975/1012975_10048514_1538703692062_Slide2--rgov-66x44.jpg" alt="H-TIME (Haptic-enabled Tele-immersive Musculoskeletal Examination) System"></a> <div class="imageCaptionContainer"> <div class="imageCaption">H-TIME (Haptic-enabled Tele-immersive Musculoskeletal Examination) System</div> <div class="imageCredit">PI</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Balakrishnan&nbsp;Prabhakaran</div> <div class="imageTitle">H-TIME (Haptic-enabled Tele-immersive Musculoskeletal Examination) System</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1012975/1012975_10048514_1538703615433_Slide1--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1012975/1012975_10048514_1538703615433_Slide1--rgov-800width.jpg" title="MR. MAPP (Mixed Reality for MAnaging Phantom Pain):"><img src="/por/images/Reports/POR/2018/1012975/1012975_10048514_1538703615433_Slide1--rgov-66x44.jpg" alt="MR. MAPP (Mixed Reality for MAnaging Phantom Pain):"></a> <div class="imageCaptionContainer"> <div class="imageCaption">MR. MAPP (Mixed Reality for MAnaging Phantom Pain):</div> <div class="imageCredit">PI</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Balakrishnan&nbsp;Prabhakaran</div> <div class="imageTitle">MR. MAPP (Mixed Reality for MAnaging Phantom Pain):</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our main aim of this project was to design and develop collaborative, multi-modal immersive environments with higher frame rates and frame quality by carrying out the following research tasks that can take advantage of information from other modalities and handle these bottlenecks:   Exploiting knowledge from these multiple modalities of data streams to manage resources, predict and/or compensate for data loss while streaming, so that the Quality of Experience (QoE) in using these distributed immersive environments is improved.  Developing GPU-based acceleration methodologies for dynamic, real-time 3D reconstruction and rendering so that the environments can support a higher frame rate.  Evaluating the QoE by conducting usability studies in which physical medicine and rehabilitation specialists will use the collaborative environments for evaluating and monitor patients requiring physical therapy or sports persons requiring physical evaluation and mentoring.     Several significant research results were obtained while carrying out the above tasks. These results improved the state-of-the-art in multimodal tele-immersion in different ways such as: (i) incorporation of haptics as a new interaction medium in tele-immersion; (ii) ability to handle latencies and losses and provide better interaction and QoE; (iii) use of the multi-modal immersive platform for remote assessment of patients with upper arm disabilities. Specifically, few key results are:  a.    Quality of Experience in Tele-Rehabilitation System   Stroke afflicted patients using the 3D immersive tele-rehab system may lack the ability to provide written/oral feedback on their Quality of Experience (QoE). To address this, we developed a set of metrics that can be used to automatically track the stability and the quality of experience of the tele-rehab system, without using a Likert scale of subjective responses. This research was presented in the IEEE International Symposium on Multimedia (ISM) held in Taichung, Taiwan, in December 2014.   b.     Middleware for Augmented/Mixed Reality:     International Standards Organization (ISO) has been developing MPEG Media Transport (MMT) protocol for the new generation multimedia applications. We identified the features that need to be incorporated into MMT for supporting augmented and mixed reality applications. A middleware named, MMT+AR, incorporating these features into ISO-MMT was designed and presented in the ACM Multimedia Systems (MMSys) conference held in Portland, Oregon, USA in March 2015.   c.    Force enhancement and Delay compensation for Haptic Devices     We developed approaches for handling Just Noticeable Difference (JND) in force perception and for handling stochastic delay variations in Internet communication of haptic data. These approaches were integrated into a system, H-TIME (Haptic-enabled Tele-Immersive Musculoskeletal Examination). Research paper describing this approach and H-TIME was orally presented in ACM Multimedia 2017 and won the Best Student Paper Award for the year.   Broader impacts of the project are in the field of pervasive health care by providing augmented abilities to carry out intricate programs such as tele-rehabilitation with increased correctness and flexibility. For instance, trials for using the above H-TIME system by upper-arm stroke afflicted patients were conducted in the Dallas Veterans Affairs Hospital. 5 healthy participants used the system first and their evaluations were used to fine tune the various aspects of the system. Then, 15 patients afflicted with upper arm disabilities (due to various reasons such as stroke or accident) were evaluated by 2 independent doctors. One doctor examined the patients in person and the other using H-TIME. The study showed a high degree of correlation in the diagnosis by the 2 doctors, demonstrating the ability of H-TIME for remote assessment of patients with upper-arm disabilities. Another system, MR. MAPP (Mixed Reality for MAnaging  Phantom Pain) was developed for providing immersive mirror therapy for alleviating the phantom pain felt by amputees. This system is also being installed in-home for amputees by the Dallas Veterans Affairs Hospital.          Last Modified: 10/04/2018       Submitted by: Balakrishnan Prabhakaran]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
