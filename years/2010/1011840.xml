<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TC:Large:Collaborative Research: Towards Trustworthy Interactions in the Cloud</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Christopher Clifton</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>As one of the most promising emerging concepts in Information Technology, outsourced computation (also known as cloud computing) is transforming our perception of how IT is consumed and managed, yielding improved cost efficiencies and delivering flexible, on-demand scalability. Cloud computing reduces IT resources and services to commodities acquired and paid-for on-demand through a fast-growing set of infrastructure, platform, and service providers.&lt;br/&gt;&lt;br/&gt;Despite the relatively fast growth and increased adoption of clouds, our understanding of aspects related to their security, privacy, and economic value proposition -- and hence our ability to trust them -- is lacking.  This project addresses this challenge by (a) extending cloud service-level agreements to govern aspects such as integrity of outsourced services, information leakage control, and fair market pricing; (b) developing mechanisms that allow providers to guarantee and users to verify that such trust-enhancing service-level agreements are being followed; and (c) exposing trustworthiness guarantees and tradeoffs to cloud customers and system integrators in ways that are both practical and usable.&lt;br/&gt;&lt;br/&gt;The research work pursued in this project is timely as it addresses the issues of cloud trustworthiness early enough to avoid having the conflicts among its various stakeholders develop unchecked -- as was the case with the Internet decades ago. Doing so has the potential of improving the utility and hardness of our cyber-infrastructure, with significant benefit to our economy and society. &lt;br/&gt;&lt;br/&gt;The project will ultimately lead to a better marketplace for computing resources, in which users are assured that the services they acquire satisfy their performance, security, and privacy expectations.</AbstractNarration>
<MinAmdLetterDate>09/07/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/12/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1011840</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Goodrich</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael T Goodrich</PI_FULL_NAME>
<EmailAddress>goodrich@acm.org</EmailAddress>
<PI_PHON>9498249366</PI_PHON>
<NSF_ID>000326182</NSF_ID>
<StartDate>09/07/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926977600</ZipCode>
<StreetAddress><![CDATA[160 Aldrich Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~100205</FUND_OBLG>
<FUND_OBLG>2011~98152</FUND_OBLG>
<FUND_OBLG>2012~198405</FUND_OBLG>
<FUND_OBLG>2013~103238</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;<strong>DATA SECURITY AND PRIVACY IN THE CLOUD</strong></p> <p>This project addressed the privacy of data stored in a cloud service, where clients outsource their data across a network, like the Internet, to a provider that guarantees that the data will always be available but is not trusted to keep the information private. Specifically, the investigators considered the scenario where a user stores a collection of data items (e.g., documents, email messages, database tables) on a cloud computing service and periodically issues queries to retrieve data items or associated metadata. For example, the user can perform a keyword search to obtain from the service a list of relevant items and then download specific items from the service. The participants developed methods, known as&nbsp;<em><strong>oblivious RAM</strong>&nbsp;<strong>(ORAM)</strong></em>&nbsp;simulation and&nbsp;<em><strong>oblivious storage (OS)</strong></em>, that allow the user to verify the integrity and completeness of the responses returned by the cloud service while keeping a small amount of metadata in secure private storage. An important and influential aspect of this work is that the participants were able to design general techniques for providing a high degree of data privacy that go beyond standard data encryption to hide also the data access pattern from the cloud service. The PI also provided improved solutions to fundamental tools, such as&nbsp;<em><strong>oblivious sorting and shuffling</strong></em>, which are used in ORAM and OS implementations.</p> <p><strong>ENSURING INTEGRITY OF OUTSOURCED DATA</strong></p> <p>The investigators addressed the integrity of data stored in a cloud service. They developed several efficient schemes for implementing&nbsp;<em><strong>authenticated data structures</strong></em>, which provide cryptographic proofs that their answers are as accurate as the author intended, even if the data structure is maintained by a remote host. The PI and co-investigators presented techniques for authenticating data structures that represent points, key-value pairs, graphs, and collections of geometric objects. In this model, a data structure maintained by a trusted source is mirrored at distributed directories that answer queries and provide proof of correctness. This work has applications to the authentication of network management systems and geographic information systems.</p> <p><strong>MEASURING PRIVACY RISKS FOR OUTSOURCED DATA</strong></p> <p>The team studied quantitative measures for characterizing the privacy risks of data that is stored in outsourced repositories in the cloud and queried using a simple query-response interface. They identified and mathematically analyzed a group of attacks, known as&nbsp;<em><strong>Mastermind</strong></em>&nbsp;algorithms,&nbsp;for attacking the privacy of an entire database, through&nbsp;<em><strong>database cloning</strong></em>, which could consist, for example, of queries involving character strings or vectors, such as DNA strings, movie ratings, or social network friendship data. Based on reductions to&nbsp;<em><strong>group testing</strong></em>, the PI and co-investigators showed that it is possible for an attacker to take advantage of minimal amounts of privacy leakage, such as contained in a single bit that indicates if two people in a medical database have any common genetic mutations, or if two people have any common friends in an online social network. They analyzed Mastermind attack algorithms using theoretical characterizations that provide sublinear bounds on the number of queries needed to clone the database, as well as experimental tests on genomic information, collaborative filtering data, and online social networks. The quantitative knowledge that this work provided gives a tool to people to be able to guage the privacy of their data, such as friendship ties in social networks, when they store this data ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  DATA SECURITY AND PRIVACY IN THE CLOUD  This project addressed the privacy of data stored in a cloud service, where clients outsource their data across a network, like the Internet, to a provider that guarantees that the data will always be available but is not trusted to keep the information private. Specifically, the investigators considered the scenario where a user stores a collection of data items (e.g., documents, email messages, database tables) on a cloud computing service and periodically issues queries to retrieve data items or associated metadata. For example, the user can perform a keyword search to obtain from the service a list of relevant items and then download specific items from the service. The participants developed methods, known as oblivious RAM (ORAM) simulation and oblivious storage (OS), that allow the user to verify the integrity and completeness of the responses returned by the cloud service while keeping a small amount of metadata in secure private storage. An important and influential aspect of this work is that the participants were able to design general techniques for providing a high degree of data privacy that go beyond standard data encryption to hide also the data access pattern from the cloud service. The PI also provided improved solutions to fundamental tools, such as oblivious sorting and shuffling, which are used in ORAM and OS implementations.  ENSURING INTEGRITY OF OUTSOURCED DATA  The investigators addressed the integrity of data stored in a cloud service. They developed several efficient schemes for implementing authenticated data structures, which provide cryptographic proofs that their answers are as accurate as the author intended, even if the data structure is maintained by a remote host. The PI and co-investigators presented techniques for authenticating data structures that represent points, key-value pairs, graphs, and collections of geometric objects. In this model, a data structure maintained by a trusted source is mirrored at distributed directories that answer queries and provide proof of correctness. This work has applications to the authentication of network management systems and geographic information systems.  MEASURING PRIVACY RISKS FOR OUTSOURCED DATA  The team studied quantitative measures for characterizing the privacy risks of data that is stored in outsourced repositories in the cloud and queried using a simple query-response interface. They identified and mathematically analyzed a group of attacks, known as Mastermind algorithms, for attacking the privacy of an entire database, through database cloning, which could consist, for example, of queries involving character strings or vectors, such as DNA strings, movie ratings, or social network friendship data. Based on reductions to group testing, the PI and co-investigators showed that it is possible for an attacker to take advantage of minimal amounts of privacy leakage, such as contained in a single bit that indicates if two people in a medical database have any common genetic mutations, or if two people have any common friends in an online social network. They analyzed Mastermind attack algorithms using theoretical characterizations that provide sublinear bounds on the number of queries needed to clone the database, as well as experimental tests on genomic information, collaborative filtering data, and online social networks. The quantitative knowledge that this work provided gives a tool to people to be able to guage the privacy of their data, such as friendship ties in social networks, when they store this data on websites that allow others to issue similarity queries.             Last Modified: 03/02/2016       Submitted by: Michael T Goodrich]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
