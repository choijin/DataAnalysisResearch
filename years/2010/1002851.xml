<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Major:  CAIRA - A Creative Artificially-Intuitive and Reasoning Agent in the Context of Ensemble Music Improvisation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>650000.00</AwardTotalIntnAmount>
<AwardAmount>650000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to engineer the Creative Artificially-Intuitive and Reasoning Agent CAIRA, an intelligent computer system designed for making decisions and producing creative work based on both reasoning and intuition ? the latter being the process of making a spontaneous decision when there is not sufficient time for reasoning. A network of humans and several CAIRA agents will be formed and studied to provide new understanding of learning and social interaction in dynamic environments where boundary conditions change over time and decisions have to be made within a given time interval. The project will use improvised avant-garde music to study the performance of the intelligent agent, but the outcome will be applicable to other time-based communication scenarios that require creative solutions and intelligent agents that can communicate naturally, as humans do. The machine listening abilities of CAIRA will be based on a music recognition system that simulates the human auditory periphery to perform an Auditory Scene Analysis (ASA), the process by which the auditory system extracts features such as pitch, timbre, and rhythm to organize sound into perceptually meaningful units. The simulation of cognitive processes will include a comprehensive cognitive calculus for reasoning and decision-making, and the system will also possess metareasoning, that is, an entity's ability to reflect upon its own reasoning. CAIRA's capacity for metareasoning will provide groundbreaking insight into the human willingness to systematically break rules and weigh the consequences in order to achieve a given goal, for example, to produce creative work. A machine correlate to human intuition will be another key component of CAIRA, and a major goal is to find out how different balances of reasoning and metareasoning on the one hand, and intuitive decisions, on the other hand, will lead to novel and captivating forms of creativity. &lt;br/&gt;&lt;br/&gt;Broader Impact: Based on a unique interdisciplinary approach between scientists and artists, and also engaging students from engineering and other fields in project-related courses, the project will help to better understand the process of artistic creation as a product of balancing different sources of creativity (e.g., rule-based reasoning approaches vs. intuitive decision-making). The general architecture of CAIRA will be useful for various musical applications, including automated composition systems and internet-based music performances with co-located ensembles. CAIRA will also provide an enhanced interaction with creative machines that will allow non-specialists and ability-impaired users to engage in expressive musical creation. Two examples include CAIRA's ability to automatically add musical texture or an accompaniment to a simple melody or to serve as a duet partner.  Beyond this, the model will further our understanding of the human mind's ability to balance creative decisions based on spontaneity and immediate perception of an environment, to factor in environmental and social context, and to consider past training and learned stylistic rules in the creative process. This understanding will be applicable to similar complex problems, such as economic systems and semantic web services, as well as other problems where creative and timely solutions and/or natural human/computer communication are essential.</AbstractNarration>
<MinAmdLetterDate>07/20/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1002851</AwardID>
<Investigator>
<FirstName>Selmer</FirstName>
<LastName>Bringsjord</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Selmer C Bringsjord</PI_FULL_NAME>
<EmailAddress>selmer@rpi.edu</EmailAddress>
<PI_PHON>5182768105</PI_PHON>
<NSF_ID>000173136</NSF_ID>
<StartDate>07/20/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Pauline</FirstName>
<LastName>Oliveros</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pauline Oliveros</PI_FULL_NAME>
<EmailAddress>olivep@rpi.edu</EmailAddress>
<PI_PHON>5182766000</PI_PHON>
<NSF_ID>000367988</NSF_ID>
<StartDate>07/20/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jonas</FirstName>
<LastName>Braasch</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonas Braasch</PI_FULL_NAME>
<EmailAddress>braasj@rpi.edu</EmailAddress>
<PI_PHON>5182763864</PI_PHON>
<NSF_ID>000186127</NSF_ID>
<StartDate>07/20/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002430742</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RENSSELAER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002430742</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rensselaer Polytechnic Institute]]></Name>
<CityName>Troy</CityName>
<StateCode>NY</StateCode>
<ZipCode>121803522</ZipCode>
<StreetAddress><![CDATA[110 8TH ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7788</Code>
<Text>CreativeIT</Text>
</ProgramElement>
<ProgramReference>
<Code>7788</Code>
<Text>CreativeIT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~650000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The scope of this project was to develop CAIRA, a Creative Artificially-Intuitive and Reasoning Agent. CAIRA is a computer-based system that listens to other musical performers and improvises music based on what the other musicians play. Our goal was to better understand human creativity and to apply this understanding to machines. To achieve this goal, we simulated several functional brain stages related to auditory processing and decision making. To this purpose, we developed an architecture with four functional layers. At the bottom layer, CAIRA performs an auditory scene analysis to extract basic musical features including pitch, tempo, and loudness. In the second layer,&nbsp; machine learning tools&nbsp; analyze sequences of events so CAIRA can make use of the time-based structure of music to, for example, capture melodies. Twotechniques, Emprical Mode Decomposition and Hidden Markov Models, were used for this process. It was important to us that CAIRA analyzed music from actual sound and not through a symbolic notation like a music score. We also incorporated features of Pauline Oliveros&rsquo; Deep Listening Practice into the learning algorithm to enable the CAIRA to discriminate between global and focal listening.</p> <p><br />CAIRA&rsquo;s third layer resembles aspects of human cognition. Here, it was important to us to enable CAIRA to select between different strategies. CAIRA can reason using the logic-based musical calculus of HANDLE to make decisions, but also employs artificial intuition in its&nbsp; musical performance. CAIRA can trade both techniques off each other to perform in different ways, giving insight into how humans develop different performance styles based on internal strategies. We could demonstrate that CAIRA benefitted from using artificial intuition in cases where it had insufficient time for reasoning to respond to other musicians. A sub version of CAIRA, FILTER &ndash; the Freely Improvising, Learning and Transforming Evolutionary Recombination system &ndash;&nbsp; simulates a highly intuitive approach to music improvisation building on Pauline Oliveros' Deep Listening Practice. In instances CAIRA uses the fundamentals of jazz theory to accompany a human soloist or perform with two musicians in a jazz. The fourth layer is the output stage of CAIRA.&nbsp; The system&rsquo;s performance is based on a database of audio samples that CAIRA uses to create its own compositions to perform with others. CAIRA can also conduct an ensemble using an adaptive video score.</p> <p><br />CAIRA and FILTER have been featured in concerts and recordings including New Interfaces for the Musical Expression (NIME) 2012, Eyebeam, New York City, 2014, and the Deep Listening Conference, Troy, New York 2013.<br /><br /><br /><br /><br /><br /><br /></p><br> <p>            Last Modified: 10/23/2014<br>      Modified by: Jonas&nbsp;Braasch</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2014/1002851/1002851_10018856_1414095681138_CAIRAarchitecture--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/1002851/1002851_10018856_1414095681138_CAIRAarchitecture--rgov-800width.jpg" title="Caira Architecture"><img src="/por/images/Reports/POR/2014/1002851/1002851_10018856_1414095681138_CAIRAarchitecture--rgov-66x44.jpg" alt="Caira Architecture"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Main Architecture of CAIRA</div> <div class="imageCredit">Jonas Braasc...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The scope of this project was to develop CAIRA, a Creative Artificially-Intuitive and Reasoning Agent. CAIRA is a computer-based system that listens to other musical performers and improvises music based on what the other musicians play. Our goal was to better understand human creativity and to apply this understanding to machines. To achieve this goal, we simulated several functional brain stages related to auditory processing and decision making. To this purpose, we developed an architecture with four functional layers. At the bottom layer, CAIRA performs an auditory scene analysis to extract basic musical features including pitch, tempo, and loudness. In the second layer,  machine learning tools  analyze sequences of events so CAIRA can make use of the time-based structure of music to, for example, capture melodies. Twotechniques, Emprical Mode Decomposition and Hidden Markov Models, were used for this process. It was important to us that CAIRA analyzed music from actual sound and not through a symbolic notation like a music score. We also incorporated features of Pauline OliverosÆ Deep Listening Practice into the learning algorithm to enable the CAIRA to discriminate between global and focal listening.   CAIRAÆs third layer resembles aspects of human cognition. Here, it was important to us to enable CAIRA to select between different strategies. CAIRA can reason using the logic-based musical calculus of HANDLE to make decisions, but also employs artificial intuition in its  musical performance. CAIRA can trade both techniques off each other to perform in different ways, giving insight into how humans develop different performance styles based on internal strategies. We could demonstrate that CAIRA benefitted from using artificial intuition in cases where it had insufficient time for reasoning to respond to other musicians. A sub version of CAIRA, FILTER &ndash; the Freely Improvising, Learning and Transforming Evolutionary Recombination system &ndash;  simulates a highly intuitive approach to music improvisation building on Pauline Oliveros' Deep Listening Practice. In instances CAIRA uses the fundamentals of jazz theory to accompany a human soloist or perform with two musicians in a jazz. The fourth layer is the output stage of CAIRA.  The systemÆs performance is based on a database of audio samples that CAIRA uses to create its own compositions to perform with others. CAIRA can also conduct an ensemble using an adaptive video score.   CAIRA and FILTER have been featured in concerts and recordings including New Interfaces for the Musical Expression (NIME) 2012, Eyebeam, New York City, 2014, and the Deep Listening Conference, Troy, New York 2013.              Last Modified: 10/23/2014       Submitted by: Jonas Braasch]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
