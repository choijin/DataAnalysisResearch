<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Reinventing Smartphones for Sensing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>498000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The driving vision of this NSF CAREER project is a smartphone that can see, hear, and feel and therefore serve the user continuously.   Smartphones have embraced a variety of sensors, such as cameras, microphones, accelerometers, GPS, and more. An emerging, important category of smartphone applications requires the use of sensors to learn about the physical world and the human user, often in the background without user engagement. However, existing and emerging smartphone platforms are fundamentally flawed for such sensing applications: they adopt a centralized processing model that always uses the increasingly powerful central processor, even for very simple tasks, in particular sensor data processing. This model leads to unacceptable battery lifetime when a smartphone senses frequently.&lt;br/&gt;&lt;br/&gt;To address this fundamental flaw, this project targets at reinventing the smartphone platform by adopting a heterogeneous, distributed processing model that incorporates weak processors for simple, frequent tasks. The research has three objectives: (i) Relieve developers from dealing with the heterogeneous, distributed processing model with runtime and compiler support; (ii) Support efficient and secure execution for third-party applications that use heterogeneous, distributed resources; (iii) Provide optimized design and realization of the envisioned heterogeneous smartphone hardware, including both board and chip integrations. While the project has a focus on smartphone-like systems, the research results are expected to support general embedded systems with heterogeneous, distributed resources. The research project also provides a multidisciplinary platform to realize the educational objectives of developing system and experimental components for mobile embedded computing curriculum, involving undergraduate students in publishable research, and promoting science and engineering studies to high-school students and to groups underrepresented in these areas.</AbstractNarration>
<MinAmdLetterDate>01/26/2011</MinAmdLetterDate>
<MaxAmdLetterDate>05/13/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1054693</AwardID>
<Investigator>
<FirstName>Lin</FirstName>
<LastName>Zhong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lin Zhong</PI_FULL_NAME>
<EmailAddress>lin.zhong@yale.edu</EmailAddress>
<PI_PHON>2034369450</PI_PHON>
<NSF_ID>000189041</NSF_ID>
<StartDate>01/26/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050299031</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WILLIAM MARSH RICE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050299031</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[William Marsh Rice University]]></Name>
<CityName>Houston</CityName>
<StateCode>TX</StateCode>
<ZipCode>770051827</ZipCode>
<StreetAddress><![CDATA[6100 MAIN ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~106000</FUND_OBLG>
<FUND_OBLG>2012~90000</FUND_OBLG>
<FUND_OBLG>2013~196000</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<FUND_OBLG>2015~90000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The driving vision of this project is a smartphone that can see, hear, and feel and therefore serve the user continuously. The research results enable a mobile platform with heterogeneous, distributed computing resources for processing sensor data and operating system support that allows application developers easily tap into their efficiency.</p> <p>The most important results include the following three amonst many others. (1) A novel shared-most operating system architecture that allows software running on distributed resources to share states without hardware cache-coherence. This architecture empowers mobile applications to transparently benefit from the high energy efficiency provided by micro controller cores available on modern mobile systems. (2) A novel virtualization technology that allows one mobile system to access the sensors from another as if they were local. This technology not only enables existing mobile applications to be used in a novel way, but also makes a new category of mobile applications possible that leverages sensors from multiple devices. (3) A complete rethinking of the system stack for computer vision on mobile systems from application framework to operating system and to image sensing hardware. The research results deliver at least two orders of magnitude improvement in energy efficiency and promise new directions toward addressing privacy and security concerns of computer vision from a wearable device.&nbsp;</p> <p><br />The research from this project leads to numerous publications, including three that receive best paper awards from the top venues of its areas, i.e., MobiSys 2013, ASPLOS 2014 and MobiSys 2014. All source code produced by this project has been made publicly available.</p> <p><br />Over the five years, the project provides an educational and training platforms for multiple graduate students, undergraduate students and several local high-school students. Notably three of the graduate students supported by this project have joined faculty at top research universities and most of the undergraduate students went on to pursue a graduate degree. The project additionally provides materials for an undergraduate-level mobile and embedded systems course created and grown by the PI at Rice University.&nbsp;</p> <p><br />By significantly improving the energy efficiency of sensing-based applications without sacrificing developer productivity, the project provides the architectural and systems foundations for novel uses by mobile applications of sensors that are increasingly available on mobile systems. It makes applications aiming at helping people with sensory impairment feasible and practical. As mobile systems have become the primary information access platform for all walks of life, especially people from underserved communities, the socioeconomic impact of this project is likely to be broad and deep.&nbsp;</p><br> <p>            Last Modified: 10/01/2016<br>      Modified by: Lin&nbsp;Zhong</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The driving vision of this project is a smartphone that can see, hear, and feel and therefore serve the user continuously. The research results enable a mobile platform with heterogeneous, distributed computing resources for processing sensor data and operating system support that allows application developers easily tap into their efficiency.  The most important results include the following three amonst many others. (1) A novel shared-most operating system architecture that allows software running on distributed resources to share states without hardware cache-coherence. This architecture empowers mobile applications to transparently benefit from the high energy efficiency provided by micro controller cores available on modern mobile systems. (2) A novel virtualization technology that allows one mobile system to access the sensors from another as if they were local. This technology not only enables existing mobile applications to be used in a novel way, but also makes a new category of mobile applications possible that leverages sensors from multiple devices. (3) A complete rethinking of the system stack for computer vision on mobile systems from application framework to operating system and to image sensing hardware. The research results deliver at least two orders of magnitude improvement in energy efficiency and promise new directions toward addressing privacy and security concerns of computer vision from a wearable device.    The research from this project leads to numerous publications, including three that receive best paper awards from the top venues of its areas, i.e., MobiSys 2013, ASPLOS 2014 and MobiSys 2014. All source code produced by this project has been made publicly available.   Over the five years, the project provides an educational and training platforms for multiple graduate students, undergraduate students and several local high-school students. Notably three of the graduate students supported by this project have joined faculty at top research universities and most of the undergraduate students went on to pursue a graduate degree. The project additionally provides materials for an undergraduate-level mobile and embedded systems course created and grown by the PI at Rice University.    By significantly improving the energy efficiency of sensing-based applications without sacrificing developer productivity, the project provides the architectural and systems foundations for novel uses by mobile applications of sensors that are increasingly available on mobile systems. It makes applications aiming at helping people with sensory impairment feasible and practical. As mobile systems have become the primary information access platform for all walks of life, especially people from underserved communities, the socioeconomic impact of this project is likely to be broad and deep.        Last Modified: 10/01/2016       Submitted by: Lin Zhong]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
