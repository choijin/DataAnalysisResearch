<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: RI: Small: Efficient Privacy Methods Using Linear Programming</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>499274.00</AwardTotalIntnAmount>
<AwardAmount>499274</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In today's information-centric networked world, concerns about protecting identities and other private information are growing in importance. It is important to establish not only a legal baseline but also a technological baseline that protects such information.  At the same time, data search and analysis technologies are emerging that are capable of processing extremely large volumes of information. As a result, research is needed into data analysis technologies that enhance privacy and protect private information in a computationally efficient manner.  One important area of technology that supports data analysis is optimization, a set of procedures that make a system as efficient as possible. Solving optimization problems efficiently has been one of the major themes of computer science throughout the history of the field. Unfortunately many optimization problems that need to be solved in practice are unlikely to have efficient algorithmic solutions. To cope with this difficulty, computer scientists have developed numerous practical approximation algorithms along with general techniques for designing such algorithms. Often the optimization problems that need to be solved arise from the analysis of real data with potential privacy restrictions.  Importantly, there are no known general tools to design approximation algorithms which are both efficient and provably private.&lt;br/&gt;&lt;br/&gt;As an initial case study, community discovery in social network analysis will be studied. It is a natural candidate for private approximation for two reasons: first, the underlying social network data in many cases can be sensitive; second, community structure should not depend crucially on any single relation in the network, and, therefore, it should be possible to find a private community discovery algorithm with good utility. The intellectual merit of the project is in the research required to develop general methods for designing efficient differentially private approximation algorithms for combinatorial optimization problems. The project's broader impacts include applications in real-world law enforcement and counterterrorism.</AbstractNarration>
<MinAmdLetterDate>07/31/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1018445</AwardID>
<Investigator>
<FirstName>Rebecca</FirstName>
<LastName>Wright</LastName>
<PI_MID_INIT>N</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rebecca N Wright</PI_FULL_NAME>
<EmailAddress>rwright@barnard.edu</EmailAddress>
<PI_PHON>2128530219</PI_PHON>
<NSF_ID>000099098</NSF_ID>
<StartDate>07/31/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>William</FirstName>
<LastName>Pottenger</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>William M Pottenger</PI_FULL_NAME>
<EmailAddress>billp@dimacs.rutgers.edu</EmailAddress>
<PI_PHON>6109843381</PI_PHON>
<NSF_ID>000340712</NSF_ID>
<StartDate>07/31/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName>Piscataway</CityName>
<StateCode>NJ</StateCode>
<ZipCode>088543925</ZipCode>
<StreetAddress><![CDATA[33 Knightsbridge Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~499274</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In today's information-centric networked world, concerns about protecting identities and other private information are growing in importance. It is important to establish not only a legal baseline but also a technological baseline that protects such information. At the same time, data search and analysis technologies are emerging that are capable of processing extremely large volumes of information. As a result, data analysis technologies should incorporate privacy and protect private information in a computationally efficient manner. Differential privacy has emerged as a useful mathematical definition of privacy, along with a variety of methods for provably providing differential privacy in different contexts as well as surprising connections to other areas such as learning theory.&nbsp; One important area of technology that supports data analysis is optimization, a set of procedures that make a system as efficient as possible. Solving optimization problems efficiently has been one of the major themes of computer science throughout the history of the field. This project advanced the understanding and application of differential privacy, the state of the art in optimization methods, and the ability to achieve the two together.</p> <p>Project research resulted in a theoretical framework for a differentially private mechanism that provides privacy and utility for a large class of combinatorial optimization problems, including set cover, shortest path, minimum vertex cover, maximum matching, minimum cut, graph clustering, etc. In particular, we considered differential privacy for combinatorial optimization problems whose input can be represented by a matrix of 0-1 entries for which a &ldquo;neighbor&rdquo; relationship based on changing a single entry makes sense.&nbsp; (In the case of adjacency matrices for graphs this corresponds to the existing notion of &ldquo;edge privacy&rdquo;.)&nbsp; We provide a novel solution for probabilistic differential privacy for such problems.&nbsp; The solution can also make use of approximation algorithms to improve efficiency with a potential degradation in utility while maintaining privacy.&nbsp; Unlike existing differential privacy solutions, our solution does not depend on the &ldquo;global sensitivity&rdquo; of the underlying problem.&nbsp; We have experimentally validated the efficiency and utility of our approach for a variety of combinatorial and graph problems.</p> <p>Project results also include DP-WHERE, an application of differential privacy to human mobility modeling. &nbsp;Models of human mobility have broad applicability in urban planning, ecology, epidemiology, and other fields.&nbsp; Starting with Call Detail Records (CDRs) from a cellular&nbsp;telephone network that have gone through a straightforward anonymization procedure, the prior WHERE modeling approach produces synthetic CDRs for a synthetic&nbsp;population. &nbsp;The accuracy of WHERE has been validated against billions of location samples for hundreds of thousands of cell phones in the New York and Los Angeles metropolitan areas.&nbsp; DP-WHERE provides provable privacy guarantees by modifying WHERE to be differentially private.&nbsp; Experimental analysis for a large New York City data set examined the accuracy/privacy tradeoff for DP-WHERE relative to WHERE and of real CDRs.&nbsp; This work shows the feasibility for the creation and possible release of synthetic models that capture the&nbsp;mobility patterns of real metropolitan populations while preserving privacy.</p> <p>Project research focused on the development of SemRel, a novel Probabilistic Graphical Model for the discovery of semantic relations in text and a novel approach to preserve entities' privacy. The&nbsp;model improves the interpretability of topic models by using a richer relational&nbsp;feature space, but without jeopardizing the privacy of the entities and relations involved. In contra...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In today's information-centric networked world, concerns about protecting identities and other private information are growing in importance. It is important to establish not only a legal baseline but also a technological baseline that protects such information. At the same time, data search and analysis technologies are emerging that are capable of processing extremely large volumes of information. As a result, data analysis technologies should incorporate privacy and protect private information in a computationally efficient manner. Differential privacy has emerged as a useful mathematical definition of privacy, along with a variety of methods for provably providing differential privacy in different contexts as well as surprising connections to other areas such as learning theory.  One important area of technology that supports data analysis is optimization, a set of procedures that make a system as efficient as possible. Solving optimization problems efficiently has been one of the major themes of computer science throughout the history of the field. This project advanced the understanding and application of differential privacy, the state of the art in optimization methods, and the ability to achieve the two together.  Project research resulted in a theoretical framework for a differentially private mechanism that provides privacy and utility for a large class of combinatorial optimization problems, including set cover, shortest path, minimum vertex cover, maximum matching, minimum cut, graph clustering, etc. In particular, we considered differential privacy for combinatorial optimization problems whose input can be represented by a matrix of 0-1 entries for which a "neighbor" relationship based on changing a single entry makes sense.  (In the case of adjacency matrices for graphs this corresponds to the existing notion of "edge privacy".)  We provide a novel solution for probabilistic differential privacy for such problems.  The solution can also make use of approximation algorithms to improve efficiency with a potential degradation in utility while maintaining privacy.  Unlike existing differential privacy solutions, our solution does not depend on the "global sensitivity" of the underlying problem.  We have experimentally validated the efficiency and utility of our approach for a variety of combinatorial and graph problems.  Project results also include DP-WHERE, an application of differential privacy to human mobility modeling.  Models of human mobility have broad applicability in urban planning, ecology, epidemiology, and other fields.  Starting with Call Detail Records (CDRs) from a cellular telephone network that have gone through a straightforward anonymization procedure, the prior WHERE modeling approach produces synthetic CDRs for a synthetic population.  The accuracy of WHERE has been validated against billions of location samples for hundreds of thousands of cell phones in the New York and Los Angeles metropolitan areas.  DP-WHERE provides provable privacy guarantees by modifying WHERE to be differentially private.  Experimental analysis for a large New York City data set examined the accuracy/privacy tradeoff for DP-WHERE relative to WHERE and of real CDRs.  This work shows the feasibility for the creation and possible release of synthetic models that capture the mobility patterns of real metropolitan populations while preserving privacy.  Project research focused on the development of SemRel, a novel Probabilistic Graphical Model for the discovery of semantic relations in text and a novel approach to preserve entities' privacy. The model improves the interpretability of topic models by using a richer relational feature space, but without jeopardizing the privacy of the entities and relations involved. In contrast to the previously used Gibbs sampling, we derived algorithms for stochastic variational inference, which can be learned online and  thus scale to larger datasets. We also laid the theoretical founda...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
