<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Bio-Inspired Smart Sensor Networks for Adaptive Emergency Response</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2010</AwardEffectiveDate>
<AwardExpirationDate>05/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Daniel Katz</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Recent seismic calamities in Pakistan (&gt;79,000 deaths), China (&gt;68,000 deaths), and Haiti (&gt;170,000 deaths) have demonstrated the tremendous vulnerability of civil infrastructure, as well as the need for improved emergency response. What is not widely known is that disasters of this magnitude could occur in the USA: recent studies estimate that a major rupture along the New Madrid fault could result in casualties exceeding 70,000 in Tennessee and Missouri alone.  Combining techniques from civil engineering, computer science, and neurobiology, this research seeks to transform the effectiveness of emergency response personnel in dealing with such disasters--ensuring rapid assessment of the stability of physical structures, location and rescue of trapped and non-ambulatory victims, identification and provision of emergency medical treatment, and safe evacuation of ambulatory survivors. &lt;br/&gt;&lt;br/&gt;This research focuses on developing a bio-inspired smart sensing and communications framework for rapid emergency response. The system utilizes enhanced mobile phone technology to create a neurally-informed, sensor-rich, information-processing network. The research builds on the similarities in biological systems and adaptive sensing and communication frameworks.  Like biological neurons, each cell phone node has both communication and computation capabilities. Individual nodes are capable of establishing local connections with their neighbors through ad-hoc networking (much as neurons connect with synapses), as well as longer-distance global communication via cell tower infrastructure (similar to diffuse neuromodulatory and neuroendocrine signaling). Cell phones also have a variety of sensor input capabilities (e.g. sound, video, motion sensing, and GPS) that have parallels with the sensory capabilities of biological systems. These analogies facilitate translation of information processing principles from neurobiology to engineering implementations for efficient acquisition, filtering and transmission of task-relevant information in emergency response scenarios.</AbstractNarration>
<MinAmdLetterDate>05/28/2010</MinAmdLetterDate>
<MaxAmdLetterDate>05/28/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1030454</AwardID>
<Investigator>
<FirstName>Billie</FirstName>
<LastName>Spencer</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME>Jr.</PI_SUFX_NAME>
<PI_FULL_NAME>Billie F Spencer</PI_FULL_NAME>
<EmailAddress>bfs@illinois.edu</EmailAddress>
<PI_PHON>2173338630</PI_PHON>
<NSF_ID>000303677</NSF_ID>
<StartDate>05/28/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gul</FirstName>
<LastName>Agha</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gul A Agha</PI_FULL_NAME>
<EmailAddress>agha@cs.uiuc.edu</EmailAddress>
<PI_PHON>2172443087</PI_PHON>
<NSF_ID>000461849</NSF_ID>
<StartDate>05/28/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Nelson</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark E Nelson</PI_FULL_NAME>
<EmailAddress>m-nelson@uiuc.edu</EmailAddress>
<PI_PHON>2172441371</PI_PHON>
<NSF_ID>000409146</NSF_ID>
<StartDate>05/28/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207406</ZipCode>
<StreetAddress><![CDATA[1901 South First Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7684</Code>
<Text>CESER-Cyberinfrastructure for</Text>
</ProgramElement>
<ProgramReference>
<Code>7684</Code>
<Text>STRATEGIC TECHNOLOGIES FOR CI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>7969</Code>
<Text>FY 2010 Funding for PTR</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>When an earthquake strikes, many people may be trapped inside damaged buildings. &nbsp;However, the vitims may not be in a position to contact rescue workers: they may be disabled or the network may be overwhelmed.&nbsp; When first responders arrive at the scene, they will not have detailed information about the status and location of the victims. &nbsp;We developed &ldquo;iRescue&rdquo;, an emergency rescue smart phone application which can help victims trapped inside buildings following a major disaster. After a disaster, the iRescue application would start asking questions about the user&rsquo;s condition. &ldquo;Are you hurt?&rdquo; &ldquo;Are you trapped?&rdquo; If the user is unconscious and unable to answer these questions, the application will automatically estimate the status of the user based on data collected from motion sensors in the phone. Also, the application will determine the location of the victim and send this information together with the status of the user to the first responders.&nbsp; Such information can help first responders organize a quick and efficient rescue operation.</p> <p>iRescue (Illinois Rescue System) comprises 3 main components: iVAS (Illinois Victim Assessment System), iVPS(Illinois Victim Positioning System) and iVES (Illinois Victim Evacuation System).</p> <ul> <li>&nbsp;iVAS (Illinois Victim Assessment System)</li> </ul> <p>iVAS assesses the status of victims in order to help first responders plan for appropriate medical treatment and prioritize victims for evacuation.&nbsp; In order quickly and efficiently assess the status of potentially hundreds or thousands of victims in this situation, two victim assessment systems were developed: (1) Active Victim Assessment System, an automated system to quickly collect useful status information from conscious victims by responding to a series of on-screen questions, and (2) Passive Victim Assessment System, which assesses the status of individuals by using sensors inside their smartphone, without requiring input or interaction from the user.</p> <ul> <li>Active Victim Assessment System (AVAS)</li> </ul> <p>AVAS enables first responders to communicate with the victims inside a building, and also assess the status of victims by asking questions via smartphones. The questions are selected by first responders according type of disaster and emergency, and could be answered simply by selecting either &ldquo;yes&rdquo; or &ldquo;no&rdquo; button so that even injured victim could easily transmit their current situation to first responders. However this system could not be work for victims those are unconscious, or who are occupied with other tasks during the emergency event, or who are not aware of this application running their smartphone. (See Figure 1 in images)</p> <ul> <li>Passive Victim Assessment System (PVAS)</li> </ul> <p>Since AVAS can&nbsp; only return status information for a limited subset of victims who respond to the prompts, PVAS was developed to assess the status of victims even when unconscious or unresponsive to the prompts. PVAS runs in the background of the phone so no action needs to be taken by the victims. The system assesses the status of the victims by collecting real-time data from sensors that are built into the smartphone, such as accelerometer, gyroscope, magnetic field, and proximity sensors. Using these data, PVAS is able to successfully recognize seven different types of activities including walking, running, standing, rolling, sitting/laying, calling, and texting using pattern recognition tools and updates every 6.4 seconds. Estimated activity classes are further grouped into ambulatory, non-ambulatory and unconscious categories to aid first responders in coordinating evacuation and rescue efforts. (See Figure 2 in images)</p> <p>&nbsp;</p> <ul> <li>&nbsp; iVPS(Illinois Victim Positioning System)</li> </ul> <p>iVPS relies on wireless signals to find the loc...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ When an earthquake strikes, many people may be trapped inside damaged buildings.  However, the vitims may not be in a position to contact rescue workers: they may be disabled or the network may be overwhelmed.  When first responders arrive at the scene, they will not have detailed information about the status and location of the victims.  We developed "iRescue", an emergency rescue smart phone application which can help victims trapped inside buildings following a major disaster. After a disaster, the iRescue application would start asking questions about the userÆs condition. "Are you hurt?" "Are you trapped?" If the user is unconscious and unable to answer these questions, the application will automatically estimate the status of the user based on data collected from motion sensors in the phone. Also, the application will determine the location of the victim and send this information together with the status of the user to the first responders.  Such information can help first responders organize a quick and efficient rescue operation.  iRescue (Illinois Rescue System) comprises 3 main components: iVAS (Illinois Victim Assessment System), iVPS(Illinois Victim Positioning System) and iVES (Illinois Victim Evacuation System).   iVAS (Illinois Victim Assessment System)   iVAS assesses the status of victims in order to help first responders plan for appropriate medical treatment and prioritize victims for evacuation.  In order quickly and efficiently assess the status of potentially hundreds or thousands of victims in this situation, two victim assessment systems were developed: (1) Active Victim Assessment System, an automated system to quickly collect useful status information from conscious victims by responding to a series of on-screen questions, and (2) Passive Victim Assessment System, which assesses the status of individuals by using sensors inside their smartphone, without requiring input or interaction from the user.  Active Victim Assessment System (AVAS)   AVAS enables first responders to communicate with the victims inside a building, and also assess the status of victims by asking questions via smartphones. The questions are selected by first responders according type of disaster and emergency, and could be answered simply by selecting either "yes" or "no" button so that even injured victim could easily transmit their current situation to first responders. However this system could not be work for victims those are unconscious, or who are occupied with other tasks during the emergency event, or who are not aware of this application running their smartphone. (See Figure 1 in images)  Passive Victim Assessment System (PVAS)   Since AVAS can  only return status information for a limited subset of victims who respond to the prompts, PVAS was developed to assess the status of victims even when unconscious or unresponsive to the prompts. PVAS runs in the background of the phone so no action needs to be taken by the victims. The system assesses the status of the victims by collecting real-time data from sensors that are built into the smartphone, such as accelerometer, gyroscope, magnetic field, and proximity sensors. Using these data, PVAS is able to successfully recognize seven different types of activities including walking, running, standing, rolling, sitting/laying, calling, and texting using pattern recognition tools and updates every 6.4 seconds. Estimated activity classes are further grouped into ambulatory, non-ambulatory and unconscious categories to aid first responders in coordinating evacuation and rescue efforts. (See Figure 2 in images)       iVPS(Illinois Victim Positioning System)   iVPS relies on wireless signals to find the locations of cell phones inside a building. Most buildings, both residential and commercial, typically have one or more wireless Wi-Fi access points that can be leveraged for indoor location tracking.  iVPS has been developed to localize users in indoor areas based on detection of wi...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
