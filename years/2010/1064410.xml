<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>G&amp;V: Medium: Collaborative Research: A Unified Approach to Material Appearance Modeling</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2011</AwardEffectiveDate>
<AwardExpirationDate>05/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>398810.00</AwardTotalIntnAmount>
<AwardAmount>398810</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Realistic image synthesis techniques from computer graphics enable the use of simulation in a wide variety of important fields including architecture, industrial design and communication, military, medical, and emergency training, cultural heritage preservation, film production, and gaming.  Realistic modeling of material appearance is an essential component of the image synthesis process.  Current approaches to material modeling include analytical modeling, numerical simulation, and image-based capture.  Each approach has distinct advantages and limitations, and different ranges of applicability.  The lack of unity makes material modeling difficult and has limited the useful application of computer graphics image synthesis.  This transformative research will change the way materials are modeled in computer graphics systems.  Rather than using disparate models as at present, this project will unify these approaches into a common physical and perceptual framework that will serve as the basis for a rich set of tools for material modeling that are physically accurate, phenomenologically expressive, computationally efficient, and easy to use.  This work should enable the use of computer-aided material design methods in a wide range of economically and culturally important applications.  Creating this framework will involve three subprojects.&lt;br/&gt;&lt;br/&gt;Development of a material simulation testbed:  In this subproject a suite of tools for material simulation will be developed that includes both Monte Carlo and deterministic algorithms.  Different classes of materials (paints, metals, textiles) will be modeled, and different numerical methods will be tested and compared.  The resulting simulation tools and a database of the simulated materials will be distributed.&lt;br/&gt;&lt;br/&gt;Unification of analytical, simulation, and image-based capture material modeling methods:  In this subproject the analytical models that represent general classes of materials will be unified with simulation and image-based capture data that represent specific material instances.  In the first part of this subproject simulation and capture data will be fit with a range of analytical models, considering both individual materials and "families" of materials generated by progressively changing the parameters of the simulation models.  In the second part of this project methods for inferring the microstructures of materials measured using image-based capture methods will be developed.  The approach will be to identify the class of a material and then vary the parameters of an appropriate simulation model to best reproduce the captured data.  The results of this subproject will be expressive and efficient analytical material models that are physically grounded because they are based on captured data and rigorous simulations.&lt;br/&gt;&lt;br/&gt;Development of perceptually-based material design tools:  An important criterion for material modeling is usability.  Material designers need to be able to easily specify and visualize material appearance properties.  This requires consideration of the human factors in material modeling.  In this subproject a series of psychophysical experiments on material perception will be conducted and the results will be used to derive perceptually-based material models with meaningful parameters.  How image properties affect the visual fidelity of rendered materials will also be investigated.  These findings will then be used to develop effective and easy-to-use interfaces for computer-aided material design.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  Better methods for material modeling and rendering will lead to improved capability and productivity in fields such as architecture, industrial design and communication, training, cultural heritage, and entertainment.  The project will build a material appearance community that stretches across academic and commercial boundaries to include computer graphics, computer vision and human vision researchers along with a range of industrial collaborators, and which focuses on developing effective solutions to real-world problems.  The research will engage and train groups of students at 3 universities for scientific/technical careers that require working in interdisciplinary teams and partnering with coworkers in remote locations.</AbstractNarration>
<MinAmdLetterDate>03/22/2011</MinAmdLetterDate>
<MaxAmdLetterDate>04/22/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1064410</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Ferwerda</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James A Ferwerda</PI_FULL_NAME>
<EmailAddress>jaf@cis.rit.edu</EmailAddress>
<PI_PHON>5854754923</PI_PHON>
<NSF_ID>000197349</NSF_ID>
<StartDate>03/22/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rochester Institute of Tech</Name>
<CityName>ROCHESTER</CityName>
<ZipCode>146235603</ZipCode>
<PhoneNumber>5854757987</PhoneNumber>
<StreetAddress>1 LOMB MEMORIAL DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002223642</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ROCHESTER INSTITUTE OF TECHNOLOGY (INC)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002223642</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rochester Institute of Tech]]></Name>
<CityName>ROCHESTER</CityName>
<StateCode>NY</StateCode>
<ZipCode>146235603</ZipCode>
<StreetAddress><![CDATA[1 LOMB MEMORIAL DR]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~100989</FUND_OBLG>
<FUND_OBLG>2012~111941</FUND_OBLG>
<FUND_OBLG>2013~92414</FUND_OBLG>
<FUND_OBLG>2014~93466</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goals of the project G&amp;V: Medium: Collaborative Research: A Unified Approach to Material Appearance Modeling&nbsp; (Federal Award ID: 1064410) were to: &ldquo;Conduct psychophysical studies of material perception and psychophysically-based material models that will be used to develop effective, high fidelity user interfaces for material visualization and design.&rdquo; Specific accomplishments of this project include: 1) psychophysical experiments on material/surface perception and the relations between image quality and surface appearance; 2) the development of novel technologies for 3D surface capture and visualization (tangible imaging systems); and 3) studies to characterize the spatial and chromatic appearance properties of 3D printers. Research findings embodied in 20 publications have been disseminated though journals and professional conferences. Software products have been made available through the Apple App Store. Five graduate students and four undergraduate students have been supported, trained, and several have secured industrial R&amp;D positions. The impacts of this project on the field include: The development and dissemination of novel display technologies for the accurate visualization of materials and surfaces; new knowledge about the properties of material and surface perception; and new knowledge about the interactions of image quality with material/surface appearance rendering. Technology transfer impacts include: use of tangible imaging technologies by both academic and industrial researchers (cultural heritage, paint and coating development, appearance design, softproofing for digital printing); and use of research findings on material perception to inform R&amp;D practices by industrial partners (paints/coatings, glass/display manufacturing, color, and 3D printing). Broader impacts include the free dissemination of tangible imaging technologies through the Apple App Store and science education through public forums and the popular press.</p><br> <p>            Last Modified: 08/01/2016<br>      Modified by: James&nbsp;A&nbsp;Ferwerda</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470059181537_2_TIS_all_1k--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470059181537_2_TIS_all_1k--rgov-800width.jpg" title="tangible imaging systems"><img src="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470059181537_2_TIS_all_1k--rgov-66x44.jpg" alt="tangible imaging systems"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Tangible imaging systems (left to right, top to bottom): The first generation tangiBook system; the tangiView system implemented on a tablet device; the tangiPaint application; and the phantoView 3D application.</div> <div class="imageCredit">James A. Ferwerda</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">James&nbsp;A&nbsp;Ferwerda</div> <div class="imageTitle">tangible imaging systems</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470058916883_1_tangibook_1k--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470058916883_1_tangibook_1k--rgov-800width.jpg" title="The tangiBook: a tangible display system."><img src="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470058916883_1_tangibook_1k--rgov-66x44.jpg" alt="The tangiBook: a tangible display system."></a> <div class="imageCaptionContainer"> <div class="imageCaption">The tangiBook: a tangible display system. Tilting or moving in front of the screen produces realistic changes in surface lighting and material appearance.</div> <div class="imageCredit">James A. Ferwerda</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">James&nbsp;A&nbsp;Ferwerda</div> <div class="imageTitle">The tangiBook: a tangible display system.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470060084671_3_impastor_1k--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470060084671_3_impastor_1k--rgov-800width.jpg" title="ImpastoR: a realistic surface display system."><img src="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470060084671_3_impastor_1k--rgov-66x44.jpg" alt="ImpastoR: a realistic surface display system."></a> <div class="imageCaptionContainer"> <div class="imageCaption">ImpastoR: a realistic surface display system. The top left image shows a real painting (left) and its simulation as rendered by the system. The remaining images show realistic simulations of surface texture, color/illumination and gloss/lighting as rendered by the system.</div> <div class="imageCredit">James A. Ferwerda</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">James&nbsp;A&nbsp;Ferwerda</div> <div class="imageTitle">ImpastoR: a realistic surface display system.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470063061163_4_mustang_1k--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470063061163_4_mustang_1k--rgov-800width.jpg" title="image quality and material appearance"><img src="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470063061163_4_mustang_1k--rgov-66x44.jpg" alt="image quality and material appearance"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Image quality and material appearance: While the quality of the right half-image of is lower than the left, its ability to represent material properties such as the finish of the car and wetness of the concrete is largely the same.</div> <div class="imageCredit">James A. Ferwerda</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">James&nbsp;A&nbsp;Ferwerda</div> <div class="imageTitle">image quality and material appearance</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470063457198_5_3dcolor_1k--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470063457198_5_3dcolor_1k--rgov-800width.jpg" title="Geometric and color characterization of 3D printers"><img src="/por/images/Reports/POR/2016/1064410/1064410_10080084_1470063457198_5_3dcolor_1k--rgov-66x44.jpg" alt="Geometric and color characterization of 3D printers"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Geometric and color characterization of 3D printers. (Top) Modulation transfer function target and measured surface data. (Bottom) Close-up of 3D printed tile and measured pigment concentrations.  These studies were used to build a model of the printer to allow accurate reproduction of 3D surfaces.</div> <div class="imageCredit">James A. Ferwerda</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">James&nbsp;A&nbsp;Ferwerda</div> <div class="imageTitle">Geometric and color characterization of 3D printers</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goals of the project G&amp;V: Medium: Collaborative Research: A Unified Approach to Material Appearance Modeling  (Federal Award ID: 1064410) were to: "Conduct psychophysical studies of material perception and psychophysically-based material models that will be used to develop effective, high fidelity user interfaces for material visualization and design." Specific accomplishments of this project include: 1) psychophysical experiments on material/surface perception and the relations between image quality and surface appearance; 2) the development of novel technologies for 3D surface capture and visualization (tangible imaging systems); and 3) studies to characterize the spatial and chromatic appearance properties of 3D printers. Research findings embodied in 20 publications have been disseminated though journals and professional conferences. Software products have been made available through the Apple App Store. Five graduate students and four undergraduate students have been supported, trained, and several have secured industrial R&amp;D positions. The impacts of this project on the field include: The development and dissemination of novel display technologies for the accurate visualization of materials and surfaces; new knowledge about the properties of material and surface perception; and new knowledge about the interactions of image quality with material/surface appearance rendering. Technology transfer impacts include: use of tangible imaging technologies by both academic and industrial researchers (cultural heritage, paint and coating development, appearance design, softproofing for digital printing); and use of research findings on material perception to inform R&amp;D practices by industrial partners (paints/coatings, glass/display manufacturing, color, and 3D printing). Broader impacts include the free dissemination of tangible imaging technologies through the Apple App Store and science education through public forums and the popular press.       Last Modified: 08/01/2016       Submitted by: James A Ferwerda]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
