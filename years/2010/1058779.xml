<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: RESYST: Resilience via Synergistic Redundancy and Fault Tolerance for High-End Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>376219.00</AwardTotalIntnAmount>
<AwardAmount>376219</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In High-End Computing (HEC), faults have become the norm rather than the exception for parallel computation on clusters with 10s/100s of thousands of cores. As the core count increases, so does the overhead for fault-tolerant techniques relying on checkpoint/restart(C/R) mechanisms. At 50% overheads, redundancy is a viable alternative to fault recovery and actually scales, which makes the approach attractive for HEC.&lt;br/&gt;&lt;br/&gt;The objective of this work to the develop a synergistic approach by combining C/R-based fault tolerance with redundancy in HEC installations to achieve high levels of resilience.&lt;br/&gt;&lt;br/&gt;This work alleviates scalability limitations of current fault tolerant practices. It contributes to fault modeling as well as fault detection and recovery in significantly advancing existing techniques by controlling levels of redundancy and checkpointing intervals in the presence of faults. It is transformative in providing a model where users select a target failure probability at the price of using additional resources.</AbstractNarration>
<MinAmdLetterDate>09/22/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1058779</AwardID>
<Investigator>
<FirstName>Frank</FirstName>
<LastName>Mueller</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Frank Mueller</PI_FULL_NAME>
<EmailAddress>mueller@cs.ncsu.edu</EmailAddress>
<PI_PHON>9195157889</PI_PHON>
<NSF_ID>000484031</NSF_ID>
<StartDate>09/22/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957514</ZipCode>
<StreetAddress><![CDATA[2601 Wolf Village Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~376219</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In High-End Computing (HEC), faults have become the norm rather than<br />the exception for parallel computation on clusters with 10s/100s of<br />thousands of cores. As the core count increases, so does the overhead<br />for fault-tolerant techniques relying on checkpoint/restart (C/R)<br />mechanisms. At 50% overheads, redundancy is a viable alternative to<br />fault recovery and actually scales, which makes the approach<br />attractive for HEC.<br /><br />The objective of this work is to develop a synergistic approach by<br />combining C/R-based fault tolerance with redundancy in HEC<br />installations to achieve high levels of resilience.<br /><br />This work alleviates scalability limitations of current fault tolerant<br />practices. It contributes to fault modeling as well as fault detection<br />and recovery in significantly advancing existing techniques by<br />controlling levels of redundancy and checkpointing intervals in the<br />presence of faults. It is transformative in providing a model where<br />users select a target failure probability at the price of using<br />additional resources.<br /><br />Our work shows that redundancy-based fault tolerance can be used in<br />synergy with checkpoint/restart-based fault tolerance to achieve<br />better application performance for large-scale HPC applications than<br />can be achieved by any of the two techniques alone, which has been<br />analytically modeled and experimentally confirmed.<br /><br />We further assessed the feasibility and effectiveness of SDC detection<br />and correction at the MPI layer via redundancy.&nbsp; We develped two<br />consistency protocols, explored the unique challenges in creating a<br />deterministic MPI environment for replication purposes, investigated<br />the effects of fault injection in to our framework, analyzed the<br />costs and showed the benefits of SDC protection via redundancy.<br /><br />We also studied Single Event Upsets (SEUs) in floating-point data. We<br />show that SEUs produce predictable, non-uniform errors that can be<br />bounded using analytical modeling of perturbed dot-products for<br />elementary linear algebra constructs, and by analyzing convergence<br />theory of first-order (stationary) iterative linear solvers.<br />Convergence for stationary iterative methods is provable, and the<br />performance impact (increased iteration count) of an SEU in data is<br />predictable with low error.</p><br> <p>            Last Modified: 11/10/2016<br>      Modified by: Frank&nbsp;Mueller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In High-End Computing (HEC), faults have become the norm rather than the exception for parallel computation on clusters with 10s/100s of thousands of cores. As the core count increases, so does the overhead for fault-tolerant techniques relying on checkpoint/restart (C/R) mechanisms. At 50% overheads, redundancy is a viable alternative to fault recovery and actually scales, which makes the approach attractive for HEC.  The objective of this work is to develop a synergistic approach by combining C/R-based fault tolerance with redundancy in HEC installations to achieve high levels of resilience.  This work alleviates scalability limitations of current fault tolerant practices. It contributes to fault modeling as well as fault detection and recovery in significantly advancing existing techniques by controlling levels of redundancy and checkpointing intervals in the presence of faults. It is transformative in providing a model where users select a target failure probability at the price of using additional resources.  Our work shows that redundancy-based fault tolerance can be used in synergy with checkpoint/restart-based fault tolerance to achieve better application performance for large-scale HPC applications than can be achieved by any of the two techniques alone, which has been analytically modeled and experimentally confirmed.  We further assessed the feasibility and effectiveness of SDC detection and correction at the MPI layer via redundancy.  We develped two consistency protocols, explored the unique challenges in creating a deterministic MPI environment for replication purposes, investigated the effects of fault injection in to our framework, analyzed the costs and showed the benefits of SDC protection via redundancy.  We also studied Single Event Upsets (SEUs) in floating-point data. We show that SEUs produce predictable, non-uniform errors that can be bounded using analytical modeling of perturbed dot-products for elementary linear algebra constructs, and by analyzing convergence theory of first-order (stationary) iterative linear solvers. Convergence for stationary iterative methods is provable, and the performance impact (increased iteration count) of an SEU in data is predictable with low error.       Last Modified: 11/10/2016       Submitted by: Frank Mueller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
