<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Spectral Methods for Learning Time Series and Graphical Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>224998.00</AwardTotalIntnAmount>
<AwardAmount>224998</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
<PO_EMAI>tleen@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The investigators study a new class of statistical methods for learning time series and graphical models. Their approach is based on spectral analysis and matrix decomposition methods that have enjoyed tremendous success in applications, but their use in graphical models has drawn less attention. The goal of this investigation is to extend the enormous previous successes of matrix decomposition methods to the realm of more complicated time series and certain graphical models, which will lead to new statistical machine learning algorithms with important practical applications.&lt;br/&gt;&lt;br/&gt;In the information age, an important measure of computer intelligence is the ability to analyze huge amount of data that become available electronically, and make critical decisions under uncertain environment. Statistical machine learning is the main technique for analyzing electronic data, and graphical models are mathematical tools for understanding these complex data both by computer systems and by human operators in order to facilitate decision making. However, traditional algorithms for learning graphical models have limitations that restrict capabilities of modern computing systems. The current research attempts a new class of mathematical algorithms that can be used to design more effective graphical models, which in turn allows modern computers to analyze data more accurately and achieve higher level of intelligence.</AbstractNarration>
<MinAmdLetterDate>08/07/2010</MinAmdLetterDate>
<MaxAmdLetterDate>03/15/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1018651</AwardID>
<Investigator>
<FirstName>Dean</FirstName>
<LastName>Foster</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dean P Foster</PI_FULL_NAME>
<EmailAddress>dean@foster.net</EmailAddress>
<PI_PHON>2158988233</PI_PHON>
<NSF_ID>000228963</NSF_ID>
<StartDate>03/15/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sham</FirstName>
<LastName>Kakade</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sham Kakade</PI_FULL_NAME>
<EmailAddress>sham@cs.washington.edu</EmailAddress>
<PI_PHON>2065439344</PI_PHON>
<NSF_ID>000553028</NSF_ID>
<StartDate>08/07/2010</StartDate>
<EndDate>03/15/2013</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<StreetAddress2><![CDATA[3451 Walnut St, 5th Flr Franklin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042250712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042250712</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pennsylvania]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191046205</ZipCode>
<StreetAddress><![CDATA[Research Services]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~73313</FUND_OBLG>
<FUND_OBLG>2011~151685</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp; Fast linear methods were created for estimating hidden state time&nbsp;series models. &nbsp;These have been extended to include some forms of&nbsp;factorial hidden state models. &nbsp;For example, if a very slow Markov&nbsp;model and a much faster one are both used to generate an observed&nbsp;process, then we have developed a method that will find both hidden&nbsp;processes and hence be able to use them to make forecasts about the&nbsp;future of the process. &nbsp;Other extensions were made to the usual&nbsp;spectral estimation methods to allow them to be used in a regression&nbsp;like setting. &nbsp;These methods have been applied to a variety of data&nbsp;sets. &nbsp;The primary focus has been on linguistic data such as named&nbsp;entity recognition and other NLP tasks. &nbsp;But neural data has also been successfully&nbsp;analyzed and we have had some success in very high frequency financial&nbsp;data.</p> <p><br />&nbsp;In related work, we have extended these methods to work on trees. &nbsp;In&nbsp;particular, we have made them work with both traditional parse trees&nbsp;and dependency parse trees. &nbsp;In both cases, we have generated&nbsp;estimation methods which are competitive with existing methods. &nbsp;The&nbsp;new methods run up to 10 to 100 times faster and hence allow analyzing&nbsp;much more data.<br /><br /><br /></p><br> <p>            Last Modified: 09/02/2013<br>      Modified by: Dean&nbsp;P&nbsp;Foster</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Fast linear methods were created for estimating hidden state time series models.  These have been extended to include some forms of factorial hidden state models.  For example, if a very slow Markov model and a much faster one are both used to generate an observed process, then we have developed a method that will find both hidden processes and hence be able to use them to make forecasts about the future of the process.  Other extensions were made to the usual spectral estimation methods to allow them to be used in a regression like setting.  These methods have been applied to a variety of data sets.  The primary focus has been on linguistic data such as named entity recognition and other NLP tasks.  But neural data has also been successfully analyzed and we have had some success in very high frequency financial data.    In related work, we have extended these methods to work on trees.  In particular, we have made them work with both traditional parse trees and dependency parse trees.  In both cases, we have generated estimation methods which are competitive with existing methods.  The new methods run up to 10 to 100 times faster and hence allow analyzing much more data.          Last Modified: 09/02/2013       Submitted by: Dean P Foster]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
