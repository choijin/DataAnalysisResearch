<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Individuation in Visual Cognition</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2011</AwardEffectiveDate>
<AwardExpirationDate>02/28/2017</AwardExpirationDate>
<AwardTotalIntnAmount>484737.00</AwardTotalIntnAmount>
<AwardAmount>564158</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many visual tasks require that we divide attention across multiple locations at once.  We need this ability for everyday tasks, from counting a set of chairs before a dinner party to navigating complex traffic during rush hour.  We also need this ability at  school or at work, when following the complex layout of a diagram or finding differences among values within graphs.  In these kinds of tasks there is a surprising limit to our ability to split our attention and we can typically deal with only a few locations at once.  The ubiquity of this limitation has led to its acceptance as a fundamental limit on visual processing, yet we have little understanding of why it happens.  With the support of an NSF CAREER Award, Dr. Franconeri, Northwestern University, will test the possibility that these limits stem from a bottleneck within a cognitive 'map' of attended locations in the world.  &lt;br/&gt;&lt;br/&gt;Understanding the limits of divided attention could lead to important changes in the ways that we organize information in graphs and diagrams and may offer critical insight into our understanding of how children learn to count.  It may also lead to better understanding of visual processing differences in autistic populations, who have greater difficulty dividing their attention.  This research will be integrated with an education plan that includes (1) outreach to the general public through the design of a "Brain Week" series as well as other outreach talks in the Chicago area,  (2) curriculum development, (3) advising of students and researchers from high school to postdoctoral levels, (4) outreach to underrepresented groups via recruitment to both Northwestern and the investigator's laboratory, including a summer fellowship for a local student from an under-represented background, and (5) collaborative outreach to related disciplines including education and information visualization.</AbstractNarration>
<MinAmdLetterDate>02/25/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1056730</AwardID>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Franconeri</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven L Franconeri</PI_FULL_NAME>
<EmailAddress>franconeri@northwestern.edu</EmailAddress>
<PI_PHON>2246161430</PI_PHON>
<NSF_ID>000201156</NSF_ID>
<StartDate>02/25/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606114579</ZipCode>
<StreetAddress><![CDATA[750 N. Lake Shore Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~96508</FUND_OBLG>
<FUND_OBLG>2012~190131</FUND_OBLG>
<FUND_OBLG>2013~159689</FUND_OBLG>
<FUND_OBLG>2014~117830</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="normal">When we open our eyes, we think that we see the external world. We see an environment made up of surfaces, textures, objects, liquids, animals, people, actions, and events. We feel that we see these things directly and automatically, and that we simply need to permit reality to enter our eyes. This is a powerful illusion. The visual system constructs this illusion of a world &lsquo;out there&rsquo; from a vast set of inferences performed on light that has bounced off of this world and landed on the receptors in our eyes. This inference process is massively complex, requiring approximately 40% of our brain to conduct the necessary calculations. While vision is one of the better-understood systems in the brain, our understanding is still far from complete. Attempts to replicate the visual system&rsquo;s feats in computers have failed in all but the most constrained and simplistic environments.</p> <p class="normal">&nbsp;</p> <p class="normal">Understanding visual processing is a fundamental theoretical goal, but it is also of critical practical importance. To teach students how to read and use maps, interpret diagrams, learn from graphs, or understand the structure of mathematical functions or equations, educational materials and practices must be guided by knowledge of how the visual system represents objects and their relations. To maximize the perceptual efficiency of displays and interfaces from scientific visualizations to flight control systems, the designer must understand the strengths and limits of the visual system.</p> <p class="normal">&nbsp;</p> <p class="normal">Because the visual system is so vast, studying it in smaller parts makes the problem of understanding it more tractable. Visual processing can be thought of as a stream that moves from basic operations, such as detecting the color or brightness of an object, to more abstract operations, such as understanding the arrangement within a diagram. Our laboratory seeks to understand this more abstract level of processing, a subfield known as <em>visual cognition</em>. We study how the visual system allows us to count objects, track objects that move across space, know left from right, or interpret a diagram or graph. We study how these processes interact with the rest of our cognitive system, such as the processes that govern language, memory, and reasoning.</p> <p class="normal">&nbsp;</p> <p class="normal">One core question from our NSF-funded research is: How many objects can we attend, track, or count at once? And how can we increase that number? We are able to focus our attention to specific objects or locations within our visual field, akin to placing them within a mental &lsquo;spotlight&rsquo;. This allows us to attend to a relevant object, or to monitor a place where we expect something relevant to appear in the near future. While many visual tasks involve only a single relevant object or location, others such as comparing two objects or monitoring multiple regions may require that we attend to two or more things at once. Intriguingly, in many of these tasks, there is a frequently encountered &lsquo;magical number&rsquo; in performance limits. We are typically limited to monitoring, tracking, remembering, or counting about 4 or 5 objects or locations at once (see Figure 1 for examples). These findings have historically placed a strong constraint on the architecture of the visual system, by suggesting that we rely on a fixed number of processors that each deal independently with a single object.</p> <p class="normal">&nbsp;</p> <p class="normal">In contrast, the work funded by this grant challenged this idea by demonstrating that these limits are actually flexible &ndash;&nbsp;and we have explored where this flexibility comes from. We have argued that it involves a tradeoff between the number of locations or objects processed at once, and the precision of processing for each one. For instance, we have challenged the idea that we can monitor only around 4 locations at once, depending on how the task is set up, your abilities can sink to a single object, or rise to up to 8 objects, at once. In particular, our research argues that these differences are due to how efficiently you use your visual &lsquo;window&rsquo; on the world. Different parts of that window have independent resources for tracking or attending, and if you spread your visual tasks evenly throughout the window, your abilities will improve &ndash;&nbsp;and this has clear implications for how visual displays should be designed.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/17/2017<br>      Modified by: Steven&nbsp;L&nbsp;Franconeri</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1056730/1056730_10075461_1497735940339_foo--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1056730/1056730_10075461_1497735940339_foo--rgov-800width.jpg" title="Visual Attention Tasks"><img src="/por/images/Reports/POR/2017/1056730/1056730_10075461_1497735940339_foo--rgov-66x44.jpg" alt="Visual Attention Tasks"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our research used these tasks to test the abilities of the visual system</div> <div class="imageCredit">Steve Franconeri</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Steven&nbsp;L&nbsp;Franconeri</div> <div class="imageTitle">Visual Attention Tasks</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[When we open our eyes, we think that we see the external world. We see an environment made up of surfaces, textures, objects, liquids, animals, people, actions, and events. We feel that we see these things directly and automatically, and that we simply need to permit reality to enter our eyes. This is a powerful illusion. The visual system constructs this illusion of a world ?out there? from a vast set of inferences performed on light that has bounced off of this world and landed on the receptors in our eyes. This inference process is massively complex, requiring approximately 40% of our brain to conduct the necessary calculations. While vision is one of the better-understood systems in the brain, our understanding is still far from complete. Attempts to replicate the visual system?s feats in computers have failed in all but the most constrained and simplistic environments.   Understanding visual processing is a fundamental theoretical goal, but it is also of critical practical importance. To teach students how to read and use maps, interpret diagrams, learn from graphs, or understand the structure of mathematical functions or equations, educational materials and practices must be guided by knowledge of how the visual system represents objects and their relations. To maximize the perceptual efficiency of displays and interfaces from scientific visualizations to flight control systems, the designer must understand the strengths and limits of the visual system.   Because the visual system is so vast, studying it in smaller parts makes the problem of understanding it more tractable. Visual processing can be thought of as a stream that moves from basic operations, such as detecting the color or brightness of an object, to more abstract operations, such as understanding the arrangement within a diagram. Our laboratory seeks to understand this more abstract level of processing, a subfield known as visual cognition. We study how the visual system allows us to count objects, track objects that move across space, know left from right, or interpret a diagram or graph. We study how these processes interact with the rest of our cognitive system, such as the processes that govern language, memory, and reasoning.   One core question from our NSF-funded research is: How many objects can we attend, track, or count at once? And how can we increase that number? We are able to focus our attention to specific objects or locations within our visual field, akin to placing them within a mental ?spotlight?. This allows us to attend to a relevant object, or to monitor a place where we expect something relevant to appear in the near future. While many visual tasks involve only a single relevant object or location, others such as comparing two objects or monitoring multiple regions may require that we attend to two or more things at once. Intriguingly, in many of these tasks, there is a frequently encountered ?magical number? in performance limits. We are typically limited to monitoring, tracking, remembering, or counting about 4 or 5 objects or locations at once (see Figure 1 for examples). These findings have historically placed a strong constraint on the architecture of the visual system, by suggesting that we rely on a fixed number of processors that each deal independently with a single object.   In contrast, the work funded by this grant challenged this idea by demonstrating that these limits are actually flexible &ndash; and we have explored where this flexibility comes from. We have argued that it involves a tradeoff between the number of locations or objects processed at once, and the precision of processing for each one. For instance, we have challenged the idea that we can monitor only around 4 locations at once, depending on how the task is set up, your abilities can sink to a single object, or rise to up to 8 objects, at once. In particular, our research argues that these differences are due to how efficiently you use your visual ?window? on the world. Different parts of that window have independent resources for tracking or attending, and if you spread your visual tasks evenly throughout the window, your abilities will improve &ndash; and this has clear implications for how visual displays should be designed.           Last Modified: 06/17/2017       Submitted by: Steven L Franconeri]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
