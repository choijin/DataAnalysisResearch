<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF:  Large:  Collaborative Research:  Reliable Performance for Modern Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>346250.00</AwardTotalIntnAmount>
<AwardAmount>346250</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Today's computer systems are more powerful than ever, but have become so complex that it is now difficult for programmers to produce high-performance software. Even slight changes in programs or differences in a user's system can cause dramatic slowdowns. Currently, there is no way to guarantee that a program will perform as well as it did during testing. This situation makes it extremely difficult to track down the sources of inefficiencies or repair them. The result is reduced power and computational efficiency on servers, and a degraded user experience on client platforms.&lt;br/&gt;&lt;br/&gt;This research aims to deliver reliable performance on modern computer systems. By introducing randomness into the way a computer runs programs, a reliably performant system will significantly reduce the probability that any small change will have a large impact on performance. For instance, consider a cache miss caused by a conflict. With standard caches, repeated access to the same elements would always cause misses, degrading performance.  In a randomized cache or with randomized object placement, it would be very unlikely for the same line to be repeatedly evicted. The investigators are designing and evaluating the use of both randomized algorithms in software and hardware, separately and in combination, to remedy the numerous sources of pathological behavior in modern systems. The result will enable performance-portable applications that are immune to unfortunate interactions with microprocessor components.</AbstractNarration>
<MinAmdLetterDate>07/26/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/02/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1012195</AwardID>
<Investigator>
<FirstName>Emery</FirstName>
<LastName>Berger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emery Berger</PI_FULL_NAME>
<EmailAddress>emery@cs.umass.edu</EmailAddress>
<PI_PHON>4135450698</PI_PHON>
<NSF_ID>000483414</NSF_ID>
<StartDate>07/26/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010359450</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~113750</FUND_OBLG>
<FUND_OBLG>2011~116250</FUND_OBLG>
<FUND_OBLG>2012~116250</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">Enhanced safety and efficiency features in cars and planes have the potential to save thousands of lives and millions of dollars each year, but the computational power of existing real-time systems cannot meet the demands of these new applications. Modern processors are vastly more powerful than typical real-time systems, but the hardware designs that make these processors so fast are directly at odds with the requirements for real-time systems. A particularly unlucky task or combination of tasks can lead a processors into a "bad state" where programs run ten or a hundred times slower than normal. Conventional real-time systems are forced to assume that tasks will always run in this bad state, leaving significant computational resources unused just in case the system does run slowly.&nbsp;</p> <p class="p1"><br />This project makes the performance of modern hardware predictable and probabilistically analyzable, enabling "probabilistic real-time systems": systems that can use significantly more of a processor's computational power in exchange for a vanishingly small probability of a missed deadline due to "bad states". Our approach is to constantly shuffle software components so that repeatedly ending up in a bad state---and thus running too slow---is as unlikely as winning the lottery hundreds of times in a row.</p> <p class="p1">Probabilistic real-time systems can use the increased computational power of modern hardware---power that is required for new safety and efficiency applications---without significantly sacrificing timing guarantees. Applications include reducing fuel cost via more efficient steering and engine controls, and adding safety by incorporating sophisticated models of airflow to reduce turbulence or predicting vehicle trajectories to avoid collisions.&nbsp;</p> <p class="p1">This project also represents a fundamental shift in the way computer scientists approach performance evaluation. While computer hardware is composed of many simple, well-understood components, the dynamic interactions of these components make it impossible to reliably reason about software performance. Other disciplines rely on careful experimental design and powerful statistical techniques to draw conclusions in the face of uncertainty, but there are significant technical obstacles to the adoption of these techniques for performance evaluation. Our work makes it possible for computer scientists to perform rigorous experiments, and provides a sound statistical framework for drawing conclusions from these experiments.</p> <p class="p1">&nbsp;</p><br> <p>            Last Modified: 11/20/2014<br>      Modified by: Emery&nbsp;Berger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Enhanced safety and efficiency features in cars and planes have the potential to save thousands of lives and millions of dollars each year, but the computational power of existing real-time systems cannot meet the demands of these new applications. Modern processors are vastly more powerful than typical real-time systems, but the hardware designs that make these processors so fast are directly at odds with the requirements for real-time systems. A particularly unlucky task or combination of tasks can lead a processors into a "bad state" where programs run ten or a hundred times slower than normal. Conventional real-time systems are forced to assume that tasks will always run in this bad state, leaving significant computational resources unused just in case the system does run slowly.   This project makes the performance of modern hardware predictable and probabilistically analyzable, enabling "probabilistic real-time systems": systems that can use significantly more of a processor's computational power in exchange for a vanishingly small probability of a missed deadline due to "bad states". Our approach is to constantly shuffle software components so that repeatedly ending up in a bad state---and thus running too slow---is as unlikely as winning the lottery hundreds of times in a row. Probabilistic real-time systems can use the increased computational power of modern hardware---power that is required for new safety and efficiency applications---without significantly sacrificing timing guarantees. Applications include reducing fuel cost via more efficient steering and engine controls, and adding safety by incorporating sophisticated models of airflow to reduce turbulence or predicting vehicle trajectories to avoid collisions.  This project also represents a fundamental shift in the way computer scientists approach performance evaluation. While computer hardware is composed of many simple, well-understood components, the dynamic interactions of these components make it impossible to reliably reason about software performance. Other disciplines rely on careful experimental design and powerful statistical techniques to draw conclusions in the face of uncertainty, but there are significant technical obstacles to the adoption of these techniques for performance evaluation. Our work makes it possible for computer scientists to perform rigorous experiments, and provides a sound statistical framework for drawing conclusions from these experiments.         Last Modified: 11/20/2014       Submitted by: Emery Berger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
