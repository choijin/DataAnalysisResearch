<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF:  Medium:  Collaborative Research: System Solutions for Context-aware and Energy-Efficient Mobile Displays</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>297500.00</AwardTotalIntnAmount>
<AwardAmount>313500</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Mobile devices such as smartphones and tablets are intended for usage under demanding physical conditions. As a result, their displays face two unique challenges. First, contextual factors, including the viewing angle, ambient lighting, and unwanted shaking of the device, tend to distort the perceived display content. Moreover, the display is known to be among the largest power consumers on a state-of-the-art mobile device. The goal of this project is to provide the algorithmic foundation as well as software and hardware solutions required for addressing these two challenges. As a close collaboration between Rice University and the University of Southern California, the project targets the following scientific contributions. (1) Sensor-based inference of viewing context that efficiently obtains the viewing context from sensors available in modern mobile devices. (2) Compensation for contextual factors that transforms the display content to produce an improved user perception in terms of fidelity and/or usability. (3) Supply voltage scaling and color/image transformations that modify the display data to significantly reduce the power consumption of mobile OLED displays under human perceptual constraints. &lt;br/&gt;By improving the performance and energy efficiency of mobile displays under challenging viewing conditions, this project will extend the reach of mobile computing beyond its current levels, therefore, having a far-reaching socio-economic impact. Through the NSF/FDA Scholar-in-Residence (SIR) program, graduate students working on this project will visit the US FDA and collaborate with FDA researchers to apply research results to medical imaging problems with mobile displays. The multidisciplinary nature of the proposed research will invite new research problems in system architecture and circuit design, human-computer interaction, image processing, and photometry. It will also provide a multidisciplinary platform for undergraduate and graduate education and research.</AbstractNarration>
<MinAmdLetterDate>08/09/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1065506</AwardID>
<Investigator>
<FirstName>Lin</FirstName>
<LastName>Zhong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lin Zhong</PI_FULL_NAME>
<EmailAddress>lin.zhong@yale.edu</EmailAddress>
<PI_PHON>2034369450</PI_PHON>
<NSF_ID>000189041</NSF_ID>
<StartDate>08/09/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050299031</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WILLIAM MARSH RICE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050299031</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[William Marsh Rice University]]></Name>
<CityName>Houston</CityName>
<StateCode>TX</StateCode>
<ZipCode>770051827</ZipCode>
<StreetAddress><![CDATA[6100 MAIN ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~98839</FUND_OBLG>
<FUND_OBLG>2012~214661</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Mobile devices such as smartphones and tablets are intended for usage under demanding physical conditions. As a result, their displays face two unique challenges. First, contextual factors, including the viewing angle, ambient lighting, and unwanted shaking of the device, tend to distort the perceived display content. Moreover, the display is known to be among the largest power consumers on a state-of-the-art mobile device.</span></p> <p><span>This project provides the algorithmic foundation and system solutions toward addressing the above two challenges. First, it contributes a suite of technologies for optimizing the energy consumption by context sensors, especially image sensors, &nbsp;used for viewing context inference, and enabling&nbsp;one mobile device to use context sensors from another. &nbsp;Second, the project contributes a set of algorithms that compensate for contextual factors including viewing angle and motion by transforming the display content. Finally, it provides novel algorithms that modify the display data to significantly reduce the power consumption of mobile OLED displays under human perceptual constraints.&nbsp;</span><br /><br /><span>The project produced multiple conference and journal publications and demonstrations, including two Best Paper awards.&nbsp;It provided a multidisciplinary platform for undergraduate and graduate education and research, including students from underrepresented populations.&nbsp;By improving the usability and energy efficiency of mobile displays under challenging viewing conditions, this project extends the reach of mobile computing beyond its current levels, therefore, having a far-reaching socio-economic impact.&nbsp;</span></p><br> <p>            Last Modified: 08/14/2014<br>      Modified by: Lin&nbsp;Zhong</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Mobile devices such as smartphones and tablets are intended for usage under demanding physical conditions. As a result, their displays face two unique challenges. First, contextual factors, including the viewing angle, ambient lighting, and unwanted shaking of the device, tend to distort the perceived display content. Moreover, the display is known to be among the largest power consumers on a state-of-the-art mobile device.  This project provides the algorithmic foundation and system solutions toward addressing the above two challenges. First, it contributes a suite of technologies for optimizing the energy consumption by context sensors, especially image sensors,  used for viewing context inference, and enabling one mobile device to use context sensors from another.  Second, the project contributes a set of algorithms that compensate for contextual factors including viewing angle and motion by transforming the display content. Finally, it provides novel algorithms that modify the display data to significantly reduce the power consumption of mobile OLED displays under human perceptual constraints.   The project produced multiple conference and journal publications and demonstrations, including two Best Paper awards. It provided a multidisciplinary platform for undergraduate and graduate education and research, including students from underrepresented populations. By improving the usability and energy efficiency of mobile displays under challenging viewing conditions, this project extends the reach of mobile computing beyond its current levels, therefore, having a far-reaching socio-economic impact.        Last Modified: 08/14/2014       Submitted by: Lin Zhong]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
