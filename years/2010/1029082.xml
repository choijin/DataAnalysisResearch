<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>The Emergence of Cognitive Flexibility in Neural-Behavioral Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1100767.00</AwardTotalIntnAmount>
<AwardAmount>1130883</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to understand how the brain realizes the impressive flexibility that is a hallmark of human cognition.  For example, adults can flexibly shift from conversing about current events, to feeding the cats, to cooking dinner, all without getting mixed up and cooking cat food as the main course. This ability is thought to rely on the actions and interactions of multiple brain areas. A central challenge in understanding cognitive flexibility is to understand how these brain networks change with learning and how they organize and re-organize "on-the-fly" depending on the situation. More generally, how does the brain keep track of events as they unfold but at the same time retain flexibility?&lt;br/&gt;&lt;br/&gt;In this project, a multidisciplinary team of investigators will test a new theory of cognitive flexibility using computer modeling and functional neuroimaging data. The theory is implemented using dynamic neural fields -a specific type of neural network that can be simulated on a computer and that specifies how different areas of the cortex interact during complex tasks. Some cortical areas actively maintain neural patterns related to the lower-level details of what is happening, for instance, maintaining information about critical visual features of the pan, the items you are cooking for dinner, and so on. Other cortical areas modulate what these systems are up to. Critically, "higher-level" systems do not need to understand all the details of what is going on. They just need to help decide which general patterns of information are important in the context. It is the dialog between these different neural patterns that makes cognition flexible.&lt;br/&gt;&lt;br/&gt;The success of this project would have far-reaching effects. The ability to modulate behavior in context-specific ways is a central achievement that impacts language skills, mathematical abilities, school and work performance, and IQ. Moreover, deficits in cognitive flexibility and so-called executive functions underlie different forms of psychopathology, such as schizophrenia, as well as many of the challenges faced by aging adults.  The investigators have also established a collaboration with the Iowa Children's Museum where they will work with museum staff to design an interactive display around the theme of "Brain Play," in which children construct simple solar-powered robots that embody how the brain and body realize flexibility.</AbstractNarration>
<MinAmdLetterDate>09/21/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1029082</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Spencer</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John P Spencer</PI_FULL_NAME>
<EmailAddress>john-spencer@uiowa.edu</EmailAddress>
<PI_PHON>3193352482</PI_PHON>
<NSF_ID>000290164</NSF_ID>
<StartDate>09/21/2010</StartDate>
<EndDate>08/13/2015</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gregor</FirstName>
<LastName>Schoner</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gregor Schoner</PI_FULL_NAME>
<EmailAddress>gregor.schoener@neuroinformatik.ruhr-uni-bochum.de</EmailAddress>
<PI_PHON>2343227965</PI_PHON>
<NSF_ID>000068900</NSF_ID>
<StartDate>09/21/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Hazeltine</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard E Hazeltine</PI_FULL_NAME>
<EmailAddress>eliot-hazeltine@uiowa.edu</EmailAddress>
<PI_PHON>3193352123</PI_PHON>
<NSF_ID>000373551</NSF_ID>
<StartDate>08/13/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Hazeltine</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard E Hazeltine</PI_FULL_NAME>
<EmailAddress>eliot-hazeltine@uiowa.edu</EmailAddress>
<PI_PHON>3193352123</PI_PHON>
<NSF_ID>000373551</NSF_ID>
<StartDate>09/21/2010</StartDate>
<EndDate>08/13/2015</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rodica</FirstName>
<LastName>Curtu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rodica Curtu</PI_FULL_NAME>
<EmailAddress>rodica-curtu@uiowa.edu</EmailAddress>
<PI_PHON>3193350744</PI_PHON>
<NSF_ID>000515488</NSF_ID>
<StartDate>09/21/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vincent</FirstName>
<LastName>Magnotta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vincent Magnotta</PI_FULL_NAME>
<EmailAddress>vincent-magnotta@uiowa.edu</EmailAddress>
<PI_PHON>3193568255</PI_PHON>
<NSF_ID>000558829</NSF_ID>
<StartDate>09/21/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Iowa</Name>
<CityName>IOWA CITY</CityName>
<ZipCode>522421320</ZipCode>
<PhoneNumber>3193352123</PhoneNumber>
<StreetAddress>2 GILMORE HALL</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<StateCode>IA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>062761671</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF IOWA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>062761671</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Iowa]]></Name>
<CityName>IOWA CITY</CityName>
<StateCode>IA</StateCode>
<ZipCode>522421320</ZipCode>
<StreetAddress><![CDATA[2 GILMORE HALL]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<ProgramReference>
<Code>7956</Code>
<Text>SBE Interdisciplinary Research</Text>
</ProgramReference>
<ProgramReference>
<Code>7969</Code>
<Text>FY 2010 Funding for PTR</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~805287</FUND_OBLG>
<FUND_OBLG>2011~125390</FUND_OBLG>
<FUND_OBLG>2012~170090</FUND_OBLG>
<FUND_OBLG>2015~30116</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the project was to further our understanding of how the various regions of the brain work together to produce flexible behavior.&nbsp; Humans can perform different tasks in the same environment depending on their goals and the instructions.&nbsp; How is it that we are able to change our actions to meet our needs when the environment offers us no clues as to what the most appropriate thing to do is?&nbsp; Moreover, it has long been known that distinct regions of the brain play different roles, but how these regions work together to generate coherent, voluntary actions remains mysterious.&nbsp; How do the parts of the brain controlling the eyes know to move to the same object that the hands are moving towards?&nbsp; And how are both these sets of regions influenced by a person&rsquo;s goals and intentions?&nbsp; The proposed work examined how these regions might interact so that each is working on the same action.&nbsp; The approach was to build a large-scale model of the brain that incorporated multiple regions. &nbsp;This model was used to predict both behavioral data and data from functional magnetic resonance imaging (fMRI), a means by which we are able to see blood move to different regions of the brain as they require more oxygen.&nbsp;</p> <p>We trained the model to perform multiple tasks in which visual information indicated multiple responses.&nbsp; For accurate performance, some sources of information had to drive behavior and other sources had to be suppressed.&nbsp; The model successfully performed in these tasks even though they had very different demands, demonstrating that the model provided a foothold for understanding the flexibility of human behavior.&nbsp; Moreover, it performed less well on conditions that humans found more difficult.&nbsp; The same model also predicted observations of changes in blood flow observed with fMRI.&nbsp; This approach represented a breakthrough on several fronts.&nbsp; First, it provided a single model that could explain behavior from several tasks using a single, shared set of parameters.&nbsp; Second, it predicted both the behavioral and neuroimaging data.&nbsp; This approach is potentially very powerful, as it may provide a link between individual differences in behavior and individual differences in neural activation.&nbsp; It can also be applied to understanding development across the lifespan.&nbsp; Finally, the model offers a new theory-based means of interpreting neuroimaging data that relies on the model and how it is affected by manipulations of task factors rather than simply the task factors themselves.&nbsp; This alternative strategy can generate predictions that may not be captured by conventional analytic techniques, particularly when task factors do not map to the activation of specific brain regions in a linear fashion.</p><br> <p>            Last Modified: 10/27/2017<br>      Modified by: Richard&nbsp;E&nbsp;Hazeltine</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the project was to further our understanding of how the various regions of the brain work together to produce flexible behavior.  Humans can perform different tasks in the same environment depending on their goals and the instructions.  How is it that we are able to change our actions to meet our needs when the environment offers us no clues as to what the most appropriate thing to do is?  Moreover, it has long been known that distinct regions of the brain play different roles, but how these regions work together to generate coherent, voluntary actions remains mysterious.  How do the parts of the brain controlling the eyes know to move to the same object that the hands are moving towards?  And how are both these sets of regions influenced by a person?s goals and intentions?  The proposed work examined how these regions might interact so that each is working on the same action.  The approach was to build a large-scale model of the brain that incorporated multiple regions.  This model was used to predict both behavioral data and data from functional magnetic resonance imaging (fMRI), a means by which we are able to see blood move to different regions of the brain as they require more oxygen.   We trained the model to perform multiple tasks in which visual information indicated multiple responses.  For accurate performance, some sources of information had to drive behavior and other sources had to be suppressed.  The model successfully performed in these tasks even though they had very different demands, demonstrating that the model provided a foothold for understanding the flexibility of human behavior.  Moreover, it performed less well on conditions that humans found more difficult.  The same model also predicted observations of changes in blood flow observed with fMRI.  This approach represented a breakthrough on several fronts.  First, it provided a single model that could explain behavior from several tasks using a single, shared set of parameters.  Second, it predicted both the behavioral and neuroimaging data.  This approach is potentially very powerful, as it may provide a link between individual differences in behavior and individual differences in neural activation.  It can also be applied to understanding development across the lifespan.  Finally, the model offers a new theory-based means of interpreting neuroimaging data that relies on the model and how it is affected by manipulations of task factors rather than simply the task factors themselves.  This alternative strategy can generate predictions that may not be captured by conventional analytic techniques, particularly when task factors do not map to the activation of specific brain regions in a linear fashion.       Last Modified: 10/27/2017       Submitted by: Richard E Hazeltine]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
