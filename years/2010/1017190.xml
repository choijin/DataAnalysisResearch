<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Small: Collaborative Research:  Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>195726.00</AwardTotalIntnAmount>
<AwardAmount>195726</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development.  Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds.  Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills.  These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions.  Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced.  Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones.  At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task   In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children.   With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts.  Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country).  Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities.   Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children.  &lt;br/&gt;&lt;br/&gt;Broader Impacts:  This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date.  Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general.  Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains.  In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used.</AbstractNarration>
<MinAmdLetterDate>08/19/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1017190</AwardID>
<Investigator>
<FirstName>Yang</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yang Liu</PI_FULL_NAME>
<EmailAddress>yangl@hlt.utdallas.edu</EmailAddress>
<PI_PHON>9728836618</PI_PHON>
<NSF_ID>000288465</NSF_ID>
<StartDate>08/19/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Dallas</Name>
<CityName>Richardson</CityName>
<ZipCode>750803021</ZipCode>
<PhoneNumber>9728832313</PhoneNumber>
<StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX32</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>800188161</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT DALLAS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Dallas]]></Name>
<CityName>Richardson</CityName>
<StateCode>TX</StateCode>
<ZipCode>750803021</ZipCode>
<StreetAddress><![CDATA[800 W. Campbell Rd., AD15]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~195726</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Khairun-nisa Hassanali has completed her Ph.d dissertation &ldquo;Using Natural Language Processing for Child Language Analysis&rdquo;, supported by this NSF project.</p> <p>Hassanali investigated using automatic natural language processing (NLP) techniques for child language impairment detection and child language analysis in general. The following lists some major outcomes of her work.</p> <ol> <li>&nbsp;The Index of Productive Syntax (IPSyn) is a measure of syntactic development in child language and has been used by clinicians for language sample analysis. However, it is often done manually which is very time consuming. We implemented a system based on the current NLP techniques to automatically compute IPSyn. Our results show the automatic system performs at levels comparable to scores computed manually.</li> <li>&nbsp;IPSyn only looks at existence of certain syntactic constructs. To give more feedback on child language development, we propose to automatically detect grammatical errors a child makes. We explore the automatic detection of 6 types of verb related grammatical errors in this study using NLP techniques. We compare rule based systems to statistical systems and investigate the use of different features and found the statistical systems performed better than the rule based systems for most of the error categories.</li> <li>Previous work has used mostly shallow language processing features for language impairment detection. We investigated if deeper language processing features can help improve LI detection performance. The features include syntactic, semantic, entity grid features, and narrative quality features. Our experiments show that narrative structure and quality features along with a combination of other features are helpful in the prediction of LI in storytelling narratives.</li> <li>Coherence is an important aspect of language ability. We analyze and annotate child language samples of story retell sessions for coherence and presence of narrative structure and narrative quality constructs. We use these constructs as features and use existing NLP techniques to build models that automatically predict coherence and language impairment in narratives. We perform feature analysis that gives us an insight into some of the important narrative quality features such as the use of cognitive inferences and social engagement devices.&nbsp;</li> <li>We explored the use of Latent Dirichlet Allocation (LDA) for detecting topics from narratives, and use the topics derived from LDA in two classification tasks: automatic prediction of coherence and language impairment. Our experiments show LDA is useful for detecting the topics that correspond to the narrative structure. We also observed improved performance for the automatic prediction of coherence and language impairment when we use features derived from the topic words provided by LDA.&nbsp;</li> </ol> <p>&nbsp;</p><br> <p>            Last Modified: 10/31/2015<br>      Modified by: Yang&nbsp;Liu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Khairun-nisa Hassanali has completed her Ph.d dissertation "Using Natural Language Processing for Child Language Analysis", supported by this NSF project.  Hassanali investigated using automatic natural language processing (NLP) techniques for child language impairment detection and child language analysis in general. The following lists some major outcomes of her work.   The Index of Productive Syntax (IPSyn) is a measure of syntactic development in child language and has been used by clinicians for language sample analysis. However, it is often done manually which is very time consuming. We implemented a system based on the current NLP techniques to automatically compute IPSyn. Our results show the automatic system performs at levels comparable to scores computed manually.  IPSyn only looks at existence of certain syntactic constructs. To give more feedback on child language development, we propose to automatically detect grammatical errors a child makes. We explore the automatic detection of 6 types of verb related grammatical errors in this study using NLP techniques. We compare rule based systems to statistical systems and investigate the use of different features and found the statistical systems performed better than the rule based systems for most of the error categories. Previous work has used mostly shallow language processing features for language impairment detection. We investigated if deeper language processing features can help improve LI detection performance. The features include syntactic, semantic, entity grid features, and narrative quality features. Our experiments show that narrative structure and quality features along with a combination of other features are helpful in the prediction of LI in storytelling narratives. Coherence is an important aspect of language ability. We analyze and annotate child language samples of story retell sessions for coherence and presence of narrative structure and narrative quality constructs. We use these constructs as features and use existing NLP techniques to build models that automatically predict coherence and language impairment in narratives. We perform feature analysis that gives us an insight into some of the important narrative quality features such as the use of cognitive inferences and social engagement devices.  We explored the use of Latent Dirichlet Allocation (LDA) for detecting topics from narratives, and use the topics derived from LDA in two classification tasks: automatic prediction of coherence and language impairment. Our experiments show LDA is useful for detecting the topics that correspond to the narrative structure. We also observed improved performance for the automatic prediction of coherence and language impairment when we use features derived from the topic words provided by LDA.            Last Modified: 10/31/2015       Submitted by: Yang Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
