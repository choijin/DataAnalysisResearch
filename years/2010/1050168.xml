<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>GV: EAGER: Innovative Analysis and Visualization Approaches for Understanding Model Uncertainty</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>102999.00</AwardTotalIntnAmount>
<AwardAmount>119299</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This exploratory project strives to develop a new approach to support human understanding of the uncertainty that is inherent in the structure and predictions of complex models.Specifically, the focus in the project is on understanding several types of uncertainty that are associated with model predictions.&lt;br/&gt;Sample uncertainty occurs when regions of the instance space are not well represented in the training data, and predictions are therefore based on sparse information. Model instability occurs when model predictions vary, depending on the training data that was used to construct the model. Prediction variability occurs when a given observation may have noisy attributes, and this input uncertainty leads to uncertainty in the model's predictions. Novel analytical techniques are developed to create meta-models that characterize these three forms of uncertainty. To facilitate user understanding of the nature and distribution of these multiple types of uncertainty across the model space, novel visualization methods represent these meta-models in a display space. Finally, a novel evaluation methodology is used to measure whether, and in what ways, important characteristics of the meta-models are captured in the visualization display space.&lt;br/&gt;&lt;br/&gt;This work develops novel techniques in the fields of machine learning and data visualization. Contributions in machine learning include more powerful methods for constructing and analyzing meta-models that characterize multiple types of uncertainty associated with predictive models. Data visualization research focuses on new approaches for representing multi-valued, probabilistic, and complex data, enabling the display of the nature and range of model predictions and uncertainty. An interdisciplinary contribution is the development of a novel methodology for evaluating the quality of model visualizations with respect to the preservation of important model and meta-model characteristics.&lt;br/&gt;&lt;br/&gt;The broader impacts of this project may be grouped into three major clusters: a new model building paradigm; fostering scientific collaboration; and integrating research and education. The results are expected to provide foundations for further research is management of uncertainty in deriving models representing a wide range of phenomena. This project lays a technical groundwork that can contribute to new collaborations between the PIs and application domain experts, facilitating broad interdisciplinary collaborations. Project results will be widely disseminated via the project web site (http://maple.cs.umbc.edu/complexmodels/). Finally, through teaching and training activities, this research project is also well suited to include the introduction of undergraduates to the possibilities of research and the incorporation of project topics into the PIs' courses on visualization and artificial intelligence.</AbstractNarration>
<MinAmdLetterDate>08/24/2010</MinAmdLetterDate>
<MaxAmdLetterDate>12/02/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1050168</AwardID>
<Investigator>
<FirstName>Penny</FirstName>
<LastName>Rheingans</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Penny Rheingans</PI_FULL_NAME>
<EmailAddress>penny.rheingans@maine.edu</EmailAddress>
<PI_PHON>2075812183</PI_PHON>
<NSF_ID>000336155</NSF_ID>
<StartDate>08/24/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marie</FirstName>
<LastName>desJardins</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marie E desJardins</PI_FULL_NAME>
<EmailAddress>mariedj@cs.umbc.edu</EmailAddress>
<PI_PHON>4104553967</PI_PHON>
<NSF_ID>000231667</NSF_ID>
<StartDate>08/24/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland Baltimore County</Name>
<CityName>Baltimore</CityName>
<ZipCode>212500002</ZipCode>
<PhoneNumber>4104553140</PhoneNumber>
<StreetAddress>1000 Hilltop Circle</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>061364808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND BALTIMORE COUNTY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland Baltimore County]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212500002</ZipCode>
<StreetAddress><![CDATA[1000 Hilltop Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~102999</FUND_OBLG>
<FUND_OBLG>2011~16300</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We developed a new approach to support human understanding of the uncertainty that is inherent in the structure and predictions of complex predictive models. <em>Sample uncertainty</em> occurs when regions of the instance space are not well represented in the training data, and predictions are therefore based on sparse information. <em>Model instability</em> occurs when model predictions vary, depending on the training data that was used to construct the model. <em>Prediction variability</em> occurs when a given observation may have noisy attributes, and this input uncertainty leads to uncertainty in the model's predictions. This research draws on and contributes to research in the fields of machine learning and visualization. We developed analytical techniques to create meta-models that characterize these three forms of uncertainty. To facilitate user understanding of the nature and distribution of these multiple types of uncertainty across the model space, we developed novel visualization methods to visualize these meta-models in a display space.</p> <p>On the machine learning side, we created new techniques for quantifying and investigating various sources of error in classification models. We developed a novel algorithm that relates model uncertainty to properties of the underlying sample space, using four novel metrics for either sample uncertainty or data uncertainty. We also incorporated this method into a rescaling technique that is capable of correcting uncertainty predictions by considering these underlying sample space metrics. The results of our confidence rescaling experiments show that, in a variety of domains, including these sample-space metrics improves predictive model performance, resulting in more accurate confidence estimates. In future work (outside the scope of this project), we intend to explore higher-dimensional regression methods that would permit us to incorporate both density and purity (possibly along with other inputs, such as instance attributes or other sample-space measures).</p> <p>On the visualization side, we implemented a baseline glyph visualization of multi-value data using a pie chart theme. Each glyph displays the predicted probabilities of different classifications for a data point. These probabilities correspond to the chance of that point belonging to a class (out of a set of multiple classes). Data points are projected into a display space using the dimension reduction technique of multidimensional scaling. Using the pie chart visualizations provides insights about the underlying model behavior. In particular, it is clear that this type of visualization gives significantly more insight into the variation of model behavior across the instance space than the traditional machine learning statistical summarizations (e.g., confusion matrices). The new interactive features have proved to be very useful in analyzing and generating new insights from domain-specific data sets.</p> <p><span style="font-size: 12px;">We are currently applying the visualization techniques to support an exploration of student retention patterns, using UMBC data warehouse. &nbsp;That activity is a joint effort that is also supported by an REU supplement on another NSF grant. &nbsp;</span></p> <p><strong>Intellectual and technical contributions.</strong> This research contributes novel techniques in the fields of machine learning and data visualization. Contributions to machine learning include more powerful methods for constructing and analyzing meta-models that characterize multiple types of uncertainty associated with predictive models. Contributions to data visualization include new approaches for representing multivalued, probabilistic, and complex data, enabling the display of the nature and range of model predictions and uncertainty.</p> <p><strong>Broader impacts.</strong> The broader impacts of this project may be grouped into three major clus...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We developed a new approach to support human understanding of the uncertainty that is inherent in the structure and predictions of complex predictive models. Sample uncertainty occurs when regions of the instance space are not well represented in the training data, and predictions are therefore based on sparse information. Model instability occurs when model predictions vary, depending on the training data that was used to construct the model. Prediction variability occurs when a given observation may have noisy attributes, and this input uncertainty leads to uncertainty in the model's predictions. This research draws on and contributes to research in the fields of machine learning and visualization. We developed analytical techniques to create meta-models that characterize these three forms of uncertainty. To facilitate user understanding of the nature and distribution of these multiple types of uncertainty across the model space, we developed novel visualization methods to visualize these meta-models in a display space.  On the machine learning side, we created new techniques for quantifying and investigating various sources of error in classification models. We developed a novel algorithm that relates model uncertainty to properties of the underlying sample space, using four novel metrics for either sample uncertainty or data uncertainty. We also incorporated this method into a rescaling technique that is capable of correcting uncertainty predictions by considering these underlying sample space metrics. The results of our confidence rescaling experiments show that, in a variety of domains, including these sample-space metrics improves predictive model performance, resulting in more accurate confidence estimates. In future work (outside the scope of this project), we intend to explore higher-dimensional regression methods that would permit us to incorporate both density and purity (possibly along with other inputs, such as instance attributes or other sample-space measures).  On the visualization side, we implemented a baseline glyph visualization of multi-value data using a pie chart theme. Each glyph displays the predicted probabilities of different classifications for a data point. These probabilities correspond to the chance of that point belonging to a class (out of a set of multiple classes). Data points are projected into a display space using the dimension reduction technique of multidimensional scaling. Using the pie chart visualizations provides insights about the underlying model behavior. In particular, it is clear that this type of visualization gives significantly more insight into the variation of model behavior across the instance space than the traditional machine learning statistical summarizations (e.g., confusion matrices). The new interactive features have proved to be very useful in analyzing and generating new insights from domain-specific data sets.  We are currently applying the visualization techniques to support an exploration of student retention patterns, using UMBC data warehouse.  That activity is a joint effort that is also supported by an REU supplement on another NSF grant.    Intellectual and technical contributions. This research contributes novel techniques in the fields of machine learning and data visualization. Contributions to machine learning include more powerful methods for constructing and analyzing meta-models that characterize multiple types of uncertainty associated with predictive models. Contributions to data visualization include new approaches for representing multivalued, probabilistic, and complex data, enabling the display of the nature and range of model predictions and uncertainty.  Broader impacts. The broader impacts of this project may be grouped into three major clusters: human resource development through teaching and training activities, laying a technical foundation to support the establishment of new interdisciplinary collaborations, and benefits to society th...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
