<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Using Empirical Generalization to Develop Predictive Models of DBMS Processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>12/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>474076.00</AwardTotalIntnAmount>
<AwardAmount>505541</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>nan zhang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Database management systems (DBMSes) are now an essential component of a vibrant information technology industry. Despite research and development efforts over several decades, DBMSes are not well understood. There is surprisingly little known about quite basic questions such as, how often does the optimizer pick the wrong plan for a query?  does adding a physical operator for an algebraic operation always improve the effectiveness of query optimization, or is there a limit to the number of operators that can be practically accommodated?  how do throughput and disk utilization depend on multiprogramming level? or when does thrashing occur?&lt;br/&gt; &lt;br/&gt;This project extends an existing laboratory information management system to develop and thoroughly test predictive models of centralized DBMSes. These models concern the role of schema complexity, effective operator set, and cardinality estimation errors on the plan chosen by the optimizer, the structure of the optimizer search space, and the interaction of multiprogramming level on throughput, disk utilization, and response time in predicting thrashing. These models predict important characteristics of DBMSes that share a common architecture, quantify the relative contributions of identified causal factors, and determine fundamental limits of that architecture.&lt;br/&gt;&lt;br/&gt;These models can be used to further improve DBMSes through engineering efforts that benefit from the fundamental understanding that this perspective can provide. Additionally, this novel research infrastructure, being made available to the community and to students via a web portal, encourages a culture of empirical generalization and the sharing of experimental results: http://www.cs.arizona.edu/projects/soc/sodb/</AbstractNarration>
<MinAmdLetterDate>08/01/2010</MinAmdLetterDate>
<MaxAmdLetterDate>10/21/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1016205</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Snodgrass</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard T Snodgrass</PI_FULL_NAME>
<EmailAddress>rts@cs.arizona.edu</EmailAddress>
<PI_PHON>5206216370</PI_PHON>
<NSF_ID>000378635</NSF_ID>
<StartDate>08/01/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857194824</ZipCode>
<StreetAddress><![CDATA[888 N Euclid Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~157574</FUND_OBLG>
<FUND_OBLG>2011~332502</FUND_OBLG>
<FUND_OBLG>2012~15465</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="tinyMCEContent"> <p>THis research project applied a standard methodology of experimental science to an engineering artifact, that of relational data base management systems (DBMSes). Richard Snodgrass (PI) and several colleagues and students at the University of Arizona used an innovative methodology that treats DBMSes as experimental  subjects to propose and test predictive models for DBMSes. DBMS transaction thrashing. Our specific objective was to understand both program time metrology and the two  underlying phenomena of query suboptimality and DBMS thrashing.</p> <p>In terms of <strong>intellectual merit</strong>,  the research developed and tested theories about two important phenomena of database management systems; these theories will apply  across multiple DBMSes. The work helps to put forth a third  methodological approach (in addition to the common mathematical and  engineering perspectives) to systems research and helps develop the  infrastructure for this methodological approach.</p> <div class="tinyMCEContent">Concerning improving program time  metrology, we have developed two  sophisticated time measurement  protocols, each of which improves on the  state of the art. The <em>Execution Measurement Protocol</em> (EMP) measures the    execution time of CPU-only programs on Linux with an order of magnitude    less variance. The <em>Tucson Timing Protocol Version 2</em> (TTPv2) improves on the    accuracy and precision of the original protocol, extending a sophisticated structural causal model of   metrics  provided by Linux. While some of the specific steps of the protocol, such as clearing    caches before executing a query, are well-known (though not    well-documented), ours is the first general query evaluation time    measurement protocol to be documented.</div> <div class="tinyMCEContent"></div> <div class="tinyMCEContent">Our second major focus has been to try to determine the   factors for predicting the generation of suboptimal queries.&nbsp; Five separate experiments and almost a million query   executions tested an articulated causal model was able to explain 34%   of the variance of suboptimality, of four causal constructs: optimizer   complexity, query complexity, plan space complexity, and schema   complexity. One surprising thing we have founds is that for a   large portion of queries, the plan chosen by the query optimizer is not   the best plan, for at least one cardinality. The predictive model and these experimental results suggest several engineering challenges.</div> <div class="tinyMCEContent"></div> <div class="tinyMCEContent">We have articulated a   second structural causal model to explain aspects of DBMS transaction thrashing and tested it with extensive experiments   (comprising over a cumulative year of execution).</div> <div class="tinyMCEContent"> <p>There are three<strong> broader impacts</strong> that have emerged  from the proposed research. First, it introduces a new perspective  (science), adding to the existing mathematical and engineering  perspectives now used prominently in database research. Second, it  offers a scientific rationale for new architectures for database  management systems. (As an example, this research has shown that current query  optimizers handle uncertainty poorly). Finally, the automated system AZDBLAB that enabled these studies by automating long-running experiments on DBMSes and CPU-only programs will be made available to the community and to  students via a web portal, encouraging a culture of scientific inquiry  and development of novel investigation scenarios.</p> </div> </div><br> <p>            Last Modified: 02/29/2016<br>      Modified by: Richard&nbsp;T&nbsp;Snodgrass</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  THis research project applied a standard methodology of experimental science to an engineering artifact, that of relational data base management systems (DBMSes). Richard Snodgrass (PI) and several colleagues and students at the University of Arizona used an innovative methodology that treats DBMSes as experimental  subjects to propose and test predictive models for DBMSes. DBMS transaction thrashing. Our specific objective was to understand both program time metrology and the two  underlying phenomena of query suboptimality and DBMS thrashing.  In terms of intellectual merit,  the research developed and tested theories about two important phenomena of database management systems; these theories will apply  across multiple DBMSes. The work helps to put forth a third  methodological approach (in addition to the common mathematical and  engineering perspectives) to systems research and helps develop the  infrastructure for this methodological approach. Concerning improving program time  metrology, we have developed two  sophisticated time measurement  protocols, each of which improves on the  state of the art. The Execution Measurement Protocol (EMP) measures the    execution time of CPU-only programs on Linux with an order of magnitude    less variance. The Tucson Timing Protocol Version 2 (TTPv2) improves on the    accuracy and precision of the original protocol, extending a sophisticated structural causal model of   metrics  provided by Linux. While some of the specific steps of the protocol, such as clearing    caches before executing a query, are well-known (though not    well-documented), ours is the first general query evaluation time    measurement protocol to be documented.  Our second major focus has been to try to determine the   factors for predicting the generation of suboptimal queries.  Five separate experiments and almost a million query   executions tested an articulated causal model was able to explain 34%   of the variance of suboptimality, of four causal constructs: optimizer   complexity, query complexity, plan space complexity, and schema   complexity. One surprising thing we have founds is that for a   large portion of queries, the plan chosen by the query optimizer is not   the best plan, for at least one cardinality. The predictive model and these experimental results suggest several engineering challenges.  We have articulated a   second structural causal model to explain aspects of DBMS transaction thrashing and tested it with extensive experiments   (comprising over a cumulative year of execution).   There are three broader impacts that have emerged  from the proposed research. First, it introduces a new perspective  (science), adding to the existing mathematical and engineering  perspectives now used prominently in database research. Second, it  offers a scientific rationale for new architectures for database  management systems. (As an example, this research has shown that current query  optimizers handle uncertainty poorly). Finally, the automated system AZDBLAB that enabled these studies by automating long-running experiments on DBMSes and CPU-only programs will be made available to the community and to  students via a web portal, encouraging a culture of scientific inquiry  and development of novel investigation scenarios.         Last Modified: 02/29/2016       Submitted by: Richard T Snodgrass]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
