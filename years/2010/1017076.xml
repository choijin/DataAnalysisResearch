<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Planning Navigation Among Movable Obstacles</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>299998.00</AwardTotalIntnAmount>
<AwardAmount>299998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Richard Voyles</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The objective of this project is to design autonomous planning algorithms for robots that move obstacles out of the way. The research is motivated by future robots that will save humans from disasters such as floods and earthquakes by solving Navigation Among Movable Obstacles (NAMO). Traditional motion planning algorithms search for collision-free paths from a start to a goal. However, when flood waters have caused furniture to float and collapse, there is no path to the victims. Instead, robots must decide which obstacles can be moved and how to move them.&lt;br/&gt;&lt;br/&gt;The practical robot algorithms developed in this project manipulate the environment and create accurate environment models. To handle uncertainty about the environment, new algorithms merge tools from decision theory with motion planning. Markov Decision Processes represent robot uncertainty about environment interactions. Process structure encodes the existence and mobility of objects. Computational techniques optimize decisions to achieve both goal-directed and information gathering actions by updating the decision process structure.&lt;br/&gt;&lt;br/&gt;Results from this work advance the understanding of decision theory to motion planning for robot systems with numerous degrees of freedom. Potential applications include solutions to rescue challenges and broader domains where uncertain outcomes of numerous possible actions require online modeling of environments. Outreach activities focus on workshops that combine decision theory with motion planning and course curriculum that introduces students to research in algorithms that simultaneously learn about the world and make effective decisions.</AbstractNarration>
<MinAmdLetterDate>09/13/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1017076</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Stilman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Stilman</PI_FULL_NAME>
<EmailAddress>mstilman@cc.gatech.edu</EmailAddress>
<PI_PHON>6502834284</PI_PHON>
<NSF_ID>000509038</NSF_ID>
<StartDate>09/13/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~299998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary goal of this project was to develop algorithms that integrated online planning and active perception for robots that interact with their environments. The research particularly focused on planning Navigation Among Movable Obstacles in realistic service environments where robots have limited range sensors and uncertainty about the objects with which they interact. We have developed a number of achievements in this field:</p> <p><br />1) We developed algorithms for robots with limited sensing that can efficiently (online) determine the next best set of actions given available knowledge of the environment from sensors.</p> <p><br />2) Through a novel combination of techniques from Machine Learning we introduced a hierarchical MDP formulation of a planar environment that split up the problem of moving from one space to another and determined candidate objects for manipualtion. Furthermore, by introducing MCTS (Monte-Carlo Tree Search) we singificantly reduced computation time for solutions to challenging MDP problems. This yielded provably linear search times in the number of obstacles and was demonstrated in simulated trials.</p> <p><br />3) Our collaboration with the MIT CSAIL group led to potentially more efficient algorithms than the ones previously studied. The BHPN (belief based planning in the now) framework allowed online task decomposition and feasible strategies for very large state spaces. This recent work enabled a new formulation of our domain. Our contribution considered Reconsideration: Deciding when to replan based on opportunity for plan improvement and computational cost of replanning and Foresight: Leveraging knowledge of future subgoals and beliefs about future observations to maintain correctness and improve optimality.</p> <p><br />4) The work in (2) was demonstrated in dynamic simulation and (3) was shown on a real mobile manipulator.</p> <p><br />5) Finally, we investigated methods for perception that would yield accurate estimates of the robot's certainty in enevironment objects. Using an object decomposition technique we developed a framework that could recognize occluded furniture with higher degrees of accuracy than previously reported.</p> <p><strong>Intellectual Merit: </strong>This project is the first major step for robots in domains such as industrial and home service to both understand their environments and be able to quantify this understanding. Utilizing accurate estimates of certainty in the robot's beliefs of the world our algorithms can now make informed decisions regarding the likelihood of success in planning and optimize for success. These approaches have value beyond service robotics, in fields including all intelligent systems such as Machine Learning, Operations Research and Robots that consider real-world interactions.</p> <p><strong>Broader Impacts: </strong>The PI has been active in both planning and humanoid robotics communities to engage researchers in the topic of environment interaction. He has co-organized two workshops at ICAPS and a workshop at RSS. Furthermore he served as General Chair for Humanoids 2013 which highlighted the importance of understanding humans and making robots function in the real world. Beyond these activities, we have opened our lab to K-12 students on National Robotics Week for the past three years and engaged elementary school children through interactive demonstrations as well as a recent interview that is being broadcasted in local area schools.</p><br> <p>            Last Modified: 12/01/2013<br>      Modified by: Michael&nbsp;Stilman</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The primary goal of this project was to develop algorithms that integrated online planning and active perception for robots that interact with their environments. The research particularly focused on planning Navigation Among Movable Obstacles in realistic service environments where robots have limited range sensors and uncertainty about the objects with which they interact. We have developed a number of achievements in this field:   1) We developed algorithms for robots with limited sensing that can efficiently (online) determine the next best set of actions given available knowledge of the environment from sensors.   2) Through a novel combination of techniques from Machine Learning we introduced a hierarchical MDP formulation of a planar environment that split up the problem of moving from one space to another and determined candidate objects for manipualtion. Furthermore, by introducing MCTS (Monte-Carlo Tree Search) we singificantly reduced computation time for solutions to challenging MDP problems. This yielded provably linear search times in the number of obstacles and was demonstrated in simulated trials.   3) Our collaboration with the MIT CSAIL group led to potentially more efficient algorithms than the ones previously studied. The BHPN (belief based planning in the now) framework allowed online task decomposition and feasible strategies for very large state spaces. This recent work enabled a new formulation of our domain. Our contribution considered Reconsideration: Deciding when to replan based on opportunity for plan improvement and computational cost of replanning and Foresight: Leveraging knowledge of future subgoals and beliefs about future observations to maintain correctness and improve optimality.   4) The work in (2) was demonstrated in dynamic simulation and (3) was shown on a real mobile manipulator.   5) Finally, we investigated methods for perception that would yield accurate estimates of the robot's certainty in enevironment objects. Using an object decomposition technique we developed a framework that could recognize occluded furniture with higher degrees of accuracy than previously reported.  Intellectual Merit: This project is the first major step for robots in domains such as industrial and home service to both understand their environments and be able to quantify this understanding. Utilizing accurate estimates of certainty in the robot's beliefs of the world our algorithms can now make informed decisions regarding the likelihood of success in planning and optimize for success. These approaches have value beyond service robotics, in fields including all intelligent systems such as Machine Learning, Operations Research and Robots that consider real-world interactions.  Broader Impacts: The PI has been active in both planning and humanoid robotics communities to engage researchers in the topic of environment interaction. He has co-organized two workshops at ICAPS and a workshop at RSS. Furthermore he served as General Chair for Humanoids 2013 which highlighted the importance of understanding humans and making robots function in the real world. Beyond these activities, we have opened our lab to K-12 students on National Robotics Week for the past three years and engaged elementary school children through interactive demonstrations as well as a recent interview that is being broadcasted in local area schools.       Last Modified: 12/01/2013       Submitted by: Michael Stilman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
