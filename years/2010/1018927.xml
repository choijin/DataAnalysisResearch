<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Information Flow in Networks: Entropy, Matroids and Groups</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research aims to develop an optimization-based approach to network information theory, that goes well beyond current networking theory and practice. There is a great deal of recent interest in the problem of simultaneous information transmission among many users over wired and wireless networks. Information theory is well poised to have an impact on the manner in which such future networks are designed and maintained, both because wired networks are ripe for applications such as network coding (where information streams are actually combined rather than simply routed) and also because wireless networks cannot be satisfactorily dealt with using conventional networking tools. The challenge is that even the simplest network information theory problems are notoriously difficult and, as a result, information theory has not been able to provide many tools to network practitioners. The research aims to remedy this situation by developing tools for more effective network design. &lt;br/&gt;&lt;br/&gt;While, in principle, it is possible to obtain the information-theoretic rates in wired networks via convex optimization over the space of entropy vectors, this effort is severely hampered by the fact that an explicit characterization of the entropic space does not appear to be within reach. To circumvent this, the research will consider frameworks that, while possibly suboptimal, apply to arbitrary networks, have reasonable complexity and lend themselves to distributed implementation. The mathematical approach taken is four-fold and makes use of the representation theory of matroids (to design linear network codes), Monte Carlo Markov chain methods to distributedly design "good" network codes, group-theoretic techniques to construct nonlinear network codes from non-Abelian groups, and determinantal inequalities to study the entropic space.</AbstractNarration>
<MinAmdLetterDate>09/14/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/14/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1018927</AwardID>
<Investigator>
<FirstName>Babak</FirstName>
<LastName>Hassibi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Babak Hassibi</PI_FULL_NAME>
<EmailAddress>hassibi@caltech.edu</EmailAddress>
<PI_PHON>6263954810</PI_PHON>
<NSF_ID>000490528</NSF_ID>
<StartDate>09/14/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>California Institute of Technology</Name>
<CityName>PASADENA</CityName>
<ZipCode>911250600</ZipCode>
<PhoneNumber>6263956219</PhoneNumber>
<StreetAddress>1200 E California Blvd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code 273-6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009584210</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CALIFORNIA INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[California Institute of Technology]]></Name>
<CityName>PASADENA</CityName>
<StateCode>CA</StateCode>
<ZipCode>911250600</ZipCode>
<StreetAddress><![CDATA[1200 E California Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project dealt with network information theory, the study of the fundamental limits of reliable information transmission in networks of many transmitters and receivers. Even though many such information transmission networks exist (the Internet, the mobile phone network, etc.), how such networks should be optimally operated to maximize the total possible information flow is not known. This is arguably the most important open problem in information theory, and one whose resolution would have a multitude of practical implications and enormous societal benefits.</p> <p>The project introduced a new framework for network information theory through the study of all possible joint entropies of a collection of signals. The concept of entropy, whose origin is in statistical mechanics, is used to measure the amount of information carried by a signal. In a network context, where one encounters a multitude of interacting signals, joint entropy plays a key role in understanding the flow of information. Unfortunately, the limits of joint entropy are not known, which is why the main problems in network information theory are open. The project studied some of the connections between joint entropy and some deep areas in mathematics, most notably group theory and matroid theory. While many revealing facts were discovered, such as families of optimal group codes in networks, linear programming methods for the design of linear binary codes, and Monte Carlo Markov chain methods for designing optimal network codes, many theoretical and computational challenges remain, so that a complete theory still appears out of reach.</p> <p>In response to the formidable challenges and road blocks that exist in formulating a general theory and solution, the project also focused on some special cases and specific examples. In many of these, significant progress was made. To describe a few:</p> <p>- New classes of error-correcting codes (so-called tree codes) were constructed that allow the reliable implementation of any multi-party protocol, or any control strategy, across networks with lossy links. Thes codes, for example, have caught the attention of NASA for the purpose of remotely controlling space assets (such as rovers on Mars).</p> <p>- The capacity of multiple antenna wireless communication systems that need to communicate with perfect secrecy in the presence of an eavesdropper was determined.</p> <p>- A class of near optimal signals, called low coherence frames, that have many applications in wireless communications, quantum measurements, and analog to digital conversion, was designed using group theory ideas.</p> <p>- The capacity of wireless communication systems that do not have a constant source of energy, and that instead have a finite battery and must harvest energy from the environment, was studied.</p> <p>- Intereference management algorithms were devised that can increase the capacity of cellular wireless networks by 20%-45%.</p> <p>- Error-correcting codes were constructed for distributed storage systems where the integrity of the data must be maintained in the presence of disk and server failures.</p> <p>The project brought together ideas from engineering, computer science and mathematics.The work was disseminated through conference and journal publications, and plenary talks by the PI. Most significantly, the PI co-organized two international workshops (with participation from the leading researchers in the fields of network information theory and entropy inequalities), one in the Chinese University of Hong Kong, and the other in the Henri Poincare Institute in Paris.</p><br> <p>            Last Modified: 07/01/2015<br>      Modified by: Babak&nbsp;Hassibi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project dealt with network information theory, the study of the fundamental limits of reliable information transmission in networks of many transmitters and receivers. Even though many such information transmission networks exist (the Internet, the mobile phone network, etc.), how such networks should be optimally operated to maximize the total possible information flow is not known. This is arguably the most important open problem in information theory, and one whose resolution would have a multitude of practical implications and enormous societal benefits.  The project introduced a new framework for network information theory through the study of all possible joint entropies of a collection of signals. The concept of entropy, whose origin is in statistical mechanics, is used to measure the amount of information carried by a signal. In a network context, where one encounters a multitude of interacting signals, joint entropy plays a key role in understanding the flow of information. Unfortunately, the limits of joint entropy are not known, which is why the main problems in network information theory are open. The project studied some of the connections between joint entropy and some deep areas in mathematics, most notably group theory and matroid theory. While many revealing facts were discovered, such as families of optimal group codes in networks, linear programming methods for the design of linear binary codes, and Monte Carlo Markov chain methods for designing optimal network codes, many theoretical and computational challenges remain, so that a complete theory still appears out of reach.  In response to the formidable challenges and road blocks that exist in formulating a general theory and solution, the project also focused on some special cases and specific examples. In many of these, significant progress was made. To describe a few:  - New classes of error-correcting codes (so-called tree codes) were constructed that allow the reliable implementation of any multi-party protocol, or any control strategy, across networks with lossy links. Thes codes, for example, have caught the attention of NASA for the purpose of remotely controlling space assets (such as rovers on Mars).  - The capacity of multiple antenna wireless communication systems that need to communicate with perfect secrecy in the presence of an eavesdropper was determined.  - A class of near optimal signals, called low coherence frames, that have many applications in wireless communications, quantum measurements, and analog to digital conversion, was designed using group theory ideas.  - The capacity of wireless communication systems that do not have a constant source of energy, and that instead have a finite battery and must harvest energy from the environment, was studied.  - Intereference management algorithms were devised that can increase the capacity of cellular wireless networks by 20%-45%.  - Error-correcting codes were constructed for distributed storage systems where the integrity of the data must be maintained in the presence of disk and server failures.  The project brought together ideas from engineering, computer science and mathematics.The work was disseminated through conference and journal publications, and plenary talks by the PI. Most significantly, the PI co-organized two international workshops (with participation from the leading researchers in the fields of network information theory and entropy inequalities), one in the Chinese University of Hong Kong, and the other in the Henri Poincare Institute in Paris.       Last Modified: 07/01/2015       Submitted by: Babak Hassibi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
