<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TC: Small: Collaborative Research: Improved Privacy though Exposure Control</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>149859.00</AwardTotalIntnAmount>
<AwardAmount>149859</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>With the advent of sensor-rich mobile devices such as smartphones, an increasing number of people are sharing personal "contextual" information like location, activity, and health/fitness information with members of their social network.  To enhance privacy for people sharing such information, a large body of research has focused on ways for users to specify who should be authorized to access their information. This research improves end-user privacy by addressing the related question of "Who is accessing my information and to what extent?". Providing users with an accurate sense of their "exposure" will enable them to better control how their contextual information is shared and will help mitigate emerging privacy risks.&lt;br/&gt;&lt;br/&gt;This research advances the state of the art in privacy by formalizing the notion of exposure-awareness research, and by investigating metrics that can be used to quantify a person?s exposure, developing usable feedback models and visualizations that leverage these metrics to convey exposure, and creating exposure control extensions to established policy architectures to help users control exposure and refine their data sharing policies over time.  The proposed research will thus allow ordinary people to proactively rein in the amount of personal information shared online, and will reduce the privacy risks for the large population of users who are increasingly using social-networking applications to share personal contextual information.</AbstractNarration>
<MinAmdLetterDate>08/27/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/27/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1017229</AwardID>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam J Lee</PI_FULL_NAME>
<EmailAddress>adamlee@cs.pitt.edu</EmailAddress>
<PI_PHON>4126247400</PI_PHON>
<NSF_ID>000514312</NSF_ID>
<StartDate>08/27/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133203</ZipCode>
<StreetAddress><![CDATA[300 Murdoch Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~149859</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>With the advent of mobile-computing devices such as smartphones, tablets, and wearables, an increasing number of people are sharing or broadcasting personal contextual information using social-networking services such as Facebook and Twitter. For example, people are now sharing not only their location, but also geo-tagged photographs, activity information as deduced from onboard sensors such as accelerometers, and fitness information. &nbsp;A large body of research has focused on disclosure policies for personal information (i.e., Who should see my information?), but has neglected to characterize what we call a user's 'exposure' (i.e., Who is accessing my information and to what extent?). &nbsp;Existing work on disclosure policies allows, e.g., Alice to specify that her co-workers are permitted to access her physical location during the work week. &nbsp;While such policies may provide Alice with some baseline notion of exposure control, they do not provide Alice with feedback about her queriers. &nbsp;Would Alice still feel in control if she learned that Bob was accessing her location every 5 minutes? &nbsp;Or if every member of her project team checked her location while she was visiting a medical specialist? &nbsp;To truly enable individual control of data, people need a way to quantify, interpret, and control the extent to which this data is accessed, cross-correlated, and disseminated. &nbsp;During the course of this project, we have made a number of important advances with respect to this exposure control lifecycle:</p> <ul> <li>Design Principles for Exposure-Aware Systems: Throughout this project, our team has conducted a variety of surveys and user studies to better understand exposure in contextual sharing systems. &nbsp;These studies have provided insight into (i) the types of factors that individuals want to consider when sharing contextual information and where existing systems fall short of supporting this conditional disclosure; (ii) how differences in usage (e.g.,&nbsp; &nbsp;social vs. professional, always-on vs. check-in) of the same system &nbsp;can lead to very different norms of sharing and access, and thereby different exposure threats; (iii) the types of access patterns to an individual's data that are allowed by specified access policies, but are inconsistent with the individual's intended sharing&nbsp; &nbsp;behavior; and (iv) how over- and under-exposure awareness can alter an individual's use of a system. &nbsp;Our findings led to the design of the first exposure-aware policy language, and have informed the design of all system artifacts produced during this research.</li> <li>Exposure Awareness Interfaces: A key difficulty in building exposure-aware systems lies in identifying instances of over-sharing. &nbsp;The contextual, temporal, and intra-personal factors that lead to instances of over-exposure are often impossible to capture using the policy or preference languages supported by most platforms; as such, although an access is allowed by an individual's preferences, it may still be contrary to their desired exposure goals. To this end, we have developed exposure awareness interfaces that leverage aggregate exposure summaries to convey information to participants in a system, and evaluation methodologies for assessing the efficacy of these types of interfaces. &nbsp;Balancing the coarseness of these types of interfaces with the cognitive overhead of more frequent interruptions is a challenging problem that defines a fruitful space for future work.<br /><br /></li> <li>Secure Storage of Presence Information: One important finding from our surveys of user perception of exposure is the distinction between the utility of allowing a individual accesses to a user's contextual data (e.g., location, presence, etc.), and the intrusiveness of aggregate data collection. &nbsp;That is, a single disclosure of Alice's location is helpful for scheduli...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With the advent of mobile-computing devices such as smartphones, tablets, and wearables, an increasing number of people are sharing or broadcasting personal contextual information using social-networking services such as Facebook and Twitter. For example, people are now sharing not only their location, but also geo-tagged photographs, activity information as deduced from onboard sensors such as accelerometers, and fitness information.  A large body of research has focused on disclosure policies for personal information (i.e., Who should see my information?), but has neglected to characterize what we call a user's 'exposure' (i.e., Who is accessing my information and to what extent?).  Existing work on disclosure policies allows, e.g., Alice to specify that her co-workers are permitted to access her physical location during the work week.  While such policies may provide Alice with some baseline notion of exposure control, they do not provide Alice with feedback about her queriers.  Would Alice still feel in control if she learned that Bob was accessing her location every 5 minutes?  Or if every member of her project team checked her location while she was visiting a medical specialist?  To truly enable individual control of data, people need a way to quantify, interpret, and control the extent to which this data is accessed, cross-correlated, and disseminated.  During the course of this project, we have made a number of important advances with respect to this exposure control lifecycle:  Design Principles for Exposure-Aware Systems: Throughout this project, our team has conducted a variety of surveys and user studies to better understand exposure in contextual sharing systems.  These studies have provided insight into (i) the types of factors that individuals want to consider when sharing contextual information and where existing systems fall short of supporting this conditional disclosure; (ii) how differences in usage (e.g.,   social vs. professional, always-on vs. check-in) of the same system  can lead to very different norms of sharing and access, and thereby different exposure threats; (iii) the types of access patterns to an individual's data that are allowed by specified access policies, but are inconsistent with the individual's intended sharing   behavior; and (iv) how over- and under-exposure awareness can alter an individual's use of a system.  Our findings led to the design of the first exposure-aware policy language, and have informed the design of all system artifacts produced during this research. Exposure Awareness Interfaces: A key difficulty in building exposure-aware systems lies in identifying instances of over-sharing.  The contextual, temporal, and intra-personal factors that lead to instances of over-exposure are often impossible to capture using the policy or preference languages supported by most platforms; as such, although an access is allowed by an individual's preferences, it may still be contrary to their desired exposure goals. To this end, we have developed exposure awareness interfaces that leverage aggregate exposure summaries to convey information to participants in a system, and evaluation methodologies for assessing the efficacy of these types of interfaces.  Balancing the coarseness of these types of interfaces with the cognitive overhead of more frequent interruptions is a challenging problem that defines a fruitful space for future work.   Secure Storage of Presence Information: One important finding from our surveys of user perception of exposure is the distinction between the utility of allowing a individual accesses to a user's contextual data (e.g., location, presence, etc.), and the intrusiveness of aggregate data collection.  That is, a single disclosure of Alice's location is helpful for scheduling an in-person meeting, while repeated disclosures can lead to a wide array of profiling attacks.  To address this problem, we have developed cryptographic approaches for facilitating lo...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
