<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Randomized Algorithms in Linear Algebra and    Numerical Evaluations on Massive Datasets</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>220413.00</AwardTotalIntnAmount>
<AwardAmount>220413</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Data matrices have structural properties that present challenges and opportunities for both the Numerical Linear Algebra (NLA) community and the Theory of Algorithms (ToA) community. Matrix factorizations, such as the eigendecomposition, the rank-revealing QR factorization, and the Singular Value Decomposition, have been widely used for information retrieval. Historically, matrix factorizations have been of central interest in NLA since one can use them to express a problem in such a way that it can be solved more easily. ToA, on the other hand, has recently addressed the computation of such decompositions from a sampling perspective. The two approaches are complementary. However, thus far, the two communities have not worked closely together to integrate them. More often than not, each community is only cursorily aware of developments in the other community. Defining significant research directions that both communities can work on, and applying the resulting linear algebraic algorithms to data analysis problems (among others) will lead to important breakthroughs. The main objective for this proposal is to bridge the existing gap and bring together NLA and ToA researchers to promote cross-fertilization of ideas that could have immediate and long-term impact on data analysis. Towards that end, the PIs will work on set of prototypical research problems that can significantly benefit from ideas and research in both NLA and ToA. These problems range from approximating the singular values and vectors of a matrix by element-wise sampling to random-projection-based algorithms for least-squares problems and the design of randomized algorithms for the widely used non-negative matrix factorization.&lt;br/&gt;&lt;br/&gt;This proposal seeks to explore the complementary perspectives that the Numerical Linear Algebra and the Theory of Algorithms (ToA) communities bring to linear algebra and matrix computations. This is a timely quest, motivated by technological developments over the last two decades that permit the automatic generation of large datasets. Such datasets are often modeled as matrices. The proposed work will serve as a demonstration project on the fruitfulness of collaboration between the NLA and the ToA communities on problems that are of common interest. It is expected that the proposed research will demonstrate commonality in the two approaches, as well as highlight the advantages of the dual perspective. Through outreach activities, the PIs hope to motivate even more researchers to undertake similar investigations on related topics. The proposed algorithms will be numerically evaluated on a suite of matrices from application domains that the PIs have been working on over the past few years, in order to understand better their properties and to demonstrate their potential in dealing with the modern, massive datasets. More specifically, the PIs will test the proposed strategies on population genetics data in order to infer ancestry of individuals, as well as gene expression data in order to investigate hypotheses that correlate genes and diseases. As such, we expect that the developed algorithms will impact the areas of linear algebra, randomized algorithms, information retrieval and data mining, as well as bioinformatics. Finally, in order to disseminate the proposed research, the PIs intend to organize workshops (following the example of the Workshops on Algorithms for Modern Massive Datasets in 2006, 2008, and 2010; the PIs were co-organizers of these workshops) and working group meetings, and will disseminate their research via blogs and articles intended for broader audiences.</AbstractNarration>
<MinAmdLetterDate>09/21/2010</MinAmdLetterDate>
<MaxAmdLetterDate>05/29/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1008983</AwardID>
<Investigator>
<FirstName>Malik</FirstName>
<LastName>Magdon-Ismail</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Malik Magdon-Ismail</PI_FULL_NAME>
<EmailAddress>magdon@rpi.edu</EmailAddress>
<PI_PHON>5182764857</PI_PHON>
<NSF_ID>000111881</NSF_ID>
<StartDate>10/05/2010</StartDate>
<EndDate>05/29/2013</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Petros</FirstName>
<LastName>Drineas</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Petros Drineas</PI_FULL_NAME>
<EmailAddress>pdrineas@purdue.edu</EmailAddress>
<PI_PHON>2039013682</PI_PHON>
<NSF_ID>000117416</NSF_ID>
<StartDate>05/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002430742</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RENSSELAER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002430742</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rensselaer Polytechnic Institute]]></Name>
<CityName>Troy</CityName>
<StateCode>NY</StateCode>
<ZipCode>121803522</ZipCode>
<StreetAddress><![CDATA[110 8TH ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~220413</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <div>One of the more remarkable trends in recent years is a new paradigm that arose in Theoretical Computer Science (TCS) and that involves the use of randomization as a computational resource for the design and analysis of algorithms for fundamental matrix problems. Randomized Numerical Linear Algebra (RandNLA) is the interdisciplinary research area that exploits randomization as a computational resource to develop improved algorithms for large-scale linear algebra problems, e.g., matrix multiplication, linear regression, low-rank matrix approximation, etc. This project focused on applications of RandNLA that are both theoretically exciting and practically useful. The major achievements of this project can be summarized in the following bullet points.</div> <div>1. Computing very accurate CUR and CX-type decompositions via deterministic algorithms: a matrix A can be approximated by the product CUR, where C consists of a few columns of A, R consists of a few rows of A, and U is a small matrix. Such decompositions have significant data analysis applications, but their applicability was impeded by the lack of very accurate, deterministic algorithms to compute them. All known provably-accurate algorithms are randomized and necessitate a sub-optimal number of rows and columns of A to be included in R and C respectively. We designed, analyzed, and empirically evaluated deterministic algorithms for such decompositions.</div> <div>2. Fast approximation algorithms for least squares and more general regression problems: regression problems have proven to be the technique of choice in order to fit experimental observations in linear and non-linear functions. We theoretically analyzed and experimentally evaluated random projection-based algorithms for regression problems, where the the penalty is computed with respect to p-norms and not necessarily the euclidean norm.</div> <div>3. Computing singular values and singular vectors of matrices efficiently via, for example, element-wise sampling and iterative techniques: the idea of probabilistically sparsifying a large matrix in order to approximate its singular values and vectors using iterative techniques is a powerful primitive in the design and analysis of randomized algorithms for numerical linear algebra problem. When combined with random projections, it leads to efficient techniques that approximate the singular values and vectors of a matrix. We theoretically and experimental investigated the performance of such methods, as well as their applicability to identify important elements in a matrix.</div> <div>4. Choosing preconditioners via sampling-based methods: Preconditioning is essential to making Krylov subspace methods effective in solving large systems of linear equations. We investigated whether sampling-based approaches may be useful for designing preconditioners for certain classes of matrices, both theoretically and empirically.</div> <div>This project trained one PhD student. The PI was an organizer and a lecturer of the 2015 Gene Golub SIAM Summer School on the topic on Randomization in Numerical Linear Algebra. This massive outreach activity attracted 50 students from US and European universities and exposed this line of research to a broad audience.</div> <p>&nbsp;</p><br> <p>            Last Modified: 09/01/2015<br>      Modified by: Petros&nbsp;Drineas</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   One of the more remarkable trends in recent years is a new paradigm that arose in Theoretical Computer Science (TCS) and that involves the use of randomization as a computational resource for the design and analysis of algorithms for fundamental matrix problems. Randomized Numerical Linear Algebra (RandNLA) is the interdisciplinary research area that exploits randomization as a computational resource to develop improved algorithms for large-scale linear algebra problems, e.g., matrix multiplication, linear regression, low-rank matrix approximation, etc. This project focused on applications of RandNLA that are both theoretically exciting and practically useful. The major achievements of this project can be summarized in the following bullet points. 1. Computing very accurate CUR and CX-type decompositions via deterministic algorithms: a matrix A can be approximated by the product CUR, where C consists of a few columns of A, R consists of a few rows of A, and U is a small matrix. Such decompositions have significant data analysis applications, but their applicability was impeded by the lack of very accurate, deterministic algorithms to compute them. All known provably-accurate algorithms are randomized and necessitate a sub-optimal number of rows and columns of A to be included in R and C respectively. We designed, analyzed, and empirically evaluated deterministic algorithms for such decompositions. 2. Fast approximation algorithms for least squares and more general regression problems: regression problems have proven to be the technique of choice in order to fit experimental observations in linear and non-linear functions. We theoretically analyzed and experimentally evaluated random projection-based algorithms for regression problems, where the the penalty is computed with respect to p-norms and not necessarily the euclidean norm. 3. Computing singular values and singular vectors of matrices efficiently via, for example, element-wise sampling and iterative techniques: the idea of probabilistically sparsifying a large matrix in order to approximate its singular values and vectors using iterative techniques is a powerful primitive in the design and analysis of randomized algorithms for numerical linear algebra problem. When combined with random projections, it leads to efficient techniques that approximate the singular values and vectors of a matrix. We theoretically and experimental investigated the performance of such methods, as well as their applicability to identify important elements in a matrix. 4. Choosing preconditioners via sampling-based methods: Preconditioning is essential to making Krylov subspace methods effective in solving large systems of linear equations. We investigated whether sampling-based approaches may be useful for designing preconditioners for certain classes of matrices, both theoretically and empirically. This project trained one PhD student. The PI was an organizer and a lecturer of the 2015 Gene Golub SIAM Summer School on the topic on Randomization in Numerical Linear Algebra. This massive outreach activity attracted 50 students from US and European universities and exposed this line of research to a broad audience.          Last Modified: 09/01/2015       Submitted by: Petros Drineas]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
