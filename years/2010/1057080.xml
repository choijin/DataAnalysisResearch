<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Speaker variability and spoken language comprehension</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>410000.00</AwardTotalIntnAmount>
<AwardAmount>410000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Vishton</SignBlockName>
<PO_EMAI>pvishton@nsf.gov</PO_EMAI>
<PO_PHON>7032928132</PO_PHON>
</ProgramOfficer>
<AbstractNarration>One of the core goals in developmental science is to understand how children make sense of their highly variable sensory input. For instance, how does a child know that a cup viewed from the top and a cup viewed from the side--two very different visual images--are the same object? How does a child know that her mother saying "cat" and her sibling saying "cat"--two very different-sounding versions--are the same word? Adults do these things with trivial ease. However, the child has to figure out what sound patterns matter: which sounds should be linked to a representation of furry animals, and which should be linked to the person talking. Moreover, because spoken language happens rapidly, one word after another, the child must compute all of this information very quickly.&lt;br/&gt; &lt;br/&gt;Surprisingly little is known about the learning mechanisms that sort out the various sound patterns in spoken language. Children in the first year of life rapidly learn to tune out sound patterns that are not present in their native language, such as the difference between French nasalized and non-nasalized vowels. However, it is not known how children process sound patterns that are not directly related to meaning. This goal of this research is to understand how young language learners process talker-related sound variability--sound differences that do not change the meaning of a word, but vary with the vocal, social, and emotional characteristics of the person speaking. The research explores how children deal with talker variability: how it influences their learning of new vocabulary; what allows them to tune it out when recognizing words, but pay attention when recognizing talkers; how well they recognize voices and properties of voices such as gender and accent; and how this changes over development.&lt;br/&gt; &lt;br/&gt;This research has the potential to transform the way researchers think about language acquisition. Is it a process of tuning out much of the sound variability present, or is it instead a process of accumulating finely-detailed acoustic knowledge? More broadly, the knowledge gleaned will help to improve learning of new sound patterns, such as words in second languages and speech in unfamiliar accents. By more fully exploring normal language development, it will contribute to the picture of what is missing or disrupted in child language deficits. It may suggest improvements to automatic voice recognition systems, which currently do not cope well with the natural acoustic variability among talkers. Finally, the research will help uncover how listeners learn to make inferences about people based on the way they talk. This award will support a variety of students (graduate, undergraduate, high school) interested in scientific fields, contributing to the future science and technology workforce. It will also enable the investigator to share experimental materials with other researchers, streamlining the research process and quickening the pace of scientific advancement.</AbstractNarration>
<MinAmdLetterDate>08/18/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1057080</AwardID>
<Investigator>
<FirstName>Sarah</FirstName>
<LastName>Creel</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sarah C Creel</PI_FULL_NAME>
<EmailAddress>creel@cogsci.ucsd.edu</EmailAddress>
<PI_PHON>8585347308</PI_PHON>
<NSF_ID>000500184</NSF_ID>
<StartDate>08/18/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress><![CDATA[Office of Contract &amp; Grant A]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~68864</FUND_OBLG>
<FUND_OBLG>2012~73578</FUND_OBLG>
<FUND_OBLG>2013~170153</FUND_OBLG>
<FUND_OBLG>2014~97405</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Spoken language contains huge amounts of variability. Each time you hear the word "cat", for example, it has a different pitch, duration, and other acoustic details. One large source of variability is who is speaking: men sound different from women, and individual women sound different from other women (or men from men). This may make it difficult to separate out what parts of the sound patterns of a word are important for meaning. Of course, it is also sometimes useful to know who is speaking because different people are likely to speak about different things.</p> <p>The goal of this CAREER Award was to understand how child and adult language learners process speaker variability in spoken language--sound differences that do not change the meaning of a word, but vary with the vocal, social, and emotional characteristics of the person speaking.</p> <p>&nbsp;</p> <p><strong>Research goals</strong></p> <p>There were two major research subgoals. The first was to explore whether speaker variability is ignored or, instead, stored in memory as children and adults learn words. The second subgoal was to looks at children's abilities to predict upcoming spoken material in real time (verb objects, or ends of words) based on preceding talker acoustics. We addressed these questions in 14 journal articles and conference proceedings papers.</p> <p><em>Is speaker variability ignored during word learning, or stored in memory?</em></p> <p>In short, speaker variability is stored in memory, likely as part of the memory of the word itself. If child learners (ages 3-5 years) are taught word pairs that sound similar, such as <em>marv</em> and <em>mard</em>, the learners tend to have difficulty telling them apart--it takes them a long time to decide which one they are hearing. However, if learners consistently hear <em>marv </em>spoken by a female speaker but <em>mard </em>by a male speaker, they can tell the words apart sooner. This finding in young children fits with what we know about adults' word learning from the PI's previous research. When talker information is useful, learners readily use it. What this suggests is that the way that language learners figure out that talker characteristics (a low-pitched "cat", for example) are irrelevant, while 'd' and 'v' sounds <em>are </em>relevant, in the real world is by exposure to lots of cases where talker characteristics are <em>not</em> useful.</p> <p>We also assessed how good people are at identifying voices to begin with. Children are not nearly as good as adults at learning to recognize new talkers. Similarly, we found that late second-language learners or are not as good as native speakers at learning to recognize new voices in a language. These findings suggest that talker recognition itself, like face recognition, is a complex perceptual problem for learners to solve.</p> <p><em>Can children predict upcoming words in "real time" (as they are hearing speech) by using talker acoustics?</em></p> <p>Yes, they can! We looked at this in multiple studies. In one set of studies, we introduced children to two cartoon characters, each of whom liked a particular color (say, black or white). They then saw sets of four shapes at a time, half of them black, half of them white. When the speaker who liked the color black began to say "can you show me the square", children looked toward the black shapes even before they heard the word "square." In a different study, children were introduced to two speakers, for example a princess and a pirate. They then saw a set of pictures such as a wand, a sword, a ship, and a carriage. When the princess said, "I want to hold the wand," children looked toward the wand (and to some extent the princess-related carriage) before they even heard the word "wand." These studies suggest that speech in a particular voice helps children to predict what is likely to be talked about</p> <p>The studies conducted here begin to help us understand how children begin to tap into the rich variation in spoken language sound patterns, and how adult listeners use that information in sophisticated ways.</p> <p>&nbsp;</p> <p><strong>Education and facilitation of research</strong></p> <p>In terms of education and facilitation of research, there were several subgoals, including: to develop a database of experimental paradigms to be used by students and researchers (Modifiable Language Experiments, or MoLE); to better prepare graduate students for the workforce; and to create science experiences for high schoolers from varied social and economic backgrounds.</p> <p>We have deployed the database of experiment code (quote.ucsd.edu/mole), trained multiple graduate students, laboratory assistants, and volunteers, and hosted 20 high school interns from UCSD's Preuss School, a nationally-recognized transformative high school for first-generation college-bound students.</p><br> <p>            Last Modified: 08/08/2019<br>      Modified by: Sarah&nbsp;C&nbsp;Creel</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Spoken language contains huge amounts of variability. Each time you hear the word "cat", for example, it has a different pitch, duration, and other acoustic details. One large source of variability is who is speaking: men sound different from women, and individual women sound different from other women (or men from men). This may make it difficult to separate out what parts of the sound patterns of a word are important for meaning. Of course, it is also sometimes useful to know who is speaking because different people are likely to speak about different things.  The goal of this CAREER Award was to understand how child and adult language learners process speaker variability in spoken language--sound differences that do not change the meaning of a word, but vary with the vocal, social, and emotional characteristics of the person speaking.     Research goals  There were two major research subgoals. The first was to explore whether speaker variability is ignored or, instead, stored in memory as children and adults learn words. The second subgoal was to looks at children's abilities to predict upcoming spoken material in real time (verb objects, or ends of words) based on preceding talker acoustics. We addressed these questions in 14 journal articles and conference proceedings papers.  Is speaker variability ignored during word learning, or stored in memory?  In short, speaker variability is stored in memory, likely as part of the memory of the word itself. If child learners (ages 3-5 years) are taught word pairs that sound similar, such as marv and mard, the learners tend to have difficulty telling them apart--it takes them a long time to decide which one they are hearing. However, if learners consistently hear marv spoken by a female speaker but mard by a male speaker, they can tell the words apart sooner. This finding in young children fits with what we know about adults' word learning from the PI's previous research. When talker information is useful, learners readily use it. What this suggests is that the way that language learners figure out that talker characteristics (a low-pitched "cat", for example) are irrelevant, while 'd' and 'v' sounds are relevant, in the real world is by exposure to lots of cases where talker characteristics are not useful.  We also assessed how good people are at identifying voices to begin with. Children are not nearly as good as adults at learning to recognize new talkers. Similarly, we found that late second-language learners or are not as good as native speakers at learning to recognize new voices in a language. These findings suggest that talker recognition itself, like face recognition, is a complex perceptual problem for learners to solve.  Can children predict upcoming words in "real time" (as they are hearing speech) by using talker acoustics?  Yes, they can! We looked at this in multiple studies. In one set of studies, we introduced children to two cartoon characters, each of whom liked a particular color (say, black or white). They then saw sets of four shapes at a time, half of them black, half of them white. When the speaker who liked the color black began to say "can you show me the square", children looked toward the black shapes even before they heard the word "square." In a different study, children were introduced to two speakers, for example a princess and a pirate. They then saw a set of pictures such as a wand, a sword, a ship, and a carriage. When the princess said, "I want to hold the wand," children looked toward the wand (and to some extent the princess-related carriage) before they even heard the word "wand." These studies suggest that speech in a particular voice helps children to predict what is likely to be talked about  The studies conducted here begin to help us understand how children begin to tap into the rich variation in spoken language sound patterns, and how adult listeners use that information in sophisticated ways.     Education and facilitation of research  In terms of education and facilitation of research, there were several subgoals, including: to develop a database of experimental paradigms to be used by students and researchers (Modifiable Language Experiments, or MoLE); to better prepare graduate students for the workforce; and to create science experiences for high schoolers from varied social and economic backgrounds.  We have deployed the database of experiment code (quote.ucsd.edu/mole), trained multiple graduate students, laboratory assistants, and volunteers, and hosted 20 high school interns from UCSD's Preuss School, a nationally-recognized transformative high school for first-generation college-bound students.       Last Modified: 08/08/2019       Submitted by: Sarah C Creel]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
