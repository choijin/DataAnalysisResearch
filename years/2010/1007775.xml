<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Sequential testing of multiple hypotheses, simultaneous confidence estimation, and multichannel change-point detection</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2010</AwardEffectiveDate>
<AwardExpirationDate>05/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The project focuses on the development of new theory and methodology of sequential multiple comparisons. It aims to develop cost-minimizing methods and supporting theory for conducting multiple statistical inferences sequentially. This includes testing multiple hypotheses, constructing sequences of simultaneous confidence sets, detecting changes in multiple channels, and making other sequential statistical decisions involving multiple parameters or multiple measurements. This study extends the recently obtained step-up and step-down procedures for multiple comparisons to sequential designs. It searches for optimal stopping rules that minimize the expected cost of the experiment while controlling for the false positive and false negative rates. The new methodology combines flexibility and cost-optimization of sequential procedures with the ability of modern statistical methods for multiple comparisons to control the familywise error rate and power. Proposed sequences of simultaneous confidence sets generalize the idea of repeated confidence intervals to the case of multiple parameters and achieve the desired overall confidence level. The new multiple hypothesis testing methodology is used for the derivation of sequential change-point detection algorithms sensitive to a change in any one or several parameters.&lt;br/&gt;&lt;br/&gt;Deliverables of the project include a sound statistical methodology for designing multiple comparison experiments at the minimum expected cost. One of the main applications is in sequential clinical trials that are conducted to answer multiple questions, for example, about the efficacy and safety of the tested treatment. Cost-optimization of such medical studies ultimately results in the reduced cost of health care. The new change-point detection procedures allow simultaneous tracking of changes in multiple parameters, which is used for the timely discovery of epidemic and pre-epidemic patterns and bioterrorist attacks. Controlling for the rate of false alarms, proposed change-point detection schemes are aimed to minimize the expected detection delay ensuring prompt reaction to unexpected changes. Their application sheds light to a number of global questions. Is the economy (welfare, climate, environment) changing? In what way and what direction is it changing? When did the change begin? Does the change continue, or has the process stabilized? Proposed sequential statistical tools address these and other important questions that involve multiple statistical comparisons.</AbstractNarration>
<MinAmdLetterDate>05/10/2010</MinAmdLetterDate>
<MaxAmdLetterDate>03/05/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1007775</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Baron</LastName>
<PI_MID_INIT>I</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael I Baron</PI_FULL_NAME>
<EmailAddress>baron@american.edu</EmailAddress>
<PI_PHON>2028853130</PI_PHON>
<NSF_ID>000228678</NSF_ID>
<StartDate>05/10/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Dallas</Name>
<CityName>Richardson</CityName>
<ZipCode>750803021</ZipCode>
<PhoneNumber>9728832313</PhoneNumber>
<StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX32</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>800188161</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT DALLAS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Dallas]]></Name>
<CityName>Richardson</CityName>
<StateCode>TX</StateCode>
<ZipCode>750803021</ZipCode>
<StreetAddress><![CDATA[800 W. Campbell Rd., AD15]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~75565</FUND_OBLG>
<FUND_OBLG>2011~72562</FUND_OBLG>
<FUND_OBLG>2012~51873</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>The project resulted in <em>a cost-efficient methodology and supporting theory of multiple sequential testing&nbsp;and other multiple statistical inferences on sequentially collected data</em>. Procedures were designed for a general sequence of observed random vectors whose components, dependent or independent data streams, are parameterized by one or several parameters. Efficient statistical tools were developed to conduct simultaneous inferences about these parameters, satisfying desired accuracy conditions and optimizing the expected cost of the whole experiment under these constraints.</p> <p>The main outcome of the project is development of <em>stepwise sequential procedures for testing multiple hypotheses that control both the Type I and Type II familywise error rates (FWER)</em>, the probabilities of at least one Type I or Type II error. Stepwise design of the developed methods allowed reduction of the expected sample size comparing with the commonly used Bonferroni procedures. Further, the new schemes showed a 15% to 30% reduction of the sample size versus non-sequential procedures with the same error rates. Application of this approach in clinical research translates into reduced cost of medical treatments, and consequently, <em>it will reduce the cost of health care.</em></p> <p>Other applications of the new methods are anticipated in quality and process control, acceptance sampling, and genetics. Addressing the issue of a <em>very large number of simultaneous tests</em> that often occurs in genomics, epidemiology, security, computer science, communications, and other areas, the stepwise methodology was developed further and resulted in sequential procedures <em>controlling generalized FWER</em>, i.e. probabilities of at least k Type I errors and at least m Type II errors at the given levels &alpha; and &beta;. The new methods are applied to testing multiple efficacy and safety endpoints, performing the DNA and protein sequence analysis, and so on. Controlling k-FWER at the given desired level is a weaker constraint than the standard FWER, and therefore, this condition can be satisfied by a smaller sample. The new results showed that this generalization of the classical notion of FWER resulted in substantial reduction of the expected sample size of multiple testing procedures.</p> <p>Special methods were developed for <em>multistage and truncated group sequential experiments</em>. These procedures are designed to control both FWER at specified levels &alpha; and &beta;, complete the entire experiment within at most K stages, and minimize the total expected cost under these constraints. These procedures are particularly attractive for group sequential clinical trials.</p> <p>Asymptotically optimal rules were obtained for a number of situations. That is, the best rate of the expected sample size was derived, and stopping boundaries were calculated that achieve the <em>best asymptotic rate</em> under the constraints on FWER I and II. Among other results, it was proved that in a battery of tests, the optimal Type I and Type II error allocation distributes all the error probabilities among the most difficult tests, determined according to the closeness between the null and alternative parameters.</p> <p>Developed sequential methodology for multiple hypothesis testing was applied to <em>sequential multi-channel change-point detection</em>. It was assumed that a number of &ldquo;sensors&rdquo; simultaneously collect and report data. These can be public health surveillance data, border patrol monitoring traffic across the border, or simply smoke detectors in different locations. When a significant event occurs, the distribution of data in one or several sequences changes, and the goal is to detect such a change as soon as possible after it occurs, subject to the rate of false alarms. This problem is well studied in the case of one sensor, but it lac...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    The project resulted in a cost-efficient methodology and supporting theory of multiple sequential testing and other multiple statistical inferences on sequentially collected data. Procedures were designed for a general sequence of observed random vectors whose components, dependent or independent data streams, are parameterized by one or several parameters. Efficient statistical tools were developed to conduct simultaneous inferences about these parameters, satisfying desired accuracy conditions and optimizing the expected cost of the whole experiment under these constraints.  The main outcome of the project is development of stepwise sequential procedures for testing multiple hypotheses that control both the Type I and Type II familywise error rates (FWER), the probabilities of at least one Type I or Type II error. Stepwise design of the developed methods allowed reduction of the expected sample size comparing with the commonly used Bonferroni procedures. Further, the new schemes showed a 15% to 30% reduction of the sample size versus non-sequential procedures with the same error rates. Application of this approach in clinical research translates into reduced cost of medical treatments, and consequently, it will reduce the cost of health care.  Other applications of the new methods are anticipated in quality and process control, acceptance sampling, and genetics. Addressing the issue of a very large number of simultaneous tests that often occurs in genomics, epidemiology, security, computer science, communications, and other areas, the stepwise methodology was developed further and resulted in sequential procedures controlling generalized FWER, i.e. probabilities of at least k Type I errors and at least m Type II errors at the given levels &alpha; and &beta;. The new methods are applied to testing multiple efficacy and safety endpoints, performing the DNA and protein sequence analysis, and so on. Controlling k-FWER at the given desired level is a weaker constraint than the standard FWER, and therefore, this condition can be satisfied by a smaller sample. The new results showed that this generalization of the classical notion of FWER resulted in substantial reduction of the expected sample size of multiple testing procedures.  Special methods were developed for multistage and truncated group sequential experiments. These procedures are designed to control both FWER at specified levels &alpha; and &beta;, complete the entire experiment within at most K stages, and minimize the total expected cost under these constraints. These procedures are particularly attractive for group sequential clinical trials.  Asymptotically optimal rules were obtained for a number of situations. That is, the best rate of the expected sample size was derived, and stopping boundaries were calculated that achieve the best asymptotic rate under the constraints on FWER I and II. Among other results, it was proved that in a battery of tests, the optimal Type I and Type II error allocation distributes all the error probabilities among the most difficult tests, determined according to the closeness between the null and alternative parameters.  Developed sequential methodology for multiple hypothesis testing was applied to sequential multi-channel change-point detection. It was assumed that a number of "sensors" simultaneously collect and report data. These can be public health surveillance data, border patrol monitoring traffic across the border, or simply smoke detectors in different locations. When a significant event occurs, the distribution of data in one or several sequences changes, and the goal is to detect such a change as soon as possible after it occurs, subject to the rate of false alarms. This problem is well studied in the case of one sensor, but it lacked adequate solutions when multiple sensors were involved. By analogy with hypothesis testing, the new change-point detection tools control the probability of a false alarm (analogue of Type ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
