<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDI-Type II: Inference at the Nanoscale</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>647493.00</AwardTotalIntnAmount>
<AwardAmount>647493</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
<PO_EMAI>sabasu@nsf.gov</PO_EMAI>
<PO_PHON>7032927843</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to develop a new inference-based information processing structure that performs probabilistic computing using radically new nanoscale devices.  This approach exploits the analog, time-dependent properties of such devices, and their massive parallelism.  By doing so, such a computing structure will be more efficient and scalable than by using more traditional digital hardware.  This approach is one of the first to include time-dependent circuit elements to build analog associative memories that approximate Bayesian inference, and which are, in turn, assembled into complex networks that capture higher order structure in streams of data.  The ultimate goal is to use these circuits to develop hybrid CMOS / molecular scale implementations of a Field Adaptable Bayesian Array (FABA), which has the potential to be a key component for Cyber-Enabled discovery.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Cyber-Enabled discovery is addressed in this research in two ways.  The first concerns the design of analog circuits based on complex nano and molecular scale devices with time-varying properties. And the second concerns the creation of a new family of semiconductor components that will significantly enhance Cyber-Enabled discovery applications across a wide range of data and applications.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Designing analog nano-electronic circuits that perform inference through space and time and which consist of dynamic components (such as mem-resistance and mem-capacitance) is extraordinarily difficult. This is particularly true when one considers the wide range of complex devices that are being developed in laboratories around the world for nano and molecular scale electronics.  For this effort we have defined an Exploration Methodology that combines multiple levels of abstraction and evolvable computation.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Two key developments then are a design exploration methodology for such devices, and a massively parallel architecture for data capture and inference.  This research will explore a new paradigm for using nanoscale electronics for emerging applications by starting with the "top-down" system requirements rather than by finding applications for new device concepts ("bottom-up").&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;As the semiconductor industry struggles with where to go next, the work proposed here may provide insight into radical new approaches to architecture, circuits and devices.  This research will ultimately benefit society by enhancing human cognition and generating new knowledge from the wealth of heterogeneous digital data society has to deal with.</AbstractNarration>
<MinAmdLetterDate>09/20/2010</MinAmdLetterDate>
<MaxAmdLetterDate>02/09/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1028378</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Hammerstrom</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel W Hammerstrom</PI_FULL_NAME>
<EmailAddress>strom@cecs.pdx.edu</EmailAddress>
<PI_PHON>5037255125</PI_PHON>
<NSF_ID>000414379</NSF_ID>
<StartDate>09/20/2010</StartDate>
<EndDate>02/09/2012</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Christof</FirstName>
<LastName>Teuscher</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christof Teuscher</PI_FULL_NAME>
<EmailAddress>teuscher@pdx.edu</EmailAddress>
<PI_PHON>5037252817</PI_PHON>
<NSF_ID>000514756</NSF_ID>
<StartDate>02/09/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Christof</FirstName>
<LastName>Teuscher</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christof Teuscher</PI_FULL_NAME>
<EmailAddress>teuscher@pdx.edu</EmailAddress>
<PI_PHON>5037252817</PI_PHON>
<NSF_ID>000514756</NSF_ID>
<StartDate>09/20/2010</StartDate>
<EndDate>02/09/2012</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Portland State University</Name>
<CityName>Portland</CityName>
<ZipCode>972070751</ZipCode>
<PhoneNumber>5037259900</PhoneNumber>
<StreetAddress>1600 SW 4th Ave</StreetAddress>
<StreetAddress2><![CDATA[Attn: Sponsored Projects Admin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052226800</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PORTLAND STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052226800</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Portland State University]]></Name>
<CityName>Portland</CityName>
<StateCode>OR</StateCode>
<ZipCode>972070751</ZipCode>
<StreetAddress><![CDATA[1600 SW 4th Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7751</Code>
<Text>CDI TYPE II</Text>
</ProgramElement>
<ProgramReference>
<Code>7721</Code>
<Text>FROM DATA TO KNOWLEDGE</Text>
</ProgramReference>
<ProgramReference>
<Code>7722</Code>
<Text>COMPLEXITY</Text>
</ProgramReference>
<ProgramReference>
<Code>7752</Code>
<Text>CDI NON SOLICITED RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~647493</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to develop a new inference-based information processing architecture that performs probabilistic computing using radically new nanoscale devices. In this collaborative project, our approach consisted in exploited the analog, time-dependent properties of such devices, and their massive parallelism. We used theory, simulations, and actual physical devices to demonstrate that such architectures can be more efficient and scalable than by using more traditional digital hardware. Our approach is one of the first to include time-dependent circuit elements to build analog associative memories that approximated Bayesian inference, and which were, in turn, assembled into complex networks that capture higher order structure in streams of data. &nbsp;</p> <p>The major outcomes can be summarized as following:</p> <p>(1) Reservoir computing is a 3rd generation machine learning approach that harnesses the intrinsic dynamics of a so-called "reservoir" that acts as a kernel. We were the first to use memristors to build such reservoirs and to show that high-performance and low-power systems can built. We used this approach to obtain a simple associative memory, which we then used as a building block for Bayesian inference architectures.</p> <p>(2) We designed, tested, and evaluated a memristor-based Bayesian Memory (BM) in hardware. The structure of the BM consists of a memory to store the training patterns, a Conditional Probability Table (CPT), where the likelihood probabilities of the input vector and the stored training vectors are calculated, and an inference module. We also showed that hierarchical systems perform better than monolithic systems.</p> <p>(3) The popularity of memristors has led to a wide range of models being proposed for both physically realized devices and their concepts in general. These models have been fit to specific devices, but the resulting device models are not often discussed in relation to specific applications. A common tool in neuromorphic algorithms, crossbar architectures rely exclusively on the electrical properties of the device connecting rows to columns. Using memristors for these connections, we investigated the viability of 14 device models found in literature for this application. Many of these models were subsequently used to validate your architectures.</p> <p>(4) Pattern matching algorithms, which may be realized via associative memories, require further improvements in both accuracy and power consumption to achieve more widespread use in real-world applications. We utilized a memristive crossbar to combine computation and memory in an approximate Hamming distance computing architecture for an associative memory. For classifying handwritten digits from the MNIST data-set, we showed that using the Hamming distance rather than the traditional dot product increased accuracy, and decreased power consumption by 100x.&nbsp;</p> <p>(5) We developed and simulated an in-situ learning algorithm with limitations on both the resolution of its weights and the means of switching between them to gain an appreciation for how these properties might affect classification performance of compact neuromorphic nanoscale architectures based on memristors. Our results also showed that the resolution required from a device depends on its transition function between states; for transitions akin to round to nearest, synaptic weights should have around 16 possible states to obtain optimal results.&nbsp;</p> <p>(6) While Bayesian inference can enhance intelligent probabilistic computing systems, such systems are often computationally expensive and not well suited for implementing on von Neumann architectures. We proposed a simplified, parallel, and efficient memristor-based architecture that approximates naive and non-naive Bayesian inference. Results with the MNIST data set showed that for similar performance, we can improve the power consumption by a factor of 10 compared to spin-neurons and by a factor of 2,000 compared to a CMOS implementation.&nbsp;</p> <p>The project trained and supported 4 undergraduate students, 5 Master's students, and 4 PhD students. The research resulted in about 20 publications. The paper "On the Influence of Synaptic Weight States in a Locally Competitive Algorithm for Memristive Hardware" won the 2014 Best Paper Award at the IEEE/ACM International Symposium on Nanoscale Architectures.</p> <p><br />The research of this project was integrated into a graduate class on "Advanced Embedded In Silico and In Materio Computing." Ethical and societal questions related to nano and other emerging technologies were discussed at length in the freshman course on "Life Unlimited?" that the PI developed and taught over the last 4 years. Majors from the entire university attended this course. The materials were further disseminated in social media and at public lectures, such as at Lincoln High School, Portland, OR, where the PI's presentation was attended by 120 high school students. As a consequence, two of the attendees later did an internship in the PI's lab.</p> <p>As the semiconductor industry struggles with where to go next, the outcomes of this award provided valuable insight into radical new approaches to architectures, circuits and devices for intelligent information processing. Our research may ultimately benefit society by enhancing human cognition and generating new knowledge from the wealth of heterogeneous digital data we all use and generate.</p><br> <p>            Last Modified: 11/30/2016<br>      Modified by: Christof&nbsp;Teuscher</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to develop a new inference-based information processing architecture that performs probabilistic computing using radically new nanoscale devices. In this collaborative project, our approach consisted in exploited the analog, time-dependent properties of such devices, and their massive parallelism. We used theory, simulations, and actual physical devices to demonstrate that such architectures can be more efficient and scalable than by using more traditional digital hardware. Our approach is one of the first to include time-dependent circuit elements to build analog associative memories that approximated Bayesian inference, and which were, in turn, assembled into complex networks that capture higher order structure in streams of data.    The major outcomes can be summarized as following:  (1) Reservoir computing is a 3rd generation machine learning approach that harnesses the intrinsic dynamics of a so-called "reservoir" that acts as a kernel. We were the first to use memristors to build such reservoirs and to show that high-performance and low-power systems can built. We used this approach to obtain a simple associative memory, which we then used as a building block for Bayesian inference architectures.  (2) We designed, tested, and evaluated a memristor-based Bayesian Memory (BM) in hardware. The structure of the BM consists of a memory to store the training patterns, a Conditional Probability Table (CPT), where the likelihood probabilities of the input vector and the stored training vectors are calculated, and an inference module. We also showed that hierarchical systems perform better than monolithic systems.  (3) The popularity of memristors has led to a wide range of models being proposed for both physically realized devices and their concepts in general. These models have been fit to specific devices, but the resulting device models are not often discussed in relation to specific applications. A common tool in neuromorphic algorithms, crossbar architectures rely exclusively on the electrical properties of the device connecting rows to columns. Using memristors for these connections, we investigated the viability of 14 device models found in literature for this application. Many of these models were subsequently used to validate your architectures.  (4) Pattern matching algorithms, which may be realized via associative memories, require further improvements in both accuracy and power consumption to achieve more widespread use in real-world applications. We utilized a memristive crossbar to combine computation and memory in an approximate Hamming distance computing architecture for an associative memory. For classifying handwritten digits from the MNIST data-set, we showed that using the Hamming distance rather than the traditional dot product increased accuracy, and decreased power consumption by 100x.   (5) We developed and simulated an in-situ learning algorithm with limitations on both the resolution of its weights and the means of switching between them to gain an appreciation for how these properties might affect classification performance of compact neuromorphic nanoscale architectures based on memristors. Our results also showed that the resolution required from a device depends on its transition function between states; for transitions akin to round to nearest, synaptic weights should have around 16 possible states to obtain optimal results.   (6) While Bayesian inference can enhance intelligent probabilistic computing systems, such systems are often computationally expensive and not well suited for implementing on von Neumann architectures. We proposed a simplified, parallel, and efficient memristor-based architecture that approximates naive and non-naive Bayesian inference. Results with the MNIST data set showed that for similar performance, we can improve the power consumption by a factor of 10 compared to spin-neurons and by a factor of 2,000 compared to a CMOS implementation.   The project trained and supported 4 undergraduate students, 5 Master's students, and 4 PhD students. The research resulted in about 20 publications. The paper "On the Influence of Synaptic Weight States in a Locally Competitive Algorithm for Memristive Hardware" won the 2014 Best Paper Award at the IEEE/ACM International Symposium on Nanoscale Architectures.   The research of this project was integrated into a graduate class on "Advanced Embedded In Silico and In Materio Computing." Ethical and societal questions related to nano and other emerging technologies were discussed at length in the freshman course on "Life Unlimited?" that the PI developed and taught over the last 4 years. Majors from the entire university attended this course. The materials were further disseminated in social media and at public lectures, such as at Lincoln High School, Portland, OR, where the PI's presentation was attended by 120 high school students. As a consequence, two of the attendees later did an internship in the PI's lab.  As the semiconductor industry struggles with where to go next, the outcomes of this award provided valuable insight into radical new approaches to architectures, circuits and devices for intelligent information processing. Our research may ultimately benefit society by enhancing human cognition and generating new knowledge from the wealth of heterogeneous digital data we all use and generate.       Last Modified: 11/30/2016       Submitted by: Christof Teuscher]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
