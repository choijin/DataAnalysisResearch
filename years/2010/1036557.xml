<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Jaws and Backbone: Chondrichthyan Phylogeny and a Spine for the Vertebrate Tree of Life</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08010206</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DEB</Abbreviation>
<LongName>Division Of Environmental Biology</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Simon Malcomber</SignBlockName>
<PO_EMAI>smalcomb@nsf.gov</PO_EMAI>
<PO_PHON>7032928227</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Chondrichthyans, or sharks, rays and chimaeras, are some of the best known marine animals in popular culture but poorly known in terms of their evolution. Despite being an ancient group, we know surprisingly little about the patterns and processes that gave rise to their current diversity - a diversity that is increasingly under threat through environmental and fishing pressures. This project will catalog the diversity of sharks, skates, rays and chimaeras, provide a genealogy of relationships based on DNA sequence comparisons, and provide a data base of 3-D virtual skeletons based on CT scan data to document all of the physical variations that characterize the major lineages.&lt;br/&gt;&lt;br/&gt;The project will involve the development of technologies that will impact the way DNA sequences are collected for the purpose of comparison across organisms. This could have far reaching benefits for disciplines such as comparative biochemistry, physiology and medicine that are based on comparative approaches. The outreach component of the project will exploit the popular appeal of sharks to show how modern molecular biology and computer visualization techniques are being applied to better understand the evolution of the world's increasingly threatened biodiversity.&lt;br/&gt;&lt;br/&gt;This project is part of a 10-year effort to digitize and mobilize the scientific information associated with biological specimens held in U.S. research collections. The images and digitized data from this project will be integrated into the online national resource as outlined in the community strategic plan available at http://digbiocol.files.wordpress.com/2010/05/digistratplanfinaldraft.pdf.</AbstractNarration>
<MinAmdLetterDate>08/19/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1036557</AwardID>
<Investigator>
<FirstName>Eliot</FirstName>
<LastName>Winer</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eliot H Winer</PI_FULL_NAME>
<EmailAddress>ewiner@iastate.edu</EmailAddress>
<PI_PHON>5159891750</PI_PHON>
<NSF_ID>000149354</NSF_ID>
<StartDate>08/19/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Iowa State University</Name>
<CityName>AMES</CityName>
<ZipCode>500112207</ZipCode>
<PhoneNumber>5152945225</PhoneNumber>
<StreetAddress>1138 Pearson</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<StateCode>IA</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IA04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005309844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005309844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Iowa State University]]></Name>
<CityName>AMES</CityName>
<StateCode>IA</StateCode>
<ZipCode>500112207</ZipCode>
<StreetAddress><![CDATA[1138 Pearson]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IA04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7689</Code>
<Text>ASSEMBLING THE TREE OF LIFE</Text>
</ProgramElement>
<ProgramReference>
<Code>6895</Code>
<Text>DIGITIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7275</Code>
<Text>CROSS-EF ACTIVITIES</Text>
</ProgramReference>
<ProgramReference>
<Code>7689</Code>
<Text>Assembling the Tree of Life</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The &ldquo;Collaborative Research: Jaws and Backbone: Chondrichthyan Phylogeny and a Spine for the Vertebrate Tree of Life&rdquo; project involves several institutions each with its own respective expertise. Iowa State University&rsquo;s role in this project was to develop advanced visualization capabilities for use in examining the anatomy of species of sharks and rays.</p> <p>Several capabilities were developed to not only visualize this data, but also allow interaction in a unique and easy to master manner. This data is stored and transmitted using the traditional medical imaging techniques of Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). So, while these advances help the project visualize sharks and rays, the software could serve as a foundation for visualizing human anatomy as well. These interactive visual representations can be done on a range of computer systems from traditional desktop computers to mobile tablets to large, immersive virtual reality (VR) systems involving multiple screens and a cluster of computers.</p> <p>A study was performed to examine if a commodity, &ldquo;natural&rdquo; interaction device (e.g., a Microsoft Kinect) was easier to use than a traditional mouse and keyboard. The results of the study demonstrated that the more natural gestures (e.g., swiping, pushing hands forward and back) afforded by the Microsoft Kinect were not only preferred by users, but also improved their performance when asked to accomplish specific tasks with the visual representations.</p> <p>In addition, development of software to create advanced 3D representations of digital medical data on mobile devices proved extremely challenging. Mobile devices (i.e. smart phones and tablets) have no where near the computational power of a typical desktop or laptop computer. This is especially true with regards to 3D graphics. Thus, creating highly realistic 3D visual representations proves difficult. Approaches were developed that not only created these 3D representations on a mobile tablet, but allowed real-time interaction. To accomplish this, complex graphical algorithms were developed using advanced features of the tablet with intelligent mathematical processing.</p> <p>Following this work, a framework for performing 3D visualizations of the anatomy of sharks and rays on a range of computer systems was accomplished.</p><br> <p>            Last Modified: 12/09/2015<br>      Modified by: Eliot&nbsp;H&nbsp;Winer</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2015/1036557/1036557_10021123_1449701814308_IMG_4095--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1036557/1036557_10021123_1449701814308_IMG_4095--rgov-800width.jpg" title="3D Visualization of Medical Data in Virtual Reality"><img src="/por/images/Reports/POR/2015/1036557/1036557_10021123_1449701814308_IMG_4095--rgov-66x44.jpg" alt="3D Visualization of Medical Data in Virtual Reality"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Demonstrating the real-time visualization of digital medical data in Iowa State University's C6 virtual reality (VR) system. The C6 is the world's highest resolution, six-sided VR system</div> <div class="imageCredit">Paul Easker</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Eliot&nbsp;H&nbsp;Winer</div> <div class="imageTitle">3D Visualization of Medical Data in Virtual Reality</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The "Collaborative Research: Jaws and Backbone: Chondrichthyan Phylogeny and a Spine for the Vertebrate Tree of Life" project involves several institutions each with its own respective expertise. Iowa State UniversityÃ†s role in this project was to develop advanced visualization capabilities for use in examining the anatomy of species of sharks and rays.  Several capabilities were developed to not only visualize this data, but also allow interaction in a unique and easy to master manner. This data is stored and transmitted using the traditional medical imaging techniques of Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). So, while these advances help the project visualize sharks and rays, the software could serve as a foundation for visualizing human anatomy as well. These interactive visual representations can be done on a range of computer systems from traditional desktop computers to mobile tablets to large, immersive virtual reality (VR) systems involving multiple screens and a cluster of computers.  A study was performed to examine if a commodity, "natural" interaction device (e.g., a Microsoft Kinect) was easier to use than a traditional mouse and keyboard. The results of the study demonstrated that the more natural gestures (e.g., swiping, pushing hands forward and back) afforded by the Microsoft Kinect were not only preferred by users, but also improved their performance when asked to accomplish specific tasks with the visual representations.  In addition, development of software to create advanced 3D representations of digital medical data on mobile devices proved extremely challenging. Mobile devices (i.e. smart phones and tablets) have no where near the computational power of a typical desktop or laptop computer. This is especially true with regards to 3D graphics. Thus, creating highly realistic 3D visual representations proves difficult. Approaches were developed that not only created these 3D representations on a mobile tablet, but allowed real-time interaction. To accomplish this, complex graphical algorithms were developed using advanced features of the tablet with intelligent mathematical processing.  Following this work, a framework for performing 3D visualizations of the anatomy of sharks and rays on a range of computer systems was accomplished.       Last Modified: 12/09/2015       Submitted by: Eliot H Winer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
