<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SignTyp Continuation: A cross-linguistic database of signs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>310101</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The primary goal of this project is to extend the current SignTyp database. SignTyp is primarily a research tool for the comparative study of the phonetics, phonology and morphology of words in sign languages. The database, which currently contains signs from 5 sign languages, does not cover sentence structure. Fifteen globally dispersed sign languages (some endangered and never documented before) will be selected and added to the database. For each language, 1000 signs for common concepts will be collected using prompts consisting of pictures, drawings, and videoclips. The videotapes of the signs will be transcribed in SignWriting (which will capture the visual properties of the signs) and this transcription will then be converted into the SignTyp coding system. Each transcription will be accompanied by glosses in both English and the spoken language of the surrounding community. All of these materials will be combined to create small on-line searchable dictionaries for each language. While sign language researchers will want to focus on the more technical SignTyp coding system which allows for unlimited aggregate queries on phonetic, phonological, morphological and semantic characteristics of signs within and across all the languages in the database,  users of sign languages, sign language students, interpreters, teachers, and anyone with an interest in sign languages can look up a sign in any of the languages, using the more accessible SignWriting transcriptions, glosses, videos, and prompt/pictorial definitions.  For example, it will be easy to compare the signs for the same concept in the different languages. This project is important because there are no other crosslinguistic sign language databases of this magnitude, based on a common set of concepts and prompt material, with detailed phonological and phonetic transcriptions and codings, and freely available on the web and as a download.</AbstractNarration>
<MinAmdLetterDate>04/28/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1049510</AwardID>
<Investigator>
<FirstName>Hendrikus</FirstName>
<LastName>van der Hulst</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hendrikus G van der Hulst</PI_FULL_NAME>
<EmailAddress>harry.van.der.hulst@uconn.edu</EmailAddress>
<PI_PHON>8604860152</PI_PHON>
<NSF_ID>000171039</NSF_ID>
<StartDate>04/28/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Connecticut</Name>
<CityName>Storrs</CityName>
<ZipCode>062691133</ZipCode>
<PhoneNumber>8604863622</PhoneNumber>
<StreetAddress>438 Whitney Road Ext.</StreetAddress>
<StreetAddress2><![CDATA[Unit 1133]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>614209054</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CONNECTICUT</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004534830</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Connecticut]]></Name>
<CityName>Storrs</CityName>
<StateCode>CT</StateCode>
<ZipCode>062691133</ZipCode>
<StreetAddress><![CDATA[438 Whitney Road Ext.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~300000</FUND_OBLG>
<FUND_OBLG>2017~10101</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project we created a prompt set of 1000+ concepts, illustrated with photographs and graphics, which we used to collect signs from 25 different sign languages. The complete prompt set was presented to each signer individually at a convenient&nbsp; place near the signer&rsquo;s home. Some signers recorded themselves, others used a helper (sometimes hearing). All signers except one are deaf or hard of hearing. One signer is a hearing adult with deaf parents. Signers vary in age from young adult (over 18) to elderly. There was a total of 11 women and 15 men. Signers were paid for their participation. Because not all signers completed the full prompt set, the 20,000 collected videos include sets of over&nbsp;1000 videos for 14 signers, sets between 100 and 1000 videos for&nbsp;9 signers, and&nbsp;3 sets with fewer than 100 videos.&nbsp; All sign videos are available for the public at <a href="https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsigntyp.uconn.edu%2Fsignpuddle%2F&amp;data=02%7C01%7Charry.van.der.hulst%40uconn.edu%7Cc950549693594282ce0f08d640f619b1%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636767823114835124&amp;sdata=WgBToTOvVzKr1haTlv22NqnrV5n6oLLO6ym%2FOACb%2Fro%3D&amp;reserved=0">https://signtyp.uconn.edu/signpuddle/</a> .</p> <p>&nbsp;</p> <p>The goal of this project was to code all signs for their visual &lsquo;building blocks&rsquo;&nbsp;such as handshapes, orientations of the hands, movements, and locations (on or in front of the body) so that sign languages can be compared with respect to these properties. This kind of research is similar to research in spoken languages that aims to investigate the building blocks of speech (such as consonants and vowels) to establish how languages differ from each other and in what respect they show a general design.&nbsp;</p> <p>&nbsp;</p> <p>The encoding of the visual building blocks of signs was done in two steps. First, all signs were transcribed in terms of the Sutton SignWriting (SW) notation system, which is a popular writing system that is used by many signers of different sign languages. In our project, the SW-transcription (which can be found for each video in the sign puddles) functions both as a way of showing a written form for signs (which is of use for deaf people who are interested in their own or other sign languages) and as an initial step to encode them for research. The second step was to map the Sutton Writing notation into a more technical encoding (a translation table with 99&nbsp;analytic variables) which can be used for research into types of visual building blocks, as well as their frequencies in the different sign languages.</p> <p>&nbsp;</p> <p>Our project also looks at iconicity&nbsp;or the way in which signs &lsquo;resemble&rsquo; the thing or action that they represent.&nbsp; It has long been known that sign languages differ less from each other than spoken languages, and this is usually attributed to the iconic possibilities inherent in a visual as opposed to vocal communication system. We are looking at cross-linguistic variation in how concepts that are represented iconically. We find three possibilities:</p> <p>1. All signers represent the whole concepts in essentially the same way (e.g., &ldquo;lightning&rdquo; with a jagged line moving downwards)</p> <p>2. Signers select a salient property of the concept to represent iconically (e.g., almost all signers represent &ldquo;moon&rdquo; with various forms of a crescent shape such as drawing a crescent or shaping the hand into a crescent)&nbsp;</p> <p>3.&nbsp; Signers selects different properties of the concepts to represent iconically (e.g., signers have different signs for &ldquo;sheep&rdquo; because they selected different properties of the concepts to represent including <em>wool,</em> <em>horns, </em>or<em> shearing</em>.)</p> <p>What we are finding is that the number of signs which fall under either 1 or 2 are surprisingly high: cross-linguistically, signers tend to select the same concept (in total or salient parts of it) for iconic representation. This suggests that the greater similarity of&nbsp;sign languages as compared to spoken languages is rooted in a cross-linguistic similarity in the way in which concepts are iconically represented</p> <p>&nbsp;</p> <p>In conclusion, our project will allow us to quantify the similarities and differences that occur in the visual form of signs of different signs language very precisely, while coming to a better understanding of the factors that determine these visual forms.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/04/2018<br>      Modified by: Hendrikus&nbsp;G&nbsp;Van Der Hulst</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1049510/1049510_10168784_1541018754129_CSLDinosaur--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1049510/1049510_10168784_1541018754129_CSLDinosaur--rgov-800width.jpg" title="CSL Dinosaur"><img src="/por/images/Reports/POR/2018/1049510/1049510_10168784_1541018754129_CSLDinosaur--rgov-66x44.jpg" alt="CSL Dinosaur"></a> <div class="imageCaptionContainer"> <div class="imageCaption">CSL Dinosaur with signwriting transcription for SignTyp</div> <div class="imageCredit">Rachel Channon</div> <div class="imageSubmitted">Hendrikus&nbsp;G&nbsp;Van Der Hulst</div> <div class="imageTitle">CSL Dinosaur</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1049510/1049510_10168784_1541019288555_catposterjpgsmall--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1049510/1049510_10168784_1541019288555_catposterjpgsmall--rgov-800width.jpg" title="CAT"><img src="/por/images/Reports/POR/2018/1049510/1049510_10168784_1541019288555_catposterjpgsmall--rgov-66x44.jpg" alt="CAT"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Signers from different countries signing CAT</div> <div class="imageCredit">Rachel Channon</div> <div class="imageSubmitted">Hendrikus&nbsp;G&nbsp;Van Der Hulst</div> <div class="imageTitle">CAT</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project we created a prompt set of 1000+ concepts, illustrated with photographs and graphics, which we used to collect signs from 25 different sign languages. The complete prompt set was presented to each signer individually at a convenient  place near the signer?s home. Some signers recorded themselves, others used a helper (sometimes hearing). All signers except one are deaf or hard of hearing. One signer is a hearing adult with deaf parents. Signers vary in age from young adult (over 18) to elderly. There was a total of 11 women and 15 men. Signers were paid for their participation. Because not all signers completed the full prompt set, the 20,000 collected videos include sets of over 1000 videos for 14 signers, sets between 100 and 1000 videos for 9 signers, and 3 sets with fewer than 100 videos.  All sign videos are available for the public at https://signtyp.uconn.edu/signpuddle/ .     The goal of this project was to code all signs for their visual ?building blocks? such as handshapes, orientations of the hands, movements, and locations (on or in front of the body) so that sign languages can be compared with respect to these properties. This kind of research is similar to research in spoken languages that aims to investigate the building blocks of speech (such as consonants and vowels) to establish how languages differ from each other and in what respect they show a general design.      The encoding of the visual building blocks of signs was done in two steps. First, all signs were transcribed in terms of the Sutton SignWriting (SW) notation system, which is a popular writing system that is used by many signers of different sign languages. In our project, the SW-transcription (which can be found for each video in the sign puddles) functions both as a way of showing a written form for signs (which is of use for deaf people who are interested in their own or other sign languages) and as an initial step to encode them for research. The second step was to map the Sutton Writing notation into a more technical encoding (a translation table with 99 analytic variables) which can be used for research into types of visual building blocks, as well as their frequencies in the different sign languages.     Our project also looks at iconicity or the way in which signs ?resemble? the thing or action that they represent.  It has long been known that sign languages differ less from each other than spoken languages, and this is usually attributed to the iconic possibilities inherent in a visual as opposed to vocal communication system. We are looking at cross-linguistic variation in how concepts that are represented iconically. We find three possibilities:  1. All signers represent the whole concepts in essentially the same way (e.g., "lightning" with a jagged line moving downwards)  2. Signers select a salient property of the concept to represent iconically (e.g., almost all signers represent "moon" with various forms of a crescent shape such as drawing a crescent or shaping the hand into a crescent)   3.  Signers selects different properties of the concepts to represent iconically (e.g., signers have different signs for "sheep" because they selected different properties of the concepts to represent including wool, horns, or shearing.)  What we are finding is that the number of signs which fall under either 1 or 2 are surprisingly high: cross-linguistically, signers tend to select the same concept (in total or salient parts of it) for iconic representation. This suggests that the greater similarity of sign languages as compared to spoken languages is rooted in a cross-linguistic similarity in the way in which concepts are iconically represented     In conclusion, our project will allow us to quantify the similarities and differences that occur in the visual form of signs of different signs language very precisely, while coming to a better understanding of the factors that determine these visual forms.             Last Modified: 11/04/2018       Submitted by: Hendrikus G Van Der Hulst]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
