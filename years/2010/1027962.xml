<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDI-Type I:  Automated Documentation and Illustration of Material Culture through the Collaborative Algorithmic Rendering Engine (CARE)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>555000.00</AwardTotalIntnAmount>
<AwardAmount>555000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ability of computers to unify visual information from multiple imaging&lt;br/&gt;modes into comprehensible illustrations will revolutionize the ability of&lt;br/&gt;scientists, engineers, and humanities scholars to gain and communicate&lt;br/&gt;knowledge about the visual world.  Achieving this goal, however, will&lt;br/&gt;require a joint focus on developing novel shape and image analysis methods,&lt;br/&gt;and designing collaborative user interfaces that allow multiple domain&lt;br/&gt;experts and illustrators to bring together their expertise.  The&lt;br/&gt;Collaborative Algorithmic Rendering Engine (CARE) will be an open-source tool&lt;br/&gt;for extracting and merging visual details available only under certain&lt;br/&gt;lighting conditions, certain wavelengths, or certain imaging modalities. &lt;br/&gt;By focusing on minimal user effort, cross-site collaborative visualization&lt;br/&gt;design, and integrated archiving and process history (provenance) tracking,&lt;br/&gt;the CARE tool is specifically designed to remove existing obstacles to&lt;br/&gt;widespread adoption of digital tools for visual analysis and communication.&lt;br/&gt;&lt;br/&gt;As part of the project, investigators are developing novel image analysis&lt;br/&gt;techniques that build upon existing technologies such as Reflectance&lt;br/&gt;Transformation Imaging (RTI) and non-photorealistic rendering using images&lt;br/&gt;with normals (RGBN NPR), which have already received enormous interest&lt;br/&gt;within the cultural heritage community.  The research includes methods for:&lt;br/&gt;(1) analyzing the collection of images to decompose them into "maps" of&lt;br/&gt;color, orientation, and material at each pixel; (2) performing an arbitrary&lt;br/&gt;sequence or combination of image-processing operations on some or all of&lt;br/&gt;the maps separately; and (3) combining several maps into the final&lt;br/&gt;illustration.  The whole process is driven by (4) a user interface designed&lt;br/&gt;for interactive response and including special features that enable&lt;br/&gt;collaborative illustration design.&lt;br/&gt;&lt;br/&gt;The project involves a close collaboration between a university-based research&lt;br/&gt;group, responsible for development of new technologies, and a non-profit&lt;br/&gt;company with a demonstrated track record of working with museums and&lt;br/&gt;archaeological sites to deploy novel imaging and computational photography&lt;br/&gt;systems.  This joint development will ensure that the underlying&lt;br/&gt;technologies will have immediate high impact in the field: cultural&lt;br/&gt;heritage scholars and scientists will be able to generate high-quality,&lt;br/&gt;comprehensible illustrations for scientific papers and textbooks, with control&lt;br/&gt;over selective emphasis, contrast, attention, and abstraction, at lower&lt;br/&gt;cost and greater flexibility than generating such figures by hand.  The subject&lt;br/&gt;matter of art history also offers the unique opportunity to stimulate the&lt;br/&gt;interest of students who would not normally take courses in computer&lt;br/&gt;science, broadening the class of students exposed to the tools and capabilities&lt;br/&gt;of computing.</AbstractNarration>
<MinAmdLetterDate>09/16/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1027962</AwardID>
<Investigator>
<FirstName>Szymon</FirstName>
<LastName>Rusinkiewicz</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Szymon M Rusinkiewicz</PI_FULL_NAME>
<EmailAddress>smr@princeton.edu</EmailAddress>
<PI_PHON>6092587479</PI_PHON>
<NSF_ID>000379377</NSF_ID>
<StartDate>09/16/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress><![CDATA[Off. of Research &amp; Proj. Adm]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7642</Code>
<Text>VIRTUAL ORGANIZATIONS</Text>
</ProgramElement>
<ProgramReference>
<Code>7721</Code>
<Text>FROM DATA TO KNOWLEDGE</Text>
</ProgramReference>
<ProgramReference>
<Code>7722</Code>
<Text>COMPLEXITY</Text>
</ProgramReference>
<ProgramReference>
<Code>7752</Code>
<Text>CDI NON SOLICITED RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~555000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>High-resolution (digital) photographs remain one of the primary ways of documenting artworks, archaeological objects, and items of significant value to our cultural heritage.&nbsp; Although a lot of information can be conveyed through an individual photo, a <em>collection</em> of images, each taken with the light coming from a different direction, can lead to even easier and more unambiguous understanding of the shape and materials of the object being studied.&nbsp; Just switching between the photos is often good enough, but compelling visualizations can be created by using computers to <em>combine</em> the information present in these photos (or other collections of photos of the same object, taken with different color filters, or using different imaging techniques such as infrared).&nbsp; For example, we can create a visualization that takes the detail visible in one part of the object in one photo, and combines it automatically with a part of another photo that reveals more detail in another part of the object being imaged.</p> <p>The aim of this project is to build a set of computer programs that would assist art historians and conservators in better understanding the objects they study, by creating the kinds of visualizations described above.&nbsp; In addition, in order to be useful to scholars in the future, these visualizations must be accompanied by <em>provenance</em>: a detailed record of exactly how the images were taken, and what steps were used by the computer to manipulate and combine them into the final visualizations.&nbsp; This is very different from common software such as Photoshop, which allows people to manipulate images but makes it hard to know and reproduce exactly how an input image was transformed into an output.</p> <p>The project was undertaken by a collaborative team of researchers and students at Princeton University, together with the employees of Cultural Heritage Imaging, Inc. (CHI), a non-profit company dedicated to the promotion of digital imaging tools among cultural heritage professionals at the top museums, libraries, and schools in the world.</p> <p>As part of the project we built three computer tools.&nbsp; The first records information about photos as they are taken, beginning the process of building up a "digital lab notebook".&nbsp; The second makes sure the images are precisely aligned, correcting for any camera shake or inadvertent motion of the object being photographed.&nbsp; Finally, the third tool allows the user to experiment with different methods of manipulating and combining images to produce compelling and informative visualizations.&nbsp; Of course, all along the programs are keeping track of the exact ways in which the users are manipulating the images, and saving this information for posterity.</p> <p>The specific technical contributions of this work include the methods for precisely aligning images, as well as methods for estimating information about the shape (surface normals) of the object being imaged.&nbsp; Another major contribution is the standardization of the "digital lab notebook" that keeps track, in a very precise and well-defined format, exactly how the images were taken, transformed, and combined.</p> <p>The broader impacts of the work include the many multi-day training sessions run by CHI, during which the digital tools we are developing were introduced to conservators, art historians, and students.&nbsp; The tools we developed are in the process of being released freely to the public (except for the last one, which is still under development as of 2014), and will promote the use of digital imaging technologies among cultural heritage scholars.</p><br> <p>            Last Modified: 06/04/2014<br>      Modified by: Szymon&nbsp;M&nbsp;Rusinkiewicz</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ High-resolution (digital) photographs remain one of the primary ways of documenting artworks, archaeological objects, and items of significant value to our cultural heritage.  Although a lot of information can be conveyed through an individual photo, a collection of images, each taken with the light coming from a different direction, can lead to even easier and more unambiguous understanding of the shape and materials of the object being studied.  Just switching between the photos is often good enough, but compelling visualizations can be created by using computers to combine the information present in these photos (or other collections of photos of the same object, taken with different color filters, or using different imaging techniques such as infrared).  For example, we can create a visualization that takes the detail visible in one part of the object in one photo, and combines it automatically with a part of another photo that reveals more detail in another part of the object being imaged.  The aim of this project is to build a set of computer programs that would assist art historians and conservators in better understanding the objects they study, by creating the kinds of visualizations described above.  In addition, in order to be useful to scholars in the future, these visualizations must be accompanied by provenance: a detailed record of exactly how the images were taken, and what steps were used by the computer to manipulate and combine them into the final visualizations.  This is very different from common software such as Photoshop, which allows people to manipulate images but makes it hard to know and reproduce exactly how an input image was transformed into an output.  The project was undertaken by a collaborative team of researchers and students at Princeton University, together with the employees of Cultural Heritage Imaging, Inc. (CHI), a non-profit company dedicated to the promotion of digital imaging tools among cultural heritage professionals at the top museums, libraries, and schools in the world.  As part of the project we built three computer tools.  The first records information about photos as they are taken, beginning the process of building up a "digital lab notebook".  The second makes sure the images are precisely aligned, correcting for any camera shake or inadvertent motion of the object being photographed.  Finally, the third tool allows the user to experiment with different methods of manipulating and combining images to produce compelling and informative visualizations.  Of course, all along the programs are keeping track of the exact ways in which the users are manipulating the images, and saving this information for posterity.  The specific technical contributions of this work include the methods for precisely aligning images, as well as methods for estimating information about the shape (surface normals) of the object being imaged.  Another major contribution is the standardization of the "digital lab notebook" that keeps track, in a very precise and well-defined format, exactly how the images were taken, transformed, and combined.  The broader impacts of the work include the many multi-day training sessions run by CHI, during which the digital tools we are developing were introduced to conservators, art historians, and students.  The tools we developed are in the process of being released freely to the public (except for the last one, which is still under development as of 2014), and will promote the use of digital imaging technologies among cultural heritage scholars.       Last Modified: 06/04/2014       Submitted by: Szymon M Rusinkiewicz]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
