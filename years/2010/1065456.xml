<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NetSE: Medium: Collaborative Research: Auditing Internet Content for Credibility, Fairness, and Privacy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2011</AwardEffectiveDate>
<AwardExpirationDate>04/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>277411.00</AwardTotalIntnAmount>
<AwardAmount>277411</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Millions of users are accessing a portion of billions of Web pages and other content on the Internet on a daily basis. While the networking research community and the public in general are well-aware of the net neutrality problem, i.e., how to develop regulatory policies and auditing mechanisms to prevent Internet Service Providers from discriminating against various applications, very little effort is invested in enabling content neutrality. In particular, it is not a secret that almost every browsing click we make is collected by either Web- or ISP-based 'information collectors and aggregators', and that our profiles are used for online advertising. Still, no public auditing mechanisms, capable of detecting and informing end users about such practices, exist in this emerging area. Take search engines as another example. How does one know that information available on these services is not biased (or will become biased in the future) for commercial, political, or any other reason? More generally, no public auditing systems are capable of monitoring the scope and effectiveness of advertising or spam campaigns on the Internet. The PIs argue that all these questions fundamentally affect fairness at all levels, information credibility, and user privacy, all of which have significant relevance for the future development of the Internet and beyond.&lt;br/&gt;&lt;br/&gt;The PIs will build a set of methodologies and tools unified in a system capable of (i) enabling auditing mechanisms for the Web advertising domain, (ii) monitoring search engines? services and revealing their neutrality, and (iii) independently determining a Web site's popularity and checking for the truthfulness of advertised popularity. Further, the PIs plan to deploy the developed system on the PlanetLab wide area network testbed to perform long term monitoring of content neutrality in the Internet.&lt;br/&gt;&lt;br/&gt;Broader Impact: By informing the public of how online advertisers and search engines behave, the auditing system will enable fair competition and preclude monopolies, oligopolies, or collusions, eventually helping to improve online information credibility and user privacy. Even if no bias nor privacy-violating practices were to exist in today's Internet (unfortunately, the PI's preliminary results show that this is not the case), the auditing system and methodologies will always be a barrier for anyone who would believe that applying such approaches might be done without public knowledge and repercussions. By exposing biased content behavior, the auditing system will be capable of revealing discriminating acts that can happen for commercial, social, political, religious, or any other reason, ultimately facilitating the development of free and open society. The PIs will design and disseminate easy-to-use browser extensions and plug-ins that will be capable of assisting end users in detecting content neutrality violations. Education is an integral part of this award. The insights and tools derived from this project will be integrated into the current undergraduate and graduate curricula.</AbstractNarration>
<MinAmdLetterDate>03/28/2011</MinAmdLetterDate>
<MaxAmdLetterDate>04/12/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1065456</AwardID>
<Investigator>
<FirstName>Y. Charlie</FirstName>
<LastName>Hu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Y. Charlie Hu</PI_FULL_NAME>
<EmailAddress>ychu@purdue.edu</EmailAddress>
<PI_PHON>7654949143</PI_PHON>
<NSF_ID>000118830</NSF_ID>
<StartDate>03/28/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072114</ZipCode>
<StreetAddress><![CDATA[Young Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7794</Code>
<Text>NETWORK SCIENCE &amp; ENGINEERING</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~277411</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Broader Impact:</span></p> <p><span>Millions  of users are accessing a portion of billions of Web pages and other  content on the Internet on a daily basis. While the networking research  community and the public in general  are well-aware of the<span>&nbsp;</span><em><span>net neutrality</span></em><span><em><span>&nbsp;</span></em></span>problem,<span>&nbsp;</span><em><span>i.e.</span></em>,  how to develop regulatory policies and auditing mechanisms to prevent  Internet Service Providers from discriminating against various  applications, very little<span><em><span>&nbsp;</span></em></span>effort  is invested in enabling<span>&nbsp;</span><em><span>content neutrality</span></em>.  In particular, how do we know that search engines and other content  providers are not biased (or will become biased in the future) for  commercial, political, or any other reason? Certainly, the most  persistent critique of search engines is the fear that they create  reality instead of reflecting it. More generally, no public  auditing systems were capable of monitoring and understanding when and  how numerous online entities track users. The key contribution of this  project lies in developing some of the first methods for auditing  content neutrality and designing systems for monitoring  user tracking. In particular, we developed content auditing systems for  the following three domains.</span></p> <p><span>&nbsp;</span></p> <p><span>Intellectual Merit:</span></p> <p><em><span>Enabling auditing mechanisms for the Web advertising domain.</span></em><span><em><span>&nbsp;</span></em></span><span>We  developed novel monitoring methods capable of accurately detecting when  a user is targeted on individual or group bases, which includes  detecting both<span>&nbsp;</span><em><span>behavioral  ad targeting</span></em><span><em><span>&nbsp;</span></em></span>and<span>&nbsp;</span><em><span>location-based  ad targeting</span></em>. A common insight of our research is that  there exists a significant lack of coordination among different entities  in the online advertising domain, even in scenarios when different  entities belong to the same organization. Our system  was among the first to analyze and reveal the properties and the  deployment of location-based and behavioral targeting methods at various  levels of granularity. To detect behavioral targeting, we developed  inconsistency tests for cases when cookies are utilized  by an online service and when they are removed by the client.</span></p> <p><span>&nbsp;</span></p> <p><em><span>Auditing search engines.</span></em><span><em><span>&nbsp;</span></em></span><span>Auditing  search engines and detecting potential bias is a challenging research  problem for several reasons. Most significantly, there exists no  accepted notion of what unbiased ranking for a given search term  represents. Indeed, each search engine has its own set of  internal ranking rules and policies that produce a given ranking  outcome. We have addressed this problem in the following ways. (a) By  detecting search-engine response<span>&nbsp;</span><em><span>inconsistency</span></em>,  in the context of a single search engine, among different keywords and  topics. To detect bias, we train our model on benign keywords and then  evaluate if the learned model deviates for less-benign keywords,  potential bias targets. (b) We continued our efforts  on building a Platform for Analyzing Web Search engines (PAWS). PAWS  measures content emphasis, i.e., the degree to which differences across  search engines&rsquo; rankings correlate with features of the ranked content.  We find that neither Google nor Bing are emphasizing  positive sentiments toward their company&rsquo;s own products; that<span>&nbsp;</span><em><span>both</span></em><span>&nbsp;</span>search  engines<span>&nbsp;</span><em><span>do </span></em>rank statistically significantly higher pages when it  contains ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Broader Impact:  Millions  of users are accessing a portion of billions of Web pages and other  content on the Internet on a daily basis. While the networking research  community and the public in general  are well-aware of the net neutrality problem, i.e.,  how to develop regulatory policies and auditing mechanisms to prevent  Internet Service Providers from discriminating against various  applications, very little effort  is invested in enabling content neutrality.  In particular, how do we know that search engines and other content  providers are not biased (or will become biased in the future) for  commercial, political, or any other reason? Certainly, the most  persistent critique of search engines is the fear that they create  reality instead of reflecting it. More generally, no public  auditing systems were capable of monitoring and understanding when and  how numerous online entities track users. The key contribution of this  project lies in developing some of the first methods for auditing  content neutrality and designing systems for monitoring  user tracking. In particular, we developed content auditing systems for  the following three domains.     Intellectual Merit:  Enabling auditing mechanisms for the Web advertising domain. We  developed novel monitoring methods capable of accurately detecting when  a user is targeted on individual or group bases, which includes  detecting both behavioral  ad targeting and location-based  ad targeting. A common insight of our research is that  there exists a significant lack of coordination among different entities  in the online advertising domain, even in scenarios when different  entities belong to the same organization. Our system  was among the first to analyze and reveal the properties and the  deployment of location-based and behavioral targeting methods at various  levels of granularity. To detect behavioral targeting, we developed  inconsistency tests for cases when cookies are utilized  by an online service and when they are removed by the client.     Auditing search engines. Auditing  search engines and detecting potential bias is a challenging research  problem for several reasons. Most significantly, there exists no  accepted notion of what unbiased ranking for a given search term  represents. Indeed, each search engine has its own set of  internal ranking rules and policies that produce a given ranking  outcome. We have addressed this problem in the following ways. (a) By  detecting search-engine response inconsistency,  in the context of a single search engine, among different keywords and  topics. To detect bias, we train our model on benign keywords and then  evaluate if the learned model deviates for less-benign keywords,  potential bias targets. (b) We continued our efforts  on building a Platform for Analyzing Web Search engines (PAWS). PAWS  measures content emphasis, i.e., the degree to which differences across  search enginesÆ rankings correlate with features of the ranked content.  We find that neither Google nor Bing are emphasizing  positive sentiments toward their companyÆs own products; that both search  engines do rank statistically significantly higher pages when it  contains the engine companyÆs ads, as opposed to competitor ads; that  there exists statistically significant news search bias across different  hosts, indicating that the two search engines often  prefer different hosts.     Auditing Web sitesÆ popularity and Internet campaigns.  We developed methodologies to audit Web sitesÆ popularity at scale and  to monitor advertising and spam campaigns on the Internet. Among  others, we developed the first system that enables an endpoint to remotely measure traffic of a Website. In addition, we conducted  research on automatically identifying low-credibility content on the  Web: social-media spam. The approach is based on the insight that social  media spam content is often generated from template-based  mechanisms, which automatically creates ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
