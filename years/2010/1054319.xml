<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:  Flexible Learning for Natural Language Processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2011</AwardEffectiveDate>
<AwardExpirationDate>01/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>549812.00</AwardTotalIntnAmount>
<AwardAmount>565812</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Statistical learning is now central to natural language processing&lt;br/&gt;(NLP).  Bridging the gap between learning and linguistic&lt;br/&gt;representation requires going beyond learning parameters.  This CAREER&lt;br/&gt;project addresses three challenging, unresolved questions:&lt;br/&gt;&lt;br/&gt;1. Given recent advances in learning the parameters of linguistic&lt;br/&gt;models and in approximate inference, how can the process of feature&lt;br/&gt;design be automated?&lt;br/&gt;&lt;br/&gt;2. Given that NLP tasks are often defined without recourse to real&lt;br/&gt;applications and that a specific annotated dataset is unlikely to&lt;br/&gt;fulfill the needs of multiple NLP projects, can learning frameworks be&lt;br/&gt;extended to perform automatic task refinement, simplifying a&lt;br/&gt;linguistic analysis task to obtain more consistent, more precise, or&lt;br/&gt;faster performance?&lt;br/&gt;&lt;br/&gt;3. Can computational models of language take into account the non-text&lt;br/&gt;context in which our linguistic data are embedded?  Building on recent&lt;br/&gt;success in social text analysis and text-driven forecasting, this&lt;br/&gt;CAREER project seeks to exploit context to refine models of linguistic&lt;br/&gt;structure while enabling advances in this application area.&lt;br/&gt;&lt;br/&gt;This basic research supports advances in a wide range of language&lt;br/&gt;engineering applications and discrete data analysis.  In addition to&lt;br/&gt;core research advances, this CAREER project contributes a new&lt;br/&gt;publicly-available parser that models the most consistently learnable&lt;br/&gt;elements of syntactic struture.  Educational activities include a new&lt;br/&gt;project-based on text-driven forecasting within the PI's undergraduate&lt;br/&gt;NLP course and a new undergraduate course in machine learning. It&lt;br/&gt;supports involvement by the PI in outreach activities to high school&lt;br/&gt;students and to a wider range of students at CMU by exposing aspects&lt;br/&gt;of his research in non-CS classrooms.</AbstractNarration>
<MinAmdLetterDate>01/14/2011</MinAmdLetterDate>
<MaxAmdLetterDate>03/02/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1054319</AwardID>
<Investigator>
<FirstName>Noah</FirstName>
<LastName>Smith</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Noah A Smith</PI_FULL_NAME>
<EmailAddress>nasmith@cs.cmu.edu</EmailAddress>
<PI_PHON>4122257851</PI_PHON>
<NSF_ID>000228357</NSF_ID>
<StartDate>01/14/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~105536</FUND_OBLG>
<FUND_OBLG>2012~110458</FUND_OBLG>
<FUND_OBLG>2013~123614</FUND_OBLG>
<FUND_OBLG>2014~129019</FUND_OBLG>
<FUND_OBLG>2015~97185</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This CAREER&nbsp;project addressed three challenging, unresolved technical questions.</p> <p><strong>Given recent advances in learning the parameters of linguistic&nbsp;models and in approximate inference, how can the process of feature&nbsp;design be automated?</strong></p> <p>A wide range of new learning algorithms for text data were introduced, building on ideas in multiple kernel learning, structured sparsity, new loss functions for structured prediction, and representation learning with recurrent neural networks. &nbsp;Together, these advances have increased automation in the development of systems for translation, parsing, and other natural language processing modules.</p> <p><strong>Given that NLP tasks are often defined without recourse to real&nbsp;applications and that a specific annotated dataset is unlikely to&nbsp;fulfill the needs of multiple NLP projects, can learning frameworks be&nbsp;extended to perform automatic task refinement, simplifying a&nbsp;linguistic analysis task to obtain more consistent, more precise, or&nbsp;faster performance?</strong></p> <p>A wide range of new inference algorithms that flexibly adapt to new datasets and prediction tasks involving linguistic structure were introduced. &nbsp;These include alternating directions dual decomposition, large-scale sociolinguistic discovery methods, new approaches to efficiently analyzing and disambiguating multiword expressions, new NLP tools targeting social media text, and the graph fragment language approach to rapid annotation of dependency and multiword structure by humans.</p> <p><strong>Can computational models of language take into account the non-text&nbsp;context in which our linguistic data are embedded?</strong></p> <p>A wide range of new data analysis methods that associate text with non-linguistic context were introduced. &nbsp;These include inferring a network of linguistic influence among American cities, detection of content censorship in microblogs, models of geographically situated language, prediction of sports outcomes from social media text, and models for online argumentation and sarcasm, among others.</p> <p>Beyond the technical goals of the project, contributions were made to more than ten international tutorials and short courses; seven graduate students and nine undergraduate researchers were trained in research at the junction of computer science, linguistics, and the social sciences. &nbsp;Software and datasets, as well as a public demo of algorithms developed, have been released for use by other researchers.</p><br> <p>            Last Modified: 04/23/2016<br>      Modified by: Noah&nbsp;A&nbsp;Smith</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This CAREER project addressed three challenging, unresolved technical questions.  Given recent advances in learning the parameters of linguistic models and in approximate inference, how can the process of feature design be automated?  A wide range of new learning algorithms for text data were introduced, building on ideas in multiple kernel learning, structured sparsity, new loss functions for structured prediction, and representation learning with recurrent neural networks.  Together, these advances have increased automation in the development of systems for translation, parsing, and other natural language processing modules.  Given that NLP tasks are often defined without recourse to real applications and that a specific annotated dataset is unlikely to fulfill the needs of multiple NLP projects, can learning frameworks be extended to perform automatic task refinement, simplifying a linguistic analysis task to obtain more consistent, more precise, or faster performance?  A wide range of new inference algorithms that flexibly adapt to new datasets and prediction tasks involving linguistic structure were introduced.  These include alternating directions dual decomposition, large-scale sociolinguistic discovery methods, new approaches to efficiently analyzing and disambiguating multiword expressions, new NLP tools targeting social media text, and the graph fragment language approach to rapid annotation of dependency and multiword structure by humans.  Can computational models of language take into account the non-text context in which our linguistic data are embedded?  A wide range of new data analysis methods that associate text with non-linguistic context were introduced.  These include inferring a network of linguistic influence among American cities, detection of content censorship in microblogs, models of geographically situated language, prediction of sports outcomes from social media text, and models for online argumentation and sarcasm, among others.  Beyond the technical goals of the project, contributions were made to more than ten international tutorials and short courses; seven graduate students and nine undergraduate researchers were trained in research at the junction of computer science, linguistics, and the social sciences.  Software and datasets, as well as a public demo of algorithms developed, have been released for use by other researchers.       Last Modified: 04/23/2016       Submitted by: Noah A Smith]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
