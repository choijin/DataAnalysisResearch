<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Acquisition of Large-Memory, Many-Core Compute Node for Mathematical Science Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2011</AwardExpirationDate>
<AwardTotalIntnAmount>127196.00</AwardTotalIntnAmount>
<AwardAmount>127196</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jennifer Pearl</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The purchase of a large-memory, many-core computing system and its integration into a large, distributed, high-performance computing cluster provides the opportunity for researchers at Clemson to increase the size of problems that can be solved in several research areas in the mathematical sciences and to scale up shared-memory, parallel algorithms in anticipation of new, many-core computing systems under development by chip manufacturers.  In addition, it creates the possibility of developing innovative, heterogeneous, shared-distributed algorithms for problems where that approach is promising.&lt;br/&gt;       &lt;br/&gt;Among the important areas where large-memory and heterogeneous computing systems promise to be effective are: computational optimization, simulation of 3-D filter systems, statistical models of reliability and survival, computational cell biology, biochemical modeling, quantum molecular dynamics, and combinatorial number theory.&lt;br/&gt;       &lt;br/&gt;Large-memory, many-core systems are not widely available to researchers in the US.  This resource will be a valuable addition to the pool of resources for scientific computing in the United States.</AbstractNarration>
<MinAmdLetterDate>09/11/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1026385</AwardID>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Saltzman</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew J Saltzman</PI_FULL_NAME>
<EmailAddress>mjs@clemson.edu</EmailAddress>
<PI_PHON>8646563185</PI_PHON>
<NSF_ID>000127436</NSF_ID>
<StartDate>09/11/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>James</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin L James</PI_FULL_NAME>
<EmailAddress>kevja@clemson.edu</EmailAddress>
<PI_PHON>8646566766</PI_PHON>
<NSF_ID>000261404</NSF_ID>
<StartDate>09/11/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Taufiquar</FirstName>
<LastName>Khan</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Taufiquar R Khan</PI_FULL_NAME>
<EmailAddress>tkhan13@uncc.edu</EmailAddress>
<PI_PHON>7046870635</PI_PHON>
<NSF_ID>000490312</NSF_ID>
<StartDate>09/11/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hugh</FirstName>
<LastName>MacMillan</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hugh R MacMillan</PI_FULL_NAME>
<EmailAddress>hmacmil@clemson.edu</EmailAddress>
<PI_PHON>8502548654</PI_PHON>
<NSF_ID>000483084</NSF_ID>
<StartDate>09/11/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Elena</FirstName>
<LastName>Dimitrova</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elena S Dimitrova</PI_FULL_NAME>
<EmailAddress>edimitro@calpoly.edu</EmailAddress>
<PI_PHON>8057561689</PI_PHON>
<NSF_ID>000242434</NSF_ID>
<StartDate>09/11/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Clemson University</Name>
<CityName>CLEMSON</CityName>
<ZipCode>296345701</ZipCode>
<PhoneNumber>8646562424</PhoneNumber>
<StreetAddress>230 Kappa Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>South Carolina</StateName>
<StateCode>SC</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>SC03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042629816</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CLEMSON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042629816</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Clemson University]]></Name>
<CityName>CLEMSON</CityName>
<StateCode>SC</StateCode>
<ZipCode>296345701</ZipCode>
<StreetAddress><![CDATA[230 Kappa Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>South Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>SC03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1260</Code>
<Text>INFRASTRUCTURE PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~127196</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This grant funded the acquisition of specialized computing equipment<br />needed to solve several computational problems in several areas of the mathematical sciences.</p> <p>Many large computational problems in engineering, science, and business<br />require solution methods that involve computations executed in parallel in<br />a coordinated fashion. Such algorithms may also require that computations have simultaneous access to large amounts of data. There are two basic architectures for co ?rdinating computations and their access to data: distributed and shared-memory. These architectures are suitable for different styles of algorithms, although some algorithms can combine methods suitable for each.<br />&bull; Distributed systems (clusters) of workstation-class computers (with a<br />few processors and a few gigabytes of memory) are common&mdash;they are<br />inexpensive and easy to build. Algorithms designed for these systems<br />co ?rdinate and distribute the work among processors by sending messages over a high-speed network.<br />&bull; Shared-memory machines with tens of processors and terabytes of memory are substantially more expensive and are less commonly available to researchers. Algorithms for these machines manage data for all processors in a single memory pool and coordinate the work using special instructions to lock memory locations so they cannot be modified simultaneously by different processors.</p> <p>The funded machine is intended to support highly parallel, shared-memory<br />algorithms. It consists of 64 processors and two terabytes of memory. The<br />machine has been integrated into Clemson University&rsquo;s distributed cluster&mdash;ranked 128 on the November, 2011 list of the world&rsquo;s top 500 supercomputers. The integrated system facilitates the development of hybrid distributed-shared memory algorithms that can exploit the best features of both types of architectures. Investigators are using the funded machine and the surrounding cluster to solve massive computational problems in the following areas:<br />&bull; Computational optimization problems in management and engineering:<br />Scalable algorithms for a broad class of problems in business analyt-<br />ics and engineering design, such as facility location, vehicle routing,<br />scheduling, and circuit layout.<br />&bull; Simulation of high-efficiency particulate air filters: Three-dimensional<br />modeling of fluid flow through a chromatography column consisting of<br />capillary-channeled polymer fibers.<br />&bull; Longitudinal functions and data models: Methods for regression anal-<br />ysis of time-series data with many covariates.<br />&bull; Computational cell biology: Modeling of the development of genomic<br />variation among brain cells and its implications for understanding dis-<br />eases of the brain, such as Down&rsquo;s syndrome, schizophrenia, Alzheimer&rsquo;s<br />disease, and autism.<br />&bull; Simulation of quantum molecular dynamics: Modeling of quantum ef-<br />fects of excited states of molecules, to develop techniques for quantum<br />control.<br />&bull; Combinatorial number theory: Computational investigations of impor-<br />tant mathematical questions related to generalized partition functions,<br />modular forms, and Ramsey theory.<br />&bull; Modeling biochemical regulatory networks: Reconstructing the struc-<br />ture of biochemical regulatory networks based on observations of net-<br />work state changes.<br />In addition to these research projects, the machine is used in courses<br />and in Clemson&rsquo;s REU program, which train future computational scientists.</p> <p>Spare capacity will in the future be shared with scientists at other institutions via the Internet. All software developed in the course of this research will be made available to others as open source.</p><br> <p>            Last Modified: 01/09/2012<br>      Modified by: Mat...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This grant funded the acquisition of specialized computing equipment needed to solve several computational problems in several areas of the mathematical sciences.  Many large computational problems in engineering, science, and business require solution methods that involve computations executed in parallel in a coordinated fashion. Such algorithms may also require that computations have simultaneous access to large amounts of data. There are two basic architectures for co ?rdinating computations and their access to data: distributed and shared-memory. These architectures are suitable for different styles of algorithms, although some algorithms can combine methods suitable for each. &bull; Distributed systems (clusters) of workstation-class computers (with a few processors and a few gigabytes of memory) are common&mdash;they are inexpensive and easy to build. Algorithms designed for these systems co ?rdinate and distribute the work among processors by sending messages over a high-speed network. &bull; Shared-memory machines with tens of processors and terabytes of memory are substantially more expensive and are less commonly available to researchers. Algorithms for these machines manage data for all processors in a single memory pool and coordinate the work using special instructions to lock memory locations so they cannot be modified simultaneously by different processors.  The funded machine is intended to support highly parallel, shared-memory algorithms. It consists of 64 processors and two terabytes of memory. The machine has been integrated into Clemson UniversityÆs distributed cluster&mdash;ranked 128 on the November, 2011 list of the worldÆs top 500 supercomputers. The integrated system facilitates the development of hybrid distributed-shared memory algorithms that can exploit the best features of both types of architectures. Investigators are using the funded machine and the surrounding cluster to solve massive computational problems in the following areas: &bull; Computational optimization problems in management and engineering: Scalable algorithms for a broad class of problems in business analyt- ics and engineering design, such as facility location, vehicle routing, scheduling, and circuit layout. &bull; Simulation of high-efficiency particulate air filters: Three-dimensional modeling of fluid flow through a chromatography column consisting of capillary-channeled polymer fibers. &bull; Longitudinal functions and data models: Methods for regression anal- ysis of time-series data with many covariates. &bull; Computational cell biology: Modeling of the development of genomic variation among brain cells and its implications for understanding dis- eases of the brain, such as DownÆs syndrome, schizophrenia, AlzheimerÆs disease, and autism. &bull; Simulation of quantum molecular dynamics: Modeling of quantum ef- fects of excited states of molecules, to develop techniques for quantum control. &bull; Combinatorial number theory: Computational investigations of impor- tant mathematical questions related to generalized partition functions, modular forms, and Ramsey theory. &bull; Modeling biochemical regulatory networks: Reconstructing the struc- ture of biochemical regulatory networks based on observations of net- work state changes. In addition to these research projects, the machine is used in courses and in ClemsonÆs REU program, which train future computational scientists.  Spare capacity will in the future be shared with scientists at other institutions via the Internet. All software developed in the course of this research will be made available to others as open source.       Last Modified: 01/09/2012       Submitted by: Matthew J Saltzman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
