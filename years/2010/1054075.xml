<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Compiler-Inserted Runtime Adaptation for Multicore Processors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Increases in the number of cores in multicore processors have lead to&lt;br/&gt;increases in the architectural and environmental diversity present in&lt;br/&gt;computer systems: the number, complexity, and mix of available cores&lt;br/&gt;vary greatly and the resources allocated to an application differ from&lt;br/&gt;run-to-run and within runs.&lt;br/&gt;&lt;br/&gt;Diversity has a significant impact on application performance;&lt;br/&gt;applications must adapt to differences in their architecture and&lt;br/&gt;environment to achieve good performance.  However, developing adaptive&lt;br/&gt;applications greatly increases the difficulty of writing efficient&lt;br/&gt;parallel programs while increasing the level of skill required to&lt;br/&gt;write a parallel application, and may therefore limit programmers'&lt;br/&gt;ability to write parallel applications and take full advantage of&lt;br/&gt;multicore processors.&lt;br/&gt;&lt;br/&gt;This project develops and disseminates new compilation techniques and&lt;br/&gt;runtime adaptation strategies in which a compiler analyzes the&lt;br/&gt;concurrency and locality features of an application, selects a runtime&lt;br/&gt;adaptation strategy based on these features, and adds adaptation to&lt;br/&gt;the application.  Key contributions address the challenges of&lt;br/&gt;discovering and representing concurrency and locality and selecting&lt;br/&gt;adaptation strategies based upon application characteristics.&lt;br/&gt;&lt;br/&gt;These new compilation techniques and adaptation strategies will free&lt;br/&gt;programmers from the need to concern themselves with architectural and&lt;br/&gt;environmental diversity when writing parallel applications.  This&lt;br/&gt;freedom will then enable a wide variety of applications to benefit&lt;br/&gt;from multicore processors, thus ensuring that multicore processor&lt;br/&gt;systems will be able to live up to users' increased performance&lt;br/&gt;expectations.</AbstractNarration>
<MinAmdLetterDate>07/07/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/07/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1054075</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Penry</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David A Penry</PI_FULL_NAME>
<EmailAddress>dpenry@ee.byu.edu</EmailAddress>
<PI_PHON>8014227665</PI_PHON>
<NSF_ID>000069557</NSF_ID>
<StartDate>07/07/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brigham Young University</Name>
<CityName>Provo</CityName>
<ZipCode>846021231</ZipCode>
<PhoneNumber>8014223360</PhoneNumber>
<StreetAddress>A-285 ASB</StreetAddress>
<StreetAddress2><![CDATA[Campus Drive]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009094012</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BRIGHAM YOUNG UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001940170</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brigham Young University]]></Name>
<CityName>Provo</CityName>
<StateCode>UT</StateCode>
<ZipCode>846021231</ZipCode>
<StreetAddress><![CDATA[A-285 ASB]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~450000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The goal of this project was to increase the productivity of programmers designing software which can use multiple processing elements and accelerators. &nbsp;It is difficult for such programmers to deal with the great diversity of processing elements and accelerators, and the complex systems composed of them. &nbsp;In many situations, programmers cannot predict what the system will look like; in fact, the system itself may change its characterstics while the program is running.</span></p> <p>Our approach was to develop compilation techniques which partition a program into tasks which can be scheduled at runtime to run on the processing elements and accelerators that are actually available as the program executes. &nbsp;A very important enabler of these techniques is having a powerful representation of concurrency (what portions of a program may execute at the same time) and locality (how data is used by portions of a program).</p> <p>The goal was very ambitious, and we were only able to achieve it in part. &nbsp;We were able to develop a very useful representation of concurrency and locality which exposes them to the compiler and the runtime system. &nbsp;We demonstrated the use of this representation to improve the scheduling of data transfers between processors and accelerators (GPUs). &nbsp;We developed a tool to visualize program structure using this representation.</p> <p>This project has supported the studies of 2 PhD students and 2 MS students. &nbsp;7 undergraduates have worked on it. &nbsp;All of the students gained valuable experience in computer systems, compilers, and programming. &nbsp;Furthermore, the graduate students gained experience in project planning and supervision as they mentored the undergraduates.</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/29/2017<br>      Modified by: David&nbsp;A&nbsp;Penry</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to increase the productivity of programmers designing software which can use multiple processing elements and accelerators.  It is difficult for such programmers to deal with the great diversity of processing elements and accelerators, and the complex systems composed of them.  In many situations, programmers cannot predict what the system will look like; in fact, the system itself may change its characterstics while the program is running.  Our approach was to develop compilation techniques which partition a program into tasks which can be scheduled at runtime to run on the processing elements and accelerators that are actually available as the program executes.  A very important enabler of these techniques is having a powerful representation of concurrency (what portions of a program may execute at the same time) and locality (how data is used by portions of a program).  The goal was very ambitious, and we were only able to achieve it in part.  We were able to develop a very useful representation of concurrency and locality which exposes them to the compiler and the runtime system.  We demonstrated the use of this representation to improve the scheduling of data transfers between processors and accelerators (GPUs).  We developed a tool to visualize program structure using this representation.  This project has supported the studies of 2 PhD students and 2 MS students.  7 undergraduates have worked on it.  All of the students gained valuable experience in computer systems, compilers, and programming.  Furthermore, the graduate students gained experience in project planning and supervision as they mentored the undergraduates.          Last Modified: 09/29/2017       Submitted by: David A Penry]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
