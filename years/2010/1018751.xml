<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI:  Small:  Learning  and Inference with And-Or Graphs for Image Understanding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2010</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In this project, the PIs and students study a probabilistic and graphical representation, called the And-or graph (AoG) for visual knowledge representation.  This AoG model embodies hierarchical and contextual models for visual objects and scenes and is the key to robust object and scene recognition. More specifically, the project addresses two major technical challenges: (i)  Learning the AoG for representing objects and scenes in an unsupervised way; and (ii)  Developing effective inference algorithm by scheduling top-down and bottom-up processes to extract semantic contents in a parse graph under the guidance of the AoG. The extracted semantics include the hierarchical decomposition of the image from scene to objects, and parts, as well as the contextual relations. These contents are crucial for filling in the semantic gap in large scale image search and retrieval.  The technologies studied in this project are key to a number of applications, such as image content extraction for security surveillance, information gathering, Internet image search, and situation awareness. One specific application studied in this project is autonomous driving assistant for designing safer vehicles and reducing car accidence. The project also supports the training of 3 graduate students over the three year period. Research results are disseminated through public publications in major computer vision conferences and journals, institutional webpages, and shared data sets and code in the Internet.</AbstractNarration>
<MinAmdLetterDate>07/29/2010</MinAmdLetterDate>
<MaxAmdLetterDate>11/13/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1018751</AwardID>
<Investigator>
<FirstName>Yingnian</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yingnian Wu</PI_FULL_NAME>
<EmailAddress>ywu@stat.ucla.edu</EmailAddress>
<PI_PHON>3102548332</PI_PHON>
<NSF_ID>000097763</NSF_ID>
<StartDate>07/29/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Song-Chun</FirstName>
<LastName>Zhu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Song-Chun Zhu</PI_FULL_NAME>
<EmailAddress>sczhu@stat.ucla.edu</EmailAddress>
<PI_PHON>3102068693</PI_PHON>
<NSF_ID>000096074</NSF_ID>
<StartDate>07/29/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Los Angeles]]></Name>
<CityName>LOS ANGELES</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951406</ZipCode>
<StreetAddress><![CDATA[10889 Wilshire Boulevard]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~138171</FUND_OBLG>
<FUND_OBLG>2011~311829</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this NSF project is to develop learning and inference algorithms on&nbsp;hierarchical compositional and-or graph representations, so that&nbsp;computer vision systems that can understand the contents of images. This project has exceeded the original proposed plan in &nbsp;about 4 years 2010-2015, more specifically, the project has the following outcomes.</p> <p>&nbsp;1, &nbsp;We have developed an unsupervised learning framework for learning the And-or graph models from raw images for object recognition. &nbsp;Figure 1 shows an example of the And-or Graph automatically learned from input images without human annotation. &nbsp;The representation discovered the primitives and parts in a hierarchy, and was used for object detection and recognition. &nbsp;The figure is from a published paper:</p> <p>&nbsp; &nbsp; Z. Si and S.C. Zhu, &nbsp;Learning And-Or Templates&nbsp;<span>for Object Recognition and Detection,&nbsp;</span><em>&nbsp;IEEE Trans on Pattern Analysis and Machine Intelligence</em><span>, vol. 35, no.9, 2189-2205, 2013.</span></p> <p><span>2, We have used the And-or Graph structure for modeling a wide variety of scene configurations, objects, occlusion patterns, human pose estimation, &nbsp;human actions, vehicle detection and pose estimation. These vision tasks are important components in a range of vision applications. &nbsp;Figure 2 illustrates a results of the algorithm for detecting vehicles where we use the and-or graph to represent the vehicle variabilities and occlusion patterns. This work has achieved state-of-the-art results on a challenging dataset for vehicle detection. &nbsp;This figure is from a published paper:</span></p> <p><span>B. Li, T.F. Wu and S.C. Zhu,&nbsp;Integrating Context and Occlusion for&nbsp;</span><em>Car Detection</em><span>&nbsp;by Hierarchical And-Or Model.&nbsp;</span><em>Proc. of European Conf. on Computer Vision</em><span>&nbsp;(ECCV), 2014.</span></p> <p><span>3, &nbsp;We have developed effective inference algorithms for scheduling top-down and bottom-up algorithm in the hierarchical And-Or graph. This algorithm is cost-effective and improve the performance in difficult conditions. &nbsp;Figure 3 shows the results of detecting human faces in non-coorperative condition (in contrast to photo albums), excerpted from a published paper:&nbsp;</span></p> <p>T.F. Wu and S.C. Zhu,&nbsp;A Numeric Study of the Bottom-up and Top-down Inference<span>&nbsp;Processes in And-Or Graphs,&nbsp;</span><em>&nbsp;Int'l Journal of Computer Vision,&nbsp;</em><span>vol. 93, no 2, p226-252, June 2011.</span></p> <p>4, As a demonstration of applications, we developed a I2T: Image Parsing to Text Generation system. &nbsp;The system diagram is shown in Figure 4. This is the first of its kind system that parse the images and video using the and-or graph representation, and thus convert the parsed results into narrative text description. The latter will support human queries in video surveillance.</p> <p>&nbsp; &nbsp;This figure is from paper: &nbsp;</p> <p>Z.Y. Yao, X. Yang, L. Lin, M. W. Lee, and S.C. Zhu,&nbsp;I2T: Image Parsing to Text Description, &nbsp;Proceedings of IEEE, Vol 98, no.8,, pp 1485-1508, August, 2010.&nbsp;</p> <p>The work was also reported by <em>MIT Technology Review in&nbsp;</em>2010&nbsp;&nbsp;<a href="http://www.technologyreview.com/news/419171/surveillance-software-knows-what-a-camera-sees/">Surveillance Software Knows What a Camera Sees</a>&nbsp;.</p> <p>5, Education aspects: the project &nbsp;supported 4 Ph.D dissertations, and provided training for undergraduate students, &nbsp;and enhance the computer vision program and curriculum at UCLA. The PI initiated a workshop series on Stochastic Image Grammar (SIG) with CVPR 2009, &nbsp;ICCV2011 and a tutoal in CVPR 2012 to promote research in this direction. The PI also organized and gave lectures in &nbsp;summer schools to attract underrepresented student groups.</...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this NSF project is to develop learning and inference algorithms on hierarchical compositional and-or graph representations, so that computer vision systems that can understand the contents of images. This project has exceeded the original proposed plan in  about 4 years 2010-2015, more specifically, the project has the following outcomes.   1,  We have developed an unsupervised learning framework for learning the And-or graph models from raw images for object recognition.  Figure 1 shows an example of the And-or Graph automatically learned from input images without human annotation.  The representation discovered the primitives and parts in a hierarchy, and was used for object detection and recognition.  The figure is from a published paper:      Z. Si and S.C. Zhu,  Learning And-Or Templates for Object Recognition and Detection,  IEEE Trans on Pattern Analysis and Machine Intelligence, vol. 35, no.9, 2189-2205, 2013.  2, We have used the And-or Graph structure for modeling a wide variety of scene configurations, objects, occlusion patterns, human pose estimation,  human actions, vehicle detection and pose estimation. These vision tasks are important components in a range of vision applications.  Figure 2 illustrates a results of the algorithm for detecting vehicles where we use the and-or graph to represent the vehicle variabilities and occlusion patterns. This work has achieved state-of-the-art results on a challenging dataset for vehicle detection.  This figure is from a published paper:  B. Li, T.F. Wu and S.C. Zhu, Integrating Context and Occlusion for Car Detection by Hierarchical And-Or Model. Proc. of European Conf. on Computer Vision (ECCV), 2014.  3,  We have developed effective inference algorithms for scheduling top-down and bottom-up algorithm in the hierarchical And-Or graph. This algorithm is cost-effective and improve the performance in difficult conditions.  Figure 3 shows the results of detecting human faces in non-coorperative condition (in contrast to photo albums), excerpted from a published paper:   T.F. Wu and S.C. Zhu, A Numeric Study of the Bottom-up and Top-down Inference Processes in And-Or Graphs,  Int'l Journal of Computer Vision, vol. 93, no 2, p226-252, June 2011.  4, As a demonstration of applications, we developed a I2T: Image Parsing to Text Generation system.  The system diagram is shown in Figure 4. This is the first of its kind system that parse the images and video using the and-or graph representation, and thus convert the parsed results into narrative text description. The latter will support human queries in video surveillance.     This figure is from paper:    Z.Y. Yao, X. Yang, L. Lin, M. W. Lee, and S.C. Zhu, I2T: Image Parsing to Text Description,  Proceedings of IEEE, Vol 98, no.8,, pp 1485-1508, August, 2010.   The work was also reported by MIT Technology Review in 2010  Surveillance Software Knows What a Camera Sees .  5, Education aspects: the project  supported 4 Ph.D dissertations, and provided training for undergraduate students,  and enhance the computer vision program and curriculum at UCLA. The PI initiated a workshop series on Stochastic Image Grammar (SIG) with CVPR 2009,  ICCV2011 and a tutoal in CVPR 2012 to promote research in this direction. The PI also organized and gave lectures in  summer schools to attract underrepresented student groups.  6, Publications:   under the support of this project, the project team has published 20+ papers in top journal and conferences,  collected  and released new datasets and benchmark with codes to the public.          Last Modified: 07/03/2015       Submitted by: Song-Chun Zhu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
