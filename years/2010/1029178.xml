<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Head Eye Coordination, Motion Detection and Feedback Control with Counters</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2010</AwardEffectiveDate>
<AwardExpirationDate>09/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>345560.00</AwardTotalIntnAmount>
<AwardAmount>345560</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The proposal deals with orientation control of the human head/eye combination. The goal is to obtain the tracking signals to the combined head eye pair for the purpose of gaze fixation and tracking. The geometric framework utilizes Lagrangian dynamics in order to derive the dynamical system. For the purpose of tracking, the PI proposes to use nonlinear dynamics and control theory. The control signals to the human head eye complex are derived from three sources. The first two are position and velocity of the head and the eye. They are related to the muscles that actuate the eye movement and the vestibulo ocular reflex. The third signal is the target velocity in the coordinate system attached to the eye. The focus is to study dynamics and control of eye/head orientation; statistical modeling of the retinal signals conditioned on the target motion followed by target motion estimation and event based control implemented as a dynamical system with counters&lt;br/&gt;&lt;br/&gt;Intellectual Merit: &lt;br/&gt;&lt;br/&gt;The three major components of this proposal are: (a) Orientation control of the head eye combination for the purpose of ?Tracking?. (b) Statistical Modeling of the Retina for the purpose of estimating ?Target Motion Parameters?. (c) Dynamic control with counters in order to implement ?Event Based Control?. This component of the proposal can be described as ? Dynamic Control Theory with Event Based Counters. The deterministic signals are triggered by the events and the dynamic controller is described by an equation that has two components ? a smooth part and a jump discontinuity. The PI plans to work with researchers from the University of Chicago for the turtle retina and with Technische Universit¨at M¨unchen for  the eye/head coordination.&lt;br/&gt;&lt;br/&gt;Broader Impacts: The project is interdisciplinary and attracts attention from sensor guided robotics, nonlinear control and systems theory and neuroscientists interested in modeling. The research would be performed as integral part of the laboratory for Bio Cybernetics and Intelligent Systems. The research results would be part of a senior undergraduate special topics course, attended by students from Engineering, Biology and Arts and Sciences.</AbstractNarration>
<MinAmdLetterDate>09/20/2010</MinAmdLetterDate>
<MaxAmdLetterDate>09/20/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1029178</AwardID>
<Investigator>
<FirstName>Bijoy</FirstName>
<LastName>Ghosh</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bijoy K Ghosh</PI_FULL_NAME>
<EmailAddress>bijoy.ghosh@ttu.edu</EmailAddress>
<PI_PHON>8067422566</PI_PHON>
<NSF_ID>000098417</NSF_ID>
<StartDate>09/20/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas Tech University</Name>
<CityName>Lubbock</CityName>
<ZipCode>794091035</ZipCode>
<PhoneNumber>8067423884</PhoneNumber>
<StreetAddress>349 Administration Bldg</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>19</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX19</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041367053</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS TECH UNIVERSITY SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041367053</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas Tech University]]></Name>
<CityName>Lubbock</CityName>
<StateCode>TX</StateCode>
<ZipCode>794091035</ZipCode>
<StreetAddress><![CDATA[349 Administration Bldg]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>19</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX19</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~345560</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, the PI along with 4 graduate students, studied orientation control of human eye and head.&nbsp; Two of these students eventually got their PhD and two others finished their MS. The project was conducted in collaboration with a Neuroscience Laboratory at the University of Chicago together with a consultant from the Center of Sensorimotor Research, Ludwig-Maximillian Univ., Munich, Germany.</p> <p>&nbsp;</p> <p>As a result of this project, we now have a nonlinear dynamic model of the eye and head movement as a control system, improving from second order models that are often used in the literature. The head and the eye are modeled as a homogeneous sphere, actuated externally by torque inputs as control signals. The control signals are generated by appropriate neural excitation to the muscles.&nbsp; The states of the control system satisfy Listing&rsquo;s Law for the eye movement and Donders&rsquo; Law for the head movement. These laws were proposed since the mid-19<sup>th</sup> century by German physiologists Helmholtz, Donders and Listing.</p> <p>&nbsp;</p> <p>Data for this project was recorded from six subjects, aged 25 to 38 years with no known neurological or orthopedic disorders. For 3D eye movement recordings, a dual search coil was used on the left eye and for the 3D head movements, two coils mounted on a head ring at 90 degrees angle between them was used. Subjects had to follow a laser dot with a combination of natural eye and head (gaze) movements. The laser dot jumped randomly between the center and eight peripheral positions. The head movement data had been recorded as a temporal sequence of orientation points, each point represented as a unit quaternion. A second order Donders&rsquo; surface is obtained by least squares regression.</p> <p>&nbsp;</p> <p>A new &lsquo;potential control method&rsquo; has been introduced in this project to regulate eye and head to a desired final orientation.&nbsp; Optimal head movement trajectories are constructed using a pseudo spectral method, where the goal is to minimize a quadratic cost function on the energy of the applied control torques. The model trajectories are compared with measured trajectories of human eye and head movement.</p> <p>&nbsp;</p> <p>Using two forms of parameterization, the eye and head motion dynamics is described as an Euler-Lagrange&rsquo;s equation.&nbsp; For the dynamical systems so obtained, we address the well-known regulation and tracking problem.&nbsp; Particularly, we used our dynamic models to track trajectories of human eye and head generated from observed data.&nbsp; This gives us validation of the model, which we have constructed. Using our model, we are able to study various optimal strategies, viz. minimum time and minimum energy, and compare optimal trajectories with the trajectory obtained from recorded data.</p> <p>As a final application of our model, we studied human head-eye coordination to rapidly moving targets in the visual space. In the process, we modeled the vestibule-ocular reflex which stabilizes the image on the retina even while the head continues to move towards the target.&nbsp; The eye moves opposite to the movement of the head to compensate and maintain image stability.</p> <p>&nbsp;</p> <p>As another outcome of this project, we have completed modeling the turtle retina, for the purpose of estimating the target motion parameters. Using a model patch of the turtle retina, we show that it is possible to decode the motion direction and speed of a point target moving in the visual space of a turtle, using the spatiotemporal response of a retinal patch. Turtle retina primarily contains two kinds of cells that are functionally different &ndash; the intensity sensitive A cells and the motion direction sensitive B cells. The cells are clustered primarily in the vicinity of a visual streak and in this paper we analyze the decodability of a circular patch lo...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, the PI along with 4 graduate students, studied orientation control of human eye and head.  Two of these students eventually got their PhD and two others finished their MS. The project was conducted in collaboration with a Neuroscience Laboratory at the University of Chicago together with a consultant from the Center of Sensorimotor Research, Ludwig-Maximillian Univ., Munich, Germany.     As a result of this project, we now have a nonlinear dynamic model of the eye and head movement as a control system, improving from second order models that are often used in the literature. The head and the eye are modeled as a homogeneous sphere, actuated externally by torque inputs as control signals. The control signals are generated by appropriate neural excitation to the muscles.  The states of the control system satisfy ListingÆs Law for the eye movement and DondersÆ Law for the head movement. These laws were proposed since the mid-19th century by German physiologists Helmholtz, Donders and Listing.     Data for this project was recorded from six subjects, aged 25 to 38 years with no known neurological or orthopedic disorders. For 3D eye movement recordings, a dual search coil was used on the left eye and for the 3D head movements, two coils mounted on a head ring at 90 degrees angle between them was used. Subjects had to follow a laser dot with a combination of natural eye and head (gaze) movements. The laser dot jumped randomly between the center and eight peripheral positions. The head movement data had been recorded as a temporal sequence of orientation points, each point represented as a unit quaternion. A second order DondersÆ surface is obtained by least squares regression.     A new æpotential control methodÆ has been introduced in this project to regulate eye and head to a desired final orientation.  Optimal head movement trajectories are constructed using a pseudo spectral method, where the goal is to minimize a quadratic cost function on the energy of the applied control torques. The model trajectories are compared with measured trajectories of human eye and head movement.     Using two forms of parameterization, the eye and head motion dynamics is described as an Euler-LagrangeÆs equation.  For the dynamical systems so obtained, we address the well-known regulation and tracking problem.  Particularly, we used our dynamic models to track trajectories of human eye and head generated from observed data.  This gives us validation of the model, which we have constructed. Using our model, we are able to study various optimal strategies, viz. minimum time and minimum energy, and compare optimal trajectories with the trajectory obtained from recorded data.  As a final application of our model, we studied human head-eye coordination to rapidly moving targets in the visual space. In the process, we modeled the vestibule-ocular reflex which stabilizes the image on the retina even while the head continues to move towards the target.  The eye moves opposite to the movement of the head to compensate and maintain image stability.     As another outcome of this project, we have completed modeling the turtle retina, for the purpose of estimating the target motion parameters. Using a model patch of the turtle retina, we show that it is possible to decode the motion direction and speed of a point target moving in the visual space of a turtle, using the spatiotemporal response of a retinal patch. Turtle retina primarily contains two kinds of cells that are functionally different &ndash; the intensity sensitive A cells and the motion direction sensitive B cells. The cells are clustered primarily in the vicinity of a visual streak and in this paper we analyze the decodability of a circular patch located near the center of the streak. The patch is subjected to a moving point target, as input, that passes through its center along various different angles and speed. The first problem considered is to detect the motion direction of ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
