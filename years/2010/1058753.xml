<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Brain-Mobile Interfaces: Exploratory Research into the Development of Networked NeuroPhones</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2010</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>249998.00</AwardTotalIntnAmount>
<AwardAmount>249998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Thyagarajan Nandagopal</SignBlockName>
<PO_EMAI>tnandago@nsf.gov</PO_EMAI>
<PO_PHON>7032924550</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Research supported by this EAGER award is developing the NeuroPhone system, the first Brain-Mobile phone Interface (BMI) that enables neural signals from consumer-level wireless electroencephalography (EEG) headsets worn by people as they go about their everyday lives to be interfaced to mobile phones and combined with existing sensor streams on the phone (e.g., accelerometers, gyroscopes, GPS) to enable new forms of interaction, communications and human behavior modeling. &lt;br/&gt;&lt;br/&gt;Specifically, this high-risk exploratory research is to:&lt;br/&gt;&lt;br/&gt;1) study new energy-efficient techniques and algorithms for low-cost wireless EEG headsets and mobile phones for robust sensing, processing and duty cycling of neural signals using consumer devices;&lt;br/&gt;&lt;br/&gt;2) develop new learning and classifications algorithms for the mobile phone to extract and infer cognitively informative signals (e.g., P300, N400, and neural synchrony) from EEG headsets in noisy mobile environments;&lt;br/&gt;&lt;br/&gt;3) deploy networked NeuroPhone systems with a focus on real-time multi-party neural synchrony and the networking, privacy and sharing of neural signals between networked NeuroPhones; and&lt;br/&gt;&lt;br/&gt;4) evaluate networked NeuroPhones applications, specifically, measuring teacher-student engagement in the classroom and measuring group level emotional state.&lt;br/&gt;&lt;br/&gt;This interdisciplinary research opens up opportunities in education, teaching and outreach, in part because it focuses on an educational NeuroPhone application, which contributes new insights into cognitive engagements of students in the classroom as well as engages students from the Department of Computer Science and the Department of Psychological and Brain Sciences in the project. Results from this work will transform applications across diverse domains such as education, health monitoring, and social networking.</AbstractNarration>
<MinAmdLetterDate>08/26/2010</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1058753</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Campbell</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew T Campbell</PI_FULL_NAME>
<EmailAddress>campbell@cs.dartmouth.edu</EmailAddress>
<PI_PHON>6136468712</PI_PHON>
<NSF_ID>000103945</NSF_ID>
<StartDate>08/26/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tanzeem</FirstName>
<LastName>Choudhury</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tanzeem Choudhury</PI_FULL_NAME>
<EmailAddress>tanzeem.choudhury@cornell.edu</EmailAddress>
<PI_PHON>6072556979</PI_PHON>
<NSF_ID>000083187</NSF_ID>
<StartDate>08/26/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rajeev</FirstName>
<LastName>Raizada</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rajeev Raizada</PI_FULL_NAME>
<EmailAddress>rajeev.raizada@gmail.com</EmailAddress>
<PI_PHON/>
<NSF_ID>000540784</NSF_ID>
<StartDate>08/26/2010</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Dartmouth College</Name>
<CityName>HANOVER</CityName>
<ZipCode>037551421</ZipCode>
<PhoneNumber>6036463007</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROJECTS</StreetAddress>
<StreetAddress2><![CDATA[11 ROPE FERRY RD #6210]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041027822</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF DARTMOUTH COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041027822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dartmouth College]]></Name>
<CityName>HANOVER</CityName>
<StateCode>NH</StateCode>
<ZipCode>037551421</ZipCode>
<StreetAddress><![CDATA[OFFICE OF SPONSORED PROJECTS]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NH02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~249998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This research project addressed the intersection of three different problems: using neural decoding to extract meaningful information from people's brain activation patterns, obtaining reliable neural data in noisy real-world environments using low-cost consumer-level EEG headsets, and using the information decoded from that neural data to interface with iPhones.</p> <p><br />The project made significant steps forward on all three of these problems. Although it will likely be many years before neural interfacing with smartphones becomes fully practical for everyday use, we believe that this project has laid the foundations for that future work.</p> <p><br />Specifically, we produced a fully working prototype system which allowed the user to choose amongst contacts in their phonebook and to dial the selected contact, entirely driven by neural signals transmitted wirelessly to the phone. We further developed and extended this work by testing the reliability of the neural signals in real-world conditions. The most difficult typical scenario is when the user is freely walking, as vibration from each footstep causes large EEG artifacts. We found that even in this scenario, information could still be extracted from the neural signals for the purposes of classification. We also developed novel algorithms for neural decoding which are able to capture commonalities across different individuals, a result which will be important in order for systems to be usable by new users with minimal person-specific training.</p> <p><br />We disseminated the results of this research via publications not only in scholarly journals and international conferences, but also in ways which will reach a wider audience. In particular, our work was featured in the New York Times, and we freely and publicly released the source code for our system so that anybody can explore our system and build upon it in order to further their own research.</p><br> <p>            Last Modified: 12/01/2013<br>      Modified by: Rajeev&nbsp;Raizada</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This research project addressed the intersection of three different problems: using neural decoding to extract meaningful information from people's brain activation patterns, obtaining reliable neural data in noisy real-world environments using low-cost consumer-level EEG headsets, and using the information decoded from that neural data to interface with iPhones.   The project made significant steps forward on all three of these problems. Although it will likely be many years before neural interfacing with smartphones becomes fully practical for everyday use, we believe that this project has laid the foundations for that future work.   Specifically, we produced a fully working prototype system which allowed the user to choose amongst contacts in their phonebook and to dial the selected contact, entirely driven by neural signals transmitted wirelessly to the phone. We further developed and extended this work by testing the reliability of the neural signals in real-world conditions. The most difficult typical scenario is when the user is freely walking, as vibration from each footstep causes large EEG artifacts. We found that even in this scenario, information could still be extracted from the neural signals for the purposes of classification. We also developed novel algorithms for neural decoding which are able to capture commonalities across different individuals, a result which will be important in order for systems to be usable by new users with minimal person-specific training.   We disseminated the results of this research via publications not only in scholarly journals and international conferences, but also in ways which will reach a wider audience. In particular, our work was featured in the New York Times, and we freely and publicly released the source code for our system so that anybody can explore our system and build upon it in order to further their own research.       Last Modified: 12/01/2013       Submitted by: Rajeev Raizada]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
