<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Pilot:   Assisted Musical Composition through Functional Scaffolding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>295229.00</AwardTotalIntnAmount>
<AwardAmount>295229</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As a ubiquitous creative endeavor across all human cultures, musical composition is an effective microcosm for the study of creativity in general.  This project will impact computer science by showing through assisted musical composition how computers can genuinely improve upon the creative capabilities of humans alone.   By introducing an interactive framework that enables even inexperienced users to realize their creative vision, this project also helps pave the way for such systems to amplify our creative potential in other areas in the future, such as in engineering and design.  The technology that will be developed, called Functional Scaffolding for Musical Composition (FSMC), takes the unique approach of computing accompaniment for existing musical tracks (called the ?scaffold?) by generating special functions that take the scaffold as input and output accompanying tracks.  In this way, generated tracks are in effect transformations of the scaffold, allowing them to inherit the global structure and implicit nuance of the preexisting music.  The implication for computational creativity in general is thus to harness the richness of preexisting human-generated content as a seed for further elaboration.   Furthermore, the user will be provided an interactive evolutionary interface that makes it possible to search the space of such transforming functions, in effect allowing the user to continually breed and elaborate new concepts that build upon preexisting incomplete works.&lt;br/&gt;&lt;br/&gt;The primary target audience for FSMC as a practical technology will be musicians who lack the resources, collaborators, or expertise to produce complete musical compositions.  For example, while a hobbyist with a keyboard might be able to compose a compelling melody, lack of expertise in other instruments may prohibit adding accompanying guitar or base.  In addition, even more experienced musicians may benefit from the capability to quickly propose accompaniment as a new means of concept generation.  In fact, existing computer programs that aid in musical composition often register millions of downloads online, demonstrating broad public interest in applications that enhance musical creativity.  In addition to dissemination through scientific conferences focusing on computational creativity, the results of this research will be released in a form compatible with such programs, thereby directly impacting the public with a practical utility and consequently raising awareness of the potential for artificial intelligence and machine learning to enhance creativity in general.</AbstractNarration>
<MinAmdLetterDate>07/20/2010</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1002507</AwardID>
<Investigator>
<FirstName>Kenneth</FirstName>
<LastName>Stanley</LastName>
<PI_MID_INIT>O</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kenneth O Stanley</PI_FULL_NAME>
<EmailAddress>kstanley@cs.ucf.edu</EmailAddress>
<PI_PHON>4078234289</PI_PHON>
<NSF_ID>000092231</NSF_ID>
<StartDate>07/20/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>The University of Central Florida Board of Trustees</Name>
<CityName>Orlando</CityName>
<ZipCode>328168005</ZipCode>
<PhoneNumber>4078230387</PhoneNumber>
<StreetAddress>4000 CNTRL FLORIDA BLVD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>150805653</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The University of Central Florida Board of Trustees]]></Name>
<CityName>Orlando</CityName>
<StateCode>FL</StateCode>
<ZipCode>328168005</ZipCode>
<StreetAddress><![CDATA[4000 CNTRL FLORIDA BLVD]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7788</Code>
<Text>CreativeIT</Text>
</ProgramElement>
<ProgramReference>
<Code>7788</Code>
<Text>CreativeIT</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~295229</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>While the specific artificial intelligence technology developed over the course of this project was to assist humans without musical expertise to compose plausible musical compositions, the project also served more broadly as a demonstration of how humans and computers can collaborate effectively to amplify the potential achievements on non-experts in domains usually confined to experts.&nbsp; Furthermore, the project enlisted not only Ph.D. students in computer science but also undergraduate music majors, who thereby gained unique knowledge of relevant computer technology that they can bring back to their respective industries in the future.</p> <p>The main technology product is based on a novel algorithmic approach to music composition called functional scaffolding for musical composition (FSMC).&nbsp; The main idea in FSMC is that musical accompaniment can be generated literally as a function of preexisting music.&nbsp; That is, because functions are transformations of the patterns they input, FSMC generates plausible accompaniment by transforming an existing line of music into another line that inherits some of its properties.&nbsp; That way, the newly-generated accompaniment shares commonalities with the initial music.&nbsp; This approach to music is interesting because it shifts the burden for the computer away from generating a specific sequence of notes to instead generating a function that converts one sequence of notes to another.&nbsp;</p> <p>The FSMC approach was implemented in a user-friendly program called MaestroGenesis (see accompanying figure), which was made freely available to the public at <a href="http://maestrogenesis.org/">http://maestrogenesis.org/</a>.&nbsp; &nbsp;MaestroGenesis generates a set of transforming functions and shows the user the resulting accompaniments, from which the user can pick his or her favorites.&nbsp; MaestroGenesis then generates a new population of accompaniments that are derived from the functions that the user liked in the previous generation.&nbsp; In effect, the user (who does not need to understand the underlying functions being generated) is able to breed new accompaniments almost like a human might breed dogs or horses.&nbsp; &nbsp;Over the course of the project, increasingly sophisticated versions of this idea were built until it became possible to generate entire multi-part pieces from only a single monophonic starting melody.&nbsp; Examples can be heard at <a href="http://eplex.cs.ucf.edu/fsmc/cmj/">http://eplex.cs.ucf.edu/fsmc/cmj/</a>. &nbsp;Thus a key outcome of this project is one of the most sophisticated musical accompaniment generation technologies available.</p> <p>The intellectual merit of the project is apparent in the several ways in which it advanced knowledge:&nbsp; First, it confirmed (1) that new musical parts can be generated as functions of preexisting parts, thereby introducing a new hypothesis on the relationships among different musical parts and also a new algorithm for generating such relationships.&nbsp; Second (2), the method and interface that allows humans to collaborate with computers to create new creative artifacts through a simple interactive breeding process shows that in fact non-experts can produce plausible works with the right support.&nbsp; This idea for human-computer collaboration was later generalized (3) to a more generic platform that can be applied even outside of music called Worldwide Interactive Neuroevolution in the latter part of the project.&nbsp;</p> <p>Broader impacts that can potentially benefit society include (1) a new understanding of human music appreciation that suggests why some pieces sound better than others.&nbsp; In short, the theory behind FSMC and the project&rsquo;s results from human studies suggest that humans implicitly enjoy perceiving the functional relationships among different musical parts.&nbsp; (2) The Maestrogenesis software opens u...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ While the specific artificial intelligence technology developed over the course of this project was to assist humans without musical expertise to compose plausible musical compositions, the project also served more broadly as a demonstration of how humans and computers can collaborate effectively to amplify the potential achievements on non-experts in domains usually confined to experts.  Furthermore, the project enlisted not only Ph.D. students in computer science but also undergraduate music majors, who thereby gained unique knowledge of relevant computer technology that they can bring back to their respective industries in the future.  The main technology product is based on a novel algorithmic approach to music composition called functional scaffolding for musical composition (FSMC).  The main idea in FSMC is that musical accompaniment can be generated literally as a function of preexisting music.  That is, because functions are transformations of the patterns they input, FSMC generates plausible accompaniment by transforming an existing line of music into another line that inherits some of its properties.  That way, the newly-generated accompaniment shares commonalities with the initial music.  This approach to music is interesting because it shifts the burden for the computer away from generating a specific sequence of notes to instead generating a function that converts one sequence of notes to another.   The FSMC approach was implemented in a user-friendly program called MaestroGenesis (see accompanying figure), which was made freely available to the public at http://maestrogenesis.org/.   MaestroGenesis generates a set of transforming functions and shows the user the resulting accompaniments, from which the user can pick his or her favorites.  MaestroGenesis then generates a new population of accompaniments that are derived from the functions that the user liked in the previous generation.  In effect, the user (who does not need to understand the underlying functions being generated) is able to breed new accompaniments almost like a human might breed dogs or horses.   Over the course of the project, increasingly sophisticated versions of this idea were built until it became possible to generate entire multi-part pieces from only a single monophonic starting melody.  Examples can be heard at http://eplex.cs.ucf.edu/fsmc/cmj/.  Thus a key outcome of this project is one of the most sophisticated musical accompaniment generation technologies available.  The intellectual merit of the project is apparent in the several ways in which it advanced knowledge:  First, it confirmed (1) that new musical parts can be generated as functions of preexisting parts, thereby introducing a new hypothesis on the relationships among different musical parts and also a new algorithm for generating such relationships.  Second (2), the method and interface that allows humans to collaborate with computers to create new creative artifacts through a simple interactive breeding process shows that in fact non-experts can produce plausible works with the right support.  This idea for human-computer collaboration was later generalized (3) to a more generic platform that can be applied even outside of music called Worldwide Interactive Neuroevolution in the latter part of the project.   Broader impacts that can potentially benefit society include (1) a new understanding of human music appreciation that suggests why some pieces sound better than others.  In short, the theory behind FSMC and the projectÆs results from human studies suggest that humans implicitly enjoy perceiving the functional relationships among different musical parts.  (2) The Maestrogenesis software opens up the experience of musical creativity to musical non-experts who would otherwise have no way to express their musical intuitions effectively.   The implications of this achievement also extend beyond just music to many creative endeavors (3) by providing a proof of concept that s...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
