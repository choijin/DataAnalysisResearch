<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Serious Gaming Platform for Mastering the Physician-Patient Diagnostic Interview</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2011</AwardExpirationDate>
<AwardTotalIntnAmount>149335.00</AwardTotalIntnAmount>
<AwardAmount>149335</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Glenn H. Larsen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project aims to implement a new strategy for teaching medical students to interact with and relate to patients. Present teaching methods are labor intensive for instructors and students and limited to fixed settings. The project team will develop a serious gaming software platform that captures the human element by simulating patient responses (level of trust, topic comfort, and sense of urgency) through the use of ?intelligent, emoting avatars? (virtual patients) represented through artificial intelligence (AI) and dynamic video. The software platform replaces the passive experience of dialog tree based character interaction with the active experience of dynamic conversation. The training platform will have elements of virtual reality (interactive, immersive, and experiential) and be capable of supporting libraries of virtual patients. The innovation will enable applications to provide a new level of emotional experience for the users by achieving an emotional attachment and sense of bonding with intelligent virtual characters, capable of dynamic conversation and emotional responses based on concepts involving level of trust, topic comfort, and sense of urgency. The product will enable the student to practice and learn at their own computer on their own schedule within a ?learning environment? that is extraordinarily rich and realistic.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project will change the way medical students learn in the medical school environment.  Medical school teaching methods are costly, labor intensive for instructors and students and limited to fixed settings. The project team will develop a serious gaming software platform that relies on artificial intelligence and makes use of the interactive, immersive, and experiential elements of virtual reality that have made video games so successful. They will adapt these elements to serious gaming to create an instructional technology to teach medical students to interact with and relate to patients. The student will interact with a virtual patient by entering keyboard based dialog or by using speech recognition technology. The product will enable the student to practice and learn at their own computer on their own schedule. The essentially passive experience of dialog tree based character interaction is replaced with the active experience of dynamic conversation. This technology is intended to address the problems posed by present expensive medical school teaching methods which are labor intensive for instructors and students. The technology will offer advances over traditional on-line and class-room instruction materials such as video presentations, PowerPoint and flat written formats. Over the long term, this entirely scalable technology has the potential to fundamentally enrich the educational environment for medical school teaching with a correspondingly enormous commercial profitability and societal impact.</AbstractNarration>
<MinAmdLetterDate>12/15/2010</MinAmdLetterDate>
<MaxAmdLetterDate>12/15/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1046589</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Baker</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David V Baker</PI_FULL_NAME>
<EmailAddress>vicbaker01@gmail.com</EmailAddress>
<PI_PHON>3042918977</PI_PHON>
<NSF_ID>000518232</NSF_ID>
<StartDate>12/15/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>IntelligentSimulations LLC</Name>
<CityName>Morgantown</CityName>
<ZipCode>265088900</ZipCode>
<PhoneNumber>3042918977</PhoneNumber>
<StreetAddress>1022 Laurelwood Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>West Virginia</StateName>
<StateCode>WV</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WV01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>828349246</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>INTELLIGENTSIMULATIONS LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[IntelligentSimulations LLC]]></Name>
<CityName>Morgantown</CityName>
<StateCode>WV</StateCode>
<ZipCode>265088900</ZipCode>
<StreetAddress><![CDATA[1022 Laurelwood Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>West Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WV01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>1658</Code>
<Text>SOFTWARE</Text>
</ProgramReference>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~149335</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This Small Business Innovation Research (SBIR) Phase I project implemented an Artificial Intelligence (AI) Patient Platform which is a new strategy for teaching medical students to interact with and relate to patients. Present teaching methods are labor intensive for instructors and students and limited to fixed settings. The Phase I project team developed a serious gaming software platform that captures the human element by simulating patient responses (level of trust, topic comfort, and sense of urgency) through the use of &ldquo;intelligent, emoting avatars&rdquo; (virtual patients) represented through artificial intelligence and dynamic video. The software platform replaces the passive experience of dialog tree based character interaction with the active experience of dynamic conversation. The training platform has elements of virtual reality (interactive, immersive, experiential) and is capable of supporting libraries of virtual patients. The AI Patient platform provides a new level of emotional experience for the users by achieving an emotional attachment and sense of bonding with intelligent virtual characters, capable of dynamic conversation and emotional responses based on concepts involving level of trust, topic comfort, and sense of urgency. The product enables the student to practice and learn at their own computer on their own schedule within a learning environment that is extraordinarily rich and realistic.</p> <p>&nbsp;</p> <p>The broader impact of this project will change the way medical students learn in the medical school environment.&nbsp; Medical school teaching methods are costly, labor intensive for instructors and students, and limited to fixed settings. The project team developed a serious gaming software platform that relies on artificial intelligence and makes use of the interactive, immersive, and experiential elements of virtual reality that have made video games so successful. We adapted these elements to serious gaming to create an instructional technology to teach medical students to master the diagnostic interview by interacting with a virtual patient. The students can interact with the virtual patient by entering keyboard based dialog or by using speech recognition technology.<span style="text-decoration: line-through;">&nbsp; </span></p> <p>At the conclusion of the Phase I project we conducted a focus group consisting of a medical school physician and six medical students.&nbsp; Based on quantitative results as well as oral and written comments, the focus group participants rated<strong><em> the AI Patient training software as an effective way of improving their skills and they are excited to use it as a method of training in the near future.</em></strong></p> <p>All of the focus group participants indicated that their attitude toward the AI Patient was similar to the attitude they have in a real patient interaction.&nbsp; Additionally, 71% of the focus group participants stated they could transfer their learning from the AI software to a real-life environment successfully.</p> <p>The results of the Phase I focus group show that the technology readily out competes traditional on-line and class-room instruction materials such as video presentations, PowerPoint and flat written formats.&nbsp; In our Phase I focus group, the AI Patient Platform was ranked as the most effective <strong>training solution</strong><strong> that most closely approximates human 1:1 mentoring and real-life experience</strong>.&nbsp; Over the long term, this entirely scalable technology has the potential to fundamentally enrich the educational environment for medical school teaching, or any additional fields requiring rapport building skills, with a correspondingly enormous commercial profitability and societal impact.</p><br> <p>            Last Modified: 07/09/2011<br>      Modified by: David&nbsp;V&nbsp;Baker</p> </div> <div class="porSideCol"></div> </div...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This Small Business Innovation Research (SBIR) Phase I project implemented an Artificial Intelligence (AI) Patient Platform which is a new strategy for teaching medical students to interact with and relate to patients. Present teaching methods are labor intensive for instructors and students and limited to fixed settings. The Phase I project team developed a serious gaming software platform that captures the human element by simulating patient responses (level of trust, topic comfort, and sense of urgency) through the use of "intelligent, emoting avatars" (virtual patients) represented through artificial intelligence and dynamic video. The software platform replaces the passive experience of dialog tree based character interaction with the active experience of dynamic conversation. The training platform has elements of virtual reality (interactive, immersive, experiential) and is capable of supporting libraries of virtual patients. The AI Patient platform provides a new level of emotional experience for the users by achieving an emotional attachment and sense of bonding with intelligent virtual characters, capable of dynamic conversation and emotional responses based on concepts involving level of trust, topic comfort, and sense of urgency. The product enables the student to practice and learn at their own computer on their own schedule within a learning environment that is extraordinarily rich and realistic.     The broader impact of this project will change the way medical students learn in the medical school environment.  Medical school teaching methods are costly, labor intensive for instructors and students, and limited to fixed settings. The project team developed a serious gaming software platform that relies on artificial intelligence and makes use of the interactive, immersive, and experiential elements of virtual reality that have made video games so successful. We adapted these elements to serious gaming to create an instructional technology to teach medical students to master the diagnostic interview by interacting with a virtual patient. The students can interact with the virtual patient by entering keyboard based dialog or by using speech recognition technology.    At the conclusion of the Phase I project we conducted a focus group consisting of a medical school physician and six medical students.  Based on quantitative results as well as oral and written comments, the focus group participants rated the AI Patient training software as an effective way of improving their skills and they are excited to use it as a method of training in the near future.  All of the focus group participants indicated that their attitude toward the AI Patient was similar to the attitude they have in a real patient interaction.  Additionally, 71% of the focus group participants stated they could transfer their learning from the AI software to a real-life environment successfully.  The results of the Phase I focus group show that the technology readily out competes traditional on-line and class-room instruction materials such as video presentations, PowerPoint and flat written formats.  In our Phase I focus group, the AI Patient Platform was ranked as the most effective training solution that most closely approximates human 1:1 mentoring and real-life experience.  Over the long term, this entirely scalable technology has the potential to fundamentally enrich the educational environment for medical school teaching, or any additional fields requiring rapport building skills, with a correspondingly enormous commercial profitability and societal impact.       Last Modified: 07/09/2011       Submitted by: David V Baker]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
