<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Plug and Play Characters for 3D Virtual Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2010</AwardEffectiveDate>
<AwardExpirationDate>12/31/2010</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Errol Arkilic</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project will evaluate the feasibility of creating reusable, self-encapsulated animated characters for use in 3D virtual environments, such as those found in training simulations, video games, virtual worlds, and other 3D applications. Animated characters are a major component of many virtual environments, but are difficult to develop. Characters move and interact with each other in complex ways, and must autonomously make rational decisions. Unnatural movement or behavior can destroy a virtual environment's believability. This project aims to create a reusable character animation component that can be integrated into different virtual environments using a high-level interface to communicate with the host application. The innovation behind this high-level interface is a novel technique that unifies control demands, environmental constraints, environmental interactions, and inter-character interactions into a single framework. The technique uses a differential representation of animation to enforce constraints while retaining small-scale details that are key to realism. &lt;br/&gt;&lt;br/&gt;Virtual environments are expensive to build.  Since nearly half of the cost of a virtual environment is spent on artwork and engineering, it makes sense to reuse as much as possible. Reuse could dramatically lower costs. In practice though, very little is reusable. Current character animation middleware products (i.e., third-party character animation software components) are not truly application-independent. They are often intimately tied to the host application's logic so that they can support application-specific features. This project will evaluate the commercial feasibility of offering application-independent, reusable character animation middleware as part of a complete virtual character platform. This platform will offer end-consumers customizable 3D avatars that can be used in any application that supports the proposed interface. If adopted, reusable character assets and application-independent middleware will reduce development time and cost, stimulating the creation of new applications for training, entertainment, communication, and education.</AbstractNarration>
<MinAmdLetterDate>04/20/2010</MinAmdLetterDate>
<MaxAmdLetterDate>04/20/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1014407</AwardID>
<Investigator>
<FirstName>Okan</FirstName>
<LastName>Arikan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Okan Arikan</PI_FULL_NAME>
<EmailAddress>okarikan@gmail.com</EmailAddress>
<PI_PHON>5107301212</PI_PHON>
<NSF_ID>000553915</NSF_ID>
<StartDate>04/20/2010</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Animeeple Inc.</Name>
<CityName>Mountain View</CityName>
<ZipCode>940401088</ZipCode>
<PhoneNumber>6504175020</PhoneNumber>
<StreetAddress>146 Montelena Ct.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832775675</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ANIMEEPLE INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Animeeple Inc.]]></Name>
<CityName>Mountain View</CityName>
<StateCode>CA</StateCode>
<ZipCode>940401088</ZipCode>
<StreetAddress><![CDATA[146 Montelena Ct.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6850</Code>
<Text>DIGITAL SOCIETY&amp;TECHNOLOGIES</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>This Small Business Innovation Research Phase I project evaluated the feasibility of creating 3D avatars with user-customizable animations.&nbsp; There were three technical goals for this project:</span></p> <ol> <li><span>Allow users to select the animations that they wish to use in each application.</span></li> <li><span>Allow users to transfer avatars and animations between applications.</span></li> <li><span>Allow users to create their own animations.</span></li> </ol> <p>To address the first goal of allowing users to select motions they wish to use, we created a novel character animation engine to which animations can be added and deleted on-the-fly, even while the host application is running.&nbsp; We created a standardized authoring pipeline, and devised a perceptually-motivated blending technique that unifies control demands and environmental constraints into a single framework. &nbsp;</p> <p>We generalized the motion synthesis technique the engine uses to address the second goal of allowing users to transfer avatars between applications.&nbsp; Generalization was achieved by extending the users&rsquo; ability to add and delete animations to the applications themselves.&nbsp;</p> <p><span>To address the third goal of allowing users to create their own animations, we created a gesture-based posing system for multitouch-enabled devices.&nbsp; Hands can perform complex and high degree of freedom gestures naturally, making them better suited for animation than traditional input devices like mice and joysticks, which have few degrees of freedom. &nbsp;</span></p> <p>This project's broader impact fell into two areas. &nbsp;First, multitouch is a new interactive paradigm that will become ubiquitous through the proliferation of smart phones and tablets. &nbsp;This project investigated multitouch schemes for intuitive control of complex, articulated models such as 3D humanoid figures. &nbsp;Second, this project investigated methods important for incremental construction of virtual environments. &nbsp;Virtual environments are used widely in entertainment, training simulations, virtual worlds, and other 3D applications.</p><br> <p>            Last Modified: 02/02/2011<br>      Modified by: Okan&nbsp;Arikan</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2011/1014407/1014407_10015038_1296689994811_IMG_0147--rgov-214x142.jpg" original="/por/images/Reports/POR/2011/1014407/1014407_10015038_1296689994811_IMG_0147--rgov-800width.jpg" title="Hipnoz screenshot"><img src="/por/images/Reports/POR/2011/1014407/1014407_10015038_1296689994811_IMG_0147--rgov-66x44.jpg" alt="Hipnoz screenshot"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Hipnoz is the first embodiment of the proposed animation technology.  In this application, multitouch gestures make the character dance.  Hipnoz won the Disney Learning Challenge 2010's award for "Outstanding Engagement in an Educational Product".</div> <div class="imageCredit">Animeeple Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Okan&nbsp;Arikan</div> <div class="imageTitle">Hipnoz screenshot</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This Small Business Innovation Research Phase I project evaluated the feasibility of creating 3D avatars with user-customizable animations.  There were three technical goals for this project:  Allow users to select the animations that they wish to use in each application. Allow users to transfer avatars and animations between applications. Allow users to create their own animations.   To address the first goal of allowing users to select motions they wish to use, we created a novel character animation engine to which animations can be added and deleted on-the-fly, even while the host application is running.  We created a standardized authoring pipeline, and devised a perceptually-motivated blending technique that unifies control demands and environmental constraints into a single framework.    We generalized the motion synthesis technique the engine uses to address the second goal of allowing users to transfer avatars between applications.  Generalization was achieved by extending the usersÆ ability to add and delete animations to the applications themselves.   To address the third goal of allowing users to create their own animations, we created a gesture-based posing system for multitouch-enabled devices.  Hands can perform complex and high degree of freedom gestures naturally, making them better suited for animation than traditional input devices like mice and joysticks, which have few degrees of freedom.    This project's broader impact fell into two areas.  First, multitouch is a new interactive paradigm that will become ubiquitous through the proliferation of smart phones and tablets.  This project investigated multitouch schemes for intuitive control of complex, articulated models such as 3D humanoid figures.  Second, this project investigated methods important for incremental construction of virtual environments.  Virtual environments are used widely in entertainment, training simulations, virtual worlds, and other 3D applications.       Last Modified: 02/02/2011       Submitted by: Okan Arikan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
