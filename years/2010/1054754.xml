<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Secure and Reliable Outsourced Storage Systems Using Remote Data Checking</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2011</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>530470.00</AwardTotalIntnAmount>
<AwardAmount>501731</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Fen Zhao</SignBlockName>
<PO_EMAI>fzhao@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When data is outsourced at a cloud storage provider, data owners lose control over the integrity of their data and must trust the storage provider unconditionally. Coupled with numerous data loss incidents, this prevents organizations from assessing the risk posed by outsourcing data to untrusted clouds, making cloud storage unsuitable for applications that require long-term security and reliability guarantees. This project establishes a practical remote data checking (RDC) framework as a mechanism to provide long-term integrity and reliability for remotely stored data. At the same time, the project seeks to develop new functionality for remote data checking that overcomes limitations of early RDC protocols and improves the usability and deployability of RDC on existing cloud storage infrastructures. Unlike previous work, this research takes a holistic approach and considers RDC protocols that minimize the combined security costs of all data management phases over the lifetime of a distributed storage system. This includes prevention, repair, and retrieval. Maintaining the health of the data in a distributed storage system requires various transformations to be applied on the data and requires data to migrate among storage servers. This project develops novel RDC protocols that are compatible with the full range of replication, erasure coding and network coding operations employed by distributed storage systems, thus enabling owners to maintain better control over their data. This project increases the transparency of cloud storage platforms and improves the security dimension of storage outsourcing enabling wider adoption of cloud storage technologies. To disseminate these ideas, the project's educational activities include curriculum development, mentoring undergraduate and graduate students and engaging them into research, and outreach to high-school teachers.</AbstractNarration>
<MinAmdLetterDate>06/21/2011</MinAmdLetterDate>
<MaxAmdLetterDate>09/22/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1054754</AwardID>
<Investigator>
<FirstName>Reza</FirstName>
<LastName>Curtmola</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Reza Curtmola</PI_FULL_NAME>
<EmailAddress>crix@njit.edu</EmailAddress>
<PI_PHON>9735965776</PI_PHON>
<NSF_ID>000520913</NSF_ID>
<StartDate>06/21/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New Jersey Institute of Technology</Name>
<CityName>Newark</CityName>
<ZipCode>071021982</ZipCode>
<PhoneNumber>9735965275</PhoneNumber>
<StreetAddress>University Heights</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>075162990</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW JERSEY INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>075162990</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New Jersey Institute of Technology]]></Name>
<CityName>Newark</CityName>
<StateCode>NJ</StateCode>
<ZipCode>071021982</ZipCode>
<StreetAddress><![CDATA[University Heights]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~493930</FUND_OBLG>
<FUND_OBLG>2013~7800</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main research goal of this project is to create a framework that provides strong integrity, availability and reliability guarantees for long-term storage when data is outsourced to a cloud storage provider (CSP). Behind this seemingly simple goal there are complexities and subtleties that stem from several constraints and requirements: CSPs cannot be trusted, long-term storage outsourcing exacerbates the short-term storage threats, and secure storage outsourcing has uniqueperformance demands in order to be practical. We rely on <em>remote data integrity checking (RDIC)</em> as the main mechanism to ensure thelong-term integrity, availability, and reliability of data outsourced to a distributed storage system.</p> <!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.0px Helvetica} --> <p class="p1">Reliability in this context is a measure of whether a CSP is still able to provide the correct data upon request by the client. A client that initially stores data with a server (CSP), later checks that the server continues to store the same data that was originally stored. We are interested in protocols that allow a client to periodically challenge the server into proving data possession, i.e. , the ability to produce the client's original data in its entirety. We seek to achieve a <em>data possession guarantee</em>, which implies both the integrity and the availability of the data stored at an untrusted server: The server possesses the same original data (integrity) and can prove it has the ability to produce this data at the moment of the challenge (availability). Such a guarantee will empower data owners to maintain control over how their data is stored and managed. It will also provide data owners with means to assess the risk of outsourcing storage and will increase the transparency of CSPs.</p> <p>The novel outcomes of this project are:</p> <p><strong>1) New Remote Data Integrity Checking (RDIC) protocols</strong> that substantially improve the guarantees, functionality, and performance when managing data stored at untrusted cloud storage providers (CSPs). This includes:</p> <p>- extending the RDIC guarantee from a single-server to a more realistic multiple-server setting,</p> <p>- handling arbitrary amounts of data corruption,&nbsp;</p> <p>-&nbsp;minimizing the data owner&rsquo;s involvement in the repair phase over the lifetime of a distributed storage system,</p> <p>- reconcilig replication with deduplication of data, while providing transparency to data owners.</p> <p>As a result,&nbsp;RDIC can fully realize our vision of outsourcing both the storage and management of data. Our new RDIC protocols provide important functionality for remote data integrity checking that overcomes limitations of previous RDIC protocols and improves the usability and deployability of RDIC protocols for existing cloud storage infrastructures.&nbsp;By designing remote data integrity checking schemes that support both replication and transparency, can ensure data reliability while enabling a new pricing model which takes into account the level of deduplication of the data: The more users store the same piece of data, the lower each individual user gets charged for storing that piece of data. This can provide significant savings for clients, thus lowering the costs of storing data in the cloud. By allowing the storage providers to preserve the remote data integrity auditing capabilities even when data suffers transformations while in storage, we reduce the cost of managing the data stored at these providers.</p> <p>&nbsp;</p> <p><strong>2) Improved Security of Version Control Systems:</strong></p> <p>- &nbsp;We have developed Auditable Version Control Systems (AVCS), which are version control systems (VCS) designed to function under an adversarial setting. We proposed RDC-AVCS, an AVCS scheme for skip delta-based VCS systems, which relies on RDIC mechanisms to ensure all the versions of a file are retrievable from the untrusted VCS server over time.&nbsp;By providing an efficient solution which is optimized for real-world VCS systems, RDC-AVCS improves the usability and deployability of RDIC for existing VCS systems.</p> <p>-&nbsp;We have improved the security of Apache Subversion (SVN), a popular Version Control System (VCS), by incorporating&nbsp;commit signatures that provide integrity and authenticity to the SVN repository. This will provide integrity, authenticity and accountability for repositories stored at untrusted servers.</p> <p>&nbsp;</p> <p><strong>3)&nbsp;Cloud Computing Workshop for Teachers (CCWT):</strong></p> <p>We organized at NJIT a professional development workshop for high school teachers.&nbsp;The workshop exposed high school teachers to the concept of Cloud Computing and the technologies associated with it, from the perspective of using cloud technologies to improve the instructional process. The teachers were then asked to select a lesson taught in their classroom and to write a revised lesson plan based on cloud computing integration and standards-based lesson planning.</p><br> <p>            Last Modified: 12/29/2017<br>      Modified by: Reza&nbsp;Curtmola</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main research goal of this project is to create a framework that provides strong integrity, availability and reliability guarantees for long-term storage when data is outsourced to a cloud storage provider (CSP). Behind this seemingly simple goal there are complexities and subtleties that stem from several constraints and requirements: CSPs cannot be trusted, long-term storage outsourcing exacerbates the short-term storage threats, and secure storage outsourcing has uniqueperformance demands in order to be practical. We rely on remote data integrity checking (RDIC) as the main mechanism to ensure thelong-term integrity, availability, and reliability of data outsourced to a distributed storage system.  Reliability in this context is a measure of whether a CSP is still able to provide the correct data upon request by the client. A client that initially stores data with a server (CSP), later checks that the server continues to store the same data that was originally stored. We are interested in protocols that allow a client to periodically challenge the server into proving data possession, i.e. , the ability to produce the client's original data in its entirety. We seek to achieve a data possession guarantee, which implies both the integrity and the availability of the data stored at an untrusted server: The server possesses the same original data (integrity) and can prove it has the ability to produce this data at the moment of the challenge (availability). Such a guarantee will empower data owners to maintain control over how their data is stored and managed. It will also provide data owners with means to assess the risk of outsourcing storage and will increase the transparency of CSPs.  The novel outcomes of this project are:  1) New Remote Data Integrity Checking (RDIC) protocols that substantially improve the guarantees, functionality, and performance when managing data stored at untrusted cloud storage providers (CSPs). This includes:  - extending the RDIC guarantee from a single-server to a more realistic multiple-server setting,  - handling arbitrary amounts of data corruption,   - minimizing the data owner?s involvement in the repair phase over the lifetime of a distributed storage system,  - reconcilig replication with deduplication of data, while providing transparency to data owners.  As a result, RDIC can fully realize our vision of outsourcing both the storage and management of data. Our new RDIC protocols provide important functionality for remote data integrity checking that overcomes limitations of previous RDIC protocols and improves the usability and deployability of RDIC protocols for existing cloud storage infrastructures. By designing remote data integrity checking schemes that support both replication and transparency, can ensure data reliability while enabling a new pricing model which takes into account the level of deduplication of the data: The more users store the same piece of data, the lower each individual user gets charged for storing that piece of data. This can provide significant savings for clients, thus lowering the costs of storing data in the cloud. By allowing the storage providers to preserve the remote data integrity auditing capabilities even when data suffers transformations while in storage, we reduce the cost of managing the data stored at these providers.     2) Improved Security of Version Control Systems:  -  We have developed Auditable Version Control Systems (AVCS), which are version control systems (VCS) designed to function under an adversarial setting. We proposed RDC-AVCS, an AVCS scheme for skip delta-based VCS systems, which relies on RDIC mechanisms to ensure all the versions of a file are retrievable from the untrusted VCS server over time. By providing an efficient solution which is optimized for real-world VCS systems, RDC-AVCS improves the usability and deployability of RDIC for existing VCS systems.  - We have improved the security of Apache Subversion (SVN), a popular Version Control System (VCS), by incorporating commit signatures that provide integrity and authenticity to the SVN repository. This will provide integrity, authenticity and accountability for repositories stored at untrusted servers.     3) Cloud Computing Workshop for Teachers (CCWT):  We organized at NJIT a professional development workshop for high school teachers. The workshop exposed high school teachers to the concept of Cloud Computing and the technologies associated with it, from the perspective of using cloud technologies to improve the instructional process. The teachers were then asked to select a lesson taught in their classroom and to write a revised lesson plan based on cloud computing integration and standards-based lesson planning.       Last Modified: 12/29/2017       Submitted by: Reza Curtmola]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
