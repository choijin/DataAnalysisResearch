<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Crossroads of Information Theory and Computer Science:  Analytic Algorithmics, Combinatorics, and Information Theory</AwardTitle>
<AwardEffectiveDate>07/01/2005</AwardEffectiveDate>
<AwardExpirationDate>06/30/2009</AwardExpirationDate>
<AwardAmount>241423</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William H Tranter</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The interplay between information theory (IT) and computer science (CS)&lt;br/&gt;dates back to the founding father of information theory, Claude E.&lt;br/&gt;Shannon. Ever since Shannon's work on both information theory and&lt;br/&gt;computer science, the research in the interplay between IT and CS has&lt;br/&gt;continued and expanded in many exciting ways.  In 2003 the first NSF&lt;br/&gt;sponsored Workshop on the IT and CS Interface was held in Chicago,&lt;br/&gt;while in 2004 a graduate course on analytic methods in information&lt;br/&gt;theory and analysis of algorithms was organized at MSRI, Berkeley.  We&lt;br/&gt;build on this momentum and propose to work on  problems of information&lt;br/&gt;theory, combinatorics, and analysis of algorithms.  Following Knuth's&lt;br/&gt;and Hadamard's precept, we study such problems using techniques of&lt;br/&gt;complex analysis.  This program, which applies complex-analytic tools&lt;br/&gt;to information theory, constitutes ``analytic information theory''.&lt;br/&gt;&lt;br/&gt;This research is focused on some facets of source coding, such as the&lt;br/&gt;redundancy rate problem, method of types, entropy evaluation, channel&lt;br/&gt;capacity, and joint channel-source coding.  The redundancy rate problem&lt;br/&gt;for a class of sources is the determination of how far the actual code&lt;br/&gt;length exceeds the optimal (ideal) code length, while the method of&lt;br/&gt;types is a powerful technique in information theory, large deviations,&lt;br/&gt;and analysis of algorithms.  It is argued that counting types can be&lt;br/&gt;accomplished efficiently by enumerating Eulerian paths (Markov types)&lt;br/&gt;or binary trees with a given path length (universal types). Likewise,&lt;br/&gt;analysis of the redundancy rate problem for memoryless and Markov&lt;br/&gt;sources leads us to interesting generating functions such as tree&lt;br/&gt;generating functions (e.g., arising in counting labeled rooted trees),&lt;br/&gt;which  are studied extensively in computer science.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/01/2005</MinAmdLetterDate>
<MaxAmdLetterDate>07/01/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0513636</AwardID>
<Investigator>
<FirstName>Wojciech</FirstName>
<LastName>Szpankowski</LastName>
<EmailAddress>spa@cs.purdue.edu</EmailAddress>
<StartDate>07/01/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7351</Code>
<Text>THEORETICAL FOUNDATIONS (TF)</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
