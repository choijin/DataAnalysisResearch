<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Model Probability Planning for Mobile Robots</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2006</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>480000.00</AwardTotalIntnAmount>
<AwardAmount>480000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>jeffrey trinkle</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Abstract for Proposal # 0546467&lt;br/&gt;&lt;br/&gt;Model-Probability Planning for Mobile Robots&lt;br/&gt;&lt;br/&gt;Robots operating in natural, dynamic domains depend on the ability to make decisions without perfect prior knowledge of the world. Robots instead use sensor data to infer a model of the world (e.g., a map) and then make decisions with respect to this map. Typically, the process of learning the map is separated from planning, simplifying both problems. In natural, populated environments, however, building a complete and accurate map becomes increasingly difficult and motion planning can become brittle. For example, a robot grasping an object on a table should not depend on having an exact and precise geometric model of the table and object.  In contrast, the robot should be able to learn the model as it goes, starting with a simple probabilistic model of the table top and object. Then, to reduce uncertainty, the robot should gather new data about the world, stopping only to take more precise measurements of the world to improve its map when doing so is predicted to lead to better overall performance. The objective of the proposed research program is to develop robust autonomy in robotics by integrating mapping and planning in a tractable manner. The approach will be to develop planning systems that operate in the space of model distributions. New techniques of modeling free and occupied space probabilistically must be developed to capture map uncertainty efficiently. Unlike conventional maps that predict sensor error, the resulting maps will be designed to maximize the predicted planner performance.  Secondly, motion planning algorithms must be developed that can plan with respect to a range of possible maps, generating motion plans that incorporate exploration and resolve ambiguities. The proposed scientific activity will create a new generation of more robust and capable autonomous systems through a combined research and educational program to study integrated learning and decision making. The educational program will introduce a generation of students to new principles of planning under uncertainty and mobile manipulation. The proposed research is vital to the long-term viability of mobile robots operating autonomously in complex, dynamic environments. For example, mobile manipulators have great potential in a number of assistive domains such as health care and manufacturing, but reliable operation in populated environments will require a solid understanding of decision making under uncertainty through integrated learning and planning.  This research will also lead to robust autonomy in unmanned underwater, air and space vehicles.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/13/2006</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0546467</AwardID>
<Investigator>
<FirstName>Nicholas</FirstName>
<LastName>Roy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nicholas Roy</PI_FULL_NAME>
<EmailAddress>nickroy@mit.edu</EmailAddress>
<PI_PHON>6172532517</PI_PHON>
<NSF_ID>000226870</NSF_ID>
<StartDate>04/13/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2006~277500</FUND_OBLG>
<FUND_OBLG>2009~99500</FUND_OBLG>
<FUND_OBLG>2010~103000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="section"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>Robotics has seen tremendous growth recently in the deployment of autonomous systems, and many systems owe their success to principled reasoning about uncertainty. For example, mapping algorithms using statistical inference&nbsp;</span>allow a robot to collect sensor data (such as laser scans or camera images) and assemble this data into a globally consistent map of the world. The map can then be used both for motion planning and position tracking in environments not supported by global positioning systems (such as GPS). During planning and decision making, however, most robots only reason about uncertainty of the robot state, and not about the uncertainty in the map of the world. Probabilistic state estimation algorithms can compensate for sensor errors, and robust control can compensate for unknown disturbances and errors in the position estimate, but the underlying assumption of most robotic planners is that the map of the world is correct and complete.&nbsp;</p> </div> </div> </div> <p><span>The major goals of the project were to develop robust autonomy in robotics by integrating modelling and planning in a tractable manner. For example, w</span>e developed an algorithm for learning models of object geometry for the purposes of manipulation; these models capture both non-rigid deformations of known objects and variability of objects within a known class. Given a single image of partially occluded objects, the model could be used to recognize objects based on the visible portion of each object contour, and then estimate the complete geometry of the object to allow the robot to plan a proper grasp of the object.</p> <p>As another example, we showed that planning in belief space can be done efficiently for linear (or linearized) Gaussian systems, which is a convential model for mobile robots and UAVs. We&nbsp;showed how a state-of-the-art motion planning algorithm called the Probabilistic Roadmap could be extended to incorporate navigation sensing uncertainty into an algorithm called the Belief Roadmap (BRM), and showed that the BRM can compute plans substantially faster than conventional strategies for planning with uncertain sensors. We demonstrated the BRM path-planning algorithm on the helicopter, navigating in an indoor environment with a laser range-finder and avoiding flight plans that would cause the vehicle to lose its position fix due to sensor limitations. We&nbsp;also showed that the BRM planning algorithm can be used as an exploration planner, and demonstrated a quadrotor helicopter autonomously mapping a large environment, specifically the MIT Stata Center.&nbsp;</p> <p>Finally, we explored how to apply our techniques to semantic mapping and exploration, specifically how to selectively gather additional information about possible objects or semantic features in the world to build a map that is labelled with human-interpretable symbols, such as locations of objects or room types. We showed that a motion planning algorithm&nbsp;that models the uncertainty of the object and scene recognition process, can generate trajectories that move through specific locations that maximize the accuracy of the object and scene detectors. We developed an online, anytime planning framework enabling active exploration, while navigating to an ultimate destination, and semantic mapping based on noisy observations from an off-&shy;the&shy;-shelf object detector.</p> </div> </div> </div> </div><br> <p>            Last Modified: 03/09/2014<br>      Modified by: Nicholas&nbsp;Roy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[        Robotics has seen tremendous growth recently in the deployment of autonomous systems, and many systems owe their success to principled reasoning about uncertainty. For example, mapping algorithms using statistical inference allow a robot to collect sensor data (such as laser scans or camera images) and assemble this data into a globally consistent map of the world. The map can then be used both for motion planning and position tracking in environments not supported by global positioning systems (such as GPS). During planning and decision making, however, most robots only reason about uncertainty of the robot state, and not about the uncertainty in the map of the world. Probabilistic state estimation algorithms can compensate for sensor errors, and robust control can compensate for unknown disturbances and errors in the position estimate, but the underlying assumption of most robotic planners is that the map of the world is correct and complete.      The major goals of the project were to develop robust autonomy in robotics by integrating modelling and planning in a tractable manner. For example, we developed an algorithm for learning models of object geometry for the purposes of manipulation; these models capture both non-rigid deformations of known objects and variability of objects within a known class. Given a single image of partially occluded objects, the model could be used to recognize objects based on the visible portion of each object contour, and then estimate the complete geometry of the object to allow the robot to plan a proper grasp of the object.  As another example, we showed that planning in belief space can be done efficiently for linear (or linearized) Gaussian systems, which is a convential model for mobile robots and UAVs. We showed how a state-of-the-art motion planning algorithm called the Probabilistic Roadmap could be extended to incorporate navigation sensing uncertainty into an algorithm called the Belief Roadmap (BRM), and showed that the BRM can compute plans substantially faster than conventional strategies for planning with uncertain sensors. We demonstrated the BRM path-planning algorithm on the helicopter, navigating in an indoor environment with a laser range-finder and avoiding flight plans that would cause the vehicle to lose its position fix due to sensor limitations. We also showed that the BRM planning algorithm can be used as an exploration planner, and demonstrated a quadrotor helicopter autonomously mapping a large environment, specifically the MIT Stata Center.   Finally, we explored how to apply our techniques to semantic mapping and exploration, specifically how to selectively gather additional information about possible objects or semantic features in the world to build a map that is labelled with human-interpretable symbols, such as locations of objects or room types. We showed that a motion planning algorithm that models the uncertainty of the object and scene recognition process, can generate trajectories that move through specific locations that maximize the accuracy of the object and scene detectors. We developed an online, anytime planning framework enabling active exploration, while navigating to an ultimate destination, and semantic mapping based on noisy observations from an off-&shy;the&shy;-shelf object detector.           Last Modified: 03/09/2014       Submitted by: Nicholas Roy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
