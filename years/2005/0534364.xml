<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:    A Novel User Interface for Operating an Assistive Robot Arm in Unstructured Environments</AwardTitle>
<AwardEffectiveDate>12/01/2005</AwardEffectiveDate>
<AwardExpirationDate>11/30/2010</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>167730</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>In this project the PIs will design, develop, and clinically test a vision-based user interface for enhancing the efficacy of wheelchair mounted assistive robot arms in unstructured environments.  The target population is wheelchair bound individuals with limited upper extremity movement, such as patients diagnosed with Cerebral Palsy, ALS, Poliomyelitis, Multiple Sclerosis, Spinal Cord Injury, Muscular Dystrophy, and similar conditions that affect use of the upper limbs.  The goal is to allow these people to function independently with comfort and speed in a variety of unstructured environments such as a grocery store, a living room, or an office.  The innovation in this project that sets it apart from existing approaches is the segregation of robot motion into gross and fine components instead of unnatural joint or Cartesian motion as is currently the norm.  To transform their bold vision into reality, the PIs will: develop a gross motion human-robot interface utilizing computer vision techniques and the human in the loop; utilize computer image processing algorithms for implementing a real-time robust feature identifier that is able to suggest to the user areas of interest, using computer vision techniques to segment by color, depth and other criteria; effect fine motion of the robot end-effector to facilitate pick-and-place tasks via fusion of geometric ideas from vision and adaptive control; develop a working prototype through unification of HRI, sensing, and control algorithms; and demonstrate benchmark activities of daily living tasks for wheelchair bound individuals with upper extremity impairments by tapping into the human resources available at Good Shepherd Rehabilitation Hospital located in Pennsylvania's Lehigh Valley.  &lt;br/&gt;&lt;br/&gt;Broader Impacts:  The design of an enhanced functionality wheelchair robot will be a major leap toward rehabilitation of a broad segment of society whose members otherwise have only limited access to resources and opportunity.  The PIs expect their approach to be directly relevant to any mobile device with on-board vision and where one can take advantage of the human in the loop, and thus to provide a new model of human-robot interaction for assistive technology.  Interaction methods developed will be adaptable to a wide range of access devices, ranging from single switch scanning to sip-and-puff to a joystick.  Moreover, the PIs expect that the fusion of vision and nonlinear control demonstrated in this project will advance the theory and applicability of computer vision and visual servoing.</AbstractNarration>
<MinAmdLetterDate>11/23/2005</MinAmdLetterDate>
<MaxAmdLetterDate>01/27/2010</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0534364</AwardID>
<Investigator>
<FirstName>Holly</FirstName>
<LastName>Yanco</LastName>
<EmailAddress>holly@cs.uml.edu</EmailAddress>
<StartDate>11/23/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Lowell Research Foundation</Name>
<CityName>Lowell</CityName>
<ZipCode>018543692</ZipCode>
<PhoneNumber>9789344723</PhoneNumber>
<StreetAddress>600 Suffolk Street</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>6846</Code>
<Text>UNIVERSAL ACCESS</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7496</Code>
<Text>COLLABORATIVE SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
