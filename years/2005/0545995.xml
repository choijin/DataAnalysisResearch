<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Power-Performance Considerations of Thread-level Parallelism in On-chip Multicore Architectures</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2006</AwardEffectiveDate>
<AwardExpirationDate>05/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>359844</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hong Jiang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>As the microprocessor industry moves toward multicore solutions (several processor cores on a single chip), performance growth on these inherently power-constrained platforms will increasingly rely upon their ability to support thread-level parallelism efficiently. The goal of the research project in this CAREER proposal is to develop the necessary insights for the successful design of mechanisms that can address the unique power-performance opportunities and challenges of running parallel applications on multicore chip architectures. We explore power-aware control of parallelism in such architectures by combining information about the application's parallel behavior, the operating constraints, and the chip's support for voltage/frequency scaling and other mechanisms for power management. Integral to this CAREER proposal is a broad educational plan with specific goals at several education levels. We also provide concrete initiatives to promote engineering among high-school girls and underrepresented minorities, and to mentor them throughout their college years. &lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/06/2006</MinAmdLetterDate>
<MaxAmdLetterDate>07/14/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0545995</AwardID>
<Investigator>
<FirstName>Jose</FirstName>
<LastName>Martinez</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jose F Martinez</PI_FULL_NAME>
<EmailAddress>martinez@cornell.edu</EmailAddress>
<PI_PHON>6072551874</PI_PHON>
<NSF_ID>000101501</NSF_ID>
<StartDate>07/06/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramElement>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2006~80000</FUND_OBLG>
<FUND_OBLG>2007~60000</FUND_OBLG>
<FUND_OBLG>2008~60000</FUND_OBLG>
<FUND_OBLG>2009~50000</FUND_OBLG>
<FUND_OBLG>2010~109844</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the last decade, improving power and energy consumption of computer systems has become a top priority for microprocessor and computer engineers. Researchers and engineers realized that, unless drastic measures were taken to address the unrelenting increase in power consumption, soon it would be impossible to make computers with cost-effective manufacturing and packaging technologies--not to mention the energy waste. The simultaneous drive toward multicore microprocessors, which house multiple processing elements in a single chip, has posed very interesting opportunities and challenges to optimizing parallel program processing on multiprocessors in general, and on multicore chips in particular, under varying power, performance, and application characteristics. In this project we set out to investigate this complex, multi-dimensional problem, and answer the fundamental question: <strong>What are effective technologies and mechanisms to deliver fast execution of parallel programs at energy-efficient operating points in the computer systems of the future?</strong></p> <p><br />One of the major hurdles toward the scalability of multicore architectures is the power-performance scalability of its interconnect that allows processing elements to cooperatively work together. Early on in this project, we conducted a pioneer study on the technological challenges, design trade-offs, and overall impact of utilizing photonics (as opposed to electronics) to implement a hybrid optical-electrical, bus-based multicore processor [Kirman et al., MICRO '06] . Our results highlighted the favorable power-performance trade-off that photonic technology may offer. This work was selected to 2007 IEEE Micro Top Picks in Computer Architecture.</p> <p>Later we developed an all-optical approach to constructing data networks on chip that relies heavily on power-efficient passive components [Kirman and Martinez, ASPLOS'10] . We employ passive optical wavelength routers, whose routing pattern is set at design time, which allows for area and power optimizations not generally available to solutions that use dynamic routing. Compared to prior proposals, our solution is significantly more power efficient at a similar level of performance.</p> <p>A related problem is the fact that, as aggressive CMOS scaling puts more and more (smaller) circuitry on a chip, it will make future chip multiprocessors increasingly susceptible to operating faults. Typically, dual modular redundancy (DMR) solutions address faults by statically binding pairs of adjacent processor cores via dedicated communication channels and buffers, so they can check each other's (redundant) execution at speed. We believe static binding is too inflexible, and it may put pressure on thermal management, since DMR pairs running code with similar thermal characteristics are placed next to each other. We explored a flexible architecture capable of executing sequential and parallel application reliably by pairing arbitrary cores &nbsp;to verify each other's execution [LaFrieda et al., DSN'07]. This results in hardware that degrades half as fast as mechanisms that rely on static &nbsp;binding, and we believe it allows for more flexible management of thermal density and variation-induced hardware inefficiencies.</p> <p><br />We have also looked at the problem of efficient allocation of a chip's power budget among processing elements, in conjunction with other shared on-chip resources [Bitirgen et al., MICRO'08]. Although several proposals that address the management of a single microarchitectural resource have been published in the literature, effective coordinated management of multiple interacting resources on CMPs remains an open problem. In that work, we proposed a framework that manages multiple shared CMP resources in a coordinated fashion to enforce higher-level performance objectives. We formulate global resource allocation as a <em>mach...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the last decade, improving power and energy consumption of computer systems has become a top priority for microprocessor and computer engineers. Researchers and engineers realized that, unless drastic measures were taken to address the unrelenting increase in power consumption, soon it would be impossible to make computers with cost-effective manufacturing and packaging technologies--not to mention the energy waste. The simultaneous drive toward multicore microprocessors, which house multiple processing elements in a single chip, has posed very interesting opportunities and challenges to optimizing parallel program processing on multiprocessors in general, and on multicore chips in particular, under varying power, performance, and application characteristics. In this project we set out to investigate this complex, multi-dimensional problem, and answer the fundamental question: What are effective technologies and mechanisms to deliver fast execution of parallel programs at energy-efficient operating points in the computer systems of the future?   One of the major hurdles toward the scalability of multicore architectures is the power-performance scalability of its interconnect that allows processing elements to cooperatively work together. Early on in this project, we conducted a pioneer study on the technological challenges, design trade-offs, and overall impact of utilizing photonics (as opposed to electronics) to implement a hybrid optical-electrical, bus-based multicore processor [Kirman et al., MICRO '06] . Our results highlighted the favorable power-performance trade-off that photonic technology may offer. This work was selected to 2007 IEEE Micro Top Picks in Computer Architecture.  Later we developed an all-optical approach to constructing data networks on chip that relies heavily on power-efficient passive components [Kirman and Martinez, ASPLOS'10] . We employ passive optical wavelength routers, whose routing pattern is set at design time, which allows for area and power optimizations not generally available to solutions that use dynamic routing. Compared to prior proposals, our solution is significantly more power efficient at a similar level of performance.  A related problem is the fact that, as aggressive CMOS scaling puts more and more (smaller) circuitry on a chip, it will make future chip multiprocessors increasingly susceptible to operating faults. Typically, dual modular redundancy (DMR) solutions address faults by statically binding pairs of adjacent processor cores via dedicated communication channels and buffers, so they can check each other's (redundant) execution at speed. We believe static binding is too inflexible, and it may put pressure on thermal management, since DMR pairs running code with similar thermal characteristics are placed next to each other. We explored a flexible architecture capable of executing sequential and parallel application reliably by pairing arbitrary cores  to verify each other's execution [LaFrieda et al., DSN'07]. This results in hardware that degrades half as fast as mechanisms that rely on static  binding, and we believe it allows for more flexible management of thermal density and variation-induced hardware inefficiencies.   We have also looked at the problem of efficient allocation of a chip's power budget among processing elements, in conjunction with other shared on-chip resources [Bitirgen et al., MICRO'08]. Although several proposals that address the management of a single microarchitectural resource have been published in the literature, effective coordinated management of multiple interacting resources on CMPs remains an open problem. In that work, we proposed a framework that manages multiple shared CMP resources in a coordinated fashion to enforce higher-level performance objectives. We formulate global resource allocation as a machine learning problem, using artificial neural networks. At runtime, our resource management scheme monitors the execution of ea...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
