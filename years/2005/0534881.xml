<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Learning from Interdependent Examples</AwardTitle>
<AwardEffectiveDate>11/01/2005</AwardEffectiveDate>
<AwardExpirationDate>10/31/2009</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>299925</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Douglas H. Fisher</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project investigates machine learning that takes into account dependencies among examples. In contrast, most machine learning methods assume that all examples are independent and identically distributed ("i.i.d."). Domains where this assumption does not hold are widespread -- from the WWW, where the relevance of a page affects the relevance of linked pages, to molecular biology, where a protein's properties determine its role in metabolic networks. By lifting the i.i.d. assumption, this project will develop learning algorithms that can exploit the information each example carries about the others. This has the potential to improve predictive performance and broaden the range of phenomena that can be effectively modeled. However, it also greatly increases the complexity of learning. This project focuses on developing techniques to make non-i.i.d. learning practical, including: (1) feature search guided by known relations among examples; (2) aggregation of variable quantities of relevant information back into examples of fixed length; (3) increasing the efficiency of learning and inference by performing them at multiple levels of abstraction; and (4) using relational domain knowledge to constrain the search space and combat overfitting. The project will apply the resulting algorithms to modeling the WWW and scientific citation networks. The broader impact of this project includes extension of machine learning to domains, within and beyond computer science, where interdependencies among examples cannot be ignored (e.g., the WWW, social networks, ubiquitous computing). It will also create a publicly available repository of data sets with interdependent examples. The project involves undergraduates, particularly those from underrepresented groups.</AbstractNarration>
<MinAmdLetterDate>10/18/2005</MinAmdLetterDate>
<MaxAmdLetterDate>10/19/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0534881</AwardID>
<Investigator>
<FirstName>Pedro</FirstName>
<LastName>Domingos</LastName>
<EmailAddress>pedrod@cs.washington.edu</EmailAddress>
<StartDate>10/18/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramElement>
<ProgramReference>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
