<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>The Neural Representation of Object Part Configuration</AwardTitle>
<AwardEffectiveDate>09/01/2005</AwardEffectiveDate>
<AwardExpirationDate>08/31/2008</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>494988</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Stacia Friedman-Hill</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Many of our behaviors depend on the ability to rapidly recognize objects in the real world.  Yet, as effortless as visual object perception seems to be, even for young infants rapidly learning the names of surrounding objects, this capability eludes the most sophisticated computers and devices.  In fact, many details of this process remain unknown despite decades of research progress in neuroscience and cognitive psychology.  Understanding how the human brain, which is a physical device that performs computations, recognizes objects is therefore a useful and important endeavor.  Recent advances in brain imaging technology, especially functional magnetic resonance imaging (fMRI), have now made it possible to safely examine the brain mechanisms in everyday adult human observers.  One basic question concerns how neurons represent complex visual objects that typically consist of distinct parts arrayed in a particular configuration.  For example, a bicycle has wheels, a frame, and handlebars arranged in a certain way that enables people, such as car drivers, to quickly recognize one on the road.  With support from the National Science Foundation, Dr. Yaoda Xu and Dr. Marvin Chun are using fMRI to probe detailed brain activity while observers perform visual recognition tasks in the MR scanner.  In particular, this project focuses on how specific object parts and part configurations are represented and distinguished from others. This knowledge will advance our understanding of how the human brain recognizes visual objects.&lt;br/&gt;&lt;br/&gt;The work should have significant implications for theories of visual object perception and especially for understanding the impact of brain damage on visual recognition abilities (agnosias).  Furthermore, an understanding of how the brain recognizes objects should facilitate the development of sophisticated computer systems that can recognize and learn visual objects in our environment.  During the course of this project, student collaborators will gain training in advanced functional brain imaging technologies and experimental methods to study human behavior.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/19/2005</MinAmdLetterDate>
<MaxAmdLetterDate>09/22/2006</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0518138</AwardID>
<Investigator>
<FirstName>Marvin</FirstName>
<LastName>Chun</LastName>
<EmailAddress>marvin.chun@yale.edu</EmailAddress>
<StartDate>08/19/2005</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yaoda</FirstName>
<LastName>Xu</LastName>
<EmailAddress>yaoda.xu@yale.edu</EmailAddress>
<StartDate>08/19/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>New Haven</CityName>
<ZipCode>065208327</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>Office of Sponsored Projects</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
