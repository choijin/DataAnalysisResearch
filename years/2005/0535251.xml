<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Machine learning algorithms for analyzing auditory scenes with multiple sound sources</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2006</AwardEffectiveDate>
<AwardExpirationDate>12/31/2009</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>375000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;&lt;br/&gt;Computer algorithms that analyze auditory scenes and extract individual sound sources would have a strong impact in several domains. For example, to facilitate natural interaction with computing devices by voice, an automatic speech recognition system must be able to focus on the voice of the person speaking to it and ignore sounds from all other sources. A hearing device must perform a similar task to allow a hearing impaired person conduct a conversation in a noisy, multiple source environment. Building on recent advances in the fields of machine learning and signal processing, we are developing sophisticated adaptive algorithms for analyzing auditory scenes with multiple sound sources. Our algorithms are based on probabilistic modeling of different sound sources and of the manner in which they overlap each other and distorted by reverberation and background noise. We use advanced recent techniques for inferring our models from sound data captured by a microphone array, separating those data into individual sources, and automatically determining the type of each source present and its location. Moreover, by reconstructing the clean signal of individual sound sources, we dramatically enhance the accuracy of automatic speech recognition for human speakers in multiple source environments. To facilitate the development and evaluation of our algorithms, and also to encourage competition between other research groups ultimately resulting in improved techniques, we collect a large dataset of multiple source auditory scenes, and make it publicly available on a dedicated website.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>01/18/2006</MinAmdLetterDate>
<MaxAmdLetterDate>04/01/2008</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0535251</AwardID>
<Investigator>
<FirstName>Terrence</FirstName>
<LastName>Sejnowski</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Terrence J Sejnowski</PI_FULL_NAME>
<EmailAddress>terry@salk.edu</EmailAddress>
<PI_PHON>8584534100</PI_PHON>
<NSF_ID>000273216</NSF_ID>
<StartDate>04/01/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Te-Won</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Te-Won Lee</PI_FULL_NAME>
<EmailAddress>tewon@ucsd.edu</EmailAddress>
<PI_PHON>8585349662</PI_PHON>
<NSF_ID>000486426</NSF_ID>
<StartDate>01/18/2006</StartDate>
<EndDate>04/01/2008</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<CountyName>SAN DIEGO</CountyName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<CountyName>SAN DIEGO</CountyName>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress><![CDATA[Office of Contract &amp; Grant A]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2006~375000</FUND_OBLG>
</Award>
</rootTag>
