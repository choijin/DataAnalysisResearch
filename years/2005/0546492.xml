<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Methodologies and Tools for Large Real-Time Concurrent System Verification</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2006</AwardEffectiveDate>
<AwardExpirationDate>02/29/2012</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>412000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
<PO_EMAI>sabasu@nsf.gov</PO_EMAI>
<PO_PHON>7032927843</PO_PHON>
</ProgramOfficer>
<AbstractNarration>ABSTRACT&lt;br/&gt;0546492&lt;br/&gt;Zheng, Hao&lt;br/&gt;U of South Florida&lt;br/&gt;&lt;br/&gt;Biological bugs can make people ill, or even endanger people's life. Similarly, logical bugs can make concurrent systems unreliable, or even fail. In today's concurrent system designs, finding and fixing logical bugs early is of the highest priority because it is very costly when bugs are found late in the design stage. Bugs left undetected in systems can cause huge losses to the economy and human society.  The correct operation of systems must be guaranteed at any cost for safety critical applications that can be found in nuclear power plants and airplane flight control systems. However, making sure complex systems work correctly is very difficult because both functional complexity and density of systems are growing exponentially, imposing unprecedented challenges on verification. Among various verification technologies, model checking, a verification approach based on formal methods, has unique advantages because it is fully automated and can produce counter-examples for errors in systems to help debugging. Because of very high verification coverage, it can find bugs hidden very deeply. However, capabilities and robustness of model checking cannot keep up with the exponential growth of concurrent system complexity. It imposes a great burden on the model checking users to have deep understanding of the underlying verification algorithms and heuristics for effective use of the tools, thus limiting the widespread acceptance of model checking.&lt;br/&gt;&lt;br/&gt;This research addresses the challenges to and limitations of real-time concurrent system verification. In this research, the investigator studies various approaches to handle the complexity issue inherent in model checking, and develops methods and tools that enable model checking to be applicable to large real-time concurrent systems.  These methods and tools are completely transparent to users of model checking so that they can be used in the same way as simulation. The intellectual merit of this research lies in a set of novel methods and algorithms to enhance the capacity and robustness of model checking for real-time concurrent system verification based on composition, hierarchy, and abstraction. Furthermore, design and verification are viewed as being interdependent, and a design-for-verification method with a new framework of high abstraction level modeling and refinement is developed. Successful completion of this research project will have broader impact on significant reduction in verification cost in the current system design process with improved capability of model checking, thus lowering the overall design cost of the final products. In addition, enabling model checking to be more accessible leads to dramatic improvements on product quality and system security, and reduces the losses due to the holes in products and systems. The integrated education plan of this research develops a new learning framework focusing on increasing students' learning and thinking skills, and integrating research with education. In addition, K-12 and underrepresented students will be involved in the proposed research through NSF REU and RET programs.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/14/2006</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0546492</AwardID>
<Investigator>
<FirstName>Hao</FirstName>
<LastName>Zheng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hao Zheng</PI_FULL_NAME>
<EmailAddress>zheng@cse.usf.edu</EmailAddress>
<PI_PHON>8139744757</PI_PHON>
<NSF_ID>000493348</NSF_ID>
<StartDate>03/14/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of South Florida</Name>
<CityName>Tampa</CityName>
<ZipCode>336172008</ZipCode>
<PhoneNumber>8139742897</PhoneNumber>
<StreetAddress>4019 E. Fowler Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 100]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL14</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>069687242</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTH FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>069687242</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of South Florida]]></Name>
<CityName>Tampa</CityName>
<StateCode>FL</StateCode>
<ZipCode>336172008</ZipCode>
<StreetAddress><![CDATA[4019 E. Fowler Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL14</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramElement>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2006~75963</FUND_OBLG>
<FUND_OBLG>2007~78090</FUND_OBLG>
<FUND_OBLG>2008~80272</FUND_OBLG>
<FUND_OBLG>2009~82511</FUND_OBLG>
<FUND_OBLG>2010~95164</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>As computing devices used more extensively in various safety critical applications, ensuring their correct operations has the highest priority. Otherwise, the well-being of our society and our lives may be at risk. Model checking is a formal verification approach, unlike the traditional testing based approach, which verifies a computing system based on rigious mathematical reasoning. The systems passing formal model checking are proved to be correct. &nbsp;</p> <p>However, model checking is typically a very difficult problem to solve due to its high complexity, therefore it is often applied to systems of limited sizes. This is the main reason why model checking is not used widely as testing based approaches. &nbsp;On the other hand, the computing systems are getting more and more sophisticated due to high demand on computational intelligence for wide and smart sensing and control in many different types of applications such as flight control, smart grid, smart buildings, transportation systems, medical systems, etc. The gap between computational systems with ever increasing complexity and the verification technologies of limited capabilities prevents these critical systems from being thoroughly checked and verified, and this potentially imposes serious dangers to our safety and security if defects and unexpected behavior are slipped into the systems after deployment..</p> <p>To address the complexity problem of model checking in this project, reduction and divide-and-conquer are regarded as essential. Reduction refers to removing unnecessary information from the systems under verification, while divide-and-conquer refers to approaches that decompose a large systems into a set of smaller components, each of which is verified individually, and then the correctness of the entire system is derived from the results of the local verification.&nbsp;</p> <p>The research results from this projects are included in an integrated framework where a system can be checked and verified as shown in the following steps.</p> <p>1. First, the system description is decomposed into components. This is fairly straightforward as most complex systems are naturally structured.</p> <p>2. A mathematical model, finite state machine (FSM) , is constructed for each component. This step is very important as the quality and complexity of FSM obtained in this step can critically affect the efficiency of the following steps. We developed a compositional construction method where the component FSMs are built by being gradually expanded with more information derived from the interface interactions between the individual components and the rest of the system.</p> <p>3. After the component FSMs are available, they need to be refined. This is because extra information may be introduced into these FSMs due to the loss of global behavior information of the entire systems, and this extra information in the component FSMs can cause a lot of false warnings to be produced. While false warnings are better then missing a real system defect, they can be annoying and cause distraction of verification engineers from the real problems. To avoid the false warnings as much as possible, the extra information in the component FSMs need to be removed. For this purpose, two efficient refinement methods are developed.</p> <p>4. The local verification in the above step works very well for properties defined locally on individual components. However, global properties such as deadlock freedom where a system does not get stuck have to be checked on the entire systems. This is infeasible as the complexity of a large and complex system is typically prohibitively high. To address this problem, a gradual construction process is developed where the component FSMs are composed together one at a time. To control the complexity, a number of reduction approaches have been developed to remove unnecessary information from these componen...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ As computing devices used more extensively in various safety critical applications, ensuring their correct operations has the highest priority. Otherwise, the well-being of our society and our lives may be at risk. Model checking is a formal verification approach, unlike the traditional testing based approach, which verifies a computing system based on rigious mathematical reasoning. The systems passing formal model checking are proved to be correct.    However, model checking is typically a very difficult problem to solve due to its high complexity, therefore it is often applied to systems of limited sizes. This is the main reason why model checking is not used widely as testing based approaches.  On the other hand, the computing systems are getting more and more sophisticated due to high demand on computational intelligence for wide and smart sensing and control in many different types of applications such as flight control, smart grid, smart buildings, transportation systems, medical systems, etc. The gap between computational systems with ever increasing complexity and the verification technologies of limited capabilities prevents these critical systems from being thoroughly checked and verified, and this potentially imposes serious dangers to our safety and security if defects and unexpected behavior are slipped into the systems after deployment..  To address the complexity problem of model checking in this project, reduction and divide-and-conquer are regarded as essential. Reduction refers to removing unnecessary information from the systems under verification, while divide-and-conquer refers to approaches that decompose a large systems into a set of smaller components, each of which is verified individually, and then the correctness of the entire system is derived from the results of the local verification.   The research results from this projects are included in an integrated framework where a system can be checked and verified as shown in the following steps.  1. First, the system description is decomposed into components. This is fairly straightforward as most complex systems are naturally structured.  2. A mathematical model, finite state machine (FSM) , is constructed for each component. This step is very important as the quality and complexity of FSM obtained in this step can critically affect the efficiency of the following steps. We developed a compositional construction method where the component FSMs are built by being gradually expanded with more information derived from the interface interactions between the individual components and the rest of the system.  3. After the component FSMs are available, they need to be refined. This is because extra information may be introduced into these FSMs due to the loss of global behavior information of the entire systems, and this extra information in the component FSMs can cause a lot of false warnings to be produced. While false warnings are better then missing a real system defect, they can be annoying and cause distraction of verification engineers from the real problems. To avoid the false warnings as much as possible, the extra information in the component FSMs need to be removed. For this purpose, two efficient refinement methods are developed.  4. The local verification in the above step works very well for properties defined locally on individual components. However, global properties such as deadlock freedom where a system does not get stuck have to be checked on the entire systems. This is infeasible as the complexity of a large and complex system is typically prohibitively high. To address this problem, a gradual construction process is developed where the component FSMs are composed together one at a time. To control the complexity, a number of reduction approaches have been developed to remove unnecessary information from these component FMSs before they are composed. This approach allows a very small FSM model to be produced for a very large system whe...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
