<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Neural Bases of Speech Perception in Human Auditory Cortex</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2005</AwardEffectiveDate>
<AwardExpirationDate>06/30/2010</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>795485</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lynne Bernstein</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Speech perception is one of our most important abilities - something that we have an innate ability &lt;br/&gt;for but nevertheless spend many years acquiring as children- and that is of the utmost&lt;br/&gt;importance for us in social interactions. It is also one of the abilities more commonly affected by strokes as well as by hearing loss. Speech perception is characterized by considerable flexibility and robustness - we can understand speakers in noisy environments, and we can cope with&lt;br/&gt;variations in the speaker's gender, accent, or mood, all of which affect the nature of the speech signal we need to decode. A better understanding of the neural basis of speech perception, thus, impacts on clinical issues such as recovery from aphasic stroke, as well as on educational neuroscience, inasmuch as the studies will have relevance for second language learning and the development of multilingual children. With support from the National Science Foundation, Dr. Josef Rauschecker seeks answers to understand the neural basis of speech perception. His studies will help to transfer knowledge gained from animal models of auditory perception toward the understanding of higher cognitive processes of speech and language perception in humans. The notions of hierarchical networks, processing streams, and higher-order computational maps have been used successfully in animal research on complex visual and auditory perception. Dr. Rauschecker will perform analogous investigations directly in humans using noninvasive,&lt;br/&gt;high-resolution functional magnetic resonance imaging (fMRI) to determine activation of auditory cortices by speech and speech-like sounds. Using high-field fMRI the studies will not only determine the location of cortical areas activated by natural and synthetic speech sounds, as opposed to other sounds with similar complexity, but also for the first time reveal detailed&lt;br/&gt;organizational principles of higher-order acoustic-phonetic feature maps within human auditory and language cortex. The studies will provide a wealth of new information in the under-researched field of higher auditory pathways in humans, as well as insight into general organizational principles of&lt;br/&gt;functional architecture in cortical processing.&lt;br/&gt;&lt;br/&gt;The broader impacts of this project include opportunities for hands-on research experience by undergraduate and graduate students in Cognitive Neuroscience. This direct immersion into ongoing research will lead to tighter integration of teaching and research. The funded project will&lt;br/&gt;enhance the infrastructure for research at Georgetown University and contribute to two formal training programs offered at GU. The project will strive to increase further the number of minority students at all levels. It will broadly disseminate results through publications and public databases&lt;br/&gt;to scientific as well as lay audiences, thus, enhancing scientific understanding by the public.</AbstractNarration>
<MinAmdLetterDate>07/29/2005</MinAmdLetterDate>
<MaxAmdLetterDate>04/22/2009</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0519127</AwardID>
<Investigator>
<FirstName>Josef</FirstName>
<LastName>Rauschecker</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Josef P Rauschecker</PI_FULL_NAME>
<EmailAddress>rauschej@georgetown.edu</EmailAddress>
<PI_PHON>2026878842</PI_PHON>
<NSF_ID>000233003</NSF_ID>
<StartDate>07/29/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgetown University</Name>
<CityName>Washington</CityName>
<ZipCode>200571789</ZipCode>
<PhoneNumber>2026250100</PhoneNumber>
<StreetAddress>37th &amp; O St N W</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049515844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGETOWN UNIVERSITY (THE)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049515844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgetown University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200571789</ZipCode>
<StreetAddress><![CDATA[37th &amp; O St N W]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0105</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2005~164952</FUND_OBLG>
<FUND_OBLG>2006~227720</FUND_OBLG>
<FUND_OBLG>2007~206020</FUND_OBLG>
<FUND_OBLG>2008~196793</FUND_OBLG>
</Award>
</rootTag>
