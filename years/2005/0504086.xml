<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SCI: TeraGrid Resource Partners</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2005</AwardEffectiveDate>
<AwardExpirationDate>07/31/2011</AwardExpirationDate>
<AwardTotalIntnAmount>3867944.00</AwardTotalIntnAmount>
<AwardAmount>3614244</AwardAmount>
<AwardInstrument>
<Value>Cooperative Agreement</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rudolf Eigenmann</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The Extensible Terascale Facility  (ETF) is the next stage in the evolution of NSF large-scale cyberinfrastructure for enabling high-end computational research. The ETF enables researchers to address the most challenging computational problems by utilizing the integrated resources, data collections, instruments, and visualization capabilities of nine resource partners.  On October 1, 2004, the ETF concluded a three-year construction effort to create this distributed environment, called the TeraGrid (TG), and we are now entering the production operations phase. &lt;br/&gt;&lt;br/&gt;The  TeraGrid  resource  partners  include:   the  University  of Chicago/Argonne  National  Laboratory,  the  San  Diego  Supercomputer  Center  at  the  University  of California  San  Diego,  the  Texas  Advanced  Computing  Center  at  the  University  of  Texas  Austin,  the National  Center  for  Supercomputing  Applications  at  the  University  of  Illinois  Urbana  Champaign, Indiana  University,  Purdue  University,  Oak  Ridge  National  Laboratory,  and  the  Pittsburgh &lt;br/&gt;Supercomputing Center.&lt;br/&gt;&lt;br/&gt;A separate proposal was submitted to NSF on October 19, 2004, for the TeraGrid Grid Infrastructure Group  (GIG)  [1].   Under the direction of Charlie Catlett at UC/ANL, the GIG will be responsible for coordination of development activities for the TeraGrid with subcontracts to the partner sites.   The Resource partners will each have independent agreements with NSF but will work closely with the GIG to implement the vision of the TeraGrid&lt;br/&gt;&lt;br/&gt;This proposal outlines our plan at the University of Chicago to participate as a resource partner (RP) in the TeraGrid team to provide the expanding user community with ongoing access to this computational science facility.  This proposal covers the period November 1, 2004, through October 31, 2009. The University of Chicago proposes to operate and further develop a Visualization and Data Analysis Resource (VDAR) for the TeraGrid. Our vision is based on the idea that many TeraGrid users will gain  Material benefit from access to a set of purposely designed and supported visualization and analysis services hosted on the TeraGrid hardware operated by the UC resource partner. These services will be made available via Web and Grid service interfaces in a manner that enables end users  (and those supporting end users) to include them in existing applications or to use them directly via Web-based portals or other client-based tools [2, 3].  Our goal is to have users routinely include visualization and analysis tools as part of their production workflow  [4].    An important design consideration is that although computing centers often have large-scale and high-end visualization infrastructure, the TeraGrid end user typically does not have access to such resources.    Therefore, the primary design point for Services delivery needs to be aimed at the average user via a modest networking infrastructure between the TeraGrid resource and the end-user desktop. The other large NSF centers (NCSA, SDSC, PSC) all provide visualization services to their user base in the form of select services, consulting, and generic package deployment. The goal of the VDAR is to reach a larger community, reduce the barrier to entry,  And to enable both users and developers by exposing applications through Web/Grid services. The TG hardware that has been deployed has been configured to support interactive use as well as batch computation.  We outline in this proposal a plan to deploy a series of increasingly capable visualization and analysis tools over the next five years and to provide specialized support services to those users that need to analyze or visualize large-scale datasets, especially those datasets that exceed the capability of their local computing environment.  The primary usage model for VDAR is founded on the idea of users being able to reserve visualization and compute resources on an on-demand basis to support interactive analysis and visualization sessions.  The services will also support batch use for rendering large movies or for non-interactive computation of images or reports. &lt;br/&gt;  &lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/09/2005</MinAmdLetterDate>
<MaxAmdLetterDate>12/04/2009</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>CoopAgrmnt</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0504086</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Papka</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael E Papka</PI_FULL_NAME>
<EmailAddress>papka@niu.edu</EmailAddress>
<PI_PHON>6302521556</PI_PHON>
<NSF_ID>000311964</NSF_ID>
<StartDate>08/09/2005</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rick</FirstName>
<LastName>Stevens</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rick L Stevens</PI_FULL_NAME>
<EmailAddress>stevens@cs.uchicago.edu</EmailAddress>
<PI_PHON>6302523378</PI_PHON>
<NSF_ID>000327926</NSF_ID>
<StartDate>08/09/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606372612</ZipCode>
<StreetAddress><![CDATA[6054 South Drexel Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>7476</Code>
<Text>XD-Extreme Digital</Text>
</ProgramElement>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0105</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2005~699999</FUND_OBLG>
<FUND_OBLG>2006~401066</FUND_OBLG>
<FUND_OBLG>2007~715874</FUND_OBLG>
<FUND_OBLG>2008~1797305</FUND_OBLG>
</Award>
</rootTag>
