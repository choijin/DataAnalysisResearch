<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Statistical Theory and Methodology</AwardTitle>
<AwardEffectiveDate>08/01/2005</AwardEffectiveDate>
<AwardExpirationDate>07/31/2008</AwardExpirationDate>
<AwardTotalIntnAmount>310000.00</AwardTotalIntnAmount>
<AwardAmount>310000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>03040200</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
</ProgramOfficer>
<AbstractNarration>  ABSTRACT&lt;br/&gt;&lt;br/&gt;Prop ID:  DMS-050 5673  &lt;br/&gt;PI:  Efron, Bradley and Diaconis, Persi&lt;br/&gt;NSF Program: STATISTICS    &lt;br/&gt;Institution:  Stanford University  &lt;br/&gt;Title:  Statistical Theory and Methodology   &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;LARGE-SCALE SIMULTANEOUS TESTING (Bradley Efron) &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This investigator is studying the analysis of large-scale simultaneous hypothesis&lt;br/&gt;testing situations, for example a microarray experiment searching for genes that&lt;br/&gt;behave differently in HIV positive or negative subjects. A simple&lt;br/&gt;methodology is being developed that requires a minimum of frequentist or&lt;br/&gt;Bayesian modelling assumptions, and provides for both the efficient&lt;br/&gt;selection of the non-null cases, and the estimation &lt;br/&gt;of effect sizes. In classical terminology, both size and power are assessed.&lt;br/&gt;This methodology depends on false discovery rate calculations, &lt;br/&gt;implemented via empirical Bayes techniques. A typical result might report&lt;br/&gt;"there are 200 of the 10,000 genes that can be clearly identified as&lt;br/&gt;differentially expressed between the two groups of subjects, but there are&lt;br/&gt;also about 800 other non-null genes that this experiment was not powerful&lt;br/&gt;enough to detect."&lt;br/&gt;&lt;br/&gt;Classical 20th Century statistical theory was fashioned to handle small&lt;br/&gt;problems, dozens or maybe hundreds of data points, with one or maybe a few&lt;br/&gt;unknown parameters. 21st Century scientific technology now provides massive&lt;br/&gt;data sets, with millions of individual measurements and thousands of&lt;br/&gt;parameters to consider all at once. Microarrays are the prime example, but&lt;br/&gt;similar problems arise from a variety of devices: proteomic chips, time of&lt;br/&gt;flight spectroscopy, flow cytometry, and fMRI scanners. The goal of this&lt;br/&gt;research is an efficient, computationally efficient methodology for analyzing&lt;br/&gt;massive simultaneous testing problems, without the need for extensive&lt;br/&gt;modelling assumptions.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;MONTE CARLO METHODS IN PROBABILITY AND STATISTICS (Persi Diaconis)&lt;br/&gt;&lt;br/&gt;The main focus of this investigation is on rates of convergence of Monte Carlo&lt;br/&gt;and Markov chain algorithms for statistical computation. One aspect is &lt;br/&gt;phase transitions ( cut-off phenomena), extending Diaconis' recent solution of&lt;br/&gt;the Peres conjecture (joint with Saloff-Coste). The work&lt;br/&gt;includes creating new algorithms using computational tools such as Grobner&lt;br/&gt;bases and combinatorial characterizations such as Tuttes f-factors. This also&lt;br/&gt;contributes to Bayesian methodology studying prior distributions for Markov&lt;br/&gt;chains, non-parametrics and&lt;br/&gt;computational tools. A final focus is the development of group theoretic&lt;br/&gt;character theories in non-standard situations such as&lt;br/&gt;unipotent groups and Hecke algebras.&lt;br/&gt;&lt;br/&gt;Probability models underlie many areas of modern scientific study, but they&lt;br/&gt;raise puzzling and important questions concerning the connection of the&lt;br/&gt;model with real world phenomena. Diaconis studies&lt;br/&gt;foundational topics such as `what does it mean to say coin flips are&lt;br/&gt;random'? This recently led to the discovery (joint with Susan Holmes and&lt;br/&gt;Richard Montgomery) that in fact, natural human coin flips show a small but&lt;br/&gt;significant bias (about 51% come up the same as the previous flip).&lt;br/&gt;Careful looks at the assumptions, justification and&lt;br/&gt;validity of `randomness' apply to widely-used simulation methods (how long&lt;br/&gt;should an algorithm be run until its job is done?). Weather forcasting&lt;br/&gt;and air pollution are just two of the areas that require the dependability&lt;br/&gt;of such simulations.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/30/2005</MinAmdLetterDate>
<MaxAmdLetterDate>05/31/2007</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0505673</AwardID>
<Investigator>
<FirstName>Bradley</FirstName>
<LastName>Efron</LastName>
<EmailAddress>brad@stat.stanford.edu</EmailAddress>
<StartDate>06/30/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Persi</FirstName>
<LastName>Diaconis</LastName>
<EmailAddress>pwd@stanford.edu</EmailAddress>
<StartDate>06/30/2005</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
