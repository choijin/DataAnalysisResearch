<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research on Latent Class Models of Measurement Error</AwardTitle>
<AwardEffectiveDate>03/01/2006</AwardEffectiveDate>
<AwardExpirationDate>02/28/2009</AwardExpirationDate>
<AwardTotalIntnAmount>59291.00</AwardTotalIntnAmount>
<AwardAmount>59291</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050300</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
</ProgramOfficer>
<AbstractNarration>One of the most crucial activities in mounting a survey is the development and testing of the survey questions.  Unfortunately, this process largely remains a qualitative endeavor, one that features reviews of the questions by experts, focus group discussions with a handful of participants, and small numbers of intensive "cognitive" interviews.  Many researchers have questioned the effectiveness of these methods for identifying problem items.  In addition, there is a disconnect between the qualitative data produced by these conventional questionnaire pretest techniques and the quantitative standards (such as reliability and validity) that the data are meant to address.  This project will systematically assess the potential of a quantitative method -- latent class analysis (LCA) -- for use in developing and testing survey questions.  The project seeks to answer several specific questions about the application of LCA models as a tool for evaluating survey questions by conducting a series of new experiments and analyses of existing data.  The experimental studies will compare results from the LCA models against "gold standards," where true values for the variables being assessed are known.  These studies will compare the conclusions from the LCA method against those from more conventional analyses.  The analytic studies will apply LCA models to existing data sets and also use simulations to assess the robustness of the LCA method to violations of its underlying assumptions.&lt;br/&gt;&lt;br/&gt;This project will advance basic knowledge about various strategies, including the use of latent class models, for questionnaire development.  It will show whether these models can assess the measurement characteristics of survey items even in the absence of external validation data (such as administrative records).  The project will compare the latent class models to conventional questionnaire development techniques and determine whether they can yield better questionnaires, reduced questionnaire development costs, or both compared to the traditional methods.  The results of this research will be of value to the survey community, including the federal statistical agencies.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/13/2006</MinAmdLetterDate>
<MaxAmdLetterDate>01/29/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0550002</AwardID>
<Investigator>
<FirstName>Frauke</FirstName>
<LastName>Kreuter</LastName>
<EmailAddress>fkreuter@survey.umd.edu</EmailAddress>
<StartDate>03/13/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
</Institution>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
</Appropriation>
<Appropriation>
<Code>0107</Code>
</Appropriation>
<Appropriation>
<Code>0108</Code>
</Appropriation>
</Award>
</rootTag>
