<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SGER:  Towards Machine Ethics</AwardTitle>
<AwardEffectiveDate>01/01/2005</AwardEffectiveDate>
<AwardExpirationDate>12/31/2006</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>110631</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines.  In all cases, only human beings have engaged in ethical reasoning.  The PIs believe the time has come to add an ethical dimension to at least some machines.  Recognition of the ethical ramifications of behavior involving machines, and recent and potential developments in machine autonomy, necessitate this.  In this project, the PIs will explore this dimension through investigation of what has been called machine ethics, which (in contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics) is concerned with the consequences of behavior of machines towards human users and other machines.  Clearly, relying on machine intelligence to effect change in the world without some restraint can be dangerous.  Until fairly recently, the ethical impact of a machine's actions has either been negligible (e.g., a calculator) or, when considerable, has only been taken under the supervision of a human operator (e.g., robotic automobile assembly).  As we increasingly rely upon machine intelligence with reduced human supervision, we will need to be able to count on a certain level of ethical behavior from them.  And as machines are given more responsibility, an equal measure of accountability for their actions must be meted out to them if we are to avoid undesirable machine behavior.  In this project, the PIs will implement prototype systems in limited domains, one that incorporates an ethical dimension to its advantage, and another that learns weights of competing duties to the end of providing a decision procedure for an ethical theory.  The PIs hope these investigations will sharpen their understanding of the field, so that they can compose a well-argued position paper that clarifies the objectives of and answers objections to machine ethics, as a first step towards dealing with an issue that has been of concern since the beginning of the 20th century but has seen little serious scientific effort.  &lt;br/&gt;&lt;br/&gt;Broader Impacts:  The PIs will develop a machine ethics website, and will organize a AAAI Machine Ethics symposium tentatively planned for fall 2005.  The outcomes of this research will contribute to the development of autonomous intelligent agents that could be used to replace human effort in many subservient, dangerous, or undesirable tasks.  In the longer run, an ethical dimension in machines could be used to alert humans who rely on machines before they do something that is ethically questionable, averting harm that might have been caused otherwise.  Such capabilities might be harnessed to assist us in ethical decision-making; machine-machine relationships might also benefit, in that the new capabilities could provide a basis for resolving resource conflicts or predicting behavior of other machines.   Perhaps most importantly, the behavior of more fully autonomous machines, guided by an ethical dimension, might be more socially acceptable in real-world environments than that of machines without such a dimension.</AbstractNarration>
<MinAmdLetterDate>11/05/2004</MinAmdLetterDate>
<MaxAmdLetterDate>05/17/2006</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0500133</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Anderson</LastName>
<EmailAddress>anderson@hartford.edu</EmailAddress>
<StartDate>11/05/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Chris</FirstName>
<LastName>Armen</LastName>
<EmailAddress>chris.armen@trincoll.edu</EmailAddress>
<StartDate>11/05/2004</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Susan</FirstName>
<LastName>Anderson</LastName>
<EmailAddress>Susan.Anderson@uconn.edu</EmailAddress>
<StartDate>11/05/2004</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Hartford</Name>
<CityName>West Hartford</CityName>
<ZipCode>061171545</ZipCode>
<PhoneNumber>8607685938</PhoneNumber>
<StreetAddress>200 Bloomfield Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6845</Code>
<Text>HUMAN COMPUTER INTER PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9237</Code>
<Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
