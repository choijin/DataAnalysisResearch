<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Framework for Learning High Accuracy Evaluation Metrics for NLP Applications</AwardTitle>
<AwardEffectiveDate>07/01/2006</AwardEffectiveDate>
<AwardExpirationDate>06/30/2009</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project investigates a new dynamic, adaptable approach for constructing&lt;br/&gt;evaluation metrics and methods for various NLP applications, with a specific&lt;br/&gt;focus on Machine Translation and Summarization.  The main objective is to&lt;br/&gt;establish a general framework that can easily support constructing automatic&lt;br/&gt;evaluation metrics for a variety of specific NLP tasks and based on a variety&lt;br/&gt;of quality criteria.  For a given NLP task (e.g.  Machine Translation) and a&lt;br/&gt;given set of established quality criteria, the framework supports learning a&lt;br/&gt;set of parameters that result in an "instance" evaluation metric that has&lt;br/&gt;optimal correlation with the desired quality criteria.  Training a new&lt;br/&gt;"instance" metric for a different task, or for a different set of quality&lt;br/&gt;criteria, can be accomplished by a fast training procedure using available&lt;br/&gt;training data consisting of system produced outputs, human-quality reference&lt;br/&gt;outputs for the same source data, and human quality judgments for the system&lt;br/&gt;outputs.&lt;br/&gt;&lt;br/&gt;A powerful new innovation of the new framework is its ability to use the set&lt;br/&gt;of all overlapping sub-sequences (also known as "skip ngrams") of the two&lt;br/&gt;strings being compared.  The process of skip n-gram matching is augmented with&lt;br/&gt;a powerful word-to-word alignment algorithm that pre-constrains the set of&lt;br/&gt;skip n-gram matches, while allowing matches between words that are&lt;br/&gt;morphological variants, synonyms or otherwise related.  Furthermore, our&lt;br/&gt;framework uses a well-founded parameterized model for establishing the weight&lt;br/&gt;or significance that should be assigned to each detected overlapping&lt;br/&gt;subsequence, and can calculate these weights as an integral process during the&lt;br/&gt;detection of the matching skip ngrams.  The result is an extremely powerful&lt;br/&gt;"metric-producing" framework.  Under this framework, the project will produce&lt;br/&gt;(instantiate) specific metrics for machine translation, summarization, and&lt;br/&gt;other NLP tasks, that are more robust, sensitive, and have high-levels of&lt;br/&gt;correlation with human judgments.  The project also explores methods for&lt;br/&gt;reducing the reliance of our resulting metrics on human judgments.  The&lt;br/&gt;resulting framework and task-specific trained metrics will be made publicly&lt;br/&gt;available to the NLP research community.  The impact of automatic evaluation&lt;br/&gt;methods extends beyond providing a flexible performance measuring mechanism&lt;br/&gt;for NLP tasks.  We expect our work to enable customizing evaluation metrics&lt;br/&gt;for specific tasks within a variety of cross-lingual applications, which&lt;br/&gt;should significantly boost the overall performance of these applications.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/16/2006</MinAmdLetterDate>
<MaxAmdLetterDate>07/13/2007</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0534932</AwardID>
<Investigator>
<FirstName>Alon</FirstName>
<LastName>Lavie</LastName>
<EmailAddress>alavie@cs.cmu.edu</EmailAddress>
<StartDate>02/16/2006</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
