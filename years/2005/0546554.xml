<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Semantics for Statistical Machine Translation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2006</AwardEffectiveDate>
<AwardExpirationDate>12/31/2011</AwardExpirationDate>
<AwardTotalIntnAmount>499955.00</AwardTotalIntnAmount>
<AwardAmount>513158</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The past few years have seen a revolution in machine&lt;br/&gt;translation, with the widespread adoption of&lt;br/&gt;statistical systems trained on large amounts of&lt;br/&gt;parallel bilingual text.  Recent evaluations have shown&lt;br/&gt;that current statistically trained research technology&lt;br/&gt;significantly outperforms commercially available MT&lt;br/&gt;systems such as those available on the web.  But even&lt;br/&gt;state-of-the-art systems produce garbled translations&lt;br/&gt;more often than not.  Further improvements in machine&lt;br/&gt;translation will require major changes in the&lt;br/&gt;architecture of statistical systems.  Our research aims&lt;br/&gt;to improve the quality of machine translation output by&lt;br/&gt;allowing statistical systems to handle deeper, semantic&lt;br/&gt;representations.&lt;br/&gt;&lt;br/&gt;Our approach focuses on improving statistical machine&lt;br/&gt;translation by using a semantic representation at the&lt;br/&gt;level of predicate-argument structure.  This work&lt;br/&gt;builds on the recent success in statistical approaches&lt;br/&gt;to shallow language understanding, and tree-based&lt;br/&gt;algorithms for machine translation using syntactic&lt;br/&gt;parses of the source and target sentences.  Over the&lt;br/&gt;course of the project we aim to: first, develop robust&lt;br/&gt;semantic parsing systems capable of generalizing to new&lt;br/&gt;domains and apply them to large bilingual corpora,&lt;br/&gt;second, develop probabilistic models of translation&lt;br/&gt;that use the resulting level of representation and can&lt;br/&gt;be practically trained, and third, integrate language&lt;br/&gt;understanding and translation to allow efficient search&lt;br/&gt;for the best overall translation of new sentences.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>12/22/2005</MinAmdLetterDate>
<MaxAmdLetterDate>03/09/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0546554</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Gildea</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Gildea</PI_FULL_NAME>
<EmailAddress>gildea@cs.rochester.edu</EmailAddress>
<PI_PHON>5852757230</PI_PHON>
<NSF_ID>000449779</NSF_ID>
<StartDate>12/22/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146270140</ZipCode>
<StreetAddress><![CDATA[518 HYLAN, RC BOX 270140]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0106</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2006~108140</FUND_OBLG>
<FUND_OBLG>2007~94530</FUND_OBLG>
<FUND_OBLG>2008~109971</FUND_OBLG>
<FUND_OBLG>2009~99068</FUND_OBLG>
<FUND_OBLG>2010~101449</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed new technology for statistical machine<br />translation (MT) systems, for example for automatic translation of<br />Chinese into English.&nbsp; Statistical MT systems are created from<br />parallel, bilingual text, that is, documents that are available with<br />translations in the desired source and target languages.&nbsp; We apply<br />machine learning techniques to automatically derive the correspondence<br />between words and phrases in the two languages, and thus learn to<br />translate new sentences.<br /><br />This project focused on learning tree-based representations of<br />language to model translation.&nbsp; This enables machine translation<br />systems to achieve the complex re-ordering patterns between languages<br />that are often necessary to convey the correct meaning, as well as to<br />correctly generate function words such as pronouns, prepositions, and<br />case markers that often differ between languages.<br /><br />We applied tree-based representations to three general areas of machine<br />translation: decoding algorithms, evaluation, and the theory of <br />translation grammars and their computational complexity.<br /><br />In the area of decoding algorithms, we developed methods to rapidly<br />produce translations of new sentences given a translation model.&nbsp; Here<br />the interaction between tree-based translation grammars and the<br />statistical model of the target language can lead to high<br />computational complexity.&nbsp; Our methods to attack this problem include<br />a multi-pass strategy where possible translation hypotheses are first<br />scored with a simpler model to identify promising areas of the search<br />space before rescoring with a more complex, and more precise, language<br />model.<br /><br />The field of machine translation evaluation develops methods for<br />automatically judging the quality of system output by comparing it to<br />human translations of the same sentences.&nbsp; This can reduce the need to<br />manually read and evaluate system output, making the development and<br />tuning of machine translation systems significantly faster.&nbsp; We developed<br />metrics that generate syntactic parses of system output and human<br />translations, and then compare the trees with a kernel-based similarity<br />measure.&nbsp; This enables machine translation evaluation to take into account<br />structural properties of the sentences, essential for preserving meaning.<br /><br />In the theoretical domain, we developed algorithms for factorizing<br />Synchronous Context-Free Grammars (SCFG) into grammars having shorter<br />rules.&nbsp; Rule size is a key component in the computational complexity<br />of machine translation systems; shorter rules mean less computation<br />time.&nbsp; We also explored a more general class of translation grammar<br />based on Linear Context-Free Rewriting Systems (LCFRS), and showed<br />how to factorize such grammars using the notion of tree decomposition<br />from graph theory.</p><br> <p>            Last Modified: 06/27/2012<br>      Modified by: Daniel&nbsp;Gildea</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed new technology for statistical machine translation (MT) systems, for example for automatic translation of Chinese into English.  Statistical MT systems are created from parallel, bilingual text, that is, documents that are available with translations in the desired source and target languages.  We apply machine learning techniques to automatically derive the correspondence between words and phrases in the two languages, and thus learn to translate new sentences.  This project focused on learning tree-based representations of language to model translation.  This enables machine translation systems to achieve the complex re-ordering patterns between languages that are often necessary to convey the correct meaning, as well as to correctly generate function words such as pronouns, prepositions, and case markers that often differ between languages.  We applied tree-based representations to three general areas of machine translation: decoding algorithms, evaluation, and the theory of  translation grammars and their computational complexity.  In the area of decoding algorithms, we developed methods to rapidly produce translations of new sentences given a translation model.  Here the interaction between tree-based translation grammars and the statistical model of the target language can lead to high computational complexity.  Our methods to attack this problem include a multi-pass strategy where possible translation hypotheses are first scored with a simpler model to identify promising areas of the search space before rescoring with a more complex, and more precise, language model.  The field of machine translation evaluation develops methods for automatically judging the quality of system output by comparing it to human translations of the same sentences.  This can reduce the need to manually read and evaluate system output, making the development and tuning of machine translation systems significantly faster.  We developed metrics that generate syntactic parses of system output and human translations, and then compare the trees with a kernel-based similarity measure.  This enables machine translation evaluation to take into account structural properties of the sentences, essential for preserving meaning.  In the theoretical domain, we developed algorithms for factorizing Synchronous Context-Free Grammars (SCFG) into grammars having shorter rules.  Rule size is a key component in the computational complexity of machine translation systems; shorter rules mean less computation time.  We also explored a more general class of translation grammar based on Linear Context-Free Rewriting Systems (LCFRS), and showed how to factorize such grammars using the notion of tree decomposition from graph theory.       Last Modified: 06/27/2012       Submitted by: Daniel Gildea]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
