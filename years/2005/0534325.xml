<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Structure Alignment-based Machine Translation</AwardTitle>
    <AwardEffectiveDate>07/01/2006</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2010</AwardExpirationDate>
    <AwardAmount>82000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Researchers at New York University, Monmouth University and the&lt;br/&gt;University of Colorado are constructing Japanese/English and&lt;br/&gt;Chinese/English machine translation systems which automatically acquire&lt;br/&gt;rules from ``deep'' linguistic analyses of parallel text. This work&lt;br/&gt;is a natural culmination of automated example-based Machine&lt;br/&gt;Translation (MT) projects that have become increasingly sophisticated&lt;br/&gt;over the last two decades. The following recent advances in Natural&lt;br/&gt;Language Processing (NLP) technologies make this inquiry feasible: (1)&lt;br/&gt;annotated data including bilingual treebanks and processors trained on&lt;br/&gt;this data (parsers, PropBankers, etc.); (2) semantic post-processors&lt;br/&gt;of parser output; (3) programs that automatically align bitexts; and&lt;br/&gt;(4) bilingual tree to tree translation models.&lt;br/&gt;&lt;br/&gt;Natural languages vary widely in the ordering of corresponding words&lt;br/&gt;for equivalent expressions across linguistic boundaries and within a&lt;br/&gt;single language. This research investigates ways to minimize the&lt;br/&gt;variations within a single language using a type of semantic&lt;br/&gt;representation (GLARF) that is derived automatically from syntactic&lt;br/&gt;trees. Such semantic representation provides for: (1) a reduction in the&lt;br/&gt;number of ways of representing the same underlying message, and (2)&lt;br/&gt;a way to handle long distance dependencies (e.g. relative&lt;br/&gt;clauses) as local phenomena. Therefore, there is no need to resort to&lt;br/&gt;arbitrarily long sentence fragments or large trees for&lt;br/&gt;training. Furthermore, since less data is needed, it&lt;br/&gt;minimizes the sparse data problem.&lt;br/&gt;&lt;br/&gt;In the training of this translation model, because of (1), the number&lt;br/&gt;of mapping rules between the source tree and the target tree is&lt;br/&gt;reduced. The translation model, then, is a tree transducer, with&lt;br/&gt;``deep'' linguistically analyzed trees for both source and target&lt;br/&gt;representations. In order to provide efficient computer algorithms&lt;br/&gt;for such partial mappings, this research needs to focus on&lt;br/&gt;(a) the training algorithm and the (b) the constraints over the&lt;br/&gt;mapping rules in order to reduce the computational complexity.&lt;br/&gt;&lt;br/&gt;This research is expected to yield several advantages: The core&lt;br/&gt;architecture of this transducer using ``deep'' linguistic analyses&lt;br/&gt;should yield more accurate results. The GLARF architecture allows&lt;br/&gt;control over different granularity of automatically-obtained&lt;br/&gt;linguistic analyses.&lt;br/&gt;&lt;br/&gt;Broader Impact: The demand for machine translation spans from the&lt;br/&gt;local government (e.g. police forces) to national government&lt;br/&gt;(e.g. CIA) and the private sector. Given the growth of the Internet&lt;br/&gt;outside the English speaking world, better machine translation is of&lt;br/&gt;critical importance for the broader community. This work directly&lt;br/&gt;affects the ability of English speakers to understand websites written&lt;br/&gt;in Chinese and Japanese, two of the most widely used languages on the&lt;br/&gt;Internet. The technique is generalizable to other language pairs and&lt;br/&gt;can ultimately have even wider impact.</AbstractNarration>
    <MinAmdLetterDate>07/14/2006</MinAmdLetterDate>
    <MaxAmdLetterDate>04/25/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0534325</AwardID>
    <Investigator>
      <FirstName>Michiko</FirstName>
      <LastName>Kosaka</LastName>
      <EmailAddress>kosaka@monmouth.edu</EmailAddress>
      <StartDate>07/14/2006</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Monmouth University</Name>
      <CityName>West Long Branch</CityName>
      <ZipCode>077641898</ZipCode>
      <PhoneNumber>7325714491</PhoneNumber>
      <StreetAddress>400 Cedar Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
  </Award>
</rootTag>
