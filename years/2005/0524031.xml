<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Multisensory Processing and Attention</AwardTitle>
<AwardEffectiveDate>09/01/2005</AwardEffectiveDate>
<AwardExpirationDate>08/31/2010</AwardExpirationDate>
<AwardAmount>329896</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lynne Bernstein</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The ability to focus attention on elements of our sensory environment is a critical cognitive function that enables one to enhance the processing of high priority stimuli. A classic auditory example is the "cocktail party effect," in which a person can focus selectively on a particular speaker while tuning out other conversations.  In vision, attending to a particular region of the visual field results in faster and better discrimination of stimuli in that region.  In recent years, both electrophysiological and functional brain imaging studies have suggested that a network of frontal and parietal brain areas enables selective attention by enhancing the responses in sensory cortices in favor of task-relevant stimuli. Almost all studies of attention, however, have been conducted within a single sensory modality. The real world is multisensory, numerous real objects have multisensory characteristics (e.g., both auditory and visual aspects) that need to be attended, perceived, and integrated. With funding from the National Science Foundation, Dr. Marty Woldorff is combining electrical and functional imaging measures of brain activity to study the mechanisms by which attention operates in a multisensory world. This includes the study of (1) whether there are separate attentional resources for processing stimuli in different sensory modalities, (2) how attention influences multisensory integration processes, and (3) how attention may spread from one sensory modality to another in a multisensory object. Recording both electrical and functional imaging measures of brain activity during the performance of multisensory attentional tasks will reveal the location, timing, and sequence of the brain mechanisms underlying multisensory attentional processes.&lt;br/&gt;&lt;br/&gt;The broader impacts of this project relate to the fact that the real world is multisensory, but the mechanisms by which attention operates in multisensory circumstances are far from understood. As just one example, every day millions of motorists drive on streets and highways in the multisensory environment of a car, in which they must cope with a myriad of visual and auditory sensory inputs, including police sirens, car horns, radios, talking passengers and misbehaving children.  Understanding processing limitations and how attention facilitates performance by influencing multisensory interactions is of fundamental importance for understanding the performance of such everyday real-life activities.  Moreover, understanding these mechanisms could have a large, practical impact on matters ranging from the training of drivers to the design of cars and cockpits.  The present work also has impact for understanding the mechanisms by which people integrate the auditory content of speech with the visual input of mouth and head movements, a function fundamental for human beings everywhere.  Lastly, gaining basic scientific understanding concerning how attention operates in multisensory circumstances has impact not only for individuals with normal perceptual and attentional capabilities, but also for individuals in whom such capabilities have been impaired through injury or other causes.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/01/2005</MinAmdLetterDate>
<MaxAmdLetterDate>08/28/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0524031</AwardID>
<Investigator>
<FirstName>Marty</FirstName>
<LastName>Woldorff</LastName>
<EmailAddress>woldorff@duke.edu</EmailAddress>
<StartDate>09/01/2005</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
