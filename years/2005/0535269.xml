<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Human-to-Robot Skill Transfer</AwardTitle>
    <AwardEffectiveDate>11/01/2005</AwardEffectiveDate>
    <AwardExpirationDate>10/31/2009</AwardExpirationDate>
    <AwardAmount>476002</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Richard Voyles</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Programming robots that function robustly in unstructured environments has met with limited success. In contrast, humans can often successfully teleoperate a robot to accomplish complex tasks in natural environments, using only the robot's sensors and actuators. The goal of this proposal is to exploit the knowledge encoded in the actions of human teleoperators to learn more robust controllers for autonomous robot tasks. &lt;br/&gt;&lt;br/&gt;The first step is to refine the huge volumes of data available to the robot to a set of features or percepts, which are both tractable for our systems to process, and sufficient to perform the task at hand. One way to empirically satisfy these constraints is to demonstrate whether a human user can execute the task in a teleoperation setting, given only the displayed sensor features. We will identify task appropriate feature sets by analysis of teleoperator performance (success, speed, distance etc.) under displayed feature combinations.&lt;br/&gt;&lt;br/&gt;The proposed approach to learning robust controllers can be summarized as: 1) a human demonstrates a task remotely; 2) recorded sensor sequences are used to learn compact low dimensional manifolds that represent regions of the feature space safe for a robot to traverse; 3) a reinforcement learning paradigm is employed to find task-optimal paths within the manifolds. The skill or task is considered mastered when the robot's performance equals or exceeds the human's. The learned controller autonomously directs the robot, and reinforcement reward is used to autonomously optimize it. However, whenever the robot runs into difficulties, the human operator can take over, generating new examples used to modify and refine the manifold.</AbstractNarration>
    <MinAmdLetterDate>10/25/2005</MinAmdLetterDate>
    <MaxAmdLetterDate>04/23/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0535269</AwardID>
    <Investigator>
      <FirstName>I. Jane</FirstName>
      <LastName>Mulligan</LastName>
      <EmailAddress>janem@cs.colorado.edu</EmailAddress>
      <StartDate>04/23/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Gregory</FirstName>
      <LastName>Grudic</LastName>
      <EmailAddress>grudic@cs.colorado.edu</EmailAddress>
      <StartDate>10/25/2005</StartDate>
      <EndDate>04/23/2010</EndDate>
      <RoleCode>Former Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>I. Jane</FirstName>
      <LastName>Mulligan</LastName>
      <EmailAddress>janem@cs.colorado.edu</EmailAddress>
      <StartDate>10/25/2005</StartDate>
      <EndDate>04/23/2010</EndDate>
      <RoleCode>Former Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Colorado at Boulder</Name>
      <CityName>Boulder</CityName>
      <ZipCode>803031058</ZipCode>
      <PhoneNumber>3034926221</PhoneNumber>
      <StreetAddress>3100 Marine Street, Room 481</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Colorado</StateName>
      <StateCode>CO</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9216</Code>
      <Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>SMET</Code>
      <Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
