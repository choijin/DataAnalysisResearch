<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Resisting Automated Algorithmic Surveillance with Human-centered Adversarial Machine Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2022</AwardEffectiveDate>
<AwardExpirationDate>02/28/2027</AwardExpirationDate>
<AwardTotalIntnAmount>593922.00</AwardTotalIntnAmount>
<AwardAmount>105781</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
<PO_EMAI>skiesler@nsf.gov</PO_EMAI>
<PO_PHON>7032928643</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project studies adversarial machine learning technologies that will resist facial recognition and other forms of automated inferencing of personally-identifiable information in images that people share online. This approach includes methods to modify images in a manner that is difficult or impossible to detect with the human eye but that reliably reduce the accuracy of machine learning classifiers. Current adversarial machine learning techniques do allow end-users to perturb images that they intend to share online but these technologies have, to date, been developed and evaluated from a technology-centered perspective, rather than a human-centered perspective. It remains unclear whether consumers find the developed technologies useful and practical. This project re-designs these technologies to improve consumer acceptance. The project introduces a human-centered approach to designing and evaluating adversarial machine learning anti-surveillance technologies.  Collaboration with advocacy organizations for populations that bear especially high risks from automated surveillance of images shared online enhance the educational and research impacts of the proposed work.&lt;br/&gt;&lt;br/&gt;The specific activities proposed involves the creation of a standardized set of measures through which developers of human-centered adversarial machine learning ask human evaluators to assess the quality and acceptability of perturbed images. When a standardized measure is created, a public repository of human quality assessments of adversarial machine learning anti-surveillance technologies will be created and seeded with evaluations of extant systems. The project also involves the creation of a differentiable-loss term that captures the aesthetic quality of adversarially perturbed images. The differentiable-loss term can be used to help generate adversarial examples that human users perceive to be high quality. An open-source implementation of this novel loss term for at least one popular machine learning library will make it easier for other researchers to use and build on this work in the creation of novel human-centered adversarial attacks against automated surveillance. The project also involves the use of co-design processes to develop a new and novel human-centered adversarial machine learning application that will allow end-users to touch-up images they choose to share online in a manner that is both aesthetically pleasing and that helps evade facial recognition and other forms of automated inferencing of personally-identifiable information. The proposed work also entails educational activities such as webinars and video lectures open to the public and organized in concert with advocacy organizations for populations at higher risk of automated surveillance, to improve public literacy and knowledge of how to protect images shared online from automated surveillance.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/13/2022</MinAmdLetterDate>
<MaxAmdLetterDate>01/13/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070, 47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2144988</AwardID>
<Investigator>
<FirstName>Sauvik</FirstName>
<LastName>Das</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sauvik Das</PI_FULL_NAME>
<EmailAddress>sdas7@gatech.edu</EmailAddress>
<PI_PHON>6789781547</PI_PHON>
<NSF_ID>000709746</NSF_ID>
<StartDate>01/13/2022</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue, NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>065Z</Code>
<Text>Human factors for security research</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~105781</FUND_OBLG>
</Award>
</rootTag>
