<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Foundations for Bayesian Nonparametric Causal Inference</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2022</AwardEffectiveDate>
<AwardExpirationDate>04/30/2027</AwardExpirationDate>
<AwardTotalIntnAmount>400002.00</AwardTotalIntnAmount>
<AwardAmount>232421</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Pena Edsel</SignBlockName>
<PO_EMAI>epena@nsf.gov</PO_EMAI>
<PO_PHON>7032928080</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).&lt;br/&gt;&lt;br/&gt;Fueled by the remarkable recent success of machine learning and artificial intelligence, there has been substantial interest in recent years in using machine learning to shed light on important policy questions. Examples of such questions include "will this treatment for a disease improve the quality of life of a particular patient?" and "will participation in this academic program increase student achievement?" Applying state-of-the-art predictive algorithms to inform policy has received tremendous attention over the past decade, with contributions made by econometricians, statisticians, and computer scientists. Despite the successes of machine learning, there exist pitfalls which are not well-understood by practitioners. We argue that the apparent flexibility of machine learning leads indirectly to a sort of rigidity, with the consequence that the results of an analysis may be a foregone conclusion, driven only by the choice to use a flexible model rather than any empirical data. For example, it is a common popular refrain that "correlation is not causation" and that one must be wary of common-causes which can explain an apparent causal relation; we show, however, that poorly designed machine learning methods behave much as humans do and are biased in some sense towards attributing correlations as causal relations. The overall objective of this proposal is to understand and correct for the hidden assumptions underlying a particular type of algorithms based on Bayesian inference, to develop robust methodology based on these insights, and to begin the development of an overarching computational framework for implementing policy-oriented Bayesian machine learning methods in practice.&lt;br/&gt;&lt;br/&gt;The appeal of Bayesian machine learning is that it promises to marry the predictive accuracy of modern machine learning and the principled uncertainty quantification of Bayesian inference. The indirect nature of prior specification for many problems leads, however, to a phenomenon we refer to as prior dogmatism: due to the inherent properties of independent priors on high-dimensional spaces, poorly designed Bayesian models can exhibit extreme bias towards the hypothesis that the amount of confounding is negligible. The first objective of this project is to characterize when this occurs (and, importantly, when it does not) in the relatively simple setting of an observational study with many potential confounding variables, and develop Bayesian methods which can be proven theoretically to be robust to dogmatism. The second objective of this project is to extend the insights obtained from the first objective to more advanced designs, such as adaptive clinical trials and observational studies with time-varying treatments and confounding variables. The final objective of this project is to begin the development of a comprehensive computational platform for implementing Bayesian nonparametric causal inference which allow for both (i) careful control over prior specification for important causal parameters and (ii) in-depth sensitivity analysis to assess robustness to untestable causal assumptions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>12/22/2021</MinAmdLetterDate>
<MaxAmdLetterDate>12/22/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2144933</AwardID>
<Investigator>
<FirstName>Antonio</FirstName>
<LastName>Linero</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Antonio R Linero</PI_FULL_NAME>
<EmailAddress>antonio.linero@austin.utexas.edu</EmailAddress>
<PI_PHON>8505917359</PI_PHON>
<NSF_ID>000733598</NSF_ID>
<StartDate>12/22/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121823</ZipCode>
<StreetAddress><![CDATA[105 E 24th St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1253</Code>
<Text>OFFICE OF MULTIDISCIPLINARY AC</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>010V2122DB</Code>
<Name><![CDATA[R&RA ARP Act DEFC V]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~232421</FUND_OBLG>
</Award>
</rootTag>
