<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: SaTC: CORE: Medium: Privacy Through Design: A Design Methodology to Promote the Creation of Privacy-Conscious Consumer AI</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2025</AwardExpirationDate>
<AwardTotalIntnAmount>669163.00</AwardTotalIntnAmount>
<AwardAmount>669163</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project centers consideration of privacy in the development of artificial intelligence (AI) technologies that directly impact consumers.  Using AI can help systems adapt to specific people's goals and abilities; however, AI systems typically require collecting data and making guesses about their users, both of which can be intrusive and cause harms.  For instance, AI systems sometimes make wrong inferences about personal, sensitive characteristics that can cause both psychological harm and affect people's access to systems; the data collected can also be used in unwanted ways, such as large facial recognition databases assembled without people's consent.  These harms often happen, even when system designers are well-intentioned, because current design practice provides little specific guidance on how to reason about possible harms.  This project will tackle this problem by creating design methods and guidelines that highlight potential privacy issues and design choices that often increase these risks.  Student and industry researcher involvement in the development and evaluation of the methods will give the work both direct educational impact and increase the chance that future AI-based systems will make informed choices around privacy and safety risks.&lt;br/&gt;&lt;br/&gt;The specific method proposed is called Privacy through Design (PtD), a novel research methodology to help creators of consumer-facing AI technologies: (i) model how acute, use-case specific privacy concerns among end-users among stakeholders trade off against the envisioned utility or value of proposed AI concepts; and, (ii) understand how to (re-)design those concepts in a manner that respects stakeholders' privacy concerns of while retaining the envisioned utility of the design.  Doing this work makes three main scientific contributions.  The first is to develop a taxonomy of algorithmic privacy intrusions to operationalize the unique privacy harms entailed by consumer AI and map those harms onto the unique capabilities and requirements of AI systems. This second is to develop PtD using an iterative methodology incorporating experts and practitioners in industry and academia. The third is to formally evaluate how products developed through PtD compare to those developed through existing industry standards for designing consumer AI technologies.  Two key envisioned outputs are a repository of design cases in which privacy concerns emerge and are resolved, and a guidebook with worksheets and recommendations to help creators of consumer AI technologies center consideration of privacy in their design processes.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/06/2021</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2126058</AwardID>
<Investigator>
<FirstName>Sauvik</FirstName>
<LastName>Das</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sauvik Das</PI_FULL_NAME>
<EmailAddress>sdas7@gatech.edu</EmailAddress>
<PI_PHON>6789781547</PI_PHON>
<NSF_ID>000709746</NSF_ID>
<StartDate>07/06/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Administration]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue, NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>065Z</Code>
<Text>Human factors for security research</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~669163</FUND_OBLG>
</Award>
</rootTag>
