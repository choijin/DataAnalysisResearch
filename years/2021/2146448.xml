<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Empowering White-box Driven Analytics to Detect AI-synthesized Deceptive Content</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2022</AwardEffectiveDate>
<AwardExpirationDate>09/30/2027</AwardExpirationDate>
<AwardTotalIntnAmount>510000.00</AwardTotalIntnAmount>
<AwardAmount>96488</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).&lt;br/&gt;&lt;br/&gt;Artificial intelligence (AI) synthesis techniques that automatically produce realistic images, videos, and other content have significantly improved over the past few years. Although there are promising legitimate applications of these techniques, they also raise serious trust and security threats. Cybercriminals increasingly weaponize AI synthesis techniques to deceive users and manipulate opinions without having to invest heavily in manual content generation. For instance, AI-synthesized profile photographs are abused to create fake accounts, while deepfake videos that simulate real people can give cybercriminals the ability to defame or impersonate others. Existing detection work mostly relies on "black-box" approaches that analyze content without considering the way the AI synthesis techniques work. This project's goal is to use "white-box" methods that consider how the techniques work, both to systematically detect AI-synthesized content, and to outline general principles that underlie how broad classes of AI synthesis algorithms work that will help detection algorithms adapt as new synthesis techniques are developed. The results of this research will reinforce user trust in online content and help social media sites and other Internet platforms mitigate deception through AI-synthesized content. The project team will integrate the new datasets and techniques developed in this research into undergraduate and graduate courses as well as online exercises to train future cybersecurity workers. The team will also support diverse participation in the research, actively recruiting and mentoring women and people from other under-represented groups.&lt;br/&gt;&lt;br/&gt;This research aims to advance AI synthesis detection in terms of efficacy, generalizability, and robustness. The work focuses on detecting AI-synthesized images and videos, as humans are more likely to be attracted to and deceived by visual content. The developed analytics principles are envisioned to inspire new work in these areas and expand to detection of other types of AI-synthesized content. The project is organized around three research thrusts. First, the team will develop a unified analytic framework to systematically dissect AI-synthesis models and gain deep understanding of synthesis patterns common across the models. Second, based on these findings, the team will design generalizable approaches based on the frequency and pixel domains to efficiently detect AI-synthesized images and videos and operate at scale. Third, it will enhance detection robustness by proactively investigating adversarial evasion strategies and prioritizing detection techniques resistant to those strategies. The framework and the developed techniques will be thoroughly evaluated with large-scale real-world data. This research will contribute to establishing a principled detection paradigm and provide insights to prevail over future forms of AI-based deception and propaganda.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/13/2022</MinAmdLetterDate>
<MaxAmdLetterDate>01/13/2022</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2146448</AwardID>
<Investigator>
<FirstName>Shuang</FirstName>
<LastName>Hao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shuang Hao</PI_FULL_NAME>
<EmailAddress>shao@utdallas.edu</EmailAddress>
<PI_PHON>9728834164</PI_PHON>
<NSF_ID>000753572</NSF_ID>
<StartDate>01/13/2022</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Dallas</Name>
<CityName>Richardson</CityName>
<ZipCode>750803021</ZipCode>
<PhoneNumber>9728832313</PhoneNumber>
<StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX32</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>800188161</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT DALLAS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The University of Texas at Dallas]]></Name>
<CityName>Richardson</CityName>
<StateCode>TX</StateCode>
<ZipCode>750803021</ZipCode>
<StreetAddress><![CDATA[800 W Campbell Rd, AD15]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>102Z</Code>
<Text>COVID-Disproportionate Impcts Inst-Indiv</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>010V2122DB</Code>
<Name><![CDATA[R&RA ARP Act DEFC V]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~96488</FUND_OBLG>
</Award>
</rootTag>
