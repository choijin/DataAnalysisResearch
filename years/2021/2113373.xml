<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Transfer Learning Approach to Algorithmic Fairness</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2021</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927902</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In today's data-driven world, machine learning models are routinely used to make high-stakes decisions in criminal justice, education, lending, medicine, and many other areas. Although replacing humans with machine learning models appears to eliminate human biases in decision-making processes, they may perpetuate or even exacerbate biases in the training data. Such algorithmic biases are especially objectionable when they adversely affect underprivileged groups. In this project, we focus on detecting and mitigating algorithmic biases that are caused by sampling biases in the training data. The project also provides research training opportunities for graduate students. &lt;br/&gt;&lt;br/&gt;There are three aims. First, the PIs identify gaps in the capabilities of existing algorithmic fairness practices for overcoming sampling biases in the training data. The PIs also study how current trends in the development of machine learning (ML) models (for example, data augmentation and overparameterization) can perpetuate and exacerbate algorithmic biases. Second, the PIs cast the fair machine learning problem as a transfer learning problem and leverage recent developments in transfer learning to detect and mitigate algorithmic biases caused by sampling bias. Third, the PIs consider how to collect training datasets that are more representative of the general population and beget ML models that are free from algorithmic biases. The ultimate goal is to broaden the appeal and adoption of algorithmic fairness practices among ML practitioners. The PIs plan to demonstrate that the transfer learning approach to algorithmic fairness avoids two barriers in the way of this ultimate goal: (i) it aligns the goal of algorithmic fairness with the goals of (possibly non-altruistic) ML practitioners by avoiding the apparent trade-off between accuracy and fairness, and (ii) it addresses the lack of consensus on the choice of algorithmic fairness practice in many ML tasks by providing an objective measure of the efficacy of such practices.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/02/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2113373</AwardID>
<Investigator>
<FirstName>Yuekai</FirstName>
<LastName>Sun</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yuekai Sun</PI_FULL_NAME>
<EmailAddress>yuekai@umich.edu</EmailAddress>
<PI_PHON>7347645981</PI_PHON>
<NSF_ID>000758966</NSF_ID>
<StartDate>08/02/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Moulinath</FirstName>
<LastName>Banerjee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Moulinath Banerjee</PI_FULL_NAME>
<EmailAddress>moulib@umich.edu</EmailAddress>
<PI_PHON>7348835099</PI_PHON>
<NSF_ID>000429273</NSF_ID>
<StartDate>08/02/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Regents of the University of Michigan - Ann Arbor]]></Name>
<CityName/>
<StateCode>MI</StateCode>
<ZipCode>481091274</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~150000</FUND_OBLG>
</Award>
</rootTag>
