<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: DASS: Policy Design for Holding AI-Supported Systems Accountable</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>350000.00</AwardTotalIntnAmount>
<AwardAmount>350000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As society is becoming more and more dependent on software systems, questions arise about how such software can be developed responsibly. In the design of software systems, flexibility and innovation must be balanced with safeguarding the public. Regulators who design policy to steward software’s effect on society often have a hard time capturing clear guidance to hold software systems accountable and keeping up with new technologies, such as the increased use of artificial intelligence (AI). Software engineers have often been left with vague guidance and no measurable goals, such as the EU’s “right to explanation.” While clarifying guidance or court decisions may eventually provide more actionable details, policy implementation is a slow, reactive process that can delay adoption of improvements. To reconcile software and policy design and construct a proactive policy framework for accountable software systems, guidance for qualities such as explainability, safety, and fairness requires more attention.&lt;br/&gt;&lt;br/&gt;This project will investigate cross-domain principles for policy design, setting corresponding obligations for software engineers, particularly in the context of AI-supported systems. Results will help stakeholders to deliberately design policy with evidence-based guidance for a specific domain. The project will facilitate interactions between policy makers and software engineers in understanding capabilities and societal expectations toward forming policy goals, investigate policy dimensions and the concrete tradeoffs involved, and connect the policy to specific quality-assurance obligations that could be used in a regulatory evaluation covering both AI and non-AI parts of the system. Specifically, the project will first investigate the important dimensions for policy design (e.g., strictness of regulation, level of evidence, policy specificity) using stakeholder interviews, historical analysis, and technical analysis. It then will evaluate, with several experiments, how design decisions affect outcomes, interact with each other, and result in tradeoffs -- which will be encoded and validated as policy design patterns. The research will combine multiple research methods, including interviews, literature and document analyses, controlled experiments, prototyping, and writer’s workshops. It will deeply integrate social-science research on policy design and regulation with software-engineering research on system design and quality assurance. The research will be disseminated broadly across multiple communities and through engagement with regulators. Educational material will be developed for multiple courses and shared publicly.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/31/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2131477</AwardID>
<Investigator>
<FirstName>Christian</FirstName>
<LastName>Kastner</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christian Kastner</PI_FULL_NAME>
<EmailAddress>kaestner@cmu.edu</EmailAddress>
<PI_PHON>4122689527</PI_PHON>
<NSF_ID>000634835</NSF_ID>
<StartDate>08/31/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>175Y</Code>
<Text>DASS-Dsgng Accntble SW Systms</Text>
</ProgramElement>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~350000</FUND_OBLG>
</Award>
</rootTag>
