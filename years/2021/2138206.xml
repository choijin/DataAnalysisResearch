<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ERI: Improving the Learning Efficiency of Adaptive Optimal Control Systems in Information-Limited Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2022</AwardEffectiveDate>
<AwardExpirationDate>12/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Harry Dankowicz</SignBlockName>
<PO_EMAI>hdankowi@nsf.gov</PO_EMAI>
<PO_PHON>7032922344</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Engineering Research Initiation (ERI) grant will fund research that enables efficient, on-the-fly learning of optimal control strategies for complex engineering systems operating in uncertain environments, with application to connected and autonomous vehicles, thereby promoting the progress of science and advancing the national prosperity and welfare. Many emerging control systems in the artificial intelligence, automotive, robotic, and energy fields require that optimal actions be identified and executed across a network of components in the absence of detailed system knowledge and based on limited input data. Learning-based approaches have been developed to meet this requirement, but are challenged by very slow rates of learning, restrictive requirements on the control policy used to initiate the learning process, and complications due to sensor limitations and sparse data sharing between individual components. This project will overcome these challenges by building a new learning-efficient control framework that integrates advantages of existing methods and demonstrates new solutions for handling missing data streams and optimizing the communication structure between system components. When applied to networks of autonomous vehicles in complex traffic scenarios, the framework may enable improvements in roadway safety and reduction in road fatalities. The broader impacts of this project include outreach efforts to the public intended to show how artificial intelligence and automatic control can be safely leveraged, as well as training and preparation of undergraduate and graduate students to pursue further education and advanced STEM careers.&lt;br/&gt;&lt;br/&gt;This research aims to make fundamental contributions to the development of a learning-efficient, adaptive optimal control framework for nonlinear dynamical systems with completely unknown system models and under conditions of partial observability, and to enable the application of this framework to networked control systems with nontrivial communication topologies. It will achieve this outcome by developing a new hybrid iterative form of reinforcement learning that achieves a quadratic rate of convergence even if a system model and an initial admissible control policy are unavailable. Inspired by ideas from hierarchical reinforcement learning, a two-layer learning-efficient method will be created to enable simultaneous learning of robust distributed control strategies for individual network agents and an optimal network communication topology, including in the presence of communication delays between agents. Micro-traffic simulations and physical experiments will be used to test the theoretical framework in the context of collision avoidance in several formation control scenarios.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>12/22/2021</MinAmdLetterDate>
<MaxAmdLetterDate>12/22/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2138206</AwardID>
<Investigator>
<FirstName>Weinan</FirstName>
<LastName>Gao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Weinan Gao</PI_FULL_NAME>
<EmailAddress>wgao@fit.edu</EmailAddress>
<PI_PHON>3216747406</PI_PHON>
<NSF_ID>000768729</NSF_ID>
<StartDate>12/22/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida Institute of Technology</Name>
<CityName>MELBOURNE</CityName>
<ZipCode>329016975</ZipCode>
<PhoneNumber>3216748000</PhoneNumber>
<StreetAddress>150 W UNIVERSITY BLVD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>053396669</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA INSTITUTE OF TECHNOLOGY, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053396669</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida Institute of Technology]]></Name>
<CityName>Melbourne</CityName>
<StateCode>FL</StateCode>
<ZipCode>329016975</ZipCode>
<StreetAddress><![CDATA[150 W UNIVERSITY BLVD]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7569</Code>
<Text>Dynamics, Control and System D</Text>
</ProgramElement>
<ProgramReference>
<Code>030E</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9264</Code>
<Text>RESEARCH INITIATION AWARD</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~200000</FUND_OBLG>
</Award>
</rootTag>
