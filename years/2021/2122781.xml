<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Development of Attention in Preschool Children</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499998.00</AwardTotalIntnAmount>
<AwardAmount>499998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Vishton</SignBlockName>
<PO_EMAI>pvishton@nsf.gov</PO_EMAI>
<PO_PHON>7032928132</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Children develop in a world cluttered with people’s talking faces and accompanying voices. To avoid confusion, and to communicate properly with any particular person, children must be able to perceptually segregate multiple talking faces and voices. To do so, they must identify and select corresponding face-voice pairs and then bind them into unitary and integrated audiovisual entities. Selective/sustained attention plays a critical role in the perceptual segregation process because it helps us identify and select corresponding faces and voices prior to binding them. This project investigates the development of selective/sustained attention to socially relevant audiovisual information and its impact on perception, learning, and memory in typically developing 4-, 5-, and 6-year-old children. The results from this project will provide critical insights into perception, attention, learning, and memory in typically developing young children and will suggest new ways to maximize their acquisition of critical cognitive skills essential for subsequent success in school and beyond. In addition, the results will provide new insights into the root causes of some learning disabilities that are known to involve impaired attention to and binding of auditory and visual information and will provide an evidence-based approach for detecting such disabilities and improving affected children’s cognitive and social development.&lt;br/&gt;&lt;br/&gt;Selective/sustained attention emerges gradually during infancy and early childhood and it is the critical gateway to perception, learning, memory, and social responsiveness. This project investigates the development of selective/sustained attention in 4-, 5-, and 6-year-old children to talking faces and their accompanying voices in the service of perceptual segregation. The project seeks to answer three principal questions. First, how well do young children rely on selective/sustained attention to identify and bind audiovisually related information normally available in their typically cluttered multisensory environment and does this ability improve with development? Second, what underlying perceptual mechanisms make the developmental improvement in selective/sustained attention to multisensory information possible? Third, how does specific early experience (e.g., exposure to multiple languages or to different-race faces) affect the growth of selective/sustained attention? To investigate selective/sustained attention, we will rely on eye tracking to measure eye gaze while children perform various experimental tasks that require them to perceptually search a cluttered audiovisual scene, to perform audio-visual transfer, to exercise their executive control skills, and to learn and remember specific audiovisually integrated events. The findings from this project will provide novel insights into the emergence of attention and learning in early childhood, suggest empirically-based ways to maximize attention and learning in typically developing children, and will provide an evidence-based method for improving attention and learning in children at risk for early learning disabilities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/27/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/27/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2122781</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Lewkowicz</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David J Lewkowicz</PI_FULL_NAME>
<EmailAddress>david.lewkowicz@yale.edu</EmailAddress>
<PI_PHON>2039982708</PI_PHON>
<NSF_ID>000229053</NSF_ID>
<StartDate>08/27/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Haskins Laboratories, Inc.</Name>
<CityName>New Haven</CityName>
<ZipCode>065116610</ZipCode>
<PhoneNumber>2038656163</PhoneNumber>
<StreetAddress>300 George Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>060010147</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>HASKINS LABORATORIES, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Haskins Laboratories, Inc.]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065116610</ZipCode>
<StreetAddress><![CDATA[300 George Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01002122DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2021~499998</FUND_OBLG>
</Award>
</rootTag>
