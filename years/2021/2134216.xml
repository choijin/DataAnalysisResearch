<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Statistical and Computational Foundations of Deep Generative Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>1150000.00</AwardTotalIntnAmount>
<AwardAmount>371416</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Eun Heui Kim</SignBlockName>
<PO_EMAI>eukim@nsf.gov</PO_EMAI>
<PO_PHON>7032922091</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Complex data are continuously generated across all areas of science and engineering on a daily basis, from photographs or news articles to biological or cosmological experiments. In order to extract meaningful information out of this stream of material, it is necessary to build appropriate statistical models that faithfully represent each data modality. Indeed, such statistical models are critical to assess the expected performance of data analysis methods on future events, and form a key component of several data processing pipelines called `inverse problemsâ€™. For example, removing noise and defects from an image, or predicting the most likely folding of a protein are instances of inverse problems that at their core require a faithful statistical model of the desired output. The main goal of this project is to advance the theoretical foundations of statistical models based on neural networks. Such classes of models provide greater flexibility than traditional statistical modeling, but as a result are harder to analyze and manipulate. The investigators will cover a wide background in machine learning, probability, statistics, and mathematical physics; their combined expertise will result in guiding principles to combine neural networks into a theoretically sound statistical modeling, as well as novel algorithms with statistical guarantees. The research outcomes will be directly applicable to a wide range of problems in science and engineering, ranging from cosmology, climate modeling, chemistry, and signal processing, and they will be tightly integrated into educational courses. &lt;br/&gt;&lt;br/&gt;The success of deep learning (DL) across science and engineering suggests that Deep Neural Networks (DNN) are effective function approximation models for complex high-dimensional data, yet the reasons for such capability are still poorly understood. To make headway on this problem, this project focuses on generative probabilistic modeling. Understanding their inner-workings is essential to explaining the success of DL on typical problem instances, as opposed to worst-case (too pessimistic) or unstructured (too simplistic) data distributions. Additionally, probabilistic models are at the core of computational tools used in many scientific disciplines, yet they often rely on domain expertise preventing them to scale efficiently with dimension. This project puts forward a unified view on generative modeling that simultaneously addresses approximation, estimation, and optimization aspects. Specifically, it covers both explicit modeling, given by Boltzmann-Gibbs distributions, and implicit modeling, given by Transport-based models (Generative Adversarial Networks, Normalizing Flows). It will establish guarantees of learning and sampling from these models when using DNNs as function approximation. This project will rely on methods for importance-sampling developed in computational sciences (such as Replica Exchange and Thermodynamic Integration) and upgrade them to operate alongside DNNs. It will also derive novel algorithms that combine implicit with explicit generative modeling. Finally, it will exploit physical priors such as symmetries and multiscale structure, and assess their benefits on challenging domains such as molecular prediction, turbulence, statistical mechanics, and exploration for reinforcement learning. The investigators have combined expertise in all these areas, making them well qualified to carry out the project.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/11/2021</MinAmdLetterDate>
<MaxAmdLetterDate>08/11/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2134216</AwardID>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Vanden-Eijnden</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric Vanden-Eijnden</PI_FULL_NAME>
<EmailAddress>eve2@cims.nyu.edu</EmailAddress>
<PI_PHON>2129983154</PI_PHON>
<NSF_ID>000188424</NSF_ID>
<StartDate>08/11/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gerard</FirstName>
<LastName>Ben Arous</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gerard Ben Arous</PI_FULL_NAME>
<EmailAddress>gba1@nyu.edu</EmailAddress>
<PI_PHON>2129983108</PI_PHON>
<NSF_ID>000155971</NSF_ID>
<StartDate>08/11/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Wilson</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew G Wilson</PI_FULL_NAME>
<EmailAddress>andrewgw@cims.nyu.edu</EmailAddress>
<PI_PHON>6074228590</PI_PHON>
<NSF_ID>000696522</NSF_ID>
<StartDate>08/11/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Joan</FirstName>
<LastName>Bruna Estrach</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joan Bruna Estrach</PI_FULL_NAME>
<EmailAddress>jb4496@nyu.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000738985</NSF_ID>
<StartDate>08/11/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jonathan</FirstName>
<LastName>Niles-Weed</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonathan Niles-Weed</PI_FULL_NAME>
<EmailAddress>jdw453@nyu.edu</EmailAddress>
<PI_PHON>2129983475</PI_PHON>
<NSF_ID>000817263</NSF_ID>
<StartDate>08/11/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100121019</ZipCode>
<StreetAddress><![CDATA[251 Mercer street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1253</Code>
<Text>OFFICE OF MULTIDISCIPLINARY AC</Text>
</ProgramElement>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~371416</FUND_OBLG>
</Award>
</rootTag>
