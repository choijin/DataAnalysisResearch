<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: FMitF: Track-1: Correctness at Both Ends: Rigorous ML Meets Efficient Sparse Implementations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2021</AwardEffectiveDate>
<AwardExpirationDate>09/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei Ding</SignBlockName>
<PO_EMAI>weiding@nsf.gov</PO_EMAI>
<PO_PHON>7032928017</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project called CBE (correctness at both ends) addresses the growing concern that on one hand systems based on deep neural networks (DNNs) are playing an increasing role in critical applications, but on the other hand these systems can do significant damage if they harbor software defects. These defects go beyond the familiar logic bugs, including also semantic bugs such as misclassifying medical images.  Traditionally, attempts to make DNNs more efficient by sparsifying them have often resulted in increased levels of semantic bugs.  The project's novelties are its integrated approach to sparsify networks while preserving semantic correctness as well as helping eliminate logic bugs.  The project's impacts are in making DNNs energy-efficient, permitting their deployment in edge devices, while also helping eliminate their defects.&lt;br/&gt;&lt;br/&gt;CBE employs a knowledge-distillation paradigm wherein a sparsified network is trained by imitating the parent network's classification behavior. Sparsification steps that meet higher level semantic objectives may unfortunately lead to an inefficient sparse implementation -- especially in newly introduced GPUs for which hand-tuned sparse libraries are unavailable. The CBE project supports the developers of such libraries by also providing low-level implementation verification tools. The investigators are domain experts in DNN semantics and optimization, and also in software&lt;br/&gt;verification. Their three-year collaborative research project is taking case studies of DNNs from critical areas such as medical imaging, and showing how DNNs can be sparsifed to ensure correctness at both ends.  The main impact of this project is to develop prototype software tools that can help spur further research and technology development. Another major impact is the training of students who will fill critical roles in the fast-growing area of deployable machine-learning systems where talent shortage can cripple the nation's economy and security.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/08/2021</MinAmdLetterDate>
<MaxAmdLetterDate>06/08/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2124205</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Baugh</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John W Baugh</PI_FULL_NAME>
<EmailAddress>jwb@ncsu.edu</EmailAddress>
<PI_PHON>9195157697</PI_PHON>
<NSF_ID>000353306</NSF_ID>
<StartDate>06/08/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957908</ZipCode>
<StreetAddress><![CDATA[Campus Box 7908]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>094Y</Code>
<Text>FMitF: Formal Methods in the F</Text>
</ProgramElement>
<ProgramReference>
<Code>071Z</Code>
<Text>FMitF-Formal Methods in the Field</Text>
</ProgramReference>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<ProgramReference>
<Code>8206</Code>
<Text>Formal Methods and Verification</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~300000</FUND_OBLG>
</Award>
</rootTag>
