<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ITR:  Estimation, Approximation and Computation in Learning Theory</AwardTitle>
<AwardEffectiveDate>09/23/2003</AwardEffectiveDate>
<AwardExpirationDate>08/31/2006</AwardExpirationDate>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010600</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
</ProgramOfficer>
<AbstractNarration>ITR: Estimation, Approximation and Computation in Learning Theory&lt;br/&gt; &lt;br/&gt;Learning theory, a rapidly growing area of multidisciplinary research has recently attracted much attention from the mathematical community. There are now numerous pressing issues coming from the statistical, engineering and computer science communities resulting from their significant progress in learning theory that provide a unique opportunity and vast need for mathematicians to develop both theoretical concepts and computational tools to assist in this area of research. We propose to study several fundamental theoretical mathematical and computational problems crucial for the continued rapid development of  learning theory. They include a further study and improvements of the F. Cucker and S. Smale theory of learning, the support vector machine (SVM) of V. Vapnik, the regression theory of T. Poggio, the deterministic approach of C. A. Micchelli for optimal estimation under uncertainty and the relationship between these important ideas. Among other things, we will be concerned with learning a function from other than function values, learning vector valued functions, learning the optimal information for learning a function and estimating the approximation error using notions of nonlinear widths of function classes which is useful for obtaining deterministic estimates that lead to statistical estimates for learning. We shall study efficient numerical solutions of second kind integral equations in high dimensions which come up in the study of the approximation error of Cucker and Smale. We will also focus upon the minimal norm interpolation approach to regression and SVM which is not emphasized  much in the learning theory literature and use duality theory as a bridge to compare all of them. We shall also study the kernel density problem whose importance in learning theory has been recently described by T. Poggio, investigate how to choose a kernel from the data and consider probability density estimation problems which are useful in pattern recognition and speech recognition. We are also interested in the question of stability of learning algorithms and seek to construct kernels on complex spaces suitable for applications.&lt;br/&gt;&lt;br/&gt;Our proposed research addresses a multitude of practical problems arising from the handling of massive amounts of data in high dimensional spaces. Therefore, in a time of heightened concern for national security against terrorism, this research will provide a new tool for dealing with the technological challenges that have recently emerged and an opportunity for applied mathematicians to assist in their solution. &lt;br/&gt; &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/13/2004</MinAmdLetterDate>
<MaxAmdLetterDate>02/13/2004</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0407476</AwardID>
<Investigator>
<FirstName>Yuesheng</FirstName>
<LastName>Xu</LastName>
<EmailAddress>y1xu@odu.edu</EmailAddress>
<StartDate>02/13/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Syracuse University</Name>
<CityName>SYRACUSE</CityName>
<ZipCode>132441200</ZipCode>
<PhoneNumber>3154432807</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROGRAMS</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>1686</Code>
<Text>ITR SMALL GRANTS</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
