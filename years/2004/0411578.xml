<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>IIS/HCI: Collaborative Research: Development and Assessment of Head-Mounted Fovea-Contingent Display Technology</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>12/15/2003</AwardEffectiveDate>
<AwardExpirationDate>04/30/2008</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>350510</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>While head-mounted display (HMD) technologies have undergone significant developments and their functional benefits for 3D visualization have been recognized, they have suffered from tradeoffs and limitations in capability, which impose critical affects on visualization accuracy, user performance, and user safety.  Chief among these problems is an ignorance of eye movement.  Most state-of-the-art HMDs use head pose to approximate line-of-sight, which may cause a significant disparity between what users are intended to look at and what they actually see.  The integration of eye tracking capability into HMDs would significantly improve display quality and user interface.  In this project, the PIs will optimize the conceptual design of HMD-eye tracker integration from low-level optical configurations; the PIs expect to achieve by this means a more compact, comfortable, easy-to-use, and dependable system than would result from integration of off-the-shelf commercially available displays and eye trackers.  The PIs will set up a comprehensive methodology to calibrate and quantitatively assess the testbed, and to quantify rendered and perceived depth/size representations of virtual objects with and without eye tracking capability in the HMD; the PIs expect thereby to determine whether integration can significantly improve the performance of both eye tracking accuracy and display quality as it relates to accuracy and precision of registration of real and virtual objects in augmented environments.  Finally, two pilot studies will be pursued.  The first of these will explore the concept of a unique fovea-contingent display scheme which utilizes photonics technology to position a high resolution inset at the gaze point, innovatively with no moving parts, in order to address the trade-off between field of view and resolution existing in conventional HMDs.  The second pilot study will investigate a "pointing by looking" visual interface in remote collaborative environments in which the focus of attention of a participant follows the point-of-regard of a remote collaborator, or vice versa.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  This research will not only advance display quality and the user interface, but most importantly it will drive new and thrilling applications of augmented reality technology.  In particular, the new HDM-eye tracker technology will lead to novel interactive interfaces for information retrieval, will provide more accurate eye-movement monitoring for human factors and vision research, will support improved assessment of behavior in virtual environments, and will afford new methods of interaction and communication for people with certain types of disabilities.  The mixture of basic optical science and engineering, computer graphics, human factors, and hands-on experience with building a testbed will be an excellent interdisciplinary training ground for the graduate and undergraduate students involved.</AbstractNarration>
<MinAmdLetterDate>12/12/2003</MinAmdLetterDate>
<MaxAmdLetterDate>04/20/2007</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0411578</AwardID>
<Investigator>
<FirstName>Hong</FirstName>
<LastName>Hua</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hong Hua</PI_FULL_NAME>
<EmailAddress>hhua@optics.arizona.edu</EmailAddress>
<PI_PHON>5206268703</PI_PHON>
<NSF_ID>000482958</NSF_ID>
<StartDate>12/12/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857194824</ZipCode>
<StreetAddress><![CDATA[888 N Euclid Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6845</Code>
<Text>HUMAN COMPUTER INTER PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0103</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0104</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0105</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2003~103000</FUND_OBLG>
<FUND_OBLG>2004~128479</FUND_OBLG>
<FUND_OBLG>2005~119031</FUND_OBLG>
</Award>
</rootTag>
