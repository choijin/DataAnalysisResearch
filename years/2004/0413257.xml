<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Learning the Sensorimotor Foundation for Spatial Reasoning</AwardTitle>
<AwardEffectiveDate>01/01/2005</AwardEffectiveDate>
<AwardExpirationDate>12/31/2008</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>435000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Douglas H. Fisher</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The sensorimotor system for a long-lived autonomous robot is the foundation for its knowledge base. This project addresses fundamental questions about how higher-level features and actions, which are usually engineered into robots by human designers, can be learned autonomously and grounded in experience interacting with the environment. The project involves three tasks. &lt;br/&gt;&lt;br/&gt;In Task 1, an unknown sensory system is divided into different sensory "modalities", for example, vision and different types of range sensors, and the goal is to learn the distinctions among these, their individual properties, and sensor fusion methods for combining their information into a common model of the nearby ("small-scale'') environment. &lt;br/&gt;&lt;br/&gt;In Task 2, the basis for a map of the "large-scale'' environment is assumed to be a deterministic automaton model consisting of a discrete set of so-called "distinctive states" that are reliably connected by actions.  One goal is to learn hill-climbing control laws that define distinctive states by reaching the local maximum activation of learned feature-detectors.  A second goal is to learn trajectory-following control laws for moving reliably from one distinctive state to the neighborhood of another, where hill-climbing eliminates accumulated error. &lt;br/&gt;&lt;br/&gt;In Task 3, the goal is to learn to model the dynamic as well as the static environment, using coherent motion to distinguish individual objects from the background, so they can be categorized and their properties learned to support recognition elsewhere. This is in contrast to the usual approach of assuming that the environment is static and that anything dynamic is treated as noise to be filtered out.&lt;br/&gt;&lt;br/&gt;Together, the results of these tasks will allow an autonomous learning agent to ground its own sensors and effectors in its own experience, supporting a high level of competence in modeling and interacting with its environment. Besides addressing fundamental issues in spatial cognition, this research has practical importance in showing how robots can adapt autonomously to new or changing sensors and effectors. These results can apply to non-standard "robots'' such as autonomic computing in complex computing systems, distributed sensor networks, MEMS sensors, or reconfigurable autonomous spacecraft, and have applications to the creation of intelligent aids, such as wheelchairs, for the disabled.&lt;br/&gt;&lt;br/&gt;The results of this project have broader impacts on many educational activities, including innovative undergraduate courses in robotics, involvement of high school students in the work of the project, and outreach to the community through open houses and public demonstrations. One focus of the project is the development of mobility aids like an Intelligent Wheelchair for persons with disabilities in mobility and communication, but with normal cognition and perception. &lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>12/01/2004</MinAmdLetterDate>
<MaxAmdLetterDate>07/25/2006</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0413257</AwardID>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Kuipers</LastName>
<EmailAddress>kuipers@umich.edu</EmailAddress>
<StartDate>12/01/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
