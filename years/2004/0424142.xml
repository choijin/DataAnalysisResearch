<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Model Selection Competition for Very Large Datasets</AwardTitle>
<AwardEffectiveDate>09/01/2004</AwardEffectiveDate>
<AwardExpirationDate>08/31/2006</AwardExpirationDate>
<AwardTotalIntnAmount>80000.00</AwardTotalIntnAmount>
<AwardAmount>80000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Werbos</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The PI will organize a machine learning competition on the theme of model selection and organize workshops at major conferences where top-ranking participants will present their results. &lt;br/&gt;The proceedings will be published as a special issue of the Journal of Machine Learning Research. The platform used for the competition will remain available for further method benchmarking as an on-line service. &lt;br/&gt;&lt;br/&gt;The competition will benchmark classification and regression methods on sizeable real-world data sets that are presently of interest to the industry datasets with either many input variables (features) or many entries (examples, patterns), or both. Many means of the order of 10,000, 100,000 or even one million features and/or patterns. Such problems are encountered, for instance, in vision, text processing, speech processing, bioinformatics, astronomy, and combinatorial chemistry (e.g. for high throughput drug screening). These pose new challenges because many techniques were developed for smaller size data sets.  &lt;br/&gt;&lt;br/&gt;People have long identified the need for benchmarks in machine learning, not with toy examples but with real-world data. With the advent of the Internet, data exchange has become very easy and it is now very common that people publish their data on-line when they publish results. Data repositories allow researcher to find easily a variety of data sets from which to choose. But, without organized competitions, comparisons can hardly be made, for various reasons. Researchers choose different data sets on which they test their method, sometimes reporting only successes. The results are often not statistically significant. There are sometimes fundamental experimental design flaws that invalidate the results (e.g. training on the test set, in a subtle way).  This project will develop and implement competent testing procedures to overcome these and related problems.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/25/2004</MinAmdLetterDate>
<MaxAmdLetterDate>08/25/2004</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0424142</AwardID>
<Investigator>
<FirstName>Isabelle</FirstName>
<LastName>Guyon</LastName>
<EmailAddress>guyon@clopinet.com</EmailAddress>
<StartDate>08/25/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Clopinet</Name>
<CityName>Berkeley</CityName>
<ZipCode>947081501</ZipCode>
<PhoneNumber>5105246211</PhoneNumber>
<StreetAddress>955 Creston Road</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<FoaInformation>
<Code>0510403</Code>
<Name>Engineering &amp; Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>1504</Code>
<Text>GOALI-Grnt Opp Acad Lia wIndus</Text>
</ProgramElement>
<ProgramElement>
<Code>1518</Code>
<Text>CONTROL, NETWORKS, &amp; COMP INTE</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>7238</Code>
<Text>ENG ITR CORE ACTIVITIES</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9147</Code>
<Text>GENERIC TECHNOL FOR MANUFACTURING CELLS</Text>
</ProgramReference>
<ProgramReference>
<Code>MANU</Code>
<Text>MANUFACTURING</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
