<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Motion Compensated Scalable Video Coding for Heterogeneous Networks</AwardTitle>
<AwardEffectiveDate>08/15/2004</AwardEffectiveDate>
<AwardExpirationDate>07/31/2006</AwardExpirationDate>
<AwardTotalIntnAmount>90000.00</AwardTotalIntnAmount>
<AwardAmount>90000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project has the goal of developing a new family of more powerful and fully scalable video compression algorithms.  It uses the interframe subband/wavelet approach that is accomplished through the use of a motion compensated temporal filter (MCTF).  This method has emerged over the recent years as having great potential for video compression closely matched with universal multimedia access and the efficient transmission of video over heterogeneous and lossy networks.  There is an on-going standards investigation in this area. &lt;br/&gt; &lt;br/&gt;Our previous video coder MC-EZBC used 2-tap Haar filters and hierarchical variable-size block matching (HVSBM).  The new improved coder uses longer temporal filters and a hierarchical variable size mesh-based motion field.  Improvements are anticipated based on various experimental and theoretical findings in the literature, and described more fully in the project description.  In performing the MCTF, a key problem is to avoid creating artifacts in the lower frame-rate data by inadvertently filtering along poorly matched paths.  A variable size block match field has been used in the past because it is easy to classify the blocks as to whether they should be filtered, predicted, or regarded as I-blocks, and just spatially interpolated.  The challenge then is to do the same with the more accurate mesh-based motion models and on a variable size mesh grid.  As we find the .true. motion paths, we can then make better use of longer filters, to reduce redundancy and to improve the quality of the video itself.  Additionally such a high quality motion field, when made available at the receiver, can enable sophisticated post-processing to be done for adaptation to display characteristics.   &lt;br/&gt; &lt;br/&gt;Level of Effort Statement: &lt;br/&gt; &lt;br/&gt;During this one-year effort, we will concentrate on scalable motion vector coding and hierarchical variable size mesh model for MCTF with longer filters.  We will not get to the investigation of alias problems or the new paradigm . combined video restoration and coding. &lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/12/2004</MinAmdLetterDate>
<MaxAmdLetterDate>08/12/2004</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0430837</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Woods</LastName>
<EmailAddress>woods@ecse.rpi.edu</EmailAddress>
<StartDate>08/12/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>4720</Code>
<Text>SIGNAL PROCESSING SYS PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
