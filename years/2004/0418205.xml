<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Conference - From Sound to Sense:  Fifty+ Years of Discoveries in Speech Communication</AwardTitle>
<AwardEffectiveDate>08/01/2004</AwardEffectiveDate>
<AwardExpirationDate>06/30/2008</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>22550</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The National Science Foundation will provide partial support for a conference, "From Sound to Sense: Fifty+ Years of Discoveries in Speech Communication," (http://rledev.mit.edu/soundtosense/default.cfm), held on June 11-13, 2004, at the Massachusetts Institute of Technology in Cambridge, MA. The conference has two goals. The first is to survey the current state of the field, by providing an historical overview of what has been accomplished during the last five decades of speech research, and by sampling some of the most interesting recent work in this active and exciting research topic. Twenty-one invited speakers will present talks in six different areas: Phonology and Phonetics; Speech Acoustics; Speech Perception; Planning and Production; Development, Pathologies and Remediation; and Speech Technology. The second goal is to promote cross-fertilization among the subdisciplines, to benefit future work in this field of study, which has its foundations in the physical, engineering, linguistic, cognitive and medical sciences. To this end the conference is organized in single sessions, rather than multiple parallel sessions, so that everyone will hear all presentations and participate in the discussions together. Many of the presentations will be archived as written papers at an MIT web site and distributed as a CD, and all of the sessions will be videotaped (if funds permit), offering a rich resource for both students and established investigators. &lt;br/&gt; &lt;br/&gt;Many of the historical overviews will be presented by senior researchers such as Gunnar Fant, Kenneth Stevens, Peter Ladefoged, John Ohala, David Pisoni, Bjorn Lindblom, Victor Zue and Ray Kent, who have done pioneering work in their subdisciplines, including advances such as &lt;br/&gt;-the source-filter theory of speech acoustics, which models the way that changes in the size and shape of the vocal tract produce the sounds of a spoken utterance, &lt;br/&gt;-the quantal theory of acoustic-articulatory mapping, which identifies the acoustically stable articulations that provide some of the bases for sound categories in languages of the world, &lt;br/&gt;-models of human speech perception, production, development and pathologies, which relate models of the acoustics and articulation of speech to human language processing, and &lt;br/&gt;-algorithms for the automatic recognition and synthesis of speech, which not only provide aids for the handicapped, but also serve as tools for testing our models of human speech processing.  &lt;br/&gt;The invited speakers who were responsible for these advances bring the valuable perspective of decades of thinking about and investigating speech to their historical overviews. The meeting thus provides an opportunity for students to hear first hand the insights of researchers who up to now may have been only names on classic papers, and to have personal contact with them. &lt;br/&gt;&lt;br/&gt;Other speakers represent leading-edge current work, addressed to a broad range of questions. These include how individual languages make different use the special articulatory-acoustic mapping properties of the vocal tract, how the brain operates to process speech both as input and as output, and how automatic recognition and synthesis can take advantage of our increasing understanding of how speech is processed by humans, to create better tools for human-computer and human-human interactions by spoken language. A final summarizing address, followed by a discussion forum, will synthesize the ideas presented at the conference, with a focus on how future speech research can benefit from interaction among the represented sub-specialties. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/11/2004</MinAmdLetterDate>
<MaxAmdLetterDate>04/23/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0418205</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Perkell</LastName>
<EmailAddress>Perkell@mit.edu</EmailAddress>
<StartDate>08/11/2004</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stefanie</FirstName>
<LastName>Shattuck-Hufnagel</LastName>
<EmailAddress>sshuf@mit.edu</EmailAddress>
<StartDate>08/11/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
