<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Entropy-Compressed Data Structures</AwardTitle>
<AwardEffectiveDate>09/01/2004</AwardEffectiveDate>
<AwardExpirationDate>08/31/2007</AwardExpirationDate>
<AwardTotalIntnAmount>255000.00</AwardTotalIntnAmount>
<AwardAmount>255000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Frank Olken</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Entropy Compressed Data Structures&lt;br/&gt;&lt;br/&gt;In this report, we highlight the intellectual challenges of the&lt;br/&gt;proposal, both theoretically and in practice.  The interplay between&lt;br/&gt;theory and practice distinguishes this proposal from many in the&lt;br/&gt;database searching area.  The goal of an entropy-compressed technology&lt;br/&gt;could have a major impact on data structure design and implementation.&lt;br/&gt;We give a three-year research plan of desired and expected outcomes.&lt;br/&gt;&lt;br/&gt;In this proposal, we introduce a new data structures model and&lt;br/&gt;technology called Entropy-Compressed Data Structures that addresses&lt;br/&gt;the importance of limiting the size of text databases and search&lt;br/&gt;structures that index huge volumes of data. The main goal is to&lt;br/&gt;achieve "optimal" space terms (with a leading coefficient of 1, with&lt;br/&gt;provably smaller second-order terms) while not sacrificing optimal&lt;br/&gt;lookup time. We measure our "optimal" space usage in a data-aware&lt;br/&gt;manner, as a function of the inherent randomness (or entropy) in the&lt;br/&gt;input data set.  This model is an outgrowth of the recent&lt;br/&gt;space-efficient discoveries made by the PI and coauthors in the area&lt;br/&gt;of text indexing, which has caused a rebirth of research in text&lt;br/&gt;indexing and has spawned considerable interest in space-efficient data&lt;br/&gt;structures.&lt;br/&gt;&lt;br/&gt;In order to analyze the space required, we need measures (or models)&lt;br/&gt;to evaluate these succinct structures and quantify the&lt;br/&gt;space-savings. The space required for a structure should relate in&lt;br/&gt;some sense to the entropy of the data that the structure is built&lt;br/&gt;upon.  We formalize a variety of intuitive and meaningful models as a&lt;br/&gt;foundation for a uniform and structured study in a number of&lt;br/&gt;applications.&lt;br/&gt;&lt;br/&gt;We plan a three-pronged approach in developing Entropy-Compressed Data&lt;br/&gt;Structure technology:&lt;br/&gt;&lt;br/&gt;First, we focus on the fundamental dictionary problem, &lt;br/&gt;where the task is to represent a set S of t items out of a universe &lt;br/&gt;U = {0, ..., n-1}.  Dictionaries are critical in text indexing &lt;br/&gt;and other database applications as a building block in designing&lt;br/&gt;entropy-compressed data structures. For text-based applications,&lt;br/&gt;dictionaries serve as a powerful black box that operates within some&lt;br/&gt;entropy-aware partitioning of the data. Any improvement to a&lt;br/&gt;dictionary structure would have tremendous impact on all such&lt;br/&gt;dependent applications.&lt;br/&gt;&lt;br/&gt;In the first year, we expect to devote our efforts in developing a&lt;br/&gt;powerful and succinct fully indexable dictionary that operates in&lt;br/&gt;near-optimal time.  In particular, we hope to achieve bounds for a&lt;br/&gt;dictionary supporting the operations of rank and select (and thus the&lt;br/&gt;predecessor operation as well) in gap + o(log {n choose t}) bits&lt;br/&gt;(where gap refers to the optimal space cost using a gap-encoding of&lt;br/&gt;the items in the dictionary), while achieving time bounds of Anderson&lt;br/&gt;and Thorup, namely O(min{{sqrt{log t/loglog t}, &lt;br/&gt;((loglog n)(loglog t))/logloglog n, loglog t + log t/loglog n }}) time.&lt;br/&gt;In a similar vein, we wish to further push our structure to achieve&lt;br/&gt;gap + o(gap) bits without sacrificing lookup time.  These&lt;br/&gt;contributions would be quite major theoretically, and their impact&lt;br/&gt;could be considerable in practice.&lt;br/&gt;&lt;br/&gt;As a further step, we would also like our dictionary to be dynamic, as&lt;br/&gt;this development would be of immediate interest to the database&lt;br/&gt;community. In practice, we want our structures to be simple, so that&lt;br/&gt;they can be readily implemented. For instance, a good implementation&lt;br/&gt;also becomes a potential solution to the IP lookup problem, since one&lt;br/&gt;could abstract an IP lookup as nothing more than a query to find the&lt;br/&gt;longest common prefix match (which is very similar to the predecessor&lt;br/&gt;problem).&lt;br/&gt;&lt;br/&gt;Second, once a powerful dictionary is developed to serve as a black&lt;br/&gt;box, we can begin to focus on the technology of space-efficient&lt;br/&gt;representations of the application data structures themselves. Text&lt;br/&gt;indexing has received quite a bit of attention in recent years, and we&lt;br/&gt;focus on improvements to these structures to motivate a similar&lt;br/&gt;progression of work in other application areas.  We will show very&lt;br/&gt;clearly the relationship between text indexing and the dictionary&lt;br/&gt;problems and how they can be used as a basic paradigm for making data&lt;br/&gt;structures entropy-compressed.&lt;br/&gt;&lt;br/&gt;A strong component of this proposal, in comparison with other projects&lt;br/&gt;in the IDM program, is the marriage of theoretical analysis and&lt;br/&gt;practical implementation.  We have demonstrated rigorous mathematical&lt;br/&gt;proofs of optimality in our earlier work, and moreover, the mathematical&lt;br/&gt;elegance has translated to efficient implementations in practice.  We&lt;br/&gt;regard our strengths in theoretical design and analysis as a very&lt;br/&gt;strong component of this project.&lt;br/&gt;&lt;br/&gt;In the second year, we propose to improve the state-of-the-art in text&lt;br/&gt;indexing. The work in text indexes boasts two individual results. &lt;br/&gt;The first achieves nH_h + o(n) bits of space with O(m) lookup time&lt;br/&gt;(where H_h is the hth order entropy), which is nearly optimal in space&lt;br/&gt;(aside from low-order terms) but not in time.  The second achieves&lt;br/&gt;epsilon^{-1}nH_h + o(n) bits with o(m) lookup time, which is optimal&lt;br/&gt;in lookup time (aside from low-order terms) but not in space. We&lt;br/&gt;expect to achieve a text-indexing data structure which takes nH_h +&lt;br/&gt;o(n) bits of space while simultaneously supporting o(m) optimal lookup&lt;br/&gt;time. Achieving a result of this type satisfies all of the goals of&lt;br/&gt;developing entropy-compressed data structures. Further improvements&lt;br/&gt;involve adding more power to compressed suffix arrays (CSAs). We hope&lt;br/&gt;to dynamize compressed suffix arrays without increasing time or space,&lt;br/&gt;as well as supporting range-searching and occurrence queries in&lt;br/&gt;optimal time without increasing space. The choice of h carries with&lt;br/&gt;it a potentially nontrivial model cost; in order to alleviate this&lt;br/&gt;inefficiency, we will use gap encoding. We also expect to present a&lt;br/&gt;compressed suffix array that adaptively chooses the best context&lt;br/&gt;length h using nH_h + o(n) bits with o(m) lookup time.&lt;br/&gt;&lt;br/&gt;In the third year, we expand our efforts to the areas of&lt;br/&gt;multidimensional matching.  We begin our exploration by first&lt;br/&gt;developing the crucial notion of a multidimensional Burrows Wheeler&lt;br/&gt;Transform. In particular, we are considering a series of novel&lt;br/&gt;transformations of the data that simultaneously allow fast access to&lt;br/&gt;the data, ease of compression, and do not violate the various&lt;br/&gt;constraints posed by Giancarlo. We then expect to achieve a&lt;br/&gt;multidimensional suffix array that operates on d-dimensional data in&lt;br/&gt;just n^d H_h + o(n^d) bits with O(polylog n^d) time.&lt;br/&gt;&lt;br/&gt;Once we have a generic space-efficient technology, we will aim to make&lt;br/&gt;it more practical via algorithms engineering by emphasizing dynamic&lt;br/&gt;updating, adaptivity, and simpler design of the implementation.  We&lt;br/&gt;envision many applications to spatial databases, GIS, geometric&lt;br/&gt;processing, and numerical algorithms.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/17/2004</MinAmdLetterDate>
<MaxAmdLetterDate>06/23/2006</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0415097</AwardID>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Vitter</LastName>
<EmailAddress>jsv@ku.edu</EmailAddress>
<StartDate>08/17/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>2860</Code>
<Text>THEORY OF COMPUTING</Text>
</ProgramElement>
<ProgramElement>
<Code>6855</Code>
<Text>INFORMATION &amp; KNOWLEDGE MANAGE</Text>
</ProgramElement>
<ProgramReference>
<Code>6855</Code>
<Text>INFORMATION &amp; KNOWLEDGE MANAGE</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
