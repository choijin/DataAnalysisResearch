<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: A Theoretical Foundation for Achievability and Optimization in Privacy-Preserving Data Mining</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
<AwardExpirationDate>12/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>440926.00</AwardTotalIntnAmount>
<AwardAmount>440926</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dmitri Maslov</SignBlockName>
<PO_EMAI>dmaslov@nsf.gov</PO_EMAI>
<PO_PHON>7032928910</PO_PHON>
</ProgramOfficer>
<AbstractNarration>CAREER: A Theoretical Foundation for Achievability and Optimization in &lt;br/&gt;        Privacy-Preserving Data Mining&lt;br/&gt;&lt;br/&gt;Data mining has been successfully applied to support a variety of applications, including marketing, weather forecasting, medical diagnosis, and homeland security. Mining data without violating the privacy of data being mined, however, is still a critical challenge. How to mine patientsÕ personal information, for example, is an ongoing problem in healthcare applications. Emerging privacy legislation, such as the Health Insurance Portability and Accountability Act (HIPAA), as well as the heightened public concerns about privacy protection, require immediate and resolute attention from the computing community on the protection of private information in data mining.&lt;br/&gt;&lt;br/&gt;This research involves the understanding, analysis, and optimization of the tradeoff between privacy protection, accuracy of data mining, and system resources in privacy-preserving data mining.  The methodology is to establish a solid theoretical foundation that defines the requirements for privacy protection in data mining, identifies the domain of privacy-preserving strategies, and determines the achievability of such strategies.  This theoretical foundation enables the design and optimization of privacy-preserving data mining algorithms that are realistic, generic, and efficient.  The research results of this project have broader impacts on the nationÕs higher education system and high-tech industries.  The ability to mine private data without violating the privacy of data owners is a must for a wide variety of corporations, universities, hospitals, and government agencies. Similarly, theoretically and empirically validated means to protect privacy in data mining would benefit all privacy-concerned individuals at large.  The impact of this project also extends to academia through educational efforts, including graduate and undergraduate student training, curriculum development, seminars, and outreach.</AbstractNarration>
<MinAmdLetterDate>09/23/2008</MinAmdLetterDate>
<MaxAmdLetterDate>12/16/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0852674</AwardID>
<Investigator>
<FirstName>Nan</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nan Zhang</PI_FULL_NAME>
<EmailAddress>nzhang@american.edu</EmailAddress>
<PI_PHON>2025240076</PI_PHON>
<NSF_ID>000491454</NSF_ID>
<StartDate>09/23/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>George Washington University</Name>
<CityName>Washington</CityName>
<ZipCode>200520086</ZipCode>
<PhoneNumber>2029940728</PhoneNumber>
<StreetAddress>1922 F Street NW</StreetAddress>
<StreetAddress2><![CDATA[4th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>043990498</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGE WASHINGTON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[George Washington University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200520086</ZipCode>
<StreetAddress><![CDATA[1922 F Street NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7351</Code>
<Text>THEORETICAL FOUNDATIONS (TF)</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~83009</FUND_OBLG>
<FUND_OBLG>2009~85508</FUND_OBLG>
<FUND_OBLG>2010~88096</FUND_OBLG>
<FUND_OBLG>2011~90771</FUND_OBLG>
<FUND_OBLG>2012~93542</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Data mining has been successfully applied to support a variety of applications, including marketing, weather forecasting, medical diagnosis, and homeland security. Mining data without violating the privacy of data being mined, however, is still a critical challenge. Emerging privacy legislation, such as the Health Insurance Portability and Accountability Act (HIPAA), as well as heightened public concerns about privacy protection, require immediate and resolute attention from the computing community on the protection of private information in data mining. In this project, we studied the theoretical foundation for privacy-preserving data mining, including the space of privacy requirements, the domain of privacy-preserving strategies, the achievability of such strategies, and the design of concrete algorithms for practical problems.</p> <p>&nbsp;</p> <p>Specifically, we identified novel privacy requirements such as robustness against algorithm-based disclosure - i.e., an attack which compromises private data based on knowledge of the algorithm with which the data were published. We also defined the domain of privacy-preserving strategies by listing a number of design principles an algorithm has to follow in order to eliminate algorithm-based disclosure. We analyzed the achievability of privacy-enhancing rules used in practice, and found a significant gap between what these rules set out to achieve and what they actually deliver in practice. We identified a key reason for the gap to be the lack of a solution for enforcing multiple privacy rules at once, and addressed the problem by developing a novel framework called versatile publishing which achieves this based on a complete set of inference axioms for privacy rules. We developed concrete algorithms for a number of applications, including a table-decomposition based framework for privacy-preserving data publishing which achieves a standard we called the Guardian Normal Form. We also studied many related techniques over private databases that have restrictive query interfaces.</p> <p>&nbsp;</p> <p>The techniques developed from this project, and their underlying theory, have broader impacts on the nation's high-tech industries. The ability to mine private data without violating the privacy of data owners (e.g., students, patients, travelers) is a must for a wide variety of corporations, universities, hospitals, and government agencies. Similarly, theoretically and empirically validated means to protect privacy in data mining would benefit all privacy-concerned individuals at large. Our findings in this project also contributed to the understanding of privacy protection for a much broader class of applications such as network security.</p><br> <p>            Last Modified: 03/02/2015<br>      Modified by: Nan&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Data mining has been successfully applied to support a variety of applications, including marketing, weather forecasting, medical diagnosis, and homeland security. Mining data without violating the privacy of data being mined, however, is still a critical challenge. Emerging privacy legislation, such as the Health Insurance Portability and Accountability Act (HIPAA), as well as heightened public concerns about privacy protection, require immediate and resolute attention from the computing community on the protection of private information in data mining. In this project, we studied the theoretical foundation for privacy-preserving data mining, including the space of privacy requirements, the domain of privacy-preserving strategies, the achievability of such strategies, and the design of concrete algorithms for practical problems.     Specifically, we identified novel privacy requirements such as robustness against algorithm-based disclosure - i.e., an attack which compromises private data based on knowledge of the algorithm with which the data were published. We also defined the domain of privacy-preserving strategies by listing a number of design principles an algorithm has to follow in order to eliminate algorithm-based disclosure. We analyzed the achievability of privacy-enhancing rules used in practice, and found a significant gap between what these rules set out to achieve and what they actually deliver in practice. We identified a key reason for the gap to be the lack of a solution for enforcing multiple privacy rules at once, and addressed the problem by developing a novel framework called versatile publishing which achieves this based on a complete set of inference axioms for privacy rules. We developed concrete algorithms for a number of applications, including a table-decomposition based framework for privacy-preserving data publishing which achieves a standard we called the Guardian Normal Form. We also studied many related techniques over private databases that have restrictive query interfaces.     The techniques developed from this project, and their underlying theory, have broader impacts on the nation's high-tech industries. The ability to mine private data without violating the privacy of data owners (e.g., students, patients, travelers) is a must for a wide variety of corporations, universities, hospitals, and government agencies. Similarly, theoretically and empirically validated means to protect privacy in data mining would benefit all privacy-concerned individuals at large. Our findings in this project also contributed to the understanding of privacy protection for a much broader class of applications such as network security.       Last Modified: 03/02/2015       Submitted by: Nan Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
