<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Multicore-Based Parallel Disk Systems for Large-Scale Data-Intensive Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2009</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>448000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;To improve disk I/O performance, one may integrate multicore processors with parallel disk systems. Unfortunately, architectures and data processing algorithms for multicore-based parallel disk systems are still in their infancy. This motivates us to develop novel architectures for parallel disk systems, where significant multicore processing power and memory are integrated into parallel disk drives. This CAREER project provides the first parallel disk system in which large parts of data and I/O processing are offloaded to multicore processors, embedded in disk drives. The proposed techniques and mechanisms are highly adaptive to dynamic workloads with both large and small disk requests, making modern parallel disk systems leverage multicore processors for better performance and scalability.&lt;br/&gt;&lt;br/&gt;The overall objective of this CAREER Development project is to build hardware and software parallel disk architectures that put substantial multicore computing power on disks. The research consists of three basic tasks: (1) designing hardware and software architectures for multicore-based parallel disk systems, (2) developing multicore-based data processing techniques, and (3) building software performance models and an analysis toolkit. The educational plan include: (1) establishing a storage systems laboratory; (2) developing new courses; (3) implementing the concept of a mini-conference to educate students; and (4) increasing underrepresented student involvement in research activities. In addition, the project would benefit society by developing hardware and software modules for next-generation parallel disk systems, where multicore processors and disk drives are tightly integrated to boost disk I/O performance.</AbstractNarration>
<MinAmdLetterDate>07/09/2009</MinAmdLetterDate>
<MaxAmdLetterDate>05/14/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0845257</AwardID>
<Investigator>
<FirstName>Xiao</FirstName>
<LastName>Qin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiao Qin</PI_FULL_NAME>
<EmailAddress>xqin@auburn.edu</EmailAddress>
<PI_PHON>3348446327</PI_PHON>
<NSF_ID>000404935</NSF_ID>
<StartDate>07/09/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Auburn University</Name>
<CityName>Auburn</CityName>
<ZipCode>368320001</ZipCode>
<PhoneNumber>3348444438</PhoneNumber>
<StreetAddress>VPRED, Research &amp; Innovation Ctr</StreetAddress>
<StreetAddress2><![CDATA[540 Devall Drive, Suite 200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<StateCode>AL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066470972</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AUBURN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>066470972</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Auburn University]]></Name>
<CityName>Auburn</CityName>
<StateCode>AL</StateCode>
<ZipCode>368320001</ZipCode>
<StreetAddress><![CDATA[VPRED, Research &amp; Innovation]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramElement>
<ProgramElement>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1800</Code>
<Text>Research Experience for Vets</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~400000</FUND_OBLG>
<FUND_OBLG>2010~16000</FUND_OBLG>
<FUND_OBLG>2011~16000</FUND_OBLG>
<FUND_OBLG>2013~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>CAREER: Multicore-Based Parallel Disk Systems for Large-Scale Data-Intensive Computing</strong></p> <p><strong>Outcomes Report 2009-2016</strong></p> <p><strong>1. Development Outcomes.</strong> This research provides the first parallel disk system in which large parts of data and I/O processing are offloaded to multicore processors embedded in disk drives. The proposed techniques and mechanisms are highly adaptive to dynamic workloads with both large and small disk requests, making modern parallel disk systems leverage multicore processors to scale up to arbitrary size. Our research has four main strengths. First, we bridged the technology gap between multicore computing and storage systems. Second, this project addresses fundamental issues of multicore processing, thermal management, energy-efficient computing, data processing, dynamic adaptability, and software performance analysis for next-generation data-intensive computing systems. Third, we proactively address design and evaluation issues from low level disk architecture all the way up to data processing algorithms, thereby gaining new experience in how low-level disk facilities affect high-level application programming interfaces. Finally, we make a significant research progress by providing a software toolkit, which is the first toolkit of its kind, for the design and analysis of hardware and software components for multicore-based data storage systems.</p> <ol> </ol> <p class="Paragraph"><strong>2. Benefits to Other Disciplines.</strong> This project benefits other disciplines by developing hardware and software modules for next-generation large-scale data storage systems where multicore processors and disk drives are tightly integrated to boost disk I/O performance. Our proposed architectures, algorithms, and performance models are effectively applied to large-scale data-intensive computing systems, such as Hadoop clusters and Hadoop distributed file systems. Therefore, our project facilitates building hardware and software components for computing systems with large data storage capacities. We make the performance analysis toolkit publicly available to other researchers, thereby benefiting both storage systems and data-intensive computing communities.</p> <ol> </ol> <p><strong>3. Outcomes of Human-Resources Development.</strong> This NSF CAREER project makes significant improvements in learning by integrating our project with a series of courses in addition to a storage systems laboratory. We have been undertaking the following educational activities. In the past five years, we not only have developed five courses, but also have advised 12 graduate students and more than 20 senior undergraduate students in hands-on research projects. The impacts on the development of human resources contain two parts: (1) a set of cross-listed undergraduate/graduate courses (accompanied by the storage systems laboratory) on the subjects of storage systems; and (2) recruitment and retention of minority students.</p> <ol> </ol> <p><strong>Course Development. </strong>Existing curricula do not prepare students to cope with multicore computing and high-performance data processing. To fill this gap, in the past five years, we have developed both undereducated/graduate level courses (integrated with the storage systems laboratory), which are focused on data-intensive computing to support big data analytics. In these courses, students can flexibly choose one out of an array of well-specified problems designed by the PI, learn to develop applications running on multicore processors, explore storage system design issues, analyze the performance of parallel disk systems, and write technical reports to summarize their design, experiments, and observations.</p> <p><strong>Recruit and Retain Minority students. </strong>The PI&rsquo;s home department at Auburn University is particularly proud of the African American and female PhD graduates produced in the past few years. We have utilized the home department&rsquo;s infrastructure as a channel to recruit underrepresented minority and female students. To motivate and retain minority students to conduct research in the area of storage systems and energy conservation technology, we have designed a research program that offers ample opportunities to minority students to conduct research in storage systems. We have leveraged the partnership with the Alabama Power Minority Engineering Program at Auburn University to increase underrepresented student involvement in research activities in Alabama.</p> <p><strong>4. Infrastructure Outcomes.</strong> We developed a multicore-based architecture (or MOD for short) for parallel disk systems. We addressed two different configurations to deal with inter-disk and intra-disk parallelisms, respectively. The first MOD configuration (hereinafter referred to as interMOD) supports the concept of inter-disk parallelisms. The architecture consists of three major components: a host processor, a DRAM memory module, and an array of multicore-based disk subsystems. Each multicore-based disk subsystem contains an embedded multicore processor, a controller, a DRAM memory chip and a disk drive. I/O buffers with a size ranging from several megabytes to gigabytes are residing in the memory modules. The second MOD configuration (hereinafter referred to as intraMOD) is designed to cope with intra-disk parallelisms, meaning that a single multicore processor is used to coordinate, schedule, and combine results from multiple disk drives. intraMOD is similar to the interMOD architecture except that data processing in all the disks are offloaded to one embedded multicore processor. The following critical questions are raised when we introduce the concept of intraMOD.</p><br> <p>            Last Modified: 08/06/2016<br>      Modified by: Xiao&nbsp;Qin</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470516107336_Fig1Architecture--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470516107336_Fig1Architecture--rgov-800width.jpg" title="System Architecture"><img src="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470516107336_Fig1Architecture--rgov-66x44.jpg" alt="System Architecture"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The prototype of multicore-enabled smart storage. Each smart storage node in the prototype contains memory, a SATA disk drive, and a multicore-processor.</div> <div class="imageCredit">Designed by Ding and Qin</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Xiao&nbsp;Qin</div> <div class="imageTitle">System Architecture</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470515857921_Fig2Design--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470515857921_Fig2Design--rgov-800width.jpg" title="The system overview"><img src="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470515857921_Fig2Design--rgov-66x44.jpg" alt="The system overview"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A testbed for the McSD prototype. A host computing node and an McSD storagenode are connected via a fast Ethernet switch. The host node can access the disk drives inMcSD through the networked file system or NFS.</div> <div class="imageCredit">Zhiyang Ding</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Xiao&nbsp;Qin</div> <div class="imageTitle">The system overview</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470516632580_Fig3EnergyCostPrediction--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470516632580_Fig3EnergyCostPrediction--rgov-800width.jpg" title="Energy Prediction Model"><img src="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470516632580_Fig3EnergyCostPrediction--rgov-66x44.jpg" alt="Energy Prediction Model"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Energy Predictor provides the energy estimates of data transmissions handled by a particular strategy. The overall energy cost includes computing energy cost and cooling cost.</div> <div class="imageCredit">Xunfei Jiang and Xiao Qin</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Xiao&nbsp;Qin</div> <div class="imageTitle">Energy Prediction Model</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470517429993_Fig4HDFS-HC--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470517429993_Fig4HDFS-HC--rgov-800width.jpg" title="Predictive Prefetching in HDFS"><img src="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470517429993_Fig4HDFS-HC--rgov-66x44.jpg" alt="Predictive Prefetching in HDFS"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Upon the arrival of a request from the Job tracker, the predictive scheduler triggers theprefetching module that forces preload worker threads to start loading data to main memory.The following three issues must be addressed in the prefetching module.</div> <div class="imageCredit">Jiong Xie and Xiao Qin</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Xiao&nbsp;Qin</div> <div class="imageTitle">Predictive Prefetching in HDFS</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470517792280_Fig5Thermal-AwareComputing--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470517792280_Fig5Thermal-AwareComputing--rgov-800width.jpg" title="Thermal-Aware Computing"><img src="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470517792280_Fig5Thermal-AwareComputing--rgov-66x44.jpg" alt="Thermal-Aware Computing"></a> <div class="imageCaptionContainer"> <div class="imageCaption">We gathered surface temperatures of storage servers.</div> <div class="imageCredit">Tausif Muzaffar and Xiao Qin</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Xiao&nbsp;Qin</div> <div class="imageTitle">Thermal-Aware Computing</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470518460730_Fig6OffloadingORCAJiZhang--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470518460730_Fig6OffloadingORCAJiZhang--rgov-800width.jpg" title="Offload Computing"><img src="/por/images/Reports/POR/2016/0845257/0845257_10026935_1470518460730_Fig6OffloadingORCAJiZhang--rgov-66x44.jpg" alt="Offload Computing"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The execution flow of offloading PostgreSQL inORCA. The computing node handles the parser, rulesystem, and optimizer; the executor is offloaded to thestorage node.</div> <div class="imageCredit">Ji Zhang and Xiao Qin</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Xiao&nbsp;Qin</div> <div class="imageTitle">Offload Computing</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ CAREER: Multicore-Based Parallel Disk Systems for Large-Scale Data-Intensive Computing  Outcomes Report 2009-2016  1. Development Outcomes. This research provides the first parallel disk system in which large parts of data and I/O processing are offloaded to multicore processors embedded in disk drives. The proposed techniques and mechanisms are highly adaptive to dynamic workloads with both large and small disk requests, making modern parallel disk systems leverage multicore processors to scale up to arbitrary size. Our research has four main strengths. First, we bridged the technology gap between multicore computing and storage systems. Second, this project addresses fundamental issues of multicore processing, thermal management, energy-efficient computing, data processing, dynamic adaptability, and software performance analysis for next-generation data-intensive computing systems. Third, we proactively address design and evaluation issues from low level disk architecture all the way up to data processing algorithms, thereby gaining new experience in how low-level disk facilities affect high-level application programming interfaces. Finally, we make a significant research progress by providing a software toolkit, which is the first toolkit of its kind, for the design and analysis of hardware and software components for multicore-based data storage systems.   2. Benefits to Other Disciplines. This project benefits other disciplines by developing hardware and software modules for next-generation large-scale data storage systems where multicore processors and disk drives are tightly integrated to boost disk I/O performance. Our proposed architectures, algorithms, and performance models are effectively applied to large-scale data-intensive computing systems, such as Hadoop clusters and Hadoop distributed file systems. Therefore, our project facilitates building hardware and software components for computing systems with large data storage capacities. We make the performance analysis toolkit publicly available to other researchers, thereby benefiting both storage systems and data-intensive computing communities.    3. Outcomes of Human-Resources Development. This NSF CAREER project makes significant improvements in learning by integrating our project with a series of courses in addition to a storage systems laboratory. We have been undertaking the following educational activities. In the past five years, we not only have developed five courses, but also have advised 12 graduate students and more than 20 senior undergraduate students in hands-on research projects. The impacts on the development of human resources contain two parts: (1) a set of cross-listed undergraduate/graduate courses (accompanied by the storage systems laboratory) on the subjects of storage systems; and (2) recruitment and retention of minority students.    Course Development. Existing curricula do not prepare students to cope with multicore computing and high-performance data processing. To fill this gap, in the past five years, we have developed both undereducated/graduate level courses (integrated with the storage systems laboratory), which are focused on data-intensive computing to support big data analytics. In these courses, students can flexibly choose one out of an array of well-specified problems designed by the PI, learn to develop applications running on multicore processors, explore storage system design issues, analyze the performance of parallel disk systems, and write technical reports to summarize their design, experiments, and observations.  Recruit and Retain Minority students. The PI?s home department at Auburn University is particularly proud of the African American and female PhD graduates produced in the past few years. We have utilized the home department?s infrastructure as a channel to recruit underrepresented minority and female students. To motivate and retain minority students to conduct research in the area of storage systems and energy conservation technology, we have designed a research program that offers ample opportunities to minority students to conduct research in storage systems. We have leveraged the partnership with the Alabama Power Minority Engineering Program at Auburn University to increase underrepresented student involvement in research activities in Alabama.  4. Infrastructure Outcomes. We developed a multicore-based architecture (or MOD for short) for parallel disk systems. We addressed two different configurations to deal with inter-disk and intra-disk parallelisms, respectively. The first MOD configuration (hereinafter referred to as interMOD) supports the concept of inter-disk parallelisms. The architecture consists of three major components: a host processor, a DRAM memory module, and an array of multicore-based disk subsystems. Each multicore-based disk subsystem contains an embedded multicore processor, a controller, a DRAM memory chip and a disk drive. I/O buffers with a size ranging from several megabytes to gigabytes are residing in the memory modules. The second MOD configuration (hereinafter referred to as intraMOD) is designed to cope with intra-disk parallelisms, meaning that a single multicore processor is used to coordinate, schedule, and combine results from multiple disk drives. intraMOD is similar to the interMOD architecture except that data processing in all the disks are offloaded to one embedded multicore processor. The following critical questions are raised when we introduce the concept of intraMOD.       Last Modified: 08/06/2016       Submitted by: Xiao Qin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
