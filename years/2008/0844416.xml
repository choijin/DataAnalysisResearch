<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Image Super-Resolution Using Trillions of Examples</AwardTitle>
<AwardEffectiveDate>02/01/2009</AwardEffectiveDate>
<AwardExpirationDate>01/31/2014</AwardExpirationDate>
<AwardAmount>219408</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia J. Spengler</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Many important image processing tasks involve solving some type of inverse problem.  Examples include: eliminating noise, compensating for low quality optical systems, enhancing a black-and-white image with plausible colors and improving the resolution of an image.  All are ill-conditioned and so their solutions must incorporate assumptions about natural images.  Although researchers have made astounding progress on these problems in the last fifty years, a key limiting property of current techniques is that they analyze their input more or less in isolation.&lt;br/&gt;&lt;br/&gt;This research will ask the question of whether an image can be improved by evaluating trillions of image patches constructed from millions of on-line images and using the set of relevant patches to improve the quality of the original.  This work will focus on one particular inverse problem: super-resolution, or increasing the resolution of an image to reveal missing details.  The IBM/Google compute cluster in conjunction with the MapReduce programming framework will be instrumental in developing and evaluating these data-intensive algorithms.  This research will investigate scaling existing example-based techniques to use a massive training database and develop entirely new techniques that better capitalize on this amount of data by incorporating higher-level patterns in images such as scene categories and object boundaries.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/02/2009</MinAmdLetterDate>
<MaxAmdLetterDate>11/19/2012</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0844416</AwardID>
<Investigator>
<FirstName>Jason</FirstName>
<LastName>Lawrence</LastName>
<EmailAddress>jdl@cs.virginia.edu</EmailAddress>
<StartDate>02/02/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7782</Code>
<Text>CLUSTER EXPLORATORY (CLuE)</Text>
</ProgramElement>
<ProgramReference>
<Code>7782</Code>
<Text>CLUSTER EXPLORATORY (CLuE)</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
