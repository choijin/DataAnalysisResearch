<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPA-CPL: Cache-Aware Synchronization and Scheduling of Data-Parallel Programs for Multi-Core Processors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
<AwardExpirationDate>08/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>298722.00</AwardTotalIntnAmount>
<AwardAmount>355717</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Project Abstract&lt;br/&gt;&lt;br/&gt;Multi-core (parallel) processors are becoming ubiquitous. The use of such systems is key to science, engineering, finance, and other major areas of the economy. However, increased applications performance on such systems can only be achieved with advances in mapping such applications to multi-core machines. This task is made more difficult by the presence of complex memory organizations which is perhaps the key bottleneck to efficient execution, and which was not previously addressed effectively.  This research involves making the mapping of the program to the machine aware of the complexities of the memory-hierarchy in all phases of the compilation process. This will ensure a good fit between the application code and the actual machine and thereby guarantee much more effective utilization of the hardware (and thus efficient/fast execution) than was previously possible. &lt;br/&gt;&lt;br/&gt;Modern processors (multi-cores) employ increasingly complex memory hierarchies. Management of such hierarchies is becoming critical to the overall success of the compilation process since effective utilization of the memory hierarchy dominates overall performance. This research develops a new cache-hierarchy-aware compilation and runtime system (i.e., including compilation, scheduling, and static/dynamic processor mapping of parallel programs). These tasks have one thing in common: they all need accurate estimates of data element (iteration, task) computation and memory access times which are currently beyond the (cache-oblivious) state-of-the-art. This research thus develops new techniques for iteration space partitioning, scheduling, and synchronization which capture the variability due to cache, memory, and conditional statement behavior and their interaction. This research will have a broad impact on the computer industry as it will allow the ubiquitous multi-core systems of the future to be efficiently exploited by parallel programs. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/09/2008</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0811882</AwardID>
<Investigator>
<FirstName>Alexandru</FirstName>
<LastName>Nicolau</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexandru Nicolau</PI_FULL_NAME>
<EmailAddress>anicolau@uci.edu</EmailAddress>
<PI_PHON>9498244079</PI_PHON>
<NSF_ID>000108570</NSF_ID>
<StartDate>08/09/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Veidenbaum</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexander V Veidenbaum</PI_FULL_NAME>
<EmailAddress>alexv@ics.uci.edu</EmailAddress>
<PI_PHON>9498246188</PI_PHON>
<NSF_ID>000181882</NSF_ID>
<StartDate>08/09/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926977600</ZipCode>
<StreetAddress><![CDATA[160 Aldrich Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~107104</FUND_OBLG>
<FUND_OBLG>2009~113853</FUND_OBLG>
<FUND_OBLG>2010~77765</FUND_OBLG>
<FUND_OBLG>2011~56995</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In a world where muti-core processors have become ubiquitous, execution of a given program on multiple cores (processors)&nbsp;is the key to further performance and productivity improvements. To achieve this, the program has to be broken up into multiple "chunks" which can then execute concurrently on different cores. &nbsp;Such breakup is exceedingly difficult to achieve, especially while significantly increasing performance, because the meaning of the overall program has to be preserved despite the complex changes made to the code and in the presence of the extreme complexity of the organization of modern computers. For example, modern processors have increasingly complex memory organization, and the growing number of cores dramatically complicates coordination of the interaction between the various chunks executing concurrently. This makes faster execution very hard to achieve, even when done by hand by experienced users &ndash; an extraordinarily tedious, time consuming and error-prone task. This project has developed several new techniques that <em>automate</em> these very difficult tasks allowing the user to focus on the scientific challenges rather than having to deal with such low-level details. Our results demonstrate the wide applicability of the techniques, often doubling the execution speed on a variety of important scientific and engineering programs on state of the art Intel multi-core processors.&nbsp;</p><br> <p>            Last Modified: 10/15/2012<br>      Modified by: Alexandru&nbsp;Nicolau</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In a world where muti-core processors have become ubiquitous, execution of a given program on multiple cores (processors) is the key to further performance and productivity improvements. To achieve this, the program has to be broken up into multiple "chunks" which can then execute concurrently on different cores.  Such breakup is exceedingly difficult to achieve, especially while significantly increasing performance, because the meaning of the overall program has to be preserved despite the complex changes made to the code and in the presence of the extreme complexity of the organization of modern computers. For example, modern processors have increasingly complex memory organization, and the growing number of cores dramatically complicates coordination of the interaction between the various chunks executing concurrently. This makes faster execution very hard to achieve, even when done by hand by experienced users &ndash; an extraordinarily tedious, time consuming and error-prone task. This project has developed several new techniques that automate these very difficult tasks allowing the user to focus on the scientific challenges rather than having to deal with such low-level details. Our results demonstrate the wide applicability of the techniques, often doubling the execution speed on a variety of important scientific and engineering programs on state of the art Intel multi-core processors.        Last Modified: 10/15/2012       Submitted by: Alexandru Nicolau]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
