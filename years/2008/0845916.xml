<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Categorical Shape Reconstruction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2009</AwardEffectiveDate>
<AwardExpirationDate>01/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>500001.00</AwardTotalIntnAmount>
<AwardAmount>266406</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Reconstructing 3D geometric models of objects from their 2D images has been a longstanding problem in computational vision. Traditional approaches to this problem require many images taken of the same objects under different viewpoints and/or illuminations; this requirement poses a significant limitation on the operating range of these methods. For example, in consumer photography, the majority of photos are not taken with such a purpose in mind. Even in research communities, collecting multi-view/illumination image data sets is a tedious task. &lt;br/&gt;&lt;br/&gt;The PI and his team are investigating novel 3D reconstruction methods that operate on a collection of images for similar-but-not-identical objects in one category and recover a family of parameterized 3D models for the category. The underlying assumption made is that the shape distribution has only limited number degrees of freedom, many less than the image data that are available for the category. This approach exploits the abundance of images on the Internet that densely sample the appearance of similar objects in different categories, such as faces, vehicles, architectures, humans, and animals. The outcome of this research enables the creation of large-scale parameterized 3D model databases for these categories, without the need of placing all individual objects on a turntable in a controlled setting. Such databases have a wide range of impact, such as autonomous navigation, security surveillance, human computer interaction, biometrics, graphics, industry design, virtual environment, forensics, archeology, and entertainment. &lt;br/&gt;&lt;br/&gt;The PI also seeks to integrate the core idea of this research project into his education plan. In particular, his primary education goal-both in course work and in mentoring graduate students - is to emphasize a data - driven approach to vision that is both foundational and practically important. The data and tools will be disseminated in a timely fashion. Updates will be available from http://www.cs.wisc.edu/~lizhang&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/23/2009</MinAmdLetterDate>
<MaxAmdLetterDate>02/02/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0845916</AwardID>
<Investigator>
<FirstName>Li</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Li Zhang</PI_FULL_NAME>
<EmailAddress>lizhang@cs.wisc.edu</EmailAddress>
<PI_PHON>6082625083</PI_PHON>
<NSF_ID>000211090</NSF_ID>
<StartDate>02/23/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Wisconsin-Madison</Name>
<CityName>MADISON</CityName>
<CountyName/>
<ZipCode>537151218</ZipCode>
<PhoneNumber>6082623822</PhoneNumber>
<StreetAddress>21 North Park Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 6401]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>161202122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WISCONSIN SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041188822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Wisconsin-Madison]]></Name>
<CityName>MADISON</CityName>
<CountyName/>
<StateCode>WI</StateCode>
<ZipCode>537151218</ZipCode>
<StreetAddress><![CDATA[21 North Park Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~112011</FUND_OBLG>
<FUND_OBLG>2010~93049</FUND_OBLG>
<FUND_OBLG>2011~61345</FUND_OBLG>
<FUND_OBLG>2012~0</FUND_OBLG>
<FUND_OBLG>2013~0</FUND_OBLG>
</Award>
</rootTag>
