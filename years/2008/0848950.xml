<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SGER: IMR: Development of Scientific Computing in the Cloud for Research and Education</AwardTitle>
<AwardEffectiveDate>10/01/2008</AwardEffectiveDate>
<AwardExpirationDate>09/30/2009</AwardExpirationDate>
<AwardAmount>58861</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03070006</Code>
<Directorate>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<LongName>Division Of Materials Research</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Charles E. Bouldin</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Non-technical Abstract&lt;br/&gt;"Cloud Computing" is a term that has gained prominence recently to describe the use of a large body of compute resources located at many different locations. These resources are typically owned by third-party organizations and are made available to consumers in terms of the capabilities of each computer rather than the underlying hardware in use. This model proved its success almost immediately in the web services hosting domain, the principle target for most cloud service providers. Our aim here is to determine whether these same resources can be adapted for scientific purposes. Thus we propose to develop applications of cloud computing for scientific calculations and making such calculations feasible for working scientists lacking sufficient compute resources at the present. Modern scientific applications require high-performance computing facilities which are beyond the reach of many practitioners who lack both the experience and funding to complete serious scientific calculations, even though their work might be enhanced by currently feasible calculations.&lt;br/&gt;Technical Abstract&lt;br/&gt;The goal of resource virtualization is to divorce workflow from locality constraints, thereby allowing it to migrate freely amongst available physical resources. This flexibility yields tremendous scheduling advantages, as jobs can be placed and often migrated in order to make the most efficient use of available hardware. Resource virtualization is certainly nothing new. For example, Condor allows a user to access a large pool of compute resources, each one of which may be a completely unique hardware configuration. Condor's virtualization strategy is to "trick" the application into thinking that it is on the home machine. The drawback is that Condor must replace system libraries, which are architecture- and OS-specific. Hence, this strategy can be very time consuming to support. Another virtualization strategy uses ?grid computing.? Writing an application that is "grid-enabled" means writing an application with the appropriate protocols in place so that it can be moved around by the grid middleware. The disadvantage here is that most scientists do not have the background or the time to write grid-enabled programs.&lt;br/&gt;We argue that within administrative differences between Cloud and Grid computing can be found the potential for CC's most intriguing and useful advantages. For instance, Amazon?s EC2 ("Elastic Compute Cloud") provides not just another web services platform, but a fully virtual computer. An EC2 "compute instance" gives you a comprehensive set of virtual hardware, complete with disk space, RAM, and IP address. On this virtual platform, you then install your own operating system. The compelling aspect of this strategy is that it virtualizes exactly what needs to be and no more: the hardware. Doing so provides the utmost extreme in generality: if I can run an application on the desktop sitting in front of me then I can run it in the Amazon Cloud.&lt;br/&gt;The goal of this work is to test this idea and compare the performance and economy of this Amazon Cloud approach with a traditional computing cluster.</AbstractNarration>
<MinAmdLetterDate>09/16/2008</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0848950</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Rehr</LastName>
<EmailAddress>jjr@phys.washington.edu</EmailAddress>
<StartDate>09/16/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Gardner</LastName>
<EmailAddress>gardnerj@phys.washington.edu</EmailAddress>
<StartDate>09/16/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
</Institution>
<FoaInformation>
<Code>0106000</Code>
<Name>Materials Research</Name>
</FoaInformation>
<ProgramElement>
<Code>1750</Code>
<Text>MPS DMR INSTRUMENTATION</Text>
</ProgramElement>
<ProgramReference>
<Code>9161</Code>
<Text>SINGLE DIVISION/UNIVERSITY</Text>
</ProgramReference>
<ProgramReference>
<Code>9237</Code>
<Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
</ProgramReference>
<ProgramReference>
<Code>AMPP</Code>
<Text>ADVANCED MATERIALS &amp; PROCESSING PROGRAM</Text>
</ProgramReference>
</Award>
</rootTag>
