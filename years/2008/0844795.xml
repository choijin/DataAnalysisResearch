<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Semidefinite Programming with Applications in Statistical Learning</AwardTitle>
<AwardEffectiveDate>01/01/2009</AwardEffectiveDate>
<AwardExpirationDate>10/31/2011</AwardExpirationDate>
<AwardAmount>376073</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName> Elliott Francis</SignBlockName>
</ProgramOfficer>
<AbstractNarration>CAREER: Semidefinite Programming with Applications in Statistical Learning&lt;br/&gt;&lt;br/&gt;The research objective of this Faculty Early Career Development (CAREER) project is the design of a set of scalable information extraction algorithms that can turn large-scale data sets into sparse, hence interpretable, models. Many intensely active research topics such as sparse recovery in coding theory, compressed sensing and basis pursuit in signal processing, lasso and covariance selection in statistics, feature selection in machine learning, all revolve around the core idea that seeking sparse models is a meaningful way of simultaneously stabilizing statistical inference procedures, and highlighting structure in the underlying data set. More specifically, this project stems from two fundamental questions in statistical learning. One is about variable selection: Is a particular variable key to the modeling of our observations? The other question is about model structure: Is the relationship between any two variables key to explain these observations? In this spirit, this project combines results in statistical learning and information theory with recent mathematical programming techniques to produce realistic performance bounds on sparse statistical estimation and decoding algorithms. &lt;br/&gt;&lt;br/&gt;From a theoretical perspective, these results should help shed light on a fundamental tradeoff in statistics between model consistency on one hand and computational complexity on the other. Early results have clearly illustrated the significance of this tradeoff on a few particular problem instances, but systematic results are scarce. Statistical problems also pose an entirely new set of algorithmic challenges as they require solving very large-scale problems with relatively coarse precision targets, which is the exact opposite of classical assumptions in mathematical programming. The results of this project will thus improve our understanding of optimization algorithms in this context. From a practical perspective, efficient sparse inference algorithms will make the output of classic statistical techniques directly interpretable by non-experts and should help us highlight key structural patterns in complex data sets.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>12/29/2008</MinAmdLetterDate>
<MaxAmdLetterDate>03/01/2012</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0844795</AwardID>
<Investigator>
<FirstName>Alexandre</FirstName>
<LastName>d'Aspremont</LastName>
<EmailAddress>aspremon@princeton.edu</EmailAddress>
<StartDate>12/29/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
</Institution>
<FoaInformation>
<Code>0107000</Code>
<Name>Operations Research</Name>
</FoaInformation>
<ProgramElement>
<Code>5514</Code>
<Text>OPERATIONS RESEARCH</Text>
</ProgramElement>
<ProgramReference>
<Code>073E</Code>
<Text>OPTIMIZATION &amp; DECISION MAKING</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9147</Code>
<Text>GENERIC TECHNOL FOR MANUFACTURING CELLS</Text>
</ProgramReference>
<ProgramReference>
<Code>MANU</Code>
<Text>MANUFACTURING</Text>
</ProgramReference>
</Award>
</rootTag>
