<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III-COR-Small: Beyond Keyword Search: Enabling Diverse Structured Query Paradigms over Text Databases</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>448976.00</AwardTotalIntnAmount>
<AwardAmount>448976</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The text available on the Web and beyond embeds unprecedented volumes&lt;br/&gt;of valuable structured data, "hidden" in natural language. For&lt;br/&gt;example, a news article might discuss an outbreak of an infectious&lt;br/&gt;disease, reporting the name of the disease, the number of people&lt;br/&gt;affected, and the geographical regions involved.  Keyword search, the&lt;br/&gt;prevalent query paradigm for text, is often insufficiently expressive&lt;br/&gt;for complex information needs that require structured data embedded in&lt;br/&gt;text. For such needs, users (e.g., an epidemiologist compiling&lt;br/&gt;statistics, as reported in the media, on recent foodborne disease&lt;br/&gt;outbreaks in a remote country) are forced to embark in labor-intensive&lt;br/&gt;cycles of keyword-based document retrieval and manual document&lt;br/&gt;filtering, until they locate the appropriate (structured) information.&lt;br/&gt;To move beyond keyword search, this project exploits information&lt;br/&gt;extraction technology, which identifies structured data in text, to&lt;br/&gt;enable structured querying. To capture diverse user information needs&lt;br/&gt;and depart from a "one-size-fits-all" querying approach, which is&lt;br/&gt;inappropriate for this extraction-based scenario, this project&lt;br/&gt;explores a wealth of structured query paradigms: sometimes users&lt;br/&gt;(e.g., a high-school student in need of some quick examples and&lt;br/&gt;statistics for a report on recent salmonella outbreaks in developing&lt;br/&gt;countries) are after a few exploratory results, which should be&lt;br/&gt;returned fast; some other times, users (e.g., the above epidemiologist&lt;br/&gt;investigating foodborne diseases) are after comprehensive results, for&lt;br/&gt;which waiting a longer time is acceptable.  The project develops&lt;br/&gt;specialized cost-based query optimizers for each query paradigm,&lt;br/&gt;accounting for the efficiency and, critically, the result quality of&lt;br/&gt;the query execution plans.  The technology produced will assist a vast&lt;br/&gt;range of users and information needs, by enabling efficient, diverse&lt;br/&gt;interactions with text databases -- for sophisticated searching and&lt;br/&gt;data mining -- that are cumbersome or impossible with today's&lt;br/&gt;technology.  The research and educational components of the project&lt;br/&gt;will rely on -- and encourage -- a tight integration of three&lt;br/&gt;complementary Computer Science disciplines, namely, natural language&lt;br/&gt;processing, information retrieval, and databases. The project will&lt;br/&gt;also provide data sets and source code, for experimentation and&lt;br/&gt;evaluation, to the community at large over the Web (http://extraction.cs.columbia.edu/).&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/14/2008</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0811038</AwardID>
<Investigator>
<FirstName>Luis</FirstName>
<LastName>Gravano</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Luis Gravano</PI_FULL_NAME>
<EmailAddress>gravano@cs.columbia.edu</EmailAddress>
<PI_PHON>2129397064</PI_PHON>
<NSF_ID>000490154</NSF_ID>
<StartDate>08/14/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName>NEW YORK</CityName>
<StateCode>NY</StateCode>
<ZipCode>100276902</ZipCode>
<StreetAddress><![CDATA[2960 Broadway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~295153</FUND_OBLG>
<FUND_OBLG>2010~153823</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The text available on the Web and beyond embeds unprecedented volumes of  valuable structured data, "hidden" in natural language. For example, a  news article might discuss an outbreak of an infectious disease,  reporting the name of the disease, the number of people affected, and  the geographical regions involved. Traditional keyword search, the  prevalent query paradigm for text, is often insufficiently expressive  for complex information needs that require structured data embedded in  text. For such needs, users (e.g., an epidemiologist compiling  statistics, as reported in the media, on recent food-borne disease  outbreaks in a remote country) are forced to embark in labor-intensive  cycles of keyword-based document retrieval and manual document  filtering, until they locate the appropriate (structured) information.  To move beyond traditional keyword search, this project exploited  information extraction technology, which identifies structured data in  text, to enable structured querying. Furthermore, at the center of this  project was the observation that user information needs are diverse, and  "one-size-fits-all" approaches are hence inappropriate: sometimes users  (e.g., a high-school student in need of some quick examples and  statistics for a report on recent salmonella outbreaks in developing  countries) are after a few exploratory results, which should be returned  fast; some other times, users (e.g., the above epidemiologist  investigating food-borne diseases) are after comprehensive results, for  which waiting a longer time is acceptable. The project developed  specialized cost-based query optimizers that adapt to the spectrum of  user needs, accounting for the efficiency and, critically, the result  quality and completeness of the query execution plans. The technology produced is likely  to assist a vast range of users and information needs, by enabling  efficient, diverse interactions with text databases --for sophisticated  searching and data mining-- that are cumbersome or impossible with  traditional technology. The research and educational components of the  project relied on --and encouraged-- a tight integration of three  complementary Computer Science disciplines, namely, natural language  processing, information retrieval, and databases. The project provided source code for experimentation and evaluation to the community at  large over the Web at http://reel.cs.columbia.edu/.</p><br> <p>            Last Modified: 12/23/2013<br>      Modified by: Luis&nbsp;Gravano</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The text available on the Web and beyond embeds unprecedented volumes of  valuable structured data, "hidden" in natural language. For example, a  news article might discuss an outbreak of an infectious disease,  reporting the name of the disease, the number of people affected, and  the geographical regions involved. Traditional keyword search, the  prevalent query paradigm for text, is often insufficiently expressive  for complex information needs that require structured data embedded in  text. For such needs, users (e.g., an epidemiologist compiling  statistics, as reported in the media, on recent food-borne disease  outbreaks in a remote country) are forced to embark in labor-intensive  cycles of keyword-based document retrieval and manual document  filtering, until they locate the appropriate (structured) information.  To move beyond traditional keyword search, this project exploited  information extraction technology, which identifies structured data in  text, to enable structured querying. Furthermore, at the center of this  project was the observation that user information needs are diverse, and  "one-size-fits-all" approaches are hence inappropriate: sometimes users  (e.g., a high-school student in need of some quick examples and  statistics for a report on recent salmonella outbreaks in developing  countries) are after a few exploratory results, which should be returned  fast; some other times, users (e.g., the above epidemiologist  investigating food-borne diseases) are after comprehensive results, for  which waiting a longer time is acceptable. The project developed  specialized cost-based query optimizers that adapt to the spectrum of  user needs, accounting for the efficiency and, critically, the result  quality and completeness of the query execution plans. The technology produced is likely  to assist a vast range of users and information needs, by enabling  efficient, diverse interactions with text databases --for sophisticated  searching and data mining-- that are cumbersome or impossible with  traditional technology. The research and educational components of the  project relied on --and encouraged-- a tight integration of three  complementary Computer Science disciplines, namely, natural language  processing, information retrieval, and databases. The project provided source code for experimentation and evaluation to the community at  large over the Web at http://reel.cs.columbia.edu/.       Last Modified: 12/23/2013       Submitted by: Luis Gravano]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
