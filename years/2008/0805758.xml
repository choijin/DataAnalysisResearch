<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>High Dimension, Low Sample Size Discrimination</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2008</AwardEffectiveDate>
<AwardExpirationDate>05/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>105000.00</AwardTotalIntnAmount>
<AwardAmount>105000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Proposed research is motivated from the discrimination problem with high dimension, low sample size data. The investigator studies the intrinsic difficulties of the discrimination problem by exploring asymptotic geometric structure of such data. Three main activities are proposed: a) the asymptotic inconsistency of leave-one-out cross-validation. The study is expected to explain why it shall fail when the number of variables greatly exceeds the number of observations; b) the effect of the relationship between the dimensionality and the sample size on the difficulty of discrimination task; and c) a discriminant direction vector that only exists for the data with high dimension, low sample size.  The data points collapse on this direction vector and also are most separated by group labels. The investigator plans to study its theoretical and empirical properties of the procedure such as its optimality, uniqueness, and asymptotic performances.&lt;br/&gt;&lt;br/&gt;The overall goal is to investigate the nontraditional and unique challenges in high dimension, low sample size discrimination. The proposed approach may be regarded atypical, but it is more relevant to the problem itself. The applications of proposed research include text document classification such as Spam email filter, medical imaging such as functional magnetic resonance imaging, and bioinformatics such as microarray gene expression and proteomics.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/10/2008</MinAmdLetterDate>
<MaxAmdLetterDate>03/03/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0805758</AwardID>
<Investigator>
<FirstName>Jeongyoun</FirstName>
<LastName>Ahn</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeongyoun Ahn</PI_FULL_NAME>
<EmailAddress>jyahn@uga.edu</EmailAddress>
<PI_PHON>7065423433</PI_PHON>
<NSF_ID>000251516</NSF_ID>
<StartDate>06/10/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Georgia Research Foundation Inc</Name>
<CityName>ATHENS</CityName>
<ZipCode>306021589</ZipCode>
<PhoneNumber>7065425939</PhoneNumber>
<StreetAddress>310 East Campus Rd</StreetAddress>
<StreetAddress2><![CDATA[Tucker Hall Room 409]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004315578</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Georgia]]></Name>
<CityName>Athens</CityName>
<StateCode>GA</StateCode>
<ZipCode>306021589</ZipCode>
<StreetAddress><![CDATA[310 East Campus Rd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~34163</FUND_OBLG>
<FUND_OBLG>2009~34992</FUND_OBLG>
<FUND_OBLG>2010~35845</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project contributes the statistics community by increasing awareness of various challenges in the analysis of data sets with more variables than the number of observations. Such data sets can have some counter-intuitive characteristics unlike traditional low-dimensional multivariate data sets in common textbooks. For example in classification, the discriminant direction vector with zero training error can be a good example such that something seemingly artificial&nbsp;can work surprisingly&nbsp;well in high dimensional settings.&nbsp;</p> <p>This project also aims to contribute the field by developing data&nbsp;analysis methods suitable&nbsp;for high dimension, low sample size data, when traditional approaches can no longer work. The new&nbsp;classification methods&nbsp;that controls the variance of the projected data can be viewed as a&nbsp;good example.</p> <p>We also have focused on some important high dimensional data&nbsp;sets, such as&nbsp;astronomy data and functional magnetic resonance imaging data, since these types of data are special even in high dimensional&nbsp;data analysis problems.&nbsp;In astronomy the study of variable stars i.e., stars characterized by showing significant variationin their brightness over time has made crucial contributions to our understanding of manyfields, from stellar birth and evolution to the calibration of the extragalactic distance scale. We performed a time series analysis of the periods between maximum brightness ofa group of 378 long period variable stars.&nbsp;</p> <p>Data from functional Magnetic Resonance Imaging (fMRI) have many (around 60,000) dimensions(voxels) that are spatially correlated and typically very small sample sizes, often less than 20, while time-dependent observations are measured. In this way, the analysis offMRI data is one of the most important high dimensional data analysis. We conducted an investigation of the null hypothesis distribution for functional magnetic resonance imaging(fMRI) data using multi-scale analysis.</p> <p>One of the most important lessons we have learned during the project&nbsp;is that high-dimensionality may not always give us challenges. The surplus of the&nbsp;dimensions (variables)&nbsp;can be translated into more leverage in terms of the modes of&nbsp;regularization or model&nbsp;selection.&nbsp;Another important lesson is that relevant non-classical&nbsp;asymptotics for increasing&nbsp;dimensionality is crucial to justify the methods.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/25/2012<br>      Modified by: Jeongyoun&nbsp;Ahn</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project contributes the statistics community by increasing awareness of various challenges in the analysis of data sets with more variables than the number of observations. Such data sets can have some counter-intuitive characteristics unlike traditional low-dimensional multivariate data sets in common textbooks. For example in classification, the discriminant direction vector with zero training error can be a good example such that something seemingly artificial can work surprisingly well in high dimensional settings.   This project also aims to contribute the field by developing data analysis methods suitable for high dimension, low sample size data, when traditional approaches can no longer work. The new classification methods that controls the variance of the projected data can be viewed as a good example.  We also have focused on some important high dimensional data sets, such as astronomy data and functional magnetic resonance imaging data, since these types of data are special even in high dimensional data analysis problems. In astronomy the study of variable stars i.e., stars characterized by showing significant variationin their brightness over time has made crucial contributions to our understanding of manyfields, from stellar birth and evolution to the calibration of the extragalactic distance scale. We performed a time series analysis of the periods between maximum brightness ofa group of 378 long period variable stars.   Data from functional Magnetic Resonance Imaging (fMRI) have many (around 60,000) dimensions(voxels) that are spatially correlated and typically very small sample sizes, often less than 20, while time-dependent observations are measured. In this way, the analysis offMRI data is one of the most important high dimensional data analysis. We conducted an investigation of the null hypothesis distribution for functional magnetic resonance imaging(fMRI) data using multi-scale analysis.  One of the most important lessons we have learned during the project is that high-dimensionality may not always give us challenges. The surplus of the dimensions (variables) can be translated into more leverage in terms of the modes of regularization or model selection. Another important lesson is that relevant non-classical asymptotics for increasing dimensionality is crucial to justify the methods.           Last Modified: 06/25/2012       Submitted by: Jeongyoun Ahn]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
