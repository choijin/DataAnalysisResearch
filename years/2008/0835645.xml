<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CDI-Type II: Collaborative Research: Cyber Enhancement of Spatial Cognition for the Visually Impaired</AwardTitle>
    <AwardEffectiveDate>09/15/2008</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>345000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Richard Voyles</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Wayfinding is an essential capability for any person who wishes to have an independent life-style. It requires successful execution of several tasks including navigation and object and place recognition, all of which necessitate accurate assessment of the surrounding environment. For a visually-impaired person these tasks may be exceedingly difficult to accomplish and there are risks associated with failure in any of these. Guide dogs and white canes are widely used for the purpose of navigation and environment sensing, respectively. The former, however, has costly and often prohibitive training requirements, while the latter can only provide cues about obstacles in one?s surroundings. Human performance on visual information dependent tasks can be improved by sensing which provides information and environmental cues, such as position, orientation, local geometry, object description, via the use of appropriate sensors and sensor fusion algorithms. Most work on wayfinding aids has focused on outdoor environments and has led to the development of speech-enabled GPS-based navigation systems that provide information describing streets, addresses and points of interest. In contrast, the limited technology that is available for indoor navigation requires significant modification to the building infrastructure, whose high cost has prevented its wide use. &lt;br/&gt;&lt;br/&gt;This proposal adopts a multi-faceted approach for solving the indoor navigation problem for people with limited vision. It leverages expertise from robotics, computer vision, and blind spatial cognition with behavioral studies on interface design to guide the discovery of information requirements and optimal delivery methods for an indoor navigation system. Designing perception and navigation algorithms, implemented on miniature-size commercially-available hardware, while explicitly considering the spatial cognition capabilities of the visually impaired, will lead to the development of indoor navigation systems that will assist blind people in their wayfinding tasks while facilitating cognitive-map development.</AbstractNarration>
    <MinAmdLetterDate>09/15/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>06/11/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0835645</AwardID>
    <Investigator>
      <FirstName>Roberto</FirstName>
      <LastName>Manduchi</LastName>
      <EmailAddress>manduchi@soe.ucsc.edu</EmailAddress>
      <StartDate>09/15/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Santa Cruz</Name>
      <CityName>Santa Cruz</CityName>
      <ZipCode>950641077</ZipCode>
      <PhoneNumber>8314595278</PhoneNumber>
      <StreetAddress>1156 High Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
  </Award>
</rootTag>
