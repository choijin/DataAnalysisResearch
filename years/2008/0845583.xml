<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Adaptive Concurrency Management for Multicore Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/15/2009</AwardEffectiveDate>
<AwardExpirationDate>01/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>459903.00</AwardTotalIntnAmount>
<AwardAmount>491903</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Career: Adaptive Concurrency Management for Multicore Computing&lt;br/&gt;Abstract: Given the increasing emphasis on multicore computing, concurrency management is likely to be one of the key techniques to unleash the power of multicore processors. Concurrency is the capability of executing multiple tasks simultaneously, but it is often difficult to achieve due to data and control dependencies. The proposed research aims to optimize thread-level concurrency for multicore applications. It will investigate architecture features for efficient shared data accesses, and use these features to dynamically control the advancement of concurrent threads and the allocation of CPU resources. The project will target computing platforms of immediate concern and the techniques will be made accessible to the programming community by integrating them into existing programming tools. The project will also extend theoretical results towards efficient multi-threaded algorithms. The proposed research project is expected to significantly improve the performance of multicore computing and expand the range of applications that can benefit from such processor platforms. It is expected to facilitate efficient multicore processing for computation-demanding applications in science, engineering, and business.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/13/2009</MinAmdLetterDate>
<MaxAmdLetterDate>03/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0845583</AwardID>
<Investigator>
<FirstName>Bo</FirstName>
<LastName>Hong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bo Hong</PI_FULL_NAME>
<EmailAddress>bohong@gatech.edu</EmailAddress>
<PI_PHON>4048949485</PI_PHON>
<NSF_ID>000486099</NSF_ID>
<StartDate>02/13/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320420</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Programs]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>4090</Code>
<Text>ADVANCED NET INFRA &amp; RSCH</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~116178</FUND_OBLG>
<FUND_OBLG>2010~115161</FUND_OBLG>
<FUND_OBLG>2011~168222</FUND_OBLG>
<FUND_OBLG>2012~8000</FUND_OBLG>
<FUND_OBLG>2013~84342</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>This research project aims to develop a systematic framework to automatically</span></p> <p><span>manage and optimize the concurrency of parallel applications.&nbsp; In this project,</span></p> <p><span>we have (1) developed concurrency management strategies for transactional</span></p> <p><span>memory, (2) developed multi-threaded algorithms with applications in network</span></p> <p><span>flow, protein-DNA docking, and </span><span>seismeistic</span><span> data management, (3) designed</span></p> <p><span>methods to explore parallelism in </span><span>GPU</span><span>-based </span><span>HPC</span><span> systems, (4) developed</span></p> <p><span>strategies to manage concurrency and data locality in distributed computing</span></p> <p><span>systems. These research results allow a much wider range of applications to</span></p> <p><span>benefit from parallel and distributed computing. For example, we have worked</span></p> <p><span>with our collaborators and have shown that </span><span>GPU</span><span> can be used to significantly</span></p> <p><span>accelerate protein-DNA docking and seismic data analysis. These </span><span>HPC</span></p> <p><span>applications will benefit from our study on </span><span>GPU</span><span>-assisted systems. Other</span></p> <p><span>applications, such as Big Data analytics will benefit from our study of data</span></p> <p><span>management. As most of such Big Data applications are data intensive, the</span></p> <p><span>improvement of data input throughput will have a significant impact on such</span></p> <p><span>applications, and subsequently enabling more advanced scientific explorations.</span></p> <p><span>Besides scientific and engineering applications that will benefit from the</span></p> <p><span>improve processing speed, our research results will have help improve the</span></p> <p><span>management of distributed computing systems.</span></p> <p><span>&nbsp;</span></p> <p><span>Research in this project has produced educational materials for multiple</span></p> <p><span>courses at the host institute in the discipline of computer science and</span></p> <p><span>engineering. And participation of student research, especially those from</span></p> <p><span>underrepresented groups, has prepared them for potential science and</span></p> <p><span>engineering&nbsp; career.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 10/13/2017<br>      Modified by: Bo&nbsp;Hong</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This research project aims to develop a systematic framework to automatically  manage and optimize the concurrency of parallel applications.  In this project,  we have (1) developed concurrency management strategies for transactional  memory, (2) developed multi-threaded algorithms with applications in network  flow, protein-DNA docking, and seismeistic data management, (3) designed  methods to explore parallelism in GPU-based HPC systems, (4) developed  strategies to manage concurrency and data locality in distributed computing  systems. These research results allow a much wider range of applications to  benefit from parallel and distributed computing. For example, we have worked  with our collaborators and have shown that GPU can be used to significantly  accelerate protein-DNA docking and seismic data analysis. These HPC  applications will benefit from our study on GPU-assisted systems. Other  applications, such as Big Data analytics will benefit from our study of data  management. As most of such Big Data applications are data intensive, the  improvement of data input throughput will have a significant impact on such  applications, and subsequently enabling more advanced scientific explorations.  Besides scientific and engineering applications that will benefit from the  improve processing speed, our research results will have help improve the  management of distributed computing systems.     Research in this project has produced educational materials for multiple  courses at the host institute in the discipline of computer science and  engineering. And participation of student research, especially those from  underrepresented groups, has prepared them for potential science and  engineering  career.          Last Modified: 10/13/2017       Submitted by: Bo Hong]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
