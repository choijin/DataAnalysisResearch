<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Programming Interfaces and Hardware Designs for a Polymorphic Multicore Cache Architecture</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/15/2009</AwardEffectiveDate>
<AwardExpirationDate>01/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hong Jiang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;The semiconductor industry has hit a wall - chip-level power and cooling constraints have slowed the march of clock frequency, forcing industry to instead bet on multicore to provide energy-efficient performance scalability. Although the multicore trend poses daunting challenges for application developers, it also creates new opportunities unavailable in traditional multi-chip multiprocessors: the drastic change in the relative costs of on-chip communication and computation enable application designs with tightly-coupled threads and frequent sharing that would prove latency- and bandwidth-prohibitive in traditional multiprocessors. Unfortunately, current multicore memory systems are inflexible and poorly-suited to support coordinated execution, as they provide no direct means for core-to-core communication or to optimize data placement on chip. Moreover, intra-chip access patterns vary drastically across applications - there is no one-size-fits-all static cache architecture. &lt;br/&gt;&lt;br/&gt;To address these deficiencies, this project seeks to develop a Polymorphic Multicore Cache Architecture (PMCA) - a modular on-chip cache design where software configures primitive hardware mechanisms to provide a cache architecture suited to a specific workload. The PMCA concept will be pursued along three fronts: First, PMCA?s architectural interface and behavioral design through a full system, cycle accurate simulation will be conducted. Second,language level constructs, software management policies, and virtualization of PMCA through FPGA based functional emulation will be investigated. Third, trade-offs in performance, area, and power for various designs will be examined.</AbstractNarration>
<MinAmdLetterDate>02/06/2009</MinAmdLetterDate>
<MaxAmdLetterDate>06/17/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0845157</AwardID>
<Investigator>
<FirstName>Thomas</FirstName>
<LastName>Wenisch</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thomas Wenisch</PI_FULL_NAME>
<EmailAddress>twenisch@umich.edu</EmailAddress>
<PI_PHON>7346477959</PI_PHON>
<NSF_ID>000110966</NSF_ID>
<StartDate>02/06/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Regents of the University of Michigan - Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091274</ZipCode>
<StreetAddress><![CDATA[3003 South State St. Room 1062]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~78497</FUND_OBLG>
<FUND_OBLG>2010~81666</FUND_OBLG>
<FUND_OBLG>2011~77843</FUND_OBLG>
<FUND_OBLG>2012~79677</FUND_OBLG>
<FUND_OBLG>2013~82317</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The semiconductor industry has hit a wall - chip-level power and cooling constraints have slowed the march of clock frequency, forcing industry to instead bet on multicore and heterogeneous accelerators to provide energy-efficient performance scalability. Although the multicore and accelerator trends posedaunting challenges for application developers, they also creates new opportunities unavailable in traditional multi-chip multiprocessors: the drastic change in the relative costs of on-chip communication and computation enable application designs with tightly-coupled threads and frequent sharing that would prove latency- and bandwidth-prohibitive in traditional multiprocessors. Unfortunately, current memory systems are inflexible and poorly-suited to support coordinated execution, as they provide no direct means for core-to-core communication or to optimize data placement on chip or among heterogeneous memories. Moreover, intra-chip access patterns vary drastically across applications - there is no one-size-fits-all memory system design.&nbsp;</p> <p>In this project, Prof. Thomas Wenisch of the University of Michigan and his NSF-funded project team have developed new mechanisms for managing memory in large-scale server systems. &nbsp;The project has developed a range of computer memory system innovations, including enhancements targeted at key infrastructure components of large-scale internet services, like Facebook or Twitter, and fundamental enhancements to memory systems that combine a traditional processor with various kinds of hardware accelerators, which are well suited for scientific computing applications. &nbsp;The project has also supported the developed of infrastructure and course materials for EECS 570 "Parallel Computer Archirtecture," a graduate course offered annually at the University of Michigan, and led to two patents, which have been licensed and commercialized by ARM, Ltd.</p><br> <p>            Last Modified: 05/06/2015<br>      Modified by: Thomas&nbsp;Wenisch</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The semiconductor industry has hit a wall - chip-level power and cooling constraints have slowed the march of clock frequency, forcing industry to instead bet on multicore and heterogeneous accelerators to provide energy-efficient performance scalability. Although the multicore and accelerator trends posedaunting challenges for application developers, they also creates new opportunities unavailable in traditional multi-chip multiprocessors: the drastic change in the relative costs of on-chip communication and computation enable application designs with tightly-coupled threads and frequent sharing that would prove latency- and bandwidth-prohibitive in traditional multiprocessors. Unfortunately, current memory systems are inflexible and poorly-suited to support coordinated execution, as they provide no direct means for core-to-core communication or to optimize data placement on chip or among heterogeneous memories. Moreover, intra-chip access patterns vary drastically across applications - there is no one-size-fits-all memory system design.   In this project, Prof. Thomas Wenisch of the University of Michigan and his NSF-funded project team have developed new mechanisms for managing memory in large-scale server systems.  The project has developed a range of computer memory system innovations, including enhancements targeted at key infrastructure components of large-scale internet services, like Facebook or Twitter, and fundamental enhancements to memory systems that combine a traditional processor with various kinds of hardware accelerators, which are well suited for scientific computing applications.  The project has also supported the developed of infrastructure and course materials for EECS 570 "Parallel Computer Archirtecture," a graduate course offered annually at the University of Michigan, and led to two patents, which have been licensed and commercialized by ARM, Ltd.       Last Modified: 05/06/2015       Submitted by: Thomas Wenisch]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
