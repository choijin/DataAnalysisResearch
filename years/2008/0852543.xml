<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SGER:   Investigating Degrading Failure Recovery in Large Scale, Heavily Utilized Disk Storage Systems</AwardTitle>
<AwardEffectiveDate>09/15/2008</AwardEffectiveDate>
<AwardExpirationDate>02/28/2010</AwardExpirationDate>
<AwardTotalIntnAmount>130746.00</AwardTotalIntnAmount>
<AwardAmount>130746</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Barry I. Schneider</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Abstract&lt;br/&gt;OCI 0852543&lt;br/&gt;Garth Gibson, Principal Investigator&lt;br/&gt;Carnegie Mellon University&lt;br/&gt;SGER: Investigating Degrading Failure Recovery in Large Scale, Heavily Utilized Disk Storage Systems&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This SGER proposal responds to an interest from NARA in File Systems and I/O research, specifically, in methods and factors contributing to fault tolerant, highly scalable, sustained I/O for very large disk based systems. The P.I. had predicted in a workshop the dangers of increasing disk sizes in ever larger disk storage systems.&lt;br/&gt;&lt;br/&gt;In order to better understand the implication of this speculation, CMU will explore the implications on performance and reliability in large scale disk storage systems of the increasing size of magnetic disks, causing the periods of degraded performance during failure recovery to grow, and the scaling of stored data capacity, causing the total number of components that might fail to grow. The P.I. and his team will explore different strategies for trading off capacity overhead, performance overhead and data reliability, for example, slower recovery in more redundant data, faster recovery with more performance degradation, and novel uses of redundancy for point solutions of specific failure modes.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/15/2008</MinAmdLetterDate>
<MaxAmdLetterDate>09/15/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0852543</AwardID>
<Investigator>
<FirstName>Garth</FirstName>
<LastName>Gibson</LastName>
<EmailAddress>garth@cs.cmu.edu</EmailAddress>
<StartDate>09/15/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Nowoczynski</LastName>
<EmailAddress>pauln@psc.edu</EmailAddress>
<StartDate>09/15/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>H369</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
