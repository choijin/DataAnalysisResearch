<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Exploring the Uncanny Valley</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2008</AwardEffectiveDate>
<AwardExpirationDate>07/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>350000.00</AwardTotalIntnAmount>
<AwardAmount>362000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Rosenblum</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;Exploring the Uncanny Valley&lt;br/&gt;&lt;br/&gt;In 1970, an eminent Japanese roboticist, Masahiro Mori, proposed the "uncanny valley" curve to describe the emotional response of humans to nonhuman agents. His hypothesis was that as an agent is made more humanlike, the observer's familiarity does not increase as one would intuit, but falls into a ``valley of eeriness,'' when the agent closely yet imperfectly impersonates a human being. With progress in computer graphics allowing increasingly realistic rendering of forms and motion, the uncanny valley has become a high-stakes concern of the entertainment industry. The uncanny valley hypothesis also poses a fundamental scientific question:  What do people perceive when they view human motion and how are those perceptions affected by realistic, nearly realistic, or caricatured human motion? With the growing accuracy of functional magnetic resonance imaging (fMRI) measurement and analysis techniques, there is a new tool with which to answer these questions. The PIs are using fMRI, eye tracking, and traditional perceptual metrics to explore the existence of and causes of the uncanny valley.  Motion capture data (including skin and muscle deformation), keyframed animations, high speed video, and clips from feature films are used to construct a set of stimuli with which to answer these questions.&lt;br/&gt;&lt;br/&gt;The outcomes of this research is a greater understanding of the perception of animated human motion which will inform practitioners and researchers in computer graphics and allow them to focus on the aspects of human animation that will have the greatest impact. The research has broad impacts on science and society.   For example, the work conducted here has applicability to the scientific understanding of autism, a devastating neurodevelopmental disorder that effects social functioning in multiple domains including the perception of other people's actions and intentions.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/08/2008</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0811450</AwardID>
<Investigator>
<FirstName>Jessica</FirstName>
<LastName>Hodgins</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jessica Hodgins</PI_FULL_NAME>
<EmailAddress>jkh@cs.cmu.edu</EmailAddress>
<PI_PHON>4122686795</PI_PHON>
<NSF_ID>000316710</NSF_ID>
<StartDate>07/08/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Pelphrey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin Pelphrey</PI_FULL_NAME>
<EmailAddress>kpelphrey@cmu.edu</EmailAddress>
<PI_PHON>4122688746</PI_PHON>
<NSF_ID>000252515</NSF_ID>
<StartDate>07/08/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~350000</FUND_OBLG>
<FUND_OBLG>2010~12000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Animated human characters that move and are rendered in such a way<br />as to appear human-like but yet are not quite 'right' have been<br />hypothesized to fall into an Uncanny Valley where the viewer's<br />emotional response is repulsion rather than empathy or emotional<br />engagement.&nbsp;&nbsp; During the time frame of this grant, we completed a<br />number of studies that explore various aspects of this phenomenon:<br />the saliency of face and body motions (perceptual), the role of<br />intention in perception of human and non-humanoid characters (fMRI),<br />voice and motion synchronization, the perception of<br />hand motions and subtle facial motions, and the effect of exaggerated or<br />damped facial motion.&nbsp;&nbsp; Taken together these<br />studies begin to allow us to form a picture of what is happening<br />with the Uncanny Valley and to provide guidelines for the construction<br />of models and motion for the animated characters and interactive avatars.<br /><br />In both the voice synchronization and the finger perception studies,<br />we learned that changes to the motion can affect the perceived<br />content of the motion without being explicitly recognized as errors.<br />In the study of face and body motions, we learned that the emotional<br />content of an animated sequence can also be affected by errors in<br />the motion.&nbsp; In the facial motion studies, we learned that remarkably<br />small errors in facial motion are detectable. For exampe the shape of<br />the trajectory for the eyelid motion during blinking is perceived<br />as incorrect when it is altered in apparently minor ways.<br /><br /></p><br> <p>            Last Modified: 03/11/2013<br>      Modified by: Jessica&nbsp;Hodgins</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Animated human characters that move and are rendered in such a way as to appear human-like but yet are not quite 'right' have been hypothesized to fall into an Uncanny Valley where the viewer's emotional response is repulsion rather than empathy or emotional engagement.   During the time frame of this grant, we completed a number of studies that explore various aspects of this phenomenon: the saliency of face and body motions (perceptual), the role of intention in perception of human and non-humanoid characters (fMRI), voice and motion synchronization, the perception of hand motions and subtle facial motions, and the effect of exaggerated or damped facial motion.   Taken together these studies begin to allow us to form a picture of what is happening with the Uncanny Valley and to provide guidelines for the construction of models and motion for the animated characters and interactive avatars.  In both the voice synchronization and the finger perception studies, we learned that changes to the motion can affect the perceived content of the motion without being explicitly recognized as errors. In the study of face and body motions, we learned that the emotional content of an animated sequence can also be affected by errors in the motion.  In the facial motion studies, we learned that remarkably small errors in facial motion are detectable. For exampe the shape of the trajectory for the eyelid motion during blinking is perceived as incorrect when it is altered in apparently minor ways.         Last Modified: 03/11/2013       Submitted by: Jessica Hodgins]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
