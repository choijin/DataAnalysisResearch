<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Symbolic Inference for Very Large Datasets</AwardTitle>
    <AwardEffectiveDate>08/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>150000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gabor J. Szekely</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Datasets that are complex with the data themselves "complex", and/or with structures that impose complications) are becoming more and more routine with the impact of contemporary computer capacity. What is not routine is how to analyse these data. Indeed, the data "collection" is fast outpacing the ability to analyse them. It is evident that, even in those situations where in theory available methodology might seem to apply, routine use of such statistical techniques is often inappropriate. Some methods (e.g. squashing) take representative "`samples"' and then use standard procedures on the sampled data. Others seek sub/patterns (e.g., data mining) and then try to focus on the data behind those patterns. Others aggregate the data in some meaningful way. One such aggregation method produces so-called symbolic data (such as lists, intervals, distributions, etc.). An advantage of symbolic data is that unlike those in sampled sets, a symbolic-value retains all the original data, while simultaneously reducing the size of the dataset. Further while the massive datasets encountered today are one source of symbolic data, there are many data that are naturally symbolic (be these small or large datasets). All are better analysed by methods developed for symbolic data. The investigator addresses three major areas. One area is classification trees. Here, distances measures for interval and histogram-valued data are developed; and then they are used in new algorithms which extend the classical CART methodolgy to symbolic data. Secondly, regression methods, in particular, logistic regression and Cox's proportional hazard models, are adapted to symbolic data. Finally, factor analysis and principal component methodoly is developed for symbolic data. &lt;br/&gt;&lt;br/&gt;With the impact of contemporary computer capacity, datasets that are complex with the data themselves "complex" are becoming more ubiquitous. Yet those same computers often lack the capacity to analyse these massive datasets. Therefore, new ways to handle them must be developed. One way is to aggregate the data in a scientifically meaningful way (with the actual aggregation being dictated by the question at hand). Such aggregation will necessarily produce data that form lists, intervals, histograms, etc. The investigator develops new methodologies for interval data in three major areas, classification trees after rst nding distance measures for intervals and histograms, regression methods especially logistic regression, and factor analysis. The results are applied to data. A synergism is achieved by the integration of mathematical/ statistical/computational arenas in addressing real issues encountered by contemporary datasets. The outcomes cannot be achieved by the tools of just one of these disciplines but needs all three. The new methodologies will have wide applicability to those datasets generated in, e.g., meteorology, environmental science, social sciences, health-care programs, industry, and the like, well beyond those motivating the work. This will have enormous impact on US science. Further since doctoral students will be engaged as collaborators and since international researchers will be active participants, the research helps in the internationalization of the next and future generation of US scientists.</AbstractNarration>
    <MinAmdLetterDate>08/01/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>08/01/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0805245</AwardID>
    <Investigator>
      <FirstName>Lynne</FirstName>
      <LastName>Billard</LastName>
      <EmailAddress>lynne@stat.uga.edu</EmailAddress>
      <StartDate>08/01/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Georgia Research Foundation Inc</Name>
      <CityName>ATHENS</CityName>
      <ZipCode>306021589</ZipCode>
      <PhoneNumber>7065425939</PhoneNumber>
      <StreetAddress>310 East Campus Rd</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
  </Award>
</rootTag>
