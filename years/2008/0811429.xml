<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPA-DA: Formal Methods for Multi-core Shared Memory Protocol Design</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2008</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>298000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
<PO_EMAI>sabasu@nsf.gov</PO_EMAI>
<PO_PHON>7032927843</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Title: Formal Methods for Multi-core Shared Memory Protocol Design&lt;br/&gt;PI: Ganesh Gopalakrishnan&lt;br/&gt;Inst: University of Utah&lt;br/&gt;NSF Proposal Number: 0811429 &lt;br/&gt;&lt;br/&gt;ABSTRACT:&lt;br/&gt;The human society crucially depends on computing devices: from embedded computers in phones to peta-scale computing systems that can perform a million billion multiplications every second, and help simulate everything from car crashes to hurricanes. The performance of a computer must increase each year, without which the information-based human society will cease to advance. Unfortunately, past methods to increase the performance of a computer ? namely increasing the clock frequency and the functional unit complexity -- cease to be effective. These techniques now produce only a miniscule performance increase, while causing huge increases in the energy consumption. Already computing equipments consume more than 5% of the nation's electricity! The only available energy-efficient method of increasing computer performance is through the use of multiple central processing units (CPUs). Unfortunately, such organizations (called "multi-core CPUs") require that the accesses to the central memory be extremely efficient - requiring the use of highly complex protocols - called cache coherence protocols.  Unfortunately these protocols must be hand-crafted for high performance, and hence are extremely error-prone. Previous methods to verify cache coherence protocols were already at the limits of the capabilities of verification tools. With the advent of multi-core CPUs, the complexity has become out of reach of all published techniques. The PI and his team are the only academic group to have developed techniques to verify, using mathematically sound computer algorithms, hierarchical multi-core CPU cache coherence protocols.  Unfortunately, their methods to date have involved expert humans and often cause considerable tedium.  The proposed methods in this proposal are expected to: (1) reduce the burden of verifying cache coherence protocols, and (2) help bridge two central abstraction gaps, thus minimizing the chances of errors in microprocessors: (i) high-level to low-level behavioral modeling gap, and (ii) the low behavioral level to hardware implementation level gap.  It will help train valuable manpower - including undergraduates and under-represented groups. It will help sustain the technological momentum of the US, as the availability of sustained high performance computing power is no less important to the nation than its other basic needs such as water, clean air, and energy.  The verification tools developed in this project are expected to be technology transferred to the computer industry.  Last but not least, the students trained in this project will join the national and international high-technology labor force.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/27/2008</MinAmdLetterDate>
<MaxAmdLetterDate>06/13/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0811429</AwardID>
<Investigator>
<FirstName>Ganesh</FirstName>
<LastName>Gopalakrishnan</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ganesh L Gopalakrishnan</PI_FULL_NAME>
<EmailAddress>ganesh@cs.utah.edu</EmailAddress>
<PI_PHON>8015813568</PI_PHON>
<NSF_ID>000160895</NSF_ID>
<StartDate>06/27/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<StreetAddress2><![CDATA[Second Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009095365</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF UTAH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009095365</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Utah]]></Name>
<CityName>SALT LAKE CITY</CityName>
<StateCode>UT</StateCode>
<ZipCode>841128930</ZipCode>
<StreetAddress><![CDATA[75 S 2000 E]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramElement>
<ProgramReference>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~223214</FUND_OBLG>
<FUND_OBLG>2009~16000</FUND_OBLG>
<FUND_OBLG>2010~42786</FUND_OBLG>
<FUND_OBLG>2012~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br />This research targeted the fundamental challenge of ensuring that<br />computing systems that are optimized for performance are also devoid<br />of logical errors in their design. Beginning around 2005, computer<br />manufacturers catering to virtually all application classes have<br />adopted multiple central processing units (CPUs) in their design.<br />Adopting this style of multicores is the only foreseeable way<br />toward achieving high computing performance at low energy costs.<br />Unfortunately, this massive-scale usage of parallel processing<br />requires a significant amount of programmer training, <br />new methods to program safely without losing efficiency, <br />as well as incisive verification tools to detect and root-cause<br />correctness errors.<br /><br />Our research made contributions in these regards in four <br />specific areas.<br /><br />VERIFICATION OF HIERARCHICAL CACHE COHERENCE PROTOCOLS<br /><br />Multicore systems are often designed by employing a small cluster<br />of CPU cores that are tightly interconnected and a hierarchical <br />arrangement of such clusters into a larger ensemble. It is crucial<br />to ensure a consistent view of memory both within the cluster as<br />well as across the cluster. This is achieved by using suitable cache<br />coherence protocols.&nbsp; Since the memory sharing patterns as<br />well as electrical distances are different between the CPUs within<br />a cluster as well as across the cluster, different cache coherence<br />protocols are employed within a cluster and spanning multiple <br />clusters. <br /><br />Our research developed techniques for developing ``overlapping<br />abstractions.'' Intuitively, the degree of coupling between the<br />the intra-cluster and intercluster protocols is limited. This<br />observation helps us develop two simpler models, one simplifying<br />the intra-cluster protocol and the other simplifying the inter-cluster<br />model. We successfully demonstrated that non-trivial hierarchical<br />cache coherence protocols can be verified using this approach.<br /><br />A PROVER OF USER GPU PROGRAMS<br /><br />The use of multiple CPU cores takes two forms in practice: (1) the use<br />of traditional CPU cores that are eficient at handling control-flow,<br />and (2) the use of specialized processors that are oriented toward <br />large-scale data processing, and controlled by traditional CPUs for <br />offloading computations. A popular type of data-oriented processor<br />suitable for use in the ``offload model'' is the Graphical Processing<br />Unit (GPU). When we began our research on GPU programming,<br />it came to our attention that no verification methods that offered firm<br />guarantees were available for GPUs. We developed a symbolic analysis<br />method that employed the power of symbolic execution and invariant<br />generation to ensure that GPU programs do not have insidious bugs<br />such as data racs (conflicting read/write accesses that led to<br />unpredictable answers).<br /><br />VERIFICATION METHODS FOR MULTICORE COMMUNICATION APIS<br /><br />As system complexity escalates, the need for multicore chips<br />that communicate using both message passing and shared memory also<br />escalates. A recent standardization effort by the industry has<br />led to the creation of the multicore communications API (MCAPI). <br />Our research helped investigate these proposed APIs and our efforts <br />led to the creation of a dynamic analysis tool called MCC that<br />orchestrates concurrency in these two regimes<br /><br />AN EXTENSIBLE UTAH MULTICORE DESIGN<br /><br />The last component of our research on multicore programming and<br />correctness analysis was centered around building an actual multicore<br />system that communicates as per MCAPI and can be made to operate on <br />field programmable gate arrays (FPGA). This design is called eXtensible<br />Utah ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This research targeted the fundamental challenge of ensuring that computing systems that are optimized for performance are also devoid of logical errors in their design. Beginning around 2005, computer manufacturers catering to virtually all application classes have adopted multiple central processing units (CPUs) in their design. Adopting this style of multicores is the only foreseeable way toward achieving high computing performance at low energy costs. Unfortunately, this massive-scale usage of parallel processing requires a significant amount of programmer training,  new methods to program safely without losing efficiency,  as well as incisive verification tools to detect and root-cause correctness errors.  Our research made contributions in these regards in four  specific areas.  VERIFICATION OF HIERARCHICAL CACHE COHERENCE PROTOCOLS  Multicore systems are often designed by employing a small cluster of CPU cores that are tightly interconnected and a hierarchical  arrangement of such clusters into a larger ensemble. It is crucial to ensure a consistent view of memory both within the cluster as well as across the cluster. This is achieved by using suitable cache coherence protocols.  Since the memory sharing patterns as well as electrical distances are different between the CPUs within a cluster as well as across the cluster, different cache coherence protocols are employed within a cluster and spanning multiple  clusters.   Our research developed techniques for developing ``overlapping abstractions.'' Intuitively, the degree of coupling between the the intra-cluster and intercluster protocols is limited. This observation helps us develop two simpler models, one simplifying the intra-cluster protocol and the other simplifying the inter-cluster model. We successfully demonstrated that non-trivial hierarchical cache coherence protocols can be verified using this approach.  A PROVER OF USER GPU PROGRAMS  The use of multiple CPU cores takes two forms in practice: (1) the use of traditional CPU cores that are eficient at handling control-flow, and (2) the use of specialized processors that are oriented toward  large-scale data processing, and controlled by traditional CPUs for  offloading computations. A popular type of data-oriented processor suitable for use in the ``offload model'' is the Graphical Processing Unit (GPU). When we began our research on GPU programming, it came to our attention that no verification methods that offered firm guarantees were available for GPUs. We developed a symbolic analysis method that employed the power of symbolic execution and invariant generation to ensure that GPU programs do not have insidious bugs such as data racs (conflicting read/write accesses that led to unpredictable answers).  VERIFICATION METHODS FOR MULTICORE COMMUNICATION APIS  As system complexity escalates, the need for multicore chips that communicate using both message passing and shared memory also escalates. A recent standardization effort by the industry has led to the creation of the multicore communications API (MCAPI).  Our research helped investigate these proposed APIs and our efforts  led to the creation of a dynamic analysis tool called MCC that orchestrates concurrency in these two regimes  AN EXTENSIBLE UTAH MULTICORE DESIGN  The last component of our research on multicore programming and correctness analysis was centered around building an actual multicore system that communicates as per MCAPI and can be made to operate on  field programmable gate arrays (FPGA). This design is called eXtensible Utah Multicore (XUM), and has been released to Opencores.Org in 2011.  There have, to date, been over a thousand downloads of XUM.  CONCLUDING REMARKS AND OUTCOMES   In the hierarchical cache coherence verification project, a female PhD student, Dr. Xiaofang Chen, graduated in 2008, working on this project.  A US Citizen Mr. Michael DeLisi  graduated, initially as an NSF REU and later as a BS/MS student.  Mr. DeLisi wa...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
