<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI-Small: An HRI Approach to Robot Learning by Demonstration</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2008</AwardEffectiveDate>
<AwardExpirationDate>09/30/2011</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>365998</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Richard Voyles</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>For years, the robotics community has sought to enable robots to efficiently learn new skills from a human trainer. While motivated by the idea of robots that are easy to teach, there's been a lack of focus on several aspects essential to this goal. This project will advance the state of the art in robot Learning by Demonstration (LbD) by focusing the issues of learning from everyday human partners. LbD work has usually been evaluated with expert humans, typically the system designer.  We will develop implementations and experiments on a humanoid social robot to address the following research questions: &lt;br/&gt;1. In continuous embodied experience, how can a robot use cues from the environment and the person to segment its own learning examples? &lt;br/&gt;2. What social cues does the human use to indicate salient aspects of the environment? What expressive mechanisms can the robot use to communicate relevant aspects of the learning state to the human partner? &lt;br/&gt;3. Imitation learning is broader than the typical ?human-demo robot-repeat? LbD interaction. How can the robot use the human as an information source beyond generalizing a way to repeat motion trajectories? For example, it may be biased to interact with objects it?s seen the human interact with.</AbstractNarration>
<MinAmdLetterDate>07/23/2008</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0812106</AwardID>
<Investigator>
<FirstName>Andrea</FirstName>
<LastName>Thomaz</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrea L Thomaz</PI_FULL_NAME>
<EmailAddress>athomaz@ece.utexas.edu</EmailAddress>
<PI_PHON>6177847154</PI_PHON>
<NSF_ID>000082310</NSF_ID>
<StartDate>07/23/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~113099</FUND_OBLG>
<FUND_OBLG>2009~130077</FUND_OBLG>
<FUND_OBLG>2010~122822</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The aim of this research project has been to get closer toward the goal of enabling robots to learn new tasks and skills from everyday people. This project takes a Human-Robot Interaction (HRI) perspective on the problem of "Learning by Demonstration" (LbD).&nbsp; In this project we have made a few significant contributions.&nbsp; <br /><br />We have argued that the majority of research in the field of robot Learning by Demonstration neglects the key point that this interaction takes place within a social structure that can guide and constrain the learning problem. In the realm of Learning by Demonstration research, it is unusual for people to go the "final step" and test that their algorithms and interfaces are appropriate for non-expert humans.&nbsp; Experiments with humans teaching robots have been the cornerstone of this research agenda.<br /><br />Over the three years of this project, we have conducted three main research investigations into the nature of how a robot can learn from social partners.<br /><br />Experiment 1: Using a small upper torso humanoid robot, we first conducted a study looking at how people structure the learning process for this robot when it is tasked with learning about object affordances. This experiment compared the robot learning about objects by itself, to the situation where it learns with a human partner.&nbsp; We compared the learning performance of Support Vector Machine (SVM) classifiers in these two situations.&nbsp; <br /><br />One of the main contributions is the insights that our experiment gave into the nature of learning input from everyday people:&nbsp; They start with simple examples, group examples in coherent chunks, the amount of data provided for a particular object is proportional to complexity, and they focus on rare events.&nbsp; Due to these differences, we found that socially collected data sets and non-socially collected sets produce SVM classifiers with differing performance.&nbsp; Most importantly, social data sets do much better on predicting rare effects. <br /><br />Experiment 2: The LbD field has tended to focus on one of the highest forms of human social learning--imitation.&nbsp; In a second line of investigation, we note that humans and other animals use many other kinds of social learning mechanisms.&nbsp;&nbsp; We implemented a series of four increasingly complex social learning mechanisms.&nbsp; The mechanisms were drawn from the literature on human imitation and social learning.&nbsp; Our main insight is that robot learning <br />tends to focus only on the most complicated mechanism (imitation), and our hypothesis was that&nbsp; other social learning mechanisms&nbsp; can also <br />inform and bias the exploration of a learner.&nbsp; We implemented computational models of four mechanisms (stimulus enhancement, emulation, mimicking, and imitation) and evaluated the impact that each mechanism has on a learner.<br /><br />Our experiment showed that each provides a distinct benefit over individual/self exploration of an environment.&nbsp; And depending on the nature of the domain and the behavior of the social partner, each learning mechanism can provide better performance than the others.&nbsp; Thus, we conclude that a robot learner (like a human learner) needs all of these mechanisms in its repertoire and the challenge for future work is to determine the appropriate framework to allow these mechanisms to coexist.<br /><br />Experiment 3: In an effort to make the learning process more interactive, we have been investigating the use of Active Learning algorithms in an HRI setting.&nbsp; The Machine Learning community has focused on the optimality of algorithms with respect to the learner.&nbsp; Our work additionally sheds light on the optimality with respect to the human "oracle" that will be providing answers to the robot's queries.&nbsp; We ran a&nbsp; study that compared passive learning to fully a...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The aim of this research project has been to get closer toward the goal of enabling robots to learn new tasks and skills from everyday people. This project takes a Human-Robot Interaction (HRI) perspective on the problem of "Learning by Demonstration" (LbD).  In this project we have made a few significant contributions.    We have argued that the majority of research in the field of robot Learning by Demonstration neglects the key point that this interaction takes place within a social structure that can guide and constrain the learning problem. In the realm of Learning by Demonstration research, it is unusual for people to go the "final step" and test that their algorithms and interfaces are appropriate for non-expert humans.  Experiments with humans teaching robots have been the cornerstone of this research agenda.  Over the three years of this project, we have conducted three main research investigations into the nature of how a robot can learn from social partners.  Experiment 1: Using a small upper torso humanoid robot, we first conducted a study looking at how people structure the learning process for this robot when it is tasked with learning about object affordances. This experiment compared the robot learning about objects by itself, to the situation where it learns with a human partner.  We compared the learning performance of Support Vector Machine (SVM) classifiers in these two situations.    One of the main contributions is the insights that our experiment gave into the nature of learning input from everyday people:  They start with simple examples, group examples in coherent chunks, the amount of data provided for a particular object is proportional to complexity, and they focus on rare events.  Due to these differences, we found that socially collected data sets and non-socially collected sets produce SVM classifiers with differing performance.  Most importantly, social data sets do much better on predicting rare effects.   Experiment 2: The LbD field has tended to focus on one of the highest forms of human social learning--imitation.  In a second line of investigation, we note that humans and other animals use many other kinds of social learning mechanisms.   We implemented a series of four increasingly complex social learning mechanisms.  The mechanisms were drawn from the literature on human imitation and social learning.  Our main insight is that robot learning  tends to focus only on the most complicated mechanism (imitation), and our hypothesis was that  other social learning mechanisms  can also  inform and bias the exploration of a learner.  We implemented computational models of four mechanisms (stimulus enhancement, emulation, mimicking, and imitation) and evaluated the impact that each mechanism has on a learner.  Our experiment showed that each provides a distinct benefit over individual/self exploration of an environment.  And depending on the nature of the domain and the behavior of the social partner, each learning mechanism can provide better performance than the others.  Thus, we conclude that a robot learner (like a human learner) needs all of these mechanisms in its repertoire and the challenge for future work is to determine the appropriate framework to allow these mechanisms to coexist.  Experiment 3: In an effort to make the learning process more interactive, we have been investigating the use of Active Learning algorithms in an HRI setting.  The Machine Learning community has focused on the optimality of algorithms with respect to the learner.  Our work additionally sheds light on the optimality with respect to the human "oracle" that will be providing answers to the robot's queries.  We ran a  study that compared passive learning to fully active learning and two hybrid  approaches.    Our experiment showed that learning was more efficient with active learning (when robot makes queries rather than just accepting examples).  People found the robot more intelligent and engaging when it aske...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
