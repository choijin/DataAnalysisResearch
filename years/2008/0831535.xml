<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CT-L:   Collaborative Research:   Comprehensive Application Analysis and Control</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2008</AwardEffectiveDate>
<AwardExpirationDate>09/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>1277500.00</AwardTotalIntnAmount>
<AwardAmount>1650000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Deborah Shands</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>A deep, pervasive problem when attempting to secure modern computer networks arises from the bewildering range of applications that these networks carry.&lt;br/&gt;Unless a specific application is understood, its presence cannot be soundly monitored and controlled. Yet we have seen in the past decade the rise and use of many hundreds of applications, a growth far outpacing the ability of security practitioners to apprehend their individual operation and implications.  &lt;br/&gt;&lt;br/&gt;This research effort aims to facilitate pervasive understanding and control of the wealth of application protocols running on today's networks. Developing in-depth visibility into these protocols will perforce lead to new capabilities for exposing the inner-workings of modern applications that have yet to be well understood within the community.  Such understanding will provide pragmatic, high-impact functionality, since operators will be able to directly incorporate this information in their monitoring efforts.&lt;br/&gt;&lt;br/&gt;A key goal of the undertaking is to facilitate the means by which the broader network research community can work together to jointly construct application analysis resources that are shared across the field.  The project envisions a "lingua franca" for expressing application protocol structure and semantics that moves beyond the status quo by providing a common platform and language for expressing a wide range of semantics and analyses. While the focus within our project is on application analysis for purposes of monitoring and securing networks, the tools we develop will often lend themselves to repurposing in support of other networking concerns such as network management, trouble-shooting, and performance optimization.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/19/2008</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0831535</AwardID>
<Investigator>
<FirstName>Vern</FirstName>
<LastName>Paxson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vern Paxson</PI_FULL_NAME>
<EmailAddress>vern@icsi.berkeley.edu</EmailAddress>
<PI_PHON>5106662900</PI_PHON>
<NSF_ID>000452263</NSF_ID>
<StartDate>08/19/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Allman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark Allman</PI_FULL_NAME>
<EmailAddress>mallman@icir.org</EmailAddress>
<PI_PHON>4402351792</PI_PHON>
<NSF_ID>000279986</NSF_ID>
<StartDate>08/19/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robin</FirstName>
<LastName>Sommer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robin Sommer</PI_FULL_NAME>
<EmailAddress>robin@icsi.berkeley.edu</EmailAddress>
<PI_PHON>5106662900</PI_PHON>
<NSF_ID>000486953</NSF_ID>
<StartDate>08/19/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>International Computer Science Institute</Name>
<CityName>Berkeley</CityName>
<ZipCode>947041345</ZipCode>
<PhoneNumber>5106662900</PhoneNumber>
<StreetAddress>2150 Shattuck Ave, Suite 1100</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>187909478</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>INTERNATIONAL COMPUTER SCIENCE INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[International Computer Science Institute]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947041345</ZipCode>
<StreetAddress><![CDATA[2150 Shattuck Ave, Suite 1100]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~492500</FUND_OBLG>
<FUND_OBLG>2009~745000</FUND_OBLG>
<FUND_OBLG>2011~412500</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project aimed to enable broad understanding and control of the wealth of application protocols running on today's Internet. &nbsp;To do so, we pursued developing technologies to capture the structure of how applications communicate: concise ways to describe their forms and powerful tools for distilling from monitored traffic its underlying information. &nbsp;We then employed these technologies to analyze the nature of modern network traffic.</p> <p>A basic component of our vision for comprehensive application analysis and control was the development of a "lingua franca" for expressing application protocol structure and semantics. &nbsp;With our framework, an analyst can simply describe the elements and sequencing of a protocol without needing to consider how to then identify those elements when they appear in network traffic. &nbsp;Instead, the framework itself automatically generates recognizers from the analyst's high-level description.</p> <p>In another thrust, we developed extensive techniques for "reverse engineering" the functioning of unknown application protocols. &nbsp;These approaches primarily draw upon execution analysis of clients and servers that use a given protocol, for which we then use dynamic monitoring of the execution to automate the extraction of the format of the application's messages. &nbsp;An important application of such protocol reverse-engineering is the study of command-and-control (C&amp;C) protocols used by botnets - huge ensembles of compromised Internet systems all under the control of a single attacker. &nbsp;By doing so, we were able to "infiltrate" botnets in order to observe their operations, targeting, and potential weaknesses, including in some cases the ability to alter their functioning unbeknownst to the "botmaster" controlling the botnet.</p> <p>We also extensively assessed the degree to which network control elements manipulate the connectivity available to a user's Internet applications. &nbsp;These manipulations often occur in a hidden fashion by which the user has no visibility into the transformations applied to their traffic or the reasons for denied connectivity. &nbsp;Our ongoing "Netalyzr" project (per netalyzr.icsi.berkeley.edu) represents conducting one of the largest studies of the constraints imposed on Internet users undertaken to date. &nbsp;Netalyzr works from a user's Web browser, working in concert with back-end servers we operate to conduct dozens of tests regarding network behavior. &nbsp;To date we have logged more than 1.3 million Netalyzr runs, illuminating a wide spectrum of application-layer proxies, rewritten Domain Name System (DNS) replies, network address translation, security issues, performance parameters, and firewall policies.</p> <p>In a different dimension, the Internet's DNS represents key infrastructure for virtually all applications, and we studied a number of aspects of its use and operation. &nbsp;We developed methodologies for efficiently discovering complex client-side DNS infrastructure, including measurement techniques for isolating the behavior of the different parties in the infrastructure.<br />We also examined the nature of the process of domain names being registered. &nbsp;In this context, we particularly aimed to discern differences between the registration of names ultimately to be used for malicious purposes, such as in spam campaigns, versus those for use by benign applications. &nbsp;Our assessment enabled us to develop a classifier that predicts with high accuracy whether a newly registered domain will see future malicious use.</p> <p>Finally, as web browsers increasingly become the de facto operating system of network-mediated applications, malicious manipulation of web browsing becomes a significant threat. &nbsp;One new domain in this regard concerns the rise of "web extension" ecosystems; in a number of ways, such extensions are a new form of "app", albeit o...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project aimed to enable broad understanding and control of the wealth of application protocols running on today's Internet.  To do so, we pursued developing technologies to capture the structure of how applications communicate: concise ways to describe their forms and powerful tools for distilling from monitored traffic its underlying information.  We then employed these technologies to analyze the nature of modern network traffic.  A basic component of our vision for comprehensive application analysis and control was the development of a "lingua franca" for expressing application protocol structure and semantics.  With our framework, an analyst can simply describe the elements and sequencing of a protocol without needing to consider how to then identify those elements when they appear in network traffic.  Instead, the framework itself automatically generates recognizers from the analyst's high-level description.  In another thrust, we developed extensive techniques for "reverse engineering" the functioning of unknown application protocols.  These approaches primarily draw upon execution analysis of clients and servers that use a given protocol, for which we then use dynamic monitoring of the execution to automate the extraction of the format of the application's messages.  An important application of such protocol reverse-engineering is the study of command-and-control (C&amp;C) protocols used by botnets - huge ensembles of compromised Internet systems all under the control of a single attacker.  By doing so, we were able to "infiltrate" botnets in order to observe their operations, targeting, and potential weaknesses, including in some cases the ability to alter their functioning unbeknownst to the "botmaster" controlling the botnet.  We also extensively assessed the degree to which network control elements manipulate the connectivity available to a user's Internet applications.  These manipulations often occur in a hidden fashion by which the user has no visibility into the transformations applied to their traffic or the reasons for denied connectivity.  Our ongoing "Netalyzr" project (per netalyzr.icsi.berkeley.edu) represents conducting one of the largest studies of the constraints imposed on Internet users undertaken to date.  Netalyzr works from a user's Web browser, working in concert with back-end servers we operate to conduct dozens of tests regarding network behavior.  To date we have logged more than 1.3 million Netalyzr runs, illuminating a wide spectrum of application-layer proxies, rewritten Domain Name System (DNS) replies, network address translation, security issues, performance parameters, and firewall policies.  In a different dimension, the Internet's DNS represents key infrastructure for virtually all applications, and we studied a number of aspects of its use and operation.  We developed methodologies for efficiently discovering complex client-side DNS infrastructure, including measurement techniques for isolating the behavior of the different parties in the infrastructure. We also examined the nature of the process of domain names being registered.  In this context, we particularly aimed to discern differences between the registration of names ultimately to be used for malicious purposes, such as in spam campaigns, versus those for use by benign applications.  Our assessment enabled us to develop a classifier that predicts with high accuracy whether a newly registered domain will see future malicious use.  Finally, as web browsers increasingly become the de facto operating system of network-mediated applications, malicious manipulation of web browsing becomes a significant threat.  One new domain in this regard concerns the rise of "web extension" ecosystems; in a number of ways, such extensions are a new form of "app", albeit one that exists wholly within the browser universe.  We developed a system for rapidly determining whether a Chrome browser extension includes latent malicious functionality...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
