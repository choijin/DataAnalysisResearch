<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NSF East Asia and Pacific Summer Institute for FY 2012 in Japan</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2012</AwardEffectiveDate>
<AwardExpirationDate>05/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>5000.00</AwardTotalIntnAmount>
<AwardAmount>5000</AwardAmount>
<AwardInstrument>
<Value>Fellowship Award</Value>
</AwardInstrument>
<Organization>
<Code>01090000</Code>
<Directorate>
<Abbreviation>O/D</Abbreviation>
<LongName>Office Of The Director</LongName>
</Directorate>
<Division>
<Abbreviation>OISE</Abbreviation>
<LongName>Office Of Internatl Science &amp;Engineering</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anne Emig</SignBlockName>
<PO_EMAI>aemig@nsf.gov</PO_EMAI>
<PO_PHON>7032927241</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This action funds Jason Narad of the University of Massachusetts Amherst to conduct a research project entitled "Improving relation extraction through marginalization of hidden syntactic structure," during the summer of 2012 at the Nara Institute of Science and Technology in Ikoma, Nara, Japan.  The host scientist is Professor Yuji Matsumoto.&lt;br/&gt;&lt;br/&gt;The Intellectual Merit of the research project is to provide a general framework for performing syntax-dependent natural language processing (NLP) tasks in resource-poor languages.  This research focuswa on relation extraction, a subfield of NLP, which aims to uncover and categorize the relationships between entities (people, places, organizations) from unstructured text. The most successful approaches to this problem rely on syntactic annotation which is unavailable for many languages and costly to produce.  The research uses an alternative approach which alleviates this requirement by instead learning a syntax-like scaffolding as a set of latent variables in a graphical model. &lt;br/&gt;&lt;br/&gt;Broader Impacts of an EAPSI fellowship include providing the Fellow a first-hand research experience outside the U.S.; an introduction to the science, science policy, and scientific infrastructure of the respective location; and an orientation to the society, culture and language.  These activities meet the NSF goal to educate for international collaborations early in the career of its scientists, engineers, and educators, thus ensuring a globally aware U.S. scientific workforce.</AbstractNarration>
<MinAmdLetterDate>05/21/2012</MinAmdLetterDate>
<MaxAmdLetterDate>05/21/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.079</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1209666</AwardID>
<Investigator>
<FirstName>Jason</FirstName>
<LastName>Narad</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jason R Narad</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>3154029848</PI_PHON>
<NSF_ID>000603986</NSF_ID>
<StartDate>05/21/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Narad                   Jason          R</Name>
<CityName>Fulton</CityName>
<ZipCode>130693311</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY24</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM/>
<ORG_LGL_BUS_NAME/>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039264</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramElement>
<ProgramReference>
<Code>5921</Code>
<Text>JAPAN</Text>
</ProgramReference>
<ProgramReference>
<Code>5978</Code>
<Text>EAST ASIA AND PACIFIC PROGRAM</Text>
</ProgramReference>
<ProgramReference>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~5000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Natural language processing (NLP) provides a backbone for many of the sophisticated processes which underly internet content and the way humans interact with it. &nbsp;Improvements in NLP have yielded accurate responses to simple questions, where previously only a set of potentially relevant documents were provided. &nbsp;The same types of advances have allowed machines to dominate trivia gameshows, and smartphones to respond to verbal interactions.</p> <p>While there are many success stories demonstrating how NLP can improve day-to-day life, moving academic successes to deliverable products has been slow and difficult. &nbsp;One of these difficulties is that the data used to train up such systems is very limited, and often comes from government documents or newswire, making it a poor fit for predictions on everyday speech, social media, and creative language use. &nbsp;The most crucial data to many NLP tasks is syntactic annotation, which describes the way in which words interact with each other, and loosely proxies the meaning of the sentence. &nbsp;The goal of this project was to alleviate the need for this data by extending machine learning techniques in powerful ways.</p> <p><br />The task of relation extraction, in which entities and the relationships between them are identified, is one of the tasks that traditionally relies heavily on syntactic annotation. &nbsp;Data annotated with relations and entities is much easier and less costly to produce, as its more elaborate and more describable to non-experts, and the signal -- what entities exist, what relationships exist, etc -- can be used to help guide a model to learn a useful notion of syntax without ever directly observing syntactic annotations. &nbsp;This is done by treating syntax as a latent variable within a larger model, and performing specialized inference algorithms which propagate information throughout all aspects of the model.<br />We conducted experiments using this model on two data sets: an English data set, and a smaller Chinese data set. &nbsp;Each corpus was annotated with entity boundaries and labels, with the relationships between them identified. &nbsp;</p> <p>&nbsp;</p> <p>We experimented using two notions of syntax: dependency syntax, in which syntactic relations are specified between words, and constituency syntax, where syntactic relationships are captured in a hierarchy of nested spans denoting ever decreasing widths of clauses and phrases. &nbsp;Our results indicate that constituency syntax is the more effective latent syntactic structure, and more importantly that latent syntax performs almost as good as, if not better than, identical models which utilize parses produced by state-of-the-art parsers trained on large amounts of external data. &nbsp;In the scenario where an NLP task would have otherwise been performed without any syntactic annotation the improvements over these models is extremely significant, without requiring any syntactic annotations. &nbsp;Conference proceedings stemming from this work and related collaborations which occurred during the program are forthcoming.</p><br> <p>            Last Modified: 12/01/2012<br>      Modified by: Jason&nbsp;R&nbsp;Narad</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Natural language processing (NLP) provides a backbone for many of the sophisticated processes which underly internet content and the way humans interact with it.  Improvements in NLP have yielded accurate responses to simple questions, where previously only a set of potentially relevant documents were provided.  The same types of advances have allowed machines to dominate trivia gameshows, and smartphones to respond to verbal interactions.  While there are many success stories demonstrating how NLP can improve day-to-day life, moving academic successes to deliverable products has been slow and difficult.  One of these difficulties is that the data used to train up such systems is very limited, and often comes from government documents or newswire, making it a poor fit for predictions on everyday speech, social media, and creative language use.  The most crucial data to many NLP tasks is syntactic annotation, which describes the way in which words interact with each other, and loosely proxies the meaning of the sentence.  The goal of this project was to alleviate the need for this data by extending machine learning techniques in powerful ways.   The task of relation extraction, in which entities and the relationships between them are identified, is one of the tasks that traditionally relies heavily on syntactic annotation.  Data annotated with relations and entities is much easier and less costly to produce, as its more elaborate and more describable to non-experts, and the signal -- what entities exist, what relationships exist, etc -- can be used to help guide a model to learn a useful notion of syntax without ever directly observing syntactic annotations.  This is done by treating syntax as a latent variable within a larger model, and performing specialized inference algorithms which propagate information throughout all aspects of the model. We conducted experiments using this model on two data sets: an English data set, and a smaller Chinese data set.  Each corpus was annotated with entity boundaries and labels, with the relationships between them identified.       We experimented using two notions of syntax: dependency syntax, in which syntactic relations are specified between words, and constituency syntax, where syntactic relationships are captured in a hierarchy of nested spans denoting ever decreasing widths of clauses and phrases.  Our results indicate that constituency syntax is the more effective latent syntactic structure, and more importantly that latent syntax performs almost as good as, if not better than, identical models which utilize parses produced by state-of-the-art parsers trained on large amounts of external data.  In the scenario where an NLP task would have otherwise been performed without any syntactic annotation the improvements over these models is extremely significant, without requiring any syntactic annotations.  Conference proceedings stemming from this work and related collaborations which occurred during the program are forthcoming.       Last Modified: 12/01/2012       Submitted by: Jason R Narad]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
