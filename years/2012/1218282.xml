<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Efficient, Nonparametric and Local-Minimum-Free Latent Variable Models: With Application to Large-Scale Computer Vision and Genomics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many modern applications ranging from computer vision  to biology require modeling and inferring high-dimensional continuous variables based on distributions with multimodality, skewness, and rich latent structures.  Most existing models in this regime rely heavily on parametric assumptions where the components of the model are typically assumed to be discrete or multivariate Gaussian, or the relations between variables are linear, which may be very different from the actual data generating processes. Furthermore, existing algorithms for discovering the latent dependency structures and learning the latent parameters largely are restricted to local search heuristics such as expectation maximization. Conclusions inferred under these restricted assumptions and suboptimal solutions can be misleading, if the underlying assumptions are violated or if the suboptimal solutions differ greatly from the globally optimal ones. This project aims to develop a novel framework which can (i) discover and take advantage of latent structures in the data, while (ii) allowing parts to handle near-arbitrary distributions, and (iii) allowing the models to scale to modern massive datasets in a local-minimum-free fashion. &lt;br/&gt;&lt;br/&gt;The key innovation in the project is a novel nonparametric latent variable modeling framework based on kernel embedding of distributions. The basic idea is to map distributions into infinite dimensional feature spaces using kernels, such that subsequent comparisons and manipulations of distributions can be achieved via feature space operations, such as inner products, distances, projections, linear transformations and spectral analysis.  Conceptually, the  framework represents components from latent variable models, such as marginal distributions over a single variable, joint distributions over variable pairs, triplets and more variables, as infinite dimensional vectors, matrices, tensors and high-order tensors respectively. Probabilistic relations between these components, i.e., conditional distributions, Sum Rule, Product Rule etc. become linear transformations and relations between these feature space components.&lt;br/&gt;&lt;br/&gt;The framework supports modeling  data with diverse statistical features without the need for making restrictive assumptions about the type of distributions and relations. It supports the application of a large pool of linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model problems in the presence of latent variables, including structure discovery, inference, parameter learning and latent feature extraction.  The framework applies not only to general continuous variables, but also to variables that  take values on strings, graphs, groups, compact manifolds, and other domains on which kernels may be defined.&lt;br/&gt;&lt;br/&gt;Besides advancing the state of the art in machine learning,the new non-parametric methods resulting from the project find applications in image data and understanding and gene expression data analysis. It also contributes to research-based training of graduate and undergraduate students at Georgia Tech and CMU.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218282</AwardID>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Xing</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric P Xing</PI_FULL_NAME>
<EmailAddress>epxing@cs.cmu.edu</EmailAddress>
<PI_PHON>4122682559</PI_PHON>
<NSF_ID>000195787</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~63914</FUND_OBLG>
<FUND_OBLG>2013~136086</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><h4>Outcomes and findings:</h4> <h4>In many machine learning applications in biology and computer vision, there is a common need for methods which can take into account diverse statistical features and the long-range and hierarchical latent dependencies among these variables.</h4> <h4>Over the life-span of the project, we have developed a novel vector space (or Hilbert space) embedding framework to take into account latent variables in the presence of noisy and complex data. The key idea is to map distributions into vector spaces using nonlinear feature maps, such that subsequent comparisons (two-sample tests and independence tests) and manipulations of distributions (sum rule, chain rule, and Bayes rule) can be achieved via vector space operations, such as inner products, distances, projections, linear transformations and spectral analysis. Our framework can address a range of challenging latent variable model problems, including latent structure discovery, latent parameter learning, inference with latent variables and latent feature extraction.</h4> <h4>Intellectual Merit:</h4> <h4>Our novel framework can model data with diverse statistical features without the need for making restrictive assumptions about the type of distributions and relations. Furthermore, the framework employs a large pool of functional analysis, linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model problems in the presence of latent variables, including structure discovery, inference, parameter learning, and latent feature extraction. For instance, by making novel use of the spectral properties of the embedded distributions, we can design fast and local-minimum-free algorithms for discovering latent structures and learning latent parameters. Another advantage of our framework is that it applies not only to general continuous variables, but also generalizes to variables which may take values on strings, graphs, groups,</h4> <h4>Broader Impact:</h4> <h4>This project has advanced the principles and technologies of latent structure analysis for high-dimensional data with general distributions. It is a necessary step towards the ultimate, long term goal of understanding and exploiting latent structures and rich diverse statistical features prevalent in many modern applications, such as computer vision, computational biology, social sciences, music research, and material sciences.</h4> <h4>We have applied our proposed work to several application domains, such as analyzing latent features from text and image data, understanding latent gene regulatory programs, and extracting latent feature for improved prediction of transcription factor binding. These applications fill the gap between imminent methodological needs and the increasing availability of large text and image collections, and offer deeper understanding of text and image representation and classification problems. Our application to computational biology problems will help us better understand cellular mechanisms in response to exogenous interventions, reason about disease causes, and design therapeutic schemes.</h4> <h4>Our proposed research also played an important synergistic role in bridging together traditionally separate areas in machine learning research, including kernel methods, probabilistic graphical models and tensor data analysis. The proposed novel hybrid use of kernel methods and higher-order tensors in latent variable model context has also opened doors for other nonparametric graphical model research. As an interdisciplinary research effort, this project has not only lead to development of new methodology, but also provide rich opportunities for multi-disciplinary educational and research training, at both undergraduate and graduate levels.</h4> <p>&nbsp;</p><br> <p>            Last Modified: 01/17/2017<br>      Modified by: Eric&nbsp;P&nbsp;Xing</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Outcomes and findings: In many machine learning applications in biology and computer vision, there is a common need for methods which can take into account diverse statistical features and the long-range and hierarchical latent dependencies among these variables. Over the life-span of the project, we have developed a novel vector space (or Hilbert space) embedding framework to take into account latent variables in the presence of noisy and complex data. The key idea is to map distributions into vector spaces using nonlinear feature maps, such that subsequent comparisons (two-sample tests and independence tests) and manipulations of distributions (sum rule, chain rule, and Bayes rule) can be achieved via vector space operations, such as inner products, distances, projections, linear transformations and spectral analysis. Our framework can address a range of challenging latent variable model problems, including latent structure discovery, latent parameter learning, inference with latent variables and latent feature extraction. Intellectual Merit: Our novel framework can model data with diverse statistical features without the need for making restrictive assumptions about the type of distributions and relations. Furthermore, the framework employs a large pool of functional analysis, linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model problems in the presence of latent variables, including structure discovery, inference, parameter learning, and latent feature extraction. For instance, by making novel use of the spectral properties of the embedded distributions, we can design fast and local-minimum-free algorithms for discovering latent structures and learning latent parameters. Another advantage of our framework is that it applies not only to general continuous variables, but also generalizes to variables which may take values on strings, graphs, groups, Broader Impact: This project has advanced the principles and technologies of latent structure analysis for high-dimensional data with general distributions. It is a necessary step towards the ultimate, long term goal of understanding and exploiting latent structures and rich diverse statistical features prevalent in many modern applications, such as computer vision, computational biology, social sciences, music research, and material sciences. We have applied our proposed work to several application domains, such as analyzing latent features from text and image data, understanding latent gene regulatory programs, and extracting latent feature for improved prediction of transcription factor binding. These applications fill the gap between imminent methodological needs and the increasing availability of large text and image collections, and offer deeper understanding of text and image representation and classification problems. Our application to computational biology problems will help us better understand cellular mechanisms in response to exogenous interventions, reason about disease causes, and design therapeutic schemes. Our proposed research also played an important synergistic role in bridging together traditionally separate areas in machine learning research, including kernel methods, probabilistic graphical models and tensor data analysis. The proposed novel hybrid use of kernel methods and higher-order tensors in latent variable model context has also opened doors for other nonparametric graphical model research. As an interdisciplinary research effort, this project has not only lead to development of new methodology, but also provide rich opportunities for multi-disciplinary educational and research training, at both undergraduate and graduate levels.          Last Modified: 01/17/2017       Submitted by: Eric P Xing]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
