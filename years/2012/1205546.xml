<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A complete sufficient dimension folding theory with novel methods</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>110000.00</AwardTotalIntnAmount>
<AwardAmount>110000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This proposal is aimed at developing a general formulation and the related methods for sufficient dimension folding where predictors are matrix-/array- valued, and where a specific functional (or parameter) of the conditional distribution is of interest. The past two decades have seen vigorous development of the sufficient dimension reduction methods for vector-valued predictors, and have accrued a striking record of their successful applications. However, many data are matrix-/array-valued, sufficient dimension reduction for vector-valued predictors applying to such data will lose its sufficiency and structure, resulting difficulties in interpretation, and to a large extent these methods treat the conditional distribution as the object of interest, without discriminating between parameter of interest and nuisance parameter. The investigator proposes a new paradigm for sufficient dimension folding for matrix-/array-valued predictors that focuses on a functional of the conditional distribution, which can be any one in a very wide class that covers most of applications. In addition, the investigator proposes to develop a coherent collection of associated techniques for estimation, computation, and asymptotic inference. &lt;br/&gt; &lt;br/&gt;Recently, high throughput technologies that produce massive amount of complex and high-dimensional data are increasingly prevalent in such diverse areas as  business, government administration, environmental studies, machine learning, and bioinformatics. These provide considerable momentum in the Statistics community to develop new theories and methodologies, that are capable of discovering critical evidence from high-dimensional, complex structural and massive data. Sufficient Dimension Folding is a new area of statistical research that arose amidst, and has been propelled by, these new demands. The investigator proposes to formulate the theories and methodologies of sufficient dimension folding so that they can be specifically tailored to target to be estimated. This new paradigm not only synthesizes, broadens, and deepens the recent advances in sufficient dimension folding, but brings the understanding of sufficient dimension folding on a par with classical statistical inference theory, by following the tradition of sufficiency, efficiency, information, parameter of interests, and nuisance parameters, which are the key ideas that had helped to propel classical inference to its maturity.</AbstractNarration>
<MinAmdLetterDate>07/20/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1205546</AwardID>
<Investigator>
<FirstName>Xiangrong</FirstName>
<LastName>Yin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiangrong Yin</PI_FULL_NAME>
<EmailAddress>yinxiangrong@uky.edu</EmailAddress>
<PI_PHON>8592571476</PI_PHON>
<NSF_ID>000485332</NSF_ID>
<StartDate>07/20/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Georgia Research Foundation Inc</Name>
<CityName>ATHENS</CityName>
<ZipCode>306021589</ZipCode>
<PhoneNumber>7065425939</PhoneNumber>
<StreetAddress>310 East Campus Rd</StreetAddress>
<StreetAddress2><![CDATA[Tucker Hall Room 409]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004315578</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF GEORGIA RESEARCH FOUNDATION, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Georgia]]></Name>
<CityName>Athens</CityName>
<StateCode>GA</StateCode>
<ZipCode>306025016</ZipCode>
<StreetAddress><![CDATA[200 D.W. Brooks Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~110000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p style="text-align: left;">Modern technology in scientific research and computing, particularly those related to machine learning, bioinformatics, pattern recognition, climate and finance, often create large quantities of high dimensional data. But they raise new questions and provide fresh momentum for contemporary statistical research. &nbsp;That is, with increased volumes and dimensions, data sets often come with increased redundancy&nbsp;and irrelevancy. As a result, how to deal with redundancy and irrelevancy in vast amount of data by appropriately reducing the data, and thereby single out useful and informative variables, has become one of the focal points of contemporary statistical research. Dimension reduction and variable selection are the two fast growing areas that reflect these new challenges. However, such data often is large, in the sense with huge observations or large number of predictors but small sample observations; not only so, data in many areas have special structure, for instance, in health science, measured predictors may come in matrix-/array-valued predictors. The main goals of proposed research are to investigate and develop nonparametric methods of dimension reduction and variable selection for large number of predictors and small sample size problems, and dimension folding methods so as to keep the interesting structure that data has. In particular, the project provides a systematic procedure when data has large number of predictors and small sample size, and that can target specific aspects of the underlying distribution for such as means, medians and quantiles in dimension folding.</p> <p style="text-align: left;">&nbsp;&nbsp;&nbsp;We have made the following&nbsp;developments towards, or related to, the proposed research:</p> <p style="text-align: left;">1. We have investigated the single-index model estimation methods using information criteria (with Wenhui Sheng; Nan Zhang).</p> <p style="text-align: left;">2. We have introduced the dimension reduction estimators for multivariate responses (with Ross Iaci, Lixing Zhu; Healab Hilafu).</p> <p style="text-align: left;">3. We have developed novel sufficient dimension folding approaches (with Yuan Xue).</p> <p style="text-align: left;">4. We have introduced local sufficient dimension reduction methods with new theory (with Qin Wang and Frank Critchley).</p> <p style="text-align: left;">5. We have initialed research of dimension reduction on a general framework and provide foundation of such research (With Wei Luo and Bing Li).</p> <p style="text-align: left;">6. We have introduced a fundamatual framework for large number of predictors but smaple sample size data (With Healab Hilafu)</p> <p style="text-align: left;">7. We have developed information criteria with dimension reduction (With Nan Zhang and Baoying Yang; Wenhui Sheng).</p> <p style="text-align: left;">8. We have established new theory for stable estimation in dimension reduction area (With Wenbo Wu).</p> <p style="text-align: left;">9.&nbsp; We have introduced new information criterion for statistical purpose and its application and basic R function for optimization(With Qingcong Yuan; Xiangyan Chen).</p> <p style="text-align: left;">Most of these works have appeared in, or accepted by, leading or top quality statistical journals. In particular, Projects in item 1 are published in Journal of Multivariate Analysis and Statistica Sinica; Projects in item 2 are revised for Journal of Multivariate Analysis and published in computational statistical and Data Analysis; Projects in item 3 have appeared in Journal of Computational and Graphical Statistics, and Journal of Nonparametric Statistics; Project in item 4 has appeared in Biometrika; Project in item 5 has appeared in Annals of Statistics; Project in item 6 has appeared in Journal of &nbsp;Royal Statistical Society Series B; Projects in item 7 have been submitted to Journal of R...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Modern technology in scientific research and computing, particularly those related to machine learning, bioinformatics, pattern recognition, climate and finance, often create large quantities of high dimensional data. But they raise new questions and provide fresh momentum for contemporary statistical research.  That is, with increased volumes and dimensions, data sets often come with increased redundancy and irrelevancy. As a result, how to deal with redundancy and irrelevancy in vast amount of data by appropriately reducing the data, and thereby single out useful and informative variables, has become one of the focal points of contemporary statistical research. Dimension reduction and variable selection are the two fast growing areas that reflect these new challenges. However, such data often is large, in the sense with huge observations or large number of predictors but small sample observations; not only so, data in many areas have special structure, for instance, in health science, measured predictors may come in matrix-/array-valued predictors. The main goals of proposed research are to investigate and develop nonparametric methods of dimension reduction and variable selection for large number of predictors and small sample size problems, and dimension folding methods so as to keep the interesting structure that data has. In particular, the project provides a systematic procedure when data has large number of predictors and small sample size, and that can target specific aspects of the underlying distribution for such as means, medians and quantiles in dimension folding.    We have made the following developments towards, or related to, the proposed research: 1. We have investigated the single-index model estimation methods using information criteria (with Wenhui Sheng; Nan Zhang). 2. We have introduced the dimension reduction estimators for multivariate responses (with Ross Iaci, Lixing Zhu; Healab Hilafu). 3. We have developed novel sufficient dimension folding approaches (with Yuan Xue). 4. We have introduced local sufficient dimension reduction methods with new theory (with Qin Wang and Frank Critchley). 5. We have initialed research of dimension reduction on a general framework and provide foundation of such research (With Wei Luo and Bing Li). 6. We have introduced a fundamatual framework for large number of predictors but smaple sample size data (With Healab Hilafu) 7. We have developed information criteria with dimension reduction (With Nan Zhang and Baoying Yang; Wenhui Sheng). 8. We have established new theory for stable estimation in dimension reduction area (With Wenbo Wu). 9.  We have introduced new information criterion for statistical purpose and its application and basic R function for optimization(With Qingcong Yuan; Xiangyan Chen). Most of these works have appeared in, or accepted by, leading or top quality statistical journals. In particular, Projects in item 1 are published in Journal of Multivariate Analysis and Statistica Sinica; Projects in item 2 are revised for Journal of Multivariate Analysis and published in computational statistical and Data Analysis; Projects in item 3 have appeared in Journal of Computational and Graphical Statistics, and Journal of Nonparametric Statistics; Project in item 4 has appeared in Biometrika; Project in item 5 has appeared in Annals of Statistics; Project in item 6 has appeared in Journal of  Royal Statistical Society Series B; Projects in item 7 have been submitted to Journal of Royal Statistical Society Series B and Journal of Computational and Graphical Statistics; Projects in item 8 have appeared in Journal of Computational and Graphical Statistics and submitted to Journal of American Statistical Association; Projects in item 9 have submitted to Biometrika, and near completion. The outcomes resulted from this project have fundamental and strong impacts on modeling modern data and advanced research in data analysis in general. The project also supports educatio...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
