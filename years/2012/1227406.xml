<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Large: Collaborative Research: Multilateral Manipulation by Human-Robot Collaborative Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1163388.00</AwardTotalIntnAmount>
<AwardAmount>1163388</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>jeffrey trinkle</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project addresses a large space of manipulation problems that are repetitive, injury-causing, or dangerous for humans to perform, yet are currently impossible to reliably achieve with purely autonomous robots. These problems generally require dexterity, complex perception, and complex physical interaction. Yet, many such problems can be reliably addressed with human/robot collaborative (HRC) systems, where one or more humans provide needed perception and adaptability, working with one or more robot systems that provide speed, precision, accuracy, and dexterity at an appropriate scale, combining these complementary capabilities.&lt;br/&gt;&lt;br/&gt;The project focuses on multilateral manipulation, which arises when a human controls one or more robot manipulators in partnership with one or more additional controllers (humans or autonomous agents). Complex operations in surgery and manufacturing can benefit from the extra degrees of freedom provided by more than two hands, and training often depends on hands-on interaction between expert and apprentice. Example applications include surgical operations, which typically involve several physicians and assistants, and other medical tasks such as turning a patient in bed and wrapping a cast to constrain a hand. Multilateral manipulation also applies in manufacturing, for example for threading wires or cables, aligning gaskets to obtain a tight seal, and in many household situations, such as folding tablecloths, wrapping packages, and zipping overfilled suitcases so they will fit inside diabolically-designed overhead airline compartments. Multilateral manipulation often arises with deformable materials or multi-jointed objects with more than six degrees of freedom (DOF). The extra DOFs in materials introduce challenges such as computational complexity, but they also can accommodate minor inconsistencies through redundancy and provide system damping. This project advances the fundamental science of multilateral manipulation guided by specific applications from surgery and manufacturing.&lt;br/&gt;&lt;br/&gt;Broader Impacts: Multilateral manipulation systems have the potential to improve healthcare, improve American competitiveness and product quality in manufacturing, and open the door to new service robot applications in the home. The project will be guided by an Advisory Board of experts from industry and medical practice. Project results will be disseminated through yearly conference workshops, open-source software tools integrated into common robotics software environments such as Robot Operating System (ROS), and the investigators' research and course webpages, to encourage integration of our approach into research projects and courses at many institutions. Outreach programs, public lab tours, and mentoring of minority students will broaden participation of underrepresented groups in engineering. These activities will encourage participation in STEM activities and provide student and postdoctoral researchers with mentoring experience.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1227406</AwardID>
<Investigator>
<FirstName>Allison</FirstName>
<LastName>Okamura</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Allison M Okamura</PI_FULL_NAME>
<EmailAddress>aokamura@stanford.edu</EmailAddress>
<PI_PHON>6507211700</PI_PHON>
<NSF_ID>000443791</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943052004</ZipCode>
<StreetAddress><![CDATA[450 Jane Stanford Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~598606</FUND_OBLG>
<FUND_OBLG>2013~564782</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Normal1">This project focused on multilateral manipulation, which arises when a human controls one or more robot manipulators in partnership with one or more additional controllers (humans or autonomous agents). Our work shows that complex operations in surgery and manufacturing can benefit from autonomous degrees of freedom and training that uses hands-on interactions between expert and apprentice, whether human or autonomous.&nbsp;</p> <p class="Normal1"><strong>Intellectual Merit:</strong> This project investigated the foundations of human-robot systems and the scientific issues that arise in the context of multilateral manipulation. The project developed new algorithmic tools for modeling, simulating, designing, and monitoring multilateral manipulation systems. This word advanced understanding of measures of stability, safety, and usability. We showed that various collaboration models between humans and autonomous agents can lead to better task performance. This project used the RAVEN II, an NSF-funded open-source hardware platform, and the da Vinci Research Kit, which were both installed at multiple institutions involved in the project.&nbsp;</p> <p class="Normal1"><strong>Broader Impacts:</strong> Multilateral manipulation systems have the potential to improve healthcare, improve American competitiveness and product quality in manufacturing, and open the door to new service robot applications in the home. Project results were disseminated through workshops, software tools, and the investigators&rsquo; research and course webpages. Outreach programs, public lab tours, and mentoring of women and minority students broadened participation of underrepresented groups in engineering. Online teaching activities and open-source hardware greatly increased the population of students benefitting from this work.</p><br> <p>            Last Modified: 01/14/2017<br>      Modified by: Allison&nbsp;M&nbsp;Okamura</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483432904592_collaborativepalpation--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483432904592_collaborativepalpation--rgov-800width.jpg" title="Collaborative palpation"><img src="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483432904592_collaborativepalpation--rgov-66x44.jpg" alt="Collaborative palpation"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Collaborative palpation between a human and a robot (a) A participant sits at the master console of a teleoperated surgical robot. (b) The surgical robot arm, with an attached force sensor, is controlled by a combination of the human input and an autonomous robotic agent.</div> <div class="imageCredit">Kirsten Kaplan</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Allison&nbsp;M&nbsp;Okamura</div> <div class="imageTitle">Collaborative palpation</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483433174764_skindeformationfeedback--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483433174764_skindeformationfeedback--rgov-800width.jpg" title="Skin deformation feedback"><img src="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483433174764_skindeformationfeedback--rgov-66x44.jpg" alt="Skin deformation feedback"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Teleoperation system with fingerpad skin deformation feedback. This form of tactile feedback can be integrated with a teleoperation system to provide haptic feedback to users and communicate the intent of autonomous agents.</div> <div class="imageCredit">Zhan Fan Quek</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Allison&nbsp;M&nbsp;Okamura</div> <div class="imageTitle">Skin deformation feedback</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483433892407_collaborativecutting--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483433892407_collaborativecutting--rgov-800width.jpg" title="Collaborative cutting"><img src="/por/images/Reports/POR/2017/1227406/1227406_10213735_1483433892407_collaborativecutting--rgov-66x44.jpg" alt="Collaborative cutting"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Multilateral cutting task: Medical gauze was anchored at three corners and pulled at the fourth corner by a needle driver on the left robot. Scissors were mounted on the right robot to cut along a marked linear path. Cases were tested with human operators and autonomous agents.</div> <div class="imageCredit">Kamran Shamaei</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Allison&nbsp;M&nbsp;Okamura</div> <div class="imageTitle">Collaborative cutting</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[This project focused on multilateral manipulation, which arises when a human controls one or more robot manipulators in partnership with one or more additional controllers (humans or autonomous agents). Our work shows that complex operations in surgery and manufacturing can benefit from autonomous degrees of freedom and training that uses hands-on interactions between expert and apprentice, whether human or autonomous.  Intellectual Merit: This project investigated the foundations of human-robot systems and the scientific issues that arise in the context of multilateral manipulation. The project developed new algorithmic tools for modeling, simulating, designing, and monitoring multilateral manipulation systems. This word advanced understanding of measures of stability, safety, and usability. We showed that various collaboration models between humans and autonomous agents can lead to better task performance. This project used the RAVEN II, an NSF-funded open-source hardware platform, and the da Vinci Research Kit, which were both installed at multiple institutions involved in the project.  Broader Impacts: Multilateral manipulation systems have the potential to improve healthcare, improve American competitiveness and product quality in manufacturing, and open the door to new service robot applications in the home. Project results were disseminated through workshops, software tools, and the investigators? research and course webpages. Outreach programs, public lab tours, and mentoring of women and minority students broadened participation of underrepresented groups in engineering. Online teaching activities and open-source hardware greatly increased the population of students benefitting from this work.       Last Modified: 01/14/2017       Submitted by: Allison M Okamura]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
