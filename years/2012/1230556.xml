<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I/UCRC:  Collaborative Research:  Detecting cancer using advanced computer vision techniques</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>99977.00</AwardTotalIntnAmount>
<AwardAmount>107977</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Thyagarajan Nandagopal</SignBlockName>
<PO_EMAI>tnandago@nsf.gov</PO_EMAI>
<PO_PHON>7032924550</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The proposed research proposes to develop novel image processing and machine learning algorithms for the detection and segmentation of cancerous regions from high-resolution images of tissue slides, distinguishing them from healthy/benign regions. The proposed research plans to advance (i) A reliable framework for use in the accurate segmentation of cancerous regions in tissue slides; (ii) New algorithms for texture analysis; (iii) Innovative representations that can increase the system throughput; (iv) Effective machine learning techniques and transparent user interfaces to assist in the reduction of the time that a pathologist needs to examine each slide; and (v) Extensive testing to a variety of cancers including prostate and breast cancer.&lt;br/&gt;&lt;br/&gt;The proposed work has the potential to yield algorithms to facilitate the design of systems that can increase the likelihood of cancer detection. The work is supported by the Industry Advisory Board as well as individual industry members of the center and has the potential to extend the center?s portfolio. The PIs plan to introduce the research content into summer robotic camps for middle schoolers from underrepresented groups, create a website along with a wiki, visit local groups and K-12 schools, and include the research products into the curricula of the participating institutions.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/07/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1230556</AwardID>
<Investigator>
<FirstName>Anneliese</FirstName>
<LastName>Andrews</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anneliese Andrews</PI_FULL_NAME>
<EmailAddress>andrews@cs.du.edu</EmailAddress>
<PI_PHON>3038713374</PI_PHON>
<NSF_ID>000250922</NSF_ID>
<StartDate>08/07/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mohammad</FirstName>
<LastName>Mahoor</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mohammad Mahoor</PI_FULL_NAME>
<EmailAddress>mmahoor@du.edu</EmailAddress>
<PI_PHON>3038713745</PI_PHON>
<NSF_ID>000511471</NSF_ID>
<StartDate>08/07/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Denver</Name>
<CityName>Denver</CityName>
<ZipCode>802104711</ZipCode>
<PhoneNumber>3038712000</PhoneNumber>
<StreetAddress>2199 S. University Blvd.</StreetAddress>
<StreetAddress2><![CDATA[Ofc of Research & Sponsored Prog]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>007431760</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COLORADO SEMINARY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431760</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Denver]]></Name>
<CityName>Denver</CityName>
<StateCode>CO</StateCode>
<ZipCode>805244820</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5761</Code>
<Text>IUCRC-Indust-Univ Coop Res Ctr</Text>
</ProgramElement>
<ProgramReference>
<Code>1049</Code>
<Text>INDUSTRY-UNIV COOPERATIVE RSCH PROJECTS</Text>
</ProgramReference>
<ProgramReference>
<Code>116E</Code>
<Text>RESEARCH EXP FOR UNDERGRADS</Text>
</ProgramReference>
<ProgramReference>
<Code>7609</Code>
<Text>IUCRC FUNDAMENTAL RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>8039</Code>
<Text>Information, Communication &amp; Computing</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~99977</FUND_OBLG>
<FUND_OBLG>2013~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary goal of this proposal was to develop novel image processing and machine learning algorithms for the detection and segmentation of cancerous regions from high-resolution images of tissue slides, distinguishing them from healthy/benign regions. At the University of Denver, we worked on using the state-of-the-art Shearlet transformation for texture representation in microscopic images. We targeted prostate cancer and breast cancer and developed two approaches based on the Shearlet transform. In our first method, the Shearlet transform along with other features such as shape/morphological features were fused using Multiple Kernel Learning for classification. Although the results were promising and show that computer-based approaches can be used to help physicians in cancer detection, we used hand-crafted features and this might be a limitation of&nbsp; the proposed approach. In the&nbsp;second approach that evolved during this research, we used Deep Neural Networks for learning patterns from&nbsp;Shearlet coefficients. Particularly, we apply Shearlet transform on images and extract the magnitude and phase of Shearlet coefficients. Then we feed Shearlet features along with the images to our convolutional neural network consisting of multiple layers of convolution, max pooling, and fully connected layers.Our experimental results show that this method is very promising in grading prostate cancers (i.e. Gleason Grading) and Prostate Cancer detection.</p><br> <p>            Last Modified: 08/03/2016<br>      Modified by: Mohammad&nbsp;Mahoor</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The primary goal of this proposal was to develop novel image processing and machine learning algorithms for the detection and segmentation of cancerous regions from high-resolution images of tissue slides, distinguishing them from healthy/benign regions. At the University of Denver, we worked on using the state-of-the-art Shearlet transformation for texture representation in microscopic images. We targeted prostate cancer and breast cancer and developed two approaches based on the Shearlet transform. In our first method, the Shearlet transform along with other features such as shape/morphological features were fused using Multiple Kernel Learning for classification. Although the results were promising and show that computer-based approaches can be used to help physicians in cancer detection, we used hand-crafted features and this might be a limitation of  the proposed approach. In the second approach that evolved during this research, we used Deep Neural Networks for learning patterns from Shearlet coefficients. Particularly, we apply Shearlet transform on images and extract the magnitude and phase of Shearlet coefficients. Then we feed Shearlet features along with the images to our convolutional neural network consisting of multiple layers of convolution, max pooling, and fully connected layers.Our experimental results show that this method is very promising in grading prostate cancers (i.e. Gleason Grading) and Prostate Cancer detection.       Last Modified: 08/03/2016       Submitted by: Mohammad Mahoor]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
