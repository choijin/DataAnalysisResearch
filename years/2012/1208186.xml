<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Small: Collaborative Research: Assistive Robotics for Grasping and Manipulation using Novel Brain Computer Interfaces</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>430000.00</AwardTotalIntnAmount>
<AwardAmount>430000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Irina Dolinskaya</SignBlockName>
<PO_EMAI>idolinsk@nsf.gov</PO_EMAI>
<PO_PHON>7032927078</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This is a collaborative proposal (with UC Davis) which is aimed at making concrete some of the major goals of Assistive Robotics. A team of experts has been brought together from the fields of signal processing and control, robotic grasping, and rehabilitative medicine to create a field-deployable assistive robotic system that will allow severely disabled patients to control a robot arm/hand system to perform complex grasping and manipulation tasks using novel Brain Muscle Computer Interfaces (BMCI). Further, the intent of this effort is not just technology-driven, but is also driven by clear and necessary clinical needs, and will be evaluated on how well it meets these clinical requirements.  Validation will be performed at the Department of Regenerative and Rehabilitation Medicine at Columbia University on a diverse set of disabled users who will provide important feedback on the technology being developed, and this feedback will be used to iterate on the system design and implementation.&lt;br/&gt;&lt;br/&gt;Intellectual Merit: The intellectual merit of this proposal includes:&lt;br/&gt;o Novel research in Human Machine Interfaces that has the potential to be transformative in eliciting rich, multi-degree-of-freedom signal content from simple and non-invasive surface electromyographic (sEMG) sensors.&lt;br/&gt;o Development of smart adaptive software that employs machine learning algorithms that can continually monitor user performance, and then automatically calibrate and tune system parameters based on system performance.&lt;br/&gt;o Data driven methods for real-time grasp planning algorithms that can be used with both known and unknown objects.&lt;br/&gt;o Methods for finding pose-robust grasps that are tolerant of errors in sensing.&lt;br/&gt;o Evaluation of an underactuated hand as a grasping device for certain application tasks.&lt;br/&gt;o Integration of 3D vision with real-time grasp planning.&lt;br/&gt;o Scientific evaluation at the clinical level of the impact of these new technologies on the disabled population.&lt;br/&gt;&lt;br/&gt;Broader Impacts: The broader impacts of this proposal include:&lt;br/&gt;o Development of a complete system to aid the severely disabled population with tetraplegia.&lt;br/&gt;o Extensions of this technlogy to others lacking motor control function including multiple sclerosis, stroke, amyotrophic lateral sclerosis (ALS or Lou Gehrig disease), cerebral palsy, and muscular dystrophy.&lt;br/&gt;o New technology that can extend the reach and impact of the field of Assistive Robotics.&lt;br/&gt;o Major extensions to the open-source GraspIt! software system that will allow many other researchers to leverage the results of this project.&lt;br/&gt;o Educational thrusts that will bring together engineering students, clinicians and the disabled population to extend the reach and scope of Assistive Robotics.&lt;br/&gt;o New directions in Human Machine Interfaces that can extend beyond the disabled population and into a variety of other applications.</AbstractNarration>
<MinAmdLetterDate>09/06/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208186</AwardID>
<Investigator>
<FirstName>Sanjay</FirstName>
<LastName>Joshi</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sanjay S Joshi</PI_FULL_NAME>
<EmailAddress>maejoshi@ucdavis.edu</EmailAddress>
<PI_PHON>5304005746</PI_PHON>
<NSF_ID>000186022</NSF_ID>
<StartDate>09/06/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Davis</Name>
<CityName>Davis</CityName>
<ZipCode>956186134</ZipCode>
<PhoneNumber>5307547700</PhoneNumber>
<StreetAddress>OR/Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1850 Research Park Dr., Ste 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>047120084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, DAVIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Davis]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>956165270</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~430000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>A study initiated by the Reeve Foundation (2009) estimates that more than 5.5 million people live with paralysis in the United States. Many of these people use ventilators to breathe and are confined to certain head/body positions at different times during the day. Our long-term goal is for paralyzed people to regain some control of their surroundings and some basic independence, even as supporting personnel help them with many other tasks. The controls and robotics methods developed during this project have helped us to move closer to these goals.</span></p> <p><span>Human-Computer Interfaces (HCIs) permit interaction between users and computers or machines. One important branch of HCI research aims to restore some lost independence for individuals living with paralysis by allowing them to act on their external environment through spared abilities. Some of these interfaces are commanded by the body&rsquo;s naturally occurring bio-signals, including electrical impulses originating from the brain (electroencephalogram; EEG and electrocorticography; ECoG), eye (electro-oculogram, EOG), or muscles (electromyogram; EMG). In this project, we aimed to create novel surface EMG-based (muscle-based) HCIs that consisted of a minimal recording configuration (by measuring from only a single muscle site). Many individuals with physical disabilities including paralysis have some access to residual muscles. In the case of high spinal cord injuries, spared muscles are usually located on the head and neck area. For other patients living with diseases of the nervous system, these muscles may be located elsewhere on the body. What most disabled users have in common is that they have a limited number of EMG recording sites (muscles) available, and for them it is critical to minimize the size of the HCI recording configuration. Through contractions of a head muscle, we aimed to have subjects represent commands that can be sent to a robot manipulator or other machine, using only a single head muscle. </span></p> <p><span>Our findings from this grant strongly suggest that our single-muscle site HCIs can produce levels of performance that are comparable to, and in many cases superior to, previously reported interfaces that rely on multiple electrodes (multiple muscles) for control. This is a significant result. Several previous methods in the literature use several head and neck muscles to perform machine control tasks. The practical issue for these methods is that multiple sensors must be placed on the person. In practice, more sensors lead to more hardware, more computing needs, and most importantly more barriers for a person to actually use the methods in daily life. In this grant, we developed methods that used only a single head sensor to achieve comparable or superior performance to methods that used multiple sensors. We also worked with our collaborators at Columbia University to test how these kinds of HCIs can be used to control robot manipulators. One day, these kinds of manipulators may be placed bedside or mounted on wheelchairs to allow those with paralysis more independence.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 05/01/2019<br>      Modified by: Sanjay&nbsp;S&nbsp;Joshi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ A study initiated by the Reeve Foundation (2009) estimates that more than 5.5 million people live with paralysis in the United States. Many of these people use ventilators to breathe and are confined to certain head/body positions at different times during the day. Our long-term goal is for paralyzed people to regain some control of their surroundings and some basic independence, even as supporting personnel help them with many other tasks. The controls and robotics methods developed during this project have helped us to move closer to these goals.  Human-Computer Interfaces (HCIs) permit interaction between users and computers or machines. One important branch of HCI research aims to restore some lost independence for individuals living with paralysis by allowing them to act on their external environment through spared abilities. Some of these interfaces are commanded by the body?s naturally occurring bio-signals, including electrical impulses originating from the brain (electroencephalogram; EEG and electrocorticography; ECoG), eye (electro-oculogram, EOG), or muscles (electromyogram; EMG). In this project, we aimed to create novel surface EMG-based (muscle-based) HCIs that consisted of a minimal recording configuration (by measuring from only a single muscle site). Many individuals with physical disabilities including paralysis have some access to residual muscles. In the case of high spinal cord injuries, spared muscles are usually located on the head and neck area. For other patients living with diseases of the nervous system, these muscles may be located elsewhere on the body. What most disabled users have in common is that they have a limited number of EMG recording sites (muscles) available, and for them it is critical to minimize the size of the HCI recording configuration. Through contractions of a head muscle, we aimed to have subjects represent commands that can be sent to a robot manipulator or other machine, using only a single head muscle.   Our findings from this grant strongly suggest that our single-muscle site HCIs can produce levels of performance that are comparable to, and in many cases superior to, previously reported interfaces that rely on multiple electrodes (multiple muscles) for control. This is a significant result. Several previous methods in the literature use several head and neck muscles to perform machine control tasks. The practical issue for these methods is that multiple sensors must be placed on the person. In practice, more sensors lead to more hardware, more computing needs, and most importantly more barriers for a person to actually use the methods in daily life. In this grant, we developed methods that used only a single head sensor to achieve comparable or superior performance to methods that used multiple sensors. We also worked with our collaborators at Columbia University to test how these kinds of HCIs can be used to control robot manipulators. One day, these kinds of manipulators may be placed bedside or mounted on wheelchairs to allow those with paralysis more independence.          Last Modified: 05/01/2019       Submitted by: Sanjay S Joshi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
