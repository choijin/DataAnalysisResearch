<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Cooling, energy and performance management in computing systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
<PO_EMAI>sabasu@nsf.gov</PO_EMAI>
<PO_PHON>7032927843</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In today's computing systems workload schedulers target best performance, but are unaware of thermal and power realities of the system.  Similarly, the cooling subsystem controllers take only data from thermal sensors as their input and are thus totally oblivious to workload scheduling and power management decisions. Even though these systems all share a single computer infrastructure, their operation is optimized separately, resulting in inefficiencies.  &lt;br/&gt;&lt;br/&gt;This proposal goes well beyond previous work on optimizing thermal problems in CPUs separately from memory by largely neglecting the rest of the system, to solutions that understand the complex interplay between CPUs, HW accelerators such as GPUs, memory and hard disks with their related cooling subsystems.  The PIs propose to develop joint control policies for such systems and to quantify the respective benefits and disadvantages. The project plans to study and design control policies for various ways of implementing cooling, using both fans and liquid cooling systems (e.g micro-channel vs. channels in a heat sink with external pump). The project will also test ideas on computing systems available in a modular data center container obtained at UCSD as a part of recently awarded NSF MRI (GreenLight) grant. &lt;br/&gt;&lt;br/&gt;Graduate and undergraduate students will be involved in various parts of the proposed research and help in connecting this work with other NSF sponsored projects. The results of research, tools and coursework materials developed will be freely and easily distributed to engineering community at large.  In addition, the PI has created a new program affiliated with the Computer Science and Engineering department at the UCSD whose target is to ensure seamless transfer of ideas, funds and people between academic and industrial settings.</AbstractNarration>
<MinAmdLetterDate>06/06/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/13/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218666</AwardID>
<Investigator>
<FirstName>Tajana</FirstName>
<LastName>Rosing</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tajana S Rosing</PI_FULL_NAME>
<EmailAddress>tajana@ucsd.edu</EmailAddress>
<PI_PHON>8585344868</PI_PHON>
<NSF_ID>000485892</NSF_ID>
<StartDate>06/06/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>920930404</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~350000</FUND_OBLG>
<FUND_OBLG>2014~100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="StyleFirstline014"><strong>Intellectual merit </strong>of our work lies in bridging the intellectual and practical divide between solving data intensive computational problems, the control of the physical environment in which such computations take place and the goal of optimizing performance for workloads running on a heterogeneous computing infrastructure while maximizing the energy efficiency. <strong>&nbsp;</strong>In today&rsquo;s systems workload schedulers for computing systems are design with the goal of ensuring the best performance, and are unaware of thermal and power realities in the system.&nbsp; Similarly, the cooling subsystem controllers take only data from thermal sensors as their input and are thus totally oblivious to workload scheduling and power management decisions. Even though these system all share a single computer&rsquo;s infrastructure, their operation is optimized separately, thus leading to inefficiencies.&nbsp; In contrast, <strong>we</strong> <strong>designed both centralized and distributed policies that jointly manage energy, performance, temperature and cooling</strong>.&nbsp;&nbsp; Our most recent work has also taken a more in depth look at how these policies impact the users.</p> <p class="StyleFirstline014"><strong>Broader impact: </strong>The resulting models and control policies are a big step toward realizing the goal of energy efficient computing in heterogeneous computing systems.&nbsp; &nbsp;We designed models and infrastructer that enables researchers and students to evaluate the impact of different energy, temperature and cooling management policies.&nbsp; Our work has enhanced computer science education with a greater focus on physical sciences needed to ensure that computing systems operate effectively through undergraduate and graduate coursework, and through mentoring of students at all levels.&nbsp; In addition, the PI has created a new CSE affiliate program at UCSD whose target is to ensure seamless transfer of ideas, funds and people between academic and industrial settings. Through this program already the first steps have been made to transfer some of the initial results to companies such as Google, Intel and Qualcomm.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/04/2015<br>      Modified by: Tajana&nbsp;S&nbsp;Rosing</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Intellectual merit of our work lies in bridging the intellectual and practical divide between solving data intensive computational problems, the control of the physical environment in which such computations take place and the goal of optimizing performance for workloads running on a heterogeneous computing infrastructure while maximizing the energy efficiency.  In todayÆs systems workload schedulers for computing systems are design with the goal of ensuring the best performance, and are unaware of thermal and power realities in the system.  Similarly, the cooling subsystem controllers take only data from thermal sensors as their input and are thus totally oblivious to workload scheduling and power management decisions. Even though these system all share a single computerÆs infrastructure, their operation is optimized separately, thus leading to inefficiencies.  In contrast, we designed both centralized and distributed policies that jointly manage energy, performance, temperature and cooling.   Our most recent work has also taken a more in depth look at how these policies impact the users. Broader impact: The resulting models and control policies are a big step toward realizing the goal of energy efficient computing in heterogeneous computing systems.   We designed models and infrastructer that enables researchers and students to evaluate the impact of different energy, temperature and cooling management policies.  Our work has enhanced computer science education with a greater focus on physical sciences needed to ensure that computing systems operate effectively through undergraduate and graduate coursework, and through mentoring of students at all levels.  In addition, the PI has created a new CSE affiliate program at UCSD whose target is to ensure seamless transfer of ideas, funds and people between academic and industrial settings. Through this program already the first steps have been made to transfer some of the initial results to companies such as Google, Intel and Qualcomm.             Last Modified: 10/04/2015       Submitted by: Tajana S Rosing]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
