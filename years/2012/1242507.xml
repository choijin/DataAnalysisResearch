<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Medium:  Collaborative Research:  Chorus: Dynamic Isolation in Shared-Memory Parallelism</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2011</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>509702.00</AwardTotalIntnAmount>
<AwardAmount>509702</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Expressing parallel computations over complex shared-memory data structures has always been a vexing issue in parallel programming. On one hand, popular task-based programming models do not provide first-class abstractions for isolation and locality. On the other, Actor-based programming naturally captures locality but is unsuitable for computations on large shared data structures. The present project partially bridges the gap between these two styles of parallelism through Chorus, a new programming model for parallel computations over unstructured, continually changing shared-memory data structures. &lt;br/&gt;&lt;br/&gt;The key abstraction of Chorus is an object assembly: a local, isolated region in the heap equipped with a thread of control. Assemblies can imperatively modify themselves, merge with other assemblies, and split into smaller assemblies?through these operations over assemblies, Chorus captures unpredictable, dynamic changes to parallelism. This makes Chorus an ideal programming model for many irregular data-parallel applications (e.g., meshing, clustering), which exhibit fine-grained data-parallelism in typical executions but no parallelism in the worst case, and whose parallelization remains an open and difficult challenge.&lt;br/&gt;&lt;br/&gt;The predicted outcomes of the project include new insights into the semantic foundations of Chorus and new language constructs integrating Chorus with existing abstractions for asynchronous task creation, directed synchronization, and locality. On the system-building end, the project will integrate Chorus with the Habanero Java parallel programming language, and implement a compiler and runtime for the resultant language. The performance and programmability of this language will be thoroughly evaluated using benchmarks largely consisting of emerging irregular workloads.</AbstractNarration>
<MinAmdLetterDate>07/16/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/04/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1242507</AwardID>
<Investigator>
<FirstName>Swarat</FirstName>
<LastName>Chaudhuri</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Swarat Chaudhuri</PI_FULL_NAME>
<EmailAddress>swarat@rice.edu</EmailAddress>
<PI_PHON>7133486314</PI_PHON>
<NSF_ID>000504208</NSF_ID>
<StartDate>07/16/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050299031</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WILLIAM MARSH RICE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050299031</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[William Marsh Rice University]]></Name>
<CityName>Houston</CityName>
<StateCode>TX</StateCode>
<ZipCode>770051827</ZipCode>
<StreetAddress><![CDATA[3103 Duncan Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramElement>
<ProgramReference>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~352517</FUND_OBLG>
<FUND_OBLG>2013~157185</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>On the scientific front, the intellectual merit outcomes of our<br />project include:<br /><br />1) The creation of delegated isolation as a productive parallel<br />programming model for irregular applications that supports isolation<br />in the presence of arbitrarily nested task creation. This result,<br />embodied in the Aida [OOPSLA-11] and Otello [OOPSLA-13] systems,<br />advances the state of the art for dynamic task parallelism with mutual<br />exclusion, along both programmability (relative to past work on<br />lock-based synchronization) and concurrency (relative to past work on<br />transactional memory) dimensions.<br /><br />2) The introduction of a composable object-based isolation programming<br />construct [EuroPar-2015a], which relies on programmer annotations to<br />guarantee isolation combined with deadlock freedom, without incurring<br />the logging and rollback overheads of transactional memory and<br />delegated isolation systems.<br /><br />3) Fundamental approaches to work-stealing runtime schedulers: a)<br />support for delegated isolation to guarantee livelock freedom (unlike<br />transactional memory runtimes); b) support for general<br />synchronization constructs including futures and barriers; c) support<br />for speculative parallel tasks that well suited for parallel search<br />and optimization applications and support priorities in dynamic task<br />scheduling; and d) support for simultaneous scheduling of elastic<br />tasks with internal SPMD parallelism.<br /><br />4) The development of a novel approach for test-driven repair of data<br />races in structured parallel programs based on a unique coupling<br />between static and dynamic analyses [PLDI-14]. This capability can<br />help programmers determine where synchronizations should be inserted<br />to guarantee data-race freedom while still minimizing the loss of<br />parallelism. Empirical results on standard benchmarks and student<br />homework submissions from a parallel computing course establish the<br />effectiveness of our approach with respect to compile-time overhead,<br />precision, and performance of the repaired code.<br /><br />The broader impacts of our project include:<br /><br />1) Training and professional development of research staff. Roberto<br />Lublinerman, a student advised by Prof. Chaudhuri, received a PhD on<br />the topic of delegated isolation, and went on a successful industrial<br />research career at Google. In addition, the project supported the<br />professional development of several other doctoral students and two<br />postdoctoral researchers (Edwin Westbrook and Srinivas Nedunuri). The<br />project also supported Rice undergraduate John Feser, who is working<br />on synthesis and repair of parallel programs, and will join a PhD<br />program next year.<br /><br />2) Pedagogy and mentoring of undergraduate students. This includes<br />development of a sophomore-level undergraduate course at Rice on<br />"Fundamentals of Parallel Programming" taught by Prof. Sarkar, and<br />modules on parallel algorithms in Prof. Chaudhuri's undergraduate<br />class on algorithms.<br /><br />3) Software. The development of the Habanero-Java library [PPPJ-2014],<br />a pure library approach to task parallelism based on Java 8 that is<br />suitable for use in both research and teaching. This software has been<br />used at other universities for teaching and research.</p><br> <p>            Last Modified: 10/21/2015<br>      Modified by: Swarat&nbsp;Chaudhuri</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ On the scientific front, the intellectual merit outcomes of our project include:  1) The creation of delegated isolation as a productive parallel programming model for irregular applications that supports isolation in the presence of arbitrarily nested task creation. This result, embodied in the Aida [OOPSLA-11] and Otello [OOPSLA-13] systems, advances the state of the art for dynamic task parallelism with mutual exclusion, along both programmability (relative to past work on lock-based synchronization) and concurrency (relative to past work on transactional memory) dimensions.  2) The introduction of a composable object-based isolation programming construct [EuroPar-2015a], which relies on programmer annotations to guarantee isolation combined with deadlock freedom, without incurring the logging and rollback overheads of transactional memory and delegated isolation systems.  3) Fundamental approaches to work-stealing runtime schedulers: a) support for delegated isolation to guarantee livelock freedom (unlike transactional memory runtimes); b) support for general synchronization constructs including futures and barriers; c) support for speculative parallel tasks that well suited for parallel search and optimization applications and support priorities in dynamic task scheduling; and d) support for simultaneous scheduling of elastic tasks with internal SPMD parallelism.  4) The development of a novel approach for test-driven repair of data races in structured parallel programs based on a unique coupling between static and dynamic analyses [PLDI-14]. This capability can help programmers determine where synchronizations should be inserted to guarantee data-race freedom while still minimizing the loss of parallelism. Empirical results on standard benchmarks and student homework submissions from a parallel computing course establish the effectiveness of our approach with respect to compile-time overhead, precision, and performance of the repaired code.  The broader impacts of our project include:  1) Training and professional development of research staff. Roberto Lublinerman, a student advised by Prof. Chaudhuri, received a PhD on the topic of delegated isolation, and went on a successful industrial research career at Google. In addition, the project supported the professional development of several other doctoral students and two postdoctoral researchers (Edwin Westbrook and Srinivas Nedunuri). The project also supported Rice undergraduate John Feser, who is working on synthesis and repair of parallel programs, and will join a PhD program next year.  2) Pedagogy and mentoring of undergraduate students. This includes development of a sophomore-level undergraduate course at Rice on "Fundamentals of Parallel Programming" taught by Prof. Sarkar, and modules on parallel algorithms in Prof. Chaudhuri's undergraduate class on algorithms.  3) Software. The development of the Habanero-Java library [PPPJ-2014], a pure library approach to task parallelism based on Java 8 that is suitable for use in both research and teaching. This software has been used at other universities for teaching and research.       Last Modified: 10/21/2015       Submitted by: Swarat Chaudhuri]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
