<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Incremental Speech Processing for Rapid Dialogue</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>449984.00</AwardTotalIntnAmount>
<AwardAmount>457984</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project develops incremental language processing techniques to enable spoken dialogue systems to communicate in a way that is more highly interactive, more efficient, and more human-like.  Most previous dialogue systems have employed a strict turn-taking regime in which one person speaks at a time, no attempt is made to understand or respond to speech until the speaker finishes speaking, and the overall latency in system responses is high in comparison to human-human conversation.  This results in systems that are unable to provide a range of rapid and overlapping responses that human interlocutors frequently use to achieve an efficient and successful communication process, including back-channels, interruptions, collaborative completions, clarifications, and other rapid responses.  This project is a computational and empirical investigation into how a system's assessment of its own incremental understanding of ongoing user speech can guide its strategic decisions to initiate such rapid and overlapping responses.  The feature representations and response policies that can implement this decision-making are studied in the context of two fast-paced interactive dialogue games.  These games are carefully chosen to support objective evaluation of incremental response strategies and fun gameplay that facilitates large-scale data collection.&lt;br/&gt;&lt;br/&gt;The resulting computational models may improve the conversational skills of a range of dialogue systems, including not only game-oriented systems but also practical applications such as intelligent tutoring and training systems, information access systems, and entertainment applications.  A second product of this project is an annotated corpus of human-human and human-system dialogue data for use by other researchers.  A third product is the incorporation of relevant software into a publicly distributed toolkit for building dialogue systems, supporting further research and education.</AbstractNarration>
<MinAmdLetterDate>08/01/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1219253</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Traum</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David R Traum</PI_FULL_NAME>
<EmailAddress>traum@ict.usc.edu</EmailAddress>
<PI_PHON>3105745729</PI_PHON>
<NSF_ID>000173016</NSF_ID>
<StartDate>08/01/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kenji</FirstName>
<LastName>Sagae</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kenji Sagae</PI_FULL_NAME>
<EmailAddress>sagae@ucdavis.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000573788</NSF_ID>
<StartDate>08/01/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>DeVault</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David J DeVault</PI_FULL_NAME>
<EmailAddress>devault@ict.usc.edu</EmailAddress>
<PI_PHON>3104485320</PI_PHON>
<NSF_ID>000573790</NSF_ID>
<StartDate>08/01/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900890001</ZipCode>
<StreetAddress><![CDATA[University Park]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~195309</FUND_OBLG>
<FUND_OBLG>2013~262675</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Today, talking to a voice-enabled computer or mobile app can be a slow<br />and frustrating experience.&nbsp; One of the reasons for this is that<br />current voice-enabled systems are relatively slow to understand and<br />respond to what a user is saying.&nbsp; While human speakers tend to<br />respond to each other very quickly, with only very short pauses<br />between one speaker and the next, typical automated systems take much<br />longer to process and respond to each new user utterance.&nbsp; This often<br />results in less natural and less efficient interactions between people<br />and automated systems.<br /><br />This research project has worked to address this limitation by<br />developing new computational techniques that can enable spoken<br />dialogue systems to understand and respond more quickly to a user's<br />speech.&nbsp; In particular, new computational techniques developed in this<br />project allow a dialogue system to understand and respond to what a<br />user is saying using real-time, "incremental" (word-by-word) speech<br />processing algorithms.&nbsp; These incremental speech processing algorithms<br />make it possible for a dialogue system to respond to what a user is<br />saying more quickly and to provide more efficient and natural<br />interactions with users.<br /><br />The outcomes for this project include new incremental speech<br />processing algorithms that have been implemented, optimized, and<br />evaluated in the context of fast-paced spoken dialogue interactions.<br />In one type of interaction used in this project, a user verbally<br />describes a series of pictures displayed on their computer screen to<br />an automated system.&nbsp; The automated system listens to the user's<br />spoken descriptions and tries to identify the correct pictures as<br />quickly and accurately as possible.&nbsp; This type of interaction<br />emphasizes the general capability for an automated system to<br />understand a user's referential language.&nbsp; This general capability is<br />relevant in a variety of voice-enabled systems that need to be able to<br />understand which object or image a user is referring to.&nbsp; In another<br />type of interaction used in this project, an automated system<br />participates in a word-guessing dialogue with a user.&nbsp; The system<br />decides on a specific target word or phrase, and then tries to provide<br />verbal clues that will enable a user to identify the target word or<br />phrase as quickly as possible.&nbsp; Both of these interactive tasks serve<br />as useful research testbeds for developing automated systems that can<br />sustain much faster-paced and more efficient interactions than is<br />possible in typical dialogue systems.<br /><br />One of the outcomes of this project is a new method for training<br />automated systems to make word-by-word decisions about whether they<br />have sufficiently understood what a user is saying.&nbsp; This new training<br />method produces an optimized incremental dialogue policy that governs<br />how a system reacts to each new word a user says, and makes it<br />possible for a system to react even before the user's speech<br />concludes.&nbsp; This project has evaluated a number of trained incremental<br />dialogue policies in empirical studies that evaluate their<br />effectiveness in comparison with alternative dialogue policies,<br />including policies that use less incremental speech processing.&nbsp; Our<br />results show that increased use of incremental, word-by-word speech<br />processing enables an automated system to significantly improve its<br />performance at rapidly understanding a user's descriptions of pictures<br />on a computer screen.&nbsp; Our results also show that increased use of<br />incremental speech processing leads to improved user ratings of<br />efficiency, understanding of speech, and naturalness of the<br />interaction.&...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Today, talking to a voice-enabled computer or mobile app can be a slow and frustrating experience.  One of the reasons for this is that current voice-enabled systems are relatively slow to understand and respond to what a user is saying.  While human speakers tend to respond to each other very quickly, with only very short pauses between one speaker and the next, typical automated systems take much longer to process and respond to each new user utterance.  This often results in less natural and less efficient interactions between people and automated systems.  This research project has worked to address this limitation by developing new computational techniques that can enable spoken dialogue systems to understand and respond more quickly to a user's speech.  In particular, new computational techniques developed in this project allow a dialogue system to understand and respond to what a user is saying using real-time, "incremental" (word-by-word) speech processing algorithms.  These incremental speech processing algorithms make it possible for a dialogue system to respond to what a user is saying more quickly and to provide more efficient and natural interactions with users.  The outcomes for this project include new incremental speech processing algorithms that have been implemented, optimized, and evaluated in the context of fast-paced spoken dialogue interactions. In one type of interaction used in this project, a user verbally describes a series of pictures displayed on their computer screen to an automated system.  The automated system listens to the user's spoken descriptions and tries to identify the correct pictures as quickly and accurately as possible.  This type of interaction emphasizes the general capability for an automated system to understand a user's referential language.  This general capability is relevant in a variety of voice-enabled systems that need to be able to understand which object or image a user is referring to.  In another type of interaction used in this project, an automated system participates in a word-guessing dialogue with a user.  The system decides on a specific target word or phrase, and then tries to provide verbal clues that will enable a user to identify the target word or phrase as quickly as possible.  Both of these interactive tasks serve as useful research testbeds for developing automated systems that can sustain much faster-paced and more efficient interactions than is possible in typical dialogue systems.  One of the outcomes of this project is a new method for training automated systems to make word-by-word decisions about whether they have sufficiently understood what a user is saying.  This new training method produces an optimized incremental dialogue policy that governs how a system reacts to each new word a user says, and makes it possible for a system to react even before the user's speech concludes.  This project has evaluated a number of trained incremental dialogue policies in empirical studies that evaluate their effectiveness in comparison with alternative dialogue policies, including policies that use less incremental speech processing.  Our results show that increased use of incremental, word-by-word speech processing enables an automated system to significantly improve its performance at rapidly understanding a user's descriptions of pictures on a computer screen.  Our results also show that increased use of incremental speech processing leads to improved user ratings of efficiency, understanding of speech, and naturalness of the interaction.  These empirical results may help other dialogue researchers and practical system builders to design and implement more efficient and natural spoken dialogue systems in the future.  Over time, this type of research, which is developing techniques that enable spoken dialogue systems to understand and respond faster to what users are saying, will greatly improve the naturalness and acceptability of a range of dialogue system ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
