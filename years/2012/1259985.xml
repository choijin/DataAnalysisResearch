<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Reduction of Survey Length through Split Questionnaire Design: Consequences for Nonresponse and Measurement Error</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>580000.00</AwardTotalIntnAmount>
<AwardAmount>580000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
<PO_EMAI>ceavey@nsf.gov</PO_EMAI>
<PO_PHON>7032927269</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Much research in the social sciences and development of government policy relies on survey data, and the demand for survey data continues to grow.  The need for more data has led to longer surveys, increasing the burden for survey respondents in terms of time and effort.  Empirical evidence shows a positive correlation between survey length and survey nonresponse, which threatens the representativeness of the survey estimates.  There also is evidence that measurement (reporting) error increases as respondents are asked to answer more questions in the survey.  Collecting fewer variables may not satisfy a given study's objectives, however.  This research project experimentally evaluates the ability to collect all desired data through a split questionnaire design in which respondents are asked only a subset of the questions.  The project will use a multiple imputation method to complete the data in the sections that are not asked of particular respondents.  The investigators' will extend current imputation methods to include semi-parametric and parametric models.  The main hypothesis is that the split questionnaire design approach will yield estimates with less bias and even less total error compared to deploying the full questionnaire.&lt;br/&gt;&lt;br/&gt;This project evaluates a method that essentially transfers part of the time and effort to complete the survey from the individual to the researcher.  It also evaluates the ability to collect higher quality data as a result of this reduction in respondent burden.  Finally, the study aims to extend the employed statistical methods to better preserve the properties of the data.  The results will help to provide an alternative methodology for a wide array of surveys, improve split questionnaire design methodology itself, and provide information regarding the circumstances under which implementing such designs can be beneficial.</AbstractNarration>
<MinAmdLetterDate>09/17/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1259985</AwardID>
<Investigator>
<FirstName>Emilia</FirstName>
<LastName>Peytcheva</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emilia Peytcheva</PI_FULL_NAME>
<EmailAddress>epeytcheva@rti.org</EmailAddress>
<PI_PHON>9195417217</PI_PHON>
<NSF_ID>000248286</NSF_ID>
<StartDate>07/18/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Emilia</FirstName>
<LastName>Peytcheva</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emilia Peytcheva</PI_FULL_NAME>
<EmailAddress>epeytcheva@rti.org</EmailAddress>
<PI_PHON>9195417217</PI_PHON>
<NSF_ID>000248286</NSF_ID>
<StartDate>09/17/2013</StartDate>
<EndDate>07/18/2016</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andrey</FirstName>
<LastName>Peytchev</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrey Peytchev</PI_FULL_NAME>
<EmailAddress>apeytchev@rti.org</EmailAddress>
<PI_PHON>9195416648</PI_PHON>
<NSF_ID>000080029</NSF_ID>
<StartDate>09/17/2013</StartDate>
<EndDate>07/18/2016</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Research Triangle Institute</Name>
<CityName>Research Triangle Park</CityName>
<ZipCode>277092194</ZipCode>
<PhoneNumber>9195416000</PhoneNumber>
<StreetAddress>3040 Cornwallis Road</StreetAddress>
<StreetAddress2><![CDATA[P. O. Box 12194]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004868105</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH TRIANGLE INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004868105</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Research Triangle Institute]]></Name>
<CityName>Research Triangle Park</CityName>
<StateCode>NC</StateCode>
<ZipCode>277092194</ZipCode>
<StreetAddress><![CDATA[3040 Cornwallis Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramElement>
<Code>m174</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>m208</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>m217</Code>
<Text/>
</ProgramElement>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~580000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Probability-based population surveys are a key source of information on the nation, providing estimates on health, education, economic well-being, and many other areas of interest to policy-making and basic research.&nbsp; The need for data is great, but the quality of the collected data can be reduced when surveys become very long.</p> <p>This study uses an experimental design to study the effect of shortening the survey on any reduction in nonresponse (nonparticipation) and reduction in measurement error (error in the responses).&nbsp; It also evaluates a way to reproduce the full data while giving only a subset of the survey questions to each selected individual, so the overall burden on respondents is smaller in comparison to completing the full questionnaire.&nbsp; The answers to the omitted questions are imputed multiple times in order to provide a complete dataset and the ability to reflect the uncertainty from obtaining these responses from a statistical model - a method reffered to in the literature as split questionnaire design, or matrix sampling.</p> <p>We fielded the experiment with four conditions, varying the length of the survey and the location of the survey questions. The survey instrument included questions from major national surveys.&nbsp; A substantial challenge was getting sufficient participation using a low-cost design that invited sample members by mail to complete a web survey.&nbsp; The data collection was paused and the data collection design was modified in order to better address the issue of low participation, approximately doubling the response rate for the latter sample releases.&nbsp; The results of these changes are being described in a separate manuscript.</p> <p>Our preliminary research showed that measurement error can be reduced when the survey is shorter, but we have not yet fully evaluated the impact on nonresponse and nonresponse bias.&nbsp; Contrary to common expectations about the effect of survey length on nonresponse, response rates were not substantially higher for the survey that was only half the length of the original instrument.&nbsp; Thus, our experimental and nonexperimental evidence so far suggests that shortening the survey can have a beneficial effect on survey estimates, but it is more through improved measurement rather than increased participation.&nbsp; Our ongoing analyses evaluate the ability to further improve the properties of the survey estimates through the use of multiple imputation in the shorter survey design.&nbsp; One of the greatest strengths of surveys is the ability to use measures that are designed for a particular purpose and can yield reliable data.&nbsp; This study provides evidence that shorter surveys and use of split questionnaire design can be one way to improve the collected information.</p><br> <p>            Last Modified: 08/09/2018<br>      Modified by: Emilia&nbsp;Peytcheva</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Probability-based population surveys are a key source of information on the nation, providing estimates on health, education, economic well-being, and many other areas of interest to policy-making and basic research.  The need for data is great, but the quality of the collected data can be reduced when surveys become very long.  This study uses an experimental design to study the effect of shortening the survey on any reduction in nonresponse (nonparticipation) and reduction in measurement error (error in the responses).  It also evaluates a way to reproduce the full data while giving only a subset of the survey questions to each selected individual, so the overall burden on respondents is smaller in comparison to completing the full questionnaire.  The answers to the omitted questions are imputed multiple times in order to provide a complete dataset and the ability to reflect the uncertainty from obtaining these responses from a statistical model - a method reffered to in the literature as split questionnaire design, or matrix sampling.  We fielded the experiment with four conditions, varying the length of the survey and the location of the survey questions. The survey instrument included questions from major national surveys.  A substantial challenge was getting sufficient participation using a low-cost design that invited sample members by mail to complete a web survey.  The data collection was paused and the data collection design was modified in order to better address the issue of low participation, approximately doubling the response rate for the latter sample releases.  The results of these changes are being described in a separate manuscript.  Our preliminary research showed that measurement error can be reduced when the survey is shorter, but we have not yet fully evaluated the impact on nonresponse and nonresponse bias.  Contrary to common expectations about the effect of survey length on nonresponse, response rates were not substantially higher for the survey that was only half the length of the original instrument.  Thus, our experimental and nonexperimental evidence so far suggests that shortening the survey can have a beneficial effect on survey estimates, but it is more through improved measurement rather than increased participation.  Our ongoing analyses evaluate the ability to further improve the properties of the survey estimates through the use of multiple imputation in the shorter survey design.  One of the greatest strengths of surveys is the ability to use measures that are designed for a particular purpose and can yield reliable data.  This study provides evidence that shorter surveys and use of split questionnaire design can be one way to improve the collected information.       Last Modified: 08/09/2018       Submitted by: Emilia Peytcheva]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
