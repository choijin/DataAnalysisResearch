<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DIP: Using dynamic formative assessment models to enhance learning of the experimental process in biology</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1333395.00</AwardTotalIntnAmount>
<AwardAmount>1333395</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kevin Lee</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project seeks to develop a dynamic formative assessment method for use with virtual labs. The research focuses on how to constrain a virtual lab experience to be amenable to automated feedback on relatively open-ended responses students are generating while still giving students an appropriate exploratory experience. The technology innovation question is how to do that with validity and reliability. The team is focusing on how to use available artificial intelligence technologies to make it possible to provide good feedback, both to learners working in these environments and to their teachers. PIs are adding dynamic formative assessment capabilities to  virtual lab experiences that are already extensively used in undergraduate and high-school biology classes.&lt;br/&gt;&lt;br/&gt;This is an automated assessment project, focusing on assessing learner understanding and capabilities in situations where learners are exploring, having, and using ideas as they are learning STEM content and practices. There are several ways one could approach automated assessment for situations where learners are acting in a fairly unconstrained way -- design algorithms that can interpret and make inferences from free text, or find ways to design the environment in such a way that learners can explore, develop, and record as needed for deep learning but where they have a more constrained way of expressing themselves or limitations in what they can do that don't constrain the learning or engagement. This project seeks to find a sweet spot -- a happy medium where learners can explore, try things out, have ideas, refine ideas, and use ideas with significant freedom but just enough constraint for already-existing artificial intelligence algorithms to interpret what learners are doing, why they are doing it, and what they mean to express. Learning how to do this is essential to designing the learning environments of the future.&lt;br/&gt;&lt;br/&gt;There is broad acknowledgement that more attention must be given in STEM fields to the teaching of higher-order thinking skills, including experimental design, data interpretation and evidence-based judgment. Timely formative assessment is a crucial component of such learning, but formative assessment is impossible for a teacher to do for a whole class of individuals at the time when it will have the most effect (when students are engaging in or have just finished engaging in such activities) and too labor intensive to be done regularly in large high school and introductory-level college classes. This project is therefore developing techniques for automatically providing immediate formative assessment as students are conducting simulation-based experiments and reasoning about their results. The investigation focuses on helping students learn to conduct experiments and interpret results within the discipline of biology; lessons learned will be applicable across STEM domains at the high-school and college levels.</AbstractNarration>
<MinAmdLetterDate>08/30/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/13/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1227245</AwardID>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Klopfer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric Klopfer</PI_FULL_NAME>
<EmailAddress>klopfer@mit.edu</EmailAddress>
<PI_PHON>6172532025</PI_PHON>
<NSF_ID>000174971</NSF_ID>
<StartDate>08/30/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Eli</FirstName>
<LastName>Meir</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eli Meir</PI_FULL_NAME>
<EmailAddress>emeir@simbio.com</EmailAddress>
<PI_PHON>6172852583</PI_PHON>
<NSF_ID>000182604</NSF_ID>
<StartDate>08/30/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Joel</FirstName>
<LastName>Abraham</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joel K Abraham</PI_FULL_NAME>
<EmailAddress>jkabraham@fullerton.edu</EmailAddress>
<PI_PHON>6572783138</PI_PHON>
<NSF_ID>000613902</NSF_ID>
<StartDate>08/30/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zhushan</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhushan Li</PI_FULL_NAME>
<EmailAddress>zhushan.li@bc.edu</EmailAddress>
<PI_PHON>6175528000</PI_PHON>
<NSF_ID>000614255</NSF_ID>
<StartDate>08/30/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SimBiotic Software</Name>
<CityName>Missoula</CityName>
<ZipCode>598010000</ZipCode>
<PhoneNumber>6173147701</PhoneNumber>
<StreetAddress>1280 S Third St. W</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Montana</StateName>
<StateCode>MT</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MT23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>198592078</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SIMBIOTIC SOFTWARE, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[SimBiotic Software]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148505742</ZipCode>
<StreetAddress><![CDATA[148 Grandview Ct.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8842</Code>
<Text>Design and Implementation Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0412</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~1333395</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Students learn best if they have opportunities to practice important skills in open-ended environments, and if they receive immediate feedback as they are practicing. This presents a tradeoff for teaching many important scientific ideas in the large introductory science classes typically&nbsp;found in colleges. If students are given an open-ended environment in which to learn and practice a skill, the teacher-to-student ratio and the time involved in assessing students' work and providing feedback mean that most feedback to the students comes days or weeks after they complete their work, greatly reducing its impact on learning. Alternately, students can be assessed using highly constrained question formats such as multiple choice. These, though, don&rsquo;t do a good job of capturing student&rsquo;s abilities on complex skills or understanding of difficult ideas.</p> <p>On this project, we tried to find a middle ground by taking open-ended exercises and question formats, such as essay questions, or simulation-based environments where students can do experiments. Focusing on the experimental process, we built tools that put some constraints on those to make them amenable to computer algorithms that could provide instant feedback to students.</p> <p>While we are still analyzing many of the final results, much of our preliminary data points to this being a fruitful direction. Two question formats we investigated as replacements for essay questions allow students to construct their own answers, yet can be scored reliably by automated graders and provide students specific feedback on their answers. We were also able to take an open-ended simulation environment in which students had to design experiments to solve a problem presented to them, and put limited constraints on that environment. Those constraints enabled us to write algorithms which provide feedback to the students on how to improve their experiments, despite the simulation still allowing students a large space of possibilities for their designs. Our results so far support the hypothesis that some combination of the constraints and the feedback they enable helps students learn key biological concepts.</p> <p>The tools developed on this grant have been incorporated into several widely used virtual laboratories, which are already benefiting 10's of thousands of students each year in hundreds of college biology courses. Among those, the new Understanding Experimental Design lab (see image) incorporates much of the learning that took place on this project.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/29/2016<br>      Modified by: Eli&nbsp;Meir</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1227245/1227245_10208367_1483046861542_ScreenShot2016-12-29at4.24.52PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1227245/1227245_10208367_1483046861542_ScreenShot2016-12-29at4.24.52PM--rgov-800width.jpg" title="Understanding Experimental Design"><img src="/por/images/Reports/POR/2016/1227245/1227245_10208367_1483046861542_ScreenShot2016-12-29at4.24.52PM--rgov-66x44.jpg" alt="Understanding Experimental Design"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A students experiment within the Understanding Experimental Design lab. Students are able to adjust several factors within each experimental plot, and choose how many (up to 8) plots to use in order to test their hypothesis.</div> <div class="imageCredit">(c) SimBiotic Software Inc., 2016</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Eli&nbsp;Meir</div> <div class="imageTitle">Understanding Experimental Design</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Students learn best if they have opportunities to practice important skills in open-ended environments, and if they receive immediate feedback as they are practicing. This presents a tradeoff for teaching many important scientific ideas in the large introductory science classes typically found in colleges. If students are given an open-ended environment in which to learn and practice a skill, the teacher-to-student ratio and the time involved in assessing students' work and providing feedback mean that most feedback to the students comes days or weeks after they complete their work, greatly reducing its impact on learning. Alternately, students can be assessed using highly constrained question formats such as multiple choice. These, though, don?t do a good job of capturing student?s abilities on complex skills or understanding of difficult ideas.  On this project, we tried to find a middle ground by taking open-ended exercises and question formats, such as essay questions, or simulation-based environments where students can do experiments. Focusing on the experimental process, we built tools that put some constraints on those to make them amenable to computer algorithms that could provide instant feedback to students.  While we are still analyzing many of the final results, much of our preliminary data points to this being a fruitful direction. Two question formats we investigated as replacements for essay questions allow students to construct their own answers, yet can be scored reliably by automated graders and provide students specific feedback on their answers. We were also able to take an open-ended simulation environment in which students had to design experiments to solve a problem presented to them, and put limited constraints on that environment. Those constraints enabled us to write algorithms which provide feedback to the students on how to improve their experiments, despite the simulation still allowing students a large space of possibilities for their designs. Our results so far support the hypothesis that some combination of the constraints and the feedback they enable helps students learn key biological concepts.  The tools developed on this grant have been incorporated into several widely used virtual laboratories, which are already benefiting 10's of thousands of students each year in hundreds of college biology courses. Among those, the new Understanding Experimental Design lab (see image) incorporates much of the learning that took place on this project.          Last Modified: 12/29/2016       Submitted by: Eli Meir]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
