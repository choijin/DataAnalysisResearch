<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Efficient, Nonparametric and Local-Minimum-Free Latent Variable Models: With Application to Large-Scale Computer Vision and Genomics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>299979.00</AwardTotalIntnAmount>
<AwardAmount>299979</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many modern applications ranging from computer vision  to biology require modeling and inferring high-dimensional continuous variables based on distributions with multimodality, skewness, and rich latent structures.  Most existing models in this regime rely heavily on parametric assumptions where the components of the model are typically assumed to be discrete or multivariate Gaussian, or the relations between variables are linear, which may be very different from the actual data generating processes. Furthermore, existing algorithms for discovering the latent dependency structures and learning the latent parameters largely are restricted to local search heuristics such as expectation maximization. Conclusions inferred under these restricted assumptions and suboptimal solutions can be misleading, if the underlying assumptions are violated or if the suboptimal solutions differ greatly from the globally optimal ones. This project aims to develop a novel framework which can (i) discover and take advantage of latent structures in the data, while (ii) allowing parts to handle near-arbitrary distributions, and (iii) allowing the models to scale to modern massive datasets in a local-minimum-free fashion. &lt;br/&gt;&lt;br/&gt;The key innovation in the project is a novel nonparametric latent variable modeling framework based on kernel embedding of distributions. The basic idea is to map distributions into infinite dimensional feature spaces using kernels, such that subsequent comparisons and manipulations of distributions can be achieved via feature space operations, such as inner products, distances, projections, linear transformations and spectral analysis.  Conceptually, the  framework represents components from latent variable models, such as marginal distributions over a single variable, joint distributions over variable pairs, triplets and more variables, as infinite dimensional vectors, matrices, tensors and high-order tensors respectively. Probabilistic relations between these components, i.e., conditional distributions, Sum Rule, Product Rule etc. become linear transformations and relations between these feature space components.&lt;br/&gt;&lt;br/&gt;The framework supports modeling  data with diverse statistical features without the need for making restrictive assumptions about the type of distributions and relations. It supports the application of a large pool of linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model problems in the presence of latent variables, including structure discovery, inference, parameter learning and latent feature extraction.  The framework applies not only to general continuous variables, but also to variables that  take values on strings, graphs, groups, compact manifolds, and other domains on which kernels may be defined.&lt;br/&gt;&lt;br/&gt;Besides advancing the state of the art in machine learning,the new non-parametric methods resulting from the project find applications in image data and understanding and gene expression data analysis. It also contributes to research-based training of graduate and undergraduate students at Georgia Tech and CMU.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218749</AwardID>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Gray</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexander Gray</PI_FULL_NAME>
<EmailAddress>agray@cc.gatech.edu</EmailAddress>
<PI_PHON>4049330666</PI_PHON>
<NSF_ID>000065875</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Le</FirstName>
<LastName>Song</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Le Song</PI_FULL_NAME>
<EmailAddress>lsong@cc.gatech.edu</EmailAddress>
<PI_PHON>4048585702</PI_PHON>
<NSF_ID>000601175</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName/>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~96772</FUND_OBLG>
<FUND_OBLG>2013~203207</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed a novel nonparametric latent vari-able modeling framework based on kernel embedding of distributions. The key idea is to map distributions into infinite dimensional feature spaces using kernels, such that subsequent comparisons and manipulations of distributions can be achieved via feature space operations, such as inner products, distances,projections, linear transformations and spectral analysis.&nbsp;The developed method can be used to address a range of latent variablemodel problems, including latent structure discovery, latent parameter learning, inference with latent variablesand latent feature extraction.</p> <p>The developed framework allows us to model data with diverse statistical features without the need formaking restrictive assumptions about the type of distributions and relations. Furthermore, it allows us to apply a large pool of linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model prob-lems in the presence of latent variables, including structure discovery, inference, parameter learning, and latentfeature extraction. For instance, by making novel use of the spectral properties of the embedded distributions,we can design fast and local-minimum-free algorithms for discovering latent structures and learning latent pa-rameters. Another advantage of our framework is that it applies not only to general continuous variables, but also generalizes to variables which may take values on strings, graphs, groups, compact manifolds, and otherdomains on which kernels may be defined.</p> <p>This project has advanced the principles and technologies of latent structure analysisfor high-dimensional data with general distributions. It is a necessary step towards the ultimate, long term goalof understanding and exploiting latent structures and rich diverse statistical features prevalent in many modernapplications, such as computer vision, computational biology, social sciences, music research, and material sciences.&nbsp;</p> <p>As an interdisciplinary research effort, this project has not only led to development of new methodology, but also provide rich opportunities formulti-disciplinary educational and research training, at both undergraduate and graduate levels.&nbsp;</p><br> <p>            Last Modified: 01/01/2018<br>      Modified by: Le&nbsp;Song</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1218749/1218749_10213231_1514868625296_framework--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1218749/1218749_10213231_1514868625296_framework--rgov-800width.jpg" title="framework of the method"><img src="/por/images/Reports/POR/2018/1218749/1218749_10213231_1514868625296_framework--rgov-66x44.jpg" alt="framework of the method"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our framework consistsof both methodology development and target applications. The former addresses structure learning, inference, parameter learning, feature extraction, and large-scale implementation. The latterfocuses on vision and biology applications.</div> <div class="imageCredit">le song</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Le&nbsp;Song</div> <div class="imageTitle">framework of the method</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed a novel nonparametric latent vari-able modeling framework based on kernel embedding of distributions. The key idea is to map distributions into infinite dimensional feature spaces using kernels, such that subsequent comparisons and manipulations of distributions can be achieved via feature space operations, such as inner products, distances,projections, linear transformations and spectral analysis. The developed method can be used to address a range of latent variablemodel problems, including latent structure discovery, latent parameter learning, inference with latent variablesand latent feature extraction.  The developed framework allows us to model data with diverse statistical features without the need formaking restrictive assumptions about the type of distributions and relations. Furthermore, it allows us to apply a large pool of linear and multi-linear algebraic (tensor) tools for addressing challenging graphical model prob-lems in the presence of latent variables, including structure discovery, inference, parameter learning, and latentfeature extraction. For instance, by making novel use of the spectral properties of the embedded distributions,we can design fast and local-minimum-free algorithms for discovering latent structures and learning latent pa-rameters. Another advantage of our framework is that it applies not only to general continuous variables, but also generalizes to variables which may take values on strings, graphs, groups, compact manifolds, and otherdomains on which kernels may be defined.  This project has advanced the principles and technologies of latent structure analysisfor high-dimensional data with general distributions. It is a necessary step towards the ultimate, long term goalof understanding and exploiting latent structures and rich diverse statistical features prevalent in many modernapplications, such as computer vision, computational biology, social sciences, music research, and material sciences.   As an interdisciplinary research effort, this project has not only led to development of new methodology, but also provide rich opportunities formulti-disciplinary educational and research training, at both undergraduate and graduate levels.        Last Modified: 01/01/2018       Submitted by: Le Song]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
