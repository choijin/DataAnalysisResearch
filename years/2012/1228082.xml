<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Similarity-based Representation of Large-scale Image Collections</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>372050.00</AwardTotalIntnAmount>
<AwardAmount>372050</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This proposal is to develop a general representation framework that uses similarity to capture relationships in large scale image collections. The representation is not restricted to any specific distance function, feature, or learning model. It includes new methods to combine multiple kernels based on different cues, learn low-rank kernels, and improve indexing efficiency. In addition, new methods for nearest neighbor search and semi-supervised learning are proposed. It  has relevance to machine learning and computer vision research agendas.  Two major research problems addressed are: (1) defining and computing similarities between images' in vast, expanding, repositories, and representing those similarities in an efficient manner so the right pairs can be retrieved on demand; and (2) developing a system that can learn and predict similarities with 'sparse supervisory information and constantly evolving data.' The approach is notable in its embrace of the scale of web archives and its use of verbal and visual means of analysis.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/06/2012</MinAmdLetterDate>
<MaxAmdLetterDate>05/24/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1228082</AwardID>
<Investigator>
<FirstName>Svetlana</FirstName>
<LastName>Lazebnik</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Svetlana Lazebnik</PI_FULL_NAME>
<EmailAddress>slazebni@illinois.edu</EmailAddress>
<PI_PHON>2173335821</PI_PHON>
<NSF_ID>000298493</NSF_ID>
<StartDate>02/06/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress><![CDATA[SUITE A 1901 SOUTH FIRST ST.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~305050</FUND_OBLG>
<FUND_OBLG>2013~67000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual Merits:</p> <p>This project has significantly advanced the state of the art in image understanding technologies aimed at large, constantly evolving photo collections, such as images found on the Web. This project has resulted in the development of several similarity-preserving binary coding methods for content-aware compression of images for large-scale image retrieval, including the highly cited Iterative Quantization method that has become a standard baseline. It has also resulted in novel methods for joint modeling of images and text that can be used to search for images given keywords or descriptive sentences, or to return tags or sentences relevant to a query image. Another outcome of this project is a system for open-universe image parsing that can automatically interpret scenes consisting of hundreds of object categories, as well as infer the locations and shapes of object instances together with their overlap relationships. Finally, this project has explored technologies such as lifelong visual learning and active inference that can be used to dynamically learn visual models or make decisions based on the characteristics of the input.</p> <p>&nbsp;</p> <p>Broader impacts:</p> <p>Accurate and efficient visual representations are key to a number of technologies with high societal impact, from image search and consumer photo organization software, to situated recognition systems for robotics and assistance for the visually impaired. The research covered by the project has been integrated into undergraduate and graduate curricula, has been used to create demos for K-12 outreach activities, and has given educational and professional training opportunities for undergraduates, graduate students, and post-doctoral researchers. Publications, code, and data resulting from this research have been made publicly available on the Web.</p><br> <p>            Last Modified: 09/17/2015<br>      Modified by: Svetlana&nbsp;Lazebnik</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merits:  This project has significantly advanced the state of the art in image understanding technologies aimed at large, constantly evolving photo collections, such as images found on the Web. This project has resulted in the development of several similarity-preserving binary coding methods for content-aware compression of images for large-scale image retrieval, including the highly cited Iterative Quantization method that has become a standard baseline. It has also resulted in novel methods for joint modeling of images and text that can be used to search for images given keywords or descriptive sentences, or to return tags or sentences relevant to a query image. Another outcome of this project is a system for open-universe image parsing that can automatically interpret scenes consisting of hundreds of object categories, as well as infer the locations and shapes of object instances together with their overlap relationships. Finally, this project has explored technologies such as lifelong visual learning and active inference that can be used to dynamically learn visual models or make decisions based on the characteristics of the input.     Broader impacts:  Accurate and efficient visual representations are key to a number of technologies with high societal impact, from image search and consumer photo organization software, to situated recognition systems for robotics and assistance for the visually impaired. The research covered by the project has been integrated into undergraduate and graduate curricula, has been used to create demos for K-12 outreach activities, and has given educational and professional training opportunities for undergraduates, graduate students, and post-doctoral researchers. Publications, code, and data resulting from this research have been made publicly available on the Web.       Last Modified: 09/17/2015       Submitted by: Svetlana Lazebnik]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
