<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Statistical Methodology in Multi-view Learning with Large Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In complex scientific research classification and regression problems, it is common for several different data sets to be used to describe the response. Each of these data sets provides a unique view of the response, but typically none of these views describes the response perfectly.  The investigator develops computationally efficient statistical methodology to model multi-view data within a framework for statistical analysis, variable and view selection, and the interpretation of results.  The methodology is based on both regularization approaches involving sparse penalties in additive models and algorithmic intensive iterative-based approaches.  In addition, the investigator provides a solid foundation for analysis of residuals in this context, establishes the consistency of the model, and addresses the practical issue of concurvity. The investigator is committed to raising awareness in scientific research communities and industries of the advantages of using these modeling techniques in the analysis of complex research problems involving data from multiple sources and to training future statisticians and related professionals through hands-on experiences with these data sets.  To support this effort, the investigator develops and maintains a powerful, user-friendly statistical software package to implement this methodology.&lt;br/&gt;&lt;br/&gt;In the modern world our ability to collect data from many different sources has expanded dramatically due in part to computer innovations over the past few decades.  What has not kept pace is the ability to analyze data from many different sources simultaneously.  As a result, scientific researchers in academia and industry are not fully harnessing the information that can be found by appropriately combining multiple, diverse sources of data in a way that can provide interpretable results. This is a challenging problem involving advances in statistics, computer science, mathematics, and database management.  The investigator addresses this problem from a statistical analysis viewpoint.  Many applications of this research involve new statistical methods to help with cancer research, pharmacology, genetics, proteomics, text data processing, and homeland security.   The need for analyses of large, complex, multi-view data sets is substantial in scientific research today, and this need is currently unmet. The results of this work are transforming how researchers in many fields analyze and interpret data.</AbstractNarration>
<MinAmdLetterDate>02/25/2013</MinAmdLetterDate>
<MaxAmdLetterDate>02/25/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1255045</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Culp</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark V Culp</PI_FULL_NAME>
<EmailAddress>mculp@stat.wvu.edu</EmailAddress>
<PI_PHON>3049065422</PI_PHON>
<NSF_ID>000535745</NSF_ID>
<StartDate>02/25/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>West Virginia University Research Corporation</Name>
<CityName>Morgantown</CityName>
<ZipCode>265066845</ZipCode>
<PhoneNumber>3042933998</PhoneNumber>
<StreetAddress>P.O. Box 6845</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>West Virginia</StateName>
<StateCode>WV</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WV01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>191510239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WEST VIRGINIA UNIVERSITY RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[West Virginia University]]></Name>
<CityName>Morgantown</CityName>
<StateCode>WV</StateCode>
<ZipCode>265066845</ZipCode>
<StreetAddress><![CDATA[PO Box 6845]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>West Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WV01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>8048</Code>
<Text>Division Co-Funding: CAREER</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this research study the principal investigator developed a statistical methodology that allows for fitting a model on data from multiple sources while simultaneously providing for model selection and inference capabilities after the model is fit. For example, researchers have the ability to follow Internet chat rooms and keep a record of interactions between suspected terrorists. These interactions form a terrorist network, and the data can be thought of as a graph, where the nodes are individual terrorists, the edges between nodes indicate an interaction between two terrorists, and edge weights represent the frequency of those interactions. The researchers may also have demographic and background information on the terrorists that they would like to combine with the graph to identify ringleaders or predict a threat. They might want to know if the terrorist network information is actually useful for threat detection. How can a model be fit to these three data sources simultaneously to predict a threat? Which data source is most important for this problem? Are there interactions between data sources? These are practical, challenging, and important questions that were answered by the developments of this project.&nbsp;Specifically,&nbsp;techniques for model selection, tools for model inference and description, along with tools for addressing model instability and degeneracy were developed. The proposed estimator and all considerations for analysis after the model was fit were novel and developed. The need for this type of analysis exists in many other fields, including pharmacology, web and text analysis, genomics, and proteomics and these applications were addressed in this project.&nbsp;</p> <p>The educational component was two-fold: (1) enhancing Statistics education by mentoring undergraduate and graduate students and developing new courses for students in Statistics and for interdisciplinary fields, and (2) raising awareness in scientific research communities and industries of the advantages of using these modeling techniques in the analysis of complex research problems involving data from multiple sources.&nbsp;</p> <p>The integration of research and education was an essential part of this project and was absolutely necessary for the success of this work. In general, scientific researchers in academia and industry are not fully harnessing the information that can be found by appropriately combining and interpreting multiple, diverse sources of data. The principal investigator disseminated the results of the proposed work to this group of researchers via national conferences and direct contact with researchers in academia and industry. In addition, the principal investigator also provided a user-friendly, computationally efficient&nbsp;<strong>R&nbsp;</strong>package that incorporates the proposed methodology for public use. It is reasonable to believe that the applications of this methodology to scientific research problems not only promoted the progress of science but also benefited society.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/23/2018<br>      Modified by: Mark&nbsp;V&nbsp;Culp</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this research study the principal investigator developed a statistical methodology that allows for fitting a model on data from multiple sources while simultaneously providing for model selection and inference capabilities after the model is fit. For example, researchers have the ability to follow Internet chat rooms and keep a record of interactions between suspected terrorists. These interactions form a terrorist network, and the data can be thought of as a graph, where the nodes are individual terrorists, the edges between nodes indicate an interaction between two terrorists, and edge weights represent the frequency of those interactions. The researchers may also have demographic and background information on the terrorists that they would like to combine with the graph to identify ringleaders or predict a threat. They might want to know if the terrorist network information is actually useful for threat detection. How can a model be fit to these three data sources simultaneously to predict a threat? Which data source is most important for this problem? Are there interactions between data sources? These are practical, challenging, and important questions that were answered by the developments of this project. Specifically, techniques for model selection, tools for model inference and description, along with tools for addressing model instability and degeneracy were developed. The proposed estimator and all considerations for analysis after the model was fit were novel and developed. The need for this type of analysis exists in many other fields, including pharmacology, web and text analysis, genomics, and proteomics and these applications were addressed in this project.   The educational component was two-fold: (1) enhancing Statistics education by mentoring undergraduate and graduate students and developing new courses for students in Statistics and for interdisciplinary fields, and (2) raising awareness in scientific research communities and industries of the advantages of using these modeling techniques in the analysis of complex research problems involving data from multiple sources.   The integration of research and education was an essential part of this project and was absolutely necessary for the success of this work. In general, scientific researchers in academia and industry are not fully harnessing the information that can be found by appropriately combining and interpreting multiple, diverse sources of data. The principal investigator disseminated the results of the proposed work to this group of researchers via national conferences and direct contact with researchers in academia and industry. In addition, the principal investigator also provided a user-friendly, computationally efficient R package that incorporates the proposed methodology for public use. It is reasonable to believe that the applications of this methodology to scientific research problems not only promoted the progress of science but also benefited society.           Last Modified: 07/23/2018       Submitted by: Mark V Culp]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
