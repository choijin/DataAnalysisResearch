<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Graphical Approaches to Modeling High-Dimensional Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>294056.00</AwardTotalIntnAmount>
<AwardAmount>294056</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This research involves theoretical and applied research on learning and representation of high-&lt;br/&gt;dimensional data. The term high dimensionality refers to the property that the number of variables&lt;br/&gt;or ?unknowns? is typically much larger than the number of observations available at hand. A key&lt;br/&gt;challenge is being able to represent and learn such phenomena with sample and computational&lt;br/&gt;requirements scaling favorably in the number of dimensions. This project addresses these challenges&lt;br/&gt;through a graphical approach by exploiting the inherent graphical structure present in many large&lt;br/&gt;data-sets.&lt;br/&gt;&lt;br/&gt;This research considers modeling high-dimensional data through probabilistic graphical models,&lt;br/&gt;also known as Markov random fields. An important research thrust of this proposal is to develop&lt;br/&gt;novel algorithms for learning and inference under the framework of graphical models. Another&lt;br/&gt;important thrust of this proposal is to develop efficient scalable models for representing high-&lt;br/&gt;dimensional data beyond the traditional framework of graphical models. This research establishes&lt;br/&gt;strong theoretical guarantees for the developed methods, as well as applies them to real data in&lt;br/&gt;various domains, including genetic and financial data, and data from large online social networks&lt;br/&gt;such as Facebook and Twitter.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/15/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/15/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1219234</AwardID>
<Investigator>
<FirstName>Animashree</FirstName>
<LastName>Anandkumar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Animashree Anandkumar</PI_FULL_NAME>
<EmailAddress>anima@caltech.edu</EmailAddress>
<PI_PHON>6073422081</PI_PHON>
<NSF_ID>000542748</NSF_ID>
<StartDate>08/15/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926977600</ZipCode>
<StreetAddress><![CDATA[160 Aldrich Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~294056</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Research under this project involved learning and representation of high dimensional data.&nbsp;The term high dimensionality refers to the property that the number of variablesor &ldquo;unknowns&rdquo; is typically much larger than the number of observations available at hand. A key challenge is being able to represent and learn such phenomena with sample and computational requirements scaling favorably in the number of dimensions.&nbsp;This project addressed these challenges by exploiting the inherent relationships present in many large data-sets. We incorporated probabilistic graphical models with hidden variables and employed tensor factorization techniques to learn these models efficiently. In addition, we employed greedy graph-based techniques to learn challenging models such as mixtures of graphical models. We establish efficient computional and sample complexities for learning these model parameters consistently. We considered learning latent tree graphical models, which incorporate a hierarchy of latent variables, using &nbsp;divide and conquer techniques, which are used for parallelization without sacrificing on consistency guarantees. These techniques were employed in various domains such as social networks and bio-informatics, and were scalable to a large number of variables and data samples. These works have appeared in venues such as Neural Information Processing (NIPS), International Conference on Machine Learning (ICML), and Journal of Machine Learning Research (JMLR).</p><br> <p>            Last Modified: 08/13/2015<br>      Modified by: Animashree&nbsp;Anandkumar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Research under this project involved learning and representation of high dimensional data. The term high dimensionality refers to the property that the number of variablesor "unknowns" is typically much larger than the number of observations available at hand. A key challenge is being able to represent and learn such phenomena with sample and computational requirements scaling favorably in the number of dimensions. This project addressed these challenges by exploiting the inherent relationships present in many large data-sets. We incorporated probabilistic graphical models with hidden variables and employed tensor factorization techniques to learn these models efficiently. In addition, we employed greedy graph-based techniques to learn challenging models such as mixtures of graphical models. We establish efficient computional and sample complexities for learning these model parameters consistently. We considered learning latent tree graphical models, which incorporate a hierarchy of latent variables, using  divide and conquer techniques, which are used for parallelization without sacrificing on consistency guarantees. These techniques were employed in various domains such as social networks and bio-informatics, and were scalable to a large number of variables and data samples. These works have appeared in venues such as Neural Information Processing (NIPS), International Conference on Machine Learning (ICML), and Journal of Machine Learning Research (JMLR).       Last Modified: 08/13/2015       Submitted by: Animashree Anandkumar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
