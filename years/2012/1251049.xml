<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: Small: DA: Collaborative Research: From Data to Users: Providing Interpretable and Verifiable Explanations in Data Mining</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The fruits of data mining pervade every aspect of our lives.  We have books and movies recommended; we are given differential pricing for insurance; screened for potential terror threats; diagnosed with various diseases; and targeted for political advertising. The ability to sift through massive data sets with sophisticated algorithms has resulted in applications with impressive predictive power.  And yet there is still a gap between what such tools can deliver, and what the users of data mining really need. It is often hard to interpret the answers produced by a learning algorithm, due to its sophistication and the use of large data sets to build models. The results of mining are often "one-size-fits-all", and convincing a user that results are actually relevant to them is difficult.  Finally, there is the important problem of validation. As the results of data mining affect more and more of our lives, the more crucial it is that the user be able to validate decisions made on their behalf and that affect them. The common theme tying these issues together is a user-centric perspective on the problems of data mining. Rather than asking "What patterns can be found in this mountain of data?" this work instead asks "What structures in this data affect me?" These issues arise precisely because of the vast amounts of data we now have the ability to mine, and the sophisticated methods at our disposal to analyze this data. In this research, the PIs develop a computational framework and key tools for user-centric data mining. A central theme in this research is the idea of interaction. In both machine learning and in the foundations of complexity theory, interaction has been used to allow a (weaker) entity to probe a much more powerful system and determine answers that it lacks the resources to compute directly itself. The PIs use formal interaction mechanisms both from the perspective of a user interacting with a powerful algorithm, as well as a client interacting with a computing source with access to large data, in order to enable the user to interpret and validate the results of data mining. &lt;br/&gt;&lt;br/&gt;The goal of this project is to develop a computational framework for user-centric data mining  that enables existing users to tailor data analysis to their needs and facilitates the use of data mining in new areas where existing The team proposes interactive mechanisms that start with the results of a learning process and, via interaction with the user, produce an explanation expressed in terms of meaningful features, drawing on ideas from active learning, feature selection, and domain adaptation. 2. Locality: Answers that are relevant. Here, the focus is on providing information that depends more on a user?s local neighborhood, achieved via a new local notion of stability. 3. Verifiability: Answers you can check. The team proposes a framework for the validation of computationally-intensive data mining by the computationally-weak user, with ideas from interactive proof theory and stream algorithms. Tools for analyzing patient medical data have become more sophisticated and individual medical profiles play a far more significant role in diagnosis and treatment.The research examines user-centric data mining via three core primitives (classification, regression and clustering), and studies the three problems of interpreting results, providing local explanations, and validating the results of data mining. Firstly, the research draws on ideas from active learning, feature selection and domain adaptation to build interpretable results via interaction with users. Secondly, it introduces local notions of stability as a way of validating predictions for a specific user. Finally, it develops a general framework for validation of an analysis by a computationally-weak user, by drawing on ideas from the theory of interactive proofs and streaming algorithms.</AbstractNarration>
<MinAmdLetterDate>09/13/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1251049</AwardID>
<Investigator>
<FirstName>Suresh</FirstName>
<LastName>Venkatasubramanian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Suresh Venkatasubramanian</PI_FULL_NAME>
<EmailAddress>suresh@cs.utah.edu</EmailAddress>
<PI_PHON>8015818233</PI_PHON>
<NSF_ID>000074075</NSF_ID>
<StartDate>09/13/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Preston</FirstName>
<LastName>Fletcher</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Preston T Fletcher</PI_FULL_NAME>
<EmailAddress>tomfletcher@virginia.edu</EmailAddress>
<PI_PHON>8014409519</PI_PHON>
<NSF_ID>000569294</NSF_ID>
<StartDate>09/13/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<StreetAddress2><![CDATA[Second Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009095365</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF UTAH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009095365</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Utah]]></Name>
<CityName/>
<StateCode>UT</StateCode>
<ZipCode>841129249</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to enhance the design of tools for data analysis in a way that made them accessible to their (human) users. The research developed as part of this project focused on the following topics:</p> <ul> <li>Designing machine learning algorithms that provided insights into how the model made decisions by using simple hypothesis spaces that allowed us to interpret the results of decisions easily</li> <li>Designing ways to verify the results of a complex computation without requiring the resources to redo the computation.</li> <li>Applying these ideas in the setting of medical imaging, where the tools were used to generate explainable interpretations of MRI scans from heterogeneous sources.&nbsp;</li> </ul> <p>The outcomes from this research include:</p> <ul> <li>A technique for quantifying the strength of association of points with their clusters in a clustering algorithm. Doing so allows us to determine how strongly we believe the label a point is assigned during clustering</li> <li>A method for <em>locally</em>&nbsp;classifiying points using a mixture of kernels. This allows us to provide a local explanation for the classification label assigned to a point.&nbsp;</li> <li>A larger effort to construct automatic image templates for MRI scans drawn from different sites with different imaging modalities. The goal was to identify groups of image scans that retained common characteristics so that they could be classified together. The overall approach makes use of ideas from mutti-task learning in an Bayesian framework.&nbsp;</li> <li>A framework for <em>verifiable interactive computing</em>&nbsp;to allow a client to verify the results of computation performed on a powerful server without having to redo the entire computation. This framework yielded algorithms for verifying a number of common data analysis tasks like near neighbor search, clustering and shape fitting, as well as complexity theoretic results on the limits of such a computational framework.&nbsp;</li> <li>Further ideas for sublinear graph computation inspired by the work above for providing near optimal solutions for some intractable graph problems.&nbsp;</li> <li>An initial exploration of how decision-making might lead to unfair societal outcomes, which included both new research on how to remove discriminatory signals from training data prior to learning a model, as well as an axiomatic approach to thinking about the problems of (biased) decision-making in society.&nbsp;</li> </ul><br> <p>            Last Modified: 08/14/2018<br>      Modified by: Suresh&nbsp;Venkatasubramanian</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to enhance the design of tools for data analysis in a way that made them accessible to their (human) users. The research developed as part of this project focused on the following topics:  Designing machine learning algorithms that provided insights into how the model made decisions by using simple hypothesis spaces that allowed us to interpret the results of decisions easily Designing ways to verify the results of a complex computation without requiring the resources to redo the computation. Applying these ideas in the setting of medical imaging, where the tools were used to generate explainable interpretations of MRI scans from heterogeneous sources.    The outcomes from this research include:  A technique for quantifying the strength of association of points with their clusters in a clustering algorithm. Doing so allows us to determine how strongly we believe the label a point is assigned during clustering A method for locally classifiying points using a mixture of kernels. This allows us to provide a local explanation for the classification label assigned to a point.  A larger effort to construct automatic image templates for MRI scans drawn from different sites with different imaging modalities. The goal was to identify groups of image scans that retained common characteristics so that they could be classified together. The overall approach makes use of ideas from mutti-task learning in an Bayesian framework.  A framework for verifiable interactive computing to allow a client to verify the results of computation performed on a powerful server without having to redo the entire computation. This framework yielded algorithms for verifying a number of common data analysis tasks like near neighbor search, clustering and shape fitting, as well as complexity theoretic results on the limits of such a computational framework.  Further ideas for sublinear graph computation inspired by the work above for providing near optimal solutions for some intractable graph problems.  An initial exploration of how decision-making might lead to unfair societal outcomes, which included both new research on how to remove discriminatory signals from training data prior to learning a model, as well as an axiomatic approach to thinking about the problems of (biased) decision-making in society.         Last Modified: 08/14/2018       Submitted by: Suresh Venkatasubramanian]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
