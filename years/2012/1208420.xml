<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Small: Virtualized Welding: A New Paradigm for Intelligent Welding Robots in Unstructured Environment</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>800000.00</AwardTotalIntnAmount>
<AwardAmount>800000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Irina Dolinskaya</SignBlockName>
<PO_EMAI>idolinsk@nsf.gov</PO_EMAI>
<PO_PHON>7032927078</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is to develop a new robotic platform with novel 3D modeling and visualization algorithms. An existing "dumb" welding robot will be augmented with sensors to observe the work piece, as well as its surroundings.  New algorithms will be developed to record and reconstruct in 3D the welding process.  The reconstructed data are transmitted to a control room and visualized with augmented reality techniques: A skilled welder can look at the welding process from different angles, as if he/she was right next to the actual welding system. Welding parameters can be adjusted by the human (with intelligence) and executed by the robot (with precision). More importantly, the adjustment, together with the reconstructed welding process, will be recorded and analyzed. System modeling techniques will be developed to correlate the human adjustment with the 3D reconstruction of the welding process.  In this way, a welding robot can "learn by examples" the knowledge and experiences of a human welder and make similar intelligent adjustments by itself in the future.  &lt;br/&gt;&lt;br/&gt;The primary use for this new technology is in manufacturing. Successful completion of the proposed project paves the foundation for intelligent welding robots with closed-loop intelligent control.  Such a robotic system can perform high-speed and high-precision welding while allowing more variations in the work pieces and environments.  In addition, virtualized welding can be integrated with a mobile platform to allow welding in places that are hazardous or unsuitable for human welders.  The proposed welding extension platform will significantly expand the use of welding robots as well as reduce manufacturing costs.  Under-represented students will be recruited to participate in the research through exiting institutional programs.  Additional funding and industrial collaboration to transfer technology from research labs to industry will also be pursued.</AbstractNarration>
<MinAmdLetterDate>08/29/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208420</AwardID>
<Investigator>
<FirstName>YuMing</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>YuMing Zhang</PI_FULL_NAME>
<EmailAddress>ymzhang@engr.uky.edu</EmailAddress>
<PI_PHON>8593233262</PI_PHON>
<NSF_ID>000343234</NSF_ID>
<StartDate>08/29/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Catherine</FirstName>
<LastName>Carswell</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Catherine M Carswell</PI_FULL_NAME>
<EmailAddress>cmcars00@uky.edu</EmailAddress>
<PI_PHON>8593332492</PI_PHON>
<NSF_ID>000266359</NSF_ID>
<StartDate>08/29/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ruigang</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ruigang Yang</PI_FULL_NAME>
<EmailAddress>ryang@cs.uky.edu</EmailAddress>
<PI_PHON>8592573886</PI_PHON>
<NSF_ID>000129435</NSF_ID>
<StartDate>08/29/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Kentucky Research Foundation</Name>
<CityName>Lexington</CityName>
<ZipCode>405260001</ZipCode>
<PhoneNumber>8592579420</PhoneNumber>
<StreetAddress>109 Kinkead Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>KY06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>939017877</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF KENTUCKY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007400724</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Kentucky Research Foundation]]></Name>
<CityName>Lexington</CityName>
<StateCode>KY</StateCode>
<ZipCode>405260001</ZipCode>
<StreetAddress><![CDATA[500 S Limestone 109 Kinkead Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>KY06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~800000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The objectives of this proposed project are (a) to establish the hardware/software foundation to allow a welding robot to combine its accurate motion control and physical strengths with the intelligence of a human welder through real-time human-robot cooperation; and (b) to formulate a framework that can distill human intelligence in welding to robotic control algorithms<em>.</em></p> <p>Through the six years of research, the team established a human-robot collaborative system. In this system, a welder operates a torch to move along the weld seam in a remote station. The operation of the human welder is captured in the remote station by sensors to commend the motion of a robot in real-time. The robot moves the welding torch to perform the actual welding. This remote human-robot collaborative welding system allows a human welder to operate the torch as real but in a comfortable environment to more concentrate on the process control. This human-robot collaborative welding system also brings the real-time welding scene to the remote station through real-time imaging using cameras attached to the robot by projecting the live real-time scene to the remote station for the welder to view. The real-time view of the welding scene provides the process feedback for the human welder to adjust the operation in real-time. Advanced machine intelligence learning methods have contributed to accurate learning and modeling from the human input (welding process scene) and output (operation). The models learned/extracted using advanced machine intelligence learning methods have been used to program welding robot for intelligent robotic welding.</p> <p>The work on learning human welder intelligences using a physical remote system as stated above was focused on human response to dynamic 3D weld pool surface which is the process feedback.&nbsp;However, the results are achieved without variations in weld joint. Many applications involve variations in weld joint. Skilled welders have the abilities to see these variations to combine with the feedback from the process to adjust the welding parameters. To produce the needed large sets of data to learn human welder intelligences to make adjustment based on also these variations, the team established a virtual welding system in which a human operator operates a virtual welding torch such that the torch moves along the weld seam on a virtual work-piece. The virtual human-robot collaborative system can now be used for the human operator to commend the robot and the robot motion is displayed in the head mounted device worn by the human operator. The establishment of this system provides a platform to learn the human welder behaviors in more complex manufacturing environment and is expected to extend the human-robot collaborative welding beyond original scopes of this project.&nbsp;</p> <p>We have conducted the first user study intended to evaluate the augmented visualization that will be available to welders in the remote workstation, specifically for the purpose of monitoring the progress of welds, detecting evolving problems, and taking timely corrective actions. The augmentation of the digital feed was developed based on the Applied Cognitive Task Analysis (ACTA). In the ACTA based augmentation evaluation, we used a regular planar display with a near view of the weld pool from the perspective of the torch (torch view).</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/26/2018<br>      Modified by: Yuming&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The objectives of this proposed project are (a) to establish the hardware/software foundation to allow a welding robot to combine its accurate motion control and physical strengths with the intelligence of a human welder through real-time human-robot cooperation; and (b) to formulate a framework that can distill human intelligence in welding to robotic control algorithms.  Through the six years of research, the team established a human-robot collaborative system. In this system, a welder operates a torch to move along the weld seam in a remote station. The operation of the human welder is captured in the remote station by sensors to commend the motion of a robot in real-time. The robot moves the welding torch to perform the actual welding. This remote human-robot collaborative welding system allows a human welder to operate the torch as real but in a comfortable environment to more concentrate on the process control. This human-robot collaborative welding system also brings the real-time welding scene to the remote station through real-time imaging using cameras attached to the robot by projecting the live real-time scene to the remote station for the welder to view. The real-time view of the welding scene provides the process feedback for the human welder to adjust the operation in real-time. Advanced machine intelligence learning methods have contributed to accurate learning and modeling from the human input (welding process scene) and output (operation). The models learned/extracted using advanced machine intelligence learning methods have been used to program welding robot for intelligent robotic welding.  The work on learning human welder intelligences using a physical remote system as stated above was focused on human response to dynamic 3D weld pool surface which is the process feedback. However, the results are achieved without variations in weld joint. Many applications involve variations in weld joint. Skilled welders have the abilities to see these variations to combine with the feedback from the process to adjust the welding parameters. To produce the needed large sets of data to learn human welder intelligences to make adjustment based on also these variations, the team established a virtual welding system in which a human operator operates a virtual welding torch such that the torch moves along the weld seam on a virtual work-piece. The virtual human-robot collaborative system can now be used for the human operator to commend the robot and the robot motion is displayed in the head mounted device worn by the human operator. The establishment of this system provides a platform to learn the human welder behaviors in more complex manufacturing environment and is expected to extend the human-robot collaborative welding beyond original scopes of this project.   We have conducted the first user study intended to evaluate the augmented visualization that will be available to welders in the remote workstation, specifically for the purpose of monitoring the progress of welds, detecting evolving problems, and taking timely corrective actions. The augmentation of the digital feed was developed based on the Applied Cognitive Task Analysis (ACTA). In the ACTA based augmentation evaluation, we used a regular planar display with a near view of the weld pool from the perspective of the torch (torch view).                Last Modified: 11/26/2018       Submitted by: Yuming Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
