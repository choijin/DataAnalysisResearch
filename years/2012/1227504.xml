<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Large: Collaborative Research: Purposeful Prediction: Co-robot Interaction via Understanding Intent and Goals</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>520000.00</AwardTotalIntnAmount>
<AwardAmount>520000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In order for robots to collaborate with humans, they need to be able to accurately forecast human intent and action.  People act with purpose: that is, they make sequences of decisions to achieve long-term objectives. For instance, in driving from home to a store, people carefully plan a sequence of roads that will get them there efficiently. In predicting a person's next decision, algorithms must be developed that reflect these purposeful actions. &lt;br/&gt;&lt;br/&gt;Currently, robots are unable to anticipate human needs and goals, and this represents a fundamental barrier to their large-scale deployment in the home and workplace. The aim of this project is to develop a new science of purposeful prediction that can be applied to human-robot interaction across a wide variety of domains.  The work draws on recent techniques based on Inverse Optimal Control and Inverse Equilibria Theory that enable statistically sound reasoning about observed deliberate behavior. These new methods provide the foundations of a theoretical framework that integrates traditional decision making techniques like optimal control, search and planning with probabilistic methods that reason about uncertainty and hidden information, particularly about goals, utility and intent. &lt;br/&gt;&lt;br/&gt;Intellectual merit:  The project will provide a general framework that allows robots to anticipate and adapt to the activities of their human co-workers based on perceptual cues. The investigators will develop the theory, a computational toolbox, and, in collaboration with industrial partners, prototype deployments of these new methods for the prediction of peoples' behavior in a diverse set of robotics domains from computer vision to motor control. The project is transformative in that it combines a novel theoretical/algorithmic framework with extensive support in terms of volume of data and validation infrastructure in the context of many applications.        &lt;br/&gt;&lt;br/&gt;Broader impacts: A revolution in personal robotics in both the home and workplace depends on the ability to forecast human activities and intents; small- and medium- scale manufacturing will make a leap forward through agile robotic systems intelligent enough to understand and assist their co-workers in flexible assembly tasks; and robust models of pedestrian and vehicular traffic flow will enable more effective driver warning systems and safer autonomous mobile robots. Purposeful prediction technology is an important step towards enabling such understanding of actions and intents in these arenas. The research work will involve the training and mentoring of undergraduate, masters and doctoral students as well as post-doctoral fellows in this emerging multi-disciplinary research area at the intersection of computer and cognitive sciences and robotics.</AbstractNarration>
<MinAmdLetterDate>09/10/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1227504</AwardID>
<Investigator>
<FirstName>Joshua</FirstName>
<LastName>Tenenbaum</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joshua B Tenenbaum</PI_FULL_NAME>
<EmailAddress>jbt@mit.edu</EmailAddress>
<PI_PHON>6174522010</PI_PHON>
<NSF_ID>000468746</NSF_ID>
<StartDate>09/10/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394307</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~130000</FUND_OBLG>
<FUND_OBLG>2013~130000</FUND_OBLG>
<FUND_OBLG>2014~260000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Introduction</strong></p> <p>Humans need rich knowledge of the world and other people to succeed in everyday life. Our work is based on the premise that this knowledge can be modeled as an intuitive version of modern computer game engines, capable of representing 3D physical scenes with realistic physical dynamics and characters autonomously acting and interacting with others, based on individual mental states and shared tasks. Cast as a probabilistic program, this intuitive game engine can be inverted to support inferences about other&rsquo;s beliefs, desires, goals, and tasks, which are vital for successful social interaction. Endowing machines with probabilistic programs for inverting the intuitive game engine will enable robot teammates that are sensitive to social context, and that can coordinate with humans on shared goals and tasks.</p> <p>Our research program has generated several outcomes, each detailed below.</p> <p><strong>Inferring the intent of embodied motion</strong></p> <p>The aim is to infer the goal of a human actor from video of their actions and environment. This will enable a robot to predict a human teammate&rsquo;s future movements, and to intervene in ways the human finds helpful. We use the Mujoco physics engine to build an approximate physical model of a human agent and the structure of the task they are performing. We embed the intuitive game engine consisting of the physics and planning models within a probabilistic program. The probabilistic program assumes that physics and planning are the processes that generate a human actor&rsquo;s observed actions, conditioned on the physical model of the world, and a physical model of the human actor. We assume that the actions are sampled from a Gaussian distribution surrounding the optimized trajectory, resulting in a distribution over trajectories, which can be used to score observations.</p> <p><em>Results</em></p> <p>Our model inferences provide a rich set of qualitative and quantitative predictions that can be compared with human judgments. At the individual trial level, the fine-grained dynamics of the target inferences of the model can be compared directly with human data. At the level of different targets, the qualitative effects that closer targets are inferred faster, and that reaching across the body produces slower goal inferences can both be tested experimentally. (See Figure 1)</p> <p><strong>Modeling human reasoning about beliefs and desires</strong></p> <p>In addition to reasoning about other people&rsquo;s goals, the ability to reason about others&rsquo; beliefs and desires is critical for successful teamwork. Only by these inferences can one know what the appropriate helping action is in this case: to return the tool. In this thrust, we have designed algorithms for jointly inferring the beliefs and desires of agents from observations of their actions in a partially observable world. We performed two human behavioral experiments, each with a large number of stimulus conditions and multiple judgments per condition, and quantitatively compared our model predictions to human judgments. The resulting modeling of these data were described in the following journal paper.</p> <p><em>Publications</em></p> <p>Human mentalizing supports rational attribution of beliefs, desires, and percepts (2017). Chris L. Baker, Julian Jara-Ettinger, Rebecca Saxe, &amp; Joshua B. Tenenbaum. <em>Nature Human Behavior</em>, 1(0064).</p> <p><em>Results</em></p> <p>The model predicts human judgments with high accuracy across all 73 trials of this experiment; the correlation between the model and human desire judgments is <em>r=</em>0.91, and the correlation between the model and human belief judgments is <em>r</em>=0.78. (See Figure 2)</p> <p><strong>Coordinated action</strong></p> <p>The aim of this thrust is to build probabilistic programs that can infer teammates&rsquo; intent to coordinate, and respond appropriately, with actions that others expect and find helpful. For example, when performing a task such as cleaning up a table, human teammates will coordinate on which objects to pick up based on their proximity to different objects, on the mass of the objects relative to their respective strengths, and on the relative status relations between participants.</p> <p><em>Publications</em></p> <p><em>&nbsp;</em>Max Kleiman-Weiner, Mark K. Ho, Joseph L. Austerweil, Michael L. Littman, &amp; Joshua B. Tenenbaum. (2016). Coordinate to cooperate or compete: Abstract goals and joint intentions in social interaction. In Proceedings of the 38th Annual Conference of the Cognitive Science Society.</p> <p><em>Results</em></p> <p>In each of the examples, two players must move in the grid from their starting location to the location of various goals (marked by the amount of reward they provide), while coordinating with the other player to avoid collisions. The model captures many features of the human data, including the proportion of participants who cooperate within each experiment. (See Figure 3)</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/04/2017<br>      Modified by: Joshua&nbsp;B&nbsp;Tenenbaum</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272079654_NSF_Report_Figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272079654_NSF_Report_Figure1--rgov-800width.jpg" title="Figure 1"><img src="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272079654_NSF_Report_Figure1--rgov-66x44.jpg" alt="Figure 1"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 1: Inferring the intent of motion. (a) Structure of our probabilistic programming framework for intent inference. (b) Example results of inferring the intent of bodily motion. The model infers the correct goal in each case.</div> <div class="imageCredit">JBT</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Joshua&nbsp;B&nbsp;Tenenbaum</div> <div class="imageTitle">Figure 1</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272129793_NSF_Report_Figure2--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272129793_NSF_Report_Figure2--rgov-800width.jpg" title="Figure 2"><img src="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272129793_NSF_Report_Figure2--rgov-66x44.jpg" alt="Figure 2"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 2: Modeling human reasoning about beliefs and desires. (a) Causal schema of the Bayesian probabilistic program. (b) In a scenario with 3 food-trucks (Korean (K), Lebanese (L), and Mexican (M)) but only two parking spots. (c) In a scenario with 3 food-carts .</div> <div class="imageCredit">jbt</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Joshua&nbsp;B&nbsp;Tenenbaum</div> <div class="imageTitle">Figure 2</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272190305_NSF_Report_Figure3--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272190305_NSF_Report_Figure3--rgov-800width.jpg" title="Figure 3"><img src="/por/images/Reports/POR/2017/1227504/1227504_10212621_1508272190305_NSF_Report_Figure3--rgov-66x44.jpg" alt="Figure 3"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 3: Coordinated action. (a) Example results of our coordination framework using simulated humanoids in MuJoCo. (b) Participant data and model predictions.</div> <div class="imageCredit">jbt</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Joshua&nbsp;B&nbsp;Tenenbaum</div> <div class="imageTitle">Figure 3</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Introduction  Humans need rich knowledge of the world and other people to succeed in everyday life. Our work is based on the premise that this knowledge can be modeled as an intuitive version of modern computer game engines, capable of representing 3D physical scenes with realistic physical dynamics and characters autonomously acting and interacting with others, based on individual mental states and shared tasks. Cast as a probabilistic program, this intuitive game engine can be inverted to support inferences about other?s beliefs, desires, goals, and tasks, which are vital for successful social interaction. Endowing machines with probabilistic programs for inverting the intuitive game engine will enable robot teammates that are sensitive to social context, and that can coordinate with humans on shared goals and tasks.  Our research program has generated several outcomes, each detailed below.  Inferring the intent of embodied motion  The aim is to infer the goal of a human actor from video of their actions and environment. This will enable a robot to predict a human teammate?s future movements, and to intervene in ways the human finds helpful. We use the Mujoco physics engine to build an approximate physical model of a human agent and the structure of the task they are performing. We embed the intuitive game engine consisting of the physics and planning models within a probabilistic program. The probabilistic program assumes that physics and planning are the processes that generate a human actor?s observed actions, conditioned on the physical model of the world, and a physical model of the human actor. We assume that the actions are sampled from a Gaussian distribution surrounding the optimized trajectory, resulting in a distribution over trajectories, which can be used to score observations.  Results  Our model inferences provide a rich set of qualitative and quantitative predictions that can be compared with human judgments. At the individual trial level, the fine-grained dynamics of the target inferences of the model can be compared directly with human data. At the level of different targets, the qualitative effects that closer targets are inferred faster, and that reaching across the body produces slower goal inferences can both be tested experimentally. (See Figure 1)  Modeling human reasoning about beliefs and desires  In addition to reasoning about other people?s goals, the ability to reason about others? beliefs and desires is critical for successful teamwork. Only by these inferences can one know what the appropriate helping action is in this case: to return the tool. In this thrust, we have designed algorithms for jointly inferring the beliefs and desires of agents from observations of their actions in a partially observable world. We performed two human behavioral experiments, each with a large number of stimulus conditions and multiple judgments per condition, and quantitatively compared our model predictions to human judgments. The resulting modeling of these data were described in the following journal paper.  Publications  Human mentalizing supports rational attribution of beliefs, desires, and percepts (2017). Chris L. Baker, Julian Jara-Ettinger, Rebecca Saxe, &amp; Joshua B. Tenenbaum. Nature Human Behavior, 1(0064).  Results  The model predicts human judgments with high accuracy across all 73 trials of this experiment; the correlation between the model and human desire judgments is r=0.91, and the correlation between the model and human belief judgments is r=0.78. (See Figure 2)  Coordinated action  The aim of this thrust is to build probabilistic programs that can infer teammates? intent to coordinate, and respond appropriately, with actions that others expect and find helpful. For example, when performing a task such as cleaning up a table, human teammates will coordinate on which objects to pick up based on their proximity to different objects, on the mass of the objects relative to their respective strengths, and on the relative status relations between participants.  Publications   Max Kleiman-Weiner, Mark K. Ho, Joseph L. Austerweil, Michael L. Littman, &amp; Joshua B. Tenenbaum. (2016). Coordinate to cooperate or compete: Abstract goals and joint intentions in social interaction. In Proceedings of the 38th Annual Conference of the Cognitive Science Society.  Results  In each of the examples, two players must move in the grid from their starting location to the location of various goals (marked by the amount of reward they provide), while coordinating with the other player to avoid collisions. The model captures many features of the human data, including the proportion of participants who cooperate within each experiment. (See Figure 3)          Last Modified: 12/04/2017       Submitted by: Joshua B Tenenbaum]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
