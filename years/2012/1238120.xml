<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Technical Evaluation Assistance in Mathematics and Science (TEAMS)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2013</AwardEffectiveDate>
<AwardExpirationDate>04/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1199997.00</AwardTotalIntnAmount>
<AwardAmount>799997</AwardAmount>
<AwardInstrument>
<Value>Cooperative Agreement</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca A. Kruse</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This Research, Evaluation and Technical Assistance project awarded to RMC Research Corporation supports the needs of the evaluation community in the Math and Science Partnership (MSP) program, improving the quality of the evaluations of the MSP awards and building community capacity in evaluation design, methodology, analysis and reporting. This project conducts on-going needs assessments to ascertain barriers to high quality evaluations, provides increased access to instruments to measure a wide variety of important STEM education outcomes, and facilitates ongoing networking among MSP evaluators and investigators to improve evaluation. Evaluation design and implementation technical assistance includes direct help in determining how projects can best utilize rigorous experimental and strong quasi-experimental designs, how investigators and evaluators can best interact with schools and districts in order to ensure their cooperation, and how the findings of evaluations can best be communicated to a variety of audiences. The technical assistance will address new methodology in evaluation that includes the use of large scale, longitudinal databases of student outcomes, social network designs to examine collaboration and capacity building, and other methodologies coming from NSF programs such as Promoting Research and Innovation in Methodologies in Evaluation (PRIME). &lt;br/&gt;&lt;br/&gt;A multi-tiered technical assistance program provides different levels of help to projects. A website, available to the general STEM education public, provides information relevant to a wide range of topics for MSP evaluation. An online Help Desk provides more detailed assistance for NSF MSP projects. An on-going analysis of evaluation plans, reports and event services that are provided through interactions with MSP projects provides examples of ways that other projects have identified and addressed barriers to robust evaluation. A series of webinars that are archived for anytime viewing address common evaluation issues that have arisen in projects. &lt;br/&gt;&lt;br/&gt;Evaluation of funded projects is an important issue that goes well beyond the target population of the NSF and Title IIB (of the U.S. Department of Education) MSP funded projects. Increasingly, research and development projects in STEM education are being required to show evidence of impact or effectiveness of their efforts. The tools and designs that are needed to ensure that the information that is provided about those impacts is distributed across a variety of reports, journal articles and publications. This project, integrated with the ongoing MSP Learning Network, expands the support that is available for STEM educators who engage in professional development and research in STEM education.</AbstractNarration>
<MinAmdLetterDate>05/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>01/20/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>CoopAgrmnt</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1238120</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Sutton</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John T Sutton</PI_FULL_NAME>
<EmailAddress>jts95@comcast.net</EmailAddress>
<PI_PHON>3038706853</PI_PHON>
<NSF_ID>000391608</NSF_ID>
<StartDate>05/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Weaver</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David W Weaver</PI_FULL_NAME>
<EmailAddress>dweaver@rmcres.com</EmailAddress>
<PI_PHON>5032238248</PI_PHON>
<NSF_ID>000226633</NSF_ID>
<StartDate>05/16/2013</StartDate>
<EndDate>01/20/2016</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>RMC Research Corporation, OR</Name>
<CityName>Portsmouth</CityName>
<ZipCode>038013358</ZipCode>
<PhoneNumber>6034228888</PhoneNumber>
<StreetAddress>1000 Market St</StreetAddress>
<StreetAddress2><![CDATA[Building 2 Unit 9]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>146589593</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RMC RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>146589593</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[RMC Research Corporation]]></Name>
<CityName>Denver</CityName>
<StateCode>CO</StateCode>
<ZipCode>802023600</ZipCode>
<StreetAddress><![CDATA[633 17th St., Suite 2100]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1793</Code>
<Text>MSP-OTHER AWARDS</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0414</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~399999</FUND_OBLG>
<FUND_OBLG>2014~399998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The Technical Evaluation Assistance in Mathematics and Science (TEAMS) project, funded (DRL 1238120) through the Mathematics and Science Partnership (MSP) Research, Evaluation, and Technical Assistance (RETA) program was in operation between May 15, 2013 and April 30, 2016. The long-term goal of the TEAMS project was to strengthen the quality of MSP project evaluation and build the capacity of evaluators by strengthening their skills related to evaluation design, methodology, analysis, and reporting. The primary means of building capacity took the forms of responding to Help Desk inquiries; providing intensive and focused technical assistance to projects such as reviewing instruments and evaluation plans; providing &ldquo;just in time&rdquo; consultation and targeted technical assistance to individual evaluators and/or projects; webinars on focused evaluation topics identified through a needs assessment and feedback; and products, publications, and materials on topics of interest to MSP evaluators based on emerging trends and identified needs. &nbsp;</p> <p>&nbsp;</p> <p>While in operation over the full duration of the project:</p> <p>TEAMS staff provided literature and research-based responses to 38 Help Desk queries; prepared and provided services and intensive technical assistance to 31 individuals representing projects; and provided consultation and targeted technical assistance to 82 individuals and/or projects.</p> <p>&nbsp;</p> <p>TEAMS staff prepared, presented, and facilitated 27 webinars on a variety of topics relevant to MSP project evaluators, Principal Investigators, and others. All webinars were recorded and placed on the teams.mspnet.org website. According to the TEAMS external evaluation report, &ldquo;the total number of viewings [of TEAMS webinars] exceeds 1800 (1149 live participants plus 660 recorded views as of 3/29/2016). This is a substantial number of viewings for webinars designed to build evaluation capacity! When averaging actual attendance in the webinars and the number of views of webinar recordings through March, 2016, the average number of &ldquo;participants&rdquo; is 72 people per webinar&mdash;quite a large reach. The webinars reached people in 6 countries, nearly 200 universities or university departments, 9 state offices of education as well as many regional offices of education and school districts/schools, well over 100 organizations specializing in evaluation that were not listed as MSP evaluators in the list provided by TEAMS, 25 federal or state agencies, and numerous non-profit organizations and for-profit businesses.&rdquo;</p> <p>&nbsp;</p> <p>TEAMS staff TEAMS staff provided or facilitated more than 15 presentations at relevant conferences including the annual NSF MSP Learning Network meeting, the USED MSP conference, and the American Evaluation Association (AEA) annual conference. Conference presentation materials are archived on the teams.mspnet.org website. According to the TEAMS external evaluation report [regarding presentations in 2015-2016 only], &ldquo;sessions drew approximately 200 people (not including the poster session, for which no data were collected), engaged enthusiastic participants in meaningful discussions and/or activities, and resulted in changed practices for five of the seven (over 70%) of those who were interviewed&mdash;a result that surprised this evaluator who often attends conference sessions, leaves enthused, but returns home to implement few new concepts!&rdquo; All TEAMS conference presentation materials are located on the teams.mspnet.org website under TEAMS Resources or Showcase sections.</p> <p>&nbsp;</p> <p>TEAMS staff created and posted on the teams.mspnet.org website eight publications over the course of the project that address a variety of topics and have the potential to contribute to evaluation capacity building over time. These publications, able to be downloaded as pdf files, a...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Technical Evaluation Assistance in Mathematics and Science (TEAMS) project, funded (DRL 1238120) through the Mathematics and Science Partnership (MSP) Research, Evaluation, and Technical Assistance (RETA) program was in operation between May 15, 2013 and April 30, 2016. The long-term goal of the TEAMS project was to strengthen the quality of MSP project evaluation and build the capacity of evaluators by strengthening their skills related to evaluation design, methodology, analysis, and reporting. The primary means of building capacity took the forms of responding to Help Desk inquiries; providing intensive and focused technical assistance to projects such as reviewing instruments and evaluation plans; providing "just in time" consultation and targeted technical assistance to individual evaluators and/or projects; webinars on focused evaluation topics identified through a needs assessment and feedback; and products, publications, and materials on topics of interest to MSP evaluators based on emerging trends and identified needs.       While in operation over the full duration of the project:  TEAMS staff provided literature and research-based responses to 38 Help Desk queries; prepared and provided services and intensive technical assistance to 31 individuals representing projects; and provided consultation and targeted technical assistance to 82 individuals and/or projects.     TEAMS staff prepared, presented, and facilitated 27 webinars on a variety of topics relevant to MSP project evaluators, Principal Investigators, and others. All webinars were recorded and placed on the teams.mspnet.org website. According to the TEAMS external evaluation report, "the total number of viewings [of TEAMS webinars] exceeds 1800 (1149 live participants plus 660 recorded views as of 3/29/2016). This is a substantial number of viewings for webinars designed to build evaluation capacity! When averaging actual attendance in the webinars and the number of views of webinar recordings through March, 2016, the average number of "participants" is 72 people per webinar&mdash;quite a large reach. The webinars reached people in 6 countries, nearly 200 universities or university departments, 9 state offices of education as well as many regional offices of education and school districts/schools, well over 100 organizations specializing in evaluation that were not listed as MSP evaluators in the list provided by TEAMS, 25 federal or state agencies, and numerous non-profit organizations and for-profit businesses."     TEAMS staff TEAMS staff provided or facilitated more than 15 presentations at relevant conferences including the annual NSF MSP Learning Network meeting, the USED MSP conference, and the American Evaluation Association (AEA) annual conference. Conference presentation materials are archived on the teams.mspnet.org website. According to the TEAMS external evaluation report [regarding presentations in 2015-2016 only], "sessions drew approximately 200 people (not including the poster session, for which no data were collected), engaged enthusiastic participants in meaningful discussions and/or activities, and resulted in changed practices for five of the seven (over 70%) of those who were interviewed&mdash;a result that surprised this evaluator who often attends conference sessions, leaves enthused, but returns home to implement few new concepts!" All TEAMS conference presentation materials are located on the teams.mspnet.org website under TEAMS Resources or Showcase sections.     TEAMS staff created and posted on the teams.mspnet.org website eight publications over the course of the project that address a variety of topics and have the potential to contribute to evaluation capacity building over time. These publications, able to be downloaded as pdf files, are listed below.  - Sutton, John T., Mitchell, A., Callow-Heusser, Catherine, Culbertson, Michael J., Espel, Emma, &amp; Weston-Sementelli, Jennifer. (April, 2016). TEAMS External Feedback ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
