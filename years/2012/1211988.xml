<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Topics in Stochastic Control and Financial Mathematics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>291887.00</AwardTotalIntnAmount>
<AwardAmount>291887</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Steuerwalt</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Sirbu&lt;br/&gt;DMS-1211988&lt;br/&gt;&lt;br/&gt;     The investigator studies problems in stochastic control and financial mathematics.  The first and most important topic is a new look at the dynamic programming method in continuous-time stochastic control using a novel version of Perron's method.  Taking the supremum of stochastic sub-solutions and infimum of stochastic super-solutions, the new method provides two viscosity solutions squeezing between them the value function.  Uniqueness of the viscosity solution (in case it holds) then easily shows that the value function is the unique solution of the dynamic programming equation.  The dynamic programming principle is obtained as a conclusion using this approach, without any a priori analysis of the value function.  This amounts to verification without smoothness of the existence of a viscosity solution (similar to the verification argument in the classic case).  The second topic of the project resides in understanding the incentives of high-watermark fees on the fund manager, by modeling his/her strategic behavior.  The investigator and his colleagues study the optimal choice of the fund manager among available assets (that leads to the fund share price), such that the rational behavior of the investor (utility maximization on her side) yields maximal fees paid to the manager.  The third topic is a first step into understanding information percolation in the context of mean-field games of optimal stopping.  &lt;br/&gt;&lt;br/&gt;     Any decision under uncertainty can be modeled as a stochastic control/optimization problem.  This applies not only to finance and economics but to engineering and life sciences.  The current project mainly consists in a new technical approach to a very general class of stochastic control problems.  The new approach provides a deeper understanding of the optimization problems, and it also extends the scope of applications.  In addition, the project models and studies the strategic behavior of fund managers, as well as the percolation of information among populations that interact randomly.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1211988</AwardID>
<Investigator>
<FirstName>Mihai</FirstName>
<LastName>Sirbu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mihai Sirbu</PI_FULL_NAME>
<EmailAddress>sirbu@math.utexas.edu</EmailAddress>
<PI_PHON>5124715161</PI_PHON>
<NSF_ID>000219317</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121068</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1266</Code>
<Text>APPLIED MATHEMATICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7552</Code>
<Text>COFFES</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~191332</FUND_OBLG>
<FUND_OBLG>2014~100555</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Stochastic control problems model a wide range of decisions under uncertainty. One of the main tools to attack such problems is the dynamic programming method. In discrete models, &nbsp;the method amounts to splitting a dynamic problem into much simpler one period problems. For continuous time stochastic control, the situation is more complicated, and the method reduces to solving a partial differential equation. &nbsp;If the differential equation (called Hamilton-Jacobi-Bellman) has a smooth solution, it can be used to find the optimal controls in feedback form, and the solution of the equation is equal to the optimal payoff. &nbsp;</p> <p>The present award mostly focused on the dynamic programming method for situations when the Hamilton-Jacobi-Bellman equation does not have a smooth solution. One of the main outcomes is to introduce a novel method &nbsp;to &nbsp;approach dynamic programming &nbsp;and show that the non-smooth solution of the partial differential equation is equal to the optimal payoff. The method is not only a technical contribution (based on a modification of Perron's method), but brings deeper understanding into dynamic programming for continuous time stochastic control problems.</p> <p><br />Another very important &nbsp;outcome is the modeling and &nbsp;dynamic programming analysis of zero-sum stochastic differential games. Strategic games are well known to pose problems in both modeling strategies of individual players and the mathematical analysis of the resulting model. Using a natural framework of feedback strategies (and counter-strategies), &nbsp;different modifications of Perron's method &nbsp;relate the values of the games to the solutions of the Hamilton-Jacobi-Bellman-Isaacs equation. Most importantly, this provides a streamlined argument to showing that such games have a value, and this value can actually be attained over &nbsp; strategies/counter-strategies that take into account only the current position of the player, and not the whole past (so called, Markovian). At the technical level this requires a finer analysis than the one done above (even in the case of control problems, with one player) and the technique introduced by the PI is another novel modification of Perron's method.&nbsp;</p> <p><br />Overall, these sum up to more than interesting technical contributions to modeling and analysis of zero-sum games and stochastic control&nbsp;problems. The outcomes of the award bring &nbsp;a &nbsp;fresh look to important classes of models &nbsp; covering &nbsp;wide ranges of real-life situations.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/14/2016<br>      Modified by: Mihai&nbsp;Sirbu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Stochastic control problems model a wide range of decisions under uncertainty. One of the main tools to attack such problems is the dynamic programming method. In discrete models,  the method amounts to splitting a dynamic problem into much simpler one period problems. For continuous time stochastic control, the situation is more complicated, and the method reduces to solving a partial differential equation.  If the differential equation (called Hamilton-Jacobi-Bellman) has a smooth solution, it can be used to find the optimal controls in feedback form, and the solution of the equation is equal to the optimal payoff.    The present award mostly focused on the dynamic programming method for situations when the Hamilton-Jacobi-Bellman equation does not have a smooth solution. One of the main outcomes is to introduce a novel method  to  approach dynamic programming  and show that the non-smooth solution of the partial differential equation is equal to the optimal payoff. The method is not only a technical contribution (based on a modification of Perron's method), but brings deeper understanding into dynamic programming for continuous time stochastic control problems.   Another very important  outcome is the modeling and  dynamic programming analysis of zero-sum stochastic differential games. Strategic games are well known to pose problems in both modeling strategies of individual players and the mathematical analysis of the resulting model. Using a natural framework of feedback strategies (and counter-strategies),  different modifications of Perron's method  relate the values of the games to the solutions of the Hamilton-Jacobi-Bellman-Isaacs equation. Most importantly, this provides a streamlined argument to showing that such games have a value, and this value can actually be attained over   strategies/counter-strategies that take into account only the current position of the player, and not the whole past (so called, Markovian). At the technical level this requires a finer analysis than the one done above (even in the case of control problems, with one player) and the technique introduced by the PI is another novel modification of Perron's method.    Overall, these sum up to more than interesting technical contributions to modeling and analysis of zero-sum games and stochastic control problems. The outcomes of the award bring  a  fresh look to important classes of models   covering  wide ranges of real-life situations.                             Last Modified: 10/14/2016       Submitted by: Mihai Sirbu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
