<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: System Support for SSD-Backed Recoverable Network Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The massive hardware scale, labyrinthine software complexity, and tangled external interactions of networked systems conspire to undermine reliability: Scale increases the frequency of failures while interconnectedness exacerbates their consequences by turning local mishaps into global disasters.  This project will establish new system support toward recoverable network applications on two foundations.  In an individual machine, fast, simple application recovery can be greatly eased if the application state on the persistent storage is kept always consistent.  Over a networked system, the fault-tolerance and global consistency can be better supported and reasoned if application components commit local state before emitting any output to others.  The time is right for this effort, because emerging Flash-based solid-state disks (SSDs) promise to dramatically reduce the cost of required persistent state management.  Research will proceed along three fronts:  First, the project will design and implement a new operating system mechanism (fast synchronous logging without double writes) for failure-atomic, synchronous I/O on SSDs.  Second, for broad applicability, this project will present the programmers with simple extensions of familiar POSIX interfaces.  Third, to achieve efficiency and fairness, research will develop a new I/O resource manager that combines the classic fair queuing scheduling with SSD-oriented anticipatory I/O.  Fast, simple failure recovery mechanisms developed in this project will enable high reliability for a broad range of networked applications that are critical to today's digital economy and society.  This project will also involve industry collaboration, curriculum enhancement, and student training.</AbstractNarration>
<MinAmdLetterDate>08/20/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1217372</AwardID>
<Investigator>
<FirstName>Kai</FirstName>
<LastName>Shen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kai Shen</PI_FULL_NAME>
<EmailAddress>kshen@cs.rochester.edu</EmailAddress>
<PI_PHON>5852755426</PI_PHON>
<NSF_ID>000489991</NSF_ID>
<StartDate>08/20/2012</StartDate>
<EndDate>07/06/2016</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Huang</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael C Huang</PI_FULL_NAME>
<EmailAddress>michael.huang@rochester.edu</EmailAddress>
<PI_PHON>5852752111</PI_PHON>
<NSF_ID>000300067</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146270140</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>In today's computing landscape, the massive hardware scale, labyrinthine software complexity, and tangled external interactions of networked systems conspire to undermine reliability: Scale increases the frequency of failures while interconnectedness exacerbates their consequences by turning local mishaps into global disasters. This project set out to eastablish new system support toward recoverable network applications on two foundations. In an individual machine, fast, simple application recovery can be greatly eased if the application state on the persistent storage is kept always consistent. Over a networked system, the fault-tolerance and global consistency can be better supported and reasoned if application components commit local state before emitting any output to others.&nbsp;</span></p> <p><span>This project has developed system-level techniques and application support for efficient, fair, reliable data management on Flash-based solid state disks.&nbsp; Significant outcomes include the development of two new Flash I/O schedulers in the operating system.&nbsp; Our FIOS scheduler achieved fairness along with high efficiency for Flash I/O.&nbsp; Our FlashFQ scheduler further enhanced the Flash I/O responsiveness by leveraging classic fair queueing resource scheduling that was primarily used in network packet switching.</span><br /><br /><span>Fast, simple application recovery can be greatly eased if the application state on the persistent storage is kept always consistent.&nbsp; Emerging Flash-based SSDs promise to dramatically reduce the cost of required persistent state management.&nbsp; Another outcome of this project was the development of a new OS interface, called failure-atomic msync(), and efficient I/O system support for broad applicability of consistent, durable I/O.&nbsp; Our new primitive enables reliable, efficient data management through a simple, POSIX-like programming interface.</span></p><br> <p>            Last Modified: 11/16/2017<br>      Modified by: Michael&nbsp;C&nbsp;Huang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In today's computing landscape, the massive hardware scale, labyrinthine software complexity, and tangled external interactions of networked systems conspire to undermine reliability: Scale increases the frequency of failures while interconnectedness exacerbates their consequences by turning local mishaps into global disasters. This project set out to eastablish new system support toward recoverable network applications on two foundations. In an individual machine, fast, simple application recovery can be greatly eased if the application state on the persistent storage is kept always consistent. Over a networked system, the fault-tolerance and global consistency can be better supported and reasoned if application components commit local state before emitting any output to others.   This project has developed system-level techniques and application support for efficient, fair, reliable data management on Flash-based solid state disks.  Significant outcomes include the development of two new Flash I/O schedulers in the operating system.  Our FIOS scheduler achieved fairness along with high efficiency for Flash I/O.  Our FlashFQ scheduler further enhanced the Flash I/O responsiveness by leveraging classic fair queueing resource scheduling that was primarily used in network packet switching.  Fast, simple application recovery can be greatly eased if the application state on the persistent storage is kept always consistent.  Emerging Flash-based SSDs promise to dramatically reduce the cost of required persistent state management.  Another outcome of this project was the development of a new OS interface, called failure-atomic msync(), and efficient I/O system support for broad applicability of consistent, durable I/O.  Our new primitive enables reliable, efficient data management through a simple, POSIX-like programming interface.       Last Modified: 11/16/2017       Submitted by: Michael C Huang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
