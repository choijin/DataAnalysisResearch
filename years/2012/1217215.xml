<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: Collaborative Research: A System of Animation Gestures for Effective Teaching Avatars</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>315000.00</AwardTotalIntnAmount>
<AwardAmount>315000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project addresses the challenge of making avatars used in tutoring systems and other learning technologies more engaging and more effective learning guides. One focus is on making the movements of an avatar more lifelike; a second focus is on understanding how to effectively integrate gestures indicating friendliness with gestures used for promoting concept learning.  Design of avatar gestures draws on the literature on the roles of gesturing in communication, the literature on grounded and embodied cognition, and the literature on mathematics.  The focus of this Cyberlearning: Transforming Education Exploration proposal is on designing avatar gestures for promoting learning of mathematical equivalence. Analysis of the effects of those gestures and extraction of preliminary guidelines for gesture design will lay the groundwork for extending gesturing capabilities of avatars across disciplinary content areas. Research focuses on how to automatically animate an avatar with life-like qualities and the conditions under which adding gestures to a teaching avatar promotes engagement and learning.&lt;br/&gt;&lt;br/&gt;Avatars are used extensively in learning technologies to guide learners' actions and to provide advice. But learners can be put off by avatars that are emotionless, and avatars technology does not yet combine gesturing and "talking" in the way good tutors and teachers do as they are trying to help learners learn difficult concepts. This project addresses both of those issues -- giving avatars enough personality so that learners will engage with them more readily and willingly and giving avatars the capability of gesturing in ways that are congruent with the concepts they are expressing. There are a variety of challenges in addressing these issues, some technical, some social, and some cognitive. The project team is addressing all three types of issues, working towards design principles for avatars that move and engage more naturally and that can gesture as people do when explaining difficult content. Enhancing the interactions between computers and people in ways that promote both sustained engagement and learning will improve the effectiveness of intelligent tutoring systems and other learning technologies across disciplines and across the ages of learners.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1217215</AwardID>
<Investigator>
<FirstName>Nicoletta</FirstName>
<LastName>Adamo-Villani</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nicoletta Adamo-Villani</PI_FULL_NAME>
<EmailAddress>nadamovi@purdue.edu</EmailAddress>
<PI_PHON>7654961297</PI_PHON>
<NSF_ID>000490363</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Voicu</FirstName>
<LastName>Popescu</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Voicu S Popescu</PI_FULL_NAME>
<EmailAddress>popescu@cs.purdue.edu</EmailAddress>
<PI_PHON>7654946010</PI_PHON>
<NSF_ID>000255170</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072107</ZipCode>
<StreetAddress><![CDATA[305 North University Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0412</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~315000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The project advances education, in particular mathematics education, (1) by advancing the understanding of what instructor gestures increase student learning, and (2) by improving the ability to create digital learning materials that are delivered eloquently.</p> <p>(1) Instructor gestures are long known to be important, but it is not yet fully understood what, when, and how gestures increase learning. Traditionally, the impact of instructor gestures has been researched through experiments that rely on video stimuli. The researcher gives an instructor a script with what the instructor should say, what gestures they should make, and when the gestures should be made relative to the speech. Then the instructor is video recorded as they act out the script. The problem with video stimuli is that the instructor has to focus on remembering the script and cannot teach freely. Furthermore, the secondary parameters such as enthusiasm level, body pose, and gaze cannot be controlled precisely from one condition to the other, which introduces confounding factors.</p> <p>This project has developed a system of instructor avatars that allows generating complex&nbsp;stimuli for instructor gesture research, with perfect control of secondary parameters. The instructor is modeled with a computer animation character. The instructor avatar is controlled through a text script, similar to the script used to record traditional video stimuli. The system produces high-quality animation without the prerequisites of computer animation or programming skills.</p> <p>The system was used to produce stimuli for a number of instructor gesture experiments. In one experiment the project team found that, just like in the case of real life instructors, instructor avatars gesture during&nbsp;a mathematical equivalence lesson leads to more student learning. In another experiment the project team found that instructor gestures increase learning the most when gestures are timed such as to slightly precede speech. In another experiment the project team tested 18 types of gestures and found that parallel, outward-focused gestures convey an engaging, charismatic personality to the instructor avatar.</p> <p>(2) In addition to providing infrastructure support to instructor gesture research, the system of instructor avatars also has potential as a software tool for the rapid and scalable authoring of eloquently delivered digital learning materials.</p> <p>First, the animation produced by the system through scripting has been compared by experts to manual animation and it has been found to be of high quality. This indicates that the system removes the manual animation bottleneck that precludes the widespread use of instructor avatars in digital learning materials.</p> <p>In addition to the script-based interface, the system also has a graphical user interface that allows animating the instructor avatar without having to learn the scripting language, which further simplifies the authoring of digital learning materials.</p> <p>Finally, the system was extended to generate additional instances of a problem automatically, by modifying the script of a reference problem instance. For example, the author of digital learning materials on mathematical equivalence only has to script one sample mathematical equivalence, and the system can automatically create tens of hours of additional examples with mathematical equivalences with different addends. The avatar speech and gesture are adapted automatically to each new problem instance.</p><br> <p>            Last Modified: 10/27/2016<br>      Modified by: Voicu&nbsp;S&nbsp;Popescu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1217215/1217215_10213336_1477585882526_image001--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1217215/1217215_10213336_1477585882526_image001--rgov-800width.jpg" title="Instructor Avatar Making Balance Gesture"><img src="/por/images/Reports/POR/2016/1217215/1217215_10213336_1477585882526_image001--rgov-66x44.jpg" alt="Instructor Avatar Making Balance Gesture"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The instructor avatar makes an embodied cognition balance gesture to illustrate the equilibrium between the left and the right side of the equation.</div> <div class="imageCredit">Purdue University</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Voicu&nbsp;S&nbsp;Popescu</div> <div class="imageTitle">Instructor Avatar Making Balance Gesture</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project advances education, in particular mathematics education, (1) by advancing the understanding of what instructor gestures increase student learning, and (2) by improving the ability to create digital learning materials that are delivered eloquently.  (1) Instructor gestures are long known to be important, but it is not yet fully understood what, when, and how gestures increase learning. Traditionally, the impact of instructor gestures has been researched through experiments that rely on video stimuli. The researcher gives an instructor a script with what the instructor should say, what gestures they should make, and when the gestures should be made relative to the speech. Then the instructor is video recorded as they act out the script. The problem with video stimuli is that the instructor has to focus on remembering the script and cannot teach freely. Furthermore, the secondary parameters such as enthusiasm level, body pose, and gaze cannot be controlled precisely from one condition to the other, which introduces confounding factors.  This project has developed a system of instructor avatars that allows generating complex stimuli for instructor gesture research, with perfect control of secondary parameters. The instructor is modeled with a computer animation character. The instructor avatar is controlled through a text script, similar to the script used to record traditional video stimuli. The system produces high-quality animation without the prerequisites of computer animation or programming skills.  The system was used to produce stimuli for a number of instructor gesture experiments. In one experiment the project team found that, just like in the case of real life instructors, instructor avatars gesture during a mathematical equivalence lesson leads to more student learning. In another experiment the project team found that instructor gestures increase learning the most when gestures are timed such as to slightly precede speech. In another experiment the project team tested 18 types of gestures and found that parallel, outward-focused gestures convey an engaging, charismatic personality to the instructor avatar.  (2) In addition to providing infrastructure support to instructor gesture research, the system of instructor avatars also has potential as a software tool for the rapid and scalable authoring of eloquently delivered digital learning materials.  First, the animation produced by the system through scripting has been compared by experts to manual animation and it has been found to be of high quality. This indicates that the system removes the manual animation bottleneck that precludes the widespread use of instructor avatars in digital learning materials.  In addition to the script-based interface, the system also has a graphical user interface that allows animating the instructor avatar without having to learn the scripting language, which further simplifies the authoring of digital learning materials.  Finally, the system was extended to generate additional instances of a problem automatically, by modifying the script of a reference problem instance. For example, the author of digital learning materials on mathematical equivalence only has to script one sample mathematical equivalence, and the system can automatically create tens of hours of additional examples with mathematical equivalences with different addends. The avatar speech and gesture are adapted automatically to each new problem instance.       Last Modified: 10/27/2016       Submitted by: Voicu S Popescu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
