<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: Small: DCM: DA: Collaborative Research: SMASH -- Scalable Multimedia content AnalysiS in a High-level language</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>403982.00</AwardTotalIntnAmount>
<AwardAmount>419982</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This big data project develops tools to support researchers and developers in the task of prototyping multimedia content analysis algorithms in a large scale. Typically, scientists and engineers prefer to use high-level programming languages such as Python or MATLAB to conduct experiments, as they allow for a quick implementation of a novel idea. Experiments on big data, however, are often computationally-intensive and therefore must eventually be recoded into a low-level language by expert programmers in order to achieve sufficient performance, creating a gap between productivity and performance. In addition, multiple strategies may exist for mapping a problem onto parallel hardware depending on the input data size and the hardware parameters, further exacerbating the problem. Using the  application area of multimedia content analysis as an example (an area with one of the largest and the fastest growing amounts of data due to the steady upload of consumer produced videos), this project performs research on a pattern-oriented, application-specific specialization framework that uses a tiered approach to parallel  programming. The ultimate aim is to provide the scalability of diverse parallel processing at the productivity level of high-level languages.&lt;br/&gt;&lt;br/&gt;Social media videos are increasingly being used for scientific research, as they allow us to observe and model many phenomena studied, for example, in social sciences, economics, meteorology and medicine. More scalable content analysis impacts any field that uses social media videos. Moreover, social media videos are an everyday part of many people's lives. Making multimedia content analysis more scalable allows for better algorithms to be developed by more students and researchers, and therefore impacts many people's lives. The framework is made available on the project website (http://smash.icsi.berkeley.edu).</AbstractNarration>
<MinAmdLetterDate>06/12/2013</MinAmdLetterDate>
<MaxAmdLetterDate>04/26/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1251276</AwardID>
<Investigator>
<FirstName>Gerald</FirstName>
<LastName>Friedland</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gerald Friedland</PI_FULL_NAME>
<EmailAddress>fractor@icsi.berkeley.edu</EmailAddress>
<PI_PHON>5106662900</PI_PHON>
<NSF_ID>000084347</NSF_ID>
<StartDate>06/12/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>International Computer Science Institute</Name>
<CityName>Berkeley</CityName>
<ZipCode>947041345</ZipCode>
<PhoneNumber>5106662900</PhoneNumber>
<StreetAddress>2150 Shattuck Ave, Suite 1100</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>187909478</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>INTERNATIONAL COMPUTER SCIENCE INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[International Computer Science Institute]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947041198</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramReference>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~403982</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The SMASH project initially proposed to create a software framework that makes it easy for students and practitioners to analyze and manipulate video, image and audio data in large scale. The vision was to create a library that makes written program code automatically scalable to cloud computing so that a successfull experiment in the small could be immediately repeated in the large.</p> <p>The outcomes of this award are as follows. We organized the creation of a research corpus of 100 Million images and 1 Million videos from Flickr (YFCC100m). The corpus contains various annotations, such as tags, title, descriptions, geo-tags, time stamps, etc. As far as we know, it is the largest openly available research corpus available for multimedia data as of today. Amazon agreed to host the corpus as part of their Open Data Initiative. Lawrence Livermore National Lab hosts the corpus for goverment research purposes. We then created the Multimedia Commons initiative to further the creation of annotation and code sharing around this dataset. We also contributed the orginally proposed scalable multimedia analysis framework (Smash) based on Amazon's cloud tools and Jupyter Notebook. Smash allows students to use Python to perform various multimedia analysis experiments directly on 100M images and 1M videos. The corpus and it's infrastructure have been widely adapted into the research community as indicated by a) mainstream media coverage (including CNN, BBC News, and Forbes) and b) references<span>&nbsp;to the main article in the Communications of the ACM, at a rate of more than two citations per week.&nbsp;</span></p> <p>The result of this NSF grant allows for empirical studies at never-before-seen scale. The images and videos show many facts that would have to otherwise be analyzed as part of interviewing, traveling and/or performing lab experiments. With the help of undergraduate supplement funding we also created the Multimedia Commons search engine which allows users to create subcorpora for their specific research questions. An example result of using this search engine by an undergraduate student for his research idea was the proposed redefinition of a difficulty metric for Origami tutorial videos. The paper was not only accepted at the 2018 International conference on&nbsp;Origami in Science, Mathematics and Education, the student also won a scholarship.&nbsp;</p> <p>The results of the Smash project will continue to have impact in teaching and research at UC Berkeley and in the multimedia community as a whole beyond the scope of the NSF funding, especially since large industry players such as IBM and Google reportedly rely on YFCC100m and Multimedia Commons and are actively funding research with it.</p><br> <p>            Last Modified: 07/31/2019<br>      Modified by: Gerald&nbsp;Friedland</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605150992_ScreenShot2019-07-31at1.29.58PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605150992_ScreenShot2019-07-31at1.29.58PM--rgov-800width.jpg" title="The Multimedia Commons Website"><img src="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605150992_ScreenShot2019-07-31at1.29.58PM--rgov-66x44.jpg" alt="The Multimedia Commons Website"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Multimedia Commons Website forms the entry point to the infrastructure around YFCC100M.</div> <div class="imageCredit">Gerald Friedland</div> <div class="imageSubmitted">Gerald&nbsp;Friedland</div> <div class="imageTitle">The Multimedia Commons Website</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605593718_smash-geo--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605593718_smash-geo--rgov-800width.jpg" title="Smash in a Jupyter Notebook"><img src="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605593718_smash-geo--rgov-66x44.jpg" alt="Smash in a Jupyter Notebook"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This screenshot shows the Smash framework in action: In a Jupyter Notebook, the user can upload an arbitrary image. A machine learning algorithm then estimates the geo-location of the image in latitude and longitude based on a model trained with the 100M photos in YFCC100M.</div> <div class="imageCredit">Gerald Friedland</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Gerald&nbsp;Friedland</div> <div class="imageTitle">Smash in a Jupyter Notebook</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605804641_ScreenShot2019-07-31at1.41.32PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605804641_ScreenShot2019-07-31at1.41.32PM--rgov-800width.jpg" title="Multimedia Commons Overview"><img src="/por/images/Reports/POR/2019/1251276/1251276_10251358_1564605804641_ScreenShot2019-07-31at1.41.32PM--rgov-66x44.jpg" alt="Multimedia Commons Overview"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This slide summarizes the core of the content, partners, and active initiatives that make the Multimedia Commons.</div> <div class="imageCredit">Gerald Friedland</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Gerald&nbsp;Friedland</div> <div class="imageTitle">Multimedia Commons Overview</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The SMASH project initially proposed to create a software framework that makes it easy for students and practitioners to analyze and manipulate video, image and audio data in large scale. The vision was to create a library that makes written program code automatically scalable to cloud computing so that a successfull experiment in the small could be immediately repeated in the large.  The outcomes of this award are as follows. We organized the creation of a research corpus of 100 Million images and 1 Million videos from Flickr (YFCC100m). The corpus contains various annotations, such as tags, title, descriptions, geo-tags, time stamps, etc. As far as we know, it is the largest openly available research corpus available for multimedia data as of today. Amazon agreed to host the corpus as part of their Open Data Initiative. Lawrence Livermore National Lab hosts the corpus for goverment research purposes. We then created the Multimedia Commons initiative to further the creation of annotation and code sharing around this dataset. We also contributed the orginally proposed scalable multimedia analysis framework (Smash) based on Amazon's cloud tools and Jupyter Notebook. Smash allows students to use Python to perform various multimedia analysis experiments directly on 100M images and 1M videos. The corpus and it's infrastructure have been widely adapted into the research community as indicated by a) mainstream media coverage (including CNN, BBC News, and Forbes) and b) references to the main article in the Communications of the ACM, at a rate of more than two citations per week.   The result of this NSF grant allows for empirical studies at never-before-seen scale. The images and videos show many facts that would have to otherwise be analyzed as part of interviewing, traveling and/or performing lab experiments. With the help of undergraduate supplement funding we also created the Multimedia Commons search engine which allows users to create subcorpora for their specific research questions. An example result of using this search engine by an undergraduate student for his research idea was the proposed redefinition of a difficulty metric for Origami tutorial videos. The paper was not only accepted at the 2018 International conference on Origami in Science, Mathematics and Education, the student also won a scholarship.   The results of the Smash project will continue to have impact in teaching and research at UC Berkeley and in the multimedia community as a whole beyond the scope of the NSF funding, especially since large industry players such as IBM and Google reportedly rely on YFCC100m and Multimedia Commons and are actively funding research with it.       Last Modified: 07/31/2019       Submitted by: Gerald Friedland]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
