<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CGV: Small: Simulation Motion Capture of Dexterous Manipulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>499838.00</AwardTotalIntnAmount>
<AwardAmount>499838</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research involves novel techniques for capturing natural human manipulation actions in all of their complexity.  Consider how we prepare food, pick up and use a common tool such as a wrench, or plant a flower.   We would like to learn from human examples of such complex actions, so that we can portray convincing graphical renditions of human characters for applications ranging from education, training, and entertainment to exposition and scientific study.   Broader impact includes use of databases and the capture tool developed as part of this research for development of dexterous robotic manipulation, design of prosthetics, and understanding of human grasping and manipulation.  The visual nature and appeal of this research makes it especially suited for mentoring of undergraduates and women, as well as for outreach to spark interest in science for K-12 students.&lt;br/&gt;&lt;br/&gt;Traditional and established approaches to motion capture, such as optical approaches, cannot handle the complex, detailed, high degree of freedom interactions that must be observed to capture dexterous manipulation actions.  The alternative pursued in this research is simulation motion capture, where a user interacts with and guides a running simulation.  Enabling technologies include (1) real-time simulation of a skeleton driven deformable hand in close interaction with simulated objects, (2) novel control algorithms and interface techniques to allow direct control of such simulations, (3) a new language for segmentation and control law development, based on user actions during the simulation, and (4) novel manipulation objective functions learned from direct observation of human actions.   Benefits of simulation capture over current capture technologies include little or no postprocessing, precise representation of contact forces, fast trial and error, ability to make use of a variety of means for control, and ability to use a variety of input devices.  The resulting capture system will be inexpensive and broady accessible.</AbstractNarration>
<MinAmdLetterDate>07/19/2012</MinAmdLetterDate>
<MaxAmdLetterDate>05/21/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218182</AwardID>
<Investigator>
<FirstName>Nancy</FirstName>
<LastName>Pollard</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nancy S Pollard</PI_FULL_NAME>
<EmailAddress>nsp@cs.cmu.edu</EmailAddress>
<PI_PHON>4122681479</PI_PHON>
<NSF_ID>000271462</NSF_ID>
<StartDate>07/19/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~159917</FUND_OBLG>
<FUND_OBLG>2013~339921</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The focus of this research was to enhance understanding of dexterous manipulation.&nbsp;&nbsp; Capturing and portraying dexterous manipulation is a grand challenge in computer graphics; reliable dexterous manipulation is a grand challenge in robotics.&nbsp;&nbsp; This project has demonstrated results in both of those fields.</p> <p>One key outcome is two real-time algorithms and systems for capturing the human hand during manipulation. &nbsp;&nbsp;The most important insight from these efforts is that facilitating user interaction with virtual objects is an excellent shortcut for capturing complex manipulation actions.&nbsp;&nbsp; When virtual objects are used, two problems are eliminated:&nbsp; there is no occlusion between the hand and a real object, which makes it much easier to capture the motion of the hand itself; and the objects do not need to be captured, because they are being simulated in the virtual world. However, there are challenges.&nbsp;&nbsp; Virtual objects must behave predictably as they are manipulated.&nbsp;&nbsp; A second important insignt and result from these efforts is to define what is meant by predictability in simulations having many and frequently changing contacts. &nbsp;&nbsp;The project has established benchmarks and guidelines for the development of more predictable simulation engines.</p> <p>Surprisingly, human manipulation is still little understood.&nbsp;&nbsp; A second key outcome of this research is to contribute extensive results and analysis from observation of human manipulation&nbsp; &ldquo;in the wild.&rdquo; &nbsp;&nbsp;Results include an analysis framework that captures observed variation in manipulation actions and an extensively annotated online database.&nbsp;&nbsp; Insights from this research set forth many new research directions and goals for what any character or robot must be able to achieve in order to behave in a truly dexterous manner.</p> <p>One critical aspect to manipulation is to represent, understand, and manage uncertainty.&nbsp;&nbsp; A third key outcome of this research is a collection of mechanisms for incorporating uncertainty in evaluation, planning, and action.&nbsp;&nbsp; First, we have found that both physics and uncertainty must be considered when evaluating a grasp in order to develop a grasp quality metric that captures real-world results.&nbsp;&nbsp; Second, we have characterized how people make frequent use of touches and adjustments when performing everyday grasping and manipulation interactions. &nbsp; Third, we have created a formal framework for real world environments such that a robot can explicitly reason about uncertainty, reachability, limits, and collision to robustly manipulate objects in real-time.</p> <p>Results from this research can impact communication, safety, and quality of life.&nbsp;&nbsp; This project has contributed new understanding of manipulation and dexterity -- how to capture it, encode it, represent it, portray it, and accomplish it.&nbsp;&nbsp; This understanding is crucial to better teach dexterous actions, communicate more clearly, and build devices that can perform both everyday and extraordinary tasks in the real world.</p><br> <p>            Last Modified: 02/05/2017<br>      Modified by: Nancy&nbsp;S&nbsp;Pollard</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329304055_Outcome2015--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329304055_Outcome2015--rgov-800width.jpg" title="Manipulation Capture"><img src="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329304055_Outcome2015--rgov-66x44.jpg" alt="Manipulation Capture"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Manipulation actions capture is facilitated by simulation of the objects in a virtual environment.</div> <div class="imageCredit">Nancy Pollard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Nancy&nbsp;S&nbsp;Pollard</div> <div class="imageTitle">Manipulation Capture</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329173764_Outcome2014--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329173764_Outcome2014--rgov-800width.jpg" title="Grasp Taxonomy"><img src="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329173764_Outcome2014--rgov-66x44.jpg" alt="Grasp Taxonomy"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our catalogue of human grasping actions reveals the importance of motion, action, and stiffness in characterizing a grasp.</div> <div class="imageCredit">Nancy Pollard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Nancy&nbsp;S&nbsp;Pollard</div> <div class="imageTitle">Grasp Taxonomy</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329086455_Outcome2013--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329086455_Outcome2013--rgov-800width.jpg" title="Grasp Quallity, Physics, and Uncertainty"><img src="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329086455_Outcome2013--rgov-66x44.jpg" alt="Grasp Quallity, Physics, and Uncertainty"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A grasp quality metric that functions well in the real world must consider both physics and uncertainty.</div> <div class="imageCredit">Nancy Pollard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Nancy&nbsp;S&nbsp;Pollard</div> <div class="imageTitle">Grasp Quallity, Physics, and Uncertainty</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329473456_Outcome2016--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329473456_Outcome2016--rgov-800width.jpg" title="Handling Uncertainty"><img src="/por/images/Reports/POR/2017/1218182/1218182_10192302_1486329473456_Outcome2016--rgov-66x44.jpg" alt="Handling Uncertainty"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Uncertainty can be reasoned about and managed in real-time.</div> <div class="imageCredit">Nancy Pollard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Nancy&nbsp;S&nbsp;Pollard</div> <div class="imageTitle">Handling Uncertainty</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The focus of this research was to enhance understanding of dexterous manipulation.   Capturing and portraying dexterous manipulation is a grand challenge in computer graphics; reliable dexterous manipulation is a grand challenge in robotics.   This project has demonstrated results in both of those fields.  One key outcome is two real-time algorithms and systems for capturing the human hand during manipulation.   The most important insight from these efforts is that facilitating user interaction with virtual objects is an excellent shortcut for capturing complex manipulation actions.   When virtual objects are used, two problems are eliminated:  there is no occlusion between the hand and a real object, which makes it much easier to capture the motion of the hand itself; and the objects do not need to be captured, because they are being simulated in the virtual world. However, there are challenges.   Virtual objects must behave predictably as they are manipulated.   A second important insignt and result from these efforts is to define what is meant by predictability in simulations having many and frequently changing contacts.   The project has established benchmarks and guidelines for the development of more predictable simulation engines.  Surprisingly, human manipulation is still little understood.   A second key outcome of this research is to contribute extensive results and analysis from observation of human manipulation  "in the wild."   Results include an analysis framework that captures observed variation in manipulation actions and an extensively annotated online database.   Insights from this research set forth many new research directions and goals for what any character or robot must be able to achieve in order to behave in a truly dexterous manner.  One critical aspect to manipulation is to represent, understand, and manage uncertainty.   A third key outcome of this research is a collection of mechanisms for incorporating uncertainty in evaluation, planning, and action.   First, we have found that both physics and uncertainty must be considered when evaluating a grasp in order to develop a grasp quality metric that captures real-world results.   Second, we have characterized how people make frequent use of touches and adjustments when performing everyday grasping and manipulation interactions.   Third, we have created a formal framework for real world environments such that a robot can explicitly reason about uncertainty, reachability, limits, and collision to robustly manipulate objects in real-time.  Results from this research can impact communication, safety, and quality of life.   This project has contributed new understanding of manipulation and dexterity -- how to capture it, encode it, represent it, portray it, and accomplish it.   This understanding is crucial to better teach dexterous actions, communicate more clearly, and build devices that can perform both everyday and extraordinary tasks in the real world.       Last Modified: 02/05/2017       Submitted by: Nancy S Pollard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
