<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Optimization Techniques for Scalable Semantic Web Data Processing in the Cloud</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>446942.00</AwardTotalIntnAmount>
<AwardAmount>446942</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The use of cloud-based data processing platforms is an increasingly attractive alternative for large-scale data processing. There is active investigation into their use for various types of processing tasks on large-scale unstructured and structured data. However, due to an increased interest in many communities to enable more automatic sharing and exchange of data on the Web using Semantic Web techniques, there is a rapid surge in the availability of very large, real-world, Semantic Web datasets. Such data are semi-structured and have more complex processing requirements than relational data processing due to the fine-grained modeling of data and also the need for inferencing during processing. Consequently, existing optimization techniques for cloud data processing platforms which often adapt relational processing optimization techniques do not address the needs of such workloads. Further, such techniques do not adequately account for the nuances of cloud runtime platforms such as Hadoop e.g., dataflow length as a cost metric, no a-priori existence of indexes and statistics.       &lt;br/&gt;&lt;br/&gt;This project contributes insight into query optimization requirements for Semantic Web data processing on Map Reduce platforms. Its contributions include a novel Nested TripleGroup data model and Algebra (NTGA), algebraic and dynamic cost query optimization techniques; inter and intra-work sharing techniques, data representation formats and system architecture issues of integrating Semantic Web optimization techniques into frameworks such as Apache Pig. The impact of this project will cut across the increasing range of communities that are aggressively adopting Semantic Web tenets such as, scientific, business, government and other general-purpose communities. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/18/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/11/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218277</AwardID>
<Investigator>
<FirstName>Kemafor</FirstName>
<LastName>Anyanwu-Ogan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kemafor Anyanwu-Ogan</PI_FULL_NAME>
<EmailAddress>kogan@ncsu.edu</EmailAddress>
<PI_PHON>9195132850</PI_PHON>
<NSF_ID>000176916</NSF_ID>
<StartDate>08/18/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957001</ZipCode>
<StreetAddress><![CDATA[Campus Box 7514, 2701 Sullivan D]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~169991</FUND_OBLG>
<FUND_OBLG>2013~276951</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The goal of this project was to investigate novel query optimization techniques for scalable processing of queries on Semantic Networks in the Cloud. Our line of investigation departed from the mainstream by introducing a new data model called a </span><span style="font-size: small;"><span style="font-family: Times New Roman;"><em><span>Nested TripleGroup model </span></em><span>and a corresponding query algebra - </span><em><span>Nested TripleGroup Algebra (NTGA), </span></em><span>which were conceived to deal specifically with the nuances of labeled graph models like RDF. A key focus was developing optimizations for transforming what are typically very complex queries (sometimes several hundreds of join operations for ontological queries) into more efficient expressions. This was achieved by developing rewritings to NTGA expressions which are special classes of second order terms, enabling more succinct and efficient expressions than the classic first order relational expressions. The issue of efficiency was with respect to processing in the Cloud - usually MapReduce, which creates large amount of network data shuffling, disk I/O and cpu costs for complex queries requiring multiple operation cycles.<br />Once NTGA was established as a foundation for query processing, the rest of our efforts focused on </span><em><span>developing query rewriting techniques for different classes of graph pattern</span></em><span>, analytical and some basic classes of ontological<br />queries into NTGA expressions. Evaluation results showed that query plans based on NTGA expressions significantly outperform state of the art when processing on Map Reduce platforms. &nbsp;</span></span></span></p> <p><span style="font-family: Times New Roman; font-size: small;">&nbsp;</span></p> <p><span><span>To further advance these benefits, we investigated how to </span><span><span style="font-family: Times New Roman; font-size: small;">autonomically</span></span><span><br /><span style="font-family: Times New Roman; font-size: small;">and efficiently impose some structure on the otherwise semi-structured RDF data </span><span style="font-family: Times New Roman; font-size: small;">model. The absence of structure in a data model imposes some limits on query </span><span style="font-family: Times New Roman; font-size: small;">optimization possibilities. We therefore developed a </span></span><span style="font-size: small;"><span style="font-family: Times New Roman;"><em><span>typing model, R Typing</span></em><span>, on top of the NTG data model which is induced automatically from a given data set and does not require a schema to be modeled by users prior to data ingestion. Correspondingly, the query rewriting framework was extended to support rewriting into expressions with R-Type terms. More interestingly, the typing opened up opportunities for new classes of query optimizations - Type-based and semantic query optimizations. These classes of optimizations exploit data type and integrity constraint rules to simplify query expressions. The simplification is made possible by identifying subexpressions within a query expression that can be deemed superfluous given the domain knowledge already represented as integrity constraints. The RDF data<br />model does not support integrity constraints but allows the representation of<br />domain knowledge as ontologies. Ontological axioms specify semantic relations between concepts and relations in a domain. However, they do not necessarily constrain data models in the same way that integrity constraints do. Consequently, new techniques for how to exploit such domain knowledge in query optimization were developed. This resulted in </span><em><span>novel query and data rewriting strategies</span></em><span>.<br /></span><strong><span>&nbsp;</span></strong></span></span></span></p> <p><span><span>The outcomes of our efforts is documented in several research publications,<br />including conference publications, a conference tutorial, a conference demo,<br />book chapter and magazine article. All are available from the project website <a href="https://research.csc.ncsu.edu/coul/RAPID+/publication.html"><span style="color: #0000ff;">https://research.csc.ncsu.edu/coul/RAPID+/publication.html</span></a>.</span></span></p> <p><span><span>Besides the </span></span><span><span>conceptual and foundational developments of this project, significant </span></span><span><span>implementation advancements were also made. A system that implemented new query </span></span><span><span>operators, query compilation, query execution and storage and indexing of RDF </span></span><span><span>data in the Cloud based on the NTGA and R-Type models were implemented as an </span></span>e<span><span>xtension of the Apache Pig project. Comprehensive evaluations against other </span></span><span><span>Cloud-based processing platforms showed over 500X performance improvement in </span></span><span><span>some cases. &nbsp;The code is currently hosted on NCSU's github repository h</span></span><a href="https://github.ncsu.edu/hkim22/semstorm"><span><span>ttps://github.ncsu.edu/hkim22/semstorm</span></span></a><span><span>) &nbsp;and is being staged for general public release. </span></span></p> <p><span><span>&nbsp;</span></span></p> <p><span>Our research efforts were closely integrated with teaching and supported two doctoral dissertations. Those Ph.D students were employed upon graduation at Lawrence Berkeley National Laboratory (LBNL) and Microsoft respectively. There were several MS independent study projects as well, which translated to employment after graduation at companies like MapR and Ebay. </span></p> <p><strong>&nbsp;</strong><em>&nbsp;</em></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/27/2017<br>      Modified by: Kemafor&nbsp;Anyanwu-Ogan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to investigate novel query optimization techniques for scalable processing of queries on Semantic Networks in the Cloud. Our line of investigation departed from the mainstream by introducing a new data model called a Nested TripleGroup model and a corresponding query algebra - Nested TripleGroup Algebra (NTGA), which were conceived to deal specifically with the nuances of labeled graph models like RDF. A key focus was developing optimizations for transforming what are typically very complex queries (sometimes several hundreds of join operations for ontological queries) into more efficient expressions. This was achieved by developing rewritings to NTGA expressions which are special classes of second order terms, enabling more succinct and efficient expressions than the classic first order relational expressions. The issue of efficiency was with respect to processing in the Cloud - usually MapReduce, which creates large amount of network data shuffling, disk I/O and cpu costs for complex queries requiring multiple operation cycles. Once NTGA was established as a foundation for query processing, the rest of our efforts focused on developing query rewriting techniques for different classes of graph pattern, analytical and some basic classes of ontological queries into NTGA expressions. Evaluation results showed that query plans based on NTGA expressions significantly outperform state of the art when processing on Map Reduce platforms.       To further advance these benefits, we investigated how to autonomically and efficiently impose some structure on the otherwise semi-structured RDF data model. The absence of structure in a data model imposes some limits on query optimization possibilities. We therefore developed a typing model, R Typing, on top of the NTG data model which is induced automatically from a given data set and does not require a schema to be modeled by users prior to data ingestion. Correspondingly, the query rewriting framework was extended to support rewriting into expressions with R-Type terms. More interestingly, the typing opened up opportunities for new classes of query optimizations - Type-based and semantic query optimizations. These classes of optimizations exploit data type and integrity constraint rules to simplify query expressions. The simplification is made possible by identifying subexpressions within a query expression that can be deemed superfluous given the domain knowledge already represented as integrity constraints. The RDF data model does not support integrity constraints but allows the representation of domain knowledge as ontologies. Ontological axioms specify semantic relations between concepts and relations in a domain. However, they do not necessarily constrain data models in the same way that integrity constraints do. Consequently, new techniques for how to exploit such domain knowledge in query optimization were developed. This resulted in novel query and data rewriting strategies.    The outcomes of our efforts is documented in several research publications, including conference publications, a conference tutorial, a conference demo, book chapter and magazine article. All are available from the project website https://research.csc.ncsu.edu/coul/RAPID+/publication.html.  Besides the conceptual and foundational developments of this project, significant implementation advancements were also made. A system that implemented new query operators, query compilation, query execution and storage and indexing of RDF data in the Cloud based on the NTGA and R-Type models were implemented as an extension of the Apache Pig project. Comprehensive evaluations against other Cloud-based processing platforms showed over 500X performance improvement in some cases.  The code is currently hosted on NCSU's github repository https://github.ncsu.edu/hkim22/semstorm)  and is being staged for general public release.      Our research efforts were closely integrated with teaching and supported two doctoral dissertations. Those Ph.D students were employed upon graduation at Lawrence Berkeley National Laboratory (LBNL) and Microsoft respectively. There were several MS independent study projects as well, which translated to employment after graduation at companies like MapR and Ebay.               Last Modified: 11/27/2017       Submitted by: Kemafor Anyanwu-Ogan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
