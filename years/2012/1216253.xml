<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: EAGER:  Authoring Game AIs by Demonstration for Real-Time Strategy Games</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>12/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>126921.00</AwardTotalIntnAmount>
<AwardAmount>142921</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research will explore novel "authoring by demonstration" techniques for real-time strategy (RTS) games. Creating rich artificial intelligence (AI) behavior sets for complex computer games requires significant engineering effort. Developers need to anticipate all imaginable circumstances that the AI may encounter within the game world. The resulting AI is often static and results in predictable behaviors, detracting from the player experience. In addition, it is difficult for average players to create AI behaviors, without significant expertise in both AI and scripting. Modeling human-like goals and behaviors required for multiplayer games with semi-autonomous avatars adds additional complexity. This potentially transformative project will develop novel learning techniques that allow users to create intelligent behaviors simply by demonstrating them. The research will be done within the domain of RTS games, as these domains pose significant challenges that must be tackled in order to scale up the learning techniques to real-world tasks.&lt;br/&gt;&lt;br/&gt;Case-based planners, hierarchical task network planners, or industry-standard behavior-tree execution engines require a library of base behaviors or methods in order to generate complete plans, which traditionally are coded by hand. The project will investigate ways to automate the process of generating such behavior libraries based on novel methods for learning strategic plans from user demonstrations. The techniques will be evaluated in the context of a case-based planning system for RTS games. RTS games are complex and involve strategic decision-making, multi-agent coordination, real-time interaction, and partially-observable environments. These properties pose significant challenges to existing AI methods for planning and learning. This research will make fundamental scientific contributions to learning, case-based reasoning, and AI for real-time strategic domains, addressing key problems in goal recognition, plan learning, and authoring support. &lt;br/&gt;&lt;br/&gt;This research will enable game designers and other non-programmers to create the behavior sets for RTS games without requiring programming knowledge. This capability has two main consequences: first, it allows game developers to create games with less effort, and second it will enable a new genre of games where players would be able to create their own AIs as part of the game play. Additionally, as RTS games are essentially domain-specific simulations, the research will support authoring of behavior sets for domains such as simulation environments for training, real-time robotic control, organizational modeling for business decision-making, or sophisticated market simulations for economics strategy or public policy. The educational impact of the project is twofold. First, the project will constitute an important advance towards easy authoring of training simulators for educational applications that require environment with complex AI behaviors. This will enable development of new educational technologies with simulators or virtual worlds. Second, the project will involve undergraduate and graduate students in all phases of the work.</AbstractNarration>
<MinAmdLetterDate>01/31/2012</MinAmdLetterDate>
<MaxAmdLetterDate>01/31/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1216253</AwardID>
<Investigator>
<FirstName>Ashwin</FirstName>
<LastName>Ram</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ashwin Ram</PI_FULL_NAME>
<EmailAddress>ashwin.ram@parc.com</EmailAddress>
<PI_PHON>6508124707</PI_PHON>
<NSF_ID>000296958</NSF_ID>
<StartDate>01/31/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Palo Alto Research Center Incorporated</Name>
<CityName>Palo Alto</CityName>
<ZipCode>943041314</ZipCode>
<PhoneNumber>6508124070</PhoneNumber>
<StreetAddress>3333 Coyote Hill Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>112219014</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PALO ALTO RESEARCH CENTER INCORPORATED</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117052210</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Palo Alto Research Center Incorporated]]></Name>
<CityName>Palo Alto</CityName>
<StateCode>CA</StateCode>
<ZipCode>943041314</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~126921</FUND_OBLG>
<FUND_OBLG>2011~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p style="margin-bottom: 0in;">The objective of this project was to investigate approaches which would enable end-users to author human-like behaviors for autonomous and semi-autonomous avatars in role-playing games (RPG). In previous work, we proposed a novel &ldquo;authoring by demonstration&rdquo; approach that used case based reasoning (CBR) techniques to enable end-users to author non-player character (NPC) behaviors in Real Time Strategy (RTS) games. For the current work, we explored how to learn role-based avatar behaviors in complex virtual worlds.</p> <p style="margin-bottom: 0in;">&nbsp;</p> <p style="margin-bottom: 0in;">The first virtual environment we used as a testbed was Second Life. We chose Second Life as it is a complete, scaled-up world with millions of users. We studied how human users could author behaviors for their Second Life avatars, and how CBR could be used to adapt those behaviors to improve them with experience. We investigated how different types of users could author avatar behaviors for a typical Second Life scenarios. We observed that even novice users easily learned to use our system and understood our behavior metaphors, vocabulary, and design concepts.</p> <p style="margin-bottom: 0in;">&nbsp;</p> <p style="margin-bottom: 0in;">One of the major outcomes of the work showed that that by using artificial intelligence engines, novice users can author satisfiable game character behaviors for RPG games. We found that it was important to provide concrete feedback on the authoring activity so that the authors could see the results of the authoring process and identify problems with it. It was also important to simplify steps required to link behavior conditions to lower level percepts. Finally, we found that the authoring task should not require creation of deep hierarchical structures and should be presented as a sequential process.</p> <p style="margin-bottom: 0in;">&nbsp;</p> <p style="margin-bottom: 0in;">The second virtual environment we used as a testbed was a commercially available RPG game called Hands of War 2. This commercial video game was modified in order to utilize the environment as a testbed for learning from demonstration research. A multi-player team-based gaming environment was created, where team members could work together to achieve particular goals/tasks (e.g. defeating an enemy). A learning from demonstration architecture for controlling characters in team-based virtual environments was designed and constructed and a study was conducted to compare the (quantitative and qualitative) performance of a team of human players versus a hybrid team that consisted of both human players and artificial agents.</p> <p style="margin-bottom: 0in;">&nbsp;</p> <p style="margin-bottom: 0in;">Two major outcomes were recorded from this work. The first showed that teams composed of both humans and artificial agents outperformed teams that were composed entirely of human players when it came to task completion. The second outcome of the study showed that when humans assessed how well teams worked together, hybrid teams (whose members consisted of both humans and artificial agents) were perceived more favorably than human-only teams for some qualitative dimensions.</p><br> <p>            Last Modified: 01/11/2013<br>      Modified by: Ashwin&nbsp;Ram</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The objective of this project was to investigate approaches which would enable end-users to author human-like behaviors for autonomous and semi-autonomous avatars in role-playing games (RPG). In previous work, we proposed a novel "authoring by demonstration" approach that used case based reasoning (CBR) techniques to enable end-users to author non-player character (NPC) behaviors in Real Time Strategy (RTS) games. For the current work, we explored how to learn role-based avatar behaviors in complex virtual worlds.   The first virtual environment we used as a testbed was Second Life. We chose Second Life as it is a complete, scaled-up world with millions of users. We studied how human users could author behaviors for their Second Life avatars, and how CBR could be used to adapt those behaviors to improve them with experience. We investigated how different types of users could author avatar behaviors for a typical Second Life scenarios. We observed that even novice users easily learned to use our system and understood our behavior metaphors, vocabulary, and design concepts.   One of the major outcomes of the work showed that that by using artificial intelligence engines, novice users can author satisfiable game character behaviors for RPG games. We found that it was important to provide concrete feedback on the authoring activity so that the authors could see the results of the authoring process and identify problems with it. It was also important to simplify steps required to link behavior conditions to lower level percepts. Finally, we found that the authoring task should not require creation of deep hierarchical structures and should be presented as a sequential process.   The second virtual environment we used as a testbed was a commercially available RPG game called Hands of War 2. This commercial video game was modified in order to utilize the environment as a testbed for learning from demonstration research. A multi-player team-based gaming environment was created, where team members could work together to achieve particular goals/tasks (e.g. defeating an enemy). A learning from demonstration architecture for controlling characters in team-based virtual environments was designed and constructed and a study was conducted to compare the (quantitative and qualitative) performance of a team of human players versus a hybrid team that consisted of both human players and artificial agents.   Two major outcomes were recorded from this work. The first showed that teams composed of both humans and artificial agents outperformed teams that were composed entirely of human players when it came to task completion. The second outcome of the study showed that when humans assessed how well teams worked together, hybrid teams (whose members consisted of both humans and artificial agents) were perceived more favorably than human-only teams for some qualitative dimensions.       Last Modified: 01/11/2013       Submitted by: Ashwin Ram]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
