<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Decoding Error-Correcting Codes using Large-Scale Decomposition Methods</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>424062.00</AwardTotalIntnAmount>
<AwardAmount>424062</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research draws upon techniques from large-scale optimization to develop new decoding algorithms for error-correcting codes.  Initial results yield a scalable decoding algorithm for linear programming decoding that runs as fast as state-of-the-art decoders, has a simple schedule, robust convergence guarantees, and achieves better empirical performance than standard decoding algorithms when the signal-to-noise ratio is high.   The decoding algorithm will have a transformative effect on the types of codes used in high-reliability applications including storage, optical networks, and microprocessor architectures. &lt;br/&gt;&lt;br/&gt;This project will develop further results, analyzing in detail algorithmic behavior in the "error floor regime" where the signal-to-noise ratio is high.  It will examine the algorithmic robustness to the specifics of hardware implementation, and investigate other applications in coding such as high-density, non-binary, and rank-metric codes. The PIs will extend the algorithmic methods to applications beyond decoding error-correcting codes, investigating large-scale data processing applications in graphical models and statistical estimation.  The research thrusts of the project are well suited for incorporation into the PIs' courses in digital communication, optimization, and information processing for "big data" problems more broadly.</AbstractNarration>
<MinAmdLetterDate>08/31/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1217058</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Nowak</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert D Nowak</PI_FULL_NAME>
<EmailAddress>rdnowak@wisc.edu</EmailAddress>
<PI_PHON>6082653914</PI_PHON>
<NSF_ID>000338270</NSF_ID>
<StartDate>05/09/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stark</FirstName>
<LastName>Draper</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stark Draper</PI_FULL_NAME>
<EmailAddress>sdraper@ece.wisc.edu</EmailAddress>
<PI_PHON>6082623822</PI_PHON>
<NSF_ID>000508966</NSF_ID>
<StartDate>08/31/2012</StartDate>
<EndDate>05/09/2014</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Recht</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin H Recht</PI_FULL_NAME>
<EmailAddress>brecht@berkeley.edu</EmailAddress>
<PI_PHON>5106423214</PI_PHON>
<NSF_ID>000569581</NSF_ID>
<StartDate>08/31/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Wisconsin-Madison</Name>
<CityName>MADISON</CityName>
<ZipCode>537151218</ZipCode>
<PhoneNumber>6082623822</PhoneNumber>
<StreetAddress>21 North Park Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 6401]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>161202122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WISCONSIN SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041188822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Wisconsin-Madison]]></Name>
<CityName>Madison</CityName>
<StateCode>WI</StateCode>
<ZipCode>537061607</ZipCode>
<StreetAddress><![CDATA[1415 Engineering Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~424062</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The aim of this project was to bring techniques of large-scale distributed convex optimization to bear in developing novel implementations of error-correction decoding. &nbsp;Our aim was to solve the long-standing "error-floor" problem of low-density parity-check (LDPC) codes. &nbsp;Error-floors present problems for digital communication systems that require exceptionally high transmission speed and ultra-high reliability. &nbsp;Optical transport networks are one such important application. &nbsp;Over the life of this project a number of major findings have resulted. &nbsp;</span></p> <p><span>First, we showed how to solve the linear programming (LP) relaxation of the maximum likelihood (ML) error-correction decoding problem in a computationally efficient manner using the alternating direction method of multipliers (ADMM). &nbsp;Our approach is computationally competitive with state-of-the-art belief propagation (BP) decoders and has much improved error floor performance. &nbsp;We made a public release of our software, which has been used and built upon by numerous other research groups.</span></p> <p><span>Second, we observed that at lower signal-to-noise ratios (SNRs), in the "waterfall" regime, our ADMM-LP decoder displayed an SNR-gap versus BP decoding. &nbsp;This was the case even through our ADMM-LP decoder solves the LP relaxation exactly; the gap is a property of the relaxation.&nbsp; To close this gap we introduced a "penalized" objective into the standard LP relaxation. &nbsp;Although the objective function becomes slightly non-convex, a slight modification of ADMM can be applied to this problem, with no increase in computational cost. &nbsp;Studying the performance of the modified decoder experimentally and analytically, we showed that the modification closes the SNR gap to BP while maintaining the much-improved error-floor performance of LP decoding.</span></p> <p><span>Third, we explored the use of ADMM-LP in other error-correction problems. &nbsp;We showed how to apply ADMM-LP decoding to non-binary LDPC codes, useful in higher-order modulation. &nbsp;We showed how to apply ADMM-LP decoding to multi-permutation codes, useful in flash memory. &nbsp;We also explored the implementation in hardware of the ADMM-LP decoder. &nbsp;We demonstrated the first fixed-point implementation of ADMM-LP, in a field-programmable gate array (FPGA). &nbsp;Implementation in FPGA is the first step in developing an application-specific integrated circuit (ASIC), which would be required in any commercial deployment of the technology.</span></p> <p><span>Fourth, in the latter half of the project we "flipped the arrow". &nbsp;Instead of applying optimization to error-correction we asked how ideas of error-correction coding can be used to accelerate large-scale optimization. &nbsp;We explored a "coding-for-computing" paradigm. &nbsp;In this paradigm techniques of error correction are applied in distributed computing systems to build redundant copies of computations. &nbsp;In cloud computing systems, wherein some subset of "straggler" nodes are unpredictably delayed, widely parallelized workloads can experience unacceptable stalling due to waiting for the last straggler(s) to report in. &nbsp;One solution is to generate redundant computations. &nbsp;By drawing on techniques of error-correction we show that for certain important linear algebraic primitives (matrix-vector multiplication, matrix-matrix multiplication, data shuffling), redundant copies of computations that are not pure replications of the other computations can be generated. &nbsp;The use of such coded computing ideas significantly accelerates convergence, important in big data and large-scale machine learning applications. &nbsp;</span></p> <p><span>Finally, paralleling and complementing our efforts on coded-computing, we developed techniques of "anytime" computing to deal with stragglers. &nbsp;Instead of assigning a fixed-sized data batch to each worker, we allocate workers a fixed amount of time to work in each computing epoch. &nbsp;In settings that require data synchronization between computing epochs, this approach greatly ameliorates the issue of stragglers. &nbsp;Effectively, our approach transforms a the problem setting from one wherein a variable number of workers finish their work to one in which a variable amount of work is completed per worker.&nbsp; Our approach shows significant gains, which we have verified both in commercial cloud computing systems such as the Amazon Elastic Compute Cloud (EC2), and in academic high-performance computing clusters.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/26/2018<br>      Modified by: Robert&nbsp;D&nbsp;Nowak</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The aim of this project was to bring techniques of large-scale distributed convex optimization to bear in developing novel implementations of error-correction decoding.  Our aim was to solve the long-standing "error-floor" problem of low-density parity-check (LDPC) codes.  Error-floors present problems for digital communication systems that require exceptionally high transmission speed and ultra-high reliability.  Optical transport networks are one such important application.  Over the life of this project a number of major findings have resulted.    First, we showed how to solve the linear programming (LP) relaxation of the maximum likelihood (ML) error-correction decoding problem in a computationally efficient manner using the alternating direction method of multipliers (ADMM).  Our approach is computationally competitive with state-of-the-art belief propagation (BP) decoders and has much improved error floor performance.  We made a public release of our software, which has been used and built upon by numerous other research groups.  Second, we observed that at lower signal-to-noise ratios (SNRs), in the "waterfall" regime, our ADMM-LP decoder displayed an SNR-gap versus BP decoding.  This was the case even through our ADMM-LP decoder solves the LP relaxation exactly; the gap is a property of the relaxation.  To close this gap we introduced a "penalized" objective into the standard LP relaxation.  Although the objective function becomes slightly non-convex, a slight modification of ADMM can be applied to this problem, with no increase in computational cost.  Studying the performance of the modified decoder experimentally and analytically, we showed that the modification closes the SNR gap to BP while maintaining the much-improved error-floor performance of LP decoding.  Third, we explored the use of ADMM-LP in other error-correction problems.  We showed how to apply ADMM-LP decoding to non-binary LDPC codes, useful in higher-order modulation.  We showed how to apply ADMM-LP decoding to multi-permutation codes, useful in flash memory.  We also explored the implementation in hardware of the ADMM-LP decoder.  We demonstrated the first fixed-point implementation of ADMM-LP, in a field-programmable gate array (FPGA).  Implementation in FPGA is the first step in developing an application-specific integrated circuit (ASIC), which would be required in any commercial deployment of the technology.  Fourth, in the latter half of the project we "flipped the arrow".  Instead of applying optimization to error-correction we asked how ideas of error-correction coding can be used to accelerate large-scale optimization.  We explored a "coding-for-computing" paradigm.  In this paradigm techniques of error correction are applied in distributed computing systems to build redundant copies of computations.  In cloud computing systems, wherein some subset of "straggler" nodes are unpredictably delayed, widely parallelized workloads can experience unacceptable stalling due to waiting for the last straggler(s) to report in.  One solution is to generate redundant computations.  By drawing on techniques of error-correction we show that for certain important linear algebraic primitives (matrix-vector multiplication, matrix-matrix multiplication, data shuffling), redundant copies of computations that are not pure replications of the other computations can be generated.  The use of such coded computing ideas significantly accelerates convergence, important in big data and large-scale machine learning applications.    Finally, paralleling and complementing our efforts on coded-computing, we developed techniques of "anytime" computing to deal with stragglers.  Instead of assigning a fixed-sized data batch to each worker, we allocate workers a fixed amount of time to work in each computing epoch.  In settings that require data synchronization between computing epochs, this approach greatly ameliorates the issue of stragglers.  Effectively, our approach transforms a the problem setting from one wherein a variable number of workers finish their work to one in which a variable amount of work is completed per worker.  Our approach shows significant gains, which we have verified both in commercial cloud computing systems such as the Amazon Elastic Compute Cloud (EC2), and in academic high-performance computing clusters.          Last Modified: 11/26/2018       Submitted by: Robert D Nowak]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
