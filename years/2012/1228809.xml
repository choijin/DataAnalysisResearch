<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>PEEPs for PD: Identifying Project Evaluation Effectiveness Principles for Professional Development in Elementary Science Teaching</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>249993.00</AwardTotalIntnAmount>
<AwardAmount>249993</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Connie Della-Piana</SignBlockName>
<PO_EMAI>cdellapi@nsf.gov</PO_EMAI>
<PO_PHON>7032925309</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This exploratory project is designed to identify and describe evaluations of Professional Development in Science Teaching (PTST) interventions with the ultimate goal of improving the quality of science instruction in elementary school classrooms. The project will 1) identify and describe evaluations of PDST interventions and 2) develop mechanisms and examples for systematically reviewing, meta-evaluating, and aggregating results of these evaluations. The focus will be on establishing a credible base of appropriate professional development STEM evaluation reviews, developing meta-evaluation techniques, and identifying the most appropriate strategies for determine the cumulative effectiveness of PDST programs.  In order to increase the capacity of professional evaluators in STEM education to conduct rigorous and useful evaluations, the project will disseminate project findings to education researchers and evaluators, sponsors, and developers of PDST interventions through research presentations, papers, and reports to the extent feasible. Dissemination products will clearly communicate the following:&lt;br/&gt;&lt;br/&gt;(1) Methods for identifying and retrieving PDST evaluations, as well as their limitations&lt;br/&gt;&lt;br/&gt;(2) Characteristics of accessible PDST evaluations&lt;br/&gt;&lt;br/&gt;(3) Research designs and methodologies used in PDST evaluations Suitable methods for assessing the performance of available evaluation documents against evaluation standards and frameworks&lt;br/&gt;&lt;br/&gt;(4) Suitable methods for assessing the performance and impacts of PDST intervention</AbstractNarration>
<MinAmdLetterDate>09/07/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/07/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1228809</AwardID>
<Investigator>
<FirstName>Lori</FirstName>
<LastName>Wingate</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lori A Wingate</PI_FULL_NAME>
<EmailAddress>lori.wingate@wmich.edu</EmailAddress>
<PI_PHON>2693875895</PI_PHON>
<NSF_ID>000297944</NSF_ID>
<StartDate>09/07/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Chris</FirstName>
<LastName>Coryn</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chris L Coryn</PI_FULL_NAME>
<EmailAddress>chris.coryn@wmich.edu</EmailAddress>
<PI_PHON>2693875906</PI_PHON>
<NSF_ID>000324427</NSF_ID>
<StartDate>09/07/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniela</FirstName>
<LastName>Schroeter</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniela C Schroeter</PI_FULL_NAME>
<EmailAddress>daniela.schroeter@wmich.edu</EmailAddress>
<PI_PHON>2693875895</PI_PHON>
<NSF_ID>000524256</NSF_ID>
<StartDate>09/07/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Juna</FirstName>
<LastName>Snow</LastName>
<PI_MID_INIT>Z</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Juna Z Snow</PI_FULL_NAME>
<EmailAddress>contact@innovatedconsulting.com</EmailAddress>
<PI_PHON>6174404435</PI_PHON>
<NSF_ID>000610817</NSF_ID>
<StartDate>09/07/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Western Michigan University</Name>
<CityName>Kalamazoo</CityName>
<ZipCode>490085200</ZipCode>
<PhoneNumber>2693878298</PhoneNumber>
<StreetAddress>1903 West Michigan Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>622364479</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WESTERN MICHIGAN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>062230560</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Western Michigan University]]></Name>
<CityName/>
<StateCode>MI</StateCode>
<ZipCode>490085200</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7261</Code>
<Text>Project &amp; Program Evaluation</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0412</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~249993</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><em>Exploratory Identification of Project Evaluation Effectiveness Principles for Professional Development in Elementary Science Teaching: PEEPs for PD</em> was a project designed to explore practical methods for identifying and describing the evaluations of professional development projects for elementary science teachers (PDST). The overarching purpose of this project was to contribute to the understanding of the quality of science instruction in elementary school classrooms by improving the evaluation of professional development projects. A systematic review, involving identification, retrieval, and classification of professional development evaluations is central to determining which professional development projects work most effectively and efficiently. Aggregated findings from diverse professional development projects can allow for the development of new professional development programs that target specific areas of need in elementary science teacher education.</p> <p>This research focused on evaluations published between 2002 and 2012. Evaluation products were collected from publically available databases, peer-reviewed journals, and via key informants and organizations that regularly evaluate PDST. After review of more than 1,000 evaluations, we found only 55 evaluation products meeting the project inclusion criteria. Our research suggests publication bias appears to be a major impasse in PDST evaluation. Not all products from evaluations are published; not all published documents are indexed; and not all indexed documents are retrievable. Searches of library catalogs and the Internet may not be sufficient to describe the population of publicly funded PDST interventions and related evaluations. Local, regional, and state PDST evaluations might not be reported or publicly available. Additionally, PDST is not a frequent topic in the pertinent evaluation literature, and PDST project evaluations are not discussed often in the educational research literature. Furthermore, project evaluations, in general, and of PDST projects specifically, are often treated as proprietary or otherwise remain unpublished.</p> <p>After a thorough review of the 55 evaluation products focusing on elementary PDST projects, we concluded that the evaluation reports and journal articles in the sample for this study typically lacked the necessary information to perform research synthesis and metaevaluation using established methods. Due to the diverse nature of the projects and methodologies used, an aggregation of findings from the evaluations was not possible. The nature and scope of the evaluation products also challenged common techniques to conduct metaevaluation. This is a significant finding of the project, as most evaluations do not use designs for which synthesis mechanisms are well established (e.g., meta-analysis). Additionally, the assumption exists that checklists and tools developed by leaders in the field can be used to perform a metaevaluation on available documents. These findings do not indicate a set of low-quality studies, but rather suggests that any attempt to judge the overall quality either of any given evaluation or of the general state of PDST will likely have low validity, and will require information beyond that found in available products. In summary, reports of PDST project evaluation do not lend themselves to metaevaluation. The amount and type of information necessary to perform an external metaevaluation is not present in either the sampled or screened evaluation products. Similarly, and because most evaluations are not based on randomized controlled trials, there is inadequate information to warrant evaluation synthesis. Better mechanisms need to be developed to allow for aggregation of and learning from evaluation products that use the range of designs and methods available to evaluation practitioners.</p> <p>Another goal of this project was to dissemi...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Exploratory Identification of Project Evaluation Effectiveness Principles for Professional Development in Elementary Science Teaching: PEEPs for PD was a project designed to explore practical methods for identifying and describing the evaluations of professional development projects for elementary science teachers (PDST). The overarching purpose of this project was to contribute to the understanding of the quality of science instruction in elementary school classrooms by improving the evaluation of professional development projects. A systematic review, involving identification, retrieval, and classification of professional development evaluations is central to determining which professional development projects work most effectively and efficiently. Aggregated findings from diverse professional development projects can allow for the development of new professional development programs that target specific areas of need in elementary science teacher education.  This research focused on evaluations published between 2002 and 2012. Evaluation products were collected from publically available databases, peer-reviewed journals, and via key informants and organizations that regularly evaluate PDST. After review of more than 1,000 evaluations, we found only 55 evaluation products meeting the project inclusion criteria. Our research suggests publication bias appears to be a major impasse in PDST evaluation. Not all products from evaluations are published; not all published documents are indexed; and not all indexed documents are retrievable. Searches of library catalogs and the Internet may not be sufficient to describe the population of publicly funded PDST interventions and related evaluations. Local, regional, and state PDST evaluations might not be reported or publicly available. Additionally, PDST is not a frequent topic in the pertinent evaluation literature, and PDST project evaluations are not discussed often in the educational research literature. Furthermore, project evaluations, in general, and of PDST projects specifically, are often treated as proprietary or otherwise remain unpublished.  After a thorough review of the 55 evaluation products focusing on elementary PDST projects, we concluded that the evaluation reports and journal articles in the sample for this study typically lacked the necessary information to perform research synthesis and metaevaluation using established methods. Due to the diverse nature of the projects and methodologies used, an aggregation of findings from the evaluations was not possible. The nature and scope of the evaluation products also challenged common techniques to conduct metaevaluation. This is a significant finding of the project, as most evaluations do not use designs for which synthesis mechanisms are well established (e.g., meta-analysis). Additionally, the assumption exists that checklists and tools developed by leaders in the field can be used to perform a metaevaluation on available documents. These findings do not indicate a set of low-quality studies, but rather suggests that any attempt to judge the overall quality either of any given evaluation or of the general state of PDST will likely have low validity, and will require information beyond that found in available products. In summary, reports of PDST project evaluation do not lend themselves to metaevaluation. The amount and type of information necessary to perform an external metaevaluation is not present in either the sampled or screened evaluation products. Similarly, and because most evaluations are not based on randomized controlled trials, there is inadequate information to warrant evaluation synthesis. Better mechanisms need to be developed to allow for aggregation of and learning from evaluation products that use the range of designs and methods available to evaluation practitioners.  Another goal of this project was to disseminate findings to the education evaluation community. The project dissemination activities...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
