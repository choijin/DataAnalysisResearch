<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Combinatorial Inference and Learning for Fusing Recognition and Perceptual Grouping</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>507903.00</AwardTotalIntnAmount>
<AwardAmount>507903</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When presented with a novel image, humans typically have little problem providing a consistent interpretation of the scene in terms of contours, surfaces, junctions, and the relations between them. This process of perceptual organization is closely coupled with recognition of familiar shapes and materials. Perceptual organization can aid recognition by reducing the complexity of a cluttered scene to a small number of candidate surfaces while recognition can help resolve ambiguities in grouping based on local image cues.   This project is developing a computational framework that fuses top-down information provided by recognition with bottom-up perceptual organization in order to automatically produce a coherent scene interpretation. This research includes (1) identifying local image features that provide cues to grouping and figure-ground, (2) developing libraries of composable detectors that capture the appearance of objects, parts and their spatial relations, and (3) designing models and efficient inference routines that explicitly reason about occlusion and the binding of image regions and contours into object shapes.&lt;br/&gt;&lt;br/&gt;Integrated models of grouping and recognition have direct significance to expand the computer vision capabilities of robotics and assistive technologies that must operate in complex, cluttered environments.  The framework being developed also has applications in automating biological image analysis where top-down shape information are useful in resolving noisy local measurements. The computational tools developed by the project along with dissemination and educational efforts are aimed at forming an interdisciplinary bridge between biological imaging and cutting-edge computer vision research.</AbstractNarration>
<MinAmdLetterDate>02/06/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/11/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1253538</AwardID>
<Investigator>
<FirstName>Charless</FirstName>
<LastName>Fowlkes</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Charless Fowlkes</PI_FULL_NAME>
<EmailAddress>fowlkes@ics.uci.edu</EmailAddress>
<PI_PHON>9498246945</PI_PHON>
<NSF_ID>000505333</NSF_ID>
<StartDate>02/06/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926173067</ZipCode>
<StreetAddress><![CDATA[Donald Bren Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~97064</FUND_OBLG>
<FUND_OBLG>2014~96461</FUND_OBLG>
<FUND_OBLG>2015~100358</FUND_OBLG>
<FUND_OBLG>2016~105058</FUND_OBLG>
<FUND_OBLG>2017~108962</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>When presented with a novel image, humans typically have little problem providing a consistent interpretation of the scene in terms of contours, surfaces, junctions, and the relations between them. This process of perceptual organization is closely coupled with recognition of familiar shapes and materials but also allows us to interpret novel objects we've never encountered. Perceptual organization can aid recognition by reducing the complexity of a cluttered scene to a small number of candidate components while recognition can help resolve ambiguities in grouping based on local image cues.</span></p> <p><span>The goals of this project were to develop computational frameworks for fusing top-down sources of information provided by recognition with bottom-up perceptual organization in order to automatically produce a coherent scene interpretation. Over the course of the project, we developed and tested a wide variety of algorithms and mathematical frameworks.&nbsp; To highlight a few key technical results:</span></p> <p><span>(1) Reasoning about grouping image pixels into coherent segments corresponding to objects is challenging in part because of combinitorial complexity of finding a "best" solution in the space of possible groupings. We developed a novel set of approximation algorithms for performing probabilistic hierarchical clustering which take advantage of the planar structure of images.</span></p> <p><span>(2) Standard machine-learning tools for computer vision, e.g. based on convolutional neural networks, have focused on categorizing images into a set of predefined classes. We developed new architectures to perform detailed "pixel-level" labeling of images with high spatial fidelity, incorporating insights from traditional signal processing. We also introduced new output representations to allow models to predict a variable number of object instance segmentations in an image with high-fidelity.</span></p> <p>(3) An additional goal of the project was to strengthen the application of computer vision techniques to problems in biological image processing. With collaborators in developmental biology and neuroscience, we developed software tools for analyzing microscopy images to extract spatial patterns of gene expression and trace nerves through the peripheral nervous system, yielding new biological insights.</p> <p>The results of this research were disseminated in more than 20 open-access papers published in top conferences and journals in computer vision and biology. In addition, the project supported the research and mentoring of 4 PhD students who have graduated and are now in postdoctoral and industry research positions. Finally, the award enriched the development of several undergraduate computer vision courses taught by the PI at UC Irvine and helped engage 10+ undergraduate students in independent research projects.</p><br> <p>            Last Modified: 01/29/2020<br>      Modified by: Charless&nbsp;Fowlkes</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ When presented with a novel image, humans typically have little problem providing a consistent interpretation of the scene in terms of contours, surfaces, junctions, and the relations between them. This process of perceptual organization is closely coupled with recognition of familiar shapes and materials but also allows us to interpret novel objects we've never encountered. Perceptual organization can aid recognition by reducing the complexity of a cluttered scene to a small number of candidate components while recognition can help resolve ambiguities in grouping based on local image cues.  The goals of this project were to develop computational frameworks for fusing top-down sources of information provided by recognition with bottom-up perceptual organization in order to automatically produce a coherent scene interpretation. Over the course of the project, we developed and tested a wide variety of algorithms and mathematical frameworks.  To highlight a few key technical results:  (1) Reasoning about grouping image pixels into coherent segments corresponding to objects is challenging in part because of combinitorial complexity of finding a "best" solution in the space of possible groupings. We developed a novel set of approximation algorithms for performing probabilistic hierarchical clustering which take advantage of the planar structure of images.  (2) Standard machine-learning tools for computer vision, e.g. based on convolutional neural networks, have focused on categorizing images into a set of predefined classes. We developed new architectures to perform detailed "pixel-level" labeling of images with high spatial fidelity, incorporating insights from traditional signal processing. We also introduced new output representations to allow models to predict a variable number of object instance segmentations in an image with high-fidelity.  (3) An additional goal of the project was to strengthen the application of computer vision techniques to problems in biological image processing. With collaborators in developmental biology and neuroscience, we developed software tools for analyzing microscopy images to extract spatial patterns of gene expression and trace nerves through the peripheral nervous system, yielding new biological insights.  The results of this research were disseminated in more than 20 open-access papers published in top conferences and journals in computer vision and biology. In addition, the project supported the research and mentoring of 4 PhD students who have graduated and are now in postdoctoral and industry research positions. Finally, the award enriched the development of several undergraduate computer vision courses taught by the PI at UC Irvine and helped engage 10+ undergraduate students in independent research projects.       Last Modified: 01/29/2020       Submitted by: Charless Fowlkes]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
