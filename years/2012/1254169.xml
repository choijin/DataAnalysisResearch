<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: The Value of Privacy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>541993.00</AwardTotalIntnAmount>
<AwardAmount>541993</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project takes a new approach to problems involving sensitive data, by focusing on rigorous mathematical modeling and characterization of the value of private information. By focusing on quantifying the loss incurred by affected individuals when their information is used -- and quantifying the attendant benefits of such use -- the approaches advanced by this work enable concrete reasoning about the relative risks and rewards of a wide variety of potential computations on sensitive data. &lt;br/&gt;&lt;br/&gt;Specifically, this work has four main technical thrusts. The first is the development of new models and definitions, enabling privacy considerations to be incorporated into agent utility functions. The second is analysis of the feasibility and costs of eliciting sensitive information, in light of these models. The third focus is on enabling more sophisticated computations in settings where individuals value their privacy. Finally, more complex settings incorporate the interests of additional actors.&lt;br/&gt;&lt;br/&gt;One of the goals of this project is not only to develop a science of the value of private information, but to build bridges between computer science and economics that will enable such work. Further, the models and algorithms developed by this project could inform future regulation regarding the use, exchange, and monetization of sensitive data. The project supports and is supported by a wide variety of educational goals, including significant research involvement of students at a range of stages, development of a course series with a substantial research component, and assessment of a pedagogical technique created to facilitate meaningful engagement with research literature.</AbstractNarration>
<MinAmdLetterDate>05/15/2013</MinAmdLetterDate>
<MaxAmdLetterDate>11/21/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1254169</AwardID>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Wierman</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam C Wierman</PI_FULL_NAME>
<EmailAddress>adamw@caltech.edu</EmailAddress>
<PI_PHON>6263956073</PI_PHON>
<NSF_ID>000498686</NSF_ID>
<StartDate>11/21/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Katrina</FirstName>
<LastName>Ligett</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katrina A Ligett</PI_FULL_NAME>
<EmailAddress>katrina@caltech.edu</EmailAddress>
<PI_PHON>6263956219</PI_PHON>
<NSF_ID>000606549</NSF_ID>
<StartDate>05/15/2013</StartDate>
<EndDate>11/21/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>California Institute of Technology</Name>
<CityName>PASADENA</CityName>
<ZipCode>911250600</ZipCode>
<PhoneNumber>6263956219</PhoneNumber>
<StreetAddress>1200 E California Blvd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code 273-6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009584210</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CALIFORNIA INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009584210</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[California Institute of Technology]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>911250001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~105093</FUND_OBLG>
<FUND_OBLG>2014~105695</FUND_OBLG>
<FUND_OBLG>2015~108002</FUND_OBLG>
<FUND_OBLG>2016~110378</FUND_OBLG>
<FUND_OBLG>2017~112825</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project has focused on the study of incentive issues related to data privacy, including questions such as: who might share data with whom and why, how could people be compensated for the use of their private data, and how to gather and use data coming from people who might have an incentive to misrepresent or hide their data. To this end, we have developed new models of incentives in information-sharing in social networks, reflecting a trade-off between the risks and benefits of sharing information.</p> <p>This project has also considered issues that stem from making the formal mathematical tools used in the study of privacy more applicable real-world problems. This grant has supported work on a paper written for economists who work with personal data, in order to introduce them to the computer science privacy literature. One surprising result that has come from this work highlights the risks in blindly applying privacy-preserving technologies without considering the broader context; we see that if the parties involved might change their behavior as a result of an increased use of such technologies, their effect could have the opposite of what was intended. We have also studied the problem of maximizing the level of privacy that can be offered to participants in a dataset, subject to accuracy constraints on the computations that will be done with the data.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/06/2018<br>      Modified by: Adam&nbsp;C&nbsp;Wierman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project has focused on the study of incentive issues related to data privacy, including questions such as: who might share data with whom and why, how could people be compensated for the use of their private data, and how to gather and use data coming from people who might have an incentive to misrepresent or hide their data. To this end, we have developed new models of incentives in information-sharing in social networks, reflecting a trade-off between the risks and benefits of sharing information.  This project has also considered issues that stem from making the formal mathematical tools used in the study of privacy more applicable real-world problems. This grant has supported work on a paper written for economists who work with personal data, in order to introduce them to the computer science privacy literature. One surprising result that has come from this work highlights the risks in blindly applying privacy-preserving technologies without considering the broader context; we see that if the parties involved might change their behavior as a result of an increased use of such technologies, their effect could have the opposite of what was intended. We have also studied the problem of maximizing the level of privacy that can be offered to participants in a dataset, subject to accuracy constraints on the computations that will be done with the data.             Last Modified: 09/06/2018       Submitted by: Adam C Wierman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
