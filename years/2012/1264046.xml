<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative proposal: A multimodal tactile sensor skin designed to reduce the cognitive burden on the user of a prosthetic hand</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>199344.00</AwardTotalIntnAmount>
<AwardAmount>199344</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michele Grimm</SignBlockName>
<PO_EMAI>mgrimm@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>PI: Santos, Veronica J. and Posner, Jonathan D.&lt;br/&gt;Proposal Number: 1264444 &amp; 1264046&lt;br/&gt;&lt;br/&gt;Intellectual Merit: Whether a prosthetic hand is a simple body-powered hook or an advanced anthropomorphic device, it will only be useful and desirable to an amputee if it improves quality of life and is intuitive to control. A prosthesis will be rejected if it poses too great of a cognitive burden on the user. One way to simultaneously reduce the cognitive burden on the user and enhance the functionality of the user to focus on high-level commands as opposed to low-level details that may be frustrating to control or even impossible to control given the "language barrier" between human and machine because of different timescales and resolutions of control. Amputees could be empowered with prostheses having autonomous, local reflex algorithms akin to short latency grip reflexes observed in humans, and even suites of basic behavioral building blocks that are critical for activities of daily living. The only way for a semi-autonomous system to gain the trust of its operator is through reliable, context-dependent performance. Such context-aware performance will require information about forceful interactions between the prosthetic hand and everyday objects in unstructured environments that can only be obtained through touch. The great number and dynamic range of tactile mechanoreceptors in the human hand (17000 tactile sensors total, 2000 in each fingertip) highlight the importance of rich multimodal tactile feedback for grasp and dexterous manipulation. Unfortunately, many tactile sensor designs have focused on detection of normal forces alone, which are necessary but not sufficient for reliable artificial grasp. What is sorely needed is a multimodal tactile sensor that can detect additional important features of finger-object interactions such as shear force, vibration, and slip direction.  This proposal aims to strengthen the ability of an artificial hand to perform automated behaviors reliably by detecting, processing, and utilizing rich, real-time information about finger-object interactions with an innovative multimodal tactile sensor skin. This sensor system is transformative because it will reduce the cognitive burden on an amputee and will provide a foundation for paradigm-shifting advancements for automating complex behaviors by artificial hands and providing a conscious perception of touch through sensory feedback to the user. The long-term research objective of this proposal is to reduce the cognitive burden on the user of an upper extremity prosthesis. The following contributions to artificial hand systems are proposed: Research Goal 1) Design, model, fabricate, and test a flexible, multimodal tactile sensor skin system for artificial fingertips using a multilayer microfluidic architecture; Research Goal 2) Establish functional relationships between finger-object interactions and tactile sensor skin data for use in autonomous grip control algorithms; and Research Goal 3) Integrate the tactile sensor skin data into grip control algorithms and evaluate effectiveness for reducing the cognitive burden on prosthesis users.&lt;br/&gt;&lt;br/&gt;Broader Impacts: The proposed translational research could enhance the functional capabilities of artificial, robotic manipulators intended for unstructured, unsafe, or limited-access environments (prosthetic, rehabilitative, assistive, space, underwater, military, rescue, surgery). The proposed work could play a critical role in improving the quality of life for end-users of prosthetic and assistive devices. Specific benefits to end-users of prosthetic devices include: automation of complex prosthesis behaviors, rich artificial sensory feedback, and "smart socket liners" for monitoring user safety and comfort.&lt;br/&gt;&lt;br/&gt;Contributions to elementary school, undergraduate, and graduate-level education are proposed: Education Goal 1) Develop hands-on instructional modules for teaching elementary school students about sensors using low-cost materials, and deploy them locally for the benefit of students underrepresented in science, technology, engineering, and mathematics fields; Education Goal 2) Enhance undergraduate-level course titled Sensors and Controls and graduate-level course titled "Robotics" with a sensors module; and Education Goal 3) Promote interdisciplinary undergraduate research opportunities via internships related to the development, testing, and application of sensors.</AbstractNarration>
<MinAmdLetterDate>08/23/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/23/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1264046</AwardID>
<Investigator>
<FirstName>Jonathan</FirstName>
<LastName>Posner</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonathan D Posner</PI_FULL_NAME>
<EmailAddress>jposner@uw.edu</EmailAddress>
<PI_PHON>2065439834</PI_PHON>
<NSF_ID>000482284</NSF_ID>
<StartDate>08/23/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Mechanical Engineering, University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981952600</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5342</Code>
<Text>Disability &amp; Rehab Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>010E</Code>
<Text>DISABILITY RES &amp; HOMECARE TECH</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~199344</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="release">If a prosthetic hand needs to delicately handle an egg while cooking an omelet it needs to be able to sense when objects are slipping out of its grasp.&nbsp; Yet to date it&rsquo;s been difficult or impossible for most prosthetic hands to accurately sense the vibrations and shear forces that occur, for example, when a finger is sliding along a tabletop or when an object begins to fall. &nbsp;&nbsp;This project focused on the development of a flexible sensor skin that can be stretched over any part of a prosthetic to accurately convey information about normal and shear forces as well as vibration that are critical to successfully grasping and manipulating objects.</p> <p class="release">The new stretchable electronic skin is made from PDMS, the same silicone rubber used in swimming goggles. The rubber is embedded with tiny serpentine channels &mdash; roughly half the width of a human hair &mdash; filled with electrically conductive liquid metal, called gallium-indium-tin, that won&rsquo;t crack or fatigue when the skin is stretched.</p> <p>The bio-inspired robot sensor skin mimics the way a human finger experiences tension and compression as it slides along a surface or distinguishes among different textures. It measures this tactile information with similar precision and sensitivity as human skin, and could vastly improve the ability of prosthetic hands to robots that perform everything from surgical and industrial procedures to cleaning a kitchen.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This funding enabled the design, fabrication, and evaluation of bioinspired sensing skin that can measure normal and shear forces consistent with light touch applications.&nbsp; The sensor can make dynamic measurements at frequencies as high as 800 Hz and with displacements smaller than one micron.&nbsp; The sensor skin can measure light touch and dynamic forces consistent with human hands.&nbsp; The sensor skins are robust against electromagnetic interference and have shown the ability to detect slip and other dynamic events when mounted on the finger of a robotic arm.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/01/2017<br>      Modified by: Jonathan&nbsp;D&nbsp;Posner</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1264046/1264046_10270084_1509578003947_robot-skin-close-up--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1264046/1264046_10270084_1509578003947_robot-skin-close-up--rgov-800width.jpg" title="Sensor skin"><img src="/por/images/Reports/POR/2017/1264046/1264046_10270084_1509578003947_robot-skin-close-up--rgov-66x44.jpg" alt="Sensor skin"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Artificial sensor skin</div> <div class="imageCredit">UCLA Engineering</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Jonathan&nbsp;D&nbsp;Posner</div> <div class="imageTitle">Sensor skin</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[If a prosthetic hand needs to delicately handle an egg while cooking an omelet it needs to be able to sense when objects are slipping out of its grasp.  Yet to date it?s been difficult or impossible for most prosthetic hands to accurately sense the vibrations and shear forces that occur, for example, when a finger is sliding along a tabletop or when an object begins to fall.   This project focused on the development of a flexible sensor skin that can be stretched over any part of a prosthetic to accurately convey information about normal and shear forces as well as vibration that are critical to successfully grasping and manipulating objects. The new stretchable electronic skin is made from PDMS, the same silicone rubber used in swimming goggles. The rubber is embedded with tiny serpentine channels &mdash; roughly half the width of a human hair &mdash; filled with electrically conductive liquid metal, called gallium-indium-tin, that won?t crack or fatigue when the skin is stretched.  The bio-inspired robot sensor skin mimics the way a human finger experiences tension and compression as it slides along a surface or distinguishes among different textures. It measures this tactile information with similar precision and sensitivity as human skin, and could vastly improve the ability of prosthetic hands to robots that perform everything from surgical and industrial procedures to cleaning a kitchen.              This funding enabled the design, fabrication, and evaluation of bioinspired sensing skin that can measure normal and shear forces consistent with light touch applications.  The sensor can make dynamic measurements at frequencies as high as 800 Hz and with displacements smaller than one micron.  The sensor skin can measure light touch and dynamic forces consistent with human hands.  The sensor skins are robust against electromagnetic interference and have shown the ability to detect slip and other dynamic events when mounted on the finger of a robotic arm.             Last Modified: 11/01/2017       Submitted by: Jonathan D Posner]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
