<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Identifying and Removing Barriers to Autovectorization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>60611.00</AwardTotalIntnAmount>
<AwardAmount>60611</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Most modern microprocessors support some form of vector operations that allow the same operation to be applied to small vectors of arguments simultaneously.  Studies have shown that use of these instructions can improve the performance of many scientific codes by a factor of 2 or more.  Unfortunately, the state of the art in autovectorization falls far short of this goal, only achieving improvements of 20-30% on the same codes.&lt;br/&gt;&lt;br/&gt;While studies have shown that current autovectorizing compilers do not identify all of the opportunities for vectorization, little is known about why they fail to do so.  The PIs plan to evaluate tradeoffs between different compiler optimizations and vectorization in an effort to understand how optimization choices affect opportunities for autovectorization.  They will use an extensive set of benchmarks to evaluate these tradeoffs.  This research will make it possible to develop better autovectorizing compilers by avoiding optimization choices that interfere with autovectorization.  The performance benefits of such compilers will improve the performance of applications ranging from multimedia software to scientific computing.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1249449</AwardID>
<Investigator>
<FirstName>Alexandru</FirstName>
<LastName>Nicolau</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexandru Nicolau</PI_FULL_NAME>
<EmailAddress>anicolau@uci.edu</EmailAddress>
<PI_PHON>9498244079</PI_PHON>
<NSF_ID>000108570</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Veidenbaum</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexander V Veidenbaum</PI_FULL_NAME>
<EmailAddress>alexv@ics.uci.edu</EmailAddress>
<PI_PHON>9498246188</PI_PHON>
<NSF_ID>000181882</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Utpal</FirstName>
<LastName>Banerjee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Utpal Banerjee</PI_FULL_NAME>
<EmailAddress>ubanerjee@acm.org</EmailAddress>
<PI_PHON>9498244768</PI_PHON>
<NSF_ID>000608727</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>926970001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~60611</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This work (EAGER award) was an effort to determine the reasons why &nbsp;vectorization - &nbsp;a very efficient technique for parallel execution of certain types of code - &nbsp;has been in practice relatively unsuccessful, yielding only modest speedups and ~30% actual code vectorization in average applications, even though numerous studies show that, in principle &gt;90% vectorization/parallelization might be achievable.</p> <p>This is a very important problem, because a significant improvement in code performance via improved vectorization/parallelization would result not only in much faster execution of programs on exiting and future computers, but significant power savings as well.</p> <p>The relative failure to vectorize well is seemingly due not to the lack of parallelization/vectorization techniques (which are plentiful following 50+ years of prior research), but rather because of inability of existing tools to predict well &nbsp;which part of the code can be parallelized/vectorized and which transformations will result in the most significant performance increase as a result of such transformations for that particular code.</p> <p>&nbsp;To remedy this, as part of this project, we developed <span>a new technique for performance evaluation that is able to <em><strong>predict</strong></em> the performance of parallel programs across very diverse and&nbsp;</span><span>complex computer systems. This constitutes the foundation of a future effort to design the "ultimate" vectorizing compiler, in as much as this prediction tool will be used to accurately guide the application of transformations and optimizations to maximize performance of a given program executing on a given system, and/or optimize power consumption as well.&nbsp;</span></p> <p><span><br /></span></p><br> <p>            Last Modified: 09/25/2013<br>      Modified by: Alexandru&nbsp;Nicolau</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This work (EAGER award) was an effort to determine the reasons why  vectorization -  a very efficient technique for parallel execution of certain types of code -  has been in practice relatively unsuccessful, yielding only modest speedups and ~30% actual code vectorization in average applications, even though numerous studies show that, in principle &gt;90% vectorization/parallelization might be achievable.  This is a very important problem, because a significant improvement in code performance via improved vectorization/parallelization would result not only in much faster execution of programs on exiting and future computers, but significant power savings as well.  The relative failure to vectorize well is seemingly due not to the lack of parallelization/vectorization techniques (which are plentiful following 50+ years of prior research), but rather because of inability of existing tools to predict well  which part of the code can be parallelized/vectorized and which transformations will result in the most significant performance increase as a result of such transformations for that particular code.   To remedy this, as part of this project, we developed a new technique for performance evaluation that is able to predict the performance of parallel programs across very diverse and complex computer systems. This constitutes the foundation of a future effort to design the "ultimate" vectorizing compiler, in as much as this prediction tool will be used to accurately guide the application of transformations and optimizations to maximize performance of a given program executing on a given system, and/or optimize power consumption as well.           Last Modified: 09/25/2013       Submitted by: Alexandru Nicolau]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
