<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Generalizing Monotonic Data Structures for Expressive, Deterministic Parallel Programming</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>377315.00</AwardTotalIntnAmount>
<AwardAmount>377315</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The current trend in computer hardware is towards increasing numbers of parallel, independent processing units (cores).  This trend necessitates a widespread transition from traditional sequential programming to parallel programming.  But because parallel programming is notoriously difficult, adoption has been slow.  A fundamental reason for this difficulty is that programs can often yield inconsistent answers, or even crash, due to unpredictable interactions between parallel tasks.  Certain classes of programs, however, admit strong mathematical guarantees that they will behave the same in spite of parallel execution.  This research is extending the mathematical foundation underlying such deterministic programs.  It studies a family of programming languages that allow both parallel computations, and communications between them in the form of restricted modifications to, and observations of, shared data.  The communication allowed is of a more general nature than previous work in the area.&lt;br/&gt;&lt;br/&gt;This project is centered around a variant of the lambda-calculus that includes shared variables whose states occupy a join semilattice and change monotonically within that lattice.  A number of deterministic programming models, both recent (Intel CnC), and older (Kahn-MacQueen Process Networks), can be mapped into this framework.  In addition to constructing proofs of determinism for the language, this project explores various extensions, including limited forms of nondeterminism (i.e., which admit failures but never wrong answers).  Finally this project will use its formal language as a tool for reasoning about practical parallel programs.  That is, determinism can be demonstrated by verifying that the program's shared states form a semilattice and state changes are monotonic.</AbstractNarration>
<MinAmdLetterDate>07/23/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/23/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218375</AwardID>
<Investigator>
<FirstName>Ryan</FirstName>
<LastName>Newton</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ryan R Newton</PI_FULL_NAME>
<EmailAddress>rrnewton@purdue.edu</EmailAddress>
<PI_PHON>8122696190</PI_PHON>
<NSF_ID>000596232</NSF_ID>
<StartDate>07/23/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474021847</ZipCode>
<StreetAddress><![CDATA[Indiana University, PO Box 1847]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~377315</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>To continue to improve performance of computers, phones, and other computational devices, hardware designers now add more independent processors, rather than making each individual processor faster. &nbsp;Unfortunately, programming many processors is more difficult than programming one, for some of the same reasons that managing a team of people is more complicated than doing a task by yourself.</p> <p><br />Programs that are designed to split themselves into independent pieces are called parallel programs. &nbsp;Parallel programming is regarded as difficult and the purview of a small sect of experts. &nbsp;The biggest problem is that the pieces of parallel programs can interact unpredictably---these programs don't do the same thing every time you run them.Yet there is a budding science of "deterministic" parallel programs that behave the same whether they run on multiple or single processors, while still improving performance.</p> <p><br />This project added a new piece to the foundation of that science, showing how to generalize several previous approaches into one mathematical model, and proving the determinism property formally. &nbsp;This project then went on to build a freely available programming environment that normal programmers can use to write these deterministic parallel programs. &nbsp;This programming environment is maintained for the community and is more general than previous software of its kind, increasing the tools the programmer can use (e.g. ways that parallel program pieces can communicate) while retaining the determinism guarantee.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/15/2015<br>      Modified by: Ryan&nbsp;R&nbsp;Newton</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ To continue to improve performance of computers, phones, and other computational devices, hardware designers now add more independent processors, rather than making each individual processor faster.  Unfortunately, programming many processors is more difficult than programming one, for some of the same reasons that managing a team of people is more complicated than doing a task by yourself.   Programs that are designed to split themselves into independent pieces are called parallel programs.  Parallel programming is regarded as difficult and the purview of a small sect of experts.  The biggest problem is that the pieces of parallel programs can interact unpredictably---these programs don't do the same thing every time you run them.Yet there is a budding science of "deterministic" parallel programs that behave the same whether they run on multiple or single processors, while still improving performance.   This project added a new piece to the foundation of that science, showing how to generalize several previous approaches into one mathematical model, and proving the determinism property formally.  This project then went on to build a freely available programming environment that normal programmers can use to write these deterministic parallel programs.  This programming environment is maintained for the community and is more general than previous software of its kind, increasing the tools the programmer can use (e.g. ways that parallel program pieces can communicate) while retaining the determinism guarantee.          Last Modified: 12/15/2015       Submitted by: Ryan R Newton]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
