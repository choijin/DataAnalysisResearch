<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>High-dimensional structured regression</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>299892.00</AwardTotalIntnAmount>
<AwardAmount>299892</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is focused on structured high dimensional regression with the term structure meant to distinguish the methods from other methods such as l1 minimization methods. Generally speaking, this structure is assumed a priori and is chosen on the basis of finding an interpretable solution to a regression problem. In this project, structure often refers to spatial structure found in areas of application such as neuroimaging or astronomical data. The project has two principal goals. First to develop scalable, flexible algorithms and software implementations for fitting such structured models. Secondly, to understand the statistical performance of such models as well as the algorithms used to fit such models.&lt;br/&gt;&lt;br/&gt;The results of the research proposed in this project will allow researcher in the field of neuroscience to improve neuroscientists' ability to predict behavior based on fMRI or other spatio-temporally structured data.</AbstractNarration>
<MinAmdLetterDate>07/20/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208857</AwardID>
<Investigator>
<FirstName>Jonathan</FirstName>
<LastName>Taylor</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonathan Taylor</PI_FULL_NAME>
<EmailAddress>jonathan.taylor@stanford.edu</EmailAddress>
<PI_PHON>6507232300</PI_PHON>
<NSF_ID>000491142</NSF_ID>
<StartDate>07/20/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>943054000</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~98645</FUND_OBLG>
<FUND_OBLG>2013~99311</FUND_OBLG>
<FUND_OBLG>2014~101936</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This proposal focused on formulating and fitting statistical model<br />to complex high dimensional data. The starting point of this work<br />is the prototypical structure inducing LASSO penalty of Tibshirani.<br />The proposal focused on developing algorithms and software to formulate<br />and fit variations on this problem, with the goal of providing<br />users a flexible interface while maintaining performance in<br />high dimensions.<br /><br />In the course of carrying out this work, the project took<br />a somewhat unexpected turn, resulting in perhaps the most interesting<br />part of this work. We discovered a way to provide valid statistical<br />inference for the strength of structures discovered by such algorithms.<br /><br />The interest in such methods of inference comes from the acknowledgment<br />that science has suffered a crisis in replicability in recent years.<br />While there are likely many sources of such a crisis, from<br />a statistical viewpoint, at least part of the problem is caused<br />by a transition from the classical hypothesis-driven approach to<br />science towards a more data-driven approach. While the efficacy<br />of the data-driven approach seems clear, much of the rigorous<br />evaluation provided by mathematical statistics was developed<br />in a hypothesis-driven world. In short, in a data-driven scientific<br />enterprise, we have forfeited many of the guarantees of mathematical<br />statistics such as Type I error or unbiasedness of estimators.<br /><br />While statisticians have long recognized this forfeiture,<br />&nbsp;as a community, it has provided relatively few tools to address<br />this issue.<br />The tools developed as part of this proposal provide<br />scientists with methods having rigorous guarantees on Type I error<br />for assessing structure they have discovered in data, without necessitating<br />the collection of new data.</p> <p>The mathematical and statistical backbone of this work is the<br />area of conditional inference. The work is classical in some sense,<br />as conditional inference dates back at least to Fisher. Modifications<br />necessary for modern applications involve describing the geometry<br />of selections made by algorithms such as the LASSO, as well as how<br />to allow the statistical model itself to be chosen post-hoc (without<br />running into circular reasoning).<br /><br />The core of this conditional approach to the problem is<br />one of the key outcomes of this proposal. Those<br />interested can find a general description in the<br />article "Statistical learning and selective inference" by Taylor and Tibshirani,<br />PNAS June 23, 2015 112 (25) 7629-7634.<br /><br /><br /></p><br> <p>            Last Modified: 10/30/2018<br>      Modified by: Jonathan&nbsp;Taylor</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This proposal focused on formulating and fitting statistical model to complex high dimensional data. The starting point of this work is the prototypical structure inducing LASSO penalty of Tibshirani. The proposal focused on developing algorithms and software to formulate and fit variations on this problem, with the goal of providing users a flexible interface while maintaining performance in high dimensions.  In the course of carrying out this work, the project took a somewhat unexpected turn, resulting in perhaps the most interesting part of this work. We discovered a way to provide valid statistical inference for the strength of structures discovered by such algorithms.  The interest in such methods of inference comes from the acknowledgment that science has suffered a crisis in replicability in recent years. While there are likely many sources of such a crisis, from a statistical viewpoint, at least part of the problem is caused by a transition from the classical hypothesis-driven approach to science towards a more data-driven approach. While the efficacy of the data-driven approach seems clear, much of the rigorous evaluation provided by mathematical statistics was developed in a hypothesis-driven world. In short, in a data-driven scientific enterprise, we have forfeited many of the guarantees of mathematical statistics such as Type I error or unbiasedness of estimators.  While statisticians have long recognized this forfeiture,  as a community, it has provided relatively few tools to address this issue. The tools developed as part of this proposal provide scientists with methods having rigorous guarantees on Type I error for assessing structure they have discovered in data, without necessitating the collection of new data.  The mathematical and statistical backbone of this work is the area of conditional inference. The work is classical in some sense, as conditional inference dates back at least to Fisher. Modifications necessary for modern applications involve describing the geometry of selections made by algorithms such as the LASSO, as well as how to allow the statistical model itself to be chosen post-hoc (without running into circular reasoning).  The core of this conditional approach to the problem is one of the key outcomes of this proposal. Those interested can find a general description in the article "Statistical learning and selective inference" by Taylor and Tibshirani, PNAS June 23, 2015 112 (25) 7629-7634.          Last Modified: 10/30/2018       Submitted by: Jonathan Taylor]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
