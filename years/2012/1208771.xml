<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Novel statistical models for text mining with applications to Chinese history and texts</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In this project, the investigators study a series of challenging problems of extracting information from Chinese text, including: (1) word/phrase discovery, (2) text segmentation, (3) technical term recognition, and (4) association discovery among technical terms. Different from alphabetical languages such as English, Chinese has many special properties: no word boundaries, no clear definition of words, traditionally no punctuation, and a unique grammar. Thus, it is problematic to apply most methods developed for alphabetical languages directly to Chinese. Moreover, the available methods for analyzing Chinese text in the literature have many limitations. Instead the investigators propose an advanced word dictionary model (AWDM) that can simultaneously achieve word discovery, text segmentation and technical term recognition, which are traditionally studied separately. The idea is to build up a word dictionary first by enumerating all word candidates satisfying a certain criterion from the texts and assign to each word candidate a latent word type label representing different types of technical terms (such as names, addresses, office titles, time labels, as well as background texts) and corresponding word usage frequencies. Then, a Markov dependence model among different words and word types is given to model the potential grammatical and semantic structure of the texts. With the help of the training data (i.e., lists of known technical terms), the AWDM can automatically select the most meaningful words from the huge space of word candidates, determine the word type for each word based on not only the content of the word but also the context around the word, and segment the texts based on both grammatical and semantic information. Compared to the existing methods in the literature, the AWDM enjoys a better efficiency due to the joint modeling of the grammatical and semantic information and the integrated analysis of word discovery, text segmentation and technical term recognition. Combined with other text mining tools, such as topic models and theme dictionary models, the proposed method will lead to a powerful multi-level (Chinese character level, word/phrase level, theme level, topic level) analysis platform for Chinese texts.&lt;br/&gt;&lt;br/&gt;With the explosive growth of the internet and digital technologies, large quantities of digitalized Chinese texts can be easily collected. For example, lots of Chinese historical documents written in traditional Chinese are now available in digital form; and, public media such as new papers, forums, blogs and microblogs, are producing huge amounts of Chinese text every day. Thus there is great appeal in developing text mining tools to automatically extract information from these data and create new knowledge. The ideas and approaches in this project may have significant impacts on how Chinese history will be studied. An efficient and reliable method for extracting information from the ever growing databases of digitized historical documents will enable researchers to analyze change over time based on large numbers of disaggregated data points, something impractical in the past. Furthermore, although originally designed for Chinese, these approaches have the potential to be applied to other Asian languages similar to Chinese, such as Japanese and Korean, and thus provide a powerful multi-language platform for the study of Asian history. In addition, the novel way of combatting the challenges in recognizing named entities studied in this project also has the potential to be extended to alphabetical languages such as English. Finally, the ideas and approaches studied in this project have the potential to be generalized into a systematic tool that digests any data flow of Chinese texts, and outputs a structured database that contains key information about the individuals and organizations described by the input data, thus making it easier for researchers to discover social network of all kinds of "units" in our social life. Various item association patterns discovered by our algorithms are also invaluable to the study of public media and sociology, and may help reveal new important epidemiological events and societal trends in a timely fashion. These types of information can have important implications in business decision making and governmental policy making.</AbstractNarration>
<MinAmdLetterDate>05/21/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/02/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208771</AwardID>
<Investigator>
<FirstName>Jun</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jun Liu</PI_FULL_NAME>
<EmailAddress>jliu@stat.harvard.edu</EmailAddress>
<PI_PHON>6174951600</PI_PHON>
<NSF_ID>000193769</NSF_ID>
<StartDate>05/21/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Bol</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter Bol</PI_FULL_NAME>
<EmailAddress>pkbol@fas.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000541029</NSF_ID>
<StartDate>05/21/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ke</FirstName>
<LastName>Deng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ke Deng</PI_FULL_NAME>
<EmailAddress>kedeng@stat.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000606249</NSF_ID>
<StartDate>05/21/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021382901</ZipCode>
<StreetAddress><![CDATA[1 Oxford St, 715 Science Center]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~127049</FUND_OBLG>
<FUND_OBLG>2013~133897</FUND_OBLG>
<FUND_OBLG>2014~139054</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>With the rapid adoption of Internet as a main social, political, and literary media source by the general public, text data are accumulated at an astonishing pace. Figure 1 shows the trend of the publications of Chinese bloggers. It has accumulated a large volume, although currently many blogs are moved to mobile platforms. Here we also provide the link to the China Biolgraphical DataBase (CBDB)&nbsp;http://projects.iq.harvard.edu/cbdb/home, which contains <span>biographical and genealogical data for more than</span> 400,000 individuals primarily from the 7th through 19th centuries&nbsp;in China. &nbsp;T<span>he data is meant to be useful for statistical, social network, and spatial analysis as well as serving as a kind of biographical reference.&nbsp;</span></p> <p>The proposed research focuses on the development of statistical models and scalable algorithms for mining such Chinese text data. Due to the special differences between Chinese and English (e.g., no word boundaries, sometimes no punctuation, unusual grammar), it is problematic to directly apply most methods developed for alphabetical languages to Chinese. Furthermore, available methods for analyzing Chinese text have many limitations.&nbsp;The text data studied here come from historical works and&nbsp;documents&nbsp;that have accumulated over the last 1500 years of&nbsp;China's&nbsp;history, and are a complex&nbsp;mixture of many different components. Considering that the writing styles changed over the course of history and the huge grammatical differences between a literary Chinese and spoken Chinese, it is extremely difficult to select a smaller subset of the data that can adequately represent the whole dataset. This fact means that the supervised methods that need high quality training data are clearly not suitable here.</p> <p>In this study, we developed&nbsp;a group of dictionary-based statistical models, i.,e., the word dictionary model (WDM), the theme dictionary model (TDM), and advanced word dictionary model (AWDM) so that we can&nbsp;model the complicated linguistic structure of Chinese text at different levels. In this way, we convert the text mining problems of word discovery, text segmentation, technical term recognition, and association discovery into a series of statistical inference problems. Efficient inference algorithms are developed for these models.&nbsp;&nbsp;Combined with other mature text mining tools designed for alphabetical languages, such as word embedding and deep learning, the proposed methods provide a powerful multi-level (Chinese character level, word/phrase level, theme level, topic level) analysis platform for Chinese text.&nbsp;&nbsp;&nbsp;Furthermore, although originally designed for Chinese, these approaches have the potential to be applied to other Asian languages similar to Chinese, such as Japanese and Korean, \thus providing a multi-language platform for the study of Asian history.&nbsp;</p> <p>Other than the historical Chinese texts, we found that the proposed methods can be applied to a few other important fields. For example, With the popular use of information technologies in China&rsquo;s hospitals, a large amount of electronic medical records (EMRs) are available. These EMRs contain rich information about the entire medical process in China's hospitals and can play a key role in precision medicine, development of medical AI system, public policy for medical service and so on. Due to the huge size of the data, there is a great need in developing computational tools to automatically extract information from these big medical text data and create new knowledge. Text is an important component of these EMRs. However, the complexity and domain-specific nature of medical texts lead to critical challenges in processing and understanding these data. The statistical models and approaches developed in this project have been successfully applied to process Chinese EMRs, which provides key information for the further development of medical diagnosis and precision medicine tools.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/01/2016<br>      Modified by: Jun&nbsp;S&nbsp;Liu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1208771/1208771_10174293_1479058193216_SinaBlogTrend--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1208771/1208771_10174293_1479058193216_SinaBlogTrend--rgov-800width.jpg" title="Chinese blog trends (sina)"><img src="/por/images/Reports/POR/2016/1208771/1208771_10174293_1479058193216_SinaBlogTrend--rgov-66x44.jpg" alt="Chinese blog trends (sina)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Time trends of Sina blogs, and also the production of most popular bloggers</div> <div class="imageCredit">Ke Deng</div> <div class="imagePermisssions">Royalty-free (restricted use - cannot be shared)</div> <div class="imageSubmitted">Jun&nbsp;S&nbsp;Liu</div> <div class="imageTitle">Chinese blog trends (sina)</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With the rapid adoption of Internet as a main social, political, and literary media source by the general public, text data are accumulated at an astonishing pace. Figure 1 shows the trend of the publications of Chinese bloggers. It has accumulated a large volume, although currently many blogs are moved to mobile platforms. Here we also provide the link to the China Biolgraphical DataBase (CBDB) http://projects.iq.harvard.edu/cbdb/home, which contains biographical and genealogical data for more than 400,000 individuals primarily from the 7th through 19th centuries in China.  The data is meant to be useful for statistical, social network, and spatial analysis as well as serving as a kind of biographical reference.   The proposed research focuses on the development of statistical models and scalable algorithms for mining such Chinese text data. Due to the special differences between Chinese and English (e.g., no word boundaries, sometimes no punctuation, unusual grammar), it is problematic to directly apply most methods developed for alphabetical languages to Chinese. Furthermore, available methods for analyzing Chinese text have many limitations. The text data studied here come from historical works and documents that have accumulated over the last 1500 years of China's history, and are a complex mixture of many different components. Considering that the writing styles changed over the course of history and the huge grammatical differences between a literary Chinese and spoken Chinese, it is extremely difficult to select a smaller subset of the data that can adequately represent the whole dataset. This fact means that the supervised methods that need high quality training data are clearly not suitable here.  In this study, we developed a group of dictionary-based statistical models, i.,e., the word dictionary model (WDM), the theme dictionary model (TDM), and advanced word dictionary model (AWDM) so that we can model the complicated linguistic structure of Chinese text at different levels. In this way, we convert the text mining problems of word discovery, text segmentation, technical term recognition, and association discovery into a series of statistical inference problems. Efficient inference algorithms are developed for these models.  Combined with other mature text mining tools designed for alphabetical languages, such as word embedding and deep learning, the proposed methods provide a powerful multi-level (Chinese character level, word/phrase level, theme level, topic level) analysis platform for Chinese text.   Furthermore, although originally designed for Chinese, these approaches have the potential to be applied to other Asian languages similar to Chinese, such as Japanese and Korean, \thus providing a multi-language platform for the study of Asian history.   Other than the historical Chinese texts, we found that the proposed methods can be applied to a few other important fields. For example, With the popular use of information technologies in China?s hospitals, a large amount of electronic medical records (EMRs) are available. These EMRs contain rich information about the entire medical process in China's hospitals and can play a key role in precision medicine, development of medical AI system, public policy for medical service and so on. Due to the huge size of the data, there is a great need in developing computational tools to automatically extract information from these big medical text data and create new knowledge. Text is an important component of these EMRs. However, the complexity and domain-specific nature of medical texts lead to critical challenges in processing and understanding these data. The statistical models and approaches developed in this project have been successfully applied to process Chinese EMRs, which provides key information for the further development of medical diagnosis and precision medicine tools.          Last Modified: 12/01/2016       Submitted by: Jun S Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
