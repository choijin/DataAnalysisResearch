<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: Small: DA: Choosing a Needle in a Big Data Haystack</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2013</AwardEffectiveDate>
<AwardExpirationDate>03/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>674765.00</AwardTotalIntnAmount>
<AwardAmount>674765</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This big data project develops tools and algorithms to support users in the task of choosing one (or a few) object(s) from a very large set, particularly when there is a great deal of complex data on which to base this choice.&lt;br/&gt;&lt;br/&gt;Consider a traveler looking at hotel options on a travel site, a scientist trying to identify proteins to investigate further based upon the results of a high throughput experiment, or an intelligence analyst trying to identify suspected terrorists.  In all of these cases we have a big data challenge in that there are likely to be hundreds, perhaps thousands or even millions, of options to choose from.  While there are some criteria that can be expressed as simple functions of attribute values, e.g. price for a hotel room, these criteria capture only a part of the objective function.  Other considerations, such as stylishness of a hotel, can be much harder to determine as a function of known attributes.  The user may be compelled to examine candidate options individually.  The computer's task is to help minimize the number of candidates examined, and to optimize the order of examination.  This project examines how best to accomplish this task.&lt;br/&gt;&lt;br/&gt;Techniques explored include supporting human specification of information need against a variety of big data sources and machine presentation of relevant results with the volume of big data.  The broader impact of this project is in effectively harnessing the power of big data in a variety of applications, including business, science, and national defense.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/28/2013</MinAmdLetterDate>
<MaxAmdLetterDate>03/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1250880</AwardID>
<Investigator>
<FirstName>H.</FirstName>
<LastName>Jagadish</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>H. V Jagadish</PI_FULL_NAME>
<EmailAddress>jag@umich.edu</EmailAddress>
<PI_PHON>7347634079</PI_PHON>
<NSF_ID>000461011</NSF_ID>
<StartDate>03/28/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481092121</ZipCode>
<StreetAddress><![CDATA[2260 Hayward]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~674765</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Big Data is affecting almost every aspect of society today, and hence is a very important topic to study.&nbsp; Three dimensions have frequently been used to characterize big data: Volume, Variety, and Velocity.&nbsp; This project studied challenges in the first two dimensions.&nbsp; The project title conveys the basic idea: we have a huge &ldquo;haystack&rdquo; of items from among which we wish to find the &ldquo;needles&rdquo; of interest.&nbsp; Furthermore, each blade of hay is different, making the haystack highly heterogeneous.</p> <p>To address the volume challenge, we developed two approaches: one, to reduce the amount of data, somehow condensing it without losing important information; and two, to scale our ability to handle larger volumes of data.&nbsp; When we discuss scaling, computer scientists typically think about scaling the ability of computer systems to process larger volumes of data.&nbsp; We did study some issues along these lines in our project.&nbsp; But, more importantly, we also studied how to make it possible for humans to make sense of large volumes of data, keeping in mind that their ability does not scale.</p> <p>The variety challenge manifests itself in two distinct places: in the construction of a clean database from the heterogeneous raw data we have access to; and in the querying of a database with complex heterogeneous structure that the user is not fully conversant with.&nbsp; We addressed both problems.&nbsp; To construct a database with desired structure and format, we developed techniques to create transformation programs by example.&nbsp; In other words, the user would specify some examples of the end result they would like to see, and the system would generalize from these examples to develop programs that could correctly adjust format, modify structure, or fuse data from multiple sources.&nbsp; To assist users in querying unfamiliar databases, we developed interactive support for data exploration, and also support for queries expressed in plain English rather than as a computer program.</p> <p>Finally, given the huge impacts of Big Data on society today, we made the case for a new &ldquo;Values&rdquo; dimension for Big Data, and developed a research agenda in this dimension.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/19/2019<br>      Modified by: H.&nbsp;V&nbsp;Jagadish</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Big Data is affecting almost every aspect of society today, and hence is a very important topic to study.  Three dimensions have frequently been used to characterize big data: Volume, Variety, and Velocity.  This project studied challenges in the first two dimensions.  The project title conveys the basic idea: we have a huge "haystack" of items from among which we wish to find the "needles" of interest.  Furthermore, each blade of hay is different, making the haystack highly heterogeneous.  To address the volume challenge, we developed two approaches: one, to reduce the amount of data, somehow condensing it without losing important information; and two, to scale our ability to handle larger volumes of data.  When we discuss scaling, computer scientists typically think about scaling the ability of computer systems to process larger volumes of data.  We did study some issues along these lines in our project.  But, more importantly, we also studied how to make it possible for humans to make sense of large volumes of data, keeping in mind that their ability does not scale.  The variety challenge manifests itself in two distinct places: in the construction of a clean database from the heterogeneous raw data we have access to; and in the querying of a database with complex heterogeneous structure that the user is not fully conversant with.  We addressed both problems.  To construct a database with desired structure and format, we developed techniques to create transformation programs by example.  In other words, the user would specify some examples of the end result they would like to see, and the system would generalize from these examples to develop programs that could correctly adjust format, modify structure, or fuse data from multiple sources.  To assist users in querying unfamiliar databases, we developed interactive support for data exploration, and also support for queries expressed in plain English rather than as a computer program.  Finally, given the huge impacts of Big Data on society today, we made the case for a new "Values" dimension for Big Data, and developed a research agenda in this dimension.          Last Modified: 07/19/2019       Submitted by: H. V Jagadish]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
