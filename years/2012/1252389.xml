<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Using computer adaptive testing (CAT) to improve STEM learning, test performance, and retention</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>499936.00</AwardTotalIntnAmount>
<AwardAmount>499936</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The PI porposes to employ computer adaptive testing (CAT) to improve: STEM learning of Physics, test performance and student retention.  The PI notes that this interdisciplinary, empirical proposal combines expertise in testing/measurement, cognition, and STEM education to diagnose students? problem solving and conceptual deficits prior to taking high-stakes course exams, and then to devise interventions aimed at remedying identified deficits in order to improve students? course performance and, ultimately, their retention in STEM disciplines. Working within the domain of physics at the undergraduate level, the research team will investigate the feasibility of using computer adaptive testing (CAT) techniques to devise a cognitively diagnostic computer adaptive testing (CD-CAT) tool that accurately predicts students? future performance on tests in difficult STEM introductory undergraduate courses prior to their administration. The potential findings will have relevance for other STEM disciplines, and if successful, for broadening participation.</AbstractNarration>
<MinAmdLetterDate>09/20/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/20/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1252389</AwardID>
<Investigator>
<FirstName>Jose</FirstName>
<LastName>Mestre</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jose P Mestre</PI_FULL_NAME>
<EmailAddress>mestre@illinois.edu</EmailAddress>
<PI_PHON>2173330098</PI_PHON>
<NSF_ID>000091976</NSF_ID>
<StartDate>09/20/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Carolyn</FirstName>
<LastName>Anderson</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Carolyn J Anderson</PI_FULL_NAME>
<EmailAddress>cja@uiuc.edu</EmailAddress>
<PI_PHON>2172443537</PI_PHON>
<NSF_ID>000467974</NSF_ID>
<StartDate>09/20/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gary</FirstName>
<LastName>Gladding</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gary E Gladding</PI_FULL_NAME>
<EmailAddress>geg@illinois.edu</EmailAddress>
<PI_PHON>2173330864</PI_PHON>
<NSF_ID>000300858</NSF_ID>
<StartDate>09/20/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hua-Hua</FirstName>
<LastName>Chang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hua-Hua Chang</PI_FULL_NAME>
<EmailAddress>chang606@purdue.edu</EmailAddress>
<PI_PHON>2174930844</PI_PHON>
<NSF_ID>000308791</NSF_ID>
<StartDate>09/20/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Ryan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katherine Ryan</PI_FULL_NAME>
<EmailAddress>k-ryan6@illinois.edu</EmailAddress>
<PI_PHON>2173332187</PI_PHON>
<NSF_ID>000624024</NSF_ID>
<StartDate>09/20/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress><![CDATA[1901 South First Street, Suite A]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~499936</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The overarching goal of this project was to evaluate an approach to better prepare students enrolled in a typical introductory physics course for scientists and engineers for their midterm exams. Large numbers of students come to midterm exams believing they are well prepared only to find out that their performance was below average (C+ or below); most of these students continue underperforming and many leave STEM majors because of their overall poor performance in physics. The approach taken in this project was multifaceted. First, we devised a computer-adaptive testing, web-based delivery platform that was used to diagnose students' preparation prior to taking midterm exams. Computer-adaptive testing (CAT) uses an algorithm to select the next problem in a testing session based on the student's performance in previous problems. For example, if the student answers a problem correctly, the next problem given is slightly harder; conversely, if the student answers a problem incorrectly, the next problem given is slightly easier. Eventually, CAT predicts the student's performance level. Having underperforming students receive a predicted performance level based on CAT provides a realistic estimate of their preparation for an upcoming midterm exam. In addition, using CAT prior to taking a midterm exam allows the students to receive diagnostic information on the topics and types of problems that they need to learn better. This first phase of the project was motivated, in part, by research showing that students (especially low-performing students) are very poor predictors of their performance in tests both prior to, as well as immediately after, taking them. Findings indicate that the CAT does well in predicting students' average performance; however, predictions of individual student's performance varied significantly (almost half of the predictions differed from the midterm exam by 10 percentage points or more) making the CAT less reliable in this context.</p> <p>The second phase in the project consisted of devising and evaluating interventions to help students remedy their deficiencies. To do so we relied on previous research indicating that students can learn from worked-out examples and thus devised a number of animated-narrated worked-out solutions to exam-type problems using multimedia learning principles. We conducted several experiments to evaluate whether or not students showed a pre-test to post-test improvement on similar and transfer problems to those they studied in the intervention.&nbsp; Findings indicate that low-performing students improved significantly from the animated-narrated worked solutions on similar problems, but showed only modest improvement on transfer problems. The interventions improved low-performing students' performance on the midterm exams, but only modestly. These mixed results may be partially because of the difficulty in achieving transfer, particularly for low-performing students, the tendency for these students to engage in cramming (a majority of students reported studying for 2 hours or less before completing the interventions), and the limited scope of the interventions (students spent only between two and three hours completing the interventions).</p> <p><strong>Intellectual merit:</strong></p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This project represents the first exploration of the possible benefits of CAT as a diagnostic tool in the context of large introductory STEM university courses. In addition, this project extended research concerning CAT by exploring its potential for predicting student scores on traditional summative paper-and-pencil physics exams. Finally, research on worked examples typically investigates the use of static worked examples for problem-solving instruction after initial instruction; we extended the research on worked examples by investigating the effect of dynamic animated solutions in the context of reviewing for high-stakes midterm exams.</p> <p><strong>Broader impacts:</strong></p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This project was among the first to explore the potential of CAT as a diagnostic tool to help students (especially underperforming students) find out what score they would likely receive on a midterm exam prior to taking it. As a diagnostic tool, CAT can provide students with a realistic assessment of their current level of competence and can also provide immediate score predictions along with diagnostic information that students can use to focus their studying.</p> <p>When combined with interventions, such as animated worked-out solutions to exam-like problems, the approach could help improve the exam performance of students, thereby resulting &nbsp;in fewer students dropping out of STEM majors and hence increasing the STEM pipeline.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/31/2018<br>      Modified by: Jose&nbsp;P&nbsp;Mestre</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The overarching goal of this project was to evaluate an approach to better prepare students enrolled in a typical introductory physics course for scientists and engineers for their midterm exams. Large numbers of students come to midterm exams believing they are well prepared only to find out that their performance was below average (C+ or below); most of these students continue underperforming and many leave STEM majors because of their overall poor performance in physics. The approach taken in this project was multifaceted. First, we devised a computer-adaptive testing, web-based delivery platform that was used to diagnose students' preparation prior to taking midterm exams. Computer-adaptive testing (CAT) uses an algorithm to select the next problem in a testing session based on the student's performance in previous problems. For example, if the student answers a problem correctly, the next problem given is slightly harder; conversely, if the student answers a problem incorrectly, the next problem given is slightly easier. Eventually, CAT predicts the student's performance level. Having underperforming students receive a predicted performance level based on CAT provides a realistic estimate of their preparation for an upcoming midterm exam. In addition, using CAT prior to taking a midterm exam allows the students to receive diagnostic information on the topics and types of problems that they need to learn better. This first phase of the project was motivated, in part, by research showing that students (especially low-performing students) are very poor predictors of their performance in tests both prior to, as well as immediately after, taking them. Findings indicate that the CAT does well in predicting students' average performance; however, predictions of individual student's performance varied significantly (almost half of the predictions differed from the midterm exam by 10 percentage points or more) making the CAT less reliable in this context.  The second phase in the project consisted of devising and evaluating interventions to help students remedy their deficiencies. To do so we relied on previous research indicating that students can learn from worked-out examples and thus devised a number of animated-narrated worked-out solutions to exam-type problems using multimedia learning principles. We conducted several experiments to evaluate whether or not students showed a pre-test to post-test improvement on similar and transfer problems to those they studied in the intervention.  Findings indicate that low-performing students improved significantly from the animated-narrated worked solutions on similar problems, but showed only modest improvement on transfer problems. The interventions improved low-performing students' performance on the midterm exams, but only modestly. These mixed results may be partially because of the difficulty in achieving transfer, particularly for low-performing students, the tendency for these students to engage in cramming (a majority of students reported studying for 2 hours or less before completing the interventions), and the limited scope of the interventions (students spent only between two and three hours completing the interventions).  Intellectual merit:              This project represents the first exploration of the possible benefits of CAT as a diagnostic tool in the context of large introductory STEM university courses. In addition, this project extended research concerning CAT by exploring its potential for predicting student scores on traditional summative paper-and-pencil physics exams. Finally, research on worked examples typically investigates the use of static worked examples for problem-solving instruction after initial instruction; we extended the research on worked examples by investigating the effect of dynamic animated solutions in the context of reviewing for high-stakes midterm exams.  Broader impacts:              This project was among the first to explore the potential of CAT as a diagnostic tool to help students (especially underperforming students) find out what score they would likely receive on a midterm exam prior to taking it. As a diagnostic tool, CAT can provide students with a realistic assessment of their current level of competence and can also provide immediate score predictions along with diagnostic information that students can use to focus their studying.  When combined with interventions, such as animated worked-out solutions to exam-like problems, the approach could help improve the exam performance of students, thereby resulting  in fewer students dropping out of STEM majors and hence increasing the STEM pipeline.          Last Modified: 10/31/2018       Submitted by: Jose P Mestre]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
