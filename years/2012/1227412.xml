<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Bayesian Rapid Optimal Adaptive Design (BROAD) for Estimating</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>467536.00</AwardTotalIntnAmount>
<AwardAmount>467536</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Leland</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>In this project the Principal Investigators will develop methods to rapidly personalize the series of questions that are asked in an experiment or survey, adjusting new questions based on a respondent?s previous answers and the speed of their responses. The methods guarantee, mathematically, that the most informative question is being asked at each step. The software challenge is being able to recompute rapidly on a variety of computer platforms. We will also make software user-friendly and widely available.&lt;br/&gt; &lt;br/&gt;In terms of broader impacts, this research will enable scientists to figure out, faster and better, how people are different from each other in what they like and how they behave. Our method will enable creation of short surveys that yield more insight. The method will specifically be used to find out how much risk people accept, how patient they are toward future costs and benefits, and how much they like to cooperate and compete with other people. These methods can help consumers and companies figure out what kind of investments they should make, and help match workers with jobs that are ideal for them.</AbstractNarration>
<MinAmdLetterDate>09/21/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/21/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1227412</AwardID>
<Investigator>
<FirstName>Colin</FirstName>
<LastName>Camerer</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Colin F Camerer</PI_FULL_NAME>
<EmailAddress>camerer@hss.caltech.edu</EmailAddress>
<PI_PHON>6263954054</PI_PHON>
<NSF_ID>000234795</NSF_ID>
<StartDate>09/21/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>California Institute of Technology</Name>
<CityName>PASADENA</CityName>
<ZipCode>911250600</ZipCode>
<PhoneNumber>6263956219</PhoneNumber>
<StreetAddress>1200 E California Blvd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code 273-6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009584210</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CALIFORNIA INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009584210</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[California Institute of Technology]]></Name>
<CityName>Pasadena</CityName>
<StateCode>CA</StateCode>
<ZipCode>911250001</ZipCode>
<StreetAddress><![CDATA[1200 E. California Blvd. 228-77]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1320</Code>
<Text>Economics</Text>
</ProgramElement>
<ProgramElement>
<Code>1321</Code>
<Text>Decision, Risk &amp; Mgmt Sci</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~467536</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;What do people want? This question is at the core of social science, and answering it is a deep science problem with many practical implications. The starting point in behavioral economics is the idea that choices people make are caused by, and reveal, underlying &ldquo;preferences&rdquo;. Preferences are thought to be stable over short periods of time and across different types of decisions. However, behavioral economics evidence has shown that choices can be influenced by many factors, and exhibit instability; then the scientific goal is to identify the causes of instability.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Inferring preferences then becomes a challenging statistical problem. For example, if people dislike investing stocks because stock prices fluctuate too much, how can we best measure their aversion to the risks inherent in owning stocks?</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Our goal in this project was to use modern computing power and statistical analysis to figure out more rapidly, and more precisely, what kind of economic choices people like. The two kinds of choices we studied are (a) risky choices, and (b) choices of valuable rewards over time. Our method doubles the rate at which we learn about these choices. The method uses a particular idea from computer science that had not been imported to social science previously (althought similar methods have been used).</p> <p>&nbsp;</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; What are these choices that we are trying to understand?</p> <p>&nbsp;</p> <p>(a) Risky choices are those in which there are several possible financial outcomes. In simple laboratory versions, these are amounts of money that can be earned with known probabilities. What we learn from these lab choices is hypothesized to tell us how much risk people will taken in personal investments, in gambling such as lottery ticket purchases, and in choosing careers with safer income or riskier income.</p> <p>(b) Choices of rewards over time force people to decide whether they want a small amount of money sooner, or a larger amount later. What we learn from these lab choices is hypothesized to tell us how patient people will be about delaying gratification by exercising, dieting to improve long-term health, and completing work projects on time.</p> <p>&nbsp;</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In social sciences, how much risk people like to take, and how patient they are, is thought to be numerically approximated by a degree of risk-aversion and a discount rate.&nbsp; Of course, this methods reduce very complicated decisions to a single number. However, statistical methods can dictate whether a single number is an adequate approximation or whether two, three, or more numerical dimensions are necessary.</p> <p>&nbsp;</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To figure out how much risk people are willing to take, and how patient they are, experiments and survey ask people a series of questions. For example, suppose a person says they would rather have $40 than have a risk in which they have an equal (50%) chance of getting $100 or nothing. Since they would rather have $40, the next step is to ask how much less than $40 they would accept, before taking the risk of $100 or nothing.&nbsp; Our computer method asks a series of questions like this in a Bayesian-optimal way. The core step is to compute how much we expect to learn from asking different questions, given what a person has already told us from their previous responses. An &ldquo;information criterion&rdquo; ranks every possible question in terms of how much we can learn about a person by asking that question.&nbsp; The method &ldquo;personalizes&rdquo; questions; for every person we use their previous choices to get the most information about what they like.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Statistical analyses indicate that by using this optimal method of personalizing questions, we can at least double the rate of information gain. Surveys that have used 10 questions before can give the same precision in only five questions, if the questions are personalized using our methods.&nbsp; The gain from learning what people want rapidly is especially useful when we branch out from &ldquo;convenience&rdquo; samples of college students, to study children, busy corporate executives, and add questions on large-scale surveys. In the latter cases, scientists sometimes can ask only a small number of questions so there is a large premium on the information value of each question. Our method provides that information value.</p> <p>The graphics accompanying this description show (a) the cycle by which preliminary (prior) information guides what choices are posed, and what conclusions are drawn from the answers to those choice questions (called &ldquo;posteriors&rdquo;); (b) a graphical user interface (GUI) which asks people to allocate money between different points of time, to measure patience; and (c) an illustration of the specific numbers expressing degrees of patience that were derived from actual choices of Amazon Turk subjects.</p> <p>&nbsp;</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Our adaptive methods have already been used in several published papers and have attracted keen interest. Beyond the life of this grant, we are continuing to develop software platforms to make the methods useable across social sciences.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/20/2017<br>      Modified by: Colin&nbsp;F&nbsp;Camerer</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1227412/1227412_10217650_1490039269267_graphic_GUI--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227412/1227412_10217650_1490039269267_graphic_GUI--rgov-800width.jpg" title="The user interface to measure time preference"><img src="/por/images/Reports/POR/2017/1227412/1227412_10217650_1490039269267_graphic_GUI--rgov-66x44.jpg" alt="The user interface to measure time preference"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The calendar shows two dates on which people can receive money (October 16 and November 6). By moving the cursor on the slider bar, people can indicate whether they want more money in October or more in November. Where they put the cursor tells us how patient they are.</div> <div class="imageCredit">Taisuke Imai</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Colin&nbsp;F&nbsp;Camerer</div> <div class="imageTitle">The user interface to measure time preference</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1227412/1227412_10217650_1490039504471_Graphic_cycleoftruth--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1227412/1227412_10217650_1490039504471_Graphic_cycleoftruth--rgov-800width.jpg" title="The cycle of estimating preferences"><img src="/por/images/Reports/POR/2017/1227412/1227412_10217650_1490039504471_Graphic_cycleoftruth--rgov-66x44.jpg" alt="The cycle of estimating preferences"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our method begins with a "prior" belief on a number that measures an aspect of preferences (e.g. patience). After each question, the method chooses the next question which is mathematically the most informative. After a person answers the question, the prior estimate is updated to a posterior.</div> <div class="imageCredit">Taisuke Imai</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Colin&nbsp;F&nbsp;Camerer</div> <div class="imageTitle">The cycle of estimating preferences</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[             What do people want? This question is at the core of social science, and answering it is a deep science problem with many practical implications. The starting point in behavioral economics is the idea that choices people make are caused by, and reveal, underlying "preferences". Preferences are thought to be stable over short periods of time and across different types of decisions. However, behavioral economics evidence has shown that choices can be influenced by many factors, and exhibit instability; then the scientific goal is to identify the causes of instability.              Inferring preferences then becomes a challenging statistical problem. For example, if people dislike investing stocks because stock prices fluctuate too much, how can we best measure their aversion to the risks inherent in owning stocks?              Our goal in this project was to use modern computing power and statistical analysis to figure out more rapidly, and more precisely, what kind of economic choices people like. The two kinds of choices we studied are (a) risky choices, and (b) choices of valuable rewards over time. Our method doubles the rate at which we learn about these choices. The method uses a particular idea from computer science that had not been imported to social science previously (althought similar methods have been used).                 What are these choices that we are trying to understand?     (a) Risky choices are those in which there are several possible financial outcomes. In simple laboratory versions, these are amounts of money that can be earned with known probabilities. What we learn from these lab choices is hypothesized to tell us how much risk people will taken in personal investments, in gambling such as lottery ticket purchases, and in choosing careers with safer income or riskier income.  (b) Choices of rewards over time force people to decide whether they want a small amount of money sooner, or a larger amount later. What we learn from these lab choices is hypothesized to tell us how patient people will be about delaying gratification by exercising, dieting to improve long-term health, and completing work projects on time.                 In social sciences, how much risk people like to take, and how patient they are, is thought to be numerically approximated by a degree of risk-aversion and a discount rate.  Of course, this methods reduce very complicated decisions to a single number. However, statistical methods can dictate whether a single number is an adequate approximation or whether two, three, or more numerical dimensions are necessary.                 To figure out how much risk people are willing to take, and how patient they are, experiments and survey ask people a series of questions. For example, suppose a person says they would rather have $40 than have a risk in which they have an equal (50%) chance of getting $100 or nothing. Since they would rather have $40, the next step is to ask how much less than $40 they would accept, before taking the risk of $100 or nothing.  Our computer method asks a series of questions like this in a Bayesian-optimal way. The core step is to compute how much we expect to learn from asking different questions, given what a person has already told us from their previous responses. An "information criterion" ranks every possible question in terms of how much we can learn about a person by asking that question.  The method "personalizes" questions; for every person we use their previous choices to get the most information about what they like.                  Statistical analyses indicate that by using this optimal method of personalizing questions, we can at least double the rate of information gain. Surveys that have used 10 questions before can give the same precision in only five questions, if the questions are personalized using our methods.  The gain from learning what people want rapidly is especially useful when we branch out from "convenience" samples of college students, to study children, busy corporate executives, and add questions on large-scale surveys. In the latter cases, scientists sometimes can ask only a small number of questions so there is a large premium on the information value of each question. Our method provides that information value.  The graphics accompanying this description show (a) the cycle by which preliminary (prior) information guides what choices are posed, and what conclusions are drawn from the answers to those choice questions (called "posteriors"); (b) a graphical user interface (GUI) which asks people to allocate money between different points of time, to measure patience; and (c) an illustration of the specific numbers expressing degrees of patience that were derived from actual choices of Amazon Turk subjects.                 Our adaptive methods have already been used in several published papers and have attracted keen interest. Beyond the life of this grant, we are continuing to develop software platforms to make the methods useable across social sciences.           Last Modified: 03/20/2017       Submitted by: Colin F Camerer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
