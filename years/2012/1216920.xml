<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Novel Algorithms for Nonlinear Optimization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>252000.00</AwardTotalIntnAmount>
<AwardAmount>252000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Junping Wang</SignBlockName>
<PO_EMAI>jwang@nsf.gov</PO_EMAI>
<PO_PHON>7032924488</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The two research objectives of this project concern the development, analysis, and implementation of novel numerical methods for the solution of nonlinear optimization problems.  The first thrust addresses the design of nonlinear programming (NLP) methods that can, in contrast to existing algorithms, reuse the factorization of derivative matrices for the solution of closely related problem instances.  Such hot-started methods are expected to lead to significant speedup of branch-and-bound algorithms for mixed-integer nonlinear optimization.  The second focus is the development of efficient parallel algorithms based on Generalized Benders Decomposition for the solution of decomposable NLPs, as they arise in design under uncertainty or two-stage stochastic optimization problems.  The emphasis lies in the fast computation of local solutions of nonconvex problems, whereas existing approaches are restricted to convex instances or limited to the much more time-consuming search for global optima.&lt;br/&gt;&lt;br/&gt;Numerical optimization has become an indispensable tool in many areas of industry, economy and science, answering questions such as "what is the best way to design and operate this plant" or "how should the electrical power grid be operated in order to be able to sustain failure of network components."  While powerful computational methods are available for the optimization of systems that can be described by models that are either linear or restricted to non-discrete decisions, the solution of problems that are both nonlinear and discrete, as they frequently appear in practice, is often too time-consuming with current technology.  Therefore, the first part of the proposed research project aims at significantly accelerating a crucial key component in algorithms for nonlinear discrete optimization.  The second research objective of this project deals with the efficient exploitation of increasingly pervasive parallel computing power for the optimization of problems that consider many potential scenarios as a way of addressing the uncertainty of future circumstances.</AbstractNarration>
<MinAmdLetterDate>07/24/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1216920</AwardID>
<Investigator>
<FirstName>Andreas</FirstName>
<LastName>Waechter</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andreas Waechter</PI_FULL_NAME>
<EmailAddress>waechter@iems.northwestern.edu</EmailAddress>
<PI_PHON>8474913172</PI_PHON>
<NSF_ID>000609240</NSF_ID>
<StartDate>07/24/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602080834</ZipCode>
<StreetAddress><![CDATA[2145 Sheridan Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramElement>
<Code>5514</Code>
<Text>OPERATIONS RESEARCH</Text>
</ProgramElement>
<ProgramReference>
<Code>073E</Code>
<Text>OPTIMIZATION &amp; DECISION MAKING</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~252000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project resulted in the development of several numerical algorithms for the optimization of systems that can be modeled by nonlinear and continuous functions. &nbsp;The theoretical convergence properties of these methods was studied. &nbsp;To evaluate their practical relevance, they were implemented in computer software and tested on academic problems and real-world instances.</p> <p>The methods fall into several categories: a) One subproject dealt with the acceleration of algorithms by permitting that subproblems (that need to be solved in each step of the algorithm) can be solved only approximately. &nbsp;To ensure that the methods converge for any given instance, termination criteria were carefully derived that balance the speedup gained by inexact subproblems solutions with theoretically necessary conditions that guarantee convergence. &nbsp;b) Under another project, a method was devised that optimizes a general process that is simulated by a computer program and that is noisy in the sense that a small difference in the input may result in a large difference in the output. &nbsp;A key feature of the algorithm is that it makes it possible to carry over the output of time-consuming computer simulations from one step of the algorithm to the next. &nbsp;This is a achieved by a novel weighted regression techniques based on randomized sample points. &nbsp;The software implementation of this method demonstrated a significant improvement in robustness compared to state-of-the-art methods. &nbsp;c) Another project dealt with the design of an optimization method for the training of predictive models as they are used in some machine learning applications. &nbsp;The novel ingredient is the criterion that quickly detects which features in the observed data are important.</p> <p>The efficiency of these methods was demonstrated on a variety of real-world problems, including: Optimal control of chemical processes, optimum experimental design, and machine learning instances.<br />Within this project, several PhD students received training in conducting independent research, writing journal papers, and presenting the results of their research at international conferences.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/20/2015<br>      Modified by: Andreas&nbsp;Waechter</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project resulted in the development of several numerical algorithms for the optimization of systems that can be modeled by nonlinear and continuous functions.  The theoretical convergence properties of these methods was studied.  To evaluate their practical relevance, they were implemented in computer software and tested on academic problems and real-world instances.  The methods fall into several categories: a) One subproject dealt with the acceleration of algorithms by permitting that subproblems (that need to be solved in each step of the algorithm) can be solved only approximately.  To ensure that the methods converge for any given instance, termination criteria were carefully derived that balance the speedup gained by inexact subproblems solutions with theoretically necessary conditions that guarantee convergence.  b) Under another project, a method was devised that optimizes a general process that is simulated by a computer program and that is noisy in the sense that a small difference in the input may result in a large difference in the output.  A key feature of the algorithm is that it makes it possible to carry over the output of time-consuming computer simulations from one step of the algorithm to the next.  This is a achieved by a novel weighted regression techniques based on randomized sample points.  The software implementation of this method demonstrated a significant improvement in robustness compared to state-of-the-art methods.  c) Another project dealt with the design of an optimization method for the training of predictive models as they are used in some machine learning applications.  The novel ingredient is the criterion that quickly detects which features in the observed data are important.  The efficiency of these methods was demonstrated on a variety of real-world problems, including: Optimal control of chemical processes, optimum experimental design, and machine learning instances. Within this project, several PhD students received training in conducting independent research, writing journal papers, and presenting the results of their research at international conferences.          Last Modified: 10/20/2015       Submitted by: Andreas Waechter]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
