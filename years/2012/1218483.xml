<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Algorithm/Architecture Co-Design of Low Power and High Performance Linear Algebra Compute Fabrics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2012</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>499919.00</AwardTotalIntnAmount>
<AwardAmount>499919</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Until recently, the speed of a computer processors could be increased&lt;br/&gt;by packing more transistors into a smaller area and increasing the&lt;br/&gt;frequency.  This trend is now unsustainable because of power&lt;br/&gt;constraints, with only moderate gains going forward even when putting&lt;br/&gt;hundreds or thousands of traditional cores onto a chip.  Thus, how to&lt;br/&gt;reduce power consumption while increasing performance is one of the&lt;br/&gt;core concerns.  It is well-accepted that specialization (designing&lt;br/&gt;parts of the processor for a specific task) and heterogeneity&lt;br/&gt;(designating different parts of the processor for different tasks) can&lt;br/&gt;lead to orders of magnitude improvements in both aspects.  However,&lt;br/&gt;the question is whether such efficiency can be maintained while&lt;br/&gt;providing enough flexibility to implement a broad class of operations.&lt;br/&gt;Leveraging unique domain expertise, research under this project&lt;br/&gt;addresses this question for the domain of matrix computations, which&lt;br/&gt;are at the core of many computational advances, both in scientific&lt;br/&gt;high-performance computing as well as in the embedded, mobile or&lt;br/&gt;cyber-physical domains.&lt;br/&gt;&lt;br/&gt;Observing that the largest benefits can be obtained through&lt;br/&gt;specialization at the foundations, this project is aimed at&lt;br/&gt;co-designing algorithms and architectures to directly realize basic&lt;br/&gt;linear algebra methods in an optimized combination of hardware and&lt;br/&gt;software.  By designing a specialized Linear Algebra Processor (LAP),&lt;br/&gt;it is possible to achieve one to two orders of magnitude improved&lt;br/&gt;efficiencies compared to traditional or proposed computer&lt;br/&gt;architectures.  The questions that the project will answer, through a&lt;br/&gt;combination of analysis, simulation, and prototyping, include: (1) How&lt;br/&gt;to best design such LAPs that can efficiently execute the full set of&lt;br/&gt;linear algebra routines; and (2) How LAPs can be scaled, networked&lt;br/&gt;into clusters and integrated with application software running on one&lt;br/&gt;or more host processors.  The broad goal of this project is to develop&lt;br/&gt;novel, integrated linear algebra compute fabrics that are co-optimized&lt;br/&gt;and co-designed across all layers ranging from the basic hardware&lt;br/&gt;foundations all the way to the application programming support through&lt;br/&gt;standard linear algebra software packages.  This project is expected&lt;br/&gt;to result in a leap in computational science and discovery&lt;br/&gt;capabilities, thus enabling novel breakthroughs in industry, for the&lt;br/&gt;consumer, at the national labs, in education and by scientists in&lt;br/&gt;academia.</AbstractNarration>
<MinAmdLetterDate>06/07/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/07/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218483</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>van de Geijn</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert A van de Geijn</PI_FULL_NAME>
<EmailAddress>rvdg@cs.utexas.edu</EmailAddress>
<PI_PHON>5124719720</PI_PHON>
<NSF_ID>000336892</NSF_ID>
<StartDate>06/07/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andreas</FirstName>
<LastName>Gerstlauer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andreas Gerstlauer</PI_FULL_NAME>
<EmailAddress>gerstl@ece.utexas.edu</EmailAddress>
<PI_PHON>5122328294</PI_PHON>
<NSF_ID>000520598</NSF_ID>
<StartDate>06/07/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787137726</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>21</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX21</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~499919</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Information and semiconductor technology has had enormous social implications over the last decades. However, with semiconductor scaling reaching physical limits, power constraints have become the primary issue in continued evolution and performance growth of computing systems going forward. Fundamentally, energy savings can only be achieved by either reducing the amount of computation performed in the first place, or by reducing the amount of overhead per required computation. The latter is achieved through specializations. Traditional general-purpose computer systems incur a tremendous amount of overhead as the price for the flexibility to run any application. It is well accepted that specialization (designing parts of the computer for a specific task) and heterogeneity (designating different parts of the computer for different tasks) can lead to orders of magnitude improvements in both performance and power consumption. At the same time, exponential increasing costs of semiconductor fabrication make it impossible to tape out a new specialized chip for every new application. The question is thus whether such efficiencies can be maintained while providing enough flexibility to implement a broad class of operations.</p> <p>In this project, we have addressed such questions by investigating novel specialized computer system designs to reduce power consumption while increasing performance specifically for the important domain of linear algebra operations. Linear algebra or matrix operations are at the root of almost all computational problems not only in science and engineering but also in emerging application areas such as data analytics, machine learning and artificial intelligence.</p> <p>Observing that the largest benefits can be obtained through specialization at the foundations, this project was aimed at co-designing architectures and the algorithms running on them to directly realize core linear algebra methods in an optimized combination of hardware and software. The primary result has been a novel design of a Linear Algebra Processor (LAP) that is orders of magnitude more energy efficient (as measured by the energy per operation) than any existing processor design, all while being able to run a complete set of operations with higher performance. Beyond just the immediate goal of designing a specialized processor, we have used our LAP design as a baseline to study fundamental limits in efficiency and fundamental tradeoffs between achievable efficiency and flexibility in the context of the targeted application domain. We have developed novel approaches for fast yet accurate power and performance modeling of the LAP and other accelerators that enable rapid, early exploration of design spaces. Using developed LAP models, results have suggested minimal modifications that should make it possible to significantly improve performance and efficiency for these types of operations on existing computer system designs. Finally, we have developed necessary software stacks and software support for integration of LAP accelerators into larger systems and overall applications, showing that when integrating the LAP with existing processor and system components in a heterogeneous environment, and with corresponding support through tightly co-optimized software stacks, close to peak efficiencies can be maintained across larger applications that utilize such linear algebra kernels.</p> <p>All combined, results of this project have demonstrated that is possible to design domain-specific accelerators with orders-of-magnitude improved efficiency of full-custom hardware but enough flexibility to run any application across a range of related domains. In doing so, we have developed novel, integrated linear algebra compute fabrics that are co-optimized and co-designed across all layers ranging from the basic hardware foundations all the way to the application programming support through standard linear algebra software packages. Being able to provide hitherto infeasible, order of magnitude improved compute capabilities even in energy-constrained devices (such as small, embedded mobile or battery-operated systems) for this important domain of applications has the potential to solve many open problems that may significantly impact society in the future.</p><br> <p>            Last Modified: 07/27/2017<br>      Modified by: Andreas&nbsp;Gerstlauer</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Information and semiconductor technology has had enormous social implications over the last decades. However, with semiconductor scaling reaching physical limits, power constraints have become the primary issue in continued evolution and performance growth of computing systems going forward. Fundamentally, energy savings can only be achieved by either reducing the amount of computation performed in the first place, or by reducing the amount of overhead per required computation. The latter is achieved through specializations. Traditional general-purpose computer systems incur a tremendous amount of overhead as the price for the flexibility to run any application. It is well accepted that specialization (designing parts of the computer for a specific task) and heterogeneity (designating different parts of the computer for different tasks) can lead to orders of magnitude improvements in both performance and power consumption. At the same time, exponential increasing costs of semiconductor fabrication make it impossible to tape out a new specialized chip for every new application. The question is thus whether such efficiencies can be maintained while providing enough flexibility to implement a broad class of operations.  In this project, we have addressed such questions by investigating novel specialized computer system designs to reduce power consumption while increasing performance specifically for the important domain of linear algebra operations. Linear algebra or matrix operations are at the root of almost all computational problems not only in science and engineering but also in emerging application areas such as data analytics, machine learning and artificial intelligence.  Observing that the largest benefits can be obtained through specialization at the foundations, this project was aimed at co-designing architectures and the algorithms running on them to directly realize core linear algebra methods in an optimized combination of hardware and software. The primary result has been a novel design of a Linear Algebra Processor (LAP) that is orders of magnitude more energy efficient (as measured by the energy per operation) than any existing processor design, all while being able to run a complete set of operations with higher performance. Beyond just the immediate goal of designing a specialized processor, we have used our LAP design as a baseline to study fundamental limits in efficiency and fundamental tradeoffs between achievable efficiency and flexibility in the context of the targeted application domain. We have developed novel approaches for fast yet accurate power and performance modeling of the LAP and other accelerators that enable rapid, early exploration of design spaces. Using developed LAP models, results have suggested minimal modifications that should make it possible to significantly improve performance and efficiency for these types of operations on existing computer system designs. Finally, we have developed necessary software stacks and software support for integration of LAP accelerators into larger systems and overall applications, showing that when integrating the LAP with existing processor and system components in a heterogeneous environment, and with corresponding support through tightly co-optimized software stacks, close to peak efficiencies can be maintained across larger applications that utilize such linear algebra kernels.  All combined, results of this project have demonstrated that is possible to design domain-specific accelerators with orders-of-magnitude improved efficiency of full-custom hardware but enough flexibility to run any application across a range of related domains. In doing so, we have developed novel, integrated linear algebra compute fabrics that are co-optimized and co-designed across all layers ranging from the basic hardware foundations all the way to the application programming support through standard linear algebra software packages. Being able to provide hitherto infeasible, order of magnitude improved compute capabilities even in energy-constrained devices (such as small, embedded mobile or battery-operated systems) for this important domain of applications has the potential to solve many open problems that may significantly impact society in the future.       Last Modified: 07/27/2017       Submitted by: Andreas Gerstlauer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
