<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative proposal: A multimodal tactile sensor skin designed to reduce the cognitive burden on the user of a prosthetic hand</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>10/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>199998.00</AwardTotalIntnAmount>
<AwardAmount>199998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alex Leonessa</SignBlockName>
<PO_EMAI>aleoness@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>PI: Santos, Veronica J. and Posner, Jonathan D.&lt;br/&gt;Proposal Number: 1264444 &amp; 1264046&lt;br/&gt;&lt;br/&gt;Intellectual Merit: Whether a prosthetic hand is a simple body-powered hook or an advanced anthropomorphic device, it will only be useful and desirable to an amputee if it improves quality of life and is intuitive to control. A prosthesis will be rejected if it poses too great of a cognitive burden on the user. One way to simultaneously reduce the cognitive burden on the user and enhance the functionality of the user to focus on high-level commands as opposed to low-level details that may be frustrating to control or even impossible to control given the "language barrier" between human and machine because of different timescales and resolutions of control. Amputees could be empowered with prostheses having autonomous, local reflex algorithms akin to short latency grip reflexes observed in humans, and even suites of basic behavioral building blocks that are critical for activities of daily living. The only way for a semi-autonomous system to gain the trust of its operator is through reliable, context-dependent performance. Such context-aware performance will require information about forceful interactions between the prosthetic hand and everyday objects in unstructured environments that can only be obtained through touch. The great number and dynamic range of tactile mechanoreceptors in the human hand (17000 tactile sensors total, 2000 in each fingertip) highlight the importance of rich multimodal tactile feedback for grasp and dexterous manipulation. Unfortunately, many tactile sensor designs have focused on detection of normal forces alone, which are necessary but not sufficient for reliable artificial grasp. What is sorely needed is a multimodal tactile sensor that can detect additional important features of finger-object interactions such as shear force, vibration, and slip direction.  This proposal aims to strengthen the ability of an artificial hand to perform automated behaviors reliably by detecting, processing, and utilizing rich, real-time information about finger-object interactions with an innovative multimodal tactile sensor skin. This sensor system is transformative because it will reduce the cognitive burden on an amputee and will provide a foundation for paradigm-shifting advancements for automating complex behaviors by artificial hands and providing a conscious perception of touch through sensory feedback to the user. The long-term research objective of this proposal is to reduce the cognitive burden on the user of an upper extremity prosthesis. The following contributions to artificial hand systems are proposed: Research Goal 1) Design, model, fabricate, and test a flexible, multimodal tactile sensor skin system for artificial fingertips using a multilayer microfluidic architecture; Research Goal 2) Establish functional relationships between finger-object interactions and tactile sensor skin data for use in autonomous grip control algorithms; and Research Goal 3) Integrate the tactile sensor skin data into grip control algorithms and evaluate effectiveness for reducing the cognitive burden on prosthesis users.&lt;br/&gt;&lt;br/&gt;Broader Impacts: The proposed translational research could enhance the functional capabilities of artificial, robotic manipulators intended for unstructured, unsafe, or limited-access environments (prosthetic, rehabilitative, assistive, space, underwater, military, rescue, surgery). The proposed work could play a critical role in improving the quality of life for end-users of prosthetic and assistive devices. Specific benefits to end-users of prosthetic devices include: automation of complex prosthesis behaviors, rich artificial sensory feedback, and "smart socket liners" for monitoring user safety and comfort.&lt;br/&gt;&lt;br/&gt;Contributions to elementary school, undergraduate, and graduate-level education are proposed: Education Goal 1) Develop hands-on instructional modules for teaching elementary school students about sensors using low-cost materials, and deploy them locally for the benefit of students underrepresented in science, technology, engineering, and mathematics fields; Education Goal 2) Enhance undergraduate-level course titled Sensors and Controls and graduate-level course titled "Robotics" with a sensors module; and Education Goal 3) Promote interdisciplinary undergraduate research opportunities via internships related to the development, testing, and application of sensors.</AbstractNarration>
<MinAmdLetterDate>08/23/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/23/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1264444</AwardID>
<Investigator>
<FirstName>Veronica</FirstName>
<LastName>Santos</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Veronica J Santos</PI_FULL_NAME>
<EmailAddress>vjsantos@ucla.edu</EmailAddress>
<PI_PHON>3108252125</PI_PHON>
<NSF_ID>000521933</NSF_ID>
<StartDate>08/23/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<CountyName>MARICOPA</CountyName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2>660 South Mill Avenue, Suite 310</StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName/>
<CountyName>MARICOPA</CountyName>
<StateCode>AZ</StateCode>
<ZipCode>852876011</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5342</Code>
<Text>Disability &amp; Rehab Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>010E</Code>
<Text>DISABILITY RES &amp; HOMECARE TECH</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~24983</FUND_OBLG>
</Award>
</rootTag>
