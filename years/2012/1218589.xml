<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Supporting Next Generation Adaptive Multi-Lens Stereoscopic Video Streaming</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project investigates a coordinated adaptation and network streaming framework for next generation multi-lens stereoscopic video.  Future stereoscopic cameras may be made up of multiple (more than two) lenses to provide a denser sampling of viewpoints to ameliorate the mismatch between capture and viewing scenario dependent display, a problem that will grow as stereoscopic devices and displays become more ubiquitous.  With an appropriate streaming system, a much richer user experience can be delivered that is both network adaptive and reduces the negative side-effects of stereoscopic imaging such as 3D eye fatigue.  A multi-lens stereoscopic video framework will require the confluence of three interrelated components: compression and representation; retrieval, streaming and adaptation; and viewing scenario dependent optimization.  These three components will act together to provide a low-latency, viewing scenario optimized experience for stereoscopic imaging.  &lt;br/&gt;&lt;br/&gt;With this architecture in mind, this project will:&lt;br/&gt;* Investigate multi-lens compression technologies to support efficient retrieval and viewing scenario optimization. The compression of the multi-lens stereoscopic data needs to achieve high compression, but at the same time, be amenable to adaptation and subset retrieval. &lt;br/&gt;* Develop adaptive streaming techniques for the proposed retrieval-friendly compression format.  The key objective is to avoid introducing artifacts (due to the decreased quality) that make their way into the stereoscopic field.  This adaptation layer will be coordinated with a viewing scenario dependent optimization in order to retrieve the best data possible while also being network adaptive.&lt;br/&gt;* Develop viewing scenario dependent optimal display management technologies.  To maximize viewing experience and minimize negative side effects, viewing scenario dependent optimization will select a subset of images from the array to best match the viewing scenario. Novel view synthesis techniques may be used to help minimize the image data retrieved, yet provide good user experience.&lt;br/&gt;&lt;br/&gt;Broader Impact: Dynamically delivering optimized stereoscopic content according to the viewing scenario can reduce side effects such as 3D fatigue and headaches that people have from viewing stereoscopic content.  The threaded architecture can also be used for other multi-view systems (e.g., video sensor networks), where the display of video requires only a subset of the camera views to be delivered.  Finally, the results from the display management work can also be combined with eye tracking to enable free-view and free-glass stereo viewing experiences.</AbstractNarration>
<MinAmdLetterDate>08/06/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218589</AwardID>
<Investigator>
<FirstName>Wu-chi</FirstName>
<LastName>Feng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wu-chi Feng</PI_FULL_NAME>
<EmailAddress>wuchi@cs.pdx.edu</EmailAddress>
<PI_PHON>5037252408</PI_PHON>
<NSF_ID>000148092</NSF_ID>
<StartDate>08/06/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Feng</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Feng Liu</PI_FULL_NAME>
<EmailAddress>fliu@pdx.edu</EmailAddress>
<PI_PHON>5037253221</PI_PHON>
<NSF_ID>000580498</NSF_ID>
<StartDate>08/06/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Portland State University</Name>
<CityName>Portland</CityName>
<ZipCode>972070751</ZipCode>
<PhoneNumber>5037259900</PhoneNumber>
<StreetAddress>1600 SW 4th Ave</StreetAddress>
<StreetAddress2><![CDATA[Attn: Sponsored Projects Admin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052226800</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PORTLAND STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052226800</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Portland State University]]></Name>
<CityName>Portland</CityName>
<StateCode>OR</StateCode>
<ZipCode>972070751</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The purpose of this project was to investigate systems and computer vision techniques required for stereoscopic viewing of multi-lens video. While most stereoscopic cameras today employ only two camera lenses (to capture the right and left eye viewing experience), we believe that, in the future, an array of linearly spaced cameras will be used to capture video meant for stereoscopic or auto-stereoscopic display. By doing so, traditional stereoscopic issues such as &ldquo;3D fatigue&rdquo; can be addressed by properly matching the visual disparity between the right and left eyes for a variety of viewing scenarios (e.g., TV, handheld device, computer monitor, or 3D headset). The major goals of this project included (i) investigating multi-lens compression technologies to support efficient retrieval and viewing scenario optimization; (ii) developing adaptive streaming techniques for the proposed retrieval-friendly compression format; and (iii) developing viewing scenario-dependent optimal display management technologies.&nbsp;</p> <p>With respect to the compression technologies, we explored compression techniques for multi-lens stereoscopic video systems that are amenable for streaming. In particular, we focused on systems that have eight linearly aligned cameras and where the viewing scenario requires the streaming of two of the views (or four in the case of interpolated views). We have shown that existing multi-view video coding techniques that have been proposed, while good for streaming the entire set of videos, is not suitable for subset streaming. We have also shown the impact of compression on multi-view video through an objective measure of feature-point movement and tracking. &nbsp;As part of this project, we also discovered an issue with the motion estimation technique that is implemented in the H.264/MVC reference software. This has been reported to the authors and is expected to be fixed in newer versions.&nbsp;</p> <p>This project investigated a variety of problems with respect to viewing scenario-dependent optimal display management and developed computer vision and graphics technologies to support it. These technologies can be grouped into two categories: content analysis and content manipulation. For the former, we developed various visual saliency and quality analysis algorithms that can be used to inform both video content compression and manipulation. For the latter, we invented a range of stereoscopic content editing and authoring technologies that produce, improve and adapt stereoscopic content for various target viewing scenarios.</p><br> <p>            Last Modified: 02/07/2017<br>      Modified by: Wu-Chi&nbsp;Feng</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The purpose of this project was to investigate systems and computer vision techniques required for stereoscopic viewing of multi-lens video. While most stereoscopic cameras today employ only two camera lenses (to capture the right and left eye viewing experience), we believe that, in the future, an array of linearly spaced cameras will be used to capture video meant for stereoscopic or auto-stereoscopic display. By doing so, traditional stereoscopic issues such as "3D fatigue" can be addressed by properly matching the visual disparity between the right and left eyes for a variety of viewing scenarios (e.g., TV, handheld device, computer monitor, or 3D headset). The major goals of this project included (i) investigating multi-lens compression technologies to support efficient retrieval and viewing scenario optimization; (ii) developing adaptive streaming techniques for the proposed retrieval-friendly compression format; and (iii) developing viewing scenario-dependent optimal display management technologies.   With respect to the compression technologies, we explored compression techniques for multi-lens stereoscopic video systems that are amenable for streaming. In particular, we focused on systems that have eight linearly aligned cameras and where the viewing scenario requires the streaming of two of the views (or four in the case of interpolated views). We have shown that existing multi-view video coding techniques that have been proposed, while good for streaming the entire set of videos, is not suitable for subset streaming. We have also shown the impact of compression on multi-view video through an objective measure of feature-point movement and tracking.  As part of this project, we also discovered an issue with the motion estimation technique that is implemented in the H.264/MVC reference software. This has been reported to the authors and is expected to be fixed in newer versions.   This project investigated a variety of problems with respect to viewing scenario-dependent optimal display management and developed computer vision and graphics technologies to support it. These technologies can be grouped into two categories: content analysis and content manipulation. For the former, we developed various visual saliency and quality analysis algorithms that can be used to inform both video content compression and manipulation. For the latter, we invented a range of stereoscopic content editing and authoring technologies that produce, improve and adapt stereoscopic content for various target viewing scenarios.       Last Modified: 02/07/2017       Submitted by: Wu-Chi Feng]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
