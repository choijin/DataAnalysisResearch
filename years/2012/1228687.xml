<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TWC: Medium: Collaborative Proposal: Policy Compliant Integration of Linked Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ubiquity of computing technology and the Internet have created an age of big data that has the potential to greatly enhance the efficiency of our societies and the well-being of all people. The trend comes with problems that threaten to prevent or undermine the benefits. An immediate concern is how to fuse, integrate and analyze data while respecting privacy, security and usage concerns. A second issue is allowing data to remain distributed, enabling its owners to maintain and control quality as well as to enforce security and privacy policies. A final underlying challenge is helping to produce sound and useful results by assuring that systems understand the meaning of the data being integrated and analyzing access and usage policies. For some domains, like health informatics and clinical research, solving these problems will have a significant impact on society.&lt;br/&gt;&lt;br/&gt;This project explores an approach to solving these problems by developing a policy-compliant integration system for linked healthcare data. The system models data, schemas and policies using open Web standards such as Semantic Web languages, federates queries to independent Linked Data stores based on content, provides policy enforcement by modifying incompliant queries, and uses formal methods to guarantee correctness of key components.&lt;br/&gt;&lt;br/&gt;This project provides new approaches to solving one of the most significant problems our society faces in the 21st century: benefiting from the integration of distributed linked data while respecting security, privacy, and usage requirements. The prototype tools and systems are incorporated into our educational activities and made available to others via appropriate open source licenses.</AbstractNarration>
<MinAmdLetterDate>08/13/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1228687</AwardID>
<Investigator>
<FirstName>Harold</FirstName>
<LastName>Abelson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Harold Abelson</PI_FULL_NAME>
<EmailAddress>HAL@MIT.EDU</EmailAddress>
<PI_PHON>6172535856</PI_PHON>
<NSF_ID>000191572</NSF_ID>
<StartDate>08/13/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lalana</FirstName>
<LastName>Kagal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lalana Kagal</PI_FULL_NAME>
<EmailAddress>lkagal@csail.mit.edu</EmailAddress>
<PI_PHON>6172531000</PI_PHON>
<NSF_ID>000502700</NSF_ID>
<StartDate>08/13/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-77e31f67-edd3-7dee-be04-3fdde7705796"> <span id="docs-internal-guid-77e31f67-edd4-e81d-4453-f05739d292fe"> </span></span></p> <p><span id="docs-internal-guid-77e31f67-edd5-bda3-ed03-8821602758fd"> </span></p> <p><span id="docs-internal-guid-77e31f67-ede2-1944-d5cd-0dafbd2c6a1a"> </span></p> <p><span id="docs-internal-guid-77e31f67-ede7-0848-06f0-ffbc26733443"> </span></p> <p dir="ltr"><span>Sensitive data about individuals is constantly being collected, analyzed, and stored by organizations for a variety of purposes: shopping sites to provide better recommendations, hospitals for improved healthcare, government agencies for national defense and law enforcement, and quantified self applications to track your health and wellbeing. &nbsp;With the recent government focus on &ldquo;transparency&rdquo; and &ldquo;openness&rdquo;, more and more government data is also being made available online. Integrating and fusing data across these datasets enables us to discover important knowledge about public safety, anti-terrorism, medical research and healthcare delivery. However, it also raises serious concerns about information privacy and trust. Even though access control mechanisms are often successful in managing access to data, they are ineffective in preventing information leakages or inappropriate uses of data. Our project explored the use of expressive policies, privacy preserving architectures, and accountability mechanisms to provide privacy-aware access, integration and analysis of sensitive data within and across organizations. We investigated challenges to accessing, integrating, and analyzing data while respecting privacy, security and usage policies in different domains and platforms including the Web, mobile, cloud, social, and healthcare.</span></p> <p dir="ltr"><span>We studied privacy protection on the Web with respect to social data as well as creative work. To improve privacy of social networking data, we augmented existing access controls with content-based policies, and developed a framework that enables users to specify the content that they wish to protect in the form of tags or keywords. Our framework enhances the provided terms with other meaningful and related concepts using Linked Open Data.We also designed several tools to support appropriate use of data on the Web, and a protocol called HTTP with Accountability (HTTPA) to provide an end-to-end accountability infrastructure that can be used to determine appropriate use of data. &nbsp;The tools and the end-to-end HTTPA protocol provide an architecture for building Web-based accountable systems. These accountable systems enable data consumers and data producers to agree to specific usage restrictions, preserve the provenance of data, and provide auditing to the data subject.</span></p> <p dir="ltr"><span>We extended our work in privacy policy specification and reasoning to smartphones. Smartphones collect a wide range of sensor data, ranging from the basic, such as location, accelerometer, and Bluetooth, to the more advanced, such as heart rate. MIT Living Lab platform is a mobile app development platform that provides MIT users with personal data stores but lacked user controls for privacy. We developed PrivacyMate, a suite of tools that enables users to have better control over their mobile personal data. It allows users to select or deselect various types of data for collection and use by apps. Users can also provide temporal and spatial specifications to indicate a context in which they are comfortable sharing their data with certain apps. We also studied the usability and effectiveness of privacy policies provided by mobile apps. This led us to develop PrivacyInformer, which automatically generates mobile app privacy descriptions, thereby relieving developers of the burden of manually creating them. This tool is implemented as an extension to the MIT App Inventor, a do-it-yourself mobile app building platform that has a vast global user base. By analyzing source code of mobile apps directly in App Inventor, PrivacyInformer can produce simple and useful privacy descriptions in both human-readable and machine-readable format. </span></p> <p dir="ltr"><span>Another area we looked into was the privacy awareness and fairness of algorithmic decision making. Currently, predictive models have become widely deployed in determining access to services like credit, insurance, housing, employment, and others that are essential for livelihood. Despite the tremendous gains that come with using these models, these models are susceptible to increasing discrimination on the basis of race, gender, religion, or other immutable characteristics. We developed a technical framework, FairML, for evaluating algorithms that would allow policy makers to quickly assess the whether predictive models are biased with respect to sensitive data. FairML leverages model compression and four input ranking algorithms to quantify a model&rsquo;s relative predictive dependence on its inputs. With FairML, analysts can more easily audit cumbersome predictive models that are difficult to interpret.</span></p> <p dir="ltr"><span>As part of this project, we also developed privacy preserving middleware for Big Data. Enterprises usually provide strong controls to prevent external cyberattacks. However, in the case where employees and data scientists have legitimate access to analyze and derive insights from the data, there are insufficient controls. Though it is important to be able to identify useful patterns of one's customers for better customization and service, customers' privacy must not be sacrificed to do so. We propose a framework that will allow privacy preserving data analytics over big data. We developed an efficient and scalable differential privacy framework for Apache Spark, a cluster computing framework, that provides strong privacy guarantees for users even in the presence of an informed adversary, while still providing high utility for analysts.</span></p><br> <p>            Last Modified: 10/05/2017<br>      Modified by: Lalana&nbsp;Kagal</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[             Sensitive data about individuals is constantly being collected, analyzed, and stored by organizations for a variety of purposes: shopping sites to provide better recommendations, hospitals for improved healthcare, government agencies for national defense and law enforcement, and quantified self applications to track your health and wellbeing.  With the recent government focus on "transparency" and "openness", more and more government data is also being made available online. Integrating and fusing data across these datasets enables us to discover important knowledge about public safety, anti-terrorism, medical research and healthcare delivery. However, it also raises serious concerns about information privacy and trust. Even though access control mechanisms are often successful in managing access to data, they are ineffective in preventing information leakages or inappropriate uses of data. Our project explored the use of expressive policies, privacy preserving architectures, and accountability mechanisms to provide privacy-aware access, integration and analysis of sensitive data within and across organizations. We investigated challenges to accessing, integrating, and analyzing data while respecting privacy, security and usage policies in different domains and platforms including the Web, mobile, cloud, social, and healthcare. We studied privacy protection on the Web with respect to social data as well as creative work. To improve privacy of social networking data, we augmented existing access controls with content-based policies, and developed a framework that enables users to specify the content that they wish to protect in the form of tags or keywords. Our framework enhances the provided terms with other meaningful and related concepts using Linked Open Data.We also designed several tools to support appropriate use of data on the Web, and a protocol called HTTP with Accountability (HTTPA) to provide an end-to-end accountability infrastructure that can be used to determine appropriate use of data.  The tools and the end-to-end HTTPA protocol provide an architecture for building Web-based accountable systems. These accountable systems enable data consumers and data producers to agree to specific usage restrictions, preserve the provenance of data, and provide auditing to the data subject. We extended our work in privacy policy specification and reasoning to smartphones. Smartphones collect a wide range of sensor data, ranging from the basic, such as location, accelerometer, and Bluetooth, to the more advanced, such as heart rate. MIT Living Lab platform is a mobile app development platform that provides MIT users with personal data stores but lacked user controls for privacy. We developed PrivacyMate, a suite of tools that enables users to have better control over their mobile personal data. It allows users to select or deselect various types of data for collection and use by apps. Users can also provide temporal and spatial specifications to indicate a context in which they are comfortable sharing their data with certain apps. We also studied the usability and effectiveness of privacy policies provided by mobile apps. This led us to develop PrivacyInformer, which automatically generates mobile app privacy descriptions, thereby relieving developers of the burden of manually creating them. This tool is implemented as an extension to the MIT App Inventor, a do-it-yourself mobile app building platform that has a vast global user base. By analyzing source code of mobile apps directly in App Inventor, PrivacyInformer can produce simple and useful privacy descriptions in both human-readable and machine-readable format.  Another area we looked into was the privacy awareness and fairness of algorithmic decision making. Currently, predictive models have become widely deployed in determining access to services like credit, insurance, housing, employment, and others that are essential for livelihood. Despite the tremendous gains that come with using these models, these models are susceptible to increasing discrimination on the basis of race, gender, religion, or other immutable characteristics. We developed a technical framework, FairML, for evaluating algorithms that would allow policy makers to quickly assess the whether predictive models are biased with respect to sensitive data. FairML leverages model compression and four input ranking algorithms to quantify a model?s relative predictive dependence on its inputs. With FairML, analysts can more easily audit cumbersome predictive models that are difficult to interpret. As part of this project, we also developed privacy preserving middleware for Big Data. Enterprises usually provide strong controls to prevent external cyberattacks. However, in the case where employees and data scientists have legitimate access to analyze and derive insights from the data, there are insufficient controls. Though it is important to be able to identify useful patterns of one's customers for better customization and service, customers' privacy must not be sacrificed to do so. We propose a framework that will allow privacy preserving data analytics over big data. We developed an efficient and scalable differential privacy framework for Apache Spark, a cluster computing framework, that provides strong privacy guarantees for users even in the presence of an informed adversary, while still providing high utility for analysts.       Last Modified: 10/05/2017       Submitted by: Lalana Kagal]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
