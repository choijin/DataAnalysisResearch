<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Direct 3D Manipulation for Computer Aided Design</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>149735.00</AwardTotalIntnAmount>
<AwardAmount>179682</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project aims to demonstrate the feasibility of a 3D gestural user input system for computer aided design (CAD) that enables engineering design firms to more rapidly explore and produce new designs.  This technology uses commodity depth-sensing cameras and applies computer vision algorithms to deliver markerless finger-precise hand-tracking, allowing users to simply reach out with their hands to directly manipulate virtual 3D objects.  In order to confirm feasibility, the objectives of the project include data gathering, investigation of computer vision algorithms, investigation of 3D input usability issues, and a thorough technical and usability evaluation.  More specifically, a data set of 3D scans of hand shapes and hand poses will be collected.  Next, a detailed investigation will be performed of multi-view registration and database-driven hand pose estimation algorithms for rapid calibration and tracking of a user's hands.  The success of the proposed technology will crucially depend on its delivery of a superior user experience, and the usability issues regarding 3D input will be carefully analyzed.  Finally, a detailed technical and usability evaluation will be performed, and the commercial viability will be based on the results.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project is in the area of engineering design.  In today's market place, the competitive capacity of an engineering firm is determined by its ability to rapidly design new products and evaluate new engineering solutions.  Most engineering design firms use computer aided design software to accelerate this process.  However, the productivity of CAD engineers is still bottlenecked by the user interface and the user input devices available to them.  This is because many CAD tasks involve 3D manipulation, which is difficult and tedious to perform with a 2D mouse.   A typical CAD user spends four to eight hours a day in CAD software. Over a million CAD users fit this profile.  The proposed technology makes these users more productive by enabling them to directly manipulate virtual CAD objects with their bare hands in 3D, at their desks---a technical feat that has never before been achieved.  The result is faster product and engineering design in a variety of industries including manufacturing, construction and architecture which spent $6B on CAD software in 2011.  This research will advance scientific and technological understanding by creating a fundamentally new way to interact with computers for productivity applications.</AbstractNarration>
<MinAmdLetterDate>06/13/2012</MinAmdLetterDate>
<MaxAmdLetterDate>02/20/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1215109</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert Wang</PI_FULL_NAME>
<EmailAddress>rywang@threegear.com</EmailAddress>
<PI_PHON>4128605468</PI_PHON>
<NSF_ID>000609314</NSF_ID>
<StartDate>06/13/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>3Gear Systems</Name>
<CityName>Foster City</CityName>
<ZipCode>944041745</ZipCode>
<PhoneNumber>4128605468</PhoneNumber>
<StreetAddress>1110 Polynesia Dr #314</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA14</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078301620</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>3GEAR SYSTEMS, INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[3Gear Systems]]></Name>
<CityName>Foster City</CityName>
<StateCode>CA</StateCode>
<ZipCode>944041745</ZipCode>
<StreetAddress><![CDATA[1110 Polynesia Dr #314]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA14</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~149735</FUND_OBLG>
<FUND_OBLG>2013~29947</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br />We have developed technology that enables rich gestural interaction with a computer much like the futuristic interfaces shown in the movies "Minority Report" and "Iron man." &nbsp;Our technology begins with finger-precise tracking of the user's hands with a commodity depth sensing camera (such as the Microsoft Kinect). &nbsp;Finger and hand motions are then interpreted as gestures which can in turn drive actions in different computer applications.<br />We developed the hand-tracking and gestural recognition algorithms with two specific applications in mind: 3D manipulation for computer aided design (CAD) and navigating medical images in the sterile field of a medical operating room.</p> <p>Computer aided design (CAD) plays a crucial role in mechanical engineering, industrial design, architecture and construction. &nbsp;Practically any new product that is mass-produced is first designed in 3D in CAD software. &nbsp;Our technology enables versatile 3D manipulation for CAD. &nbsp;Using our technology, a CAD engineer can literally grab virtual objects and place them in a 3D design space. &nbsp;This accelerates the design process for the one million users who spendan average of 6 hours each day in CAD design.</p> <p>Image-guided surgery is now an integral part of modern surgery. &nbsp;Before almost any major surgical operation, the patient is imaged through x-ray or magentic resonance. &nbsp;These CT / MRI scans are then used to plan and guide the surgery, serving as a detailed map for the operation. &nbsp;Our technology enables surgeons to directly manipulate this map in a sterile operating room without touching a mouse, keyboard or a touchscreen. &nbsp;The result is faster, more efficient access to critical medical information without the risk of contamination.</p> <p>During the NSF SBIR Phase I effort, we succeeded in developing a finger-precise hand-tracking technology. &nbsp;We developed a system that tracks the hands with spatial precision of under 1mm and angular precision of one degree. &nbsp;We have made the technology free to academics as well as to individuals for commercial use. &nbsp;We now have more than 350 licensees across the world and several paying customers. &nbsp;In addition, we are working with two of our users / clients in pilot studies to deploy the technology in a hospital. &nbsp;We are also continuing to develop a CAD plugin with the help of SolidWorks, one of the leading providers of CAD software in the United States. &nbsp;In the Phase IB effort, we reduced the hardware requirements of our technology to a single depth sensing camera (from two) while also improving the fidelity of index-finger tracking.</p> <p>In the next year, our goal is to work with several of our partners to embed our technology into a variety of products, including a medical device, a car, and a PC.</p><br> <p>            Last Modified: 08/01/2013<br>      Modified by: Robert&nbsp;Wang</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2013/1215109/1215109_10181175_1375397124224_kenrickhands--rgov-214x142.jpg" original="/por/images/Reports/POR/2013/1215109/1215109_10181175_1375397124224_kenrickhands--rgov-800width.jpg" title="Precise hand-tracking"><img src="/por/images/Reports/POR/2013/1215109/1215109_10181175_1375397124224_kenrickhands--rgov-66x44.jpg" alt="Precise hand-tracking"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our technology enables finger-precis...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  We have developed technology that enables rich gestural interaction with a computer much like the futuristic interfaces shown in the movies "Minority Report" and "Iron man."  Our technology begins with finger-precise tracking of the user's hands with a commodity depth sensing camera (such as the Microsoft Kinect).  Finger and hand motions are then interpreted as gestures which can in turn drive actions in different computer applications. We developed the hand-tracking and gestural recognition algorithms with two specific applications in mind: 3D manipulation for computer aided design (CAD) and navigating medical images in the sterile field of a medical operating room.  Computer aided design (CAD) plays a crucial role in mechanical engineering, industrial design, architecture and construction.  Practically any new product that is mass-produced is first designed in 3D in CAD software.  Our technology enables versatile 3D manipulation for CAD.  Using our technology, a CAD engineer can literally grab virtual objects and place them in a 3D design space.  This accelerates the design process for the one million users who spendan average of 6 hours each day in CAD design.  Image-guided surgery is now an integral part of modern surgery.  Before almost any major surgical operation, the patient is imaged through x-ray or magentic resonance.  These CT / MRI scans are then used to plan and guide the surgery, serving as a detailed map for the operation.  Our technology enables surgeons to directly manipulate this map in a sterile operating room without touching a mouse, keyboard or a touchscreen.  The result is faster, more efficient access to critical medical information without the risk of contamination.  During the NSF SBIR Phase I effort, we succeeded in developing a finger-precise hand-tracking technology.  We developed a system that tracks the hands with spatial precision of under 1mm and angular precision of one degree.  We have made the technology free to academics as well as to individuals for commercial use.  We now have more than 350 licensees across the world and several paying customers.  In addition, we are working with two of our users / clients in pilot studies to deploy the technology in a hospital.  We are also continuing to develop a CAD plugin with the help of SolidWorks, one of the leading providers of CAD software in the United States.  In the Phase IB effort, we reduced the hardware requirements of our technology to a single depth sensing camera (from two) while also improving the fidelity of index-finger tracking.  In the next year, our goal is to work with several of our partners to embed our technology into a variety of products, including a medical device, a car, and a PC.       Last Modified: 08/01/2013       Submitted by: Robert Wang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
