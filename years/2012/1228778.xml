<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI: Acquisition of Hybrid CPU/GPU Nodes for the Interdisciplinary UMBC High Performance Computing Facility</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita Rodriguez</SignBlockName>
<PO_EMAI>rrodrigu@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Proposal #: 12-28778&lt;br/&gt;PI(s):  Matthias K Gobbert; Erill, Ivan; Olano, Thomas M; Sparling, Lynn; Thorpe, Ian&lt;br/&gt;Institution: University of Maryland Baltimore County&lt;br/&gt;Title:   MRI/Acq.:  Hybrid CPU/GPU Nodes for the Interdisciplinary UMBC High Performance Computing Facility          &lt;br/&gt;Project Proposed:&lt;br/&gt;&lt;br/&gt;This project, acquiring an instrument based on advanced GPU/CPU computers with 360 TB high-performance storage and high-speed communication links, aims to enhance the current UMBC High Performance Computing Facility. The instrument enables research in emerging data-intensive high-performance computing topics. This multi-disciplinary and collaborative project involves faculty and students from biology, chemistry, computer science and engineering, electrical engineering, environmental systems, mathematics, physics, and statistics. &lt;br/&gt;The following current, as well as new research projects, benefit immediately from the availability of the enhanced high-performance computing instrument:&lt;br/&gt;- Parallel Algorithms for Numerical Simulations of Partial Differential Equations; &lt;br/&gt;- Application of GPU Processing to Atmospheric Chemistry and Dynamics Modeling;&lt;br/&gt;- Atmospheric Remote Sensing; etc.&lt;br/&gt;&lt;br/&gt;Broader Impacts:&lt;br/&gt;&lt;br/&gt;Research and educational initiatives should be highly impacted by the research enabled through the instrument. The research team, including female faculty members, has interactions with the Women in Science and Engineering (WISE) organization and the Center for Women in Technology (CWIT). Undergraduate students will be involved in the UMBC REU site on high performance computing. Furthermore, the instrumentation should contribute to attract students from under-represented groups into sciences. Presented are plans and initiatives to do so.</AbstractNarration>
<MinAmdLetterDate>09/04/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/04/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1228778</AwardID>
<Investigator>
<FirstName>Matthias</FirstName>
<LastName>Gobbert</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthias K Gobbert</PI_FULL_NAME>
<EmailAddress>gobbert@umbc.edu</EmailAddress>
<PI_PHON>4104552404</PI_PHON>
<NSF_ID>000485133</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Olano</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marc Olano</PI_FULL_NAME>
<EmailAddress>olano@csee.umbc.edu</EmailAddress>
<PI_PHON>4104553094</PI_PHON>
<NSF_ID>000233938</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lynn</FirstName>
<LastName>Sparling</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lynn Sparling</PI_FULL_NAME>
<EmailAddress>sparling@umbc.edu</EmailAddress>
<PI_PHON>4104556231</PI_PHON>
<NSF_ID>000067895</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ivan</FirstName>
<LastName>Erill</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ivan Erill</PI_FULL_NAME>
<EmailAddress>erill@umbc.edu</EmailAddress>
<PI_PHON>4104552470</PI_PHON>
<NSF_ID>000536736</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ian</FirstName>
<LastName>Thorpe</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ian Thorpe</PI_FULL_NAME>
<EmailAddress>ithorpe@umbc.edu</EmailAddress>
<PI_PHON>4104555728</PI_PHON>
<NSF_ID>000584984</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland Baltimore County</Name>
<CityName>Baltimore</CityName>
<ZipCode>212500002</ZipCode>
<PhoneNumber>4104553140</PhoneNumber>
<StreetAddress>1000 Hilltop Circle</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>061364808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND BALTIMORE COUNTY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland Baltimore County]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212500002</ZipCode>
<StreetAddress><![CDATA[1000 Hilltop Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The UMBC High Performance Computing Facility (HPCF) is the community-based, interdisciplinary core facility for scientific computing and research on parallel algorithms at UMBC. This MRI grant to a group of 30 researchers from ten academic departments and research centers has been instrumental in fostering a true campus culture of computing. Since HPCF's inception in 2008, over 400 users have profited from its computing clusters, including undergraduate and graduate student. In one month alone, the system had active use by about 30 research groups with over 100 users. In total since 2008, the users generated over 200 publications, including 77 papers in peer-reviewed journals (including Nature, Science, and other top-tier journals in their fields), 24 refereed conference papers, and 28 theses. <br /><br />This grant from the NSF funded the extension for about $500k in 2013 by 72 nodes with two eight-core Intel E5-2650v2 Ivy Bridge CPUs and 64 GB memory that include 19 hybrid nodes with two high-end NVIDIA K20 GPUs (graphics processing units) designed for scientific computing and 19 hybrid nodes with two cutting-edge 60-core Intel Phi 5110P accelerators. All nodes are connected via wide-bandwidth, low-latency InfiniBand interconnect to a central storage of more than 750 TB. Together with UMBC and other faculty contributions and a significant gift of compute nodes from NASA, the total system is now valued at over $1.5M.<br /><br />The system administration for HPCF is provided by the UMBC Division of Information Technology, leading to valuable significant job training for its staff. HPCF users have access to consulting support provided by dedicated full-time graduate assistants funded by UMBC. See hpcf.umbc.edu for detailed information on HPCF, extensive usage instructions, and lists of projects and publications. The following research snippets show the wide range of impact of HPCF enabled by this MRI funding.</p> <p>1. The REU (Research Experiences for Undergraduates) Site: Interdisciplinary Program in High Performance Computing (hpcreu.umbc.edu) in the Department of Mathematics and Statistics is a workforce development program funded by NSF, NSA, and DOD that trains participants in scientific, statistical, and parallel computing and engages them in research teams working on interdisciplinary projects. From its inception in 2010, it has trained 105 participants, including 28 African Americans, 14 Asians, 1 Native American, and 13 Hispanics, as well as 3 students with disabilities and 3 military veterans. The program has leveraged its direct federal funding of over $1.3M through a partnership with UMBC's renowned Meyerhoff Scholars Program (meyerhoff.umbc.edu). This program has to its credit three students who have been awarded NSF Graduate Research Fellowships.<br /><br />2. Dr. Zana Coulibaly (Ph.D. August 2015, now post-doc at UC Davis) and Dr. Bradford E. Peercy, Department of Mathematics and Statistics, achieved spontaneous spiral-shaped calcium waves in a heart cell for the first time with a model with discrete point sources in long-time simulations. Sophisticated parallel code makes adding more biophysical realism now feasible.<br /><br />3. The new state-of-the-art hybrid nodes with GPUs and Intel Phi accelerators has enabled new research and education focusing on modern computing paradigms. Dr. Xuan Huang (Ph.D. May 2015, advisor Dr. Matthias K. Gobbert, now at the MathWorks, Inc.) showed speedup using massively parallel GPUs, while simultaneously decreasing energy consumption and cooling requirements. Ph.D. candidate Samuel Khuvis (Ph.D. May 2016 anticipated, advisor Dr.&nbsp; Matthias K. Gobbert) is researching the capabilities of many-core Intel Phi accelerators for real-life algorithms.</p> <p>4. Dr. Meilin Yu from the Department of Mechanical Engineering has been using HPCF for high-fidelity computational fluid dynamics (CFD) simulation of challenging unsteady aerodynamic problems. HPCF's large number of cores enabled the simulation of the laminar-turbulent transition flow over an NACA0012 wing at different Reynolds numbers with an in-house high-order accurate large eddy simulation (LES) flow solver that is parallelized using the Message Passing Interface (MPI).<br /><br />5. Ryan Zuber and Dan Bailey from the Imaging Research Center (irc.umbc.edu) used HPCF to render a series of 3D animations depicting an anatomically correct whooping crane skeleton in motion for a film by Cathy Cook in the Visual Arts Department entitled Prehistoric Resurrection. The film visually connects prehistoric references to crane survival and longevity through the beauty of movement and the tools of technology. The cluster in HPCF made feasible the rendering of 6,986 frames at full HD resolution with 32 bit color depth (high dynamic range) for a total of 7,243,084,800 pixels rendered for the movie.<br /><br />6. The group of Dr. Jerimy Polf at the University of Maryland School of Medicine, in collaboration with UMBC, used HPCF to reconstruct computationally the world's first 3D image of the prompt gamma rays emitted during irradiation of water with a clinical proton therapy beam. Using this as preliminary data, that group were just awarded an R01 grant from the NIH to develop this technology into a clinically usable imaging system to be used to help verify and improve the precision of proton beam radiotherapy.</p><br> <p>            Last Modified: 10/29/2015<br>      Modified by: Matthias&nbsp;K&nbsp;Gobbert</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155412278_Image1_REU_ALL--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155412278_Image1_REU_ALL--rgov-800width.jpg" title="2015 group photo of REU Site participants"><img src="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155412278_Image1_REU_ALL--rgov-66x44.jpg" alt="2015 group photo of REU Site participants"></a> <div class="imageCaptionContainer"> <div class="imageCaption">2015 group photo of all 33 participants in the REU Site: Interdisciplinary Program in High Performance Computing with graduate assistants, faculty mentors, and project clients after poster and oral presentations at the UMBC Summer Undergraduate Research Fest (surf.umbc.edu).</div> <div class="imageCredit">Matthias K. Gobbert</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">2015 group photo of REU Site participants</div> </div> </li> <li> <a href="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155500668_Image2_spMaya-figure0_crop--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155500668_Image2_spMaya-figure0_crop--rgov-800width.jpg" title="Discrete calcium release sites within a model 3-D cardiac cell"><img src="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155500668_Image2_spMaya-figure0_crop--rgov-66x44.jpg" alt="Discrete calcium release sites within a model 3-D cardiac cell"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Discrete calcium release sites within a model 3-D cardiac cell support spontaneous generation of spiral waves. Calcium (green) propagates in a fire-diffuse-fire mechanism requiring a sophisticated parallel algorithm to simulate 1 second of real time within tens of minutes.</div> <div class="imageCredit">Zana Coulibaly</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Discrete calcium release sites within a model 3-D cardiac cell</div> </div> </li> <li> <a href="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155607169_Image3_GobbertHPCFslide16_fine--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155607169_Image3_GobbertHPCFslide16_fine--rgov-800width.jpg" title="Simulation times of calcium wave code"><img src="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155607169_Image3_GobbertHPCFslide16_fine--rgov-66x44.jpg" alt="Simulation times of calcium wave code"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Simulation times in hours:minutes:seconds (in parentheses: relative speedup over 1 node / 16 core run) of calcium wave code for three mesh sizes of the 3-D domain, demonstrating that for larger meshes run times with GPUs are much faster than using CPUs only.</div> <div class="imageCredit">Xuan Huang</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Simulation times of calcium wave code</div> </div> </li> <li> <a href="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155707151_Image4_Q_Re5e4_AoA8--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155707151_Image4_Q_Re5e4_AoA8--rgov-800width.jpg" title="Flow field of laminar-turbulent transition over a NACA0012 wing"><img src="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155707151_Image4_Q_Re5e4_AoA8--rgov-66x44.jpg" alt="Flow field of laminar-turbulent transition over a NACA0012 wing"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Flow field from LES of laminar-turbulent transition over a NACA0012 wing at Reynolds number 50,000. The angle of attack (AoA) is 8 degrees. Vortex structures are indicated by the Q-criterion colored with streamwise velocity.</div> <div class="imageCredit">Meilin Yu</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Flow field of laminar-turbulent transition over a NACA0012 wing</div> </div> </li> <li> <a href="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155781456_Image5_PrehistoricResurrection_Image02--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155781456_Image5_PrehistoricResurrection_Image02--rgov-800width.jpg" title="Animation of an anatomically correct whooping crane skeleton"><img src="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155781456_Image5_PrehistoricResurrection_Image02--rgov-66x44.jpg" alt="Animation of an anatomically correct whooping crane skeleton"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Animation of an anatomically correct whooping crane skeleton with realistic light reflections from surface to surface, in particular to the underside of the skeleton.</div> <div class="imageCredit">Ryan Zuber</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Animation of an anatomically correct whooping crane skeleton</div> </div> </li> <li> <a href="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155869169_Image6_datageneratedwithMayafromUMSOMuser--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155869169_Image6_datageneratedwithMayafromUMSOMuser--rgov-800width.jpg" title="3D images and 2D central axis profiles of proton beam radiotherapy"><img src="/por/images/Reports/POR/2015/1228778/1228778_10210905_1446155869169_Image6_datageneratedwithMayafromUMSOMuser--rgov-66x44.jpg" alt="3D images and 2D central axis profiles of proton beam radiotherapy"></a> <div class="imageCaptionContainer"> <div class="imageCaption">3D images and 2D central axis profiles with distal 90% beam range (dashed red line) of a dose of proton beam radiotherapy delivered by a 150 MeV pencil beam, (a) and (c) calculated by a treatment planning system and (b) and (d) reconstructed by computation from data.</div> <div class="imageCredit">Jerimy Polf</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">3D images and 2D central axis profiles of proton beam radiotherapy</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The UMBC High Performance Computing Facility (HPCF) is the community-based, interdisciplinary core facility for scientific computing and research on parallel algorithms at UMBC. This MRI grant to a group of 30 researchers from ten academic departments and research centers has been instrumental in fostering a true campus culture of computing. Since HPCF's inception in 2008, over 400 users have profited from its computing clusters, including undergraduate and graduate student. In one month alone, the system had active use by about 30 research groups with over 100 users. In total since 2008, the users generated over 200 publications, including 77 papers in peer-reviewed journals (including Nature, Science, and other top-tier journals in their fields), 24 refereed conference papers, and 28 theses.   This grant from the NSF funded the extension for about $500k in 2013 by 72 nodes with two eight-core Intel E5-2650v2 Ivy Bridge CPUs and 64 GB memory that include 19 hybrid nodes with two high-end NVIDIA K20 GPUs (graphics processing units) designed for scientific computing and 19 hybrid nodes with two cutting-edge 60-core Intel Phi 5110P accelerators. All nodes are connected via wide-bandwidth, low-latency InfiniBand interconnect to a central storage of more than 750 TB. Together with UMBC and other faculty contributions and a significant gift of compute nodes from NASA, the total system is now valued at over $1.5M.  The system administration for HPCF is provided by the UMBC Division of Information Technology, leading to valuable significant job training for its staff. HPCF users have access to consulting support provided by dedicated full-time graduate assistants funded by UMBC. See hpcf.umbc.edu for detailed information on HPCF, extensive usage instructions, and lists of projects and publications. The following research snippets show the wide range of impact of HPCF enabled by this MRI funding.  1. The REU (Research Experiences for Undergraduates) Site: Interdisciplinary Program in High Performance Computing (hpcreu.umbc.edu) in the Department of Mathematics and Statistics is a workforce development program funded by NSF, NSA, and DOD that trains participants in scientific, statistical, and parallel computing and engages them in research teams working on interdisciplinary projects. From its inception in 2010, it has trained 105 participants, including 28 African Americans, 14 Asians, 1 Native American, and 13 Hispanics, as well as 3 students with disabilities and 3 military veterans. The program has leveraged its direct federal funding of over $1.3M through a partnership with UMBC's renowned Meyerhoff Scholars Program (meyerhoff.umbc.edu). This program has to its credit three students who have been awarded NSF Graduate Research Fellowships.  2. Dr. Zana Coulibaly (Ph.D. August 2015, now post-doc at UC Davis) and Dr. Bradford E. Peercy, Department of Mathematics and Statistics, achieved spontaneous spiral-shaped calcium waves in a heart cell for the first time with a model with discrete point sources in long-time simulations. Sophisticated parallel code makes adding more biophysical realism now feasible.  3. The new state-of-the-art hybrid nodes with GPUs and Intel Phi accelerators has enabled new research and education focusing on modern computing paradigms. Dr. Xuan Huang (Ph.D. May 2015, advisor Dr. Matthias K. Gobbert, now at the MathWorks, Inc.) showed speedup using massively parallel GPUs, while simultaneously decreasing energy consumption and cooling requirements. Ph.D. candidate Samuel Khuvis (Ph.D. May 2016 anticipated, advisor Dr.  Matthias K. Gobbert) is researching the capabilities of many-core Intel Phi accelerators for real-life algorithms.  4. Dr. Meilin Yu from the Department of Mechanical Engineering has been using HPCF for high-fidelity computational fluid dynamics (CFD) simulation of challenging unsteady aerodynamic problems. HPCF's large number of cores enabled the simulation of the laminar-turbulent transition flow over an NACA0012 wing at different Reynolds numbers with an in-house high-order accurate large eddy simulation (LES) flow solver that is parallelized using the Message Passing Interface (MPI).  5. Ryan Zuber and Dan Bailey from the Imaging Research Center (irc.umbc.edu) used HPCF to render a series of 3D animations depicting an anatomically correct whooping crane skeleton in motion for a film by Cathy Cook in the Visual Arts Department entitled Prehistoric Resurrection. The film visually connects prehistoric references to crane survival and longevity through the beauty of movement and the tools of technology. The cluster in HPCF made feasible the rendering of 6,986 frames at full HD resolution with 32 bit color depth (high dynamic range) for a total of 7,243,084,800 pixels rendered for the movie.  6. The group of Dr. Jerimy Polf at the University of Maryland School of Medicine, in collaboration with UMBC, used HPCF to reconstruct computationally the world's first 3D image of the prompt gamma rays emitted during irradiation of water with a clinical proton therapy beam. Using this as preliminary data, that group were just awarded an R01 grant from the NIH to develop this technology into a clinically usable imaging system to be used to help verify and improve the precision of proton beam radiotherapy.       Last Modified: 10/29/2015       Submitted by: Matthias K Gobbert]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
