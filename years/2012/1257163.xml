<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Smart Space-Time Sampling for Recovering and Recognizing Dynamic Scenes</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>91512.00</AwardTotalIntnAmount>
<AwardAmount>91512</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Traditional, dynamic scenes are captured as video frames sampled at regular space-time grids. For many computer vision tasks, however, this uniform sampling may be either inefficient (e.g., low light, high-speed motion) or unnecessary (e.g., motion/change/event detection). This project explores non-uniform, adaptive sampling schemes that exploit the underlying structures of space-time volumes (e.g., sparsity, temporal coherence, statistical priors). These sampling schemes are implemented with novel programmable pixel-wised coded exposure and aperture in cameras. The captured information-rich coded projections of space-time volumes are used for video reconstruction or directly as features for motion/event detection. In addition to higher efficiency in imaging and higher signal-to-noise ratio in reconstructed results, the method also provides benefits in data security and privacy protection for video surveillance because decoding the captured images requires the knowledge of coded patterns and dictionaries. &lt;br/&gt;&lt;br/&gt;This research has many applications in surveillance, machine vision inspection, and high-speed imaging. The developed technology is being tested in transportation imaging for traffic monitoring and accident detection. A database of high-speed videos of traffic scenes and events is being captured and plan to be released online when it is finished. In addition to videos, the technical approach can also be applicable to other high-dimensional signals such as light fields or light transport matrices.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/30/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1257163</AwardID>
<Investigator>
<FirstName>Zoran</FirstName>
<LastName>Ninkov</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zoran Ninkov</PI_FULL_NAME>
<EmailAddress>ninkov@cis.rit.edu</EmailAddress>
<PI_PHON>5854757195</PI_PHON>
<NSF_ID>000159744</NSF_ID>
<StartDate>07/30/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jinwei</FirstName>
<LastName>Gu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jinwei Gu</PI_FULL_NAME>
<EmailAddress>jwgu@cis.rit.edu</EmailAddress>
<PI_PHON>5854756783</PI_PHON>
<NSF_ID>000573211</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate>07/30/2013</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rochester Institute of Tech</Name>
<CityName>ROCHESTER</CityName>
<ZipCode>146235603</ZipCode>
<PhoneNumber>5854757987</PhoneNumber>
<StreetAddress>1 LOMB MEMORIAL DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002223642</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ROCHESTER INSTITUTE OF TECHNOLOGY (INC)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002223642</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rochester Institute of Tech]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146235203</ZipCode>
<StreetAddress><![CDATA[1 Lomb Memoria Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~91512</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><dl class="clearing"><dd> <div class="tinyMCEContent"> <p>We redesigned and optimized the  optical system of the pixel-wise coded exposure camera, with the goal to  increase light throughput and obtain better alignment between LCoS and  camera sensor. This allows us to use the camera in outdoor scenarios. We  also fully characterized the imaging system.</p> <p>We performed thorough analysis of the proposed sparse reconstruction  algorithms in the following aspects. (1) We evaluated the relative  importance of coded sampling and dictionary-based sparse representation.  We found both factors are important for sparse reconstruction and the  coded sampling is relatively more important. &nbsp;(2) We compared our  algorithm with other recent related work including P2C2 and space&shy; time  interpolation. We found our method performs the best with a single input  image. (3) We investigated the problem of dictionary learning. We  proposed a method to visualize the items from the dictionary based on  spatial variation and temporal variation. Using this visualization as a  guide, we developed algorithms that adaptively augment the learned  dictionary for reconstruction.</p> <p>We also studied the representation and space of camera spectral  sensitivity. &nbsp;Based on this representation, we proposed a novel method  that recovers camera spectral sensitivity and unknown daylight  illumination from a single image.</p> <p>In addition to coded exposure in cameras, we applied the same  methodology of using discriminative patterns in coded illumination for  material classification based on surface texture and spectral  reflectance. The proposed algorithm has high efficiency and high SNR due  to light multiplexing. We applied the method for automatic sorting  scrap materials for recycling and obtained promising results.</p> <p>We evaluated the performance and usability of a Digital Micromirror  Device (DMD) for adoption as a coded aperature for use in a single pixel  camera system.&nbsp; Suitable electronics to operate a DMD in such a system  are being developed. An investigation into the scattered and diffractive  light effects of such a device were investigated.</p> <p>The work has made possible the development of a camera that uses a single pixel detector and a programmable optical mask to generate high resolution images rather than megpixel arrays of detectors and a single optic.</p> </div> </dd></dl><br> <p>            Last Modified: 12/02/2014<br>      Modified by: Zoran&nbsp;Ninkov</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   We redesigned and optimized the  optical system of the pixel-wise coded exposure camera, with the goal to  increase light throughput and obtain better alignment between LCoS and  camera sensor. This allows us to use the camera in outdoor scenarios. We  also fully characterized the imaging system.  We performed thorough analysis of the proposed sparse reconstruction  algorithms in the following aspects. (1) We evaluated the relative  importance of coded sampling and dictionary-based sparse representation.  We found both factors are important for sparse reconstruction and the  coded sampling is relatively more important.  (2) We compared our  algorithm with other recent related work including P2C2 and space&shy; time  interpolation. We found our method performs the best with a single input  image. (3) We investigated the problem of dictionary learning. We  proposed a method to visualize the items from the dictionary based on  spatial variation and temporal variation. Using this visualization as a  guide, we developed algorithms that adaptively augment the learned  dictionary for reconstruction.  We also studied the representation and space of camera spectral  sensitivity.  Based on this representation, we proposed a novel method  that recovers camera spectral sensitivity and unknown daylight  illumination from a single image.  In addition to coded exposure in cameras, we applied the same  methodology of using discriminative patterns in coded illumination for  material classification based on surface texture and spectral  reflectance. The proposed algorithm has high efficiency and high SNR due  to light multiplexing. We applied the method for automatic sorting  scrap materials for recycling and obtained promising results.  We evaluated the performance and usability of a Digital Micromirror  Device (DMD) for adoption as a coded aperature for use in a single pixel  camera system.  Suitable electronics to operate a DMD in such a system  are being developed. An investigation into the scattered and diffractive  light effects of such a device were investigated.  The work has made possible the development of a camera that uses a single pixel detector and a programmable optical mask to generate high resolution images rather than megpixel arrays of detectors and a single optic.         Last Modified: 12/02/2014       Submitted by: Zoran Ninkov]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
