<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Scheduling and Virtualization Technologies for Heterogeneous Clusters with Many-core Devices</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>498520.00</AwardTotalIntnAmount>
<AwardAmount>512920</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many-core graphics processing units have been used to accelerate a wide variety of applications and are increasingly a part of high performance computing clusters. Despite the rich body of literature on job scheduling and on virtualization of CPU clusters, resource management frameworks and cloud computing services for heterogeneous clusters that include many-core devices are still in their infancy.  The project targets this problem and proposes the design of a set of virtualization and scheduling technologies to allow for the efficient use of heterogeneous clusters that include general purpose processors and many-core coprocessor devices. In particular, the proposed research focuses on the following aspects and on their interactions. First, many-core sharing is explored as a means to improve system utilization while keeping infrastructure costs low. Second, scheduling mechanisms targeting both single- and multi-node applications accelerated using coprocessor devices are proposed. Third, memory unification technologies are proposed in order to hide from the users the complexity of the heterogeneous memory system. Finally, diverse software stacks are integrated into a coherent runtime system.&lt;br/&gt;&lt;br/&gt;The results of this research will be disseminated through publications and conference presentation. In addition, open-source software modules will be released and made available on the PI?s Lab website. The knowledge generated by this research will allow creating instructional material to teach cluster and cloud computing at both the undergraduate and graduate levels. Undergraduate student involvement will be promoted leveraging the University of Missouri Undergraduate Research Program and a partnership with Truman State University and Lincoln University.</AbstractNarration>
<MinAmdLetterDate>08/16/2012</MinAmdLetterDate>
<MaxAmdLetterDate>01/27/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1216756</AwardID>
<Investigator>
<FirstName>Michela</FirstName>
<LastName>Becchi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michela Becchi</PI_FULL_NAME>
<EmailAddress>mbecchi@ncsu.edu</EmailAddress>
<PI_PHON>9195152440</PI_PHON>
<NSF_ID>000573363</NSF_ID>
<StartDate>08/16/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Missouri-Columbia</Name>
<CityName>COLUMBIA</CityName>
<ZipCode>652110001</ZipCode>
<PhoneNumber>5738827560</PhoneNumber>
<StreetAddress>115 Business Loop 70 W</StreetAddress>
<StreetAddress2><![CDATA[Mizzou North, Room 501]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153890272</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Missouri-Columbia]]></Name>
<CityName>Columbia</CityName>
<StateCode>MO</StateCode>
<ZipCode>652112300</ZipCode>
<StreetAddress><![CDATA[335 Engineering Building West]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~498520</FUND_OBLG>
<FUND_OBLG>2014~14400</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Graphics Processing Units (or GPUs) are highly parallel co-processors that have been used to accelerate a wide variety of applications (weather prediction, option pricing, molecular dynamics, image processing, data mining, linear algebra, among others) and are increasingly part of high-performance computing clusters. For example, the Titan supercomputer at Oak Ridge National Lab is equipped with over eighteen thousand GPUs. However, the effective use of GPUs in shared environments is complicated by the fact that existing resource management systems for computing clusters rely directly on GPU software stacks such as CUDA and OpenCL. These stacks were designed under the assumption that GPUs are used as dedicated accelerators and they offer limited support for application concurrency. This limitation, in turn, can result in system underutilization and decreased performance.</p> <p>In this project, we have designed scheduling and virtualization technologies to allow the efficient use of GPUs in shared environments (such as clusters of computers), and we have integrated these mechanisms into a software component to be installed on all the machines of a cluster. Our software system hides the handling of GPUs from end-users, and allows applications to use the available GPU resources concurrently without interfering with one another. The system supports several scheduling and sharing policies, and allows applications to be mapped onto the hardware resources dynamically, without requiring the application developer to worry about the hardware setup of the underlying cluster of machines. In addition, our system provides advanced memory management mechanisms, load-balancing schemes, and supports dynamic upgrades and downgrades of GPUs. Our software component can be deployed in combination with existing cloud computing services to allow virtualization of heterogeneous clusters, or in combination with popular cluster resource managers to form an integrated resource management infrastructure for heterogeneous CPU-GPU clusters.</p> <p>As a side contribution, this project has led to the acceleration of several relevant applications on computing systems equipped with GPUs: from genomics applications, to graph processing (for example, for use in social networking), to deep neural networks (widely used in image and speech processing).</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/12/2016<br>      Modified by: Michela&nbsp;Becchi</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1216756/1216756_10202439_1481588863625_high-level-picture--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1216756/1216756_10202439_1481588863625_high-level-picture--rgov-800width.jpg" title="High-level software framework for CPU-GPU clusters"><img src="/por/images/Reports/POR/2016/1216756/1216756_10202439_1481588863625_high-level-picture--rgov-66x44.jpg" alt="High-level software framework for CPU-GPU clusters"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A cluster-level resource manager maps and schedules applications to server machines. On each server, a node-level runtime component performs fine-grained scheduling of GPU tasks to GPU resources and provides GPU virtualization.</div> <div class="imageCredit">Michela Becchi</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Michela&nbsp;Becchi</div> <div class="imageTitle">High-level software framework for CPU-GPU clusters</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1216756/1216756_10202439_1481589214275_node-level-runtime-design--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1216756/1216756_10202439_1481589214275_node-level-runtime-design--rgov-800width.jpg" title="Node-level runtime system's design"><img src="/por/images/Reports/POR/2016/1216756/1216756_10202439_1481589214275_node-level-runtime-design--rgov-66x44.jpg" alt="Node-level runtime system's design"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The node-level runtime system is a software component that sits between the applications and the GPU driver/runtime library. It abstracts physical GPUs through virtual GPUs (vGPUs), and includes software modules to schedule tasks onto GPUs (queues and dispatchers), and a virtual memory manager.</div> <div class="imageCredit">Michela Becchi</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Michela&nbsp;Becchi</div> <div class="imageTitle">Node-level runtime system's design</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Graphics Processing Units (or GPUs) are highly parallel co-processors that have been used to accelerate a wide variety of applications (weather prediction, option pricing, molecular dynamics, image processing, data mining, linear algebra, among others) and are increasingly part of high-performance computing clusters. For example, the Titan supercomputer at Oak Ridge National Lab is equipped with over eighteen thousand GPUs. However, the effective use of GPUs in shared environments is complicated by the fact that existing resource management systems for computing clusters rely directly on GPU software stacks such as CUDA and OpenCL. These stacks were designed under the assumption that GPUs are used as dedicated accelerators and they offer limited support for application concurrency. This limitation, in turn, can result in system underutilization and decreased performance.  In this project, we have designed scheduling and virtualization technologies to allow the efficient use of GPUs in shared environments (such as clusters of computers), and we have integrated these mechanisms into a software component to be installed on all the machines of a cluster. Our software system hides the handling of GPUs from end-users, and allows applications to use the available GPU resources concurrently without interfering with one another. The system supports several scheduling and sharing policies, and allows applications to be mapped onto the hardware resources dynamically, without requiring the application developer to worry about the hardware setup of the underlying cluster of machines. In addition, our system provides advanced memory management mechanisms, load-balancing schemes, and supports dynamic upgrades and downgrades of GPUs. Our software component can be deployed in combination with existing cloud computing services to allow virtualization of heterogeneous clusters, or in combination with popular cluster resource managers to form an integrated resource management infrastructure for heterogeneous CPU-GPU clusters.  As a side contribution, this project has led to the acceleration of several relevant applications on computing systems equipped with GPUs: from genomics applications, to graph processing (for example, for use in social networking), to deep neural networks (widely used in image and speech processing).          Last Modified: 12/12/2016       Submitted by: Michela Becchi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
