<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Intervention: A Design Framework for Resource Sharing and Exchanges Among Self-interested Users</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>491670.00</AwardTotalIntnAmount>
<AwardAmount>491670</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>In non-cooperative resource sharing and exchange systems, users compete for available resources aiming to optimize their individual objectives. Operation by self-interested users often results in suboptimal performance from a system designer's point of view. This research involves the development of a new incentive design framework for resource sharing and exchange systems where the designer can perfectly or imperfectly monitor the actions of self-interested users and intervene in their interaction. &lt;br/&gt;&lt;br/&gt;The investigators systematically study what the designer can achieve in terms of improving the performance of various non-cooperative networks and systems by designing suitable protocols and how it can achieve these improvements, given its abilities to monitor the users and its capability to intervene. This research formulates and solves the designer's problem of finding an optimal intervention rule that optimizes the designer's objective while explicitly considering the selfish nature of users. The results obtained characterize the extent to which the designer can shape the incentives of users depending on its ability to monitor the actions of users and to impact the payoffs of users.&lt;br/&gt; &lt;br/&gt;The investigators systematically study both multi-user interactions scenarios where the users interact sporadically, which will be modeled as one-shot games with intervention, as well as the case where users establish long-term relationships, which will be modeled as repeated games with intervention. In both scenarios, the cases of perfect and imperfect monitoring of the users? actions will be investigated. Overall, this research provides a novel framework to evaluate the performance gain from having a designer that has a monitoring and intervention ability, and to figure out the best way to utilize its capabilities.</AbstractNarration>
<MinAmdLetterDate>07/24/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218136</AwardID>
<Investigator>
<FirstName>Mihaela</FirstName>
<LastName>van der Schaar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mihaela van der Schaar</PI_FULL_NAME>
<EmailAddress>mihaela@ee.ucla.edu</EmailAddress>
<PI_PHON>3108255843</PI_PHON>
<NSF_ID>000152646</NSF_ID>
<StartDate>07/24/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951594</ZipCode>
<StreetAddress><![CDATA[420 Westwood Plaza, Engr. IV]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~491670</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In many settings, unregulated self-interested behavior of agents (people, robots, wireless devices, companies, institutions) will lead to socially undesirable outcomes. In such settings, outcomes can be improved by providing incentives for &ldquo;desired&rdquo; behavior; such incentives can be provided by regulation or by <em>intervention</em>.</p> <p>The research supported by this award developed a new paradigm for building incentive schemes based on intervention. In the developed intervention paradigm, a manager/regulator (government, platform operator, network provider, service provider etc.) can perfectly or imperfectly monitor the decisions/actions of the agents and can affect their benefits/payoffs by intervening in their interaction. The theory of intervention, which was developed based on the research supported by this award, formulates the manager&rsquo;s problem as the choice of an intervention rule that optimizes the manager&rsquo;s objective subject to the (physical, legal, etc.) constraints while respecting the self-interested nature of the agents. The developed theory and associated analysis answer the following fundamental questions:</p> <ul> <li>When can we construct an intervention mechanism that improves performance (e.g. social welfare social gain)?</li> <li>What is the best level of performance that an intervention mechanism can achieve?</li> <li>When can we construct an intervention mechanism that achieves optimal performance?</li> </ul> <p>The answers to these questions depend on the capacities of the manager to monitor the decisions/actions of agents (i.e., monitoring technology) and to affect the payoffs of agents through its actions (i.e., intervention capability). If monitoring is perfect (i.e., the manager can observe the actions of agents without errors/noise), the manager can focus on an intervention rule that threatens the strongest available punishment when agents deviate.&nbsp; In equilibrium, agents will never deviate and this threat will not need to be carried out.&nbsp; When monitoring is imperfect (i.e., the manager can only observe the actions of the agents with errors/noise), the manager may not wish to use such strong threats because they will need to be carried out when deviation is observed &ndash; even incorrectly. Comparing performances under different monitoring technologies enables researchers and designers to quantify the value of information, which can inform the design of new interventions and regulations. This provides a useful measure especially when the manager can choose a monitoring technology together with an intervention rule in a given environment.</p> <p>In summary, this research offers a framework to systematically evaluate the performance (e.g. welfare) gain from having a manager that has monitoring and intervention capabilities, and to design a system that best utilizes these capabilities. The findings of this research were applied to social networking platforms to create a system that discourages anti-social behavior&nbsp; -- especially bullying.&nbsp; (This work was featured in an article in the NY Times.)</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/23/2017<br>      Modified by: Mihaela&nbsp;Van Der Schaar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In many settings, unregulated self-interested behavior of agents (people, robots, wireless devices, companies, institutions) will lead to socially undesirable outcomes. In such settings, outcomes can be improved by providing incentives for "desired" behavior; such incentives can be provided by regulation or by intervention.  The research supported by this award developed a new paradigm for building incentive schemes based on intervention. In the developed intervention paradigm, a manager/regulator (government, platform operator, network provider, service provider etc.) can perfectly or imperfectly monitor the decisions/actions of the agents and can affect their benefits/payoffs by intervening in their interaction. The theory of intervention, which was developed based on the research supported by this award, formulates the manager?s problem as the choice of an intervention rule that optimizes the manager?s objective subject to the (physical, legal, etc.) constraints while respecting the self-interested nature of the agents. The developed theory and associated analysis answer the following fundamental questions:  When can we construct an intervention mechanism that improves performance (e.g. social welfare social gain)? What is the best level of performance that an intervention mechanism can achieve? When can we construct an intervention mechanism that achieves optimal performance?   The answers to these questions depend on the capacities of the manager to monitor the decisions/actions of agents (i.e., monitoring technology) and to affect the payoffs of agents through its actions (i.e., intervention capability). If monitoring is perfect (i.e., the manager can observe the actions of agents without errors/noise), the manager can focus on an intervention rule that threatens the strongest available punishment when agents deviate.  In equilibrium, agents will never deviate and this threat will not need to be carried out.  When monitoring is imperfect (i.e., the manager can only observe the actions of the agents with errors/noise), the manager may not wish to use such strong threats because they will need to be carried out when deviation is observed &ndash; even incorrectly. Comparing performances under different monitoring technologies enables researchers and designers to quantify the value of information, which can inform the design of new interventions and regulations. This provides a useful measure especially when the manager can choose a monitoring technology together with an intervention rule in a given environment.  In summary, this research offers a framework to systematically evaluate the performance (e.g. welfare) gain from having a manager that has monitoring and intervention capabilities, and to design a system that best utilizes these capabilities. The findings of this research were applied to social networking platforms to create a system that discourages anti-social behavior  -- especially bullying.  (This work was featured in an article in the NY Times.)          Last Modified: 10/23/2017       Submitted by: Mihaela Van Der Schaar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
