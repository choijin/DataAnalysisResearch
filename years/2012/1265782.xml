<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Geometric functional analysis, random matrices and applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>219000.00</AwardTotalIntnAmount>
<AwardAmount>219000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Edward Taylor</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project seeks to advance methods of geometric functional analysis and to apply them for problems of non-asymptotic random matrix theory and high-dimensional data. One of the main goals of this project is to expand our understanding of non-asymptotic properties of random matrices, in particular, their quantitative invertibility. A related goal is to develop a direct, nonspectral approach to delocalization of eigenvectors of random matrices. Methods of geometric functional analysis may succeed even where spectral methods fail due to an unknown (or nonexisting) limiting spectral distribution. Next, functional analytic and probabilistic methodology will be applied to high-dimensional data. This may result in new geometric approaches to compressed sensing, community detection in networks, and robust principal component analysis.&lt;br/&gt; &lt;br/&gt;Geometric functional analysis studies fundamental properties of high-dimensional structures. Such structures are ubiquitous in modern applications. The unprecedented volume of data described by large number of parameters prevents many traditional statistical approaches from working. This project will look for new ways to understand, represent, and analyze high-dimensional structures using methods of geometric functional analysis. Specific structures for which the new methodology can be applied include large matrices (e.g., consumer data), networks (e.g., food chains, social networks), signals (e.g., images, audio, video). Conversely, the fundamental challenges of high-dimensional data are likely to open up some new directions of basic research at the intersection of functional analysis, high-dimensional geometry, and probability.</AbstractNarration>
<MinAmdLetterDate>07/31/2013</MinAmdLetterDate>
<MaxAmdLetterDate>04/24/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1265782</AwardID>
<Investigator>
<FirstName>Roman</FirstName>
<LastName>Vershynin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Roman Vershynin</PI_FULL_NAME>
<EmailAddress>rvershyn@uci.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000397092</NSF_ID>
<StartDate>07/31/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091271</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1263</Code>
<Text>PROBABILITY</Text>
</ProgramElement>
<ProgramElement>
<Code>1281</Code>
<Text>ANALYSIS PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~70814</FUND_OBLG>
<FUND_OBLG>2014~73900</FUND_OBLG>
<FUND_OBLG>2015~74286</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="font-size: xx-small;">In the area of network analysis, we developed and rigorously analyzed new algorithmic methods for data mining in sparse networks. The previously existing&nbsp; algorithms were only applicable for relatively dense networks. Practitioners suggested that the problem for sparse networks lies in the vertices of&nbsp;</span><span style="font-size: xx-small;">abnormally high degrees and suggested that regularizing those vertices could solve the problem. We confirmed this rigorously by discovering a very&nbsp;</span><span style="font-size: xx-small;">general result: any regularization of vertices that brings their degrees down to average leads to a network whose structure can be uncovered by fast spectral methods. We also demonstrated how methods based on semidefinite</span><span style="font-size: xx-small;">programming can aid structure discovery in sparse networks. Our theory is</span><span style="font-size: xx-small;">applicable for a far wider class of networks than the benchmark class of stochastic block models that is usually discussed in network science results.</span></p> <p><span style="font-size: xx-small;"><br /></span><span style="font-size: xx-small;">These advances are tightly connected to new discoveries in random matrix theory.&nbsp;</span><span style="font-size: xx-small;">We discovered a new delocalization phenomenon for a wide class of random matrices. We also showed how the behavior of a random matrix can be improved by modifying a small fraction of its entries. Finally, we developed a simple and general tool for controlling the fluctuations of a random matrix on an arbitrary geometric set. Our new deviation inequality unified many existing results in dimension reduction, high-dimensional convex geometry, and random matrix theory, and it led to new applications in model selection, structured regression and compressed sensing.</span></p> <p><span style="font-size: xx-small;"><br /></span><span style="font-size: xx-small;">The award made it possible to support the research of graduate students from underrepresented groups. The award also enabled the PI to prepare the drat of the first textbook in high-dimensional probability and applications in data science, which will benefit graduate students and beginning researchers in mathematics, statistics, computer science and electrical engineering.&nbsp;</span></p><br> <p>            Last Modified: 04/18/2018<br>      Modified by: Roman&nbsp;Vershynin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In the area of network analysis, we developed and rigorously analyzed new algorithmic methods for data mining in sparse networks. The previously existing  algorithms were only applicable for relatively dense networks. Practitioners suggested that the problem for sparse networks lies in the vertices of abnormally high degrees and suggested that regularizing those vertices could solve the problem. We confirmed this rigorously by discovering a very general result: any regularization of vertices that brings their degrees down to average leads to a network whose structure can be uncovered by fast spectral methods. We also demonstrated how methods based on semidefiniteprogramming can aid structure discovery in sparse networks. Our theory isapplicable for a far wider class of networks than the benchmark class of stochastic block models that is usually discussed in network science results.   These advances are tightly connected to new discoveries in random matrix theory. We discovered a new delocalization phenomenon for a wide class of random matrices. We also showed how the behavior of a random matrix can be improved by modifying a small fraction of its entries. Finally, we developed a simple and general tool for controlling the fluctuations of a random matrix on an arbitrary geometric set. Our new deviation inequality unified many existing results in dimension reduction, high-dimensional convex geometry, and random matrix theory, and it led to new applications in model selection, structured regression and compressed sensing.   The award made it possible to support the research of graduate students from underrepresented groups. The award also enabled the PI to prepare the drat of the first textbook in high-dimensional probability and applications in data science, which will benefit graduate students and beginning researchers in mathematics, statistics, computer science and electrical engineering.        Last Modified: 04/18/2018       Submitted by: Roman Vershynin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
