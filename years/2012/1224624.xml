<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Tracking the Process of Data-Driven Decision Making: Exploring the Use of the Instructional Systems of Practice (ISOP) Framework to Transform Undergraduate STEM Education</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
<AwardExpirationDate>12/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>593844.00</AwardTotalIntnAmount>
<AwardAmount>593844</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040200</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Myles Boylan</SignBlockName>
<PO_EMAI>mboylan@nsf.gov</PO_EMAI>
<PO_PHON>7032928670</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is addressing the measurement of instructional practices and administrative decision-making concerning undergraduate STEM courses. In seeking to enhance the efficacy of pedagogical reforms, researchers and policymakers recommend that educators should utilize data-driven decision making (DDDM) systems.  For this to work, the data must be robust, salient to local practice, and supported by adequate technical and administrative systems.  Currently little is known about the nature of decision-making processes within STEM departments and pedagogical reform initiatives and this lack of high-quality data about instructional practice on individual campuses has retarded the use of DDDM at the postsecondary level.  &lt;br/&gt;&lt;br/&gt;The goals of this study are to collect high quality data on instructional practice, to prepare reports based on these data for decision makers in higher education, and to subsequently examine the use of these data in decision making about pedagogical reforms.  The core tool being used is the Instructional Systems of Practice (ISOP) framework.  ISOP was developed as an approach to studying faculty teaching. It is designed to improve on existing data sources on teaching such as self-report surveys, unstructured observations, or student ratings.  ISOP defines teaching to be a multi-dimensional practice comprised of course planning, classroom practice, and student interpretations of teaching efficacy.  Classroom practice is studied using the Teaching Dimensions Observation Protocol (TDOP).  &lt;br/&gt;&lt;br/&gt;STEM education leaders at three universities are committed to using the ISOP framework to help guide their decision-making. The participation of three universities is expected to define in greater detail the extent to which the ISOP framework can be used to enhance DDDM and efforts to transform undergraduate STEM education. The study will use of a longitudinal mixed methods case study design to study decision making and instructional practice over the course of three years at three research universities with active STEM education projects.  Additionally this project is planning to provide professional development opportunities to administrators and STEM education leaders.  &lt;br/&gt;&lt;br/&gt;Intellectual Merit: The ISOP framework is an innovative multidisciplinary approach that draws on established methodologies from cognitive science, naturalistic decision-making, and educational research. It does so in ways that promise to contribute new knowledge about the dynamics that underlie administrative decision-making and faculty practice, and provide better methods and measures for use in STEM education research. &lt;br/&gt;&lt;br/&gt;Broader Impacts: This research will determine to what extent the ISOP framework can be utilized in unique contexts engaged in undergraduate STEM education initiatives.  It has the potential to be of significant value to researchers, educators and policymakers in the US.</AbstractNarration>
<MinAmdLetterDate>08/14/2012</MinAmdLetterDate>
<MaxAmdLetterDate>02/15/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1224624</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Halverson</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard R Halverson</PI_FULL_NAME>
<EmailAddress>halverson@education.wisc.edu</EmailAddress>
<PI_PHON>6082623822</PI_PHON>
<NSF_ID>000333122</NSF_ID>
<StartDate>02/15/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Halverson</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard R Halverson</PI_FULL_NAME>
<EmailAddress>halverson@education.wisc.edu</EmailAddress>
<PI_PHON>6082623822</PI_PHON>
<NSF_ID>000333122</NSF_ID>
<StartDate>08/14/2012</StartDate>
<EndDate>01/15/2013</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Hora</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew T Hora</PI_FULL_NAME>
<EmailAddress>hora@wisc.edu</EmailAddress>
<PI_PHON>6082623822</PI_PHON>
<NSF_ID>000465017</NSF_ID>
<StartDate>02/15/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Hora</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew T Hora</PI_FULL_NAME>
<EmailAddress>hora@wisc.edu</EmailAddress>
<PI_PHON>6082623822</PI_PHON>
<NSF_ID>000465017</NSF_ID>
<StartDate>08/14/2012</StartDate>
<EndDate>01/15/2013</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jana</FirstName>
<LastName>Bouwma-Gearhart</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jana Bouwma-Gearhart</PI_FULL_NAME>
<EmailAddress>jana.bouwma-gearhart@oregonstate.edu</EmailAddress>
<PI_PHON>5417372206</PI_PHON>
<NSF_ID>000524743</NSF_ID>
<StartDate>08/14/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Wisconsin-Madison</Name>
<CityName>MADISON</CityName>
<ZipCode>537151218</ZipCode>
<PhoneNumber>6082623822</PhoneNumber>
<StreetAddress>21 North Park Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 6401]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>161202122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WISCONSIN SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041188822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Wisconsin-Madison]]></Name>
<CityName>Madison</CityName>
<StateCode>WI</StateCode>
<ZipCode>537151218</ZipCode>
<StreetAddress><![CDATA[21 North Park Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1133</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>7511</Code>
<Text>TUES-Type 2 Project</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0412</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~593844</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary goals of this study were: (1) To empirically  determine whether data driven decision-making (DDDM) was occurring in STEM departments regarding matters of curriculum and instruction, and (2) To field-test the Instructional  Systems of Practice (ISOP) framework as a source of data about teaching  and learning to enhance faculty decision-making processes.&nbsp; A focus of the study was to document and describe the real-world practices of faculty and administrators, rather than assessing whether or not they were operating according to a determination of "best practices" or idealized decision processes.</p> <p>This project produced 6 manuscripts, 1 conference proceeding (an extensive review of the DDDM literature), 5 conference presentations, 3 in-depth trainings on the Teaching Dimensions Observation Protocol (TDOP), and over 40 personalized data reports for participating institutions and faculty from thte ISOP data system.&nbsp; Additionally, through TDOP trainings and widespread dissemination (over 350 registered users currently utilize the instrument), the study contributed to the further development of research instruments in the field of STEM education including the COPUS tool and elements of the GORP platform.</p> <p>Regarding the first goal of the project, the study produced important new insights about how faculty and administrators make decisions about curriculum and instruction in colleges and universities, particularly in STEM departments. First, evidence from 59 faculty interviewed in Phase 1 (Spring 2013) at 3 research universities in the US and Canada, indicates that they draw upon a variety of different forms of data and information to inform their decisions (Hora, Bouwma-Gearhart, Park, 2017).&nbsp; The importance placed on conversations with colleagues and students, direct feedback, and the research literature indicates that a sole focus on numeric data is misguided in terms of how faculty actually make informed decisions in practice. Second, multi-dimensional scaling analyses of these results indicated that 6 distinct types of DDDM was evident among the sample: (1) sophisticated analysis of formative data throughout term, (2) rapid reviews of exam and evaluation data to improve next course, (3) utilize of various data in consultation with outside experts and external CI systems, (4) the absence of any data or reflection, (5) reliance on direct feedback from students, and (6) reliance on personal experience immediately prior to course design.&nbsp;</p> <p>It is important to note that a not inconsiderable percentage (20%) of faculty in the study utilized no data at all when planning, revising, and teaching their courses, though no evidence exists that this lack of DDDM led to poor student outcomes.&nbsp; We conclude from these findings that while institutions should provide better data to faculty (especially student evaluations), and that the craft of teaching relies on extensive amounts of personal experience, intuition, and socio-cultural inputs that bely technical solutions.</p> <p>Additional evidence produced in relation to the first goal of this study are as follows. Measures of active learning can be discerned from TDOP data that represent improvements over the lecture-active learning binary, which is an important component of providing ecologically valid data to faculty (Hora, 2015). Analyses of faculty use of student evaluation data revealed that institutional data are widely viewed as insufficient by faculty, who devise their own personal evaluation systems to inform continuous improvement in their teaching practices.&nbsp; Data use at the departmental and institutional levels is best viewed as a form of knowledge construction that unfolds within complex organizational contexts. Policies focused on encouraging DDDM are most effective when tailored to specific local practices, cultural norms, and technical capabilities.</p> <p>Finall...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The primary goals of this study were: (1) To empirically  determine whether data driven decision-making (DDDM) was occurring in STEM departments regarding matters of curriculum and instruction, and (2) To field-test the Instructional  Systems of Practice (ISOP) framework as a source of data about teaching  and learning to enhance faculty decision-making processes.  A focus of the study was to document and describe the real-world practices of faculty and administrators, rather than assessing whether or not they were operating according to a determination of "best practices" or idealized decision processes.  This project produced 6 manuscripts, 1 conference proceeding (an extensive review of the DDDM literature), 5 conference presentations, 3 in-depth trainings on the Teaching Dimensions Observation Protocol (TDOP), and over 40 personalized data reports for participating institutions and faculty from thte ISOP data system.  Additionally, through TDOP trainings and widespread dissemination (over 350 registered users currently utilize the instrument), the study contributed to the further development of research instruments in the field of STEM education including the COPUS tool and elements of the GORP platform.  Regarding the first goal of the project, the study produced important new insights about how faculty and administrators make decisions about curriculum and instruction in colleges and universities, particularly in STEM departments. First, evidence from 59 faculty interviewed in Phase 1 (Spring 2013) at 3 research universities in the US and Canada, indicates that they draw upon a variety of different forms of data and information to inform their decisions (Hora, Bouwma-Gearhart, Park, 2017).  The importance placed on conversations with colleagues and students, direct feedback, and the research literature indicates that a sole focus on numeric data is misguided in terms of how faculty actually make informed decisions in practice. Second, multi-dimensional scaling analyses of these results indicated that 6 distinct types of DDDM was evident among the sample: (1) sophisticated analysis of formative data throughout term, (2) rapid reviews of exam and evaluation data to improve next course, (3) utilize of various data in consultation with outside experts and external CI systems, (4) the absence of any data or reflection, (5) reliance on direct feedback from students, and (6) reliance on personal experience immediately prior to course design.   It is important to note that a not inconsiderable percentage (20%) of faculty in the study utilized no data at all when planning, revising, and teaching their courses, though no evidence exists that this lack of DDDM led to poor student outcomes.  We conclude from these findings that while institutions should provide better data to faculty (especially student evaluations), and that the craft of teaching relies on extensive amounts of personal experience, intuition, and socio-cultural inputs that bely technical solutions.  Additional evidence produced in relation to the first goal of this study are as follows. Measures of active learning can be discerned from TDOP data that represent improvements over the lecture-active learning binary, which is an important component of providing ecologically valid data to faculty (Hora, 2015). Analyses of faculty use of student evaluation data revealed that institutional data are widely viewed as insufficient by faculty, who devise their own personal evaluation systems to inform continuous improvement in their teaching practices.  Data use at the departmental and institutional levels is best viewed as a form of knowledge construction that unfolds within complex organizational contexts. Policies focused on encouraging DDDM are most effective when tailored to specific local practices, cultural norms, and technical capabilities.  Finally, the study also involved a field-test of a new dataset for documenting faculty teaching that included structured observa...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
