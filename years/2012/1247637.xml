<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: Mid-Scale: ESCE: Collaborative Research: Discovery and Social Analytics for Large-Scale Scientific Literature</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2013</AwardEffectiveDate>
<AwardExpirationDate>12/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1294450.00</AwardTotalIntnAmount>
<AwardAmount>1294450</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Big data analytics is, fundamentally, the problem of bringing the massive amounts of data produced today down to human scale. In particular scientists, engineers, physicians, and many others in knowledge-intensive professions face data that is beyond human scale. This data is in the repositories that collect the data and the reports or results in their fields. This project will address the problem of bringing all this knowledge under control by using even more data, namely the individual and social patterns of how these repositories are accessed and used, and user-specific judgments (valuations) of the data.  The proposed research will develop novel algorithms and an open-source infrastructure for improving discovery within and access to data repositories. These algorithms will aggregate and analyze the social analytic data, gathered from professional communities of data users, and will motivate them to participate by providing recommendations.&lt;br/&gt;&lt;br/&gt;The transformative goal is to develop methods for organizing, and operationalizing the access and preference patterns of users of large repositories, and for integrating those valuations to accelerate discovery within the collections. Diverse human minds interacting with data collections, as they carry out their own research or operational activities, provide a powerful source of information about the value of the data itself. Those data items may be textual documents, numerical datasets, or other kinds of media content. The novel methods for representing, aggregating, organizing and valuating interactions between the users and the items can reveal structures within data collections, which were previously invisible to any individual. This discovery of interrelations within data, driven by the capture of human intelligence, will accelerate the processes of scientific discovery. Users who are permitted to valuate data, and who are motivated by receiving valuable recommendations in return, reveal more about their own interests. This makes it possible to discover relations among the data items and among the users themselves. The educational goals are to: (a) contribute to the education of specific graduate students supported by the project, and undergraduates via the REU mechanism; (b) generate new educational materials related to algorithmic innovations, and to research findings; and (c) improve access to and discovery within specific collections of materials. Research findings will be included in courses at all three collaborating universities.&lt;br/&gt;&lt;br/&gt;Additional information about the project (including publication, software, data sets) will be made available through the project web site: http://arxiv_xs.rutgers.edu/.</AbstractNarration>
<MinAmdLetterDate>09/20/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1247637</AwardID>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Ginsparg</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Paul H Ginsparg</PI_FULL_NAME>
<EmailAddress>ginsparg@cornell.edu</EmailAddress>
<PI_PHON>6072557316</PI_PHON>
<NSF_ID>000178788</NSF_ID>
<StartDate>09/20/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Thorsten</FirstName>
<LastName>Joachims</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thorsten Joachims</PI_FULL_NAME>
<EmailAddress>tj@cs.cornell.edu</EmailAddress>
<PI_PHON>6072551372</PI_PHON>
<NSF_ID>000224646</NSF_ID>
<StartDate>09/20/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Frazier</LastName>
<PI_MID_INIT>I</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter I Frazier</PI_FULL_NAME>
<EmailAddress>pf98@cornell.edu</EmailAddress>
<PI_PHON>6077938495</PI_PHON>
<NSF_ID>000537016</NSF_ID>
<StartDate>09/20/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148537501</ZipCode>
<StreetAddress><![CDATA[4130 Upson Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~1294450</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-46118a21-20cc-a7de-949d-0b57a8b1cc55">&nbsp;</span></p> <p dir="ltr"><span>Recommender systems have become a key tool of everyday life, and we routinely use them for tasks ranging from browsing entertainment options to researching products we may want to purchase. In this project, we developed new methods for training recommender systems based on the feedback the users provided both explicitly and implicitly through their actions. In particular, the project focused on designing recommendation systems for scientific literature, where this particular application provided not only a testbed for the general methods we developed, but also explored the design of the next generation of information systems that will further enable the dissemination of scientific results.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>The project was a collaborative effort of researchers at Cornell, Princeton, and Rutgers. Focusing on the results on the Cornell side, the project developed new machine learning algorithms for several aspects of the recommendation problem. The project made many contributions to the design of such learning algorithms, but for conciseness of this report we focus on the following two areas of research.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>First, recommendation systems need to strike the right balance between exploiting what they already know about the user, and exploring aspects of the users&rsquo; interests that the system is not yet confident about. Making the right trade-offs between exploration and exploitation is important, since too much exploration makes the recommendation system look like it does not know the users&rsquo; tastes, and too much exploitation may lead to never discovering all the interests a user may have. Approaching this trade-off between exploration and exploration as a multi-armed bandit problem, we have designed new algorithms and their underlying theory for solving this trade-off optimally under various conditions.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Second, we asked the question of how to reuse data that was collected by the recommendation system in the past. The problem here lies in dealing with the biases that were introduced by the historic version of the recommendation system, as well as the biases that are inherent in how humans provide feedback and make choices. For example, if we want to use the set of papers that the user read while using our historic recommendation system as a feedback signal for learning, then it is important to know what papers the recommender system did recommend and how visible this was to the user. Clearly, a paper that was never discovered by the user cannot make it into the set of paper the user read, even if it was very relevant to the user&rsquo;s interests. To deal with such biases in a principled and provably correct way, we designed learning methods that explicitly correct for selection biases and that scale to large datasets.</span></p> <p><br /><span>Beyond these research contributions in machine learning, the project developed the my.arxiv.org system as a prototype for the next generation of systems that help researchers discover relevant scientific literature. It allowed us to explore different interfaces and how these interfaces interact with the recommendation algorithms. The lessons learned will be incorporated into the design of the next generation of Arxiv.Org, which is the main repository of scientific papers for a wide range of disciplines in science and engineering.</span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/10/2017<br>      Modified by: Thorsten&nbsp;Joachims</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Recommender systems have become a key tool of everyday life, and we routinely use them for tasks ranging from browsing entertainment options to researching products we may want to purchase. In this project, we developed new methods for training recommender systems based on the feedback the users provided both explicitly and implicitly through their actions. In particular, the project focused on designing recommendation systems for scientific literature, where this particular application provided not only a testbed for the general methods we developed, but also explored the design of the next generation of information systems that will further enable the dissemination of scientific results.    The project was a collaborative effort of researchers at Cornell, Princeton, and Rutgers. Focusing on the results on the Cornell side, the project developed new machine learning algorithms for several aspects of the recommendation problem. The project made many contributions to the design of such learning algorithms, but for conciseness of this report we focus on the following two areas of research.    First, recommendation systems need to strike the right balance between exploiting what they already know about the user, and exploring aspects of the users? interests that the system is not yet confident about. Making the right trade-offs between exploration and exploitation is important, since too much exploration makes the recommendation system look like it does not know the users? tastes, and too much exploitation may lead to never discovering all the interests a user may have. Approaching this trade-off between exploration and exploration as a multi-armed bandit problem, we have designed new algorithms and their underlying theory for solving this trade-off optimally under various conditions.    Second, we asked the question of how to reuse data that was collected by the recommendation system in the past. The problem here lies in dealing with the biases that were introduced by the historic version of the recommendation system, as well as the biases that are inherent in how humans provide feedback and make choices. For example, if we want to use the set of papers that the user read while using our historic recommendation system as a feedback signal for learning, then it is important to know what papers the recommender system did recommend and how visible this was to the user. Clearly, a paper that was never discovered by the user cannot make it into the set of paper the user read, even if it was very relevant to the user?s interests. To deal with such biases in a principled and provably correct way, we designed learning methods that explicitly correct for selection biases and that scale to large datasets.   Beyond these research contributions in machine learning, the project developed the my.arxiv.org system as a prototype for the next generation of systems that help researchers discover relevant scientific literature. It allowed us to explore different interfaces and how these interfaces interact with the recommendation algorithms. The lessons learned will be incorporated into the design of the next generation of Arxiv.Org, which is the main repository of scientific papers for a wide range of disciplines in science and engineering.             Last Modified: 05/10/2017       Submitted by: Thorsten Joachims]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
