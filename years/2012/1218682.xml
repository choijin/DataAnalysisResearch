<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Image and Video Processing with Depth</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>390510.00</AwardTotalIntnAmount>
<AwardAmount>390510</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This research aims to advance the theory and practice of image and video processing with the emerging 3D cameras.  The recent huge commercial success and excitement with low-cost consumer-grade color plus depth cameras such as Microsoft Kinect promise the wide deployment of depth sensors to every computer and display device.  This rapid development demands fundamental new methods in processing depth input and its combination with regular color images and videos.  Furthermore, this emerging depth-sensing technology has the potential to radically extend the possibilities of image and video processing.&lt;br/&gt; &lt;br/&gt;Toward these aims, this research involves, (i) calibration and denoising the raw measurements from depth cameras via accurate physical and statistical modeling of the new depth sensors and typical 3D scenes, (ii) improving the quality and resolution of depth images by exploiting the synergy between color and depth cameras, (iii) integration of multiple depth frames as an extension of super-resolution in video from 2D to 3D using computer graphics tools, and, finally, (iv) employing the improved and integrated depth information with color videos in challenging and high-impact applications including color plus depth rendering, relighting, and encoding.</AbstractNarration>
<MinAmdLetterDate>08/31/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218682</AwardID>
<Investigator>
<FirstName>Minh</FirstName>
<LastName>Do</LastName>
<PI_MID_INIT>N</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Minh N Do</PI_FULL_NAME>
<EmailAddress>minhdo@illinois.edu</EmailAddress>
<PI_PHON>2172444782</PI_PHON>
<NSF_ID>000312228</NSF_ID>
<StartDate>08/31/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sevket</FirstName>
<LastName>Babacan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sevket Babacan</PI_FULL_NAME>
<EmailAddress>dbabacan@illinois.edu</EmailAddress>
<PI_PHON>2173332187</PI_PHON>
<NSF_ID>000584576</NSF_ID>
<StartDate>08/31/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~390510</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This research aims to advance the theory and practice of image and video processing with the emerging 3D cameras. &nbsp;The recent huge commercial success and excitement with low-cost consumer-grade color plus depth cameras such as Microsoft Kinect promise the wide deployment of depth sensors to every computer and display device. &nbsp;This rapid development demands fundamental new methods in processing depth input and its combination with regular color images and videos. &nbsp;Furthermore, this emerging depth-sensing technology has the potential to radically extend the possibilities of image and video processing.&nbsp;</p> <p>This research addresses core problems at the intersection of imageprocessing, computer vision, computer graphics and statistical modeling. Therefore, the developed methods from this work will be valuable not just for depth image processing, but also for many other main problems in a variety of areas. Moreover, efficient representation, integration, fusion andmodeling of data is at the heart of all scientific imaging. Due to the increasing need of more effective 3D algorithms, we believe the outcomes of this research will prompt a new fruitful interaction between a number of fields.</p> <p>The project has trained 5 graduate students in technical areas (image and video processing, 3D imaging) that are of critical need. &nbsp;The project resulted in 9 journal papers and 9 conferences papers at top peer-reviewed venues.</p><br> <p>            Last Modified: 12/19/2016<br>      Modified by: Minh&nbsp;N&nbsp;Do</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This research aims to advance the theory and practice of image and video processing with the emerging 3D cameras.  The recent huge commercial success and excitement with low-cost consumer-grade color plus depth cameras such as Microsoft Kinect promise the wide deployment of depth sensors to every computer and display device.  This rapid development demands fundamental new methods in processing depth input and its combination with regular color images and videos.  Furthermore, this emerging depth-sensing technology has the potential to radically extend the possibilities of image and video processing.   This research addresses core problems at the intersection of imageprocessing, computer vision, computer graphics and statistical modeling. Therefore, the developed methods from this work will be valuable not just for depth image processing, but also for many other main problems in a variety of areas. Moreover, efficient representation, integration, fusion andmodeling of data is at the heart of all scientific imaging. Due to the increasing need of more effective 3D algorithms, we believe the outcomes of this research will prompt a new fruitful interaction between a number of fields.  The project has trained 5 graduate students in technical areas (image and video processing, 3D imaging) that are of critical need.  The project resulted in 9 journal papers and 9 conferences papers at top peer-reviewed venues.       Last Modified: 12/19/2016       Submitted by: Minh N Do]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
