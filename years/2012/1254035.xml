<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Banalytics: Behavioral Network Analytics with Data Transparency</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2013</AwardEffectiveDate>
<AwardExpirationDate>03/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>499998.00</AwardTotalIntnAmount>
<AwardAmount>539998</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Data from customers become central to many companies' business, and tomorrow's society's progress critically depends on scientists and public decision makers accessing citizens' data. But how to reconcile progress with privacy? This dilemma, everyday, is getting worse, because we lack an abstraction where analytics -- the science of identifying and exploiting individual types and trends -- are transparent to users and they can effectively own and trade their data. Today's analytics on proprietary data, and its highly debated need for regulation, seems a necessary evil for a lack of credible alternative. This project aims at unlocking this tussle by (1) building behavioral analytics that are compatible with distributed systems of personal data, (2) showing how context and social influence can be better leveraged, and (3) enabling incremental deployment along mutual benefits to make privacy economically efficient. &lt;br/&gt;&lt;br/&gt;The principal investigator will explore a new abstraction -- Behavioral Networks -- and show its tractability using recent results in matrix factorization, algorithms exploiting social influence, and analysis of networked incentives. Banalytics will demonstrate its applicability to various analytics tasks, including data collection, behavioral targeting, content rating and recommendation. &lt;br/&gt;&lt;br/&gt;Broader Impact:&lt;br/&gt;&lt;br/&gt;The need to regulate proprietary access to personal data is heavily discussed towards a new Privacy Bill. Unfortunately, controlling personal data used behind closed doors is highly complex, making enforcement of top-down regulation either ineffective or potentially disastrous for the free and thriving life of the web. The Banalytics project explores and makes available alternative designs empowering users, to inform this important societal debate towards better self-regulation.&lt;br/&gt;&lt;br/&gt;Not only are sound solutions to reconcile privacy and progress essential, but they need to be disseminated and understood broadly. Banalytics aims to impact the education of students at large -- not only future engineers but also the future journalists informing our citizens -- on the management of personal information and its technical, economic and societal aspects. Through close collaboration with the Columbia School of Journalism, the principal investigator will promote a unique interdisciplinary education program to allow all students and citizens, especially those who might not otherwise express interest in computer science, to be engaged in this effort.</AbstractNarration>
<MinAmdLetterDate>04/10/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/31/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1254035</AwardID>
<Investigator>
<FirstName>Augustin</FirstName>
<LastName>Chaintreau</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Augustin Chaintreau</PI_FULL_NAME>
<EmailAddress>ac3318@columbia.edu</EmailAddress>
<PI_PHON>2128546851</PI_PHON>
<NSF_ID>000575992</NSF_ID>
<StartDate>04/10/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>100277003</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7363</Code>
<Text>RES IN NETWORKING TECH &amp; SYS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~103587</FUND_OBLG>
<FUND_OBLG>2014~213979</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<FUND_OBLG>2016~103698</FUND_OBLG>
<FUND_OBLG>2017~102734</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>**Quick summary:**<br />The overarching goal of my research and this NSF CAREER project is to reconcile the risk and value of personal data networking, by designing algorithms leveraging social mobile behaviors and incentives.<br /><br />**Brief thematic overview**:<br />Readers, bloggers, shoppers, are constantly seeking new information and sharing them using social networking tools. The mundane expectation is that by accessing and sharing more data, you certainly spend time and expose yourself but you are better informed to make important decisions. In other words, it?s worth the effort and the risk. But is it? How much are we actually aware about concrete risks? And are we really seeing that this process rewards its participants efficiently? What about when the data are collected and used without your awareness and consent?<br /><br />Behavioral analytics leverage personal data about user behaviors collected and used for personalization, decision and optimization. It is arguably a historic driver of societal progress, but also one of the most controversial. It already challenges core values such as personal privacy and societal fairness in equal access to content and services.<br /><br />Behavioral analytics so far are hindered by two main defects:<br />- it provides *no transparency*: users are releasing information and permissions to use data without being aware of the induced risks and how the information they provide affects their service. At best they have crude information and guideline about which data are known and rarely how they are used.<br />- it provides *no incentive*: users are generally facing a binary choice, convenience of a service free of charge in exchange of full data disclosure. At best, they are offered a coarse choice of opting-out of some personalization features.<br /><br />This project, in contrast, works on providing transparency and incentive in today?s behavioral analytics:<br />(Th.I) Quantify the threats posed by personal data disclosure across multiple domains, in the face of emerging plausible risks: re-identification across domains and discrimination.<br />(Th.II) Build transparency tools informing users on what their data reveal, how their data are being used, and techniques guaranteeing a fair use of their data. <br />(Th.III) Design incentives for systems leveraging users participation and/or data, to align individual?s interest with global efficiency.<br /><br />Outcomes: <br />- This 5+ year effort lead to 14 papers in tier-1 conferences like ACM SIGMETRICS, Web Conf, COSN, CCS, USENIX Security, multiple ones received nomination and awards. Those results were picked up by multiple media outlets (including, each for a different result, in The Washington Post, The New York Times bits blog, The Economist, MIT Technological Review and the Times of India). One article was downloaded more than 48,000 times, most of those articles are already cited, three of them more than 100 times.<br />- Six Ph.D students including 3 female and 1 Hispanic received direct support for their research through this project. Nine undergraduate students, including 5 female, 1 African American, 2 Hispanic conducted research and authored papers. One of them was a finalist (top-4) for the CRA Undergraduate Researcher award. Three of those are currently enrolled in Ph.D (Stanford and Berkeley). <br />- This research lead to new educational initiative, including three new tutorials given at ACM SIGMETRICS and The Web Conference, a revamped social network class to address the urgent needs to incorporate ethics of algorithmic impact, as well as educational project in collaboration with the school of Journalism and Social Work at Columbia.</p><br> <p>            Last Modified: 07/21/2019<br>      Modified by: Augustin&nbsp;Chaintreau</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ **Quick summary:** The overarching goal of my research and this NSF CAREER project is to reconcile the risk and value of personal data networking, by designing algorithms leveraging social mobile behaviors and incentives.  **Brief thematic overview**: Readers, bloggers, shoppers, are constantly seeking new information and sharing them using social networking tools. The mundane expectation is that by accessing and sharing more data, you certainly spend time and expose yourself but you are better informed to make important decisions. In other words, it?s worth the effort and the risk. But is it? How much are we actually aware about concrete risks? And are we really seeing that this process rewards its participants efficiently? What about when the data are collected and used without your awareness and consent?  Behavioral analytics leverage personal data about user behaviors collected and used for personalization, decision and optimization. It is arguably a historic driver of societal progress, but also one of the most controversial. It already challenges core values such as personal privacy and societal fairness in equal access to content and services.  Behavioral analytics so far are hindered by two main defects: - it provides *no transparency*: users are releasing information and permissions to use data without being aware of the induced risks and how the information they provide affects their service. At best they have crude information and guideline about which data are known and rarely how they are used. - it provides *no incentive*: users are generally facing a binary choice, convenience of a service free of charge in exchange of full data disclosure. At best, they are offered a coarse choice of opting-out of some personalization features.  This project, in contrast, works on providing transparency and incentive in today?s behavioral analytics: (Th.I) Quantify the threats posed by personal data disclosure across multiple domains, in the face of emerging plausible risks: re-identification across domains and discrimination. (Th.II) Build transparency tools informing users on what their data reveal, how their data are being used, and techniques guaranteeing a fair use of their data.  (Th.III) Design incentives for systems leveraging users participation and/or data, to align individual?s interest with global efficiency.  Outcomes:  - This 5+ year effort lead to 14 papers in tier-1 conferences like ACM SIGMETRICS, Web Conf, COSN, CCS, USENIX Security, multiple ones received nomination and awards. Those results were picked up by multiple media outlets (including, each for a different result, in The Washington Post, The New York Times bits blog, The Economist, MIT Technological Review and the Times of India). One article was downloaded more than 48,000 times, most of those articles are already cited, three of them more than 100 times. - Six Ph.D students including 3 female and 1 Hispanic received direct support for their research through this project. Nine undergraduate students, including 5 female, 1 African American, 2 Hispanic conducted research and authored papers. One of them was a finalist (top-4) for the CRA Undergraduate Researcher award. Three of those are currently enrolled in Ph.D (Stanford and Berkeley).  - This research lead to new educational initiative, including three new tutorials given at ACM SIGMETRICS and The Web Conference, a revamped social network class to address the urgent needs to incorporate ethics of algorithmic impact, as well as educational project in collaboration with the school of Journalism and Social Work at Columbia.       Last Modified: 07/21/2019       Submitted by: Augustin Chaintreau]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
