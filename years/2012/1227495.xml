<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Large: Collaborative Research: Purposeful Prediction: Co-robot Interaction via Understanding Intent and Goals</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>2146668.00</AwardTotalIntnAmount>
<AwardAmount>2175468</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In order for robots to collaborate with humans, they need to be able to accurately forecast human intent and action.  People act with purpose: that is, they make sequences of decisions to achieve long-term objectives. For instance, in driving from home to a store, people carefully plan a sequence of roads that will get them there efficiently. In predicting a person's next decision, algorithms must be developed that reflect these purposeful actions. &lt;br/&gt;&lt;br/&gt;Currently, robots are unable to anticipate human needs and goals, and this represents a fundamental barrier to their large-scale deployment in the home and workplace. The aim of this project is to develop a new science of purposeful prediction that can be applied to human-robot interaction across a wide variety of domains.  The work draws on recent techniques based on Inverse Optimal Control and Inverse Equilibria Theory that enable statistically sound reasoning about observed deliberate behavior. These new methods provide the foundations of a theoretical framework that integrates traditional decision making techniques like optimal control, search and planning with probabilistic methods that reason about uncertainty and hidden information, particularly about goals, utility and intent. &lt;br/&gt;&lt;br/&gt;Intellectual merit:  The project will provide a general framework that allows robots to anticipate and adapt to the activities of their human co-workers based on perceptual cues. The investigators will develop the theory, a computational toolbox, and, in collaboration with industrial partners, prototype deployments of these new methods for the prediction of peoples' behavior in a diverse set of robotics domains from computer vision to motor control. The project is transformative in that it combines a novel theoretical/algorithmic framework with extensive support in terms of volume of data and validation infrastructure in the context of many applications.        &lt;br/&gt;&lt;br/&gt;Broader impacts: A revolution in personal robotics in both the home and workplace depends on the ability to forecast human activities and intents; small- and medium- scale manufacturing will make a leap forward through agile robotic systems intelligent enough to understand and assist their co-workers in flexible assembly tasks; and robust models of pedestrian and vehicular traffic flow will enable more effective driver warning systems and safer autonomous mobile robots. Purposeful prediction technology is an important step towards enabling such understanding of actions and intents in these arenas. The research work will involve the training and mentoring of undergraduate, masters and doctoral students as well as post-doctoral fellows in this emerging multi-disciplinary research area at the intersection of computer and cognitive sciences and robotics.</AbstractNarration>
<MinAmdLetterDate>09/10/2012</MinAmdLetterDate>
<MaxAmdLetterDate>03/01/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1227495</AwardID>
<Investigator>
<FirstName>Martial</FirstName>
<LastName>Hebert</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Martial Hebert</PI_FULL_NAME>
<EmailAddress>martial.Hebert@cs.cmu.edu</EmailAddress>
<PI_PHON>4122682585</PI_PHON>
<NSF_ID>000225106</NSF_ID>
<StartDate>03/01/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Martial</FirstName>
<LastName>Hebert</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Martial Hebert</PI_FULL_NAME>
<EmailAddress>martial.Hebert@cs.cmu.edu</EmailAddress>
<PI_PHON>4122682585</PI_PHON>
<NSF_ID>000225106</NSF_ID>
<StartDate>09/10/2012</StartDate>
<EndDate>03/01/2017</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Anind</FirstName>
<LastName>Dey</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anind K Dey</PI_FULL_NAME>
<EmailAddress>anind@uw.edu</EmailAddress>
<PI_PHON>2066859937</PI_PHON>
<NSF_ID>000260331</NSF_ID>
<StartDate>09/10/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>James</FirstName>
<LastName>Bagnell</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James A Bagnell</PI_FULL_NAME>
<EmailAddress>dbagnell@ri.cmu.edu</EmailAddress>
<PI_PHON>4126818669</PI_PHON>
<NSF_ID>000483613</NSF_ID>
<StartDate>09/10/2012</StartDate>
<EndDate>03/01/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~501248</FUND_OBLG>
<FUND_OBLG>2013~825456</FUND_OBLG>
<FUND_OBLG>2014~840764</FUND_OBLG>
<FUND_OBLG>2015~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In order for robots to interact with people in a truly intelligent fashion, it is essential that they be able to <span>adapt and anticipate human activities based on perceptual cues. This Grant explored new approaches to endow intelligent systems with such abilities through multidisciplinary research drawing from the fields of Machine Learning, Computer Vision, psychology, social sciences and robotics. The main scientific achievements of the Grant are:</span></p> <p>&nbsp;</p> <ul> <li>New techniques for forecasting future actions from current observations, including in multi-agent environments, such in sports or interactions in crowded settings, involving complex interactions;&nbsp;</li> <li>A suite of new tools enabling learning and application of the predictive models in real-world setting such as learning from small samples, online learning from continously streaming data, learning predictive models for problems involving representations in high dimensions, and compensating for differences between enviroment in which the predictive models are learned and the ones in which they are used;</li> <li>New aproaches for long-term forecasting of visual data, e.g., the ability to predict&nbsp; future frames given a sample video, which is a crucial as,&nbsp;in practice, much of data is visual in nature.</li> <li>Formalization of common aspects of human behaviors such as modeling high-level routines, and learning how to extract them from observations, and modeling how to handle exceptions and interruptions; all of these aspects are central to describing, recognizing, and forecasting behavior at a sufficiently high level of abstraction.</li> </ul> <p>&nbsp;</p> <p>These fundamental technical contributions were instantiated in a number of concrete scenarios including robot teleoperation, intelligent interfaces, assistive systems, driving, sports analysis and social measurement.</p> <p>In robot teleoperation, we showed how, by recognizing intent, an intelligent system can jointly control a robotic system with a person, enabling unprecedented levels of collaboration. In intelligent interfaces, anticipating user actions leads to far more effective and smoother operations, in particular enabling disabled users to perform operations that would be otherwise impossible. In assistive system, predictive models enable detecting anomalous patterns in a person's routines. In driving, or more generally autonomous operation in crowded environments, detailed forecasting of agents' motions enables far more sophisticated planning. Finally, the predictive models can potentially enable the analysis of large amounts of sensor data, e.g., video data, which would not be possible otherwise.&nbsp;</p> <p>All of these examples were explored during the life of the award through experiments with robots and human subjects. The breadth of applications and their importance in real-world conditions illustrate the broad impact of the work conducted in the Grant.</p> <p><span><br /></span></p><br> <p>            Last Modified: 01/04/2018<br>      Modified by: Martial&nbsp;Hebert</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In order for robots to interact with people in a truly intelligent fashion, it is essential that they be able to adapt and anticipate human activities based on perceptual cues. This Grant explored new approaches to endow intelligent systems with such abilities through multidisciplinary research drawing from the fields of Machine Learning, Computer Vision, psychology, social sciences and robotics. The main scientific achievements of the Grant are:     New techniques for forecasting future actions from current observations, including in multi-agent environments, such in sports or interactions in crowded settings, involving complex interactions;  A suite of new tools enabling learning and application of the predictive models in real-world setting such as learning from small samples, online learning from continously streaming data, learning predictive models for problems involving representations in high dimensions, and compensating for differences between enviroment in which the predictive models are learned and the ones in which they are used; New aproaches for long-term forecasting of visual data, e.g., the ability to predict  future frames given a sample video, which is a crucial as, in practice, much of data is visual in nature. Formalization of common aspects of human behaviors such as modeling high-level routines, and learning how to extract them from observations, and modeling how to handle exceptions and interruptions; all of these aspects are central to describing, recognizing, and forecasting behavior at a sufficiently high level of abstraction.      These fundamental technical contributions were instantiated in a number of concrete scenarios including robot teleoperation, intelligent interfaces, assistive systems, driving, sports analysis and social measurement.  In robot teleoperation, we showed how, by recognizing intent, an intelligent system can jointly control a robotic system with a person, enabling unprecedented levels of collaboration. In intelligent interfaces, anticipating user actions leads to far more effective and smoother operations, in particular enabling disabled users to perform operations that would be otherwise impossible. In assistive system, predictive models enable detecting anomalous patterns in a person's routines. In driving, or more generally autonomous operation in crowded environments, detailed forecasting of agents' motions enables far more sophisticated planning. Finally, the predictive models can potentially enable the analysis of large amounts of sensor data, e.g., video data, which would not be possible otherwise.   All of these examples were explored during the life of the award through experiments with robots and human subjects. The breadth of applications and their importance in real-world conditions illustrate the broad impact of the work conducted in the Grant.          Last Modified: 01/04/2018       Submitted by: Martial Hebert]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
