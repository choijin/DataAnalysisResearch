<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Collaborative: Pursuing High Performance on Clouds and Other Dynamically Heterogeneous Computing Platforms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>184487.00</AwardTotalIntnAmount>
<AwardAmount>192487</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anita La Salle</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Emerging technologies have led to revolutionary computing platforms&lt;br/&gt;such as computing clouds and many genres of computing grids.  These&lt;br/&gt;platforms promise to make high-performance computing platforms&lt;br/&gt;accessible to the public.  Realizing this promise, though, requires&lt;br/&gt;one to cope with the platforms' dynamic heterogeneity, i.e., the fact&lt;br/&gt;that their constituent computers' relative powers and speeds can&lt;br/&gt;change at unpredictable times and in unpredictable ways; for instance,&lt;br/&gt;shared computers may slow down or speed up significantly because of&lt;br/&gt;unpredictable changes in workloads.  The research of the PIs is&lt;br/&gt;developing a transformative computing paradigm that will enable&lt;br/&gt;high-performance computing on these platforms.  The new paradigm&lt;br/&gt;replaces traditional schedulers' attempts to accommodate the&lt;br/&gt;particulars of a computing platform---a goal that dynamic&lt;br/&gt;heterogeneity confutes---by orchestrating a complex computation in a&lt;br/&gt;way that honors the relevant details of the computation's inherent&lt;br/&gt;structure.  In this way, the paradigm increases opportunities for&lt;br/&gt;executing independent tasks in parallel (i.e., simultaneously),&lt;br/&gt;thereby completing computations faster.  Preliminary assessments---via&lt;br/&gt;simulated competitions with common computation schedulers---suggest&lt;br/&gt;that the new paradigm often completes computations faster than&lt;br/&gt;competing strategies by double-digit percentages.  The challenge is to&lt;br/&gt;realize the paradigm in a computationally efficient manner, and the&lt;br/&gt;PIs are pursuing a variety of avenues toward achieving such&lt;br/&gt;efficiency.  Because of the complexity of dynamically heterogeneous&lt;br/&gt;platforms, this goal requires advances in the technology of both&lt;br/&gt;scheduling algorithms and simulation software.  The PIs are uniquely&lt;br/&gt;qualified to produce such advances because of their complementary&lt;br/&gt;expertise in algorithms, applications, and systems.</AbstractNarration>
<MinAmdLetterDate>09/10/2012</MinAmdLetterDate>
<MaxAmdLetterDate>05/30/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1217812</AwardID>
<Investigator>
<FirstName>Michela</FirstName>
<LastName>Taufer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michela Taufer</PI_FULL_NAME>
<EmailAddress>taufer@utk.edu</EmailAddress>
<PI_PHON>3026907845</PI_PHON>
<NSF_ID>000486752</NSF_ID>
<StartDate>09/10/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Delaware</Name>
<CityName>Newark</CityName>
<ZipCode>197160099</ZipCode>
<PhoneNumber>3028312136</PhoneNumber>
<StreetAddress>210 Hullihen Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<StateCode>DE</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DE00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>059007500</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF DELAWARE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>059007500</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Delaware]]></Name>
<CityName/>
<StateCode>DE</StateCode>
<ZipCode>197162553</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DE00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~184487</FUND_OBLG>
<FUND_OBLG>2013~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Moving computation into the Cloud raises the question of whether true high performance can be achieved. This question is especially challenging when the Cloud is dynamically heterogeneous and computations have inter-task dependencies constraining the tasks&rsquo; order of execution. In this project Arnold Rosenberg (Northeastern University), Rajmohan Rajaraman (Northeaster University), and Michela Taufer (University of Delaware) joined efforts to address this challenge. By integrating both computer algorithms and systems, our work aimed to develop, analyze, and evaluate new scheduling approaches to complex computations with inter-task dependencies on the Cloud. From the algorithms point of view, we focused on designing scheduling policies based on an intensive analysis of the computation structure and the average production rate enhancement for those tasks that are eligible for execution. In other words, our approach aimed to increase opportunities for simultaneous executions of those tasks exhibiting independence while minimizing the chance of a computation&rsquo;s stalling due to the completion of already allocated tasks. Results showed that such a schedule based on eligible-task-enhancement is computationally beneficial. From the systems point of view, we focused on developing software tools based on open-source Cloud frameworks such as Eucalyptus to simulate dynamically heterogeneous platforms efficiently and faithfully. These tools allowed us to evaluate the impact of our alternative schedules on a suite of relevant algorithms via rigorous experimentation. The use of open-source software enabled the development of new educational curricula that aimed to provide students with understanding of and training in the Cloud as well as high performance computing. The open-source software also facilitated the dissemination of our tools in tutorials and their use in the Cloud community.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/25/2015<br>      Modified by: Michela&nbsp;Taufer</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Moving computation into the Cloud raises the question of whether true high performance can be achieved. This question is especially challenging when the Cloud is dynamically heterogeneous and computations have inter-task dependencies constraining the tasksÆ order of execution. In this project Arnold Rosenberg (Northeastern University), Rajmohan Rajaraman (Northeaster University), and Michela Taufer (University of Delaware) joined efforts to address this challenge. By integrating both computer algorithms and systems, our work aimed to develop, analyze, and evaluate new scheduling approaches to complex computations with inter-task dependencies on the Cloud. From the algorithms point of view, we focused on designing scheduling policies based on an intensive analysis of the computation structure and the average production rate enhancement for those tasks that are eligible for execution. In other words, our approach aimed to increase opportunities for simultaneous executions of those tasks exhibiting independence while minimizing the chance of a computationÆs stalling due to the completion of already allocated tasks. Results showed that such a schedule based on eligible-task-enhancement is computationally beneficial. From the systems point of view, we focused on developing software tools based on open-source Cloud frameworks such as Eucalyptus to simulate dynamically heterogeneous platforms efficiently and faithfully. These tools allowed us to evaluate the impact of our alternative schedules on a suite of relevant algorithms via rigorous experimentation. The use of open-source software enabled the development of new educational curricula that aimed to provide students with understanding of and training in the Cloud as well as high performance computing. The open-source software also facilitated the dissemination of our tools in tutorials and their use in the Cloud community.           Last Modified: 12/25/2015       Submitted by: Michela Taufer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
