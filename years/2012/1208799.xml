<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Building a theoretical and methodological framework for collaborative statistical inference and learning: multi-party and multiphase paradigms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>360000.00</AwardTotalIntnAmount>
<AwardAmount>360000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Scientific data almost always undergo filtering, imputation, and other forms of preprocessing before they are analyzed. When such steps are taken, the data analysis becomes a collaborative endeavor by all parties involved in data collection, preprocessing, and inference. This research terms such settings as falling within the multiparty and multiphase paradigms for statistical inference and learning. These settings are rife with subtleties and pitfalls. Each party does not and often cannot have a perfect understanding of the entire phenomenon at hand; the final results will inevitably contain some combination of their judgments, and some preprocessing can irreversibly destroy information from the raw data.  Building upon his previous theory and methods for dealing with uncongeniality with multiple imputation, the PI and his students aim to develop a set of statistical theory and methods to understand such problems and to provide better preprocessing, inferences, and learning. Their ultimate goals include providing methods for assessing the validity of such collaborative analyses, guidance on statistically-principled preprocessing, and a rich new theory of statistical learning and inference with multiple parties. The theoretical framework they develop can shed light on principles and methods for constructing more useful scientific databases, handling complex measurement processes, and analyzing massive datasets.&lt;br/&gt;&lt;br/&gt;With the dramatic increases in the size, diversity, and complexity of data available for scientific discoveries, medical advances, education reforms and evidence-based policy making, the entire enterprise of quantitative scientific inquiry has been presented with unprecedented challenges and opportunities. The vast majority of current inquiries are not made by a single individual or even a single team. In particular, the analysis of scientific data depends heavily on preprocessing in practice. Following data collection, raw data is typically transformed into a more easily handled form. Such transformations range from innocuous to highly destructive. When poorly executed, they can destroy huge scientific investments by rendering them useless for future analyses. These dangers are rising in importance as scientists and funding agencies emphasize the construction of scientific repositories and "big data". Despite its importance, preprocessing is poorly understood from a theoretical perspective. Even among statisticians, conventional wisdom and informal guidance are the norm. The PI and his students will work to close this gap, building a theory of preprocessing and collaborative inference. This theory aims to guide the construction of scientific repositories and the analysis of massive datasets generated by the latest technologies. It can also open the doors to greater collaboration and access to high-quality scientific data, broadening the scientific enterprise.</AbstractNarration>
<MinAmdLetterDate>05/21/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/02/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208799</AwardID>
<Investigator>
<FirstName>Xiao-Li</FirstName>
<LastName>Meng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiao-Li Meng</PI_FULL_NAME>
<EmailAddress>meng@stat.harvard.edu</EmailAddress>
<PI_PHON>6174951603</PI_PHON>
<NSF_ID>000107265</NSF_ID>
<StartDate>05/21/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021382901</ZipCode>
<StreetAddress><![CDATA[1 Oxford St, 300C Science Cntr]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~115459</FUND_OBLG>
<FUND_OBLG>2013~119990</FUND_OBLG>
<FUND_OBLG>2014~124551</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>As described in the summary of this proposal, the dramatic increases in the size, diversity, and complexity of data available for scientific discoveries, medical advances, education reforms, and evidence-based policy making has presented unprecedented challenges and opportunities to the entire enterprise of scientific quantitative inquiry, with Statistics at its core. One large class of challenges is that it is no longer possible for a single individual or even a single team to conduct a scientific quantitative inquiry. The final quantitative learning therefore requires multi-team effort, with teams entering the process sequentially, from data collection, processing, curation, to analysis. &nbsp;Due to practical constraints such as resource limitations and confidentiality, each team involved in a given analysis may not have full knowledge of the assumptions made by, and resources and data available to, the teams coming before or after it. This fact compels statisticians to rethink the traditional inference and learning foundations built upon the premise of the popular single-phase framework. This research has constructed key building blocks for establishing a multi-phase inference paradigm, as recognized by multiple discussants of a key discussion paper under this grant, Xie and Meng (2016+, <em>Statistics Sinica</em>). They called it &ldquo;a paper that fundamentally broadens the perspective of applied statistics", and ``provides a new paradigm for a large class of practical problems,'' and &ldquo;(T)he original contribution of the paper is really timely, important, and insightful, inspiring more innovative thinking in both theory and practice.''</p> <p><strong>Intellectual Merit.</strong> &nbsp;Scientific data almost always undergo calibration, normalizing, imputation, and other forms of preprocessing before they are analyzed. When such steps are taken, the data analysis becomes a collaborative endeavor by all parties involved in data collection, preprocessing, and inference. Such settings are rife with subtleties and pitfalls. Each party does not and often cannot have a perfect understanding of the entire phenomenon at hand; the final results will inevitably contain some combination of their judgments, and some preprocessing can irreversibly destroy information from the raw data. This proposal developed a set of statistical theories and methods to understand such problems and to provide better preprocessing, inferences, and learning, especially in the setting of distributed learning. This research helps to provide methods for assessing when it is possible to minimize the loss of information due to pre-processing. The theoretical framework developed also sheds some light on principles and methods for distributed learning, as reported in another foundational paper under this grant, Blocker and Meng (2013, <em>Bernoulli</em>). This research not only built upon on previous work with multiple imputation (MI), a popular method for dealing with non-responses in survey data, especially for public-use data files, but it also led an in-depth investigation of MI inference under uncongeniality between imputers' and analysts' methods. The investigation revealed some theoretical results for multi-dimensional problems that were unexpected from their uni-dimensional counterparts.</p> <p><strong>Broader Impacts. &nbsp;</strong>This research, as proposed, established some theoretical building blocks of<strong> </strong>a general multiphase framework for collaborative statistical<strong> </strong>inference and learning, as well as a set of corresponding methods for analysis<strong> </strong>and evaluation. These building blocks and methods can help to increase access<strong> </strong>to scientific information and extend collaborations between statisticians and<strong> </strong>those involved in data processing and curation. This work focuses on settings<strong> </strong>where those collecting and preprocessing data have better knowledge of the raw<strong> </strong>data than subsequent analysts. By providing better ways to release useful,<strong> </strong>preprocessed data, these methods allow for broader participation in the<strong> </strong>scientific process, giving those without such intricate technical knowledge the<strong> </strong>ability to contribute on a level nearer that of experts.<strong> </strong>This access is also vital for education; students need experience with real data<strong> </strong>analysis as a core piece of scientific training. However, they are typically not<strong> </strong>ready to master the complex methods required to analyze &ldquo;raw'' data from<strong> </strong>state-of-the-art experiments and other sources. Providing better preprocessed<strong> </strong>data with well-mapped limitations will allow students to learn better data<strong> </strong>analysis practices and get them working closer to the leading edge of their<strong> </strong>fields. By putting Ph.D. students at the forefront of tackling emerging grand<strong> </strong>theoretical challenges at a foundational level, the proposal also addresses the<strong> </strong>increasingly urgent need to train future scholars who will deepen their<strong> </strong>discipline's foundation while expanding its horizon, a task that is vital for<strong> </strong>any discipline's long-term health and, generally, for scientific innovation and<strong> </strong>societal advancement. With these goals as stated in the original propose, the PI has used this research grant through various projects under this grant to help six Ph.D. students to complete their Ph.D. degrees at the Harvard Statistics Department, as well as an undergraduate student to complete a first-rate senior thesis.</p><br> <p>            Last Modified: 11/23/2016<br>      Modified by: Xiao-Li&nbsp;Meng</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ As described in the summary of this proposal, the dramatic increases in the size, diversity, and complexity of data available for scientific discoveries, medical advances, education reforms, and evidence-based policy making has presented unprecedented challenges and opportunities to the entire enterprise of scientific quantitative inquiry, with Statistics at its core. One large class of challenges is that it is no longer possible for a single individual or even a single team to conduct a scientific quantitative inquiry. The final quantitative learning therefore requires multi-team effort, with teams entering the process sequentially, from data collection, processing, curation, to analysis.  Due to practical constraints such as resource limitations and confidentiality, each team involved in a given analysis may not have full knowledge of the assumptions made by, and resources and data available to, the teams coming before or after it. This fact compels statisticians to rethink the traditional inference and learning foundations built upon the premise of the popular single-phase framework. This research has constructed key building blocks for establishing a multi-phase inference paradigm, as recognized by multiple discussants of a key discussion paper under this grant, Xie and Meng (2016+, Statistics Sinica). They called it "a paper that fundamentally broadens the perspective of applied statistics", and ``provides a new paradigm for a large class of practical problems,'' and "(T)he original contribution of the paper is really timely, important, and insightful, inspiring more innovative thinking in both theory and practice.''  Intellectual Merit.  Scientific data almost always undergo calibration, normalizing, imputation, and other forms of preprocessing before they are analyzed. When such steps are taken, the data analysis becomes a collaborative endeavor by all parties involved in data collection, preprocessing, and inference. Such settings are rife with subtleties and pitfalls. Each party does not and often cannot have a perfect understanding of the entire phenomenon at hand; the final results will inevitably contain some combination of their judgments, and some preprocessing can irreversibly destroy information from the raw data. This proposal developed a set of statistical theories and methods to understand such problems and to provide better preprocessing, inferences, and learning, especially in the setting of distributed learning. This research helps to provide methods for assessing when it is possible to minimize the loss of information due to pre-processing. The theoretical framework developed also sheds some light on principles and methods for distributed learning, as reported in another foundational paper under this grant, Blocker and Meng (2013, Bernoulli). This research not only built upon on previous work with multiple imputation (MI), a popular method for dealing with non-responses in survey data, especially for public-use data files, but it also led an in-depth investigation of MI inference under uncongeniality between imputers' and analysts' methods. The investigation revealed some theoretical results for multi-dimensional problems that were unexpected from their uni-dimensional counterparts.  Broader Impacts.  This research, as proposed, established some theoretical building blocks of a general multiphase framework for collaborative statistical inference and learning, as well as a set of corresponding methods for analysis and evaluation. These building blocks and methods can help to increase access to scientific information and extend collaborations between statisticians and those involved in data processing and curation. This work focuses on settings where those collecting and preprocessing data have better knowledge of the raw data than subsequent analysts. By providing better ways to release useful, preprocessed data, these methods allow for broader participation in the scientific process, giving those without such intricate technical knowledge the ability to contribute on a level nearer that of experts. This access is also vital for education; students need experience with real data analysis as a core piece of scientific training. However, they are typically not ready to master the complex methods required to analyze "raw'' data from state-of-the-art experiments and other sources. Providing better preprocessed data with well-mapped limitations will allow students to learn better data analysis practices and get them working closer to the leading edge of their fields. By putting Ph.D. students at the forefront of tackling emerging grand theoretical challenges at a foundational level, the proposal also addresses the increasingly urgent need to train future scholars who will deepen their discipline's foundation while expanding its horizon, a task that is vital for any discipline's long-term health and, generally, for scientific innovation and societal advancement. With these goals as stated in the original propose, the PI has used this research grant through various projects under this grant to help six Ph.D. students to complete their Ph.D. degrees at the Harvard Statistics Department, as well as an undergraduate student to complete a first-rate senior thesis.       Last Modified: 11/23/2016       Submitted by: Xiao-Li Meng]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
