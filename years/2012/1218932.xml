<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Natural Language-Based Human Instruction for Task Embedded Robots</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregory Chirikjian</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project will advance the scientific state of the art in social service robots by introducing a novel approach for performing, composing, and correcting tasks using spatial language, and for handling the challenges of long-term interaction with people. The team of investigators will leverage prior work on CoBot service robots as a scientific platform. CoBots can transport objects, deliver messages, escort people and go to places, continuously executing these tasks over multiple weeks in a multi-floor building. The team will collaborate to research, develop, and evaluate algorithms for learning, composing, and correcting the execution of tasks via natural language. The proposed research will enable any person to train the robot; we will use the CoBot robots to perform evaluation and testing of our proposed algorithms.&lt;br/&gt;&lt;br/&gt;The vision of a continuously operating robot in a real-world environment that can update its behavior in response to human instruction will have a broad impact on the way students, faculty and visitors interact with and view the usefulness of robots. Some examples include: (1) Customizable intelligent robots will give people the creative power to simply and intuitively update robot behavior, making the system broadly accessible to non-experts. (2) Outreach to the community will transform the view that robots are static unchangeable systems by creating an awareness towards robots co-inhabiting our environment. We will invite children of different age groups and people from different cultures to interact with our co-robot through language-based instruction. (3) Synergistic activities across multiple research groups have and will continue to be explored and encouraged (e.g., continuous environmental measurement and monitoring).</AbstractNarration>
<MinAmdLetterDate>08/31/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218932</AwardID>
<Investigator>
<FirstName>Manuela</FirstName>
<LastName>Veloso</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Manuela M Veloso</PI_FULL_NAME>
<EmailAddress>veloso@cs.cmu.edu</EmailAddress>
<PI_PHON>4122688464</PI_PHON>
<NSF_ID>000094404</NSF_ID>
<StartDate>08/31/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project enabled the investigation of methods for the instruction of tasks to robots through the use of natural language. The project was focused on representing verbal instructions in an instruction graph with sequences of actions, conditionals, and looping actions. The primitives in such instruction graphs correspond to robot motion and sensing primitives. The instruction graphs are interpreted and translated into finite-state machines executable by the robot. The human can also correct the instructed tasks, if such need is found during the robot execution. The results of the project were applied to our mobile CoBot service robots, where the instructed tasks refer to services of going to locations, or transporting items between different locations in our multi-floor environments. The CoBot robots dialog with humans until the language can be parsed and understood to match their service tasks, while they learn the corresponding groundings and improve their interaction with experience. The project also served as the precursor of the research in the use of  complex commands, with conjunctions, disjunctions, and conditionals for  robot task instruction and execution. A template-based approach was used  to extract simple commands and connectors from the complex commands,  complemented with dialog to address unresolved understanding. A corpus  of complex commands was gathered and used to show the successful  performance of the approach.</p><br> <p>            Last Modified: 12/15/2015<br>      Modified by: Manuela&nbsp;M&nbsp;Veloso</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project enabled the investigation of methods for the instruction of tasks to robots through the use of natural language. The project was focused on representing verbal instructions in an instruction graph with sequences of actions, conditionals, and looping actions. The primitives in such instruction graphs correspond to robot motion and sensing primitives. The instruction graphs are interpreted and translated into finite-state machines executable by the robot. The human can also correct the instructed tasks, if such need is found during the robot execution. The results of the project were applied to our mobile CoBot service robots, where the instructed tasks refer to services of going to locations, or transporting items between different locations in our multi-floor environments. The CoBot robots dialog with humans until the language can be parsed and understood to match their service tasks, while they learn the corresponding groundings and improve their interaction with experience. The project also served as the precursor of the research in the use of  complex commands, with conjunctions, disjunctions, and conditionals for  robot task instruction and execution. A template-based approach was used  to extract simple commands and connectors from the complex commands,  complemented with dialog to address unresolved understanding. A corpus  of complex commands was gathered and used to show the successful  performance of the approach.       Last Modified: 12/15/2015       Submitted by: Manuela M Veloso]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
