<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Large: Collaborative Research: Exploiting Duality between Meta-Algorithms and Complexity</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>1250000.00</AwardTotalIntnAmount>
<AwardAmount>1250000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Meta-algorithms are algorithms that take  other algorithms as input.&lt;br/&gt;Meta-algorithms are important in a variety of applications, from&lt;br/&gt;minimizing circuits in VLSI to verifying hardware and software to&lt;br/&gt;machine learning. Lower bound proofs show that computational problems&lt;br/&gt;are difficult in the sense of requiring a prohibitive&lt;br/&gt;amount of time, memory, or other resource to solve.&lt;br/&gt;This is particularly important in the context of cryptography,&lt;br/&gt;where it is vital to ensure that no feasible adversary can break&lt;br/&gt;a code. Surprisingly, recent research by the PIs and others&lt;br/&gt;shows that designing meta-algorithms is, in a formal sense, &lt;br/&gt;equivalent to proving lower bounds. In other words, one can prove a &lt;br/&gt;negative (the non-existence of a small circuit to solve a problem) by &lt;br/&gt;a positive (devising a new meta-algorithm).  This was the key to a &lt;br/&gt;breakthrough by PI Williams, proving lower bounds on constant &lt;br/&gt;depth circuits with modular arithmetic gates.&lt;br/&gt;&lt;br/&gt;The proposed research will utilize this connection both to&lt;br/&gt;design new meta-algorithms and to prove new lower bounds.&lt;br/&gt;A primary focus will be on meta-algorithms for&lt;br/&gt;deciding if a given algorithm is 'trivial' or not, such as algorithms&lt;br/&gt;for the Boolean satisfiability problem.  The proposed research will devise new&lt;br/&gt;algorithms that improve over exhaustive search for many variants&lt;br/&gt;of satisfiability.  On the other hand, it will also explore&lt;br/&gt;complexity-theoretic limitations on how much improvement is&lt;br/&gt;possible, using reductions and lower bounds for restricted&lt;br/&gt;models. Satisfiability will provide a starting point for a more&lt;br/&gt;general understanding of the exact complexities of other NP-complete&lt;br/&gt;problems such as the traveling salesman problem and k-colorability.&lt;br/&gt;The proposal addresses both worst-case performance and the use&lt;br/&gt;of fast algorithms as heuristics for solving this problem.&lt;br/&gt;&lt;br/&gt;This exploration will be mainly mathematical.  However, when&lt;br/&gt;new algorithms and heuristics are developed, they will be&lt;br/&gt;implemented and the resulting software made widely available.&lt;br/&gt;This research will be incorporated in courses taught by&lt;br/&gt;the PI's, at both graduate and undergraduate levels.&lt;br/&gt;Both graduate and undergraduate students will perform research&lt;br/&gt;as part of the project.</AbstractNarration>
<MinAmdLetterDate>06/20/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/10/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1213151</AwardID>
<Investigator>
<FirstName>Samuel</FirstName>
<LastName>Buss</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Samuel R Buss</PI_FULL_NAME>
<EmailAddress>sbuss@ucsd.edu</EmailAddress>
<PI_PHON>8585346455</PI_PHON>
<NSF_ID>000259320</NSF_ID>
<StartDate>06/20/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ramamohan</FirstName>
<LastName>Paturi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Prof</PI_SUFX_NAME>
<PI_FULL_NAME>Ramamohan Paturi</PI_FULL_NAME>
<EmailAddress>paturi@cs.ucsd.edu</EmailAddress>
<PI_PHON>8585346658</PI_PHON>
<NSF_ID>000210626</NSF_ID>
<StartDate>06/20/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Russell</FirstName>
<LastName>Impagliazzo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Russell Impagliazzo</PI_FULL_NAME>
<EmailAddress>russell@cs.ucsd.edu</EmailAddress>
<PI_PHON>8585341332</PI_PHON>
<NSF_ID>000110864</NSF_ID>
<StartDate>06/20/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930404</ZipCode>
<StreetAddress><![CDATA[Department of Computer Science]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7927</Code>
<Text>COMPLEXITY &amp; CRYPTOGRAPHY</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~679264</FUND_OBLG>
<FUND_OBLG>2013~279564</FUND_OBLG>
<FUND_OBLG>2015~291172</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual merit:</p> <p>Theoretical computer science concerns itsefl with the computational resources, such as number of operations or bits of memory, needed for a computer to solve a computational problem.&nbsp; Traditionally, this is divided into two sub-fields: algorithm design, seeking new ways of&nbsp; solving problems quickly or with few resources; and computational complexity, characterizing those problems that are ``hard'' in that they require large amount of resources.&nbsp; Our research utilizes pardoxical connections between these two areas to make progress on both.&nbsp; We utilize reasons why some problems are difficult to design new algorithms that solve other problems more efficiently, and utilize new algorithms for some problems to show others are difficult.&nbsp;</p> <p>As an example, we designed a new learning algorithm that, from random labelled examples of a function of a certain type (that can be expressed witha small number of&nbsp; layers of and, or and parity gates) , deduces how to compute the function.&nbsp; This solved a problem that had been open for twenty-five years, and won the Best Paper Award in CCC 16.&nbsp; This algorithm is completely different from any in the previous learning theory literature, because it combines two ideas from complexity theory:&nbsp; the circuit size lower bound of Smolensky and Razborov and the way to remove randomness from algorithms of Nisan and Wigderson.&nbsp;</p> <p>We also bridge another divide, showing connections between the difficulty of ``very hard'' problems that require exponential time and those that are relatively easy, but where algorithm designers are stil working to make further improvements.&nbsp;</p> <p>For example, the stable marriage problem was introduced by Gale (and was cited in his Nobel Prize for Economics as a major contribution).&nbsp; The problem is to match partners in&nbsp; a way that each prefers to be together than to split up.&nbsp; It is widely used for applications such as pairing medical residents with hospitals.&nbsp; It has a reasonably efficient algorithm, but if the input is described succinctly, one could hope to improve it.&nbsp; We examined this problem from a complexity-theoretic viewpoint.&nbsp; We obtained both new algorithms for many special cases of stable marriage, and hardness results, showing that improving algorithms for other cases would violate a widely-held conjecture about the complexity of NP-complete problems.</p> <p>We also made progress on understanding the complexity of hard problems, such as Satisfiability.&nbsp; New algorithms for hard problems were designed, many using circuit lower bound arguments.&nbsp; Somewhat paradoxically, satisfiability is both a known hard problem, and a problem where heuristic algorithms solve many typical instances.&nbsp; We used proof complexity to characterize both the power and limitations of different heuristic methods; for example, we gave provable examples where the new clause learning technique is superior to any implementation of the more old-fashioned Davis-Putnam style algorithms.&nbsp; We also showed the first examples where memory restrictions would cost a SAT-solver&nbsp; a huge amount of time, even if the memory is&nbsp; much larger&nbsp; than the input formula.</p> <p>Broader impact:</p> <p>The divide between algorithm design and computational complexity was social as well as technical.&nbsp; Since researchers in the two communities are not used to each other's ideas and approaches, and have mostly worked separately, technical results explaining the connections between the two areas do not automatically create collaborations between the fields.&nbsp;&nbsp; With this in mind, we organized a special semester at the Simons Insitute in Berkeley to bring together the two groups of researchers.&nbsp; This semester program was very successful, both in terms of the research that was performed during the semester (solving many open problems and launching many new directions), and&nbsp; in creating collaborations between algorithm designer s and complexity theorists.&nbsp; Moreover, many young researchers became involved and interested in this new approach.</p> <p>We also looked for ways to use theoretical ideas to improve undergraduate education.&nbsp; One way we did this is by directly involving undergraduates in our reseach, such as Cody Murray, now a Ph.D. student at MIT working with non-UCSD PI Wlliiams.&nbsp; We also used algorithmic problems that came up in our research as example problems in undergraduate courses.&nbsp; Finally, some of us were instrumental in creating programs to ease the transition into the computer science major for new&nbsp; undergraduates with little computing experience.</p><br> <p>            Last Modified: 11/28/2017<br>      Modified by: Ramamohan&nbsp;Paturi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual merit:  Theoretical computer science concerns itsefl with the computational resources, such as number of operations or bits of memory, needed for a computer to solve a computational problem.  Traditionally, this is divided into two sub-fields: algorithm design, seeking new ways of  solving problems quickly or with few resources; and computational complexity, characterizing those problems that are ``hard'' in that they require large amount of resources.  Our research utilizes pardoxical connections between these two areas to make progress on both.  We utilize reasons why some problems are difficult to design new algorithms that solve other problems more efficiently, and utilize new algorithms for some problems to show others are difficult.   As an example, we designed a new learning algorithm that, from random labelled examples of a function of a certain type (that can be expressed witha small number of  layers of and, or and parity gates) , deduces how to compute the function.  This solved a problem that had been open for twenty-five years, and won the Best Paper Award in CCC 16.  This algorithm is completely different from any in the previous learning theory literature, because it combines two ideas from complexity theory:  the circuit size lower bound of Smolensky and Razborov and the way to remove randomness from algorithms of Nisan and Wigderson.   We also bridge another divide, showing connections between the difficulty of ``very hard'' problems that require exponential time and those that are relatively easy, but where algorithm designers are stil working to make further improvements.   For example, the stable marriage problem was introduced by Gale (and was cited in his Nobel Prize for Economics as a major contribution).  The problem is to match partners in  a way that each prefers to be together than to split up.  It is widely used for applications such as pairing medical residents with hospitals.  It has a reasonably efficient algorithm, but if the input is described succinctly, one could hope to improve it.  We examined this problem from a complexity-theoretic viewpoint.  We obtained both new algorithms for many special cases of stable marriage, and hardness results, showing that improving algorithms for other cases would violate a widely-held conjecture about the complexity of NP-complete problems.  We also made progress on understanding the complexity of hard problems, such as Satisfiability.  New algorithms for hard problems were designed, many using circuit lower bound arguments.  Somewhat paradoxically, satisfiability is both a known hard problem, and a problem where heuristic algorithms solve many typical instances.  We used proof complexity to characterize both the power and limitations of different heuristic methods; for example, we gave provable examples where the new clause learning technique is superior to any implementation of the more old-fashioned Davis-Putnam style algorithms.  We also showed the first examples where memory restrictions would cost a SAT-solver  a huge amount of time, even if the memory is  much larger  than the input formula.  Broader impact:  The divide between algorithm design and computational complexity was social as well as technical.  Since researchers in the two communities are not used to each other's ideas and approaches, and have mostly worked separately, technical results explaining the connections between the two areas do not automatically create collaborations between the fields.   With this in mind, we organized a special semester at the Simons Insitute in Berkeley to bring together the two groups of researchers.  This semester program was very successful, both in terms of the research that was performed during the semester (solving many open problems and launching many new directions), and  in creating collaborations between algorithm designer s and complexity theorists.  Moreover, many young researchers became involved and interested in this new approach.  We also looked for ways to use theoretical ideas to improve undergraduate education.  One way we did this is by directly involving undergraduates in our reseach, such as Cody Murray, now a Ph.D. student at MIT working with non-UCSD PI Wlliiams.  We also used algorithmic problems that came up in our research as example problems in undergraduate courses.  Finally, some of us were instrumental in creating programs to ease the transition into the computer science major for new  undergraduates with little computing experience.       Last Modified: 11/28/2017       Submitted by: Ramamohan Paturi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
