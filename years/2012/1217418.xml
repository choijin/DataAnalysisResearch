<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Application-Specific Memory System Optimizations using Programmable Memory Controllers</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>tao li</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The off-chip memory subsystem is a significant performance and power bottleneck in modern computer systems, necessitating a memory controller that can overcome memory timing and resource constraints by carefully orchestrating data movement between the processor and main memory. The goal of this project is to address this need by enabling application-specific memory system optimizations using a programmable main memory controller, thereby improving the performance, energy-efficiency, and quality-of-service of future computer systems. To realize this vision of programmable main memory controllers, the project addresses challenges all the way from the hardware design of programmable processing units to the firmware implementation of novel memory management algorithms. Automated machine learning and search techniques are employed to quickly arrive at high-performance control algorithms customized to different applications, and to different phases of a single application. Application-specific memory management algorithms ranging from address mapping, command scheduling, and DRAM power management to error-correcting codes and memory compression are developed.&lt;br/&gt;&lt;br/&gt;The flexibility of the resulting application-specific memory systems is expected to have a direct impact on the performance and energy-efficiency of future computer systems, with tremendous positive fallout to science, technology, and society as a whole. Architecture and software innovations are disseminated to the broader research community through published papers, as well as tutorials on programmable controllers and application-specific memory controller algorithms at major conferences. The educational component of the project involves (1) training both graduate and undergraduate students in computer architecture, (2) a memory systems course that integrates programmable memory controllers and next-generation memory systems into the syllabus, and (3) a memory controller design experience for undergraduates as part of the existing computer architecture curriculum.</AbstractNarration>
<MinAmdLetterDate>06/25/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/25/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1217418</AwardID>
<Investigator>
<FirstName>Engin</FirstName>
<LastName>Ipek</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Engin Ipek</PI_FULL_NAME>
<EmailAddress>ipek@cs.rochester.edu</EmailAddress>
<PI_PHON>5852751420</PI_PHON>
<NSF_ID>000552279</NSF_ID>
<StartDate>06/25/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146270140</ZipCode>
<StreetAddress><![CDATA[518 Hylan]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>Since the early 2000s, power has been the central problem that limits the performance of computer systems, from datacenters to smartphones and wearable devices. Since data movement is a primary contributor to power dissipation</span><span>, minimizing data movement is a first order design constraint for future computer systems.&nbsp;</span></p> </div> </div> </div> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>As part of this project, &nbsp;a new class of energy-efficient computer architectures that aim at minimizing data movement, and improving memory bandwidth efficiency were explored. The specific contributions include the first proposal for a programmable DRAM memory controller, a new data encoding technique using synchronized counters, and a novel memory bandwidth optimization technique using erasure codes. Three Ph.D. students were trained in computer architecture, and a total of five articles were published and disseminated to the broader research community.</span></p> </div> </div> </div> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><strong>Programmable DRAM Memory Controllers. </strong><span>Modern dynamic random access memory (DRAM) controllers employ sophisticated address mapping, command scheduling, and power management optimizations to alleviate the adverse effects of DRAM timing and resource constraints on system performance. These optimizations must satisfy different system requirements, which complicates memory controller design. Not only is it challenging to satisfy multiple conflicting performance requirements in a hardwired memory controller, but also it is not possible to incorporate application-specific optimizations into control policies implemented in fixed-function hardware. A promising way of improving the versatility and energy efficiency of these controllers is to make them programmable. Unfortunately, the stringent latency and throughput requirements of modern DRAM devices have rendered such programmability largely impractical, confining DRAM controllers to fixed-function hardware. As compared to a hardwired memory controller, a programmable controller may result in slower request processing, thereby decreasing throughput. In addition, as a result of instruction processing overheads, the control firmware may add extra latency to every memory access. Moreover, the power dissipation and area overheads of the controller may become limiting factors.&nbsp;</span></p> <p><span>In </span><span>ISCA 2012</span><span>, we propose a fully programmable DRAM controller that receives read and write requests from the last level cache, and manages DRAM data and command processing to optimize system power and performance.</span><span>&nbsp;The proposed programmable memory controller exhibits a significant improvement over today&rsquo;s rigid and relatively inefficient systems, and holds the promise of solving some of the key energy problems in next-generation memory interfaces.&nbsp;</span></p> <p><span>&nbsp;</span>This work was selected as one of the 11 most significant papers of 2012 by IEEE Micro based on novelty and potential for long term impact (IEEE Top Picks 2012). In addition, an invited journal article was published in the ACM Transactions on Computer Systems. The paper was also considered by industry; in particular, researchers at the Intelligent Memory Systems Lab of Samsung Information Systems America (SISA) showed their interest in the proposed programmable DDRx controller, and collaborated with us in transferring the technology to an SoC developed for mobile platforms.&nbsp;</p> </div> </div> </div> <div class="page" title="Page 2"> <div class="layoutArea"> <div class="column"> <p><strong>Energy Efficient Data Movement in Large Last Level Caches. </strong><span>Industry often employs large last level caches (LLCs) to bridge the performance and power gaps between the processor cores and main memory. The increasing cache sizes in modern microprocessors require long wires to connect the data arrays and the processing cores. As a result, the LLC has become a major contributor to the processor energy, which necessitates techniques to increase the energy efficiency of data movement over the long LLC interconnects. </span></p> <p><span>In </span><span>MICRO 2013</span><span>, we presented a novel, energy-efficient data exchange mechanism using synchronized counters. The key idea is to represent information by the delay between two consecutive pulses on a set of wires connecting the data arrays to the cache controller. This time-based data representation makes the number of state transitions on the interconnect independent of the bit patterns, and significantly lowers the activity factor on the interconnect. We also present a viable hardware implementation of the proposed mechanism that incurs negligible area and delay overheads. </span></p> <p>In ICCD 2015<span>, we present novel signaling and encoding techniques that together improve the energy efficiency of data communication between the processor cores and the last level cache. </span><span>Compared to conventional binary codes, the proposed combination of sparse encoding and transition signaling enables energy-efficient data movement for point-to-point on-chip interconnects. </span></p> <p><strong>Energy Efficient Hybrid Memory Cube Systems. </strong><span>In addition to conventional DDRx systems, we also consider improving the energy- and bandwidth-efficiency of next generation memory interfaces. The Hybrid Memory Cube (HMC) is a promising alternative to double-data rate (DDRx) memory due to its potential to achieve significantly higher bandwidth. However, the high static power of an HMC device compromises power efficiency when the device is lightly utilized. </span><span>In </span><span>ISLPED 2015</span><span>, we introduce a new technique that alleviates the long wake-up penalty of an HMC by employing </span><span>erasure codes</span><span>. Inaccessible data stored in a sleeping HMC module can be reconstructed by decoding the related data retrieved from other active HMCs, rather than waiting for the sleeping HMC module to become active.&nbsp;</span></p> <p><span><br /></span></p> </div> </div> </div><br> <p>            Last Modified: 11/13/2016<br>      Modified by: Engin&nbsp;Ipek</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    Since the early 2000s, power has been the central problem that limits the performance of computer systems, from datacenters to smartphones and wearable devices. Since data movement is a primary contributor to power dissipation, minimizing data movement is a first order design constraint for future computer systems.         As part of this project,  a new class of energy-efficient computer architectures that aim at minimizing data movement, and improving memory bandwidth efficiency were explored. The specific contributions include the first proposal for a programmable DRAM memory controller, a new data encoding technique using synchronized counters, and a novel memory bandwidth optimization technique using erasure codes. Three Ph.D. students were trained in computer architecture, and a total of five articles were published and disseminated to the broader research community.        Programmable DRAM Memory Controllers. Modern dynamic random access memory (DRAM) controllers employ sophisticated address mapping, command scheduling, and power management optimizations to alleviate the adverse effects of DRAM timing and resource constraints on system performance. These optimizations must satisfy different system requirements, which complicates memory controller design. Not only is it challenging to satisfy multiple conflicting performance requirements in a hardwired memory controller, but also it is not possible to incorporate application-specific optimizations into control policies implemented in fixed-function hardware. A promising way of improving the versatility and energy efficiency of these controllers is to make them programmable. Unfortunately, the stringent latency and throughput requirements of modern DRAM devices have rendered such programmability largely impractical, confining DRAM controllers to fixed-function hardware. As compared to a hardwired memory controller, a programmable controller may result in slower request processing, thereby decreasing throughput. In addition, as a result of instruction processing overheads, the control firmware may add extra latency to every memory access. Moreover, the power dissipation and area overheads of the controller may become limiting factors.   In ISCA 2012, we propose a fully programmable DRAM controller that receives read and write requests from the last level cache, and manages DRAM data and command processing to optimize system power and performance. The proposed programmable memory controller exhibits a significant improvement over today?s rigid and relatively inefficient systems, and holds the promise of solving some of the key energy problems in next-generation memory interfaces.    This work was selected as one of the 11 most significant papers of 2012 by IEEE Micro based on novelty and potential for long term impact (IEEE Top Picks 2012). In addition, an invited journal article was published in the ACM Transactions on Computer Systems. The paper was also considered by industry; in particular, researchers at the Intelligent Memory Systems Lab of Samsung Information Systems America (SISA) showed their interest in the proposed programmable DDRx controller, and collaborated with us in transferring the technology to an SoC developed for mobile platforms.         Energy Efficient Data Movement in Large Last Level Caches. Industry often employs large last level caches (LLCs) to bridge the performance and power gaps between the processor cores and main memory. The increasing cache sizes in modern microprocessors require long wires to connect the data arrays and the processing cores. As a result, the LLC has become a major contributor to the processor energy, which necessitates techniques to increase the energy efficiency of data movement over the long LLC interconnects.   In MICRO 2013, we presented a novel, energy-efficient data exchange mechanism using synchronized counters. The key idea is to represent information by the delay between two consecutive pulses on a set of wires connecting the data arrays to the cache controller. This time-based data representation makes the number of state transitions on the interconnect independent of the bit patterns, and significantly lowers the activity factor on the interconnect. We also present a viable hardware implementation of the proposed mechanism that incurs negligible area and delay overheads.   In ICCD 2015, we present novel signaling and encoding techniques that together improve the energy efficiency of data communication between the processor cores and the last level cache. Compared to conventional binary codes, the proposed combination of sparse encoding and transition signaling enables energy-efficient data movement for point-to-point on-chip interconnects.   Energy Efficient Hybrid Memory Cube Systems. In addition to conventional DDRx systems, we also consider improving the energy- and bandwidth-efficiency of next generation memory interfaces. The Hybrid Memory Cube (HMC) is a promising alternative to double-data rate (DDRx) memory due to its potential to achieve significantly higher bandwidth. However, the high static power of an HMC device compromises power efficiency when the device is lightly utilized. In ISLPED 2015, we introduce a new technique that alleviates the long wake-up penalty of an HMC by employing erasure codes. Inaccessible data stored in a sleeping HMC module can be reconstructed by decoding the related data retrieved from other active HMCs, rather than waiting for the sleeping HMC module to become active.              Last Modified: 11/13/2016       Submitted by: Engin Ipek]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
