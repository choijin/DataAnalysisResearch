<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TWC: Frontier: Privacy Tools for Sharing Research Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>03/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>4863840.00</AwardTotalIntnAmount>
<AwardAmount>6048707</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Information technology, advances in statistical computing, and the deluge of data available through the Internet are transforming computational social science. However, a major challenge is maintaining the privacy of human subjects. This project is a broad, multidisciplinary effort to help enable the collection, analysis, and sharing of sensitive data while providing privacy for individual subjects.  Bringing together computer science, social science, statistics, and law, the investigators seek to refine and develop definitions and measures of privacy and data utility, and design an array of technological, legal, and policy tools for dealing with sensitive data. In addition to contributing to research infrastructure around the world, the ideas developed in this project will benefit society more broadly as it grapples with data privacy issues in many other domains, including public health and electronic commerce.&lt;br/&gt; &lt;br/&gt;This project will define and measure privacy in both mathematical and legal terms, and explore alternate definitions of privacy that may be more general or more practical.  The project will study variants of differential privacy and develop new theoretical results for use in contexts where it is currently inappropriate or impractical. The research will provide a better understanding of the practical performance and usability of a variety of algorithms for analyzing and sharing privacy-sensitive data. The project will develop secure implementations of these algorithms and legal instruments, which will be made publicly available and used to enable wider access to privacy-sensitive data sets at the Harvard Institute for Quantitative Social Science's Dataverse Network.</AbstractNarration>
<MinAmdLetterDate>09/19/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/12/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1237235</AwardID>
<Investigator>
<FirstName>Gary</FirstName>
<LastName>King</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gary King</PI_FULL_NAME>
<EmailAddress>king@harvard.edu</EmailAddress>
<PI_PHON>6174952027</PI_PHON>
<NSF_ID>000160261</NSF_ID>
<StartDate>09/19/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Salil</FirstName>
<LastName>Vadhan</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Salil P Vadhan</PI_FULL_NAME>
<EmailAddress>salil_vadhan@harvard.edu</EmailAddress>
<PI_PHON>6174960439</PI_PHON>
<NSF_ID>000138824</NSF_ID>
<StartDate>09/19/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Latanya</FirstName>
<LastName>Sweeney</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Latanya Sweeney</PI_FULL_NAME>
<EmailAddress>latanya@fas.harvard.edu</EmailAddress>
<PI_PHON>6174963629</PI_PHON>
<NSF_ID>000346506</NSF_ID>
<StartDate>09/19/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Edoardo</FirstName>
<LastName>Airoldi</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edoardo M Airoldi</PI_FULL_NAME>
<EmailAddress>airoldi@temple.edu</EmailAddress>
<PI_PHON>6176970608</PI_PHON>
<NSF_ID>000516839</NSF_ID>
<StartDate>09/19/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Urs</FirstName>
<LastName>Gasser</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Urs Gasser</PI_FULL_NAME>
<EmailAddress>ugasser@cyber.law.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000552941</NSF_ID>
<StartDate>08/08/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Phillip</FirstName>
<LastName>Malone</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Phillip R Malone</PI_FULL_NAME>
<EmailAddress>pmalome@cyber.law.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000581960</NSF_ID>
<StartDate>09/19/2012</StartDate>
<EndDate>08/08/2013</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021382933</ZipCode>
<StreetAddress><![CDATA[33 Oxford Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>8087</Code>
<Text>Frontiers in SaTC</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~1130125</FUND_OBLG>
<FUND_OBLG>2013~1199482</FUND_OBLG>
<FUND_OBLG>2014~1287304</FUND_OBLG>
<FUND_OBLG>2015~1323029</FUND_OBLG>
<FUND_OBLG>2016~1052767</FUND_OBLG>
<FUND_OBLG>2017~56000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-97152a5b-f09f-e83a-159c-c2a7454c0a7e"> </span></p> <p dir="ltr"><span>Computing technology and vast new sources of data are transforming the social sciences. With the ability to collect and analyze massive amounts of data on human behavior and interactions, social scientists can hope to uncover many more phenomena, with greater detail and confidence, than allowed by traditional means such as surveys and interviews. In addition to advancing the state of knowledge, the rich analysis of behavioral data can enable companies to better serve their customers, and governments their citizenry. However, a major challenge for computational social science is maintaining the privacy of human subjects. &nbsp;At present, an individual social science researcher is left to devise her own privacy shields, such as stripping the dataset of &ldquo;personally identifiable information&rdquo; (PII). However, such privacy shields are often ineffective and provide limited or no real-world privacy protection. Indeed, there have been a number of cases where the individuals in a supposedly anonymized dataset have been re-identified. </span></p> <p dir="ltr"><span>This project was a broad, multidisciplinary effort to help enable the collection, analysis, and sharing of sensitive research data while providing strong privacy protections for individual research subjects. Bringing together computer science, social science, statistics, and law, the investigators refined and developed definitions and measures of privacy and data utility, and designed an integrated array of technological, legal, and policy tools for dealing with sensitive research data. </span></p> <p dir="ltr"><span>In the year after the project&rsquo;s completion, some of these tools will be deployed in digital data repositories around the world, offering the potential to have a large impact on many fields of human subject research, including social science, medicine, public health, and economics. &nbsp;Specifically, the project&rsquo;s &ldquo;DataTags&rdquo; tool will enable an owner of a privacy-sensitive dataset to select a policy for the repository&rsquo;s handling and sharing of the dataset, informed by relevant laws and best practices; the project&rsquo;s &ldquo;Robot Lawyers&rdquo; tool will generate customized Data Use Agreements for the repository to use when sharing the dataset with other researchers; and the project&rsquo;s &ldquo;PSI&rdquo; tool will provide a much wider set of users statistical access to this dataset with the strong privacy protections of &ldquo;differential privacy.&rdquo;</span></p> <p dir="ltr"><span>The intellectual contributions of the project include extensive mathematical work delineating the fundamental tradeoffs between privacy protection and statistical utility, an understanding of how mathematical and legal conceptions of privacy can be related to each other, and methods for automating reasoning about legal privacy requirements in order to generate custom data-sharing licenses. &nbsp;&nbsp;Many of the project&rsquo;s contributions required extensive interdisciplinary collaboration, resulting in papers whose authors and publication venues span computer science, law, statistics, and social science.  A number of the advances in the project relate to &ldquo;differential privacy,&rdquo; a powerful mathematical framework for protecting privacy when performing statistical analysis of sensitive data, which emerged from the theoretical computer science literature and has recently found large-scale practical deployments by Apple, Google, and the US Census Bureau. &nbsp;The &ldquo;PSI&rdquo; tool produced in the project is unique in enabling differential privacy to be used effectively by practicing social science researchers, with no specialized expertise in privacy, computer science, or statistics. </span></p> <p dir="ltr"><span>In addition to bringing data privacy solutions to practice in the sharing of research data, the project achieves broader impacts by exposing a multidisciplinary understanding of data privacy to a wide range of audiences. &nbsp;It has achieved this through organizing several workshops and symposia (including a public symposium with over 700 registrants), training many students in multidisciplinary research (including over 125 research assistants from computer science, law, social science, and statistics), sharing extensive policy recommendations and best practices with policymakers, practitioners, and the general public, and producing numerous open-access pedagogical materials.</span></p> <p dir="ltr"><span>Moreover, the ideas developed in this project will benefit society more broadly as it grapples with data privacy issues in many other domains, including national security, electronic commerce, public health, and government operations and accountability. &nbsp;Indeed, this project spawned a number of offshoot efforts on data privacy in these various domains, including helping the US Census Bureau and other government agencies adopt more modern privacy methods starting with the 2020 Decennial Census, an exploration of better methods for companies to analyze their user data in a privacy-protective manner, and the development of a new model for industry-academic partnerships to carry out social science research on sensitive corporate data.</span></p><br> <p>            Last Modified: 07/31/2018<br>      Modified by: Salil&nbsp;P&nbsp;Vadhan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Computing technology and vast new sources of data are transforming the social sciences. With the ability to collect and analyze massive amounts of data on human behavior and interactions, social scientists can hope to uncover many more phenomena, with greater detail and confidence, than allowed by traditional means such as surveys and interviews. In addition to advancing the state of knowledge, the rich analysis of behavioral data can enable companies to better serve their customers, and governments their citizenry. However, a major challenge for computational social science is maintaining the privacy of human subjects.  At present, an individual social science researcher is left to devise her own privacy shields, such as stripping the dataset of "personally identifiable information" (PII). However, such privacy shields are often ineffective and provide limited or no real-world privacy protection. Indeed, there have been a number of cases where the individuals in a supposedly anonymized dataset have been re-identified.  This project was a broad, multidisciplinary effort to help enable the collection, analysis, and sharing of sensitive research data while providing strong privacy protections for individual research subjects. Bringing together computer science, social science, statistics, and law, the investigators refined and developed definitions and measures of privacy and data utility, and designed an integrated array of technological, legal, and policy tools for dealing with sensitive research data.  In the year after the project?s completion, some of these tools will be deployed in digital data repositories around the world, offering the potential to have a large impact on many fields of human subject research, including social science, medicine, public health, and economics.  Specifically, the project?s "DataTags" tool will enable an owner of a privacy-sensitive dataset to select a policy for the repository?s handling and sharing of the dataset, informed by relevant laws and best practices; the project?s "Robot Lawyers" tool will generate customized Data Use Agreements for the repository to use when sharing the dataset with other researchers; and the project?s "PSI" tool will provide a much wider set of users statistical access to this dataset with the strong privacy protections of "differential privacy." The intellectual contributions of the project include extensive mathematical work delineating the fundamental tradeoffs between privacy protection and statistical utility, an understanding of how mathematical and legal conceptions of privacy can be related to each other, and methods for automating reasoning about legal privacy requirements in order to generate custom data-sharing licenses.   Many of the project?s contributions required extensive interdisciplinary collaboration, resulting in papers whose authors and publication venues span computer science, law, statistics, and social science.  A number of the advances in the project relate to "differential privacy," a powerful mathematical framework for protecting privacy when performing statistical analysis of sensitive data, which emerged from the theoretical computer science literature and has recently found large-scale practical deployments by Apple, Google, and the US Census Bureau.  The "PSI" tool produced in the project is unique in enabling differential privacy to be used effectively by practicing social science researchers, with no specialized expertise in privacy, computer science, or statistics.  In addition to bringing data privacy solutions to practice in the sharing of research data, the project achieves broader impacts by exposing a multidisciplinary understanding of data privacy to a wide range of audiences.  It has achieved this through organizing several workshops and symposia (including a public symposium with over 700 registrants), training many students in multidisciplinary research (including over 125 research assistants from computer science, law, social science, and statistics), sharing extensive policy recommendations and best practices with policymakers, practitioners, and the general public, and producing numerous open-access pedagogical materials. Moreover, the ideas developed in this project will benefit society more broadly as it grapples with data privacy issues in many other domains, including national security, electronic commerce, public health, and government operations and accountability.  Indeed, this project spawned a number of offshoot efforts on data privacy in these various domains, including helping the US Census Bureau and other government agencies adopt more modern privacy methods starting with the 2020 Decennial Census, an exploration of better methods for companies to analyze their user data in a privacy-protective manner, and the development of a new model for industry-academic partnerships to carry out social science research on sensitive corporate data.       Last Modified: 07/31/2018       Submitted by: Salil P Vadhan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
