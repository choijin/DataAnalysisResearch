<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Secure and Trustworthy Ocular Biometrics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>512964.00</AwardTotalIntnAmount>
<AwardAmount>695556</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The need for accurate and unforgeable identity recognition techniques has become an issue of increasing urgency. Biometric approaches such as iris recognition hold huge promise but still have significant limitations, including susceptibility to 'spoofing'. This project seeks to advance our knowledge of security and accuracy of multibiometric systems by inventing, evaluating, and applying innovative methods and tools to combine highly accurate static traits, such as iris patterns, with novel traits based on the dynamics of eye movements. The strategy is to use existing iris recognition hardware to combine three different biometrics approaches related to the eye: measurement of iris patterns, unique characteristics of the eye globe and its muscles, and the brain's strategies for guiding visual attention. This multimodal ocular biometrics approach has the potential to improve liveness detection and resistance to sophisticated counterfeiting techniques and coercion attacks, while improving identification accuracy. This research tackles important questions related to the individuality, variability, scalability, and longevity of these ocular traits, building a foundation for security and accuracy improvement when those traits are combined with iris recognition. This project aims to benefit efforts such as the Unique Identification project in India, which seeks to use biometric information of 1.2 billion individuals to fight fraud.&lt;br/&gt;&lt;br/&gt;Educational activities include three initiatives: 1) creation of a strong outreach activity to K-12 students, 2) expansion of an interdisciplinary research-oriented educational program previously created by the PI for undergraduate and graduate students, and 3) mentoring and guidance to interest undergraduate students in scientific careers and encourage more students from diverse backgrounds to pursue graduate study.</AbstractNarration>
<MinAmdLetterDate>02/05/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/16/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1250718</AwardID>
<Investigator>
<FirstName>Oleg</FirstName>
<LastName>Komogortsev</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Oleg V Komogortsev</PI_FULL_NAME>
<EmailAddress>ok11@txstate.edu</EmailAddress>
<PI_PHON>5122452314</PI_PHON>
<NSF_ID>000518752</NSF_ID>
<StartDate>02/05/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas State University - San Marcos</Name>
<CityName>San Marcos</CityName>
<ZipCode>786664616</ZipCode>
<PhoneNumber>5122452314</PhoneNumber>
<StreetAddress>601 University Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>28</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX28</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>074602368</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>101405814</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas State University - San Marcos]]></Name>
<CityName>San Marcos</CityName>
<StateCode>TX</StateCode>
<ZipCode>787494684</ZipCode>
<StreetAddress><![CDATA[601 University dr.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>21</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX21</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~121591</FUND_OBLG>
<FUND_OBLG>2014~318258</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<FUND_OBLG>2016~223707</FUND_OBLG>
<FUND_OBLG>2017~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project concentrated on understanding highly dynamic and individualistic traits related to eye movements and their relationship to internal, non-visible, anatomical properties of the human eye and the brain&rsquo;s strategies for guiding visual attention to assess the utility of eye movement biometrics &ndash; an accurate and spoof resistant method of person&rsquo;s authentication.</p> <p>&nbsp;</p> <p>We found individual differences in ways people move their eyes on macro and micro scale. If eye motility is recorded with high enough quality the differences in eye movement patterns of any two individuals are such that it is possible to distinguish between them with an accuracy comparable to fingerprints. This discovery validates eye movements as an authentication method for devices that have eye tracking capabilities.</p> <p>&nbsp;</p> <p>We have also verified the efficacy of eye movements as a tool against spoof attacks where intruders create various replicas of a human eye to get an unauthorized entry into a secure system. For example, we have successfully verified that it is possible to guard against print attacks (printed images of the human eye) and eye mechanical replicas by analyzing signal captured by eye tracking capable hardware.</p> <p>&nbsp;</p> <p>The findings of uniqueness of eye movements were verified via statistical methods which were based on the idea of improving authentication accuracy by selecting uncorrelated eye motility-derived features that have high degree of temporal persistence. The use of statistical methods in eye movement-driven biometrics will help to understand and interpret the nature of the phenomenon of why fingerprint-like accuracy of user authentication can be achieved from eye movement signal.</p> <p>&nbsp;</p> <p>While we expect that future machine learning-based approaches to improve the authentication performance we posit that statistical methods provide an important analytical tool to start answering future research questions such as: &ldquo;How to assess neurological health of a person using same features that are employed for person authentication?&rdquo;, &ldquo;How such human states as fatigue, emotions, stress affect eye movement signal and the performance of eye movement biometrics system in the authentication and health assessment mode?&rdquo;, &ldquo;How quality of the captured eye tracking signal affects the performance of the eye movement-driven biometric system in authentication and health assessment mode?&rdquo;.</p> <p>&nbsp;</p> <p>We have made publicly available the eye movement dataset that was recorded as a result of work on this grant to facilitate further research in the eye movement biometrics domain and beyond.</p> <p>&nbsp;</p> <p>Our findings of high authentication accuracy and spoofing resistance have positive implications for future virtual and augmented reality platforms, which are expected to have eye tracking hardware incorporated in them for purposes of foveated rendering and human computer interaction. Assuming that eye motility signal capture on such platforms can be done with high enough quality eye movements can be used as one of the most secure ways to authenticate its users or even provide health assessment capabilities with proper privacy handling.</p> <p>&nbsp;</p> <p>Important educational and outreach activities were supported by this grant including but not limited to involvement of minority and underrepresented undergraduate students, several of which, subsequently, have received National Science Foundation Graduate Research Fellowship awards. The work on this grant supported a development and enactment of a Ph.D. program in Computer Science at Texas State University &ndash; a Hispanic serving institution. Multiple news articles, papers, patents, and talks have resulted from the work on this grant.</p> <p>&nbsp;</p> <p>Deep gratitude goes to President Barack Obama for recognizing the importance of this direction of work and bestowing Presidential Early Career Award for Scientists and Engineers on this grant&rsquo;s PI as a sign of support.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/29/2020<br>      Modified by: Oleg&nbsp;V&nbsp;Komogortsev</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project concentrated on understanding highly dynamic and individualistic traits related to eye movements and their relationship to internal, non-visible, anatomical properties of the human eye and the brain’s strategies for guiding visual attention to assess the utility of eye movement biometrics &ndash; an accurate and spoof resistant method of person’s authentication.     We found individual differences in ways people move their eyes on macro and micro scale. If eye motility is recorded with high enough quality the differences in eye movement patterns of any two individuals are such that it is possible to distinguish between them with an accuracy comparable to fingerprints. This discovery validates eye movements as an authentication method for devices that have eye tracking capabilities.     We have also verified the efficacy of eye movements as a tool against spoof attacks where intruders create various replicas of a human eye to get an unauthorized entry into a secure system. For example, we have successfully verified that it is possible to guard against print attacks (printed images of the human eye) and eye mechanical replicas by analyzing signal captured by eye tracking capable hardware.     The findings of uniqueness of eye movements were verified via statistical methods which were based on the idea of improving authentication accuracy by selecting uncorrelated eye motility-derived features that have high degree of temporal persistence. The use of statistical methods in eye movement-driven biometrics will help to understand and interpret the nature of the phenomenon of why fingerprint-like accuracy of user authentication can be achieved from eye movement signal.     While we expect that future machine learning-based approaches to improve the authentication performance we posit that statistical methods provide an important analytical tool to start answering future research questions such as: "How to assess neurological health of a person using same features that are employed for person authentication?", "How such human states as fatigue, emotions, stress affect eye movement signal and the performance of eye movement biometrics system in the authentication and health assessment mode?", "How quality of the captured eye tracking signal affects the performance of the eye movement-driven biometric system in authentication and health assessment mode?".     We have made publicly available the eye movement dataset that was recorded as a result of work on this grant to facilitate further research in the eye movement biometrics domain and beyond.     Our findings of high authentication accuracy and spoofing resistance have positive implications for future virtual and augmented reality platforms, which are expected to have eye tracking hardware incorporated in them for purposes of foveated rendering and human computer interaction. Assuming that eye motility signal capture on such platforms can be done with high enough quality eye movements can be used as one of the most secure ways to authenticate its users or even provide health assessment capabilities with proper privacy handling.     Important educational and outreach activities were supported by this grant including but not limited to involvement of minority and underrepresented undergraduate students, several of which, subsequently, have received National Science Foundation Graduate Research Fellowship awards. The work on this grant supported a development and enactment of a Ph.D. program in Computer Science at Texas State University &ndash; a Hispanic serving institution. Multiple news articles, papers, patents, and talks have resulted from the work on this grant.     Deep gratitude goes to President Barack Obama for recognizing the importance of this direction of work and bestowing Presidential Early Career Award for Scientists and Engineers on this grant’s PI as a sign of support.          Last Modified: 12/29/2020       Submitted by: Oleg V Komogortsev]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
