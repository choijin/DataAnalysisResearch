<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Partial and Multilevel Effect Sizes in Meta-analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>475901.00</AwardTotalIntnAmount>
<AwardAmount>475901</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The investigators propose to develop and study partial effect-size indices for results of single and multilevel regression analyses and examine the suitability of the indices for use in meta-analysis. The investigators propose a program of work which combines mathematical statistics and simulation studies, illustrated with real educational examples.  This work will provide guidelines that researchers can use in reporting results and effect sizes for complex primary-study analyses; facilitate meta-analyses of complex studies; and inform the conduct and reporting of primary studies in STEM research.</AbstractNarration>
<MinAmdLetterDate>09/14/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1252338</AwardID>
<Investigator>
<FirstName>Betsy Jane</FirstName>
<LastName>Becker</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Betsy Jane Becker</PI_FULL_NAME>
<EmailAddress>bbecker@fsu.edu</EmailAddress>
<PI_PHON>8506452371</PI_PHON>
<NSF_ID>000234757</NSF_ID>
<StartDate>09/14/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida State University</Name>
<CityName>TALLAHASSEE</CityName>
<ZipCode>323064166</ZipCode>
<PhoneNumber>8506445260</PhoneNumber>
<StreetAddress>874 Traditions Way, 3rd Floor</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790877419</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida State University]]></Name>
<CityName>Tallahassee</CityName>
<StateCode>FL</StateCode>
<ZipCode>323064453</ZipCode>
<StreetAddress><![CDATA[3204F Stone Bldg., FSU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~475901</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Research in education, particularly in the science, technology, engineering, and mathematics (STEM) fields, often aims to understand how to help students learn and achieve strong educational goals. In some cases researchers develop and study programs to enhance learning or other outcomes. In others, scholars inquire into the variables that enhance or serve as barriers to achievement, with or without intervention. Across both cases, studies have grown more complex, with many characteristics of students, teachers, and contexts in the mix. &nbsp;This complexity in studies leads to special challenges when one tries to "sum up" or synthesize what is known about problems in STEM education.</p> <p>Our research has provided tools for researchers who want to summarize complex studies, particularly when multiple predictors are considered. Because STEM studies aim to understand outcomes such as achievement, attitudes towards learning, and persistence (e.g., at continued course taking, or selecting a STEM major in college), a variety of outcomes may be present whenever one gathers up studies on a particular topic. This diversity of constructs, and of the scales that operationalize them, must be considered when selecting effect sizes in any research synthesis.</p> <p>We have examined two main strategies to deal with study diversity, and the accompanying diversity of independent variables in STEM studies. First we have examined the potential for using correlation based measures&nbsp;<em>per se&nbsp;</em>for synthesis, including syntheses of simple, partial, and semi-partial correlations, and correlation matrices. Synthetic models can be derived from matrices, and used for both prediction and exploration. Our open access R software shortly will be posted as online material associated with a forthcoming handbook, and as an R package, making it more widely available. Second, we examined ways to summarize other associational analyses such as regression models and factor analyses, which are often used to examine complex systems of variables in primary studies of STEM learning .</p> <p>We have also written about how to improve the conduct of syntheses of complex studies. We focused on the types of study features that should be gathered and analyzed (and therefore that should be included in primary research reports), and how to assess potential biases when the summarized studies include quasi-experiments. We have also written about the special considerations needed when studied interventions are themselves complex.</p> <p>In all of our work we have advanced knowledge about the behavior of our analytic tools, and other tools used in current practice. By applying statistical theory to derive indices, study alternative analytic approaches, and understand existing studies and syntheses, we have provided a foundation that justifies the use of our techniques, and raised questions about certain approaches seen in the literature. For example, we showed that it is not desirable to synthesize multiple regression-slope indices taken from several models of a specific outcome in a single study. Such indices can be extremely highly correlated, leading to high levels of dependence typically not accounted for in common practice. Our primary findings include the following.</p> <p style="padding-left: 30px;">1) <em>There is more than one way to skin a cat</em>: Several effect sizes can serviceably reflect the findings of complex studies. The decision about which effect index to use should be based on the question of interest, and what has been done and reported most frequently in the primary research on that question. Also, partial relationships can be synthesized in two ways with comparable results -- either via simple summaries of partial indices, or via multivariate summaries of simpler indices.</p> <p style="padding-left: 30px;">2) "<em>One man's constant is another man's variable"</em><a href="file:///C:/Users/betsy/Documents/1Words/Research/grants/REESE%202012/Final%20report/Project%20Outcomes%20Report_bb.docx#_ftn1">[1]</a>: Meta-analysts examining partial relationships should carefully code, and analyze roles of, the control variables and other critical predictors included in the primary research. These variables often differ across studies, as do the ways the variables are controlled, such as by design or analysis. Such features can lead to important variation in partial effect sizes.</p> <p style="padding-left: 30px;">3) "<em>Simplicity is the keynote of all true elegance"</em><a href="file:///C:/Users/betsy/Documents/1Words/Research/grants/REESE%202012/Final%20report/Project%20Outcomes%20Report_bb.docx#_ftn2">[2]</a>: Not all complexity matters.&nbsp; Dispersion in indices from complex studies depends on whether the focal predictor shares common variance with other predictors that were modeled in the included studies. When relationships among predictors&nbsp;are weak, most partial indices are relatively unaffected by the number and nature of the additional predictors, thus indices based on superficially different models can be combined.</p> <div> <p>Our work provides guidance for selecting the most suitable effect-size measures to be summarized to support desired inferences, and the analyses that can be done with those indices. We have shown that multivariate syntheses provide understandings of both what is known, and what is not, about the multivariate problems of interest to STEM researchers. Our work has already reached beyond STEM research, as attested to by our invitations to contribute to conferences, special issues, and handbook projects across such diverse areas as education, public health, and epidemiology.&nbsp;&nbsp;</p> <hr size="1" /> <div> <p><a href="file:///C:/Users/betsy/Documents/1Words/Research/grants/REESE%202012/Final%20report/Project%20Outcomes%20Report_bb.docx#_ftnref1">[1]</a> A.J. Perlis, 1982; see also <a href="http://pu.inf.uni-tuebingen.de/users/klaeren/epigrams.html">http://pu.inf.uni-tuebingen.de/users/klaeren/epigrams.html</a>.</p> </div> <div> <p><a href="file:///C:/Users/betsy/Documents/1Words/Research/grants/REESE%202012/Final%20report/Project%20Outcomes%20Report_bb.docx#_ftnref2">[2]</a> Attributed to Coco Chanel.</p> </div> </div> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/25/2019<br>      Modified by: Betsy Jane&nbsp;Becker</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Research in education, particularly in the science, technology, engineering, and mathematics (STEM) fields, often aims to understand how to help students learn and achieve strong educational goals. In some cases researchers develop and study programs to enhance learning or other outcomes. In others, scholars inquire into the variables that enhance or serve as barriers to achievement, with or without intervention. Across both cases, studies have grown more complex, with many characteristics of students, teachers, and contexts in the mix.  This complexity in studies leads to special challenges when one tries to "sum up" or synthesize what is known about problems in STEM education.  Our research has provided tools for researchers who want to summarize complex studies, particularly when multiple predictors are considered. Because STEM studies aim to understand outcomes such as achievement, attitudes towards learning, and persistence (e.g., at continued course taking, or selecting a STEM major in college), a variety of outcomes may be present whenever one gathers up studies on a particular topic. This diversity of constructs, and of the scales that operationalize them, must be considered when selecting effect sizes in any research synthesis.  We have examined two main strategies to deal with study diversity, and the accompanying diversity of independent variables in STEM studies. First we have examined the potential for using correlation based measures per se for synthesis, including syntheses of simple, partial, and semi-partial correlations, and correlation matrices. Synthetic models can be derived from matrices, and used for both prediction and exploration. Our open access R software shortly will be posted as online material associated with a forthcoming handbook, and as an R package, making it more widely available. Second, we examined ways to summarize other associational analyses such as regression models and factor analyses, which are often used to examine complex systems of variables in primary studies of STEM learning .  We have also written about how to improve the conduct of syntheses of complex studies. We focused on the types of study features that should be gathered and analyzed (and therefore that should be included in primary research reports), and how to assess potential biases when the summarized studies include quasi-experiments. We have also written about the special considerations needed when studied interventions are themselves complex.  In all of our work we have advanced knowledge about the behavior of our analytic tools, and other tools used in current practice. By applying statistical theory to derive indices, study alternative analytic approaches, and understand existing studies and syntheses, we have provided a foundation that justifies the use of our techniques, and raised questions about certain approaches seen in the literature. For example, we showed that it is not desirable to synthesize multiple regression-slope indices taken from several models of a specific outcome in a single study. Such indices can be extremely highly correlated, leading to high levels of dependence typically not accounted for in common practice. Our primary findings include the following. 1) There is more than one way to skin a cat: Several effect sizes can serviceably reflect the findings of complex studies. The decision about which effect index to use should be based on the question of interest, and what has been done and reported most frequently in the primary research on that question. Also, partial relationships can be synthesized in two ways with comparable results -- either via simple summaries of partial indices, or via multivariate summaries of simpler indices. 2) "One man's constant is another man's variable"[1]: Meta-analysts examining partial relationships should carefully code, and analyze roles of, the control variables and other critical predictors included in the primary research. These variables often differ across studies, as do the ways the variables are controlled, such as by design or analysis. Such features can lead to important variation in partial effect sizes. 3) "Simplicity is the keynote of all true elegance"[2]: Not all complexity matters.  Dispersion in indices from complex studies depends on whether the focal predictor shares common variance with other predictors that were modeled in the included studies. When relationships among predictors are weak, most partial indices are relatively unaffected by the number and nature of the additional predictors, thus indices based on superficially different models can be combined.   Our work provides guidance for selecting the most suitable effect-size measures to be summarized to support desired inferences, and the analyses that can be done with those indices. We have shown that multivariate syntheses provide understandings of both what is known, and what is not, about the multivariate problems of interest to STEM researchers. Our work has already reached beyond STEM research, as attested to by our invitations to contribute to conferences, special issues, and handbook projects across such diverse areas as education, public health, and epidemiology.      [1] A.J. Perlis, 1982; see also http://pu.inf.uni-tuebingen.de/users/klaeren/epigrams.html.    [2] Attributed to Coco Chanel.                  Last Modified: 11/25/2019       Submitted by: Betsy Jane Becker]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
