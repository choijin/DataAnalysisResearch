<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Small: Collaborative Research: Addressing Clutter and Uncertainty for Robotic Manipulation in Human Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>12/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregory Chirikjian</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The long-term goal of this project is to develop personal robots that share a workspace with humans. To achieve the goal of personal robots in homes, the robots must adapt to the humans? living space, not vice-versa. Unfortunately, most human living spaces appear cluttered and unstructured to a robot. Much of this "clutter" is in fact structure, but structure for humans, not robots. The preliminary work proposed in this revised project addresses preliminary work in robot manipulation in the presence of clutter and uncertainty. The demonstrator task is a canonical example of human-robot coexistence: sharing a refrigerator. The robot must be able to extract specified items from a refrigerator that may also be accessed and altered by humans. We will develop the beginnings of a solution based on the following principles: such manipulation tasks can be solved by a hierarchical two-level planning strategy, consisting of a high-level metaplanner making use of low-level primitives; the low-level primitives should include push-grasping, sweeping, and other nonprehensile actions that take advantage of mechanics to manipulate cluttered environments when simple grasp-and-carry is impeded; and uncertainty in the state of the environment and its physical properties should be accounted for at both the metaplanner and primitive levels.&lt;br/&gt;&lt;br/&gt;Broader Impacts: Although not all outreach goals can be completed within the revised scope, cluttered tasks are critically important for an aging population of about 35 million people (one in eight) in the United States. Furthermore, graduate students involved in this project will benefit from an ongoing collaboration with TU Munich, a world leader in robot control and personal robotics. TUM, CMU, and Northwestern have a history of graduate student exchange and have agreed to host exchange students under this project. Undergraduates will participate in the research as REU students or in other capacities. Several recent undergraduates working in the labs at CMU and Northwestern have gone on to PhD study in robotics, some with NSF graduate fellowships. Graduate students on this project will participate in internships at the Museum of Science and Industry during its upcoming Robot Revolution exhibit. They will interact with the public and help develop a robot manipulation demonstration for the exhibit main stage. These students will provide technical expertise to the exhibit while benefitting from a valuable outreach experience. Other planned outreach activities include lab tours and talks at local high schools. Both PIs serve as mentors in research programs for underrepresented undergraduate students. These students would have an opportunity to work on state-of-the-art manipulation hardware as part of this project.</AbstractNarration>
<MinAmdLetterDate>09/06/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1208479</AwardID>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Lynch</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin M Lynch</PI_FULL_NAME>
<EmailAddress>kmlynch@northwestern.edu</EmailAddress>
<PI_PHON>8474675451</PI_PHON>
<NSF_ID>000225559</NSF_ID>
<StartDate>09/06/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602083100</ZipCode>
<StreetAddress><![CDATA[2145 Sheridan Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Robots generally manipulate objects by grasping and carrying them in controlled settings like factories, where objects are presented to the robots in well-organized pallets. &nbsp;For robots to manipulate objects in natural human environments, they must be able to deal with clutter, like that found in a typical refrigerator. &nbsp;</p> <p><br />To manipulate objects in complex environments, the robot requires a repertoire of human-like capabilities, beyond just grasping: &nbsp;the ability to push objects; to push several objects simultaneously; to slide or throw objects; to roll objects; or to adjust an object within a grasp. &nbsp;</p> <p><br />This project addressed the problem of developing robot manipulators with (1) the sensing capabilities and (2) the planning capabilities to perform complex manipulation tasks requiring a repertoire of manipulation skills. &nbsp;</p> <p><br />One outcome of this project is motion planning and control software for the ERIN robot system, a state-of-the-art robot manipulator consisting of an advanced Barrett WAM robot arm with seven joints; a robot hand with four fingers; tactile sensors on each of the robot fingers; and a 10-camera 3D high-speed vision system (see figure). &nbsp;Under this project, ERIN has demonstrated advanced hand-eye coordination tasks like catching and balancing a thrown object and repositioning an object within a grasp. &nbsp;These are part of an emerging repertoire of robot capabilities for complex manipulation tasks.</p> <p><br />This project contributed to the education of two PhD students. &nbsp;The results of this project have been demonstrated in venues such as the Chicago Museum of Science and Industry, exposing many school children to advanced robotics.</p><br> <p>            Last Modified: 06/13/2015<br>      Modified by: Kevin&nbsp;M&nbsp;Lynch</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2015/1208479/1208479_10211565_1434249200612_ERIN--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1208479/1208479_10211565_1434249200612_ERIN--rgov-800width.jpg" title="The ERIN advanced manipulation system."><img src="/por/images/Reports/POR/2015/1208479/1208479_10211565_1434249200612_ERIN--rgov-66x44.jpg" alt="The ERIN advanced manipulation system."></a> <div class="imageCaptionContainer"> <div class="imageCaption">The ERIN advanced manipulation system.</div> <div class="imageCredit">Jian Shi</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Kevin&nbsp;M&nbsp;Lynch</div> <div class="imageTitle">The ERIN advanced manipulation system.</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Robots generally manipulate objects by grasping and carrying them in controlled settings like factories, where objects are presented to the robots in well-organized pallets.  For robots to manipulate objects in natural human environments, they must be able to deal with clutter, like that found in a typical refrigerator.     To manipulate objects in complex environments, the robot requires a repertoire of human-like capabilities, beyond just grasping:  the ability to push objects; to push several objects simultaneously; to slide or throw objects; to roll objects; or to adjust an object within a grasp.     This project addressed the problem of developing robot manipulators with (1) the sensing capabilities and (2) the planning capabilities to perform complex manipulation tasks requiring a repertoire of manipulation skills.     One outcome of this project is motion planning and control software for the ERIN robot system, a state-of-the-art robot manipulator consisting of an advanced Barrett WAM robot arm with seven joints; a robot hand with four fingers; tactile sensors on each of the robot fingers; and a 10-camera 3D high-speed vision system (see figure).  Under this project, ERIN has demonstrated advanced hand-eye coordination tasks like catching and balancing a thrown object and repositioning an object within a grasp.  These are part of an emerging repertoire of robot capabilities for complex manipulation tasks.   This project contributed to the education of two PhD students.  The results of this project have been demonstrated in venues such as the Chicago Museum of Science and Industry, exposing many school children to advanced robotics.       Last Modified: 06/13/2015       Submitted by: Kevin M Lynch]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
