<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: Small: DCM: Open Flow Enabled Hadoop over Local and Wide  Area Clusters</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>749806.00</AwardTotalIntnAmount>
<AwardAmount>749806</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Chadduck</SignBlockName>
<PO_EMAI>rchadduc@nsf.gov</PO_EMAI>
<PO_PHON>7032922247</PO_PHON>
</ProgramOfficer>
<AbstractNarration>BigData: Small: DCM: Open Flow Enabled Hadoop over Local and Wide Area Clusters&lt;br/&gt;Robert L. Grossman&lt;br/&gt;University of Chicago&lt;br/&gt;&lt;br/&gt;In the recent years, data intensive programming using Hadoop and MapReduce has become more and more important.  As normally deployed, Hadoop's implementation of MapReduce in a multi-rack cluster is dependent upon the top of the rack switches and of the aggregator switches connecting multiple racks.  To use Hadoop effectively at scale across many racks requires expensive network switches and routers that are complex to configure and to maintain.&lt;br/&gt;&lt;br/&gt;Software defined networks using OpenFlow have proven in many cases to offer good performance at lower cost and to be simpler to manage.  The first goal of this proposal is to contribute to the development of a new version of Hadoop called Hadoop-OFP.  The basic idea of Hadoop-OFP is to integrate OpenFlow enabled switches with Hadoop: to i) improve performance; ii) lower the cost of the hardware required; and iii) simplify the management of the cluster.  &lt;br/&gt;&lt;br/&gt;Large data flows are also a critical component of data intensive computing.  Unfortunately, setting up networks to manage large data flows can be challenging.  A second goal of this proposal is to develop a tool that can configure OpenFlow enabled networks to handle more efficiently the large data flows that arise with data intensive computing.</AbstractNarration>
<MinAmdLetterDate>06/07/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/07/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1251201</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Grossman</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert L Grossman</PI_FULL_NAME>
<EmailAddress>robert.grossman@uchicago.edu</EmailAddress>
<PI_PHON>7738344669</PI_PHON>
<NSF_ID>000278293</NSF_ID>
<StartDate>06/07/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606375418</ZipCode>
<StreetAddress><![CDATA[5801 South Ellis Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7701</Code>
<Text>DATA INTEROPERABILITY NETWORKS</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~749806</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Although scientists are producing more and more data, making discoveries from this data grows harder each year as the amount of data grows and as it becomes scattered among more and more repositories.&nbsp; One of the approaches for addressing this problem is a data commons. A data commons co-locates data, storage and computing infrastructure with commonly used software tools, services and applications for managing, integrating, analyzing and sharing data to create an open interoperable resource for a scientific research community.&nbsp; Data commons may be developed using a variety of software frameworks, including Hadoop, Spark and using the software services available from cloud computing platforms.</p> <p>In practice, the performance of a data commons is often limited by the network.&nbsp; One way to improve the performance of a network supporting a data commons is to use traffic engineering. By traffic engineering (or traffic management), we mean optimizing the performance of a network by dynamically analyzing, predicting and regulating the behavior of data transmitted over the network.&nbsp; For example, we can regulate behavior using network devices, such as switches or routers, by dynamically changing the internal configurations of the device based upon our predictions.&nbsp;One technology that provides this capability is software defined networking (SDN).</p> <p>In this project, we designed and developed software and performed experimental studies to examine two questions:</p> <p>Question 1. Can software defined networks be used to reduce network bottlenecks so as to improve the performance of Hadoop and related frameworks supporting data commons operating within a data center?</p> <p>Question 2. Can software defined networks be used to support data commons over wide area networks connecting two or more data centers?</p> <p>When multiple researchers use a data commons for data intensive computing, they compete for the fixed bandwidth available on the network supporting the data commons.&nbsp; For example, multiple users may be downloading large files or accessing and analyzing large datasets. This is an example of user contention. One standard approach is to assign different jobs different priorities.&nbsp; The priorities can be assigned in a number of different ways.&nbsp; &nbsp;From our experimental studies involving user contention in a data commons supporting software defined networking, we found in certain cases we could use traffic management to reduce the time to finish high priority downloads or data accesses by approximately 60%, while only degrading lower priority jobs by approximately 2%.</p> <p>An important practical problem when using Hadoop-based data commons is importing new data into the data commons.&nbsp; From our experimental studies involving the Hadoop-based data commons, we found in certain cases we could use traffic management to reduce the time needed to import data into the Hadoop Distributed File System (HDFS) by approximately 50% while other applications continued as usual.&nbsp;</p> <p>These two results address Question 1 in part.</p> <p>We also explored using software defined networks to support data intensive computing over geographically distributed data.&nbsp;&nbsp; In particular a SDN exchange point or SDX is a software application that can be deployed at Internet exchange points to provide SDN abstractions to those services and applications that use the exchange point.&nbsp;&nbsp; In this project, we performed experimental studies where a data commons accesses geographically distributed data using a SDX.&nbsp; We found using a SDX simplified the process of setting up, monitoring and tearing down wide area high performance application specific optical network paths (or lambdas) connecting data centers from multiple network domains to a data commons.&nbsp; &nbsp;This activity addresses Question 3 in part.</p> <p>Data commons are emerging as an important component of cyberinfrastructure supporting data science.&nbsp; To summarize, in this project, we showed that software defined networking looks like a promising technology for improving the performance of data commons.</p> <p>During the project, we trained two post-doctoral fellows and provided a research experience for an undergraduate.</p><br> <p>            Last Modified: 08/30/2017<br>      Modified by: Robert&nbsp;L&nbsp;Grossman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Although scientists are producing more and more data, making discoveries from this data grows harder each year as the amount of data grows and as it becomes scattered among more and more repositories.  One of the approaches for addressing this problem is a data commons. A data commons co-locates data, storage and computing infrastructure with commonly used software tools, services and applications for managing, integrating, analyzing and sharing data to create an open interoperable resource for a scientific research community.  Data commons may be developed using a variety of software frameworks, including Hadoop, Spark and using the software services available from cloud computing platforms.  In practice, the performance of a data commons is often limited by the network.  One way to improve the performance of a network supporting a data commons is to use traffic engineering. By traffic engineering (or traffic management), we mean optimizing the performance of a network by dynamically analyzing, predicting and regulating the behavior of data transmitted over the network.  For example, we can regulate behavior using network devices, such as switches or routers, by dynamically changing the internal configurations of the device based upon our predictions. One technology that provides this capability is software defined networking (SDN).  In this project, we designed and developed software and performed experimental studies to examine two questions:  Question 1. Can software defined networks be used to reduce network bottlenecks so as to improve the performance of Hadoop and related frameworks supporting data commons operating within a data center?  Question 2. Can software defined networks be used to support data commons over wide area networks connecting two or more data centers?  When multiple researchers use a data commons for data intensive computing, they compete for the fixed bandwidth available on the network supporting the data commons.  For example, multiple users may be downloading large files or accessing and analyzing large datasets. This is an example of user contention. One standard approach is to assign different jobs different priorities.  The priorities can be assigned in a number of different ways.   From our experimental studies involving user contention in a data commons supporting software defined networking, we found in certain cases we could use traffic management to reduce the time to finish high priority downloads or data accesses by approximately 60%, while only degrading lower priority jobs by approximately 2%.  An important practical problem when using Hadoop-based data commons is importing new data into the data commons.  From our experimental studies involving the Hadoop-based data commons, we found in certain cases we could use traffic management to reduce the time needed to import data into the Hadoop Distributed File System (HDFS) by approximately 50% while other applications continued as usual.   These two results address Question 1 in part.  We also explored using software defined networks to support data intensive computing over geographically distributed data.   In particular a SDN exchange point or SDX is a software application that can be deployed at Internet exchange points to provide SDN abstractions to those services and applications that use the exchange point.   In this project, we performed experimental studies where a data commons accesses geographically distributed data using a SDX.  We found using a SDX simplified the process of setting up, monitoring and tearing down wide area high performance application specific optical network paths (or lambdas) connecting data centers from multiple network domains to a data commons.   This activity addresses Question 3 in part.  Data commons are emerging as an important component of cyberinfrastructure supporting data science.  To summarize, in this project, we showed that software defined networking looks like a promising technology for improving the performance of data commons.  During the project, we trained two post-doctoral fellows and provided a research experience for an undergraduate.       Last Modified: 08/30/2017       Submitted by: Robert L Grossman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
