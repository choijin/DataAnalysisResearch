<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CI-P:Collaborative Research:The Speech Recognition Virtual Kitchen</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2012</AwardEffectiveDate>
<AwardExpirationDate>05/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>48509.00</AwardTotalIntnAmount>
<AwardAmount>48509</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>CI-P:Collaborative Research: The Speech Recognition Virtual Kitchen &lt;br/&gt;&lt;br/&gt;This project provides a "kitchen" environment to promote community sharing of research techniques, foster innovative experimentation, and provide solid reference systems for automatically recognizing speech, as a tool for education, research, and evaluation. The research infrastructure is built around virtual machines (VMs), which can be reconfigured and shared easily. We liken the virtual machines to a "kitchen" because they provide the environmental infrastructure into which one can install "appliances" (e.g., speech recognition toolkits), "recipes" (scripts for creating state-of-the art systems for a toolkit), and "ingredients" (spoken language data), along with "dishes" (completed experiments with log-files for reference). &lt;br/&gt;&lt;br/&gt;The planning project engages the community to tackle some of the issues that have previously hampered efforts in cross-community sharing, including distribution methods and intellectual property issues. The project also provides an example architecture, which serves as a focus point for community-wide discussion. &lt;br/&gt;&lt;br/&gt;In terms of broader impacts, the project engages researchers and educators that typically do not participate in automatic speech recognition (ASR) research by providing travel scholarships to a workshop at INTERSPEECH2012. In a wider scope, the infrastructure may be useable by other data-intensive fields (synthesis, dialog systems, NLP, computer vision, data mining). By providing a permanent, publicly available resource for research, education, and evaluation in ASR research, we can better train the next generation of undergraduates and graduates. The "kitchen" gives them easy access to a large number of state-of-the-art implementations, and facilitates deeper analysis of algorithms and better comparisons across systems.</AbstractNarration>
<MinAmdLetterDate>05/16/2012</MinAmdLetterDate>
<MaxAmdLetterDate>05/16/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1205424</AwardID>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Fosler-Lussier</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric Fosler-Lussier</PI_FULL_NAME>
<EmailAddress>fosler@cse.ohio-state.edu</EmailAddress>
<PI_PHON>6142924890</PI_PHON>
<NSF_ID>000182577</NSF_ID>
<StartDate>05/16/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~48509</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>Building and maintaining a state-of-the-art Automatic Speech Recognition (ASR) system has moved beyond the ability of a single developer. It is difficult for all but the largest of University laboratories to maintain an end-to-end system, and adapt it to new languages, tasks, or conditions as required. Other researchers, who are not experts in speech recognition, find it impossible to use ASR in non-English languages, non-mainstream dialects, for distant microphones, or with children&rsquo;s speech &ndash; simply because no such recognizer is available off-the- shelf. What has been missing is a way for academic institutions (and industry) to leverage community resources in order to branch off new research from fully functional end-to-end system configurations, rather than a collection of individually downloaded tools, scripts and data. Even if a well documented, state-of-the-art open-source ASR toolkit is being used, a &ldquo;black box&rdquo; approach usually results in poor performance. </span></p> <p><span>This project attempts to extend the model of lab-internal knowledge transfer to a community-wide effort through the use of Virtual Machines (VMs). We design an infrastructure to share entire ready-to-run baseline &ldquo;recipes&rdquo; together with data, log-files, results, etc. &ndash; in a working environment, and with links to other users that work on exactly the same task across the world. Students and researchers can then modify recipes step by step, observing the effect of changes. Testing a system on different data becomes almost trivial, and retraining a system becomes very easy, because a working training setup is available for comparisons. </span></p> <p><span>The &ldquo;Speech Recognition Virtual Kitchen&rdquo; first serves as a repository for Virtual Machines, which will typically be based on redistributable operating systems such as the Ubuntu Linux derivative, to provide a common infrastructure for the use of tool-kits and data. A user would download a VM from the &ldquo;Kitchen Server&rdquo; onto his &ldquo;Host PC&rdquo;, and run it. Using the kitchen, any changes he makes to the VM can be compiled into a software package, and shared with other users that are running the same VM. Results can be uploaded to the kitchen, and displayed in a &ldquo;high score&rdquo; table, showing how well individual users are doing, and offering an incentive to continue for students. Class projects can be shared easily using VMs, which also allow for &ldquo;versioning&rdquo;, which could be used to distribute example solutions to students. </span></p> <p><span>The present CRI-P planning grant developed the idea and organized a workshop to collect community input. Example VMs and concepts for setting up the kitchen server for minimum data transfer were created. A follow-up CRI grant is currently implementing the &ldquo;Speech Recognition Virtual Kitchen&rdquo;, which we expect to go public in 2014. </span></p> <p><span>The &ldquo;Speech Recognition Virtual Kitchen&rdquo; represents an easy mechanism to create, maintain, and distribute high quality experiments in the speech and language area, which can be used at all levels of education, to distribute baselines for evaluation, and to promote the use of speech recognition in related fields such as information retrieval, user interfaces, robotics, etc. The outcome will be a better educated future work force in a field that is critical for man machine communication, information access or analysis, ICT for development, and many other uses.&nbsp;</span></p> </div> </div> </div> </div> <p>&nbsp;</p><br> <p>            Last Modified: 09/11/2013<br>      Modified by: Eric&nbsp;Fosler-Lussier</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[     Building and maintaining a state-of-the-art Automatic Speech Recognition (ASR) system has moved beyond the ability of a single developer. It is difficult for all but the largest of University laboratories to maintain an end-to-end system, and adapt it to new languages, tasks, or conditions as required. Other researchers, who are not experts in speech recognition, find it impossible to use ASR in non-English languages, non-mainstream dialects, for distant microphones, or with childrenÃ†s speech &ndash; simply because no such recognizer is available off-the- shelf. What has been missing is a way for academic institutions (and industry) to leverage community resources in order to branch off new research from fully functional end-to-end system configurations, rather than a collection of individually downloaded tools, scripts and data. Even if a well documented, state-of-the-art open-source ASR toolkit is being used, a "black box" approach usually results in poor performance.   This project attempts to extend the model of lab-internal knowledge transfer to a community-wide effort through the use of Virtual Machines (VMs). We design an infrastructure to share entire ready-to-run baseline "recipes" together with data, log-files, results, etc. &ndash; in a working environment, and with links to other users that work on exactly the same task across the world. Students and researchers can then modify recipes step by step, observing the effect of changes. Testing a system on different data becomes almost trivial, and retraining a system becomes very easy, because a working training setup is available for comparisons.   The "Speech Recognition Virtual Kitchen" first serves as a repository for Virtual Machines, which will typically be based on redistributable operating systems such as the Ubuntu Linux derivative, to provide a common infrastructure for the use of tool-kits and data. A user would download a VM from the "Kitchen Server" onto his "Host PC", and run it. Using the kitchen, any changes he makes to the VM can be compiled into a software package, and shared with other users that are running the same VM. Results can be uploaded to the kitchen, and displayed in a "high score" table, showing how well individual users are doing, and offering an incentive to continue for students. Class projects can be shared easily using VMs, which also allow for "versioning", which could be used to distribute example solutions to students.   The present CRI-P planning grant developed the idea and organized a workshop to collect community input. Example VMs and concepts for setting up the kitchen server for minimum data transfer were created. A follow-up CRI grant is currently implementing the "Speech Recognition Virtual Kitchen", which we expect to go public in 2014.   The "Speech Recognition Virtual Kitchen" represents an easy mechanism to create, maintain, and distribute high quality experiments in the speech and language area, which can be used at all levels of education, to distribute baselines for evaluation, and to promote the use of speech recognition in related fields such as information retrieval, user interfaces, robotics, etc. The outcome will be a better educated future work force in a field that is critical for man machine communication, information access or analysis, ICT for development, and many other uses.               Last Modified: 09/11/2013       Submitted by: Eric Fosler-Lussier]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
