<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Individualized Adaptive Robot-Mediated Intervention Architecture for Autism</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>312753.00</AwardTotalIntnAmount>
<AwardAmount>312753</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michele Grimm</SignBlockName>
<PO_EMAI>mgrimm@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>PI: Sarkar, Nilanjan and Warren, Zachary&lt;br/&gt;Proposal Number: 1264462&lt;br/&gt;&lt;br/&gt;Project Summary: A novel and transformative robotic intervention technology, called ARIA&lt;br/&gt;(Adaptive Robot-mediated Intervention Architecture), with the potential to accelerate social communication skill development for young children with autism spectrum disorders (ASD) is proposed in this research. ARIA will fluidly integrate a humanoid robot, multiple spatially distributed network of cameras, an array of display monitors, as well as a complex but efficient computational face, gaze and gesture detection methodology in order to create a highly flexible and adaptive intelligent environment to potentially advance early joint attention and imitation related skills for young children with ASD. Application of this system will be examined across two user studies with well-defined samples of young children with ASD to provide specific answers and direction to important questions of generalization and potential impact of robotic intervention.&lt;br/&gt;&lt;br/&gt;Intellectual Merit: The proposed research advances the design and development of intelligent adaptive robotic platforms to offer a potentially transformative intervention application for young children with ASD. The specific technological innovation proposed here has the potential to significantly contribute to new non-invasive and closed-loop human-robot interaction learning paradigms with potential broad extension to individuals with a vast array of neurodevelopmental conditions and limiting sensory vulnerabilities across the lifespan. From the perspective of the science and technology of robotics, the project will contribute towards the design and development of smart environments for learning, intelligent system architecture for adaptive robotics as well as affective computing and control of dynamic human-robot interaction. In particular, it has the potential to significantly contribute towards developing novel efficient applications of computational methods for affective computing, particularly affective computing mediated by non-invasive gaze and attention processing. It will also contribute towards closed loop gesture-based human-robot interaction by developing new methodologies for gesture recognition and adaptive response from the robot. The project will develop a framework and tools to design adaptive environments for enhanced robotic and embodied social interaction that intelligently and fluidly integrates real-time behavioral indices of attentive and gesture information into flexible and controllable response systems. In short, the proposed activity represents a system has the potential to fundamentally advance the engineering knowledge of intelligent human-robotic interaction. This paradigm may also potently impact our understanding of the science of ASD intervention itself. The embedded user studies will test the potential efficacy of robotic intervention on the earliest core symptoms of ASD.&lt;br/&gt;&lt;br/&gt;Broader Impacts: With the most recent Centers for Disease Control and Prevention (CDC) prevalence estimates for children with ASD at 1 in 88, effective early identification and treatment is often characterized as a public health emergency. The costs of ASD are thought to be enormous across the lifespan, with recent individual incremental lifetime cost projections exceeding $3.2 million and national cost over $35 billion annually. The proposed research explicitly focuses on realizing robotic intervention technologies with potential for improving early ASD related impairments and could have significant beneficial impact on this population. This research may further a technology that can enable all core components of effective intervention at only a fraction of the cost of typical intervention programs, while at the same time increasing the ability of the intervention provider to systematically control and promote intervention related skills targeting individual deficit. The educational activities will train and mentor undergraduate and graduate students in the proposed research, and bring research into classroom through several courses. The outreach activities will include offering research opportunities to high school students, especially among groups currently underrepresented in STEM (science, technology, engineering, and mathematics) fields, and providing high school teachers with research experience during summer. The project offers a strong community connection through formal dissemination to ASD family, clinical, and scientific communities.</AbstractNarration>
<MinAmdLetterDate>08/12/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/12/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1264462</AwardID>
<Investigator>
<FirstName>Nilanjan</FirstName>
<LastName>Sarkar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nilanjan Sarkar</PI_FULL_NAME>
<EmailAddress>nilanjan.sarkar@vanderbilt.edu</EmailAddress>
<PI_PHON>6153437219</PI_PHON>
<NSF_ID>000216429</NSF_ID>
<StartDate>08/12/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zachary</FirstName>
<LastName>Warren</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zachary Warren</PI_FULL_NAME>
<EmailAddress>zachary.warren@vanderbilt.edu</EmailAddress>
<PI_PHON>6153222631</PI_PHON>
<NSF_ID>000501255</NSF_ID>
<StartDate>08/12/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Vanderbilt University</Name>
<CityName>Nashville</CityName>
<ZipCode>372350002</ZipCode>
<PhoneNumber>6153222631</PhoneNumber>
<StreetAddress>Sponsored Programs Administratio</StreetAddress>
<StreetAddress2><![CDATA[PMB 407749 2301 Vanderbilt Place]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<StateCode>TN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>965717143</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VANDERBILT UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004413456</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Vanderbilt University]]></Name>
<CityName>Nashville</CityName>
<StateCode>TN</StateCode>
<ZipCode>372350002</ZipCode>
<StreetAddress><![CDATA[2301 Vanderbilt Pl]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5342</Code>
<Text>Disability &amp; Rehab Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>010E</Code>
<Text>DISABILITY RES &amp; HOMECARE TECH</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~312753</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The Centers for Disease Control and Prevention estimates 1 in 68 children in the United States have an Autism Spectrum Disorder (ASD). ASD is associated with enormous individual, familial, and social costs across the lifespan. Many families and service systems struggle to provide appropriately intensive evidence-based interventions due to extreme resource limitations. As such, there is an urgent need for more efficacious treatments that can be delivered across resource-strained environments. This research project leverages a common preference that many children with ASD show towards technological engagement, to design a novel an Adaptive Robot-mediated Intervention Architecture (ARIA) system that can effectively address social communication deficits associated with ASD.</p> <p>ARIA was designed to help with two fundamental building blocks for early social communication development, which were coordinated joint attention and imitation skills, using novel robotic interaction paradigms. ARIA fluidly integrates a humanoid robot, a network of spatially distributed cameras and display monitors, as well as complex and efficient computational face, gaze and gesture detection methodologies in order to create a highly flexible and adaptive intelligent intervention environment.&nbsp; This system will have the potential to advance current intervention practice by gathering individualized behavioral performance data at a level beyond human capacity to inform real-time adaptive response and reinforcement strategies that may accelerate learning in key neurodevelopmental skills areas thought to be critical in the treatment of ASD.</p> <p>Once the ARIA system was designed and developed, it was tested with children with ASD in several pilot studies. A two-phase joint attention study revealed that children with ASD were engaged in interacting with the robot, paid more attention to the robot than a therapist, performed equally well and did not lose interest in the robot-mediated interaction in multiple sessions. Thus this study established the feasibility of a log-term intervention with ARIA. However, the most important finding was that many children showed improvement in human-human interaction after ARIA-based human-robot interaction. While further research is needed, such skill generalization in real-world is very promising. In robot-mediated gesture imitation skill study, ARIA-based training showed significant improvement in the gesture imitation capabilities of children with ASD. Finally, another study was designed, called Response-to-Name (RTN), where using the essential elements of ARIA we could quantitatively measure how children with ASD and typically developing children respond when their names are called. This has important implication in ASD diagnosis and intervention.</p> <p>The <strong>intellectual merit</strong> of this research lies in the design and development of smart environments for learning, intelligent system architecture for adaptive robotics, as well as affective computing and control of dynamic human-robot interaction. In particular, the project significantly contributed towards developing novel efficient applications of computational methods for affective computing, including affective computing mediated by non-invasive gaze and attention processing. It also contributed towards closed-loop gesture-based human-robot interaction by developing new methodologies for gesture recognition and adaptive response. The project developed a framework and tools to design adaptive environments for enhanced robotic and embodied social interaction that intelligently and fluidly integrates real-time behavioral indices of attentive and gesture information into flexible and controllable response systems.&nbsp; This paradigm may potently impact and accelerate learning regarding core underlying neurodevelopmental impairments of ASD and thereby impact the science of ASD intervention itself.</p> <p>The grant offered research opportunities and training for both graduate and undergraduate students. It also provided research opportunities for high school students in STEM related disciplines. It fostered interdisciplinary research combining engineering and psychological sciences and provided opportunities to mentor early career scientists. The results of this research were disseminated to both scientific and lay communities to underscore the importance of such research endeavors. Ultimately, robot-mediated therapeutic tools that can target and specifically address impairing social communication processes associated with ASD may allow for more widely accessible intervention opportunities of specific impact.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/03/2017<br>      Modified by: Nilanjan&nbsp;Sarkar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Centers for Disease Control and Prevention estimates 1 in 68 children in the United States have an Autism Spectrum Disorder (ASD). ASD is associated with enormous individual, familial, and social costs across the lifespan. Many families and service systems struggle to provide appropriately intensive evidence-based interventions due to extreme resource limitations. As such, there is an urgent need for more efficacious treatments that can be delivered across resource-strained environments. This research project leverages a common preference that many children with ASD show towards technological engagement, to design a novel an Adaptive Robot-mediated Intervention Architecture (ARIA) system that can effectively address social communication deficits associated with ASD.  ARIA was designed to help with two fundamental building blocks for early social communication development, which were coordinated joint attention and imitation skills, using novel robotic interaction paradigms. ARIA fluidly integrates a humanoid robot, a network of spatially distributed cameras and display monitors, as well as complex and efficient computational face, gaze and gesture detection methodologies in order to create a highly flexible and adaptive intelligent intervention environment.  This system will have the potential to advance current intervention practice by gathering individualized behavioral performance data at a level beyond human capacity to inform real-time adaptive response and reinforcement strategies that may accelerate learning in key neurodevelopmental skills areas thought to be critical in the treatment of ASD.  Once the ARIA system was designed and developed, it was tested with children with ASD in several pilot studies. A two-phase joint attention study revealed that children with ASD were engaged in interacting with the robot, paid more attention to the robot than a therapist, performed equally well and did not lose interest in the robot-mediated interaction in multiple sessions. Thus this study established the feasibility of a log-term intervention with ARIA. However, the most important finding was that many children showed improvement in human-human interaction after ARIA-based human-robot interaction. While further research is needed, such skill generalization in real-world is very promising. In robot-mediated gesture imitation skill study, ARIA-based training showed significant improvement in the gesture imitation capabilities of children with ASD. Finally, another study was designed, called Response-to-Name (RTN), where using the essential elements of ARIA we could quantitatively measure how children with ASD and typically developing children respond when their names are called. This has important implication in ASD diagnosis and intervention.  The intellectual merit of this research lies in the design and development of smart environments for learning, intelligent system architecture for adaptive robotics, as well as affective computing and control of dynamic human-robot interaction. In particular, the project significantly contributed towards developing novel efficient applications of computational methods for affective computing, including affective computing mediated by non-invasive gaze and attention processing. It also contributed towards closed-loop gesture-based human-robot interaction by developing new methodologies for gesture recognition and adaptive response. The project developed a framework and tools to design adaptive environments for enhanced robotic and embodied social interaction that intelligently and fluidly integrates real-time behavioral indices of attentive and gesture information into flexible and controllable response systems.  This paradigm may potently impact and accelerate learning regarding core underlying neurodevelopmental impairments of ASD and thereby impact the science of ASD intervention itself.  The grant offered research opportunities and training for both graduate and undergraduate students. It also provided research opportunities for high school students in STEM related disciplines. It fostered interdisciplinary research combining engineering and psychological sciences and provided opportunities to mentor early career scientists. The results of this research were disseminated to both scientific and lay communities to underscore the importance of such research endeavors. Ultimately, robot-mediated therapeutic tools that can target and specifically address impairing social communication processes associated with ASD may allow for more widely accessible intervention opportunities of specific impact.          Last Modified: 11/03/2017       Submitted by: Nilanjan Sarkar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
