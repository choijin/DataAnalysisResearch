<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER:   Collaborative Research:   The Perceptual Basis of Collective Behavior in a Model Vertebrate</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2013</AwardEffectiveDate>
<AwardExpirationDate>12/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>89951.00</AwardTotalIntnAmount>
<AwardAmount>89951</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08090500</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>IOS</Abbreviation>
<LongName>Division Of Integrative Organismal Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michelle Elekonich</SignBlockName>
<PO_EMAI>melekoni@nsf.gov</PO_EMAI>
<PO_PHON>7032927202</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A fundamental problem in biology is understanding how complex systems work from interactions among its components. In many animal groups, such as schooling fish or flocking birds, coordinated movements are thought to result from self-organizing social interactions among individuals. However, little is known about the social cues that the organisms within groups pay attention to and how they integrate them during decision-making, or how these interactions produce collective behavior. The proposed research combines novel experimental and computational approaches to investigate the relationship between sensory input and collective behavior using zebrafish as an experimental model. The research focuses on vision, which is essential in the coordination of many animal groups. The researchers will: (a) characterize key dimensions of the visual system, (b) use this sensory information to model the visual saliency of social cues, (c) incorporate the zebrafish visual information in current models that track the motion of individuals in real shoals, (d) develop and implement new technologies to investigate behavioral responses, and (e) measure these behavioral responses under experimental conditions that manipulate the visual saliency of group mates.  Ultimately, this project will increase our understanding of how and why organisms coordinate their behavior in groups.  The PI and collaborator will disseminate the results and technologies to the broader scientific community through publications, and give public lectures to broad audiences and schools.</AbstractNarration>
<MinAmdLetterDate>08/15/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/15/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1251424</AwardID>
<Investigator>
<FirstName>Esteban</FirstName>
<LastName>Fernandez-Juricic</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Esteban Fernandez-Juricic</PI_FULL_NAME>
<EmailAddress>efernan@purdue.edu</EmailAddress>
<PI_PHON>7654946044</PI_PHON>
<NSF_ID>000386755</NSF_ID>
<StartDate>08/15/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072054</ZipCode>
<StreetAddress><![CDATA[915 West State Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7659</Code>
<Text>Animal Behavior</Text>
</ProgramElement>
<ProgramReference>
<Code>1228</Code>
<Text>MINORITY INVOLVEMENT -- BIO</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~89951</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Biologists and engineers have been interested in collective animal behavior (i.e., coordinated movements of bird flocks, fish schools, mammal herds, insect swarms) for decades, because establishing the rules animals use to coordinate their behavior with group mates can have multiple applied applications (e.g., unmanned aerial vehicles, disease transmission prevention, etc.). These rules have been incorporated into multiple mathematical models that intend to predict the behavior of these groups. Some of these assumptions are associated with the way animals perceive group mates through their sensory systems. Unfortunately, before this project little empirical evidence had been gathered about whether these assumptions were accurate and how they could influence the predictions of collective behavior models. We characterized key dimensions of the zebrafish eye, which has a wide degree of visual coverage and a single center of acute vision per retina that projects into the dorso-frontal portion of the visual field. Based on this visual sensory information, we developed species-specific predictions relative to their collective behavior (i.e., positioning, orientation and spacing of individuals in a group) and corroborated some of them empirically. Additionally, this sensory information allowed us to determine that the sensory assumptions often used in collective behavior mathematical models do not match with the real sensory configuration of the species studied. More importantly, when considering the realistic sensory assumptions, these mathematical models make very different predictions about collective behavior. These findings have important implications for developing future models that better predict collective animal behavior and establishing the sensory cues animals use to track neighbors. Ultimately, this project has the potential to inform the development of more realistic algorithms to better manipulate the interactions between agents in virtual or real environments. &nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/09/2017<br>      Modified by: Esteban&nbsp;Fernandez-Juricic</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Biologists and engineers have been interested in collective animal behavior (i.e., coordinated movements of bird flocks, fish schools, mammal herds, insect swarms) for decades, because establishing the rules animals use to coordinate their behavior with group mates can have multiple applied applications (e.g., unmanned aerial vehicles, disease transmission prevention, etc.). These rules have been incorporated into multiple mathematical models that intend to predict the behavior of these groups. Some of these assumptions are associated with the way animals perceive group mates through their sensory systems. Unfortunately, before this project little empirical evidence had been gathered about whether these assumptions were accurate and how they could influence the predictions of collective behavior models. We characterized key dimensions of the zebrafish eye, which has a wide degree of visual coverage and a single center of acute vision per retina that projects into the dorso-frontal portion of the visual field. Based on this visual sensory information, we developed species-specific predictions relative to their collective behavior (i.e., positioning, orientation and spacing of individuals in a group) and corroborated some of them empirically. Additionally, this sensory information allowed us to determine that the sensory assumptions often used in collective behavior mathematical models do not match with the real sensory configuration of the species studied. More importantly, when considering the realistic sensory assumptions, these mathematical models make very different predictions about collective behavior. These findings have important implications for developing future models that better predict collective animal behavior and establishing the sensory cues animals use to track neighbors. Ultimately, this project has the potential to inform the development of more realistic algorithms to better manipulate the interactions between agents in virtual or real environments.            Last Modified: 04/09/2017       Submitted by: Esteban Fernandez-Juricic]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
