<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDS&amp;E: Collaborative Research:  Least-Squares Finite Element Methods for Data Assimilation in Large-Scale Simulations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>262933.00</AwardTotalIntnAmount>
<AwardAmount>262933</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dimitrios Papavassiliou</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Abstract&lt;br/&gt;&lt;br/&gt;#1249858 / Manteuffel, Thomas&lt;br/&gt;#1249950 / Jeffrey Heys &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The role of computer simulations in scientific discovery continues to grow in many fields, including biology, finance, chemistry, and medicine. In many cases, these computer simulations are based on the solution of partial differential equations, which are mathematical equations that can only be approximately solved on large computers. Scientific discovery is also continuing through the use of more advanced experimental techniques that are enabling us to obtain more data than ever before and obtain new data that was not available previously. A critical need for scientists now is an approach for combining the computer simulations with the abundant data that is now available. To help address this need, we are proposing the development of advanced least-square finite element methods, which have a number of advantages for solving this problem of combining computer simulations with experimental data. First, the approach is flexible enough that it can assimilate data from any location in the simulation. If you are simulating blood flow through a vessel, the experimental data can be located anywhere, including near the wall or near the center of the vessel. Second, the approach can account for the accuracy of the experimental data. If the blood flow data is more accurate near the center of the vessel than near the wall, the simulation will more closely match the accurate data near the center, and it will not match the data near the wall as closely because the data likely contains significant error. A final advantage for the proposed approach is that it is computationally efficient. It has been designed from the beginning to work well with scalable, multilevel mathematical techniques and work well on modern, multiprocessor computer architectures. This is not an approach that will be overwhelmed by large, complex problems, but it will be efficient on today's computers and tomorrow's computers. &lt;br/&gt;&lt;br/&gt;If a mechanic wishes to assess the condition of a cars engine, they will open up the hood and inspect the critical parts of the engine. The assessment of the health of the heart is a much more challenging problem because we cannot easily and safely open up the hood. An alternative approach is for a cardiologist to inject FDA approved microbubbles, these are bubbles that are smaller than red blood cells, into the blood, and then these microbubbles can be safely visualized using an external ultrasound machine. The movement of these microbubbles gives an indication of the blood flow in the heart, but more information is needed to properly assess the health of the heart. Specifically, cardiologists are interested in pressure changes in the heart and the overall efficiency of the heart. To obtain this additional information, we can simulate the flow of blood in the heart on a computer, and, ideally, combine the data from the moving microbubbles with the computer simulation so that we can obtain information specific to each individuals own heart. Problems that require us to combine a computer simulation with experimental data are becoming increasing common in fields from medicine to microbiology to meteorology. The work described in this proposal will provide a powerful new tool for combining experimental data with computer simulations. The approach will allow scientist to account for the accuracy of the data so that the more accurate data will be matched closely by the simulation and less accurate data will not match the simulation as well. The approach will be efficient on the next generation of computers because it supports advanced mathematic techniques. Overall, the positive impact of this approach should extent to many different scientific fields. The project will involve graduate and undergraduate students at both Montana State University and the University of Colorado-Boulder, and these students will interact extensively between universities. The project will also include the development of new engineering and mathematics course content and support scientific conferences.</AbstractNarration>
<MinAmdLetterDate>09/04/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/04/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1249858</AwardID>
<Investigator>
<FirstName>Thomas</FirstName>
<LastName>Manteuffel</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thomas A Manteuffel</PI_FULL_NAME>
<EmailAddress>tmanteuf@colorado.edu</EmailAddress>
<PI_PHON>3038847423</PI_PHON>
<NSF_ID>000300357</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Steve</FirstName>
<LastName>McCormick</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steve F McCormick</PI_FULL_NAME>
<EmailAddress>stevem@colorado.edu</EmailAddress>
<PI_PHON>4803322026</PI_PHON>
<NSF_ID>000452400</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Boulder</Name>
<CityName>Boulder</CityName>
<ZipCode>803031058</ZipCode>
<PhoneNumber>3034926221</PhoneNumber>
<StreetAddress>3100 Marine Street, Room 481</StreetAddress>
<StreetAddress2><![CDATA[572 UCB]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>007431505</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF COLORADO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431505</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Colorado at Boulder]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803090572</ZipCode>
<StreetAddress><![CDATA[3100 Marine Street, Room 479]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~262933</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The focus of this effort is the use of the least-squares finite element method (LSFEM), and related methods such as the first-order system least-squares adjoint method (FOSLL*) and hybrid methods, to develop a new approach to data assimilation problems in the numerical solution of partial differential equations.&nbsp; We have developed an approach that can assimilate data in a weighted manner that respects the accuracy of the data. This allows the model to strongly match accurate data more closely by the approximate solution to the partial differential equation and to weakly match less accurate data.&nbsp; Major Activities have as a unifying theme to develop a more robust and simple framework for assimilating experimental data into the solution of the mathematical model.&nbsp; Our vision is an approach that other researchers can quickly utilize without the need for many months of frustration while trying to get it to work.</p> <p>&nbsp;</p> <p>We have made significant progress in supporting complex geometries, a range of different mathematical models beyond Navier-Stokes, improved computational performance, and the ability to automatically determine previously unknown parameters.&nbsp; All of these changes guide us towards a simpler and more robust approach that can be easily used by others.&nbsp;</p> <p>&nbsp;</p> <p>One major activity to highlight from the project is associated with objective 3: improvements to computational accuracy and stability.&nbsp; The original approach was based on using weighted LSFEM to solve the model partial differential equations and data assimilation in a single functional.&nbsp; This approach was relatively straightforward, but it was limited in certain applications where there was an existing, optimized numerical approach for solving the partial differential equations that was different from LSFEM.&nbsp; During the course of this project we recognized that in many cases it is possible to use an existing numerical approach to solve the model equations, and then use the weighted LSFEM approach to solve a smaller problem using the prior numerical solution and the data for assimilation.&nbsp; This is very much a one-step Bayesian approach &ndash; the initial numerical solution to the model equations is used as the Bayesian prior, and then an updated and improved prediction can be obtained using the prior and assimilated data from experiments.&nbsp; The calculation of the improved prediction is, of course, obtained using the weighted least-squares finite element approach.</p> <p>This approach is easiest to illustrate through a simple example.&nbsp; If we wish to simulate blood flow in the left ventricle of the heart and assimilate PIV microbubble data into the final solution, we start by solving the model equations using any existing algorithm and obtain the vorticity from that numerical solution.&nbsp; The numerical solution for the vorticity is then used as an input for a small LSFEM problem that calculates the velocity by solving a small div-curl system with boundary conditions and assimilated experimental data.&nbsp; The advantages of this approach are simplified algorithm development, the ability to reuse existing numerical algorithm, and significantly reduced computational costs (e.g., a factor of 3) in many cases.</p><br> <p>            Last Modified: 09/17/2015<br>      Modified by: Thomas&nbsp;A&nbsp;Manteuffel</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The focus of this effort is the use of the least-squares finite element method (LSFEM), and related methods such as the first-order system least-squares adjoint method (FOSLL*) and hybrid methods, to develop a new approach to data assimilation problems in the numerical solution of partial differential equations.  We have developed an approach that can assimilate data in a weighted manner that respects the accuracy of the data. This allows the model to strongly match accurate data more closely by the approximate solution to the partial differential equation and to weakly match less accurate data.  Major Activities have as a unifying theme to develop a more robust and simple framework for assimilating experimental data into the solution of the mathematical model.  Our vision is an approach that other researchers can quickly utilize without the need for many months of frustration while trying to get it to work.     We have made significant progress in supporting complex geometries, a range of different mathematical models beyond Navier-Stokes, improved computational performance, and the ability to automatically determine previously unknown parameters.  All of these changes guide us towards a simpler and more robust approach that can be easily used by others.      One major activity to highlight from the project is associated with objective 3: improvements to computational accuracy and stability.  The original approach was based on using weighted LSFEM to solve the model partial differential equations and data assimilation in a single functional.  This approach was relatively straightforward, but it was limited in certain applications where there was an existing, optimized numerical approach for solving the partial differential equations that was different from LSFEM.  During the course of this project we recognized that in many cases it is possible to use an existing numerical approach to solve the model equations, and then use the weighted LSFEM approach to solve a smaller problem using the prior numerical solution and the data for assimilation.  This is very much a one-step Bayesian approach &ndash; the initial numerical solution to the model equations is used as the Bayesian prior, and then an updated and improved prediction can be obtained using the prior and assimilated data from experiments.  The calculation of the improved prediction is, of course, obtained using the weighted least-squares finite element approach.  This approach is easiest to illustrate through a simple example.  If we wish to simulate blood flow in the left ventricle of the heart and assimilate PIV microbubble data into the final solution, we start by solving the model equations using any existing algorithm and obtain the vorticity from that numerical solution.  The numerical solution for the vorticity is then used as an input for a small LSFEM problem that calculates the velocity by solving a small div-curl system with boundary conditions and assimilated experimental data.  The advantages of this approach are simplified algorithm development, the ability to reuse existing numerical algorithm, and significantly reduced computational costs (e.g., a factor of 3) in many cases.       Last Modified: 09/17/2015       Submitted by: Thomas A Manteuffel]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
