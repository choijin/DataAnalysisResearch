<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Collaborative Research: Adaptive Automatic Parallelization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>249998.00</AwardTotalIntnAmount>
<AwardAmount>249998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>To effectively exploit the power of multi-core processors, programs must be structured as a collection of independent tasks, where separate tasks execute on independent cores.  The complexity of modern software makes it difficult for programmers to express their algorithms within this model, both due to the amount of program analysis needed to identify regions of code that can run in parallel, and the likelihood that different regions of code will be best suited by distinct, and possibly incompatible, models of parallel computing.  In particular, some codes are best parallelized through speculative techniques, while others favor regular analysis, such as that provided by the polyhedral approach.&lt;br/&gt;&lt;br/&gt;The proposed research addresses fundamental issues in the creation of parallel programs through a novel combination of automatic and profile-driven techniques.  The heart of the research is a robust system based on machine learning, through which a compilation tool can analyze a program, assess the suitability of a variety of parallelization techniques to that program, and then apply the most promising techniques automatically.  At run-time, the program will also employ learning to adapt its behavior according to inputs and environment.  Furthermore, the programmer will be given a profile-driven feedback mechanism, in order to guide the tool to refine its parallelization of the program, and guide the program's self-tuning behavior.  In conjunction with the creation of this system, new algorithms and tools for speculative parallelization and large-scale program analysis will be invented. Prototypes and source code will be distributed as open-source software.</AbstractNarration>
<MinAmdLetterDate>09/04/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/04/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218734</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Cavazos</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr</PI_SUFX_NAME>
<PI_FULL_NAME>John Cavazos</PI_FULL_NAME>
<EmailAddress>cavazos@cis.udel.edu</EmailAddress>
<PI_PHON>3028312136</PI_PHON>
<NSF_ID>000500366</NSF_ID>
<StartDate>09/04/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Delaware</Name>
<CityName>Newark</CityName>
<ZipCode>197160099</ZipCode>
<PhoneNumber>3028312136</PhoneNumber>
<StreetAddress>210 Hullihen Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<StateCode>DE</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DE00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>059007500</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF DELAWARE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>059007500</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Delaware]]></Name>
<CityName>Newark</CityName>
<StateCode>DE</StateCode>
<ZipCode>197110099</ZipCode>
<StreetAddress><![CDATA[Hullihen Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DE00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramReference>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramReference>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~249998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="western"><span style="color: #333333;"><span style="font-family: Arial, Helvetica, sans-serif;"><span>The research done for this grant involved developing program characterization techniques and using machine learning for program auto-parallelization and for application energy efficiency.</span></span></span></p> <p class="western"><span style="color: #333333;"><span style="font-family: Arial, Helvetica, sans-serif;"><span>The first part of this project involved d</span></span></span><span style="color: #000000;"><span style="font-family: arial, helvetica, sans-serif;"><span>eveloping a polyhedral compiler that generates accelerator code (i.e., OpenACC). In particular, we were able to generate code that runs on GPUs and on Intel Phi accelerator cards. Our modified polyhedral compiler takes in a sequential program as input and outputs OpenACC code. The OpenACC code can be translated into OpenCL code which runs on heterogeneous platforms like GPUs and MIC (Many-Integrated-Core) cards. We have also developed several patterns using a system called HERCULES from Oak Ridge National Laboratory that can be used to drive the optimization and parallelization done by our compiler. </span></span></span><span style="color: #333333;"><span style="font-family: Arial, Helvetica, sans-serif;"><span>In this framework, the goal is to </span></span></span><span style="color: #333333;"><span style="font-family: arial, helvetica, sans-serif;"><span>identify good mixtures of static and dynamic characteristics of a program to be used with machine learning models to drive auto-parallelization in our compiler. The accuracy of our learning models that will predict the right parallelization to be used for a particular program segment depends on the features used. The pattern-based system (HERCULES from ORNL) outperforms state-of-the art program characterization techniques in feeding machine learning models with representative static program features. </span></span></span></p> <p class="western"><span style="color: #333333;"><span style="font-family: Arial, Helvetica, sans-serif;"><span>The second part of the project funded by this grant involved applying program characterization and machine learning techniques for the application of energy optimization. Our goal was to automatically find the code regions of parallel programs with certain characteristics that could offer power saving opportunities, using machine learning techniques. By studying the memory traffic of application code regions, we applied CPU clock modulation techniques to improve application energy. CPU clock modulation is a power saving technique offered on recent Intel architectures. Its advantage over more widely known DVFS includes the faster frequency transition speed and per-core frequency control. We also constructed machine learning models to predict the parallelization of code that produces the most energy efficient version of the code.</span></span></span></p> <p class="western"><span style="color: #333333;"><span style="font-family: Arial, Helvetica, sans-serif;"><span>&nbsp;</span></span></span></p> <blockquote><br /></blockquote> <p>&nbsp;</p><br> <p>            Last Modified: 04/22/2016<br>      Modified by: John&nbsp;Cavazos</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The research done for this grant involved developing program characterization techniques and using machine learning for program auto-parallelization and for application energy efficiency. The first part of this project involved developing a polyhedral compiler that generates accelerator code (i.e., OpenACC). In particular, we were able to generate code that runs on GPUs and on Intel Phi accelerator cards. Our modified polyhedral compiler takes in a sequential program as input and outputs OpenACC code. The OpenACC code can be translated into OpenCL code which runs on heterogeneous platforms like GPUs and MIC (Many-Integrated-Core) cards. We have also developed several patterns using a system called HERCULES from Oak Ridge National Laboratory that can be used to drive the optimization and parallelization done by our compiler. In this framework, the goal is to identify good mixtures of static and dynamic characteristics of a program to be used with machine learning models to drive auto-parallelization in our compiler. The accuracy of our learning models that will predict the right parallelization to be used for a particular program segment depends on the features used. The pattern-based system (HERCULES from ORNL) outperforms state-of-the art program characterization techniques in feeding machine learning models with representative static program features.  The second part of the project funded by this grant involved applying program characterization and machine learning techniques for the application of energy optimization. Our goal was to automatically find the code regions of parallel programs with certain characteristics that could offer power saving opportunities, using machine learning techniques. By studying the memory traffic of application code regions, we applied CPU clock modulation techniques to improve application energy. CPU clock modulation is a power saving technique offered on recent Intel architectures. Its advantage over more widely known DVFS includes the faster frequency transition speed and per-core frequency control. We also constructed machine learning models to predict the parallelization of code that produces the most energy efficient version of the code.              Last Modified: 04/22/2016       Submitted by: John Cavazos]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
