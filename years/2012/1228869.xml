<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TWC: Medium: Collaborative: Towards Secure, Robust, and Usable Gesture-Based Authentication</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ralph Wachter</SignBlockName>
<PO_EMAI>rwachter@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project investigates the feasibility of secure, robust, and usable gesture-based authentication as an alternative to traditional alphanumeric passwords and biometrics. It is motivated by the rapid increase in authentication-related security breaches and by the emergence of new human-computer interfaces. While the breaches have demonstrated the seriousness of the issue, two emerging types of gesture-based interfaces, multi-touch (smartphones, tablets) and camera-based (Kinect), offer a unique opportunity for robust solution.&lt;br/&gt;&lt;br/&gt;The benefit of gesture-based authentication over a purely-biometric one lies in the fact that it combines involuntary biometric features (e.g., hand shape), that are irrevocable, with user-controlled voluntary characteristics that can be easily changed. Three research thrusts are being pursued: 1) gesture recognition algorithms (search for robust gesture features, their compact representation, and reliable classification algorithms), 2) human factors (study of uniqueness, repeatability, ergonomics, device dependence of gestures, and gesture complexity) and 3) security considerations (evaluation of authentication performance under a range of performance measures and different threat models). &lt;br/&gt;&lt;br/&gt;A successful completion of this research will catalyze the development and adoption of next-generation authentication methods that are critically needed at the personal, institutional, and governmental levels. As the price paid (time, money, and resources) to repair a security breach can be astounding, this project will have substantial societal impact by increasing the sense of security and reducing breach-related costs. At educational level, this project is involved in middle and high school outreach at Boston University as well as the annual cybsersecurity competition CSAW at NYU-Poly.</AbstractNarration>
<MinAmdLetterDate>08/17/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1228869</AwardID>
<Investigator>
<FirstName>Janusz</FirstName>
<LastName>Konrad</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Janusz Konrad</PI_FULL_NAME>
<EmailAddress>jkonrad@bu.edu</EmailAddress>
<PI_PHON>6173531246</PI_PHON>
<NSF_ID>000104869</NSF_ID>
<StartDate>08/17/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Prakash</FirstName>
<LastName>Ishwar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Prakash Ishwar</PI_FULL_NAME>
<EmailAddress>pi@bu.edu</EmailAddress>
<PI_PHON>6173583499</PI_PHON>
<NSF_ID>000310021</NSF_ID>
<StartDate>08/17/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022151300</ZipCode>
<StreetAddress><![CDATA[881 Commonwealth Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In the last decade, we have witnessed proliferation of two disruptive technologies: multi-touch surfaces employed in smartphones, tablets, laptops and even some desktops, and depth cameras extensively used in gaming and computer interfaces. However, these emerging human-machine interfaces still rely on old-fashioned forms of user authentication, such as typing an alphanumeric password, which may be inconvenient to enter (depending on the interface) and difficult to remember (especially long, secure passwords). In this collaborative project we have investigated the feasibility of intuitive, yet robust, user authentication via full-body and hand gestures recorded by a depth camera (our partners focused on authentication via finger swipes on a multi-touch surface).</p> <p>To study gesture passwords, a dataset of gestures for many users is needed. However, datasets available to date contain many different gestures for few users as they are meant for gesture recognition rather than user recognition. Therefore, we collected two new datasets, one with full-body gestures (BodyLogin, 40 users) and another one with hand-only gestures (HandLogin, 21 users) that we made available to research community. Using these datasets we developed several new user authentication (given a user&rsquo;s name and gesture password, check if they match) and user identification (given a gesture password, find a user it belongs to) algorithms. The best of these algorithms results in about 1 failed attempt per 100 tries to login via gesture and, similarly, about 1 unauthorized login per 100 tries. We have analyzed contributions of user&rsquo;s initial pose, body build and gesture dynamics to this performance. While the initial pose and body build by themselves can deliver a respectable performance of about 4 errors per 100 tries, it is the gesture dynamics that bring this to less than 1 error per 100 tries. More importantly, however, gesture dynamics allow to change a gesture password should it ever be compromised, a property known as password renewability. This would be very difficult to accomplish with initial posture and impossible with body build or, for that matter, with fingerprint, iris, or face &nbsp;which are commonly used biometrics.</p> <p>A common user authentication method today requires entry of a unique alphanumeric password. However, a gesture is not unique &ndash; a user cannot perfectly repeat a gesture each time. Therefore, a degree of error is permitted, which may lead to an unauthorized login or a failed attempt by an authorized user, and needs to be judiciously selected to balance convenience and security. We have leveraged this degree of uncertainty by authenticating a user based on his/her ``style&rsquo;&rsquo; of performing a gesture instead of performing a specific gesture password. To do so, we have exploited the called ``deep learning&rsquo;&rsquo;. It is a branch of machine learning where an artificial neural network, mimicking some functions of the human brain, is trained by large amounts of data to perform a classification task at hand. Applied to user authentication or identification, this allows a user to perform a gesture that is similar to the enrolled one but not necessarily identical to it. A key practical outcome is that there is no need to retrain the algorithm as long as users do not use dramatically different gestures. With some degradation in performance, a similar new gesture can still be used for convenience. A visual illustration of the performance of deep learning is shown in the attached figure. Note how well deep learning features group users in the left column, whereas another method (using silhouette covariances) groups gestures (right column) rather than users. The tight grouping of users allows for accurate authentication or identification of users. This is a new, promising paradigm in user authentication for emerging interfaces, such as gestures and swipes.</p> <p>Although focused on gesture-based&nbsp;authentication, a secondary outcome of the data, features, representations, and algorithms developed in this project is that they can also be utilized for gesture recognition (as opposed to person recognition) and for&nbsp;developing next-generation human computer interfaces, e.g., virtual keyboard, gesture mouse, etc., based on&nbsp;emerging depth-sensing&nbsp;devices.</p> <p>Beyond scientific outcomes, 1 PhD, 4 undergraduate and 2 high-school students received training within this project. The participation of high-school students is particularly noteworthy since it is not straightforward to get students at such an early stage of learning engaged in rigorous, math-oriented research. Furthermore, one of these students was instrumental in initiating a project on authentication from hand gestures that eventually lead to a conference publication with her being a co-author. Overall, this project has generated 1 journal paper (submitted), 1 book chapter (under review), and 6 conference papers.</p> <p>This project has established a solid foundation upon which a new class of authentication methods at the personal, institutional, and governmental levels can be built. This can have a substantial societal impact by&nbsp;increasing the sense of security and reducing the significant costs associated with repairing a security breach.</p><br> <p>            Last Modified: 11/17/2016<br>      Modified by: Janusz&nbsp;Konrad</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1228869/1228869_10202793_1479361315804_t-SNE_NSF_report--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1228869/1228869_10202793_1479361315804_t-SNE_NSF_report--rgov-800width.jpg" title="User recognition versus gesture recognition"><img src="/por/images/Reports/POR/2016/1228869/1228869_10202793_1479361315804_t-SNE_NSF_report--rgov-66x44.jpg" alt="User recognition versus gesture recognition"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Visualization of user separation capacity of deep learning versus gesture separation capacity of covariance features. The tight grouping of users on left permits accurate authentication via deep learning, and the tight grouping of gestures on right allows accurate gesture recognition via covariance.</div> <div class="imageCredit">Jonathan Wu, Prakash Ishwar, Janusz Konrad</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Janusz&nbsp;Konrad</div> <div class="imageTitle">User recognition versus gesture recognition</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In the last decade, we have witnessed proliferation of two disruptive technologies: multi-touch surfaces employed in smartphones, tablets, laptops and even some desktops, and depth cameras extensively used in gaming and computer interfaces. However, these emerging human-machine interfaces still rely on old-fashioned forms of user authentication, such as typing an alphanumeric password, which may be inconvenient to enter (depending on the interface) and difficult to remember (especially long, secure passwords). In this collaborative project we have investigated the feasibility of intuitive, yet robust, user authentication via full-body and hand gestures recorded by a depth camera (our partners focused on authentication via finger swipes on a multi-touch surface).  To study gesture passwords, a dataset of gestures for many users is needed. However, datasets available to date contain many different gestures for few users as they are meant for gesture recognition rather than user recognition. Therefore, we collected two new datasets, one with full-body gestures (BodyLogin, 40 users) and another one with hand-only gestures (HandLogin, 21 users) that we made available to research community. Using these datasets we developed several new user authentication (given a user?s name and gesture password, check if they match) and user identification (given a gesture password, find a user it belongs to) algorithms. The best of these algorithms results in about 1 failed attempt per 100 tries to login via gesture and, similarly, about 1 unauthorized login per 100 tries. We have analyzed contributions of user?s initial pose, body build and gesture dynamics to this performance. While the initial pose and body build by themselves can deliver a respectable performance of about 4 errors per 100 tries, it is the gesture dynamics that bring this to less than 1 error per 100 tries. More importantly, however, gesture dynamics allow to change a gesture password should it ever be compromised, a property known as password renewability. This would be very difficult to accomplish with initial posture and impossible with body build or, for that matter, with fingerprint, iris, or face  which are commonly used biometrics.  A common user authentication method today requires entry of a unique alphanumeric password. However, a gesture is not unique &ndash; a user cannot perfectly repeat a gesture each time. Therefore, a degree of error is permitted, which may lead to an unauthorized login or a failed attempt by an authorized user, and needs to be judiciously selected to balance convenience and security. We have leveraged this degree of uncertainty by authenticating a user based on his/her ``style?? of performing a gesture instead of performing a specific gesture password. To do so, we have exploited the called ``deep learning??. It is a branch of machine learning where an artificial neural network, mimicking some functions of the human brain, is trained by large amounts of data to perform a classification task at hand. Applied to user authentication or identification, this allows a user to perform a gesture that is similar to the enrolled one but not necessarily identical to it. A key practical outcome is that there is no need to retrain the algorithm as long as users do not use dramatically different gestures. With some degradation in performance, a similar new gesture can still be used for convenience. A visual illustration of the performance of deep learning is shown in the attached figure. Note how well deep learning features group users in the left column, whereas another method (using silhouette covariances) groups gestures (right column) rather than users. The tight grouping of users allows for accurate authentication or identification of users. This is a new, promising paradigm in user authentication for emerging interfaces, such as gestures and swipes.  Although focused on gesture-based authentication, a secondary outcome of the data, features, representations, and algorithms developed in this project is that they can also be utilized for gesture recognition (as opposed to person recognition) and for developing next-generation human computer interfaces, e.g., virtual keyboard, gesture mouse, etc., based on emerging depth-sensing devices.  Beyond scientific outcomes, 1 PhD, 4 undergraduate and 2 high-school students received training within this project. The participation of high-school students is particularly noteworthy since it is not straightforward to get students at such an early stage of learning engaged in rigorous, math-oriented research. Furthermore, one of these students was instrumental in initiating a project on authentication from hand gestures that eventually lead to a conference publication with her being a co-author. Overall, this project has generated 1 journal paper (submitted), 1 book chapter (under review), and 6 conference papers.  This project has established a solid foundation upon which a new class of authentication methods at the personal, institutional, and governmental levels can be built. This can have a substantial societal impact by increasing the sense of security and reducing the significant costs associated with repairing a security breach.       Last Modified: 11/17/2016       Submitted by: Janusz Konrad]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
