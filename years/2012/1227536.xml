<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI-Large: Collaborative Research: Multilateral Manipulation by Human-Robot Collaborative Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1168000.00</AwardTotalIntnAmount>
<AwardAmount>1168000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>jeffrey trinkle</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project addresses a large space of manipulation problems that are repetitive, injury-causing, or dangerous for humans to perform, yet are currently impossible to reliably achieve with purely autonomous robots. These problems generally require dexterity, complex perception, and complex physical interaction. Yet, many such problems can be reliably addressed with human/robot collaborative (HRC) systems, where one or more humans provide needed perception and adaptability, working with one or more robot systems that provide speed, precision, accuracy, and dexterity at an appropriate scale, combining these complementary capabilities.&lt;br/&gt;&lt;br/&gt;The project focuses on multilateral manipulation, which arises when a human controls one or more robot manipulators in partnership with one or more additional controllers (humans or autonomous agents). Complex operations in surgery and manufacturing can benefit from the extra degrees of freedom provided by more than two hands, and training often depends on hands-on interaction between expert and apprentice. Example applications include surgical operations, which typically involve several physicians and assistants, and other medical tasks such as turning a patient in bed and wrapping a cast to constrain a hand. Multilateral manipulation also applies in manufacturing, for example for threading wires or cables, aligning gaskets to obtain a tight seal, and in many household situations, such as folding tablecloths, wrapping packages, and zipping overfilled suitcases so they will fit inside diabolically-designed overhead airline compartments. Multilateral manipulation often arises with deformable materials or multi-jointed objects with more than six degrees of freedom (DOF). The extra DOFs in materials introduce challenges such as computational complexity, but they also can accommodate minor inconsistencies through redundancy and provide system damping. This project advances the fundamental science of multilateral manipulation guided by specific applications from surgery and manufacturing.&lt;br/&gt;&lt;br/&gt;Broader Impacts: Multilateral manipulation systems have the potential to improve healthcare, improve American competitiveness and product quality in manufacturing, and open the door to new service robot applications in the home. The project will be guided by an Advisory Board of experts from industry and medical practice. Project results will be disseminated through yearly conference workshops, open-source software tools integrated into common robotics software environments such as Robot Operating System (ROS), and the investigators' research and course webpages, to encourage integration of our approach into research projects and courses at many institutions. Outreach programs, public lab tours, and mentoring of minority students will broaden participation of underrepresented groups in engineering. These activities will encourage participation in STEM activities and provide student and postdoctoral researchers with mentoring experience.</AbstractNarration>
<MinAmdLetterDate>09/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1227536</AwardID>
<Investigator>
<FirstName>Ken</FirstName>
<LastName>Goldberg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ken Goldberg</PI_FULL_NAME>
<EmailAddress>goldberg@berkeley.edu</EmailAddress>
<PI_PHON>5106439565</PI_PHON>
<NSF_ID>000221423</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Pieter</FirstName>
<LastName>Abbeel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pieter Abbeel</PI_FULL_NAME>
<EmailAddress>pabbeel@cs.berkeley.edu</EmailAddress>
<PI_PHON>5106428109</PI_PHON>
<NSF_ID>000511407</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947201776</ZipCode>
<StreetAddress><![CDATA[Computer Science, Soda Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~773478</FUND_OBLG>
<FUND_OBLG>2013~394522</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-9bd3a530-2dc8-a804-191a-2a2a26eb3802"> <span id="docs-internal-guid-9bd3a530-2dc9-0bc8-1c4a-c32c61efb8a0"> NSF NRI-Large: Collaborative Research: Multilateral Manipulation by Human-Robot Collaborative Systems, Federal Award ID: 1227536&nbsp;</span>Period: 10/01/2015 to 09/30/2016</span></p> <p>&nbsp;</p> <p><span id="docs-internal-guid-9bd3a530-2dc8-a804-191a-2a2a26eb3802"> <p dir="ltr"><span>This 4-year multi-campus research project investigated the expert-apprentice relationship between humans and robots, developing new ways for robots to learn from and help humans by enabling multilateral manipulation, where a human controls one or more devices in partnership with one or more robotic manipulators. &nbsp;Multilateral manipulation is useful for handling deformable materials which can accommodate minor inconsistencies through redundancy and provide system damping. This project advanced the fundamental science of multilateral manipulation guided by specific applications from robot-assisted surgery.</span></p> <p dir="ltr"><span>Intellectual Merit: &nbsp;The UC Berkeley PIs on the project, Pieter Abbeel and Ken Goldberg, &nbsp;worked with undergraduate, graduate, postdoctoral students to develop new algorithmic tools for modeling, simulating, designing, and monitoring multilateral manipulation systems, including automated segmentation by recognizing significant transitions in system status. The project built on emerging advances in robot learning, stochastic motion planning, open-source software, and robot learning from human demonstrations. The project developed new models and algorithms for robot grasping and manipulation in the presence of uncertainty in pose, friction, and control, bringing together ideas from Partially-Observed Markov Decision Processes, Belief Space Planning, Gaussian Process Implicit Surfaces and Multi-Armed Bandit models of sequential optimization. &nbsp;The project also developed new algorithms for leveraging Cloud Robotics including a survey paper and the &ldquo;Dexterity Network,&rdquo; an implemented dataset of over 10,000 3D object mesh models and over 2.5M robust grasps computed by efficiently sampling pertubations in pose, friction, and control using Muti-View Neural Networks to efficiently identify similar objects in the dataset from viewpoints. &nbsp;The project also developed new algorithms to facilitate robot learning manipulation of non-rigid objects (such as cloth and rope) from observing human demonstrations, and new algorithms for robot motion planning over long time horizons by segmenting demonstrations by clustering transition events in state space and new algorithms for motion planning that combine the benefits of randomized sampling based planners and optimization based planners.</span></p> <p dir="ltr"><span>Under this project a number of application-oriented advances were made, including a novel approach to personalized radiation delivery using 3D printed implants where internal channels are optimized using a novel motion planning algorithm for intracavitary brachytherapy radiation delivery. The project developed a number of advances in robot-assisted surgery, including autonomous multilateral debridement (</span><span>removal of damaged tissue or foreign objects from a wound) and learning to tension and cut 2D orthotropic and 3D viscoelastic tissue phantoms, a well-known challenge for surgical residents. &nbsp;The project also developed new methods for learning to grasp complex 3D objects in clutter which is applicable to home decluttering and warehouse order packing.</span></p> <p dir="ltr"><span>This project also resulted in several novel devices for automating surgical subtasks: &nbsp;a single-use palpation probe, a fluid injector for stem cells, and interchangeable mounts for surgical tools. &nbsp;Papers describing each have been published, and two provisional patent applications have been filed. &nbsp;The project also resulted in the design of a novel haptic display, the </span><span>Slip-Pad, which uses interleaved moving belts to produce a range of lateral and rotational slip sensations at the fingertip that can be used for robot feedback.</span></p> <p dir="ltr"><span>Broader Impacts: The project has made technical advances that have the potential to improve healthcare, improve American competitiveness in logistics and manufacturing, and open the door to new service robot applications in the home. &nbsp;Findings were reported in peer-reviewed publications in the leading robotics venues (such as ICRA, IROS, RSS, CASE), presentations at conferences and workshops, over 50 invited lectures, press articles (including The New York Times and MIT Technology Review), and in the short documentary film: &ldquo;Why We Love Robots.&rdquo;</span></p> <span>The work has contributed to establishing shared software for the da Vinci Research Kit and RAVEN II, state-of-the-art experimental research platforms in surgical robotics. &nbsp;The project contributed to the training of a post-doc, seven PhD students and over twenty undergraduate researchers, many of whom have gone on to top-tier PhD programs. The project also enabled the principal investigators to host over sixty outreach visits at their labs (to encourage interest in STEM fields) and to share their instructional materials with tens of thousands of students anywhere in the world through a MOOC on Artificial Intelligence on edX as well as with other instructors for teaching their courses. &nbsp;The Berkeley AI course materials have been used by over 60 other instructors.</span></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 12/23/2016<br>      Modified by: Ken&nbsp;Goldberg</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1227536/1227536_10213740_1482531725053_MM-Image-1--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1227536/1227536_10213740_1482531725053_MM-Image-1--rgov-800width.jpg" title="Multilateral Surgical Debridement"><img src="/por/images/Reports/POR/2016/1227536/1227536_10213740_1482531725053_MM-Image-1--rgov-66x44.jpg" alt="Multilateral Surgical Debridement"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Autonomous multilateral surgical subtasks with the da Vinci Research Kit.  Left: Debridement of 3D Viscoelastic Tissue Phantoms in which small target fragments are removed from a phantom. Right: Pattern Cutting of 2D Orthotropic Tissue Phantoms, the objective is to cut out a specified circular area.</div> <div class="imageCredit">Ken Goldberg and Pieter Abbeel</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Ken&nbsp;Goldberg</div> <div class="imageTitle">Multilateral Surgical Debridement</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1227536/1227536_10213740_1482531810583_MM-image-2--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1227536/1227536_10213740_1482531810583_MM-image-2--rgov-800width.jpg" title="NRI MM Outreach visit"><img src="/por/images/Reports/POR/2016/1227536/1227536_10213740_1482531810583_MM-image-2--rgov-66x44.jpg" alt="NRI MM Outreach visit"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The UC Berkeley PIs hosted over 50 educational groups, showing robot demos and explaining our research, to motivate studying STEM disciplines.  This image shows one of the groups who visited our lab, Girls Who Code.  See:  rll.berkeley.edu/outreach.</div> <div class="imageCredit">Pieter Abbeel and Ken Goldberg</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Ken&nbsp;Goldberg</div> <div class="imageTitle">NRI MM Outreach visit</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   NSF NRI-Large: Collaborative Research: Multilateral Manipulation by Human-Robot Collaborative Systems, Federal Award ID: 1227536 Period: 10/01/2015 to 09/30/2016      This 4-year multi-campus research project investigated the expert-apprentice relationship between humans and robots, developing new ways for robots to learn from and help humans by enabling multilateral manipulation, where a human controls one or more devices in partnership with one or more robotic manipulators.  Multilateral manipulation is useful for handling deformable materials which can accommodate minor inconsistencies through redundancy and provide system damping. This project advanced the fundamental science of multilateral manipulation guided by specific applications from robot-assisted surgery. Intellectual Merit:  The UC Berkeley PIs on the project, Pieter Abbeel and Ken Goldberg,  worked with undergraduate, graduate, postdoctoral students to develop new algorithmic tools for modeling, simulating, designing, and monitoring multilateral manipulation systems, including automated segmentation by recognizing significant transitions in system status. The project built on emerging advances in robot learning, stochastic motion planning, open-source software, and robot learning from human demonstrations. The project developed new models and algorithms for robot grasping and manipulation in the presence of uncertainty in pose, friction, and control, bringing together ideas from Partially-Observed Markov Decision Processes, Belief Space Planning, Gaussian Process Implicit Surfaces and Multi-Armed Bandit models of sequential optimization.  The project also developed new algorithms for leveraging Cloud Robotics including a survey paper and the "Dexterity Network," an implemented dataset of over 10,000 3D object mesh models and over 2.5M robust grasps computed by efficiently sampling pertubations in pose, friction, and control using Muti-View Neural Networks to efficiently identify similar objects in the dataset from viewpoints.  The project also developed new algorithms to facilitate robot learning manipulation of non-rigid objects (such as cloth and rope) from observing human demonstrations, and new algorithms for robot motion planning over long time horizons by segmenting demonstrations by clustering transition events in state space and new algorithms for motion planning that combine the benefits of randomized sampling based planners and optimization based planners. Under this project a number of application-oriented advances were made, including a novel approach to personalized radiation delivery using 3D printed implants where internal channels are optimized using a novel motion planning algorithm for intracavitary brachytherapy radiation delivery. The project developed a number of advances in robot-assisted surgery, including autonomous multilateral debridement (removal of damaged tissue or foreign objects from a wound) and learning to tension and cut 2D orthotropic and 3D viscoelastic tissue phantoms, a well-known challenge for surgical residents.  The project also developed new methods for learning to grasp complex 3D objects in clutter which is applicable to home decluttering and warehouse order packing. This project also resulted in several novel devices for automating surgical subtasks:  a single-use palpation probe, a fluid injector for stem cells, and interchangeable mounts for surgical tools.  Papers describing each have been published, and two provisional patent applications have been filed.  The project also resulted in the design of a novel haptic display, the Slip-Pad, which uses interleaved moving belts to produce a range of lateral and rotational slip sensations at the fingertip that can be used for robot feedback. Broader Impacts: The project has made technical advances that have the potential to improve healthcare, improve American competitiveness in logistics and manufacturing, and open the door to new service robot applications in the home.  Findings were reported in peer-reviewed publications in the leading robotics venues (such as ICRA, IROS, RSS, CASE), presentations at conferences and workshops, over 50 invited lectures, press articles (including The New York Times and MIT Technology Review), and in the short documentary film: "Why We Love Robots." The work has contributed to establishing shared software for the da Vinci Research Kit and RAVEN II, state-of-the-art experimental research platforms in surgical robotics.  The project contributed to the training of a post-doc, seven PhD students and over twenty undergraduate researchers, many of whom have gone on to top-tier PhD programs. The project also enabled the principal investigators to host over sixty outreach visits at their labs (to encourage interest in STEM fields) and to share their instructional materials with tens of thousands of students anywhere in the world through a MOOC on Artificial Intelligence on edX as well as with other instructors for teaching their courses.  The Berkeley AI course materials have been used by over 60 other instructors.          Last Modified: 12/23/2016       Submitted by: Ken Goldberg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
