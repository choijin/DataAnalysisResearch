<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Small: New Infrastructure Concepts for Robust Handling of Inputs with Uncertainty</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>499919.00</AwardTotalIntnAmount>
<AwardAmount>535119</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The conventional software currently used to handle input in nearly all modern graphical user interfaces (GUIs) is effective and highly evolved.  This has the advantages of promoting reuse rather than reinvention of interaction techniques, and making it easy to create GUis, even for those with limited programming ability.  However, these successful software abstractions assume the inputs reported to the system accurately reflect the actions of the user - that input is certain rather than uncertain.  Unfortunately, this does not hold for some of the most interesting new input technologies including naturalistic inputs such as free space gestures (e.g., as sensed by the Kinect depth camera), pen input (including handwriting, gestures, and free hand drawing), touch input, sensors for context, and voice input.  Some of these new technologies contain inherent uncertainty, such as when a finger touch area (that the user cannot see) is much larger than the pixels of a display.  Others make use of recognizers for input and typically produce estimates of what might have occurred.  Since conventional methods of input handling have no way to manage uncertainty in input, many of them force uncertainty to be resolved before input processing even starts.  For example, the location of input from a touch screen may be represented as certain using a single point (its centroid).  But when uncertainty information is thrown away, interfaces can quickly become brittle; small recognition errors can derail the interaction and destroy the user experience.  As a result, these new and very promising forms of input have often proven difficult to use to their full potential.  The PI's goal in this project is to overcome this problem by creating a redesigned input-handling infrastructure, which will robustly model, and make use of, inputs with uncertainty.  It will do this by treating all input, and all UI actions stemming from that input, on a probabilistic basis, entertaining multiple possible interpretations of input (and all its consequences over time), along with estimates of the likelihood of each interpretation.  As a result, when decisions need to be made and irreversible actions undertaken, systems will have a sound basis for choosing among interpretations.  Rather than starting with completely new input concepts, the PI's approach is to extend conventional input abstractions with support for uncertainty.  Normally, a single certain input event is dispatched to a single interactor, which interprets its meaning to track its own interactive state and eventually request actions.  Now, each of these parts of the input process will be done probabilistically.  An estimated probability distribution will be tracked over input alternatives that might have occurred, interactors which might have received that input, states that interactors might be in, and actions that interactors might request as a result.  These probability distributions can then be used to make informed decisions about when, whether, and which actions to actually undertake.  To hide the complexity of maintaining each of these distributions over time from the UI programmer, the PI will employ a Monte Carlo representation of a probability distribution (i.e., a weighted set of samples each indicating the probability of one definite value).  Crucially, this representation will allow the code to simply execute traditional (certain) input processing steps multiple times - once for each sample in the relevant probability distribution(s).  This hides nearly all the complexity associated with uncertainty, and allows programmers to use their current conceptual models, and even code nearly identical to their current practices, for most aspects of input handling.&lt;br/&gt;&lt;br/&gt;Broader Impacts:   Project outcomes will radically change the ease with which readily available new input technologies can be incorporated into interactive systems, and thus will have wide impact in expanding our ability to build and deploy interfaces with new forms of input.  As part of this research, the PI will develop working solutions for both graphical user interfaces and context-aware applications.  He will also create and widely distribute a full teaching toolkit which embodies these concepts (where the term "teaching" is used in the same spirit that Pascal was a teaching programming language - it used good concepts and the best practices of the time; it was conceptually clean, yet suitable for real work).  This teaching toolkit will be integrated into educational activities at the PI's institution, and curricular modules will be developed which should allow this to be carried to other universities.</AbstractNarration>
<MinAmdLetterDate>08/14/2012</MinAmdLetterDate>
<MaxAmdLetterDate>04/07/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1217929</AwardID>
<Investigator>
<FirstName>Scott</FirstName>
<LastName>Hudson</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Scott E Hudson</PI_FULL_NAME>
<EmailAddress>hudson@cs.cmu.edu</EmailAddress>
<PI_PHON>4122682429</PI_PHON>
<NSF_ID>000396012</NSF_ID>
<StartDate>08/14/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jennifer</FirstName>
<LastName>Mankoff</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jennifer Mankoff</PI_FULL_NAME>
<EmailAddress>jmanoff@uw.edu</EmailAddress>
<PI_PHON>2066853035</PI_PHON>
<NSF_ID>000149860</NSF_ID>
<StartDate>08/14/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~160127</FUND_OBLG>
<FUND_OBLG>2013~358992</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Graphical user interfaces have revolutionized the ability of people to make use of computers in everyday activities.&nbsp; The underlying software concepts that make these user interfaces work are now well understood and widely adopted.&nbsp; However, recent advances in user interface technology &ndash; for example, the touch input found on mobile phones and tablets, voice input, pen input, and new techniques that make use of &ldquo;big data&rdquo; to predict the activities of users &ndash; have introduced significant new challenges that these software concepts were not designed to handle.&nbsp; Specifically, the original software concepts for handling user input assume that user actions (inputs) are certain to have occurred as they are reported to a system &ndash; if the system reports that the right mouse button has been pressed down, it is very likely that the user has pressed the right mouse button.&nbsp; However, new naturalistic forms of input like those listed above introduce uncertainty into input &ndash; in a voice interface, the user might say &ldquo;50&rdquo; but the system may find it hard to distinguish this from &ldquo;15&rdquo;.&nbsp; Current software for handling user input has no good way to resolve this uncertainty.&nbsp; As a result systems are normally forced to resolve this ambiguity as soon as the input occurs &ndash; they cannot take into account information which may arrive later, or make use of the context in which inputs occur, instead they must make an immediate decision.&nbsp; This leads to &ldquo;brittle&rdquo; interfaces which can make significantly more mistakes than necessary, and have no way to let the user guide them to a correct interpretation of ambiguous input.&nbsp;</p> <p>The primary result of this project has been the development of a new set of input handling software concepts which support new forms of uncertain input much better.&nbsp; These software concepts track the uncertainty involved with input across multiple user actions and provide systems with accurate estimates of the probabilities of various combinations of input, while allowing systems both to wait until actions must be performed to make decisions, and to know when those decisions are highly uncertain.&nbsp; This allows better, more usable and more understandable user interfaces to be created.&nbsp; Importantly, these software concepts have been designed to appear to programmers in a very similar form to the existing concepts for input handling &ndash; with most of the difficult probabilistic modeling occurring &ldquo;under the covers&rdquo;.&nbsp; This should allow techniques based on these concepts to be easily adopted into future systems.&nbsp; As a consequence, the results of this project provide the promise of improving user interfaces in a wide range of applications and for a wide range of future devices.&nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/02/2017<br>      Modified by: Scott&nbsp;E&nbsp;Hudson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Graphical user interfaces have revolutionized the ability of people to make use of computers in everyday activities.  The underlying software concepts that make these user interfaces work are now well understood and widely adopted.  However, recent advances in user interface technology &ndash; for example, the touch input found on mobile phones and tablets, voice input, pen input, and new techniques that make use of "big data" to predict the activities of users &ndash; have introduced significant new challenges that these software concepts were not designed to handle.  Specifically, the original software concepts for handling user input assume that user actions (inputs) are certain to have occurred as they are reported to a system &ndash; if the system reports that the right mouse button has been pressed down, it is very likely that the user has pressed the right mouse button.  However, new naturalistic forms of input like those listed above introduce uncertainty into input &ndash; in a voice interface, the user might say "50" but the system may find it hard to distinguish this from "15".  Current software for handling user input has no good way to resolve this uncertainty.  As a result systems are normally forced to resolve this ambiguity as soon as the input occurs &ndash; they cannot take into account information which may arrive later, or make use of the context in which inputs occur, instead they must make an immediate decision.  This leads to "brittle" interfaces which can make significantly more mistakes than necessary, and have no way to let the user guide them to a correct interpretation of ambiguous input.   The primary result of this project has been the development of a new set of input handling software concepts which support new forms of uncertain input much better.  These software concepts track the uncertainty involved with input across multiple user actions and provide systems with accurate estimates of the probabilities of various combinations of input, while allowing systems both to wait until actions must be performed to make decisions, and to know when those decisions are highly uncertain.  This allows better, more usable and more understandable user interfaces to be created.  Importantly, these software concepts have been designed to appear to programmers in a very similar form to the existing concepts for input handling &ndash; with most of the difficult probabilistic modeling occurring "under the covers".  This should allow techniques based on these concepts to be easily adopted into future systems.  As a consequence, the results of this project provide the promise of improving user interfaces in a wide range of applications and for a wide range of future devices.            Last Modified: 01/02/2017       Submitted by: Scott E Hudson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
