<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  A Novel Platform for Automatic Geo-Tagging of Images</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2013</AwardExpirationDate>
<AwardTotalIntnAmount>146581.00</AwardTotalIntnAmount>
<AwardAmount>146581</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project aims to develop computer software that automatically recognizes buildings, structures, and landmarks in digital photographs, as well as the precise location where photos were taken. The advent of the digital age has led to hundreds of millions of photos being shared on the Web every day. This influx of user-generated content is leading to significant challenges in organizing and understanding large photo collections from the many thousands of photographs captured by a family over several years, to the billions of photos shared online each month. For instance, annotating photos is currently a burdensome task; users of photo-sharing services have no accurate, automated method for labeling landmarks and other structures present in their pictures, instead relying on manual tagging. Using newly invented computer vision technology, this project aims to automatically transform photographs of locations into geo-tagged user engagement portals storyboards rich with pixel-level annotations and hyper-relevant information. The innovations leverage a unique database of 3D models, yielding very accurate locations and tags. The project objectives include developing algorithms for world-scale location-based image content recognition, an accurate annotation method, and an application programming interface for the system for use by application developers.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project are significant; as digital photo-sharing has become a major online activity, there will be considerable market interest in the ability to identify and link photos to hyper-local and highly relevant information, including advertising, for the tourism and hospitality market sector, as well as for small local businesses. Additionally, the technology will enable companies in the social media market sector to increase user engagement through interactive and contextualized photo browsing. Furthermore, the proposed technology can transform photos into image-powered platform for the mobile phone market sector, allowing for a seamless transition between digital photos and online maps and thus greatly enhancing user navigation of new physical environments using mobile devices. Finally, the technology can also provide key analytics to companies in social media monitoring, by determining aggregate patterns in where and why people take photos at locations of interest.</AbstractNarration>
<MinAmdLetterDate>12/02/2012</MinAmdLetterDate>
<MaxAmdLetterDate>02/15/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1248731</AwardID>
<Investigator>
<FirstName>Yunpeng</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yunpeng Li</PI_FULL_NAME>
<EmailAddress>ypltaggpic@gmail.com</EmailAddress>
<PI_PHON>5202470143</PI_PHON>
<NSF_ID>000622722</NSF_ID>
<StartDate>12/02/2012</StartDate>
<EndDate>02/15/2013</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tsung-Lin</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tsung-Lin Yang</PI_FULL_NAME>
<EmailAddress>tlytaggpic@gmail.com</EmailAddress>
<PI_PHON>5202470143</PI_PHON>
<NSF_ID>000640704</NSF_ID>
<StartDate>02/15/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>TaggPic, Inc.</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502848</ZipCode>
<PhoneNumber>5202470143</PhoneNumber>
<StreetAddress>210 Summerhill Drive</StreetAddress>
<StreetAddress2><![CDATA[Suite 6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078496743</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TAGGPIC INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[TaggPic, Inc.]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502848</ZipCode>
<StreetAddress><![CDATA[210 Summerhill Dr., Suite 6]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>4080</Code>
<Text>ADVANCED COMP RESEARCH PROGRAM</Text>
</ProgramReference>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~146581</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Under this Phase I Small Business Innovation Research grant, TaggPic further developed a computer vision software technology invented at Cornell University. This technology automatically recognizes landmarks in digital photos, and the precise locations where the photos were captured. The technology is based solely on visual features, and does not require any metadata, such as GPS tags. The underlying algorithms can determine the precise position of the camera viewpoint in a geo-referenced coordinate system, even if no data about the photo&rsquo;s location is known.&nbsp;</p> <p>Because the system explicitly reasons about the 3D relationship between an image and a database of 3D models (Figure 1), representing TaggPic&rsquo;s 3D World Model, it can produce quite accurate positions and orientations, often more accurate than is possible with GPS; in a sense, it can achieve near pixel-accurate image localization. This system will enable automatic geo-tagging and recognition of location-based photography, transforming these photos into interactive gateways that link to further relevant information and details for that location.&nbsp;</p> <p>There were three main objectives outlined in TaggPic&rsquo;s Phase I proposal. First, to achieve world-scale visual object recognition, deployed in a distributed fashion on a cloud computing framework. Second, to perform accurate annotation and develop a prototype framework for pixel-level annotation of recognized images with names of locations, buildings, and objects. Finally, to create an API layer suitable for web application development.&nbsp;</p> <p>During Phase I, TaggPic built a prototype system for taking an image, and quickly extracting visual features to geo-recognize the image by determining its location and orientation, or returning a response that the photo could not be recognized. The Phase I project made this system scalable, for both the large number of images used to construct the 3D models, and for geo-recognizing large numbers of images.</p> <p>Also during Phase I, TaggPic performed extensive evaluation of the performance of our algorithms, and compared our performance with that of potential competitors. We performed testing on different image sources to characterize the performance of our geo-recognition in different scenarios such as identifying images of famous wonders, and geotagging images found on the internet.</p> <p>During Phase I TaggPic also successfully annotated large numbers of &nbsp;objects in our 3D World Model, meaning that precise outlines can be rendered onto images processed by the TaggPic recognition engine when the image contains one of these objects. Finally, TaggPic was able to create application programming interface (API) for this recognition system, suitable for use by web application developers.&nbsp;</p><br> <p>            Last Modified: 07/24/2013<br>      Modified by: Tsung-Lin&nbsp;Yang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Under this Phase I Small Business Innovation Research grant, TaggPic further developed a computer vision software technology invented at Cornell University. This technology automatically recognizes landmarks in digital photos, and the precise locations where the photos were captured. The technology is based solely on visual features, and does not require any metadata, such as GPS tags. The underlying algorithms can determine the precise position of the camera viewpoint in a geo-referenced coordinate system, even if no data about the photoÃ†s location is known.   Because the system explicitly reasons about the 3D relationship between an image and a database of 3D models (Figure 1), representing TaggPicÃ†s 3D World Model, it can produce quite accurate positions and orientations, often more accurate than is possible with GPS; in a sense, it can achieve near pixel-accurate image localization. This system will enable automatic geo-tagging and recognition of location-based photography, transforming these photos into interactive gateways that link to further relevant information and details for that location.   There were three main objectives outlined in TaggPicÃ†s Phase I proposal. First, to achieve world-scale visual object recognition, deployed in a distributed fashion on a cloud computing framework. Second, to perform accurate annotation and develop a prototype framework for pixel-level annotation of recognized images with names of locations, buildings, and objects. Finally, to create an API layer suitable for web application development.   During Phase I, TaggPic built a prototype system for taking an image, and quickly extracting visual features to geo-recognize the image by determining its location and orientation, or returning a response that the photo could not be recognized. The Phase I project made this system scalable, for both the large number of images used to construct the 3D models, and for geo-recognizing large numbers of images.  Also during Phase I, TaggPic performed extensive evaluation of the performance of our algorithms, and compared our performance with that of potential competitors. We performed testing on different image sources to characterize the performance of our geo-recognition in different scenarios such as identifying images of famous wonders, and geotagging images found on the internet.  During Phase I TaggPic also successfully annotated large numbers of  objects in our 3D World Model, meaning that precise outlines can be rendered onto images processed by the TaggPic recognition engine when the image contains one of these objects. Finally, TaggPic was able to create application programming interface (API) for this recognition system, suitable for use by web application developers.        Last Modified: 07/24/2013       Submitted by: Tsung-Lin Yang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
