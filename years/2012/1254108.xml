<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Investigating linguistic dimensions in cross-domain authorship analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>45084.00</AwardTotalIntnAmount>
<AwardAmount>45084</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ability to analyze a text and determine with certainty the author of that document, a task known as Authorship Attribution (AA), can help build a case against an online abuser, determine the trustworthiness of a document, and can also support this country's fight against terrorism by analyzing online communities of interest.  This EArly Grant for Exploratory Research investigates new approaches for AA in two specific cross-domain settings: where both the topic and genre of the test documents differ from those of the training data. The research study departs from the standard single feature vector representation in text classification settings and follows a framework where the writeprint of authors is represented as a set of linguistic dimensions.  The goal is to understand how each dimension will change in the new domain.  &lt;br/&gt;&lt;br/&gt;The findings from this exploratory research will show the feasibility of building new text representations and approaches for text classification problems where there are larger domain shifts between the training and testing data and the breakout representation into linguistic dimensions is suitable. The results and findings from this work will contribute to building longer-term research projects which will be able to tackle more challenging cross-domain settings.</AbstractNarration>
<MinAmdLetterDate>08/30/2012</MinAmdLetterDate>
<MaxAmdLetterDate>01/15/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1254108</AwardID>
<Investigator>
<FirstName>Thamar</FirstName>
<LastName>Solorio</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thamar Solorio</PI_FULL_NAME>
<EmailAddress>thamar.solorio@gmail.com</EmailAddress>
<PI_PHON>7137435542</PI_PHON>
<NSF_ID>000492342</NSF_ID>
<StartDate>08/30/2012</StartDate>
<EndDate>01/15/2015</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Bethard</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven J Bethard</PI_FULL_NAME>
<EmailAddress>bethard@email.arizona.edu</EmailAddress>
<PI_PHON>5206215223</PI_PHON>
<NSF_ID>000606292</NSF_ID>
<StartDate>01/15/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Alabama at Birmingham</Name>
<CityName>Birmingham</CityName>
<ZipCode>352940001</ZipCode>
<PhoneNumber>2059345266</PhoneNumber>
<StreetAddress>AB 1170</StreetAddress>
<StreetAddress2><![CDATA[1720 2nd Avenue South]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<StateCode>AL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>063690705</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ALABAMA AT BIRMINGHAM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>808245794</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Alabama at Birmingham]]></Name>
<CityName>Birmingham</CityName>
<StateCode>AL</StateCode>
<ZipCode>352940001</ZipCode>
<StreetAddress><![CDATA[University of Alabama at Birming]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~45084</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our research provided answers to several open issues in the field of authorship attribution, where the goal is to computationally analyze a text and predict who it was written by. We found that when computational models are faced with writing from topics they have never seen before, they are better able to predict authorship if they have been trained on a variety of different topics rather than a single topic. We also found strong evidence of different linguistic dimensions within the short sequences of characters ("character n-grams") that are typically used as features in authorship attribution models. We observed that character n-grams representing linguistic morphology and punctuation were more robust than other types of character n-grams. These results were evaluated only in authorship attribution problems, but there are many related text classification tasks where these findings are promising as well, such as in native language identification, where models are often faced with writing from topics they have never seen before.</p> <p>The project provided a topic for a PhD dissertation and supported the activities of the doctoral student member of the research team. The findings from this research also informed the design of a research program in the area of authorship attribution in cross-domain settings that resulted in an NSF CAREER award.</p><br> <p>            Last Modified: 10/14/2015<br>      Modified by: Steven&nbsp;J&nbsp;Bethard</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our research provided answers to several open issues in the field of authorship attribution, where the goal is to computationally analyze a text and predict who it was written by. We found that when computational models are faced with writing from topics they have never seen before, they are better able to predict authorship if they have been trained on a variety of different topics rather than a single topic. We also found strong evidence of different linguistic dimensions within the short sequences of characters ("character n-grams") that are typically used as features in authorship attribution models. We observed that character n-grams representing linguistic morphology and punctuation were more robust than other types of character n-grams. These results were evaluated only in authorship attribution problems, but there are many related text classification tasks where these findings are promising as well, such as in native language identification, where models are often faced with writing from topics they have never seen before.  The project provided a topic for a PhD dissertation and supported the activities of the doctoral student member of the research team. The findings from this research also informed the design of a research program in the area of authorship attribution in cross-domain settings that resulted in an NSF CAREER award.       Last Modified: 10/14/2015       Submitted by: Steven J Bethard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
