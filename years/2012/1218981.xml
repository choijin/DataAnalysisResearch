<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: MapReduce Workload Management</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>299971.00</AwardTotalIntnAmount>
<AwardAmount>315971</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Researchers and decision makers in diverse fields such as &lt;br/&gt;fraud detection, genome sequencing, and datacenter&lt;br/&gt;management need to process many terabytes of data every day. &lt;br/&gt;Many fields are turning to MapReduce systems to process such &lt;br/&gt;growing datasets. Consequently, the relatively young MapReduce&lt;br/&gt;ecosystem has to support complex workloads that include &lt;br/&gt;declarative queries for report generation, MapReduce &lt;br/&gt;programs for machine learning tasks, and large job workflows.&lt;br/&gt;Furthermore, elastic and pay-as-you-go cloud platforms pose novel &lt;br/&gt;challenges and opportunities for MapReduce workload management.&lt;br/&gt;&lt;br/&gt;This project is building the Hadoop AutoAdmin system for &lt;br/&gt;automating MapReduce workload management. To the PI's knowledge, &lt;br/&gt;Hadoop AutoAdmin is the first system to address this challenging &lt;br/&gt;problem that will become increasingly important as a broad class &lt;br/&gt;of users adopt MapReduce. Hadoop AutoAdmin has three research &lt;br/&gt;thrusts. The first thrust is to understand and characterize the &lt;br/&gt;behavior of MapReduce workloads based on a comprehensive empirical &lt;br/&gt;study involving workloads and data from multiple application domains &lt;br/&gt;as well as different cluster configurations on the cloud. The second &lt;br/&gt;thrust is to develop an easy-to-use and efficient warehouse to &lt;br/&gt;store, retrieve, and visualize the diverse forms of workload &lt;br/&gt;monitoring data. The models and insights from these activities will &lt;br/&gt;drive the third thrust of developing end-to-end algorithms for &lt;br/&gt;workload management.&lt;br/&gt;&lt;br/&gt;This project can have significant impact in areas of national &lt;br/&gt;importance like security and healthcare that are inundated with &lt;br/&gt;data. Hadoop AutoAdmin will improve worker productivity, system &lt;br/&gt;utilization, and cost-effectiveness of cloud platforms. The &lt;br/&gt;technical contributions will be disseminated broadly and the &lt;br/&gt;system released publicly.</AbstractNarration>
<MinAmdLetterDate>08/15/2012</MinAmdLetterDate>
<MaxAmdLetterDate>05/07/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218981</AwardID>
<Investigator>
<FirstName>Shivnath</FirstName>
<LastName>Babu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shivnath Babu</PI_FULL_NAME>
<EmailAddress>shivnath@cs.duke.edu</EmailAddress>
<PI_PHON>9196606579</PI_PHON>
<NSF_ID>000488390</NSF_ID>
<StartDate>08/15/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName/>
<StateCode>NC</StateCode>
<ZipCode>277054010</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~299971</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-905ca75b-e49b-15fd-3599-dfd6dfc0b288"> <span id="docs-internal-guid-fcda6d93-e4ae-1b18-5084-c2ad6c0a7c7e"> <p dir="ltr"><span>Data-parallel jobs running on frameworks such as MapReduce, Spark, and Tez form the dominant and growing category of workloads in data-intensive cluster computing across many disciplines of science and engineering. Many businesses, governments, as well as scientific researchers are using such workloads to process the large datasets that they generate. However, there is limited understanding of how these workloads behave and how to troubleshoot performance and reliability issues for these workloads. The focus of this project has been to develop solutions to make the operators and users of data-parallel workloads like MapReduce more productive in how they use and benefit from these workloads.</span></p> <p dir="ltr"><span> The project has made significant contributions foundationally and empirically along four topics: </span></p> <p dir="ltr"><span>(1) Workload-generation techniques to create simple to complex MapReduce workloads on a cluster; (2) Data-analysis techniques to analyze and understand how these workloads behave; (3) Workload-modeling techniques to model the behavior of these workloads; and (4) Workload-optimization techniques to tune these workloads to the cluster size, workload type, performance, and infrastructure. </span></p> <p dir="ltr"><span>The strength of these contributions comes from the wide spectrum along which MapReduce workloads were explored: (a) Scale of processing: where clusters of many different sizes were studied to understand how MapReduce workloads work at different types of scale; (b) Diversity of processing: where workloads of different types ranging from SQL to matrix processing were studied; (c) Performance requirements: where MapReduce workloads being used for batch processing, real-time stream processing, graph processing, etc., were studied; and (d) Infrastructure used: where MapReduce workloads on the elastic cloud as well as multi-tenant on-premises clusters were studied. </span></p> <span>The project has generated operational insights from a real-life MapReduce cluster used by analysts, data scientists, and statisticians working on different mission-critical activities at a large enterprise. This fast-growing Hadoop cluster currently stores approximately 30 petabytes of data across more than 1000 nodes. Almost all the types of challenges considered in this project are seen in this cluster. Operational experiences from this large multi-tenant cluster were used to showcase challenges that operators of data-parallel workloads face, and how the work from this project benefits them. Multiple demonstrations of the contributions of this project have been given in venues like VLDB. Talks at research conferences as well as at popular venues like the Hadoop and Spark Summit have been given. The project has also contributed to two PhD dissertations in USA and Europe. </span></span> <p dir="ltr">&nbsp;</p> </span></p><br> <p>            Last Modified: 12/09/2016<br>      Modified by: Shivnath&nbsp;Babu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Data-parallel jobs running on frameworks such as MapReduce, Spark, and Tez form the dominant and growing category of workloads in data-intensive cluster computing across many disciplines of science and engineering. Many businesses, governments, as well as scientific researchers are using such workloads to process the large datasets that they generate. However, there is limited understanding of how these workloads behave and how to troubleshoot performance and reliability issues for these workloads. The focus of this project has been to develop solutions to make the operators and users of data-parallel workloads like MapReduce more productive in how they use and benefit from these workloads.  The project has made significant contributions foundationally and empirically along four topics:  (1) Workload-generation techniques to create simple to complex MapReduce workloads on a cluster; (2) Data-analysis techniques to analyze and understand how these workloads behave; (3) Workload-modeling techniques to model the behavior of these workloads; and (4) Workload-optimization techniques to tune these workloads to the cluster size, workload type, performance, and infrastructure.  The strength of these contributions comes from the wide spectrum along which MapReduce workloads were explored: (a) Scale of processing: where clusters of many different sizes were studied to understand how MapReduce workloads work at different types of scale; (b) Diversity of processing: where workloads of different types ranging from SQL to matrix processing were studied; (c) Performance requirements: where MapReduce workloads being used for batch processing, real-time stream processing, graph processing, etc., were studied; and (d) Infrastructure used: where MapReduce workloads on the elastic cloud as well as multi-tenant on-premises clusters were studied.  The project has generated operational insights from a real-life MapReduce cluster used by analysts, data scientists, and statisticians working on different mission-critical activities at a large enterprise. This fast-growing Hadoop cluster currently stores approximately 30 petabytes of data across more than 1000 nodes. Almost all the types of challenges considered in this project are seen in this cluster. Operational experiences from this large multi-tenant cluster were used to showcase challenges that operators of data-parallel workloads face, and how the work from this project benefits them. Multiple demonstrations of the contributions of this project have been given in venues like VLDB. Talks at research conferences as well as at popular venues like the Hadoop and Spark Summit have been given. The project has also contributed to two PhD dissertations in USA and Europe.           Last Modified: 12/09/2016       Submitted by: Shivnath Babu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
