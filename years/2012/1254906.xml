<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Modeling the Dynamic Interplay of Control, Planning and Perceptual Functions in Agile Human Guidance</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2013</AwardEffectiveDate>
<AwardExpirationDate>01/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Irina Dolinskaya</SignBlockName>
<PO_EMAI>idolinsk@nsf.gov</PO_EMAI>
<PO_PHON>7032927078</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The research objective of this Faculty Early Career Development (CAREER) Program grant is to study and model the interplay of spatial control, perception and planning functions in human guidance skills.  Ample empirical evidence exists supporting the observation that experienced pilots or operators display patterns in their behavior.  These patterns are significant because they are manifestations of the mechanisms used by humans to organize and implement agile guidance behaviors.  Guidance tasks conducted with small-scale helicopters will be used to generate experimental data that combine vehicle motion, pilot control and visual gaze information.  The research is organized in three threads: 1) Determine the principles of patterns' emergence using a data-driven approach combining dynamics, control, identification and data-clustering methods; 2) Analyze the transition across patterns and their dynamic makeup to determine the underlying model structures; and finally 3) Integrate the gained knowledge to form an interaction model that describes the interplay between control, perceptual and planning functions. &lt;br/&gt;&lt;br/&gt;If successful this research will enable tele-operation systems that take advantage of the operator's innate guidance functions to reduce workload and increase safety.  Example applications include search and rescue helicopters or tele-surgery systems.   These systems will work by directing the operator's visual attention to cues that are significant to performance and conversely, decode visual attention to predict future control actions.  The proposed research activities will promote interactions between the fields of control engineering and cognitive sciences.  Cross-disciplinary opportunities will be leveraged to: 1) Create stimulating undergraduate and graduate courses; 2) Encourage the involvement of underrepresented students in the research environment; 3) Design outreach activities for high-schools and elementary schools. The results will be disseminated through a website accessible to the broader public and through conference workshops designed to reach across the control and human factor communities.</AbstractNarration>
<MinAmdLetterDate>01/23/2013</MinAmdLetterDate>
<MaxAmdLetterDate>01/23/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1254906</AwardID>
<Investigator>
<FirstName>Berenice</FirstName>
<LastName>Mettler</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Berenice F Mettler</PI_FULL_NAME>
<EmailAddress>mettler@umn.edu</EmailAddress>
<PI_PHON>6126240529</PI_PHON>
<NSF_ID>000222077</NSF_ID>
<StartDate>01/23/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554552070</ZipCode>
<StreetAddress><![CDATA[110 Union St. SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1632</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramElement>
<ProgramReference>
<Code>030E</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>031E</Code>
<Text>MECHATRONICS</Text>
</ProgramReference>
<ProgramReference>
<Code>034E</Code>
<Text>Dynamical systems</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The general goal of this award was to study and model the interplay of control, perception, and planning functions in human spatial guidance and control skills to better understand their unique versatility and performance.</p> <p><strong>Intellectual Merit </strong></p> <p>Abundant evidence has suggested that experienced operators mitigate the complexities of motion programming and physical implementation by employing control and planning strategies organized around <em>units of behavior</em> that tightly link the domain of physical implementation, which is dictated by dynamics and other constraints, within the abstract domain of reasoning and planning. These units are also expected to play a critical role in learning, knowledge transfer, and adaptation.</p> <p>From research in other human performance domains, especially memory and other cognitive functions such as attention, it&rsquo;s reasonable to assume that spatial behavioral units represent a form of chunking, i.e., a grouping of elements into some relevant whole. Chunking is the most common principle for overcoming limitations associated with human information processing and memory. Until this work, however, the form and principles of chunking in spatial control domains were unclear.</p> <p>Our preliminary studies showed that human control mechanisms and planning strategies manifest as <em>interaction patterns</em> in the behavior. These results also suggested the general hypothesis that humans form sensory-motor primitives by exploiting <em>invariant properties</em> related to functional processes (control, sensory, and perceptual), and larger invariants associated with the geometry and topology of spatial behavior.</p> <p>The general approach was to reverse-engineer <em>interaction patterns</em> extracted from experiments in actual and simulated control tasks. The experimental framework conceived under this grant accounts for comprehensive system-wide interactions (see <strong>Fig. 1</strong>) that enable studying how humans organize their behavior and elaborate plans. On the theoretical side, the general hypothesis was formalized via the concept of <em>equivalence relations, </em>which provides a mathematical framework to explain how humans simplify tasks by decomposing them into a series of more tractable subtasks.</p> <p>We used these frameworks to study the equivalence properties in behavior, and more specifically how the brain exploits invariants, to coordinate behavior into sensory-motor units that serve as <em>units of organization </em>(see <strong>Fig. 2</strong>). Once the larger organizational principles were elucidated, we were able to detail the functional mechanisms specific to control, perception, and learning. The lawful decomposition of behavior made it possible to tear it apart along functionally meaningful segments. Segmented data could then be aggregated and clustered according to similar functional properties. These behavior classes could subsequently be analyzed using data-driven techniques to detail the underlying perceptual, control, and guidance mechanisms. <strong>Figure 3</strong> depicts the discrete control modes and associated perceptual guidance laws identified by studying dynamic behavior underlying interaction patterns (IP).</p> <p>Using IP as <em>units of analysis</em> enabled insights into other critical aspects of behavior, including analyzing and modeling the human operators&rsquo; learning of task environment. <strong>Figure 4</strong> shows the evolution of trajectories and gaze distribution for two operators of different proficiency level learning to navigate in an obstacle field.&nbsp;</p> <p><strong>Broader Impacts</strong></p> <p>The gained understanding about roots of humans&rsquo; versatile spatial guidance and control principles carries broad practical applications. It will enable more rigorous and comprehensive human skill analysis, natural and effective human-machine interfaces for tele-robotic systems, and computationally efficient and versatile guidance algorithms for autonomous vehicles.</p> <p>The research framework also was applied to exploratory research in surgical skill analysis, which was performed as a collaboration with the UMN&rsquo;s medical school and mechanical engineering department. <strong>Figure 5</strong> shows results from comparisons between traditional motion segmentation based on kinematics and segmentation based on <em>interaction patterns</em> that capture semantically meaningful movement segments.</p> <p>This project also demonstrated a trajectory planning algorithm that leverages subgoal structure to mitigate computational complexity. In human-machine engineering and robotics, we demonstrated a tele-operation search via a mobile robot (see <strong>Fig. 6</strong>); the operator received virtual subgoals displayed on the user interface that were optimized for coverage and enabled enhanced search performance across the user population.</p> <p>The work started under this NSF-funded research project is currently continuing through collaborations with several research groups, including the Berkeley Deep Drive Initiative, where the techniques are being applied to investigate performance and principles of deep learning neural networks (i.e., self-driving cars). The research also inspired the creation of human movement skill augmentation technology to help humans learn and rehabilitate complex movement skills.</p> <p>This research project also created broader benefits for society. The PI engaged in annual outreach activities including holding classes and hands-on projects for UMN&rsquo;s College of Science and Engineering Summer camp, designing educational activities in robotics and aerospace during UMN&rsquo;s Math &amp; Science Family Fun Fair, and hosting the Aviation Career Education (ACE) camps at UMN&rsquo;s Aerospace Department. The PI also hosted several undergraduate students for summer research projects at her Interactive Guidance and Control Lab. Three of the undergraduate students are now pursuing PhD programs, and three of the PI&rsquo;s seven PhD students are now pursuing their own academic careers.</p><br> <p>            Last Modified: 05/02/2018<br>      Modified by: Berenice&nbsp;F&nbsp;Mettler</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524868800822_Overview_newnew--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524868800822_Overview_newnew--rgov-800width.jpg" title="Figure 1 -- Framework overview"><img src="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524868800822_Overview_newnew--rgov-66x44.jpg" alt="Figure 1 -- Framework overview"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Emergent patterns in spatial behavior resulting from agent-environment interactions are extracted based on invariants and equivalence relations. Resulting interaction patterns enable detailed analysis and modeling of perceptual, control, and higher-level planning and learning functions.</div> <div class="imageCredit">Mettler</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Berenice&nbsp;F&nbsp;Mettler</div> <div class="imageTitle">Figure 1 -- Framework overview</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524869164830_equivalenceclassanddecomposition--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524869164830_equivalenceclassanddecomposition--rgov-800width.jpg" title="Figure 2 -- Equivalence relations and behavior decomposition."><img src="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524869164830_equivalenceclassanddecomposition--rgov-66x44.jpg" alt="Figure 2 -- Equivalence relations and behavior decomposition."></a> <div class="imageCaptionContainer"> <div class="imageCaption">a) Illustration of the interaction patterns (IP) as unit of behavior and the formalization as equivalence relation and resulting equivalence class decomposition of the navigation task into subtasks; b1)-b3)  and c1-c3) show segmentation and clustering of IP extracted from two human guidance experime</div> <div class="imageCredit">B. Mettler</div> <div class="imageSubmitted">Berenice&nbsp;F&nbsp;Mettler</div> <div class="imageTitle">Figure 2 -- Equivalence relations and behavior decomposition.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524881876285_functionalanalysis--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524881876285_functionalanalysis--rgov-800width.jpg" title="Figure 3 -- Functional analysis based on Interaction Patterns"><img src="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524881876285_functionalanalysis--rgov-66x44.jpg" alt="Figure 3 -- Functional analysis based on Interaction Patterns"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Scatter plot in the control behavior and operating regimes showing discrete control modes (a); After clustering (b) modes were analyzed using graphical modeling (c), to determine their underlying control and perceptual mechanisms, which demonstrates tau-guidance properties.</div> <div class="imageCredit">Mettler</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Berenice&nbsp;F&nbsp;Mettler</div> <div class="imageTitle">Figure 3 -- Functional analysis based on Interaction Patterns</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882267390_learningperformanceandgaze--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882267390_learningperformanceandgaze--rgov-800width.jpg" title="Figure 4 -- Task environment learning based on Interaction Patterns"><img src="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882267390_learningperformanceandgaze--rgov-66x44.jpg" alt="Figure 4 -- Task environment learning based on Interaction Patterns"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Evolution of gaze distribution, guidance and control behavior in obstacle navigation task for novice (subject A) and expert (subject B). First trial shows scanning behavior to support environment exploration; last trial shows marked difference between subject A and B due to skill level.</div> <div class="imageCredit">Mettler</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Berenice&nbsp;F&nbsp;Mettler</div> <div class="imageTitle">Figure 4 -- Task environment learning based on Interaction Patterns</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882665077_surgicalskillapplication--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882665077_surgicalskillapplication--rgov-800width.jpg" title="Figure 5 &ndash; Illustration of the use of Interaction Patterns in surgical skill analysis"><img src="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882665077_surgicalskillapplication--rgov-66x44.jpg" alt="Figure 5 &ndash; Illustration of the use of Interaction Patterns in surgical skill analysis"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Study with data from laparoscopic training system (a) compared traditional segmentation based on kinematic characteristics (b) and (c) with our method based on Interaction Patterns (d). IPs can clearly delineate surgeons? movements from trajectories and extract kinematic characteristics.</div> <div class="imageCredit">Mettler</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Berenice&nbsp;F&nbsp;Mettler</div> <div class="imageTitle">Figure 5 ? Illustration of the use of Interaction Patterns in surgical skill analysis</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882886599_teleroboticsearchapplication--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882886599_teleroboticsearchapplication--rgov-800width.jpg" title="Figure 6 &ndash; Illustration of the use of Interaction Patterns in human machine system application"><img src="/por/images/Reports/POR/2018/1254906/1254906_10229572_1524882886599_teleroboticsearchapplication--rgov-66x44.jpg" alt="Figure 6 &ndash; Illustration of the use of Interaction Patterns in human machine system application"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Search application with a tele-operated mobile robot (a). Subgoals identified in human performance are used as a control abstraction to reduce operator workload (b). Operators follow virtual subgoals optimized for coverage (c). Results show increased search performance across user group (d).</div> <div class="imageCredit">Mettler</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Berenice&nbsp;F&nbsp;Mettler</div> <div class="imageTitle">Figure 6 ? Illustration of the use of Interaction Patterns in human machine system application</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The general goal of this award was to study and model the interplay of control, perception, and planning functions in human spatial guidance and control skills to better understand their unique versatility and performance.  Intellectual Merit   Abundant evidence has suggested that experienced operators mitigate the complexities of motion programming and physical implementation by employing control and planning strategies organized around units of behavior that tightly link the domain of physical implementation, which is dictated by dynamics and other constraints, within the abstract domain of reasoning and planning. These units are also expected to play a critical role in learning, knowledge transfer, and adaptation.  From research in other human performance domains, especially memory and other cognitive functions such as attention, it?s reasonable to assume that spatial behavioral units represent a form of chunking, i.e., a grouping of elements into some relevant whole. Chunking is the most common principle for overcoming limitations associated with human information processing and memory. Until this work, however, the form and principles of chunking in spatial control domains were unclear.  Our preliminary studies showed that human control mechanisms and planning strategies manifest as interaction patterns in the behavior. These results also suggested the general hypothesis that humans form sensory-motor primitives by exploiting invariant properties related to functional processes (control, sensory, and perceptual), and larger invariants associated with the geometry and topology of spatial behavior.  The general approach was to reverse-engineer interaction patterns extracted from experiments in actual and simulated control tasks. The experimental framework conceived under this grant accounts for comprehensive system-wide interactions (see Fig. 1) that enable studying how humans organize their behavior and elaborate plans. On the theoretical side, the general hypothesis was formalized via the concept of equivalence relations, which provides a mathematical framework to explain how humans simplify tasks by decomposing them into a series of more tractable subtasks.  We used these frameworks to study the equivalence properties in behavior, and more specifically how the brain exploits invariants, to coordinate behavior into sensory-motor units that serve as units of organization (see Fig. 2). Once the larger organizational principles were elucidated, we were able to detail the functional mechanisms specific to control, perception, and learning. The lawful decomposition of behavior made it possible to tear it apart along functionally meaningful segments. Segmented data could then be aggregated and clustered according to similar functional properties. These behavior classes could subsequently be analyzed using data-driven techniques to detail the underlying perceptual, control, and guidance mechanisms. Figure 3 depicts the discrete control modes and associated perceptual guidance laws identified by studying dynamic behavior underlying interaction patterns (IP).  Using IP as units of analysis enabled insights into other critical aspects of behavior, including analyzing and modeling the human operators? learning of task environment. Figure 4 shows the evolution of trajectories and gaze distribution for two operators of different proficiency level learning to navigate in an obstacle field.   Broader Impacts  The gained understanding about roots of humans? versatile spatial guidance and control principles carries broad practical applications. It will enable more rigorous and comprehensive human skill analysis, natural and effective human-machine interfaces for tele-robotic systems, and computationally efficient and versatile guidance algorithms for autonomous vehicles.  The research framework also was applied to exploratory research in surgical skill analysis, which was performed as a collaboration with the UMN?s medical school and mechanical engineering department. Figure 5 shows results from comparisons between traditional motion segmentation based on kinematics and segmentation based on interaction patterns that capture semantically meaningful movement segments.  This project also demonstrated a trajectory planning algorithm that leverages subgoal structure to mitigate computational complexity. In human-machine engineering and robotics, we demonstrated a tele-operation search via a mobile robot (see Fig. 6); the operator received virtual subgoals displayed on the user interface that were optimized for coverage and enabled enhanced search performance across the user population.  The work started under this NSF-funded research project is currently continuing through collaborations with several research groups, including the Berkeley Deep Drive Initiative, where the techniques are being applied to investigate performance and principles of deep learning neural networks (i.e., self-driving cars). The research also inspired the creation of human movement skill augmentation technology to help humans learn and rehabilitate complex movement skills.  This research project also created broader benefits for society. The PI engaged in annual outreach activities including holding classes and hands-on projects for UMN?s College of Science and Engineering Summer camp, designing educational activities in robotics and aerospace during UMN?s Math &amp; Science Family Fun Fair, and hosting the Aviation Career Education (ACE) camps at UMN?s Aerospace Department. The PI also hosted several undergraduate students for summer research projects at her Interactive Guidance and Control Lab. Three of the undergraduate students are now pursuing PhD programs, and three of the PI?s seven PhD students are now pursuing their own academic careers.       Last Modified: 05/02/2018       Submitted by: Berenice F Mettler]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
