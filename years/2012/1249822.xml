<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Compositional Data Fusion</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The proposed activity will address two problems: (1) transportability, and (2) data fusion. In the first topic, the project focuses on the problem of utilizing conclusions obtained in one environment in another by permitting reasoning agents to focus their reasoning on only the differences, while taking for granted that which is common to both environments. In the second topic, this project will formalize and reduce to algorithmic procedures the general problem of fusing data coherently from multiple heterogeneous sources. The proposed activities will develop effective procedures for determining whether unbiased estimates of causal relationships in a target environment can be synthesized from information obtained from a set of heterogeneous studies. These activities will lead to a theoretical understanding of the conditions under which a learning system can rely on previously learned information, transferred from a different environment. &lt;br/&gt;&lt;br/&gt;Results from this research project have the potential to impact all data-related sciences where the transportability and data-fusion problems are ubiquitous. These two problems demand understanding of causal relationships in the domains being considered. Such causal relationships need to be addressed by causal calculi so as to extract the invariant features from each information source. The approach pursued in this project builds on previous work of the PI, for instance, reasoning with structural causal models and counterfactuals. The problems of transportability and data fusion are critical in the health and social sciences, where data is scarce and experiments are costly; they are of particular interest in the "Big Data" enterprise, which is driven by the premise that data availability will automatically result in data interpretability and where there are nuances among the contexts of data collection.</AbstractNarration>
<MinAmdLetterDate>09/05/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/05/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1249822</AwardID>
<Investigator>
<FirstName>Judea</FirstName>
<LastName>Pearl</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Judea Pearl</PI_FULL_NAME>
<EmailAddress>judea@cs.ucla.edu</EmailAddress>
<PI_PHON>3108253243</PI_PHON>
<NSF_ID>000179905</NSF_ID>
<StartDate>09/05/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA Computer Science Department]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951596</ZipCode>
<StreetAddress><![CDATA[4514 Boelter Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The investigating team has tackled a scientific and computational problem that has been lingering around for at least two centuries. The problem is that of "generalizability" -- under what conditions we are able to generalize experimental results obtained in one environment onto a different environment, potentially different from the first. Needless to state, this problem haunts all the empirical sciences and it has now received formal treatment using graph theoretic tools and perspectives; we currently know precisely when cross domain extrapolations are feasible; that is, we have polynomial time algorithms for deciding this question and for combining information from several diverse environments to synthesize a coherent estimate of the target quantity.</p> <p>We anticipate an immediate practical applications of these results in improving the validity of Randomized Controlled Trials (RCT) which have become the gold standard of program effectiveness tests in the health and social sciences, yet suffer severely from lack of external validity -- subjects volunteering for these trials are not representatives of the population as a whole.</p> <p>Another problem that was tackled using the language of causal graph is that of "missing data." We showed that this problem, which has traditionally been handled by statistical technique, is fundamentally a causal problem, and can benefit substantially from reasoning about the causal process responsible from causing some variables to escape measurement. This paradigm has led to new algorithms capable of recovering probabilistic and causal queries from data corrupted by missingness.</p> <p>Finally, the algorithmization of counterfactuals has enabled the investigating team to apply counterfactual logic to personal decision making, with the aim of equipping robots with the capability of acquiring autonomy, based on their own experience.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/29/2014<br>      Modified by: Judea&nbsp;Pearl</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The investigating team has tackled a scientific and computational problem that has been lingering around for at least two centuries. The problem is that of "generalizability" -- under what conditions we are able to generalize experimental results obtained in one environment onto a different environment, potentially different from the first. Needless to state, this problem haunts all the empirical sciences and it has now received formal treatment using graph theoretic tools and perspectives; we currently know precisely when cross domain extrapolations are feasible; that is, we have polynomial time algorithms for deciding this question and for combining information from several diverse environments to synthesize a coherent estimate of the target quantity.  We anticipate an immediate practical applications of these results in improving the validity of Randomized Controlled Trials (RCT) which have become the gold standard of program effectiveness tests in the health and social sciences, yet suffer severely from lack of external validity -- subjects volunteering for these trials are not representatives of the population as a whole.  Another problem that was tackled using the language of causal graph is that of "missing data." We showed that this problem, which has traditionally been handled by statistical technique, is fundamentally a causal problem, and can benefit substantially from reasoning about the causal process responsible from causing some variables to escape measurement. This paradigm has led to new algorithms capable of recovering probabilistic and causal queries from data corrupted by missingness.  Finally, the algorithmization of counterfactuals has enabled the investigating team to apply counterfactual logic to personal decision making, with the aim of equipping robots with the capability of acquiring autonomy, based on their own experience.          Last Modified: 12/29/2014       Submitted by: Judea Pearl]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
