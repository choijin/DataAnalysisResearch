<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Practical Geo-Replicated Storage for Web Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>There is increasing demand to deploy web applications across multiple data&lt;br/&gt;centers to improve fault tolerance and reduce network delays to&lt;br/&gt;users.  As application servers need to share data, their&lt;br/&gt;construction can be significantly simplified if a storage backend exists for&lt;br/&gt;applications to seamlessly access replicated data at different data centers.&lt;br/&gt;&lt;br/&gt;A geo-replicated storage system faces the unpleasant tradeoff of consistency&lt;br/&gt;vs. performance because of large inter-data-center communication delay.  This&lt;br/&gt;proposal investigates novel consistency and programming models for&lt;br/&gt;geo-replicated storage that are easy-to-use and can achieve good performance.&lt;br/&gt;In particular,  this project proposes parallel snapshot isolation, a novel &lt;br/&gt;consistency model that enables efficient implementation with minimal&lt;br/&gt;coordination across data centers.  Parallel snapshot isolation provides much&lt;br/&gt;stronger guarantees than existing weak consistency models by disallowing&lt;br/&gt;write-write conflicts and preserving the causality of operations.  The PI&lt;br/&gt;builds Walter, a geo-replicated transactional key-value store that guarantees&lt;br/&gt;parallel snapshot isolation.  A number of common web applications are written&lt;br/&gt;on top of Walter and evaluations demonstrate that the new consistency model is&lt;br/&gt;easy to program for and enables applications to achieve high performance.  The&lt;br/&gt;success of this project will bring much improvement to the state-of-art in&lt;br/&gt;writing scalable and fault tolerant web applications.</AbstractNarration>
<MinAmdLetterDate>08/16/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1218117</AwardID>
<Investigator>
<FirstName>Jinyang</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jinyang Li</PI_FULL_NAME>
<EmailAddress>jinyang@cs.nyu.edu</EmailAddress>
<PI_PHON>2129983372</PI_PHON>
<NSF_ID>000105743</NSF_ID>
<StartDate>08/16/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100121019</ZipCode>
<StreetAddress><![CDATA[70 Washington Square S]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~450000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Large-scale web applications rely on a geo-replicated storage backend to improve fault tolerance and reduce network delays to users. &nbsp;However, when data is partitioned and replicated across geographically distant data centers, existing storage systems often have to give up strong consistency guarantees in order to achieve good performance. &nbsp;The goal of this project is to develop geo-distributed storage systems that provide strong consistency guarantees while also achieving good performance.<br />This proposal has produced four geo-distributed storage systems to explore the limits of the tradeoffs between consistency and performance. &nbsp;Our first system is Walter, which provides a novel relaxed consistency model, called Parallel Snapshot Isolation (PSI). PSI is weaker than serializability but allows low-latency asynchronous cross-data center replication. &nbsp;Although PSI is a relaxed consistency model, its guarantees are much stronger than eventual consistency, which is the most common consistency model used by geo-replicated storage systems at the time when Walter was designed. &nbsp;Our next system is Lynx, which provides serializable transactions that can also be asynchronously replicated to remote data centers. &nbsp;Lynx's great consistency vs. performance tradeoff comes with two caveats: one, it guarantees a non-strict form of serializability that may not preserve the actual order between the completion of a transaction and the start of another. &nbsp;Second, Lynx achieves low-latency operations only for ``well-behaved'' workloads for which an offline analysis shows it is safe to execute transactions efficiently one stored procedure piece at a time. &nbsp;Our third system is RoCoCo, which provides the strongest guarantee, i.e. strictly-serializable transactions. &nbsp;It is designed to run on top of synchronous, Paxos-based replication. &nbsp;As a result, each transaction can take up to two wide-area roundtrips. &nbsp;As the latency of a transaction increases significantly due to geo-replication, so does the contention observed in a given workload. &nbsp;Strongly-consistent storage systems based on traditional concurrency control protocols handle contention via pessimistic locking or opportunistic aborts and retries, &nbsp;both of which result in a serious drop in throughput. &nbsp;By contrast, RoCoCo can deliver much higher throughputs when the workload is contended, by avoiding aborting transactions that conflict. &nbsp;Our last system, Janus, cuts down the latency required to achieve strict serializability from multiple cross-data center roundtrips to one in the best case when transactions do not conflict. &nbsp;Janus achieves one-roundtrip latency by consolidating transaction commit and replication into one combined protocol. When transactions conflict, Janus has to commit and replicate a transaction in two roundtrips. It can still achieve good throughput by avoiding aborts.<br />We have prototyped and evaluated our systems on multiple Amazon EC2 data centers. Our evaluations show that our systems can achieve much better performance compared to existing systems that provide similar consistency guarantees. For example, on the popular TPC-C benchmark, RoCoCo's throughput is 130\% and 347\% higher than the two traditional concurrency control protocols, 2PL and OCC.<br />Beyond the main goal of improving the consistency and performance tradeoff in geo-replicated storage systems, this proposal has also made two other note-worthy contributions. &nbsp;First, we have contributed to a practical, high-performance relational storage system design. &nbsp;Among the web development community in the industry, there has been a heated debate on the merits of NoSQL vs. SQL storage backends. &nbsp;With the success of key-value-based NoSQL stores such as Cassandra/HBase/S3, most developers believe that one has to sacrifice the usability of relational stores in order to achieve scalability and high performance. &nbsp;With Lynx, we demonstrate that it is possible to keep the easy-to-use abstraction of relational tables (with indices, materialized views) while providing the same high performance as key-value stores. Second, we have shown that the high-level ideas of RoCoCo and Janus can be applied to multi-core in-memory databases to improve throughput by avoiding contention-induced aborts. We have designed the IC3 multi-core database which achieves 1.2X-20X the throughput of 2PL or OCC under a medium or high level contention.</p><br> <p>            Last Modified: 12/31/2016<br>      Modified by: Jinyang&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Large-scale web applications rely on a geo-replicated storage backend to improve fault tolerance and reduce network delays to users.  However, when data is partitioned and replicated across geographically distant data centers, existing storage systems often have to give up strong consistency guarantees in order to achieve good performance.  The goal of this project is to develop geo-distributed storage systems that provide strong consistency guarantees while also achieving good performance. This proposal has produced four geo-distributed storage systems to explore the limits of the tradeoffs between consistency and performance.  Our first system is Walter, which provides a novel relaxed consistency model, called Parallel Snapshot Isolation (PSI). PSI is weaker than serializability but allows low-latency asynchronous cross-data center replication.  Although PSI is a relaxed consistency model, its guarantees are much stronger than eventual consistency, which is the most common consistency model used by geo-replicated storage systems at the time when Walter was designed.  Our next system is Lynx, which provides serializable transactions that can also be asynchronously replicated to remote data centers.  Lynx's great consistency vs. performance tradeoff comes with two caveats: one, it guarantees a non-strict form of serializability that may not preserve the actual order between the completion of a transaction and the start of another.  Second, Lynx achieves low-latency operations only for ``well-behaved'' workloads for which an offline analysis shows it is safe to execute transactions efficiently one stored procedure piece at a time.  Our third system is RoCoCo, which provides the strongest guarantee, i.e. strictly-serializable transactions.  It is designed to run on top of synchronous, Paxos-based replication.  As a result, each transaction can take up to two wide-area roundtrips.  As the latency of a transaction increases significantly due to geo-replication, so does the contention observed in a given workload.  Strongly-consistent storage systems based on traditional concurrency control protocols handle contention via pessimistic locking or opportunistic aborts and retries,  both of which result in a serious drop in throughput.  By contrast, RoCoCo can deliver much higher throughputs when the workload is contended, by avoiding aborting transactions that conflict.  Our last system, Janus, cuts down the latency required to achieve strict serializability from multiple cross-data center roundtrips to one in the best case when transactions do not conflict.  Janus achieves one-roundtrip latency by consolidating transaction commit and replication into one combined protocol. When transactions conflict, Janus has to commit and replicate a transaction in two roundtrips. It can still achieve good throughput by avoiding aborts. We have prototyped and evaluated our systems on multiple Amazon EC2 data centers. Our evaluations show that our systems can achieve much better performance compared to existing systems that provide similar consistency guarantees. For example, on the popular TPC-C benchmark, RoCoCo's throughput is 130\% and 347\% higher than the two traditional concurrency control protocols, 2PL and OCC. Beyond the main goal of improving the consistency and performance tradeoff in geo-replicated storage systems, this proposal has also made two other note-worthy contributions.  First, we have contributed to a practical, high-performance relational storage system design.  Among the web development community in the industry, there has been a heated debate on the merits of NoSQL vs. SQL storage backends.  With the success of key-value-based NoSQL stores such as Cassandra/HBase/S3, most developers believe that one has to sacrifice the usability of relational stores in order to achieve scalability and high performance.  With Lynx, we demonstrate that it is possible to keep the easy-to-use abstraction of relational tables (with indices, materialized views) while providing the same high performance as key-value stores. Second, we have shown that the high-level ideas of RoCoCo and Janus can be applied to multi-core in-memory databases to improve throughput by avoiding contention-induced aborts. We have designed the IC3 multi-core database which achieves 1.2X-20X the throughput of 2PL or OCC under a medium or high level contention.       Last Modified: 12/31/2016       Submitted by: Jinyang Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
