<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TWC: Small: Assessing Online Information Exposure Using Web Footprints</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/15/2013</AwardEffectiveDate>
<AwardExpirationDate>12/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>499996.00</AwardTotalIntnAmount>
<AwardAmount>499996</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>nan zhang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This research project studies a new area of research - exposure detection - that is at the intersection of data mining, security, and natural language processing. Exposure detection refers to discovering components/attributes of a user's public profile that reduce the user's privacy. To help the public understand the privacy risks of sharing certain information on the web, this research project focuses on developing efficient algorithms for modeling how an adversary learns information using incomplete and schemaless public data sources. Theoretically sound and efficient techniques for identifying accurate web footprints are introduced, including: new methods for data matching using a novel probabilistic join operator on multi-granular data, automated approaches for generating inference rules, and new solutions for identifying missing information and unifying mismatched vocabulary using lightweight natural language processing and text mining. The research activities also investigate methods for quantifying and adjusting exposure and risk, facilitating a better understanding of individuals' vulnerability on the web. These techniques not only advance the state of the art in re-identification, probabilistic reasoning and inference logic, and natural language understanding, but also serve as a foundation for exposure detection.</AbstractNarration>
<MinAmdLetterDate>08/28/2012</MinAmdLetterDate>
<MaxAmdLetterDate>08/28/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1223825</AwardID>
<Investigator>
<FirstName>Lisa</FirstName>
<LastName>Singh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lisa Singh</PI_FULL_NAME>
<EmailAddress>singh@cs.georgetown.edu</EmailAddress>
<PI_PHON>2026879253</PI_PHON>
<NSF_ID>000233811</NSF_ID>
<StartDate>08/28/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Micah</FirstName>
<LastName>Sherr</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Micah Sherr</PI_FULL_NAME>
<EmailAddress>msherr@cs.georgetown.edu</EmailAddress>
<PI_PHON>2026874381</PI_PHON>
<NSF_ID>000562040</NSF_ID>
<StartDate>08/28/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Grace Hui</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Grace Hui Yang</PI_FULL_NAME>
<EmailAddress>huiyang@cs.georgetown.edu</EmailAddress>
<PI_PHON>2026876355</PI_PHON>
<NSF_ID>000604905</NSF_ID>
<StartDate>08/28/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgetown University</Name>
<CityName>Washington</CityName>
<ZipCode>200571789</ZipCode>
<PhoneNumber>2026250100</PhoneNumber>
<StreetAddress>37th &amp; O St N W</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049515844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGETOWN UNIVERSITY (THE)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049515844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgetown University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200571789</ZipCode>
<StreetAddress><![CDATA[37th & O St N W]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~499996</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Normal1">With the emergence of online social networks and the growing popularity of digital communication, more and more information about individuals is becoming available on the Internet. While much of this information is not sensitive, it is not uncommon for users to publish some sensitive information on social networking sites. The availability of this publicly accessible and potentially sensitive data can (and does) lead to abuse, exposing users to stalking and identity theft.</p> <div class="page" title="Page 1"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>To help users better understand the potential risks associated with publishing certain data on the web, as well as the quantity and sensitivity of information that can be obtained by combining data from various online sources, we developed a multi&shy;faceted framework and prototype system that generates and analyzes web footprints. Web footprints are the traces of one&rsquo;s social activities represented by a set of attributes that are known or can be inferred with a high probability by an adversary who has basic i</span>nformation about a user and has access to publicly available information from online sources. This research project focused on mitigating such privacy threats by constructing a framework that includes algorithms for modeling how an adversary learns information using incomplete and schema-less public data sources that enable web users to better understand their public profiles.&nbsp;</p> </div> </div> </div> </div> <div class="page" title="Page 2"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>Our framework includes three types of inference &ndash; pattern&shy; based inference, probabilistic dependency inference, and population&shy; based inference. Pattern based inference uses bootstrapped patterns found in a corpus&nbsp;to extract structured attributes from text, e.g. identify a birthday from a tweet. &nbsp;This helps increase the amount of usable information for web footprint construction. In addition to observable data, probabilistic inference logic is applied to supplement web footprints with probable attribute value pairs learned using algebraic dependencies between attribute values in user profiles on different sites. Finally, we use site-level population data to further infer the user&rsquo;s attribute values. To allow for population level comparison, our framework also quantifies a user&rsquo;s level of public information exposure relative to others with similar traits as well as with regard to others in the population.</span></p> </div> </div> </div> </div> <p class="Normal1">The final part of our framework focuses on helping users improve their privacy. We developed risk reduction recommendation algorithms that suggest removal or modification of a small number of attributes, thereby reducing the overall number of attributes that can be discovered with high confidence using inference methods. While we developed a number of different strategies, the most novel focuses on suggesting modifications to a user&rsquo;s public profile to directly match a persona, where a persona is a set of attribute-value pairs that occur together in a population with a frequency above a predefined threshold. A profile is deemed safe if it matches a persona because that profile&rsquo;s particular set of attributes occurs enough times in the population to allow it to blend into a homogeneous group. The concept of blending into a crowd is similar to the idea of k- anonymity, but we extend it to the realm of public social network data containing shared attributes across websites.&nbsp;</p> <p class="Normal1">The project resulted in over 20 publications, including a best paper runner up, a prototype privacy application that can be used by students to monitor their web footprints, research training of seven undergraduates, three Master&rsquo;s students and two PhD students, and a half a dozen outreach talks related to web privacy to high school and college students, as well as researchers and practicioners. Our work in the area of web footprinting, the ethics of using big data, privacy in information retrieval, dynamic search algorithms, voice authentication privacy, and network traffic privacy are pioneering in their respective communities. Research is being advanced in data mining, privacy, security, and information retrieval. Ideas related to this project have been shared through papers, presentations, invited panels, and workshop organization. We hope that the algorithms and software will be extended and used by different universities to help their students better understand the privacy risks associated with sharing so much data publicly.&nbsp;</p><br> <p>            Last Modified: 03/31/2017<br>      Modified by: Lisa&nbsp;Singh</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[With the emergence of online social networks and the growing popularity of digital communication, more and more information about individuals is becoming available on the Internet. While much of this information is not sensitive, it is not uncommon for users to publish some sensitive information on social networking sites. The availability of this publicly accessible and potentially sensitive data can (and does) lead to abuse, exposing users to stalking and identity theft.      To help users better understand the potential risks associated with publishing certain data on the web, as well as the quantity and sensitivity of information that can be obtained by combining data from various online sources, we developed a multi&shy;faceted framework and prototype system that generates and analyzes web footprints. Web footprints are the traces of one?s social activities represented by a set of attributes that are known or can be inferred with a high probability by an adversary who has basic information about a user and has access to publicly available information from online sources. This research project focused on mitigating such privacy threats by constructing a framework that includes algorithms for modeling how an adversary learns information using incomplete and schema-less public data sources that enable web users to better understand their public profiles.           Our framework includes three types of inference &ndash; pattern&shy; based inference, probabilistic dependency inference, and population&shy; based inference. Pattern based inference uses bootstrapped patterns found in a corpus to extract structured attributes from text, e.g. identify a birthday from a tweet.  This helps increase the amount of usable information for web footprint construction. In addition to observable data, probabilistic inference logic is applied to supplement web footprints with probable attribute value pairs learned using algebraic dependencies between attribute values in user profiles on different sites. Finally, we use site-level population data to further infer the user?s attribute values. To allow for population level comparison, our framework also quantifies a user?s level of public information exposure relative to others with similar traits as well as with regard to others in the population.     The final part of our framework focuses on helping users improve their privacy. We developed risk reduction recommendation algorithms that suggest removal or modification of a small number of attributes, thereby reducing the overall number of attributes that can be discovered with high confidence using inference methods. While we developed a number of different strategies, the most novel focuses on suggesting modifications to a user?s public profile to directly match a persona, where a persona is a set of attribute-value pairs that occur together in a population with a frequency above a predefined threshold. A profile is deemed safe if it matches a persona because that profile?s particular set of attributes occurs enough times in the population to allow it to blend into a homogeneous group. The concept of blending into a crowd is similar to the idea of k- anonymity, but we extend it to the realm of public social network data containing shared attributes across websites.  The project resulted in over 20 publications, including a best paper runner up, a prototype privacy application that can be used by students to monitor their web footprints, research training of seven undergraduates, three Master?s students and two PhD students, and a half a dozen outreach talks related to web privacy to high school and college students, as well as researchers and practicioners. Our work in the area of web footprinting, the ethics of using big data, privacy in information retrieval, dynamic search algorithms, voice authentication privacy, and network traffic privacy are pioneering in their respective communities. Research is being advanced in data mining, privacy, security, and information retrieval. Ideas related to this project have been shared through papers, presentations, invited panels, and workshop organization. We hope that the algorithms and software will be extended and used by different universities to help their students better understand the privacy risks associated with sharing so much data publicly.        Last Modified: 03/31/2017       Submitted by: Lisa Singh]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
