<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research:   The Use of Segmentation Cues in Second Language Learners of English</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2013</AwardEffectiveDate>
<AwardExpirationDate>01/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>13482.00</AwardTotalIntnAmount>
<AwardAmount>13482</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The first step in speech comprehension is to break up the speech signal and identify the individual words. To do so, one must locate where one word ends and the next begins. Unlike in written text, where there is a visual gap between pairs of words, no such reliable cue for word boundaries exists in spoken speech. Research has shown that native English listeners can utilize a set of cues to segment continuous speech, including the structure and meaning of sentences, knowledge of what constitutes a real word in English, sensitivity to whether a sound is allowed in a certain position in the word, and the emphasis given to a part of the word. However, it is not clear whether these segmentation cues are used by nonnative listeners in a similar fashion. &lt;br/&gt;&lt;br/&gt;The use of cues may be influenced by nonnative listeners' English proficiency. Beginning or intermediate second language (L2) learners may have less established knowledge about what constitute a real word in English. Also, L2 learners' use of cues may be influenced by the characteristics of sounds in their native languages. Four groups of participants, including a monolingual English group and three nonnative groups (Mandarin, Korean, and Spanish), will participate in four experiments. Each experiment will examine how L2 learners differ from native listeners in the use of cues and how the three L2 groups differ from each other as a result of their native language experiences.&lt;br/&gt;&lt;br/&gt;Understanding speech is a critical component in language acquisition and identifying cues that can facilitate this process will benefit both learners and teachers. There are nearly 40 million L2 learners in the U.S.; improved English proficiency will help them become more competitive and productive in the work place. This study also contributes to the training of a promising young researcher.</AbstractNarration>
<MinAmdLetterDate>01/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>01/16/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1251589</AwardID>
<Investigator>
<FirstName>Rochelle</FirstName>
<LastName>Newman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rochelle Newman</PI_FULL_NAME>
<EmailAddress>rnewman1@umd.edu</EmailAddress>
<PI_PHON>3014054226</PI_PHON>
<NSF_ID>000292318</NSF_ID>
<StartDate>01/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Min</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Min Wang</PI_FULL_NAME>
<EmailAddress>minwang@umd.edu</EmailAddress>
<PI_PHON>3014058798</PI_PHON>
<NSF_ID>000204212</NSF_ID>
<StartDate>01/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Candise</FirstName>
<LastName>Lin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Candise Lin</PI_FULL_NAME>
<EmailAddress>candisec@umd.edu</EmailAddress>
<PI_PHON>3014056269</PI_PHON>
<NSF_ID>000608326</NSF_ID>
<StartDate>01/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~13482</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The problem of segmenting continuous speech is a great challenge for native listeners and second language (L2) learners alike. Speech signal, unlike written text with the presence of visual gaps, often do not contain breaks at word edges. Even when breaks occur in the form of pauses, they usually do not coincide with perceived word boundaries. Listeners can solve the segmentation problem by utilizing a variety of cues such as the context and structure of sentences, listeners&rsquo; own knowledge of what constitutes a real word in English, which sound is legal or not legal at the beginning&nbsp;or ending of a word, and greater phonetic emphasis at the edges of word. Previous research with native English listeners have shown that, when all cues are available, they tend to rely more on sentence and vocabulary cues than cues that involve individual sounds or acoustic cues. It is not clear whether such patterns of cue use can be applied to listeners who learned English as a second language (L2) since studies of L2 segmentation are relatively scarce. The current dissertation project might be one of the first to fill in this gap in the literature.</p> <p>&nbsp;</p> <p>Participants in the current project included English L2 learners who were native speakers of Mandarin, Korean, and Spanish as well as monolingual English listeners. The reason for choosing these three L1 languages was that they vary in terms of which sounds are allowed in word-initial or word-final positions. The phoneme /n/ is allowed in both word-initial and word-final positions in all four languages. In Mandarin, Korean, and English, [ng] (as in <em>sing and finger</em>)&nbsp;is only allowed word-finally while this phoneme does not exist in Spanish (although /n/ is sometimes realized as [ng] in certain phonological environments). While /s/ is allowed word-initially in all four languages, this consonant cannot be in the word-final position in both Mandarin and Korean. Four experiments were conducted. In each experiment, participants were asked to identify or make lexical judgment about the target word, which is embedded in a phrase or sentence, thus word boundaries must be identified before participants could make a response. Experiment 1 showed that all three L2 groups did not use vocabulary knowledge to the same extent as native English listeners. Experiment 2 showed that although [ng] does not exist in Spanish&rsquo;s phoneme inventory, Spanish L2 learners of English did not experience any difficulty using this cue in segmentation. In other words, they are faster to identify a word boundary following [ng] than following /n/. On the other than, all four language groups were slower to identify a word boundary following /s/ than following /n/ since /s/ is more likely to be a word-initial consonant than /n/. Therefore, listeners might have mistakenly grouped /s/ with the following word. Experiment 3 showed that L2 learners did not use word meaning as a segmentation cue to the same extent as native listeners. Finally, Experiment 4 showed that L2 learners did not use sentence context to the same extent as native listeners. Overall, the current dissertation project showed that nonnative listeners did not use cues at the word and sentence level as efficiently as native listeners did. One&nbsp;explanation for this fining is that the access to word meaning and sentence structure in English may be less automatized in L2 learners. However, it is possible for L2 learners develop sensitivity to the distributional patterns of sounds in English.</p> <p>This study may have significant implications for pedagogical practices. First, our findings could inform teachers about cues that are employed less reliably by L2 learners. L2 speech comprehension will be more effective if teachers can selectively direct students&rsquo; attention to&nbsp;these cues. Second, participants in this study represented a diversity of language b...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The problem of segmenting continuous speech is a great challenge for native listeners and second language (L2) learners alike. Speech signal, unlike written text with the presence of visual gaps, often do not contain breaks at word edges. Even when breaks occur in the form of pauses, they usually do not coincide with perceived word boundaries. Listeners can solve the segmentation problem by utilizing a variety of cues such as the context and structure of sentences, listenersÆ own knowledge of what constitutes a real word in English, which sound is legal or not legal at the beginning or ending of a word, and greater phonetic emphasis at the edges of word. Previous research with native English listeners have shown that, when all cues are available, they tend to rely more on sentence and vocabulary cues than cues that involve individual sounds or acoustic cues. It is not clear whether such patterns of cue use can be applied to listeners who learned English as a second language (L2) since studies of L2 segmentation are relatively scarce. The current dissertation project might be one of the first to fill in this gap in the literature.     Participants in the current project included English L2 learners who were native speakers of Mandarin, Korean, and Spanish as well as monolingual English listeners. The reason for choosing these three L1 languages was that they vary in terms of which sounds are allowed in word-initial or word-final positions. The phoneme /n/ is allowed in both word-initial and word-final positions in all four languages. In Mandarin, Korean, and English, [ng] (as in sing and finger) is only allowed word-finally while this phoneme does not exist in Spanish (although /n/ is sometimes realized as [ng] in certain phonological environments). While /s/ is allowed word-initially in all four languages, this consonant cannot be in the word-final position in both Mandarin and Korean. Four experiments were conducted. In each experiment, participants were asked to identify or make lexical judgment about the target word, which is embedded in a phrase or sentence, thus word boundaries must be identified before participants could make a response. Experiment 1 showed that all three L2 groups did not use vocabulary knowledge to the same extent as native English listeners. Experiment 2 showed that although [ng] does not exist in SpanishÆs phoneme inventory, Spanish L2 learners of English did not experience any difficulty using this cue in segmentation. In other words, they are faster to identify a word boundary following [ng] than following /n/. On the other than, all four language groups were slower to identify a word boundary following /s/ than following /n/ since /s/ is more likely to be a word-initial consonant than /n/. Therefore, listeners might have mistakenly grouped /s/ with the following word. Experiment 3 showed that L2 learners did not use word meaning as a segmentation cue to the same extent as native listeners. Finally, Experiment 4 showed that L2 learners did not use sentence context to the same extent as native listeners. Overall, the current dissertation project showed that nonnative listeners did not use cues at the word and sentence level as efficiently as native listeners did. One explanation for this fining is that the access to word meaning and sentence structure in English may be less automatized in L2 learners. However, it is possible for L2 learners develop sensitivity to the distributional patterns of sounds in English.  This study may have significant implications for pedagogical practices. First, our findings could inform teachers about cues that are employed less reliably by L2 learners. L2 speech comprehension will be more effective if teachers can selectively direct studentsÆ attention to these cues. Second, participants in this study represented a diversity of language backgrounds. Since English is the lingua franca of the world, children and adults around the world are learning English both formally...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
