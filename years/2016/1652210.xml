<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Perceptually Guided Hand Motion Synthesis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2017</AwardEffectiveDate>
<AwardExpirationDate>01/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>497158.00</AwardTotalIntnAmount>
<AwardAmount>542158</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research will explore ways to automatically synthesize hand and finger animation for virtual characters that exploit human perception as an inherent part of the algorithm.   In recent years, character animation has taken tremendous strides towards realistic virtual agents, with increasingly better solutions for body motion capture, for achieving highly realistic facial animation, and for simulating cloth and hair.  With these key components in place, the need to create plausible hand and finger motions has become important because these play a crucial role in communicating information while also allowing us to conduct basic tasks and to handle complex tools.  But the differences in size and complexity of hand motions compared to body motions make it difficult to capture or synthesize both at the same time.  Therefore, finger motions are typically still animated manually, which is a cumbersome process.  Taking advantage of perceptual findings could enable the creation of new algorithms to accomplish this task (e.g., by suggesting new methods and by aiding in algorithm parameter adjustment).  The ultimate goal of this research is to merge character animation and motion perception into an interdisciplinary field that yields new insights and approaches to finger and hand movement synthesis as well as a better understanding of how we communicate.    If successful, the work will significantly advance the way we design algorithms to bring virtual characters to life, and project outcomes will have broad impact not only in computer graphics but also in applications such as virtual reality, robotics and prosthetics.  The project includes integrated educational and outreach activities for K-12, undergraduate, and graduate students.  &lt;br/&gt;&lt;br/&gt;This research will initiate a fundamental transformation of how we design algorithms for character animation by coupling perceptual experiments with computer animation algorithm development for hand and finger motion synthesis.  Several approaches and devices have been suggested for hand and finger animation, each with their own drawbacks. Some of these approaches show promise and could be improved or combined, but the options are many and a more systematic approach is required.  This work will focus on two applications: data-driven hand motion synthesis for virtual characters, and hand motions for interaction and communication in virtual reality.  The plan is to develop an algorithm for hand motion synthesis based on segment and pose matching, on perceptual insights on the relevance of finger poses and dynamics, and on the perception of collisions, to support real-time interaction in virtual reality.</AbstractNarration>
<MinAmdLetterDate>01/31/2017</MinAmdLetterDate>
<MaxAmdLetterDate>05/25/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1652210</AwardID>
<Investigator>
<FirstName>Sophie</FirstName>
<LastName>Joerg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sophie Joerg</PI_FULL_NAME>
<EmailAddress>sjoerg@clemson.edu</EmailAddress>
<PI_PHON>8646560538</PI_PHON>
<NSF_ID>000626746</NSF_ID>
<StartDate>01/31/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Clemson University</Name>
<CityName>CLEMSON</CityName>
<ZipCode>296345701</ZipCode>
<PhoneNumber>8646562424</PhoneNumber>
<StreetAddress>230 Kappa Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>South Carolina</StateName>
<StateCode>SC</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>SC03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042629816</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CLEMSON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042629816</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Clemson University]]></Name>
<CityName>Clemson</CityName>
<StateCode>SC</StateCode>
<ZipCode>296340001</ZipCode>
<StreetAddress><![CDATA[School of Computing, 318 McAdams]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>South Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>SC03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~109459</FUND_OBLG>
<FUND_OBLG>2018~95895</FUND_OBLG>
<FUND_OBLG>2019~105990</FUND_OBLG>
<FUND_OBLG>2020~117902</FUND_OBLG>
<FUND_OBLG>2021~112912</FUND_OBLG>
</Award>
</rootTag>
