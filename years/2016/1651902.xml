<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Vision-Based Activity Forecasting by Mining Temporal Causalities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>180000.00</AwardTotalIntnAmount>
<AwardAmount>180000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project explores methodologies for forecasting long-term human group activity from videos. Forecasting future activities in real-world videos is an emerging computer vision problem with important applications in visual surveillance for security. This project systematically and rigorously formulates long-term group activity forecasting problem as causalities of visual entities, and designs visual intelligence systems using machine learning and data mining methods. The research considers multiple visual identities of different types, models their interactions, and mines the sequential causalities between these visual entities in videos. These causalities are used for forecasting future group and individual activities. The project creates new mathematical models for describing and simplifying understanding statistical properties of human activity videos. The project leads to important and timely technology that can help to design future video analysis systems with optimal performance in understanding and searching activities from videos. The project tightly integrates research and education activities for the purpose of providing young researchers with project-based learning opportunities in an interdisciplinary environment that offers exceptional professional and personal growth opportunities. &lt;br/&gt;&lt;br/&gt;This research discovers complex causality patterns between visual entities from noisy visual data, in order to gain rich and useful knowledge for the forecasting of future visual activities. This essentially bridges the gap between human understandable visual semantics and high-dimensional noisy visual data. The research enables to efficiently capture interactions between multiple visual entities and their temporal causalities, and provides rich knowledge for guiding long-term group activity forecasting. The project also explores several innovative ways to leverage rich sequential context and builds progress level-invariant features. This naturally enriches feature representations from temporally partially observed data, and allows building more time efficient activity prediction machines. Moreover, the project develops an effective forecasting model that can elegantly utilize causalities mined from visual data for long-term forecasting. The developed technologies can lead to new intelligent systems.</AbstractNarration>
<MinAmdLetterDate>08/18/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1651902</AwardID>
<Investigator>
<FirstName>Yun</FirstName>
<LastName>Fu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yun Fu</PI_FULL_NAME>
<EmailAddress>y.fu@neu.edu</EmailAddress>
<PI_PHON>2172991432</PI_PHON>
<NSF_ID>000560082</NSF_ID>
<StartDate>08/18/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~180000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Standard">By completing this project, a set of novel visual understanding methodologies and mathematical models for long-term human group activity forecasting has been created and addressed from low-level to high-level computer vision. Comprehensive vision-based intelligent forecasting framework has been investigated that reasons future activities of people. Fundamental research topics have also been extensively explored such as multiview multitask and multisource learning, deep sequential context networks, guided attention inference networks, residual dense networks, adaptive graph embedding and transfer learning, adversarial graph embedding, etc. Such new methods have been evaluated in general and broader visual learning and classification tasks, as well as specific domains including human motion segmentation, action recognitions, activity prediction, person re-identification, zero-shot action recognition, and unsupervised domain adaptation, etc. Multi-object tracking and re-identification techniques were integrated to further consider multiple visual identities of different types, model their interactions, and mine the sequential causalities between these visual entities from visual cues in videos. Feasible results of activity and action recognition, early prediction, and long-term forecasting have been achieved and expected significance of outcomes were demonstrated.</p> <p class="Standard">The key project outcomes include a fully comprehensive study of vision-based activity forecasting at different temporal level of observing; byproducts of fundamental techniques, models, algorithms have been presented and evaluated on visual processing, recognition, re-identification, classification, inference and prediction scenarios; and more than 76 peer-reviewed publications in conference proceedings, journals, and books. The research has also provided opportunities for the research team to engage in educational and outreach activities to serve a variety of communities, including the NSF Young Scholars/RET/REU programs and Gordon Scholar program at Northeastern University.</p><br> <p>            Last Modified: 09/16/2019<br>      Modified by: Yun&nbsp;Fu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[By completing this project, a set of novel visual understanding methodologies and mathematical models for long-term human group activity forecasting has been created and addressed from low-level to high-level computer vision. Comprehensive vision-based intelligent forecasting framework has been investigated that reasons future activities of people. Fundamental research topics have also been extensively explored such as multiview multitask and multisource learning, deep sequential context networks, guided attention inference networks, residual dense networks, adaptive graph embedding and transfer learning, adversarial graph embedding, etc. Such new methods have been evaluated in general and broader visual learning and classification tasks, as well as specific domains including human motion segmentation, action recognitions, activity prediction, person re-identification, zero-shot action recognition, and unsupervised domain adaptation, etc. Multi-object tracking and re-identification techniques were integrated to further consider multiple visual identities of different types, model their interactions, and mine the sequential causalities between these visual entities from visual cues in videos. Feasible results of activity and action recognition, early prediction, and long-term forecasting have been achieved and expected significance of outcomes were demonstrated. The key project outcomes include a fully comprehensive study of vision-based activity forecasting at different temporal level of observing; byproducts of fundamental techniques, models, algorithms have been presented and evaluated on visual processing, recognition, re-identification, classification, inference and prediction scenarios; and more than 76 peer-reviewed publications in conference proceedings, journals, and books. The research has also provided opportunities for the research team to engage in educational and outreach activities to serve a variety of communities, including the NSF Young Scholars/RET/REU programs and Gordon Scholar program at Northeastern University.       Last Modified: 09/16/2019       Submitted by: Yun Fu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
