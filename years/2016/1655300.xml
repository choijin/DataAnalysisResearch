<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Discovering Hierarchical Representations for Action Understanding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>555792.00</AwardTotalIntnAmount>
<AwardAmount>555792</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A major issue in the psychological sciences is understanding how people can infer the intentions of others. Humans are remarkably adept at predicting the actions of other people and making inferences about their intention and goals. The present investigation examines how humans make such inferences from the physical movements of others. The work is guided by a computational theory of biological motion understanding that quantifies what aspects of actions allow observers to make inferences about the meaning of actions and what might come next. The larger goal is to explain how perception and reasoning operate synergistically to infer hidden goals and intentions. These findings will guide development of the next generation of intelligent machine-vision systems, useful in forensic sciences as well as many other real-world applications. Such systems will need to perform challenging tasks that currently are difficult and time-consuming for humans (for example, automated interpretation of human actions recorded in low-resolution surveillance video). The project will also help to identify individual differences in action understanding, potentially revealing the nature of the impairments in action understanding observed in people with autism disorder. In addition, the project will provide a unique training opportunity for students who are interested in interdisciplinary research at the interface between cognitive science and artificial intelligence and will provide an in-depth international research experience for a graduate student and postdoctoral fellow.&lt;br/&gt;&lt;br/&gt;The research will integrate advanced psychophysical methods with sophisticated computational approaches. A key aim is to develop a unified theory based on a hierarchical non-parametric Bayesian framework, specifying the fundamental computational mechanisms involved in perception of human actions and reasoning about them. More generally, the project will use human body movements as an underutilized approach to understanding general problems in learning: how to construct, use and transform hierarchical representations to support human perception and cognition. Three aims are particularly noteworthy. First, the project will integrate computational modeling approaches with behavioral experiments to investigate the critical connection between perceptual and cognitive systems. Second, the project uses action stimuli derived from motion capture data in the real world as the visual input (CCTV images collected in the UK and secured at the University of Glasgow). By avoiding the limitations of studies that use restricted examples and constrained environments, the investigators maximize the likelihood that the findings will generalize to real-world situations. Third, the project will develop significant extensions of Bayesian approaches in order to study complex visual processes by combining generative models with probabilistic constraints.  This award is co-funded by the Perception, Action, and Cognition Program and the Office of International Science and Engineering.</AbstractNarration>
<MinAmdLetterDate>04/05/2017</MinAmdLetterDate>
<MaxAmdLetterDate>04/05/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1655300</AwardID>
<Investigator>
<FirstName>Hongjing</FirstName>
<LastName>Lu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hongjing Lu</PI_FULL_NAME>
<EmailAddress>hongjing@ucla.edu</EmailAddress>
<PI_PHON>3102062587</PI_PHON>
<NSF_ID>000498799</NSF_ID>
<StartDate>04/05/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA Psychology Department]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951563</ZipCode>
<StreetAddress><![CDATA[BOX 951563, 6552 Franz Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>054Y</Code>
<Text>GVF - Global Venture Fund</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>5946</Code>
<Text>UNITED KINGDOM</Text>
</ProgramReference>
<ProgramReference>
<Code>5980</Code>
<Text>WESTERN EUROPE PROGRAM</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~555792</FUND_OBLG>
</Award>
</rootTag>
