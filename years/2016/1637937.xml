<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Collaborative Research: A Framework for Hierarchical, Probabilistic Planning and Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>365437.00</AwardTotalIntnAmount>
<AwardAmount>381437</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Miller</SignBlockName>
<PO_EMAI>damiller@nsf.gov</PO_EMAI>
<PO_PHON>7032924914</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is an effort to create a unified framework for solving very large problems with uncertain states and actions, such as manipulator robots acting in real-world environments.  The results may have especially great promise for assistive technologies, including autonomous robots that can be used by elderly and disabled populations to aid them in their daily activities.  The proposed integrated framework will represent, apply, and learn hierarchical domain knowledge, and will include the ability to transfer knowledge from simpler problems to more complex ones. The research will enable autonomous agents to develop a structured representation of complex domains based on experience. The agents will use learned representations to interpret natural language commands for both low-level and high-level requests.  &lt;br/&gt;&lt;br/&gt;The technical focus is enabling tractable planning in large, uncertain domains by generating and leveraging probabilistic domain knowledge at multiple levels of abstraction. Agents will autonomously create layered representations in which the layers build on one another to produce complex behaviors. Agents will learn to perform useful behaviors, such as navigating using low-level sensor feedback or assembling complex objects such as a bridge or a table.  The key technical contributions will be methods for (1) planning in large state/action spaces using the abstract object-oriented Markov decision process (AMDP) model, a new formalism for representing probabilistic domain knowledge at multiple levels of abstraction; (2) learning hierarchical task knowledge in the form of AMDPs; and (3) interpreting natural language commands at multiple levels of abstraction by mapping to the learned hierarchical structure. The formalism will be demonstrated and validated in several domains, including a simulated "cleanup" toy domain, challenging and complex video games, and a robot manipulation task.</AbstractNarration>
<MinAmdLetterDate>08/17/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1637937</AwardID>
<Investigator>
<FirstName>Cynthia</FirstName>
<LastName>Matuszek</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Cynthia Matuszek</PI_FULL_NAME>
<EmailAddress>cmat@umbc.edu</EmailAddress>
<PI_PHON>5125774025</PI_PHON>
<NSF_ID>000690099</NSF_ID>
<StartDate>06/14/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marie</FirstName>
<LastName>desJardins</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marie E desJardins</PI_FULL_NAME>
<EmailAddress>mariedj@cs.umbc.edu</EmailAddress>
<PI_PHON>4104553967</PI_PHON>
<NSF_ID>000231667</NSF_ID>
<StartDate>08/17/2016</StartDate>
<EndDate>06/14/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland Baltimore County</Name>
<CityName>Baltimore</CityName>
<ZipCode>212500002</ZipCode>
<PhoneNumber>4104553140</PhoneNumber>
<StreetAddress>1000 Hilltop Circle</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>061364808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND BALTIMORE COUNTY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland Baltimore County]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212500002</ZipCode>
<StreetAddress><![CDATA[1000 Hilltop Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~365437</FUND_OBLG>
<FUND_OBLG>2017~8000</FUND_OBLG>
<FUND_OBLG>2018~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major goal of this project is to create a framework that will allow self-guided software and robots (agents) to make plans and follow them in complicated human environments. They do this in the same way people do: by learning parts of tasks, and then generalizing to more abstract versions of the same tasks. For example, "Picking something up and moving it" is an abstraction of "Bring me the water bottle," which, once learned, provides understanding of bringing other things to other places. These agents learn by being told how to perform tasks, then corrected over the course of doing them as mistakes are made. We also studied how these software agents can learn more efficiently by asking questions as well as receiving instructions, rather like human students do.<br /><br />Over the course of this project, we have made scientific contribution that enable the following. First, we developed methods to improve the efficiency of planning forward in time. The process of planning out a series of actions is fast for people, but slow for agents. This is because naive planning involves looking at many combinations and sequences of possible actions. We introduced a novel planning model to find abstractions of actions and apply those to new problems, as described above. This method entails both a new way of representing planning problems hierarchically, and a new way of learning both abstractions and specifics simultaneously. Second, we discovered efficient ways of learning those plans by enabling the agents to ask good questions and by improving the core approach to exploring possible plans. Finally, because the right way to make plans depends on the complexity of the problem, we developed a new method of evaluating how complicated an instruction is, both linguistically and with respect to the environment it occurs in.<br /><br />This work is part of the rich body of research on how computers and robots can learn from people by asking questions, performing actions, and learning from mistakes. Ultimately, this will allow agents to work seamlessly alongside people on shared tasks.</p><br> <p>            Last Modified: 05/18/2021<br>      Modified by: Cynthia&nbsp;Matuszek</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goal of this project is to create a framework that will allow self-guided software and robots (agents) to make plans and follow them in complicated human environments. They do this in the same way people do: by learning parts of tasks, and then generalizing to more abstract versions of the same tasks. For example, "Picking something up and moving it" is an abstraction of "Bring me the water bottle," which, once learned, provides understanding of bringing other things to other places. These agents learn by being told how to perform tasks, then corrected over the course of doing them as mistakes are made. We also studied how these software agents can learn more efficiently by asking questions as well as receiving instructions, rather like human students do.  Over the course of this project, we have made scientific contribution that enable the following. First, we developed methods to improve the efficiency of planning forward in time. The process of planning out a series of actions is fast for people, but slow for agents. This is because naive planning involves looking at many combinations and sequences of possible actions. We introduced a novel planning model to find abstractions of actions and apply those to new problems, as described above. This method entails both a new way of representing planning problems hierarchically, and a new way of learning both abstractions and specifics simultaneously. Second, we discovered efficient ways of learning those plans by enabling the agents to ask good questions and by improving the core approach to exploring possible plans. Finally, because the right way to make plans depends on the complexity of the problem, we developed a new method of evaluating how complicated an instruction is, both linguistically and with respect to the environment it occurs in.  This work is part of the rich body of research on how computers and robots can learn from people by asking questions, performing actions, and learning from mistakes. Ultimately, this will allow agents to work seamlessly alongside people on shared tasks.       Last Modified: 05/18/2021       Submitted by: Cynthia Matuszek]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
