<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Conference:   Perceptrons and Syntactic Structures at 60: Computational Modeling of Language</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>01/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>24184.00</AwardTotalIntnAmount>
<AwardAmount>24184</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This workshop will bring together leading researchers in cognitive science and artificial intelligence who specialize in the integration of linguistic theory with statistical approaches, especially neural networks. Neural networks have been important in many of the recent advances in language technologies (in what's called "deep learning"), and the greater integration of linguistic structure into these models promises to lead to further breakthroughs. &lt;br/&gt;&lt;br/&gt;The main focus of this meeting will be on how integration of models of linguistic structure with probabilistic learning theories may lead to a deeper understanding of the way that humans process and represent language. This sort of integration has been difficult to achieve in the past in part because of the separation of researchers in each tradition into different disciplines interacting in different conferences. In-depth analysis of the structure of human languages is conducted in mostly in Linguistics, while neural network modeling and other statistical learning research is conducted mostly in Psychology and Computer Science. The workshop will be held as part of the inaugural meeting of the Society for Computation in Linguistics, taking place concurrently with the meeting of the Linguistic Society of America. It will thus bring researchers from other disciplines into contact with linguists, and will stimulate productive intellectual exchange.</AbstractNarration>
<MinAmdLetterDate>07/19/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1651142</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Pater</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joseph Pater</PI_FULL_NAME>
<EmailAddress>pater@linguist.umass.edu</EmailAddress>
<PI_PHON>4135771308</PI_PHON>
<NSF_ID>000168563</NSF_ID>
<StartDate>07/19/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brendan</FirstName>
<LastName>O'Connor</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brendan T O'Connor</PI_FULL_NAME>
<EmailAddress>brenocon@cs.umass.edu</EmailAddress>
<PI_PHON>4135772503</PI_PHON>
<NSF_ID>000703500</NSF_ID>
<StartDate>07/19/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039242</ZipCode>
<StreetAddress><![CDATA[70 Butterfield Terrace]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~24184</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Language technology is now part of the daily lives of most citizens of this country, as they make use of voice recognition or translation software, or even write text messages that are completed automatically. Recent developments in that technology have largely been fueled by developments in computational neural networks, also known as deep learning.&nbsp;This project aimed to bring together research in neural networks with research in linguistics.&nbsp;</p> <p>In linguistics, a primary focus is the structural complexity of human language. The meaning of a sentence is more than the sum of the meanings of the individual words: it derives also from the way the words are put together in syntactic structures (for example, into noun and verb phrases, which themselves are put together to form entire sentences).&nbsp;</p> <p>To bring together these two research traditions, a workshop was held that brought together researchers working across them. The central question addressed in this workshop was the extent to which the existing neural network models used in language technology can learn to represent the full structural complexity of human language. This leads to a further question of whether the insights of linguistic theory can be leveraged in creating computational models that do better in representing linguistic knowledge. The 9 talks and 3 discussion sections at the workshop provided considerable new evidence on both of these questions, and pointed to a number of directions for further research.</p> <p>The workshop was held with the annual meeting of the Linguistic Society of America in January 2018, which allowed a broad audience to participate. The talks and discussion sections were videotaped, and are publicly available at https://www.youtube.com/playlist?list=PL9UURLQttNX2Lfs0EoOlIa4ns0bhra8_Y.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/21/2019<br>      Modified by: Joseph&nbsp;Pater</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Language technology is now part of the daily lives of most citizens of this country, as they make use of voice recognition or translation software, or even write text messages that are completed automatically. Recent developments in that technology have largely been fueled by developments in computational neural networks, also known as deep learning. This project aimed to bring together research in neural networks with research in linguistics.   In linguistics, a primary focus is the structural complexity of human language. The meaning of a sentence is more than the sum of the meanings of the individual words: it derives also from the way the words are put together in syntactic structures (for example, into noun and verb phrases, which themselves are put together to form entire sentences).   To bring together these two research traditions, a workshop was held that brought together researchers working across them. The central question addressed in this workshop was the extent to which the existing neural network models used in language technology can learn to represent the full structural complexity of human language. This leads to a further question of whether the insights of linguistic theory can be leveraged in creating computational models that do better in representing linguistic knowledge. The 9 talks and 3 discussion sections at the workshop provided considerable new evidence on both of these questions, and pointed to a number of directions for further research.  The workshop was held with the annual meeting of the Linguistic Society of America in January 2018, which allowed a broad audience to participate. The talks and discussion sections were videotaped, and are publicly available at https://www.youtube.com/playlist?list=PL9UURLQttNX2Lfs0EoOlIa4ns0bhra8_Y.          Last Modified: 06/21/2019       Submitted by: Joseph Pater]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
