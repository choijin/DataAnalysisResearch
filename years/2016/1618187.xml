<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Small: Eliciting Accurate and Useful Information from Heterogeneous Agents</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will design and study systems for eliciting and aggregating information and expertise when it is distributed across many heterogeneous agents.   This addresses a central challenge in the field of crowdsourcing, and these solutions can be directly applied to typical crowdsourcing problems including peer grading, and labeling spam or other non-compliant material.  Additionally, these systems should prove useful in gathering and aggregating information in basic scientific research, reputation systems, and many decision-making contexts including purchasing, product development, pricing, etc.  Because privacy is an instance of a participant cost, the ideas developed in this research will readily import back to the field of privacy as well.&lt;br/&gt; &lt;br/&gt;While the field of information elicitation promises many rich applications, challenges in the area of mechanism design must be overcome to fulfill its promise.  The current state of the art is sufficient to run mechanisms in simple settings, but very little effort has gone into studying the difficulty of having heterogeneous agents with various levels and/or areas of expertise.  Particularly problematic are what we term divisive problems where naïve agents err in a systematic and non-random way that can be predicted by more expert agents.  In such a setting, the expert agent may answer incorrectly, in anticipation of being scored against naïve agents.   Such occurrences are extremely problematic because they render the above mechanisms incapable of soliciting information from experts, exactly those whom are most important to reach.&lt;br/&gt; &lt;br/&gt;This project will develop the theory necessary to reason about information elicitation mechanisms with heterogeneous agents, tackle key challenges, and devise innovative solutions to overcome these challenges.  This project will break through the most daunting barriers by creating new mechanisms and accompanying theoretical analysis and empirical tests to show that they achieve the stated goals.  The PI will build upon the rich and emerging literature in information elicitation without verification using cutting-edge tools and insights from various fields including privacy, mechanism design, game theory, proper scoring rules, information theory, probability, and learning theory.  If successful, this proposal will transform the field of information elicitation by creating robust mechanisms having provable guarantees that work with heterogeneous agents.</AbstractNarration>
<MinAmdLetterDate>08/31/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1618187</AwardID>
<Investigator>
<FirstName>Grant</FirstName>
<LastName>Schoenebeck</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Grant Schoenebeck</PI_FULL_NAME>
<EmailAddress>schoeneb@umich.edu</EmailAddress>
<PI_PHON>7347645876</PI_PHON>
<NSF_ID>000649423</NSF_ID>
<StartDate>08/31/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481092121</ZipCode>
<StreetAddress><![CDATA[2260 Hayward, Beyster Bldg.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7932</Code>
<Text>COMPUT GAME THEORY &amp; ECON</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project has transformed the field of information elicitation by solidifying the goals for information elicitation mechanisms, creating a new theoretical lens for the field of information elicitation (along with new tools), and designed new mechanisms that provably achieve these goals.&nbsp;</p> <p>Traditionally, theoretical computer science studies how, given inputs, to efficiently compute the output of a function. However, often the inputs are as hard to obtain as the computation is to execute. Thus it is important to design tools to elicit truthful, but unverifiable, information. Examples would be crowdsourcing tasks (even with no ground truth), surveys, on-line ratings, recommendations, and peer-grading.&nbsp; For example, without some incentive, peer-graders may not mark other students' work thoughtfully and could always give full marks. However, incentives must be carefully designed.&nbsp; If students are rewarded only for agreement, they may not remove points for subtle errors they expect other students might miss.</p> <p>Therefore, this project argues, mechanisms should maximize an agent's expected payments when they report truthfully---even if they believe that most other agents will disagree and their answers cannot be directly verified. &nbsp;Formally, we want mechanisms that are&nbsp;<strong>focal</strong>: truth-telling is a strict equilibrium which rewards agents more than other equilibria. In focal mechanisms, it is natural for agents to coordinate on the truth-telling equilibrium because it pays the most.</p> <p>&nbsp;This project discovered that many information elicitation mechanisms can be understood as paying agents the ``mutual information" between their report and that of some other agent's. This observation provides a unified framework for the field, simplifies several existing and foundational results, as well as provides new results like the ones below.&nbsp; A key ingredient is the variational representation of mutual information, which uses Fenchel duality to transform mutual information into an optimization problem.&nbsp; This allows the measurement of mutual information, and thus the design of mechanisms, to be reduced to well-studied machine learning optimization problems.&nbsp;</p> <p>This project also generalized the definition of mutual information and showed two distinct types: f-mutual information and f-Bregman mutual information. These two types have different properties which are useful in different settings. The well-known Shannon mutual information is (uniquely) a special case of both types.</p> <p>For information elicitation mechanisms, this project creates new mechanisms in both the multi-task and single-task setting.&nbsp; In the multi-question setting, agents are given several similar questions (e.g. peer grading different answers for the same problem). Using f-mutual information, this project gave the first focal mechanism that works for non-binary questions in the multi-question setting and even creates natural mechanisms for the continuous setting. &nbsp;In the single-task settings (each agent is only asked about one question), this project showed the first focal mechanism requiring only finitely many agents, 6.&nbsp; Moreover, it extended these results to the case where agents have continuous signals (for a more restricted setting).</p> <p>&nbsp;Additionally, this project also leverages these new techniques to make substantial progress on one of the most important problems in the field: how to incentivize agents to reveal ``expensive" information without the ability to explicitly verify their answers. Previous techniques allowed agents to coordinate on ``cheap" signals (for example, reporting the length of an essay instead of the quality of the essay). This project shows how to use conditional mutual information to condition out the cheap signals and only reward agents for expensive information.</p> <p>&nbsp;Finally, this project also applies techniques from this field to provide rigorous theoretical justification for &ldquo;co-training&rdquo; --- a machine learning technique to combine two input streams, both of which contain information about some value to be predicted.&nbsp; A concrete application of this is the &ldquo;noisy-label&rdquo; problem where subsequent work shows empirical improvement to machine learning algorithms trained on data that contains labeling errors.</p> <p>&nbsp;<br /> <br /></p> <p>&nbsp;</p><br> <p>            Last Modified: 02/24/2021<br>      Modified by: Grant&nbsp;Schoenebeck</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project has transformed the field of information elicitation by solidifying the goals for information elicitation mechanisms, creating a new theoretical lens for the field of information elicitation (along with new tools), and designed new mechanisms that provably achieve these goals.   Traditionally, theoretical computer science studies how, given inputs, to efficiently compute the output of a function. However, often the inputs are as hard to obtain as the computation is to execute. Thus it is important to design tools to elicit truthful, but unverifiable, information. Examples would be crowdsourcing tasks (even with no ground truth), surveys, on-line ratings, recommendations, and peer-grading.  For example, without some incentive, peer-graders may not mark other students' work thoughtfully and could always give full marks. However, incentives must be carefully designed.  If students are rewarded only for agreement, they may not remove points for subtle errors they expect other students might miss.  Therefore, this project argues, mechanisms should maximize an agent's expected payments when they report truthfully---even if they believe that most other agents will disagree and their answers cannot be directly verified.  Formally, we want mechanisms that are focal: truth-telling is a strict equilibrium which rewards agents more than other equilibria. In focal mechanisms, it is natural for agents to coordinate on the truth-telling equilibrium because it pays the most.   This project discovered that many information elicitation mechanisms can be understood as paying agents the ``mutual information" between their report and that of some other agent's. This observation provides a unified framework for the field, simplifies several existing and foundational results, as well as provides new results like the ones below.  A key ingredient is the variational representation of mutual information, which uses Fenchel duality to transform mutual information into an optimization problem.  This allows the measurement of mutual information, and thus the design of mechanisms, to be reduced to well-studied machine learning optimization problems.   This project also generalized the definition of mutual information and showed two distinct types: f-mutual information and f-Bregman mutual information. These two types have different properties which are useful in different settings. The well-known Shannon mutual information is (uniquely) a special case of both types.  For information elicitation mechanisms, this project creates new mechanisms in both the multi-task and single-task setting.  In the multi-question setting, agents are given several similar questions (e.g. peer grading different answers for the same problem). Using f-mutual information, this project gave the first focal mechanism that works for non-binary questions in the multi-question setting and even creates natural mechanisms for the continuous setting.  In the single-task settings (each agent is only asked about one question), this project showed the first focal mechanism requiring only finitely many agents, 6.  Moreover, it extended these results to the case where agents have continuous signals (for a more restricted setting).   Additionally, this project also leverages these new techniques to make substantial progress on one of the most important problems in the field: how to incentivize agents to reveal ``expensive" information without the ability to explicitly verify their answers. Previous techniques allowed agents to coordinate on ``cheap" signals (for example, reporting the length of an essay instead of the quality of the essay). This project shows how to use conditional mutual information to condition out the cheap signals and only reward agents for expensive information.   Finally, this project also applies techniques from this field to provide rigorous theoretical justification for "co-training" --- a machine learning technique to combine two input streams, both of which contain information about some value to be predicted.  A concrete application of this is the "noisy-label" problem where subsequent work shows empirical improvement to machine learning algorithms trained on data that contains labeling errors.                Last Modified: 02/24/2021       Submitted by: Grant Schoenebeck]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
