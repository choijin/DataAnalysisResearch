<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Combinatorial Optimization, Spin Models, and the Geometry of Sparse Random Graphs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>599999.00</AwardTotalIntnAmount>
<AwardAmount>599999</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tomek Bartoszynski</SignBlockName>
<PO_EMAI>tbartosz@nsf.gov</PO_EMAI>
<PO_PHON>7032924885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Networks and graphs are ubiquitous mathematical models to describe important systems (social networks, transportation networks, and biological systems, among others). A network is comprised of a certain number of objects (normally referred to as 'nodes' or 'vertices') connected by links of various importance ('edges' and their 'weights'). Analyzing network data is notoriously challenging. An important task is to group the vertices into subgroups such that each subgroup is highly connected, and any two subgroups have only loose interconnections. Even if one is only trying to identify merely two subgroups (known as the min-bisection problem), no efficient algorithm is known to partition the nodes of large graphs in general. The situation changes when one considers that the graphs might have a random structure. Indeed, for many reasonable probabilistic models on graphs, there appear to be efficient algorithms to solve the min-bisection problem. This project will develop our fundamental understanding of these probabilistic models and will study efficient algorithms to treat them.&lt;br/&gt;&lt;br/&gt;The project focuses on various models of sparse random graphs, the simplest being the Erdos-Renyi (independent edges) random graph, with bounded average degree. Many statistical inference tasks can be addressed by suitably defined combinatorial optimization problems. For instance, the min-bisection problem requires to find a balanced partition of the vertex set that minimizes the number of edges across the partition. These optimization problems are associated to certain Gibbs measures on the underlying graph, from which the optimizers are recovered as ground states. Statistical physicists conjectured that these Gibbs measures are asymptotically equivalent (for random graphs) to Gibbs measures of suitably defined spin glass models. This project aims at establishing this connection on a firm basis and exploiting it to study the structure of large random graphs. It has also recently been suggested that semidefinite-programming relaxations for the same problems can be studied through other Gibbs measures (with vector spins). Studying these spin models will improve our understanding of efficient algorithms for solving these tasks.</AbstractNarration>
<MinAmdLetterDate>06/23/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1613091</AwardID>
<Investigator>
<FirstName>Amir</FirstName>
<LastName>Dembo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amir Dembo</PI_FULL_NAME>
<EmailAddress>amir@stat.stanford.edu</EmailAddress>
<PI_PHON>6507252237</PI_PHON>
<NSF_ID>000192524</NSF_ID>
<StartDate>06/23/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andrea</FirstName>
<LastName>Montanari</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrea Montanari</PI_FULL_NAME>
<EmailAddress>montanari@stanford.edu</EmailAddress>
<PI_PHON>6507232300</PI_PHON>
<NSF_ID>000107366</NSF_ID>
<StartDate>06/23/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>943054000</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1263</Code>
<Text>PROBABILITY</Text>
</ProgramElement>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~118683</FUND_OBLG>
<FUND_OBLG>2017~118477</FUND_OBLG>
<FUND_OBLG>2018~115437</FUND_OBLG>
<FUND_OBLG>2019~116052</FUND_OBLG>
<FUND_OBLG>2020~131350</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><pre><pre><span>Utilizing stochastic dynamics and Gibbs measures we made progress in the </span><span>rigorous study of probabilistic models </span></pre> <pre><span>for large systems of discrete variables interacting according to an ensemble of (randomly chosen) </span><span>sparse graphs.</span><span> </span></pre> <pre><span>We focused on the mathematics behind the geometry </span><span>of such </span><span>models at zero temperature, and the </span></pre> <pre><span>structure of the solution spaces for related combinatorial optimization and constraint satisfaction problems.</span></pre> <pre><pre><span><br /></span></pre> <pre><span>Beyond the immediate resolution of challenging problems in probability theory, </span><span>the new mathematical </span></pre> <pre><span>techniques we developed may also impact graph theory and statistical physics. Among the applications of </span></pre> <pre><span>our work are better understanding of large constraint satisfaction networks and new algorithms </span><span>for solving </span></pre> <pre><span>certain combinatorial </span><span>optimization problems which are </span><span>relevant to </span><span>statistical inference (for example, in </span></pre> <pre><span>aiming to </span><span>detect relations among a set of objects).</span></pre> </pre> <pre><pre><br /></pre> <pre><span>Specifically, we considered combinatorial optimization problems on large random </span><span>graphs where each vertex is </span></pre> <pre><span>associated with a decision variable, and the </span><span>objective function decomposes according to the underlying graph. </span></pre> <pre><span>Prototypical examples such as graph max-cut and min-bisection, can further </span><span>be written as quadratic optimization </span></pre> <pre><span>problems with binary decision variables. We made progress in characterizing the asymptotic value of these problems,</span></pre> <pre><span>investigating their connection to convex relaxations and local algorithms for solving them.</span></pre> <pre><span>In addition, we made progress on the asymptotic of sparse random graphs and their </span><span>adjacency matrices,</span></pre> <pre><span>in understanding the energy landscape and dynamical </span><span>properties of spiked disorder tensor models and </span></pre> <pre><span>two-layered neural networks</span><span>.</span></pre> </pre> <pre><br /></pre> <pre><span>While doing so we also trained several talented graduate and post-graduate </span></pre> <pre><span>students in discrete probability and information theory.</span></pre> <br /></pre><br> <p>            Last Modified: 08/14/2021<br>      Modified by: Amir&nbsp;Dembo</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Utilizing stochastic dynamics and Gibbs measures we made progress in the rigorous study of probabilistic models  for large systems of discrete variables interacting according to an ensemble of (randomly chosen) sparse graphs.  We focused on the mathematics behind the geometry of such models at zero temperature, and the  structure of the solution spaces for related combinatorial optimization and constraint satisfaction problems.   Beyond the immediate resolution of challenging problems in probability theory, the new mathematical  techniques we developed may also impact graph theory and statistical physics. Among the applications of  our work are better understanding of large constraint satisfaction networks and new algorithms for solving  certain combinatorial optimization problems which are relevant to statistical inference (for example, in  aiming to detect relations among a set of objects).    Specifically, we considered combinatorial optimization problems on large random graphs where each vertex is  associated with a decision variable, and the objective function decomposes according to the underlying graph.  Prototypical examples such as graph max-cut and min-bisection, can further be written as quadratic optimization  problems with binary decision variables. We made progress in characterizing the asymptotic value of these problems, investigating their connection to convex relaxations and local algorithms for solving them. In addition, we made progress on the asymptotic of sparse random graphs and their adjacency matrices, in understanding the energy landscape and dynamical properties of spiked disorder tensor models and  two-layered neural networks.    While doing so we also trained several talented graduate and post-graduate  students in discrete probability and information theory.         Last Modified: 08/14/2021       Submitted by: Amir Dembo]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
