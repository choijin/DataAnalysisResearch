<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Understanding Prosody and Tone Interactions through Documentation of Two Endangered Languages</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/26/2015</AwardEffectiveDate>
<AwardExpirationDate>10/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>248585.00</AwardTotalIntnAmount>
<AwardAmount>287601</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For accurate automated translation of text-to-spoken-word or spoken-word-to-text, it is necessary to understand the prosodic patterning of speech since prosody, i.e. stress, rhythm, and pauses between phrases, is central in conveying meaning and structuring discourse.  In addition, many languages use tone to change the meaning of words but little is known about how prosodic features interact with tone.  Since tone and prosody are conveyed by using some of the same acoustic dimensions (pitch, duration, voice quality), one must know how these two systems interact for automatic speech recognition and translation.&lt;br/&gt;&lt;br/&gt;To investigate and test hypotheses about the relationship of tone and prosody, Christian Di Canio, along with an interdisciplinary team, will create a database of 30 hours of transcribed narratives from Itunyoso Trique and expand an existing similar database in Yoloxóchitl Mixtec, both both Mixtecan languages from eastern central Mexico.  These transcribed narratives will then be parsed into smaller units applying a  'forced alignment' tool used in automatic speech recognition.   Important results from the project will include the testing and improvement of the forced alignment tool; new corpora and expanded dictionaries for and Yoloxóchitl Mixtec; and an analysis of tone and prosody interactions in these two languages.  The resulting prosodically segmented and tagged corpora will be a first of its kind for an endangered language that will be of use to the speaker-community and the broader scientific community.&lt;br/&gt;&lt;br/&gt;This project is partially supported by funds from the Robust Intelligence program.</AbstractNarration>
<MinAmdLetterDate>11/19/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/28/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1603323</AwardID>
<Investigator>
<FirstName>Christian</FirstName>
<LastName>DiCanio</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christian T DiCanio</PI_FULL_NAME>
<EmailAddress>dicanio@haskins.yale.edu</EmailAddress>
<PI_PHON>2014499109</PI_PHON>
<NSF_ID>000625009</NSF_ID>
<StartDate>11/19/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Buffalo</Name>
<CityName>Buffalo</CityName>
<ZipCode>142282567</ZipCode>
<PhoneNumber>7166452634</PhoneNumber>
<StreetAddress>520 Lee Entrance</StreetAddress>
<StreetAddress2><![CDATA[Suite 211]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY26</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>038633251</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Buffalo]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>142607016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY26</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramElement>
<Code>7719</Code>
<Text>DEL</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7484</Code>
<Text>IIS SPECIAL PROJECTS</Text>
</ProgramReference>
<ProgramReference>
<Code>7719</Code>
<Text>DEL</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~161188</FUND_OBLG>
<FUND_OBLG>2015~87396</FUND_OBLG>
<FUND_OBLG>2017~39016</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Speakers of human languages often change their pitch or lengthen words to indicate things like emphasis, attitude, or emotions in speech (<em>intonation</em>). Yet, for about 50-60% of the world's languages, pitch also distinguishes word meaning. These are called <em>tonal</em> languages. For instance, in Yolox&oacute;chitl Mixtec (spoken in Mexico), the word /nama/ pronounced with a medium level pitch means '<em>to change' </em>but the word /nama/ pronounced with a high level pitch means <em>'to be piling rocks.'</em> There are many well-known tonal languages, like Mandarin Chinese (spoken by over a billion people), Vietnamese, Thai, Yoruba, and Swedish, and several thousand lesser well-known tonal languages that have not been studied as extensively by linguists and speech scientists. Yet, an interesting and open linguistic question is how speakers of languages like these are able to convey things like emphasis, attitude, and emotion since they are already using pitch for distinguishing word meaning. Speakers of English can distinguish questions from statements using pitch alone, e.g. "<em>Marcus bought roses." </em>vs. <em>"Marcus bought roses?" </em>but just<em> </em>how do speakers of tonal languages do the same thing? And might the answer to this question reveal something fundamental about the nature of all human language? These were the central scientific questions which motivated this grant research.</p> <p>Within this grant, a team focused on studying two lesser-known languages of Mexico - Itunyoso Triqui and Yolox&oacute;chitl Mixtec. These languages, both American Indian, are remarkable for having very complex tones. In each of them, there are nine distinct tonal patterns that distinguish word and grammatical meaning. A team consisting of linguists, students, and speakers of these languages worked together to investigate the scientific questions. Applying close experimental methods in phonetics, we found that, for Yolox?chitl Mixtec, pitch can <em>still</em> be used to mark words under emphasis, but principally for words containing the highest tones or the lowest tones in the language. Speakers of this language expand their pitch range when they need to emphasize particular words. In another study, we examined how speakers of this language might control their pitch differently across the span of a sentence. Typically, speakers of non-tonal languages like English will lower pitch gradually in a statement but raise pitch towards the end of the sentence in a question. Examining this question with Yolox?chitl Mixtec speakers, we found that they do the same thing except certain tones (the highest ones) are impervious to pitch lowering, but the lower tones lower more dramatically.</p> <p>Each of these phonetic studies were replicated with speakers of Itunyoso Triqui, a distant and distinct language from that of Yolox&oacute;chitl Mixtec. Unlike the results from Yolox&oacute;chitl Mixtec, we found that speakers of Triqui do not use pitch at all in emphasizing words in sentences. Moreover, we found that Triqui speakers do not lower pitch across sentences. This finding was a surprise since linguists have assumed that pitch lowering is a universal pattern in speech. The findings from work on this language suggest that this assumption is false and, moreover, that there are some languages that simply lack intonation altogether. These are novel findings in relation to how speech is produced by humans.</p> <p>In addition to these scientific questions, the research on this grant advanced methods in acoustic phonetic analysis of speech of this type. Novel computational methods for automatically segmenting and transcribing speech were applied prior to the analysis of the acoustic signal. A number of methods for collecting this type of careful data were applied throughout the experiments, each of which took place abroad in Mexico. The development of these techniques has spurred interest in the use of computational methods more generally to research on endangered and minority languages. The idea here is that linguists and others can use these tools to more quickly document and describe these languages.</p> <p>The final goal of the grant was to develop a spoken language corpus (a collection of recordings) for one of the languages on the project - Itunyoso Triqui. This involved the careful recording of dozens of speakers of the language over the course of several years. Approximately 30 hours of recordings (over 200 individual recordings) on a range of culturally diverse topics were collected. Several speaker consultants were trained in native literacy and transcription methods during the project and the team of linguists and speaker-consultants transcribed and translated the corpus of recordings. This material is culturally-relevant for the community and the world since it is an archived record of an endangered language. Simultaneously, this corpus is available for other researchers and scientists wishing to investigate Triqui speech acoustics. The final two years of the grant focused on Triqui literacy development via community workshops in the San Mart?n Itunyoso community in Oaxaca, Mexico. These workshops both promoted the language and brought the texts back to the local community.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/25/2020<br>      Modified by: Christian&nbsp;T&nbsp;Dicanio</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1603323/1603323_10317442_1603639626082_Fieldwork_2018_literacy_workshop--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1603323/1603323_10317442_1603639626082_Fieldwork_2018_literacy_workshop--rgov-800width.jpg" title="Triqui literacy workshop in 2018"><img src="/por/images/Reports/POR/2020/1603323/1603323_10317442_1603639626082_Fieldwork_2018_literacy_workshop--rgov-66x44.jpg" alt="Triqui literacy workshop in 2018"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The PI, Christian DiCanio (far left) and his consultant Basileo Mart�nez Cruz (far right) alongside students in the Itunyoso Triqui community during a native literacy workshop in 2018.</div> <div class="imageCredit">Christian DiCanio</div> <div class="imageSubmitted">Christian&nbsp;T&nbsp;Dicanio</div> <div class="imageTitle">Triqui literacy workshop in 2018</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Speakers of human languages often change their pitch or lengthen words to indicate things like emphasis, attitude, or emotions in speech (intonation). Yet, for about 50-60% of the world's languages, pitch also distinguishes word meaning. These are called tonal languages. For instance, in Yolox&oacute;chitl Mixtec (spoken in Mexico), the word /nama/ pronounced with a medium level pitch means 'to change' but the word /nama/ pronounced with a high level pitch means 'to be piling rocks.' There are many well-known tonal languages, like Mandarin Chinese (spoken by over a billion people), Vietnamese, Thai, Yoruba, and Swedish, and several thousand lesser well-known tonal languages that have not been studied as extensively by linguists and speech scientists. Yet, an interesting and open linguistic question is how speakers of languages like these are able to convey things like emphasis, attitude, and emotion since they are already using pitch for distinguishing word meaning. Speakers of English can distinguish questions from statements using pitch alone, e.g. "Marcus bought roses." vs. "Marcus bought roses?" but just how do speakers of tonal languages do the same thing? And might the answer to this question reveal something fundamental about the nature of all human language? These were the central scientific questions which motivated this grant research.  Within this grant, a team focused on studying two lesser-known languages of Mexico - Itunyoso Triqui and Yolox&oacute;chitl Mixtec. These languages, both American Indian, are remarkable for having very complex tones. In each of them, there are nine distinct tonal patterns that distinguish word and grammatical meaning. A team consisting of linguists, students, and speakers of these languages worked together to investigate the scientific questions. Applying close experimental methods in phonetics, we found that, for Yolox?chitl Mixtec, pitch can still be used to mark words under emphasis, but principally for words containing the highest tones or the lowest tones in the language. Speakers of this language expand their pitch range when they need to emphasize particular words. In another study, we examined how speakers of this language might control their pitch differently across the span of a sentence. Typically, speakers of non-tonal languages like English will lower pitch gradually in a statement but raise pitch towards the end of the sentence in a question. Examining this question with Yolox?chitl Mixtec speakers, we found that they do the same thing except certain tones (the highest ones) are impervious to pitch lowering, but the lower tones lower more dramatically.  Each of these phonetic studies were replicated with speakers of Itunyoso Triqui, a distant and distinct language from that of Yolox&oacute;chitl Mixtec. Unlike the results from Yolox&oacute;chitl Mixtec, we found that speakers of Triqui do not use pitch at all in emphasizing words in sentences. Moreover, we found that Triqui speakers do not lower pitch across sentences. This finding was a surprise since linguists have assumed that pitch lowering is a universal pattern in speech. The findings from work on this language suggest that this assumption is false and, moreover, that there are some languages that simply lack intonation altogether. These are novel findings in relation to how speech is produced by humans.  In addition to these scientific questions, the research on this grant advanced methods in acoustic phonetic analysis of speech of this type. Novel computational methods for automatically segmenting and transcribing speech were applied prior to the analysis of the acoustic signal. A number of methods for collecting this type of careful data were applied throughout the experiments, each of which took place abroad in Mexico. The development of these techniques has spurred interest in the use of computational methods more generally to research on endangered and minority languages. The idea here is that linguists and others can use these tools to more quickly document and describe these languages.  The final goal of the grant was to develop a spoken language corpus (a collection of recordings) for one of the languages on the project - Itunyoso Triqui. This involved the careful recording of dozens of speakers of the language over the course of several years. Approximately 30 hours of recordings (over 200 individual recordings) on a range of culturally diverse topics were collected. Several speaker consultants were trained in native literacy and transcription methods during the project and the team of linguists and speaker-consultants transcribed and translated the corpus of recordings. This material is culturally-relevant for the community and the world since it is an archived record of an endangered language. Simultaneously, this corpus is available for other researchers and scientists wishing to investigate Triqui speech acoustics. The final two years of the grant focused on Triqui literacy development via community workshops in the San Mart?n Itunyoso community in Oaxaca, Mexico. These workshops both promoted the language and brought the texts back to the local community.          Last Modified: 10/25/2020       Submitted by: Christian T Dicanio]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
