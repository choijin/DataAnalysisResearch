<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Human-Aware Navigation in Populated Indoor Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>259396.00</AwardTotalIntnAmount>
<AwardAmount>259396</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Current autonomous mobile robots are able to navigate accurately through sparsely populated areas without bumping into things.  However, they have more trouble in situations that commonly arise in public buildings, such as when passing people in narrow hallways, when moving through open, populated spaces, or when crossing a crowd of people exiting an auditorium.  Thus, for autonomous robots to reach their full potential, in terms of positive impact on society, they will need to improve their navigational abilities to be more "human-aware."  That is, they will explicitly need to take account the characteristics of the people with whom they need to interact in public spaces.  With this motivation in mind, the goal of this research is to understand how best to enable mobile robots to navigate smoothly, robustly, and safely through human-populated indoor environments in pursuit of high-level goals, with varying levels of guidance from a human operator in a fully human-aware manner.&lt;br/&gt;&lt;br/&gt;This project focuses on two complementary, high-risk, and potentially foundational research thrusts as being crucial to laying the groundwork for eventual development of a robust, human-aware navigation system.  First, it aims to develop formal specifications for safe robot-operator-pedestrian interactions, using probabilistic temporal logics.  Second, it aims to develop methods for generating learned models of operator preferences that can influence the robot's choice of paths with regards to, for example, trajectory smoothness, order of subgoal achievement, task completion time, travel speed, and proximity of trajectory to pedestrians and fixed objects, learning user preferences and determining how to combine them with task-achieving reward functions.</AbstractNarration>
<MinAmdLetterDate>08/18/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1651089</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Stone</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter H Stone</PI_FULL_NAME>
<EmailAddress>pstone@cs.utexas.edu</EmailAddress>
<PI_PHON>5124716424</PI_PHON>
<NSF_ID>000156504</NSF_ID>
<StartDate>08/18/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Luis</FirstName>
<LastName>Sentis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Luis Sentis</PI_FULL_NAME>
<EmailAddress>lsentis@austin.utexas.edu</EmailAddress>
<PI_PHON>5124716424</PI_PHON>
<NSF_ID>000570648</NSF_ID>
<StartDate>08/18/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ufuk</FirstName>
<LastName>Topcu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ufuk Topcu</PI_FULL_NAME>
<EmailAddress>utopcu@utexas.edu</EmailAddress>
<PI_PHON>5124716424</PI_PHON>
<NSF_ID>000690245</NSF_ID>
<StartDate>08/18/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121757</ZipCode>
<StreetAddress><![CDATA[2317 Speedway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~259396</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to enable autonomous robots to navigate <br />smoothly and confidently in environments where people are present and <br />going about their own business.&nbsp; Towards this end the project focused <br />on two complementary, high-risk, and potentially foundational research <br />thrusts as being crucial to laying the groundwork for eventual <br />development of a robust human-aware navigation system on mobile <br />robots.&nbsp; First, it aims to develop formal specifications for safe <br />robot-operator-pedestrian interactions.&nbsp; Second, it aims to develop <br />methods for generating learned models of operator preferences that can <br />influence the robot's choice of paths with regards to, for example, <br />trajectory smoothness, order of subgoal achievement, task completion <br />time, travel speed, and proximity of trajectory to pedestrians and <br />fixed objects. <br />&nbsp;<br />We have investigated strategies for intelligent collision management <br />in dynamic environments.&nbsp; We have investigated methods for evaluating <br />whether pedestrians are aware the robot is nearby, and considered <br />how that influnces a robot's best navigation plan.&nbsp; <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br />Regarding pedestrian awareness of robots, we introduced an awareness <br />state based on pedestrian gaze detection. We calculate the time <br />duration and frequency that a person looks at a robot. With this <br />information we have devised models of sensor-based awareness and used <br />them for effective and safe mobile navigation. <br />&nbsp;<br />Our results offer (i) better scalability compared to the competing <br />methods in the literature in planning in partially-observable Markov <br />decision processes through reasoning at multiple levels of <br />abstractions (ii) better generalization in inverse reinforcement <br />learning by directly incorporating side information encoded in <br />temporal logic and (iii) better robustness to pedestrian modeling <br />uncertainty in scenarios where robots and people cross paths.</p><br> <p>            Last Modified: 12/30/2018<br>      Modified by: Peter&nbsp;H&nbsp;Stone</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to enable autonomous robots to navigate  smoothly and confidently in environments where people are present and  going about their own business.  Towards this end the project focused  on two complementary, high-risk, and potentially foundational research  thrusts as being crucial to laying the groundwork for eventual  development of a robust human-aware navigation system on mobile  robots.  First, it aims to develop formal specifications for safe  robot-operator-pedestrian interactions.  Second, it aims to develop  methods for generating learned models of operator preferences that can  influence the robot's choice of paths with regards to, for example,  trajectory smoothness, order of subgoal achievement, task completion  time, travel speed, and proximity of trajectory to pedestrians and  fixed objects.    We have investigated strategies for intelligent collision management  in dynamic environments.  We have investigated methods for evaluating  whether pedestrians are aware the robot is nearby, and considered  how that influnces a robot's best navigation plan.          Regarding pedestrian awareness of robots, we introduced an awareness  state based on pedestrian gaze detection. We calculate the time  duration and frequency that a person looks at a robot. With this  information we have devised models of sensor-based awareness and used  them for effective and safe mobile navigation.    Our results offer (i) better scalability compared to the competing  methods in the literature in planning in partially-observable Markov  decision processes through reasoning at multiple levels of  abstractions (ii) better generalization in inverse reinforcement  learning by directly incorporating side information encoded in  temporal logic and (iii) better robustness to pedestrian modeling  uncertainty in scenarios where robots and people cross paths.       Last Modified: 12/30/2018       Submitted by: Peter H Stone]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
