<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CHS: Customized Navigation for Older Adults with Vision Loss</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2017</AwardEffectiveDate>
<AwardExpirationDate>02/29/2020</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For a person with low vision, interacting with a smartphone to access information that is critical to their independence and safety, while possible, is slow and tedious.  The ultimate goal of this research is to remedy that deficiency by creating technology that enables these users to access information quickly and easily, both at home and on the go.  As a concrete and challenging first step, the work will focus on systems to enable seniors with low vision to plan and execute urban navigation tasks.  If successful, members of this large and growing target community will be empowered to perform a key activity of daily living with more confidence and independence.  Project outcomes will advance the state of the art in accessibility research more broadly, by laying the foundation for a new paradigm of accessible interaction via low-cost mainstream devices.&lt;br/&gt;&lt;br/&gt;To these ends, the research will involve a number of phases: (1) documenting the navigation and mobility patterns and challenges facing members of the target user community; (2) the design and implementation of a desktop system that produces "optimal" routes based on feature accessibility along a given route; (3) the design and implementation of a smartphone navigation application that will provide accessible guidance including accessible maps; and (4) evaluation of the smartphone application in the field with target users.   Achieving these goals will require an interdisciplinary effort that draws on expertise in a diverse set of fields, including accessibility, interaction techniques, information processing, and machine learning.</AbstractNarration>
<MinAmdLetterDate>03/01/2017</MinAmdLetterDate>
<MaxAmdLetterDate>03/01/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1657315</AwardID>
<Investigator>
<FirstName>Shiri</FirstName>
<LastName>Azenkot</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shiri Azenkot</PI_FULL_NAME>
<EmailAddress>shiri.azenkot@cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000690878</NSF_ID>
<StartDate>03/01/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell Tech]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100115201</ZipCode>
<StreetAddress><![CDATA[111 8th Ave #302]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~175000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p id="docs-internal-guid-ceaaa0bf-7fff-284c-8c2f-60608169e317" style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">While extensive prior research has investigated navigation for blind people and people with other disabilities, the navigation needs of older adults with low vision have not yet been systematically addressed. As the number of older adults with vision loss increases, this research will impact millions of people. The navigation assistance systems developed in this study will enable older adults to navigate new spaces, climb stairs, and identify text and images more easily, safely, and confidently.&nbsp;</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">In this multi-step research project, we investigated the navigation and mobility needs of older adults with vision loss, created technologies that detect obstacles and highlight safe routes, designed usable interfaces for these systems, and evaluated these prototypes with the target population. In a first study, we interviewed and observed participants with low vision as they navigated indoor and outdoor spaces. This study showed that stairs and surface level changes (e.g., curbs and sidewalk cracks) are a source of difficulty for many participants. In most cases, these were more difficult for participants to navigate than other features in the environment, such as obstacles or street intersections. Unlike blind people, our participants with low vision used their vision extensively when navigating, sometimes using a cane as a supplement. While they preferred to use their vision, they still felt unsafe and insecure.</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">In a series of follow-up studies, we designed technologies that enable users to more easily navigate stairs and wayfind in unfamiliar indoor spaces, and created interfaces that make these systems easy to use. We leveraged commercially available augmented and virtual reality systems to enhance a user&rsquo;s environment directly. To support navigation, we designed virtual contrast stripes to augment the edges of stairs to facilitate stair navigation, and designed a virtual path and spatial audio guidance instructions to support wayfinding. In addition, we designed a vision enhancement system that incorporated customizable magnification, contrast enhancement, and other basic video refinement algorithms to support general near and distance viewing tasks. We evaluated our new interfaces for each task with target users, showing that participants achieved better performance with our designs than with baseline. Overall, our studies highlighted the importance of allowing users to combine visual and audio feedback and customize interfaces to fit their preferences and particular vision needs.</span></p><br> <p>            Last Modified: 04/01/2020<br>      Modified by: Shiri&nbsp;Azenkot</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663821276_stairs-edit--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663821276_stairs-edit--rgov-800width.jpg" title="AR guidance for stair navigation"><img src="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663821276_stairs-edit--rgov-66x44.jpg" alt="AR guidance for stair navigation"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Visualizations that help users with low vision navigate stairs more safely. Left: projection-based AR highlighting stair edges. Right: Smartglasses visualization highlighting the stair railing.</div> <div class="imageCredit">The research team</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Shiri&nbsp;Azenkot</div> <div class="imageTitle">AR guidance for stair navigation</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663677120_wayfinding--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663677120_wayfinding--rgov-800width.jpg" title="Wayfinding Guidance on Smartglasses"><img src="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663677120_wayfinding--rgov-66x44.jpg" alt="Wayfinding Guidance on Smartglasses"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Different types of wayfinding guidance implemented on commercially available smartglasses. From left to right: guidance with a path, distance markers, and a destination star; a destination star beside a path; and a destination indicator.</div> <div class="imageCredit">The research team</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Shiri&nbsp;Azenkot</div> <div class="imageTitle">Wayfinding Guidance on Smartglasses</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663560041_stairproblems--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663560041_stairproblems--rgov-800width.jpg" title="Navigation Difficulties with Stairs"><img src="/por/images/Reports/POR/2020/1657315/1657315_10475254_1585663560041_stairproblems--rgov-66x44.jpg" alt="Navigation Difficulties with Stairs"></a> <div class="imageCaptionContainer"> <div class="imageCaption">People navigating stairs often rely on luminance contrast in order to navigate safely. This image shows shadows cast by stair risers and railings, which make navigation difficult</div> <div class="imageCredit">The research team</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Shiri&nbsp;Azenkot</div> <div class="imageTitle">Navigation Difficulties with Stairs</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[While extensive prior research has investigated navigation for blind people and people with other disabilities, the navigation needs of older adults with low vision have not yet been systematically addressed. As the number of older adults with vision loss increases, this research will impact millions of people. The navigation assistance systems developed in this study will enable older adults to navigate new spaces, climb stairs, and identify text and images more easily, safely, and confidently.     In this multi-step research project, we investigated the navigation and mobility needs of older adults with vision loss, created technologies that detect obstacles and highlight safe routes, designed usable interfaces for these systems, and evaluated these prototypes with the target population. In a first study, we interviewed and observed participants with low vision as they navigated indoor and outdoor spaces. This study showed that stairs and surface level changes (e.g., curbs and sidewalk cracks) are a source of difficulty for many participants. In most cases, these were more difficult for participants to navigate than other features in the environment, such as obstacles or street intersections. Unlike blind people, our participants with low vision used their vision extensively when navigating, sometimes using a cane as a supplement. While they preferred to use their vision, they still felt unsafe and insecure.    In a series of follow-up studies, we designed technologies that enable users to more easily navigate stairs and wayfind in unfamiliar indoor spaces, and created interfaces that make these systems easy to use. We leveraged commercially available augmented and virtual reality systems to enhance a user’s environment directly. To support navigation, we designed virtual contrast stripes to augment the edges of stairs to facilitate stair navigation, and designed a virtual path and spatial audio guidance instructions to support wayfinding. In addition, we designed a vision enhancement system that incorporated customizable magnification, contrast enhancement, and other basic video refinement algorithms to support general near and distance viewing tasks. We evaluated our new interfaces for each task with target users, showing that participants achieved better performance with our designs than with baseline. Overall, our studies highlighted the importance of allowing users to combine visual and audio feedback and customize interfaces to fit their preferences and particular vision needs.       Last Modified: 04/01/2020       Submitted by: Shiri Azenkot]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
