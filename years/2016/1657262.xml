<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: SCH: Using Digital Images to Connect Eating Environment with Dietary Quality</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2017</AwardEffectiveDate>
<AwardExpirationDate>03/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>174792.00</AwardTotalIntnAmount>
<AwardAmount>174792</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Chronic disease such as heart disease, diabetes, and obesity are known to be strongly linked with diet and may be rooted in the environmental context where they are prevalent. This proposal aims to develop imaging-based techniques to investigate the link between eating environment and dietary quality and satisfaction which are not known. The project will use images from the food environment to address the fundamental question of where, how and when food should be consumed to maximize health and prevent disease. Monitoring the personal dietary environment and determination of environmental patterns related to dietary intake can empower both health care providers and patients to optimize evidence-based decisions. This information can help individuals recognize less healthful behaviors that may be occurring in their lives. Health professionals will also have better information to advise behavioral strategies within the context of the patient's environment. The results may also be used to help guide the development of programs to reduce the prevalence of obesity and diet-related chronic diseases in the US population and advise US dietary policy.&lt;br/&gt;&lt;br/&gt;This highly interdisciplinary investigation explores image processing and computer vision techniques to extract and quantify dietary environmental factors and study their connections with dietary intake. The project plans to build informative models of behavioral health profiles that can take advantage of a large set of observed data, including food images and contextual information that the PI has access to. The team will develop computational methods that leverage the use of contextual information for image-based dietary data which is highly individualized, temporal, and contextualized. The benefits of including contextual information are twofold: it provides a more complete composite of a person's health influencers of dietary behavior; and can improve the accuracy of food recognition and nutrient intake estimation using computer vision techniques. The proposed work will develop 1) new image analysis techniques that leverage contextual cues such as eating time, location type, co-occurrence patterns of objects, personalized learning models from image-based dietary record; 2) novel machine learning and statistical analysis tools for dietary pattern discovery and prediction by exploring relationships among the environmental factors and their association with dietary quality; 3) experimental validation of the proposed methods using existing image-based dietary data.</AbstractNarration>
<MinAmdLetterDate>04/10/2017</MinAmdLetterDate>
<MaxAmdLetterDate>04/10/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1657262</AwardID>
<Investigator>
<FirstName>Fengqing</FirstName>
<LastName>Zhu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fengqing Zhu</PI_FULL_NAME>
<EmailAddress>zhu0@ecn.purdue.edu</EmailAddress>
<PI_PHON>7654941055</PI_PHON>
<NSF_ID>000692128</NSF_ID>
<StartDate>04/10/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072114</ZipCode>
<StreetAddress><![CDATA[155 South Grant Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~174792</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our research focuses on assessing the eating environment using digital images to develop a more complete composite of a person's health in influencers on dietary behavior. Here we summarize the key outcomes and contributions of the project in two examples.</p> <p>We developed a context based image analysis system for dietary assessment where contextual dietary information is defined as data that is not directly produced by the visual appearance of an object in the image but yields information about a user?s diet or can be used for diet planning. We integrate contextual dietary information that a user supplies to the system either explicitly or implicitly to correct potential misclassifications from automatic image analysis. We show that both segmentation-to-classification system with handcrafted features and a region proposal based method with deep features benefit from the contextual data.</p> <p>While many studies have been conducted to understand the influence of dietary habits on health, little is known about the relationship between eating environments and health. Using mobile, image based tools that can better capture dietary information, we propose an image clustering method to automatically extract the eating environments from eating occasion images captured during a community dwelling dietary study. Results show that our method performance significantly better than existing clustering approaches.</p> <p>Our integrated approaches and novel data analytics methods resulted from this project have been deployed in a mobile, imaged based dietary intake data capture tool which has been rigorously evaluated and validated using both controlled feeding and community dwelling approaches. The project also provides new components for piloting innovative course projects in nutrition science and a platform to engage undergraduate students in cross-disciplinary research.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/14/2020<br>      Modified by: Fengqing&nbsp;Zhu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our research focuses on assessing the eating environment using digital images to develop a more complete composite of a person's health in influencers on dietary behavior. Here we summarize the key outcomes and contributions of the project in two examples.  We developed a context based image analysis system for dietary assessment where contextual dietary information is defined as data that is not directly produced by the visual appearance of an object in the image but yields information about a user?s diet or can be used for diet planning. We integrate contextual dietary information that a user supplies to the system either explicitly or implicitly to correct potential misclassifications from automatic image analysis. We show that both segmentation-to-classification system with handcrafted features and a region proposal based method with deep features benefit from the contextual data.  While many studies have been conducted to understand the influence of dietary habits on health, little is known about the relationship between eating environments and health. Using mobile, image based tools that can better capture dietary information, we propose an image clustering method to automatically extract the eating environments from eating occasion images captured during a community dwelling dietary study. Results show that our method performance significantly better than existing clustering approaches.  Our integrated approaches and novel data analytics methods resulted from this project have been deployed in a mobile, imaged based dietary intake data capture tool which has been rigorously evaluated and validated using both controlled feeding and community dwelling approaches. The project also provides new components for piloting innovative course projects in nutrition science and a platform to engage undergraduate students in cross-disciplinary research.                            Last Modified: 10/14/2020       Submitted by: Fengqing Zhu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
