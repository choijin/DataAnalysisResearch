<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Computational Challenges in Machine Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>20000.00</AwardTotalIntnAmount>
<AwardAmount>20000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this workshop is to advance the algorithmic frontier of machine learning. Target areas include Bayesian statistics, in which many of the core algorithmic problems bear similarity to problems that have been studied intensively in the theoretical computer science community; and large-scale optimization, in which a host of interesting challenges arise at the interface of theory and practical deployment.&lt;br/&gt;&lt;br/&gt;The workshop will bring together researchers in algorithms, statistics, mathematics and artificial intelligence. It will be open to all potential participants, and the workshop findings (including videotapes of presentations) will be distributed to the public for comments and engagement. The organizers  will encourage students to attend the workshop, and will actively recruit scientists from a diversity of backgrounds to contribute to a wide range of algorithmic topics.</AbstractNarration>
<MinAmdLetterDate>05/13/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/13/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1639630</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Karp</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard M Karp</PI_FULL_NAME>
<EmailAddress>karp@cs.berkeley.edu</EmailAddress>
<PI_PHON>5106425799</PI_PHON>
<NSF_ID>000099536</NSF_ID>
<StartDate>05/13/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>947045940</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~20000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Workshop on &ldquo;Computational Challenges in Machine Learning&rdquo;<br /></strong><strong>Simons Institute for the Theory of Computing, 1-5 May, 2017</strong></p> <p>The final workshop of the Simons Institute program on Foundations of Machine Learning was organized by Santosh Vempala, David Blei, Katherine Heller, John Langford and Le Song. The aim of the workshop was to bring together researchers investigating a wide range of algorithmic questions that arise in machine learning, and especially in large-&shy;scale learning, including algorithms for Bayesian estimation and variational inference, nonlinear and nonparametric function estimation, reinforcement learning and stochastic processes.</p> <p>Each of the first four days of the workshop was thematically structured around one of the following topics:</p> <ol> <li>Probability and inference</li> <li>Optimization</li> <li>Applications</li> <li>High dimension</li> </ol> <p>Each of these days began with a 1-hour tutorial given by a leading expert in the field (David Blei, Michael Jordan, Katherine Heller and Le Song, respectively). The rest of the day consisted of 45-minute invited talks related to the day&rsquo;s theme.</p> <p>There were many new interactions at the workshop between ML-centric and algorithms/complexity-centric researchers, as well as between junior researchers and more senior researchers. Some sub-themes of particular interest that emerged were the analysis of empirical methods for variational inference, the ubiquity of stochastic gradient descent, the challenges of nonconvex optimization, and the need for robust methods in high-dimensional statistics. While there were some talks on learning with neural nets and their limitations, there was also extensive discussion on challenges and approaches beyond deep learning and why the latter is not (yet) a panacea.</p> <p>The final day (a half day on Friday) consisted of three talks on diverse topics: the optimal design of experiments; dealing with untrustworthy data sources; and a model for the cost of communication in large-scale machine learning.</p> <p>In additional to invited talks, there was a lively and thought-provoking panel on &ldquo;Computational Challenges and the future of ML&rdquo; with panelists Maryam Fazel, Yoav Freund, Michael Jordan, Richard Karp and Marina Meila. Workshop attendees also continued their discussions in the relaxed atmosphere of the Cinco de Mayo fiesta organized by the insanely competent Simons staff on the last afternoon.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/13/2017<br>      Modified by: Richard&nbsp;M&nbsp;Karp</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Workshop on "Computational Challenges in Machine Learning" Simons Institute for the Theory of Computing, 1-5 May, 2017  The final workshop of the Simons Institute program on Foundations of Machine Learning was organized by Santosh Vempala, David Blei, Katherine Heller, John Langford and Le Song. The aim of the workshop was to bring together researchers investigating a wide range of algorithmic questions that arise in machine learning, and especially in large-&shy;scale learning, including algorithms for Bayesian estimation and variational inference, nonlinear and nonparametric function estimation, reinforcement learning and stochastic processes.  Each of the first four days of the workshop was thematically structured around one of the following topics:  Probability and inference Optimization Applications High dimension   Each of these days began with a 1-hour tutorial given by a leading expert in the field (David Blei, Michael Jordan, Katherine Heller and Le Song, respectively). The rest of the day consisted of 45-minute invited talks related to the day?s theme.  There were many new interactions at the workshop between ML-centric and algorithms/complexity-centric researchers, as well as between junior researchers and more senior researchers. Some sub-themes of particular interest that emerged were the analysis of empirical methods for variational inference, the ubiquity of stochastic gradient descent, the challenges of nonconvex optimization, and the need for robust methods in high-dimensional statistics. While there were some talks on learning with neural nets and their limitations, there was also extensive discussion on challenges and approaches beyond deep learning and why the latter is not (yet) a panacea.  The final day (a half day on Friday) consisted of three talks on diverse topics: the optimal design of experiments; dealing with untrustworthy data sources; and a model for the cost of communication in large-scale machine learning.  In additional to invited talks, there was a lively and thought-provoking panel on "Computational Challenges and the future of ML" with panelists Maryam Fazel, Yoav Freund, Michael Jordan, Richard Karp and Marina Meila. Workshop attendees also continued their discussions in the relaxed atmosphere of the Cinco de Mayo fiesta organized by the insanely competent Simons staff on the last afternoon.           Last Modified: 11/13/2017       Submitted by: Richard M Karp]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
