<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Reconceptualizing STEM+Computing Literacy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2016</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>299420.00</AwardTotalIntnAmount>
<AwardAmount>299420</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Arlene de Strulle</SignBlockName>
<PO_EMAI>adestrul@nsf.gov</PO_EMAI>
<PO_PHON>7032925117</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Reconceptualizing STEM + Computing Literacy is funded by the STEM+Computing Partnership (STEM+C) program, which seeks to advance multidisciplinary integration of computing and computational thinking in K-12 science, technology, engineering, and mathematics (STEM) teaching and learning through applied research and development across one or more domains, and broadening participation in computing and computing-related fields. The project will study the integration of computational thinking as part of a new and more contemporary perspective of STEM literacy, and will design, develop, and beta-test a prototype literacy assessment tool that will measure computational thinking literacy along with measures of literacy in other STEM content areas. The tool will be available to the general public as a self-measurement application (App) that can be used by individuals to test their own literacy, and by teachers, schools, and informal educators and organizations to assess literacy development in their students and in their STEM education programs.  This transdisciplinary research project will begin the process of creating an innovative approach and tool for measuring literacy that will expand the definition of literacy to include computational skills along with science reasoning. Literacy is an important concept and measurement that has traditionally been used to assess an individual's knowledge of science. This project will explore a broader literacy perspective that incorporates learning derived from out of school and one that incorporates computational skills and thinking as part of a more contemporary perspective of STEM literacy. A prototype web-based App allowing individuals and education organizations to assess literacy levels, and ways to enhance literacy, will be developed and studied. The methodology will be developed using discussions and knowledge from over 60 experts across computing, education, science, social science, and other STEM fields using a Delphi method to engage in reconceptualization of literacy. The hypothesis is that this new STEM+C literacy framework should be structured along four interacting but semi-independent domains: 1) general STEM+C knowledge; 2) self-defined areas of STEM+C knowledge and expertise; 3) attitudes and beliefs related to STEM+C; and 4) the skills and competencies necessary to participate in STEM+C related pursuits and discussions, including measures of modes of STEM+C thinking. Each of these four domains is likely to include numerous sub-domains and associated descriptors, which collectively describe the different aspects of being a STEM+C literate citizen. The application will be designed to provide feedback to individuals on their knowledge, attitudes and skills compared with those of others and suggest ways to enhance and improve their skills and understanding through an embedded feedback mechanism. This project creates public benefit by providing individuals and organizations with a responsive real-time understanding measuring STEM+C literacy, deepening the dialogue about the value of public engagement in science, engineering, technology, math and computing and revealing the dynamic factors that inform STEM+C literacy.</AbstractNarration>
<MinAmdLetterDate>09/12/2016</MinAmdLetterDate>
<MaxAmdLetterDate>09/12/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1656124</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Falk</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John Falk</PI_FULL_NAME>
<EmailAddress>john.falk@freechoicelearning.org</EmailAddress>
<PI_PHON>5415207140</PI_PHON>
<NSF_ID>000663796</NSF_ID>
<StartDate>09/12/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Monae</FirstName>
<LastName>Verbeke</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Monae Verbeke</PI_FULL_NAME>
<EmailAddress>monae.verbeke@freechoicelearning.org</EmailAddress>
<PI_PHON/>
<NSF_ID>000722756</NSF_ID>
<StartDate>09/12/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Institute for Learning Innovation</Name>
<CityName>Beaverton</CityName>
<ZipCode>970087105</ZipCode>
<PhoneNumber>4432230694</PhoneNumber>
<StreetAddress>9450 SW Gemini Drive</StreetAddress>
<StreetAddress2><![CDATA[#79315]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079246886</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>INSTITUTE FOR LEARNING INNOVATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Institute for Learning Innovation]]></Name>
<CityName/>
<StateCode>OR</StateCode>
<ZipCode>972174141</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>005Y</Code>
<Text>STEM + Computing (STEM+C) Part</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~299420</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Supporting and sustaining public STEM+C literacy is the primary goal of almost all informal (and formal) science education. Unfortunately, there is currently no widely accepted nor easily administered measure of STEM+C literacy; particularly one that broadly and accurately captures the multi-dimensional, situated realities of how people learn over their lifetime through experiences in and out of school. The research supported by this award was designed to: (1) reconceptualize the construct of science, technology, engineering, mathematics and computational literacy, with a particular attention to the role played by informal science education in supporting such literacies,; (2) construct and test for validity and reliability a new measure of science literacy designed to capture the highly variable and individualized knowledge of the public; and (3) determine if it was feasible to format this new measure of science literacy in ways that could be readily utilized by professionals and the general public within free-choice learning contexts. Our work resulted in development of a platform designed to serve a wide variety of purposes, including assisting individuals with defining, assessing, and enhancing their STEM+C literacy based on their own individualized knowledge and interests. The platform we developed has the following features:&nbsp;</p> <p>&nbsp;</p> <ul> <li>Custom design allowing informal science learning professionals to create quizzes (questions, answers, recommendations, etc) that capture specific subject areas they deem important;</li> <li>A community platform with groups for specific scientific domains, activity feeds, profiles, messaging, notifications;</li> <li>Back-end reporting systems that allow professionals and researchers to run reports on individual or aggregate quiz results, including the ability to export reports to PDF and/or XLS; and</li> <li>Integration of gamification strategies, badges, opportunities for gaining further information and other types of (potential) self-reinforcing rewards for users.</li> </ul> <p>&nbsp;</p> <p>To bring this project to a broad audience,&nbsp;the new tool would be most effective if it could: (A) continuously and intelligently gather and categorize (from novice to expert) questions from users and experts in the domian; and (B) gather and continuously and intelligently deliver recommendations for how users could improve their own knowledge and competencies. The latter item would include the ability to automatically find resources, including events and readings listed online.&nbsp;The advantages of this approach are that it would provide a built-in mechanism for researcher?s to validate self-assessments, make participation a meaningful learning experience for users, and insure a continuously expanding and up-to-date science literacy tool. Such a tool is theoretically possible using current artificial intelligence technologies but creation and implementation of these technologies were beyond the scope and budget of the current project.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/30/2019<br>      Modified by: Monae&nbsp;Verbeke</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Supporting and sustaining public STEM+C literacy is the primary goal of almost all informal (and formal) science education. Unfortunately, there is currently no widely accepted nor easily administered measure of STEM+C literacy; particularly one that broadly and accurately captures the multi-dimensional, situated realities of how people learn over their lifetime through experiences in and out of school. The research supported by this award was designed to: (1) reconceptualize the construct of science, technology, engineering, mathematics and computational literacy, with a particular attention to the role played by informal science education in supporting such literacies,; (2) construct and test for validity and reliability a new measure of science literacy designed to capture the highly variable and individualized knowledge of the public; and (3) determine if it was feasible to format this new measure of science literacy in ways that could be readily utilized by professionals and the general public within free-choice learning contexts. Our work resulted in development of a platform designed to serve a wide variety of purposes, including assisting individuals with defining, assessing, and enhancing their STEM+C literacy based on their own individualized knowledge and interests. The platform we developed has the following features:      Custom design allowing informal science learning professionals to create quizzes (questions, answers, recommendations, etc) that capture specific subject areas they deem important; A community platform with groups for specific scientific domains, activity feeds, profiles, messaging, notifications; Back-end reporting systems that allow professionals and researchers to run reports on individual or aggregate quiz results, including the ability to export reports to PDF and/or XLS; and Integration of gamification strategies, badges, opportunities for gaining further information and other types of (potential) self-reinforcing rewards for users.      To bring this project to a broad audience, the new tool would be most effective if it could: (A) continuously and intelligently gather and categorize (from novice to expert) questions from users and experts in the domian; and (B) gather and continuously and intelligently deliver recommendations for how users could improve their own knowledge and competencies. The latter item would include the ability to automatically find resources, including events and readings listed online. The advantages of this approach are that it would provide a built-in mechanism for researcher?s to validate self-assessments, make participation a meaningful learning experience for users, and insure a continuously expanding and up-to-date science literacy tool. Such a tool is theoretically possible using current artificial intelligence technologies but creation and implementation of these technologies were beyond the scope and budget of the current project.           Last Modified: 12/30/2019       Submitted by: Monae Verbeke]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
