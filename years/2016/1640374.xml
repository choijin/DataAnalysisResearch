<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Bridging The Gap between Theory and Practice in Data Privacy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>299564.00</AwardTotalIntnAmount>
<AwardAmount>299564</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to bridge the gap between theory and practice in privacy-preserving data sharing and analysis. Data collected by organizations and agencies are a key resource in today's information age.  However, the disclosure of those data poses serious threats to individual privacy.  While differential privacy provides a solid foundation for developing techniques to balance privacy and utility in data sharing, currently there is a significant gap between theory and practice in research in this area.  In the current state of the art, each task requires specialized algorithms to achieve acceptable trade-off of privacy and utility.  The process of designing new algorithms is manual and challenging.  Furthermore, research in this area tends to take either a pure theoretical approach or a pure experimental approach; both have significant limitations.  This project aims to develop algorithms that can be broadly and automatically applied, and methodologies for combining theoretical analysis with experimental validations, focusing on concrete (instead of asymptotic) analysis where constants are spelled out.  Advances in data privacy techniques will benefit society by providing a better balance between the need to release data to serve public interest and the need to protect individuals' privacy.  &lt;br/&gt;&lt;br/&gt;The project pursues the following research goals to advance the state-of-the-art of data privacy.  One goal is to develop a general method that can take a non-private data analysis algorithm as a blackbox, and make it private.  This may require the development of a data privacy notion that is more relaxed than differential privacy.  Another goal is to develop a concrete approach to understanding the utility of data analysis algorithms.  The theoretical approach of proving asymptotic utility bounds is limited for a number of reasons.  Asymptotic analysis ignores constants (and oftentimes poly-logarithmic terms as well), which are critical for utility in practice.  A method with an appealing asymptotic utility bound often performs poorly except for very large parameters, when applying the method requires an unacceptable amount of space and time computing resources.  As the utility bound must hold for all datasets (including pathological ones), such bounds can be so loose that they are meaningless once the actual parameters are plugged in.  Bridging this gap requires better understanding of the factors affecting utility, better utility metrics, and methods to formalize the dependencies of utility on dataset features.  The resulting concrete approach combines theoretical analysis with heuristic approximations and experimental validations, and can more effectively guide the development of practically effective algorithms.</AbstractNarration>
<MinAmdLetterDate>08/25/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/25/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1640374</AwardID>
<Investigator>
<FirstName>Ninghui</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ninghui Li</PI_FULL_NAME>
<EmailAddress>ninghui@cs.purdue.edu</EmailAddress>
<PI_PHON>7654966756</PI_PHON>
<NSF_ID>000166436</NSF_ID>
<StartDate>08/25/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072107</ZipCode>
<StreetAddress><![CDATA[305 N. University Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>022Z</Code>
<Text>International Partnerships</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~299564</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project has resulted in a spectrum of impactful results in the theory and practice of local differential privacy (LDP), a popular privacy notion used for privacy-preserving data collection in the industry.&nbsp; &nbsp;LDP differs from Differential Privacy in that random noises are added by each user before the data leaves the user's device. Thus, users do not need to trust the server.&nbsp; This project first systematically analyzed the existing protocols and proposed Optimized Local Hash (OLH) as the basic tool for histogram estimation.&nbsp; While providing the same level of privacy guarantees, OLH can perform analysis tasks more accurately than others.&nbsp; OLH was proposed in 2017 and is still the state-of-the-art method for estimating histograms, even though this area has been under intensive study in recent years.&nbsp; With the help of information theory, several theoretical lower-bound about OLH and other algorithms are obtained.&nbsp;</p> <p><br />Building on top of OLH, this project also resulted in several algorithms for performing higher-level data analysis tasks while satisfying LDP, including algorithms for frequent itemset mining and publishing item counts for transactional datasets, answering marginal queries, answering range queries, and estimating densities.&nbsp; Beyond designing effective protocols for different tasks, this project also studied several other related problems, including surveying existing methods for post-processing the results, assessing people's acceptance of differential privacy, and studying the more recently proposed notion of shuffler differential privacy.</p> <p><br />This project resuled in around a dozen papers that have appeared in top publication venues in privacy and databases.&nbsp; It also partially supported the study of four PhD students.&nbsp;&nbsp;</p><br> <p>            Last Modified: 10/02/2020<br>      Modified by: Ninghui&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project has resulted in a spectrum of impactful results in the theory and practice of local differential privacy (LDP), a popular privacy notion used for privacy-preserving data collection in the industry.   LDP differs from Differential Privacy in that random noises are added by each user before the data leaves the user's device. Thus, users do not need to trust the server.  This project first systematically analyzed the existing protocols and proposed Optimized Local Hash (OLH) as the basic tool for histogram estimation.  While providing the same level of privacy guarantees, OLH can perform analysis tasks more accurately than others.  OLH was proposed in 2017 and is still the state-of-the-art method for estimating histograms, even though this area has been under intensive study in recent years.  With the help of information theory, several theoretical lower-bound about OLH and other algorithms are obtained.    Building on top of OLH, this project also resulted in several algorithms for performing higher-level data analysis tasks while satisfying LDP, including algorithms for frequent itemset mining and publishing item counts for transactional datasets, answering marginal queries, answering range queries, and estimating densities.  Beyond designing effective protocols for different tasks, this project also studied several other related problems, including surveying existing methods for post-processing the results, assessing people's acceptance of differential privacy, and studying the more recently proposed notion of shuffler differential privacy.   This project resuled in around a dozen papers that have appeared in top publication venues in privacy and databases.  It also partially supported the study of four PhD students.         Last Modified: 10/02/2020       Submitted by: Ninghui Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
