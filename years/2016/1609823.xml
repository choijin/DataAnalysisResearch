<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Approximate Computing on Real World Data Using Representation and Coding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>383000.00</AwardTotalIntnAmount>
<AwardAmount>383000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Goldberg</SignBlockName>
<PO_EMAI>lgoldber@nsf.gov</PO_EMAI>
<PO_PHON>7032928339</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The diminishing benefits from traditional transistor scaling has coincided with an overwhelming increase in the rate of data generation. Expert analyses show that in 2011, the amount of generated data surpassed 1.8 zeta bytes and will increase by a factor of 50 until 2020. To overcome these challenges, both the semiconductor industry and the research community are exploring new avenues in computing. Two of the promising approaches are acceleration and approximation. Among accelerators, Graphic Processing Units provide significant compute capabilities. Graphic Processing Units, originally designed to accelerate graphics functions, now are processing large amounts of real-world data that are collected from sensors, radar, environment, financial markets, and medical devices. As Graphic Processing Units play a major role in accelerating many classes of applications, improving their performance and energy efficiency has become imperative. This project leverages the fact that many applications that benefit from Graphic Processing Units are amenable to imprecise computation. This characteristic provides an opportunity to devise approximation techniques that trade small losses in the output quality for significant gains in performance and energy efficiency. This project aims to exploit this opportunity and develop a comprehensive framework for approximation in Graphic Processing Units along with effective quality control mechanisms based on coding theory. Energy efficiency is arguably the biggest challenge of the computing industry. To maintain the nation's economic leadership in this industry, it is vital to develop solutions, such as this project, that address the fundamental challenges of energy-efficient computing. The computing industry has reached an era in which many of the innovative techniques, such as this work, crosses the boundary of multiple disciplines, including computer architecture, information theory, and signal processing. Thus, it is imperative to educate a workforce that not only deeply understands multiple disciples, but also can innovate across their boundaries. This project provides a foundation for such education and research. This project will produce benchmarks, tools and general infrastructure. These artifacts will be made publicly available and will be integrated in the Georgia Tech and Harvard curricula. To transfer these technologies, the principle investigators have established close contacts with several companies. Besides the customary routes academics use to disseminate results, the principle investigator will continue organizing workshops on approximate computing. The principle investigator is also coauthoring a book on approximate computing, which will include results from this project. The investigators are committed to diversity and inclusion of undergraduate, underrepresented, and high school students and are currently mentoring students from all groups that will continue throughout this project. &lt;br/&gt;&lt;br/&gt;This project will first develop an accelerated architecture for Graphic Processing Units, which leverage an approximate algorithmic transformation for faster and more energy efficient execution. The core idea is to use neural models to learn how a region of code behaves and replace the region with a hardware accelerator that is tightly integrated within the many cores of the Graphic Processing Units. Second, inspired by Shannon's work and the success of random codes in providing reliable communication over noisy channels, this work will devise quality control solutions that utilize coding techniques to reduce the imprecision. The code is implicit in a sense that whenever an approximate output must be improved, its correlation with available exact outputs is exploited for constructing and decoding the code. Third, the project will study mechanisms that leverage the inherent similarity and predictability in the real-world data to address the memory bottlenecks in Graphic Processing Units. The main idea is to predict the values of a data load operation when it misses in the local on-chip cache and continue the computation without waiting for the long-latency response from the off-chip memory. To perform effective prediction, this project will develop multi-regime adaptive nonlinear time-varying dynamical models for the input data using our new theories of model matching.</AbstractNarration>
<MinAmdLetterDate>07/14/2016</MinAmdLetterDate>
<MaxAmdLetterDate>02/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1609823</AwardID>
<Investigator>
<FirstName>Faramarz</FirstName>
<LastName>Fekri</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Faramarz Fekri</PI_FULL_NAME>
<EmailAddress>fekri@ece.gatech.edu</EmailAddress>
<PI_PHON>4048943335</PI_PHON>
<NSF_ID>000261381</NSF_ID>
<StartDate>08/10/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Faramarz</FirstName>
<LastName>Fekri</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Faramarz Fekri</PI_FULL_NAME>
<EmailAddress>fekri@ece.gatech.edu</EmailAddress>
<PI_PHON>4048943335</PI_PHON>
<NSF_ID>000261381</NSF_ID>
<StartDate>07/14/2016</StartDate>
<EndDate>08/10/2018</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hadi</FirstName>
<LastName>Esmaeilzadeh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hadi Esmaeilzadeh</PI_FULL_NAME>
<EmailAddress>hadi@eng.ucsd.edu</EmailAddress>
<PI_PHON>2066583952</PI_PHON>
<NSF_ID>000653497</NSF_ID>
<StartDate>08/10/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hadi</FirstName>
<LastName>Esmaeilzadeh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hadi Esmaeilzadeh</PI_FULL_NAME>
<EmailAddress>hadi@eng.ucsd.edu</EmailAddress>
<PI_PHON>2066583952</PI_PHON>
<NSF_ID>000653497</NSF_ID>
<StartDate>07/14/2016</StartDate>
<EndDate>08/10/2018</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Ave NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>153E</Code>
<Text>Wireless comm &amp; sig processing</Text>
</ProgramReference>
<ProgramReference>
<Code>154E</Code>
<Text>Computat systems &amp; security</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~383000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 7"> <div class="section"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 7"> <div class="section"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 7"> <div class="section"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 6"> <div class="section"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 6"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>Recent breakthroughs in data sciences are sparking a move towards developing techniques thate xtract useful insights from massive amounts of data. However, the rate of data generation is increasing at an overwhelming rate that is beyond the capabilities of current computings ystems. Analyses show that in 2011, the amount of generated data surpassed 1.8 trillion GB and by 2020, consumers will generate 50x this figure. This data growth has coincided with the dark silicon era, in which the benefits from transistor scaling ared iminishing and the current paradigm of general</span><span>&#8203; </span><span>purpose computing falls significantly shorto f historical performance improvements. However, there are silver linings. One is that a largec lass of emerging applications that collect and process data exhibit inherent tolerance to imprecision. Examples are machine learning, data visualization, sensory and streaming data processing, augmented reality, search, optimizations and vision. General</span><span>&#8203;</span><span>purpose approximate computing exploits this tolerance to imprecision and trades small losses in the output qualityf or significant gains in performance and efficiency. In this project, we aim to develop solutions that leveraging approximation to tackle these challenges. </span></p> <p><span>Our work has developed solutions that provide significant gains that were not achieved before and has sparked a move in the computer architecture community toward approximation techniques. </span></p> <p><span>The processing of massive amount of data may lead to discoveries in health, planning, etc. that can impact the society in an extremely positive way. </span></p> </div> </div> </div> </div> <p>&nbsp;</p> <p><span>Our work is a true multidisciplinary work that brings together elements from computer architecture, software engineering, and machine learning. Several works outside of the computer architecture community has already cited the resulting papers from this work. The significant benefits from our work has drawn attention from other communities such as programing languages and software engineering to develop support for approximate computing. </span></p> <p><span>The improvements that are achieved with our techniques can enable the next generation computing systems to provide capabilities that are out of reach today. These capabilities can enable new advances in different disciplines such as data analytics, sensory data processing, and even healthcare and fitness industry that is becoming more reliant on low</span><span>&#8203;</span><span>power and/or high</span><span>&#8203;</span><span>performance commuting. </span></p> <p><span>In the course of developing new algorithms for decoding error correcting codes, we have discovered a new type of neural networks that we refer to them as logic learners, which are based on boolean logic algebra. Such a networks can learn algorithmic tasks far better than existing state of the art neural networks. In addition to error correcting codes, we have so far shown that neural logic learners outperform the state of the art in learning binary addition, grammar verification, </span><span>Relational reinforcement learning, Causality inference in gene regularity networks</span><span>, </span><span>Classification tasks for large scale relational datasets such as IMDB and Cora</span><span>, and Learning large scale arithmetic and symbolic tasks. This can have significant impacts in developing AI for algorithmic tasks. </span></p> </div> </div> </div> </div> <p>&nbsp;</p> <p><span>The education and training given during the performance of this project leads to development of highly skilled human resources and may have positive impact on future scientific, engineering and technological developments.</span></p> </div> </div> </div> </div> <p><span>This work can be integrated in the future computing platforms that for the physical infrastructure for many different disciplines. In fact, the work is developing techniques that can be potentially incorporated in commercial processors.</span></p> </div> </div> </div> </div> <div class="page" title="Page 7"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>Computing has become a commodity and microprocessors have had the most significant role in commoditizing computing. Every institution uses compute platforms for different tasks and applications. The ever increasing reliance on computing require higher</span><span>&#8203;</span><span>performance and lower</span><span>&#8203;</span><span>power from the computing platforms. Our techniques provide such benefits and can play a significant role in future institutional resources. </span></p> </div> </div> </div> </div> <p><span>This project is likely to form the basis of the future computing nodes that are required to process overwhelming amount of data with limited power budget. This work takes advantage of the fact that many of the emerging application are amenable to approximation. </span></p> </div> </div> </div> </div> <p>&nbsp;</p><br> <p>            Last Modified: 09/10/2020<br>      Modified by: Hadi&nbsp;Esmaeilzadeh</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[                     Recent breakthroughs in data sciences are sparking a move towards developing techniques thate xtract useful insights from massive amounts of data. However, the rate of data generation is increasing at an overwhelming rate that is beyond the capabilities of current computings ystems. Analyses show that in 2011, the amount of generated data surpassed 1.8 trillion GB and by 2020, consumers will generate 50x this figure. This data growth has coincided with the dark silicon era, in which the benefits from transistor scaling ared iminishing and the current paradigm of general&#8203; purpose computing falls significantly shorto f historical performance improvements. However, there are silver linings. One is that a largec lass of emerging applications that collect and process data exhibit inherent tolerance to imprecision. Examples are machine learning, data visualization, sensory and streaming data processing, augmented reality, search, optimizations and vision. General&#8203;purpose approximate computing exploits this tolerance to imprecision and trades small losses in the output qualityf or significant gains in performance and efficiency. In this project, we aim to develop solutions that leveraging approximation to tackle these challenges.   Our work has developed solutions that provide significant gains that were not achieved before and has sparked a move in the computer architecture community toward approximation techniques.   The processing of massive amount of data may lead to discoveries in health, planning, etc. that can impact the society in an extremely positive way.          Our work is a true multidisciplinary work that brings together elements from computer architecture, software engineering, and machine learning. Several works outside of the computer architecture community has already cited the resulting papers from this work. The significant benefits from our work has drawn attention from other communities such as programing languages and software engineering to develop support for approximate computing.   The improvements that are achieved with our techniques can enable the next generation computing systems to provide capabilities that are out of reach today. These capabilities can enable new advances in different disciplines such as data analytics, sensory data processing, and even healthcare and fitness industry that is becoming more reliant on low&#8203;power and/or high&#8203;performance commuting.   In the course of developing new algorithms for decoding error correcting codes, we have discovered a new type of neural networks that we refer to them as logic learners, which are based on boolean logic algebra. Such a networks can learn algorithmic tasks far better than existing state of the art neural networks. In addition to error correcting codes, we have so far shown that neural logic learners outperform the state of the art in learning binary addition, grammar verification, Relational reinforcement learning, Causality inference in gene regularity networks, Classification tasks for large scale relational datasets such as IMDB and Cora, and Learning large scale arithmetic and symbolic tasks. This can have significant impacts in developing AI for algorithmic tasks.          The education and training given during the performance of this project leads to development of highly skilled human resources and may have positive impact on future scientific, engineering and technological developments.      This work can be integrated in the future computing platforms that for the physical infrastructure for many different disciplines. In fact, the work is developing techniques that can be potentially incorporated in commercial processors.          Computing has become a commodity and microprocessors have had the most significant role in commoditizing computing. Every institution uses compute platforms for different tasks and applications. The ever increasing reliance on computing require higher&#8203;performance and lower&#8203;power from the computing platforms. Our techniques provide such benefits and can play a significant role in future institutional resources.       This project is likely to form the basis of the future computing nodes that are required to process overwhelming amount of data with limited power budget. This work takes advantage of the fact that many of the emerging application are amenable to approximation.               Last Modified: 09/10/2020       Submitted by: Hadi Esmaeilzadeh]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
