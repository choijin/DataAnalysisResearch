<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Honest Inference and Efficiency Bounds for Nonparametric Regression and Approximate Moment Condition Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>199260.00</AwardTotalIntnAmount>
<AwardAmount>199260</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nancy Lutz</SignBlockName>
<PO_EMAI>nlutz@nsf.gov</PO_EMAI>
<PO_PHON>7032927280</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In analyzing economic data, researchers use models and assumptions that are typically best thought of as approximations of reality.  This project will develop statistical methods that are valid when these models are only approximately correct, rather than exactly correct.  The methods developed in this project can also be used to provide simple ways of assessing the sensitivity of the conclusions of an empirical study to its underlying assumptions.  These methods can be applied to numerous commonly studied problems that are relevant for policy and for understanding the economy.&lt;br/&gt;&lt;br/&gt;This project will develop confidence intervals in approximate moment condition models with convex parameter spaces, as well as sharp efficiency bounds showing that they are as tight as possible in a certain precise sense. The setup covers inference on a linear functional of a nonparametric regression function, such as its value at a point, the regression discontinuity parameter, or an average treatment effect under unconfoundedness. The setup also covers parameter constraints in the linear regression model as well as moment condition models such as generalized method of moments (GMM) or minimum distance models in which the moment condition is locally misspecified. The confidence intervals are simple to construct, and valid in an "honest" or uniform sense. As special cases of the results, the project obtains optimal kernels for inference in nonparametric regression models, and optimal weights for GMM under misspecification.</AbstractNarration>
<MinAmdLetterDate>08/31/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1628878</AwardID>
<Investigator>
<FirstName>Michal</FirstName>
<LastName>Kolesar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michal Kolesar</PI_FULL_NAME>
<EmailAddress>mkolesar@princeton.edu</EmailAddress>
<PI_PHON>6092586726</PI_PHON>
<NSF_ID>000714505</NSF_ID>
<StartDate>08/31/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Woodrow Wilson School]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress><![CDATA[203 Fisher Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1320</Code>
<Text>Economics</Text>
</ProgramElement>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramElement>
<Code>1397</Code>
<Text>Cross-Directorate  Activities</Text>
</ProgramElement>
<ProgramReference>
<Code>040Z</Code>
<Text>Robust and Reliable Science</Text>
</ProgramReference>
<ProgramReference>
<Code>1320</Code>
<Text>ECONOMICS</Text>
</ProgramReference>
<ProgramReference>
<Code>1333</Code>
<Text>METHOD, MEASURE &amp; STATS</Text>
</ProgramReference>
<ProgramReference>
<Code>1397</Code>
<Text>CROSS-DIRECTORATE  ACTIV PROGR</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~199260</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In many models commonly used by practitioners, estimates of parameters of interest display finite-sample bias. The bias may arise because the model is misspecified, or because the researcher uses smoothing or regularization. A regularization bias arises in non-parametric and semi-parametric models, including regression discontinuity or regression kink designs, estimation of average treatment effects under unconfoundedness, or in modern high-dimensional regression models. The standard approach to quantifying uncertainty about the parameter estimates in these models is to employ large-sample approximations in which the bias becomes negligible relative to the sampling variability of the estimator: this can be achieved, for instance, by "undersmoothing". However, since the theory of undersmoothing only restricts the rate at which tuning parameters, such as bandwidths, must shrink with sample size, the practical prescriptions of this theory are unclear: one can justify any tuning parameter choice by promising to shrink it sufficiently fast if one had more data.<br /><br />In this project, we developed an alternative approach to inference in a class of regression models that includes regression discontinuity designs, linear or partly linear regression, estimation of average treatment effects under unconfoundedness, or high-dimensional regression. Rather than assuming that the bias will be asymptotically negligible, our confidence intervals (CIs) explicitly take into account the potential bias of the estimator by using a larger critical value than the usual 1.96 critical value. We are able to calculate the necessary adjustment by making explicit the smoothness assumptions that the researcher imposes, including any smoothness constants. This approach is "honest" in the sense that its validity doesn't rely on any asymptotic promises about the tuning parameters; our CIs are valid uniformly over the parameter space that the researcher specifies by their smoothness assumptions.<br /><br />We show that the explicit specification of the smoothness conditions cannot be avoided by the researcher: we derive a sharp efficiency bound which implies that one cannot start with a conservative specification for the smoothness, and use the data to tighten the CIs if the regression function turns out to be smooth. We also show that, in the context of inference in regression discontinuity designs, a practically attractive implementation of our CIs is to simply center them around an estimator with MSE-optimal bandwidth, rather than reoptimizing the bandwidth for CI length. This approach also works when the covariates are discrete; in contrast, as we show in work with Christoph Rothe, the standard practice of clustering the standard errors by the running variable can in this context be highly misleading.<br /><br />We also consider the case in which the source of bias is model misspecification. In particular, we consider inference in generalized method of moments (GMM) models under the weaker assumption that the model is only approximately correct. Our key insight is that because valid CIs need to be widened to account for the potential model misspecification, the optimal weighting matrix differs from the one that is optimal under correct specification: one needs to trade off the precision of the moments against their potential misspecification.<br /><br />Our work provides practitioners with novel and more robust ways of quantifying uncertainty in common economic models. We have developed software implementing our methods, adding directly to the toolkit of applied researchers in economics and other social sciences.</p><br> <p>            Last Modified: 11/25/2019<br>      Modified by: Michal&nbsp;Kolesar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In many models commonly used by practitioners, estimates of parameters of interest display finite-sample bias. The bias may arise because the model is misspecified, or because the researcher uses smoothing or regularization. A regularization bias arises in non-parametric and semi-parametric models, including regression discontinuity or regression kink designs, estimation of average treatment effects under unconfoundedness, or in modern high-dimensional regression models. The standard approach to quantifying uncertainty about the parameter estimates in these models is to employ large-sample approximations in which the bias becomes negligible relative to the sampling variability of the estimator: this can be achieved, for instance, by "undersmoothing". However, since the theory of undersmoothing only restricts the rate at which tuning parameters, such as bandwidths, must shrink with sample size, the practical prescriptions of this theory are unclear: one can justify any tuning parameter choice by promising to shrink it sufficiently fast if one had more data.  In this project, we developed an alternative approach to inference in a class of regression models that includes regression discontinuity designs, linear or partly linear regression, estimation of average treatment effects under unconfoundedness, or high-dimensional regression. Rather than assuming that the bias will be asymptotically negligible, our confidence intervals (CIs) explicitly take into account the potential bias of the estimator by using a larger critical value than the usual 1.96 critical value. We are able to calculate the necessary adjustment by making explicit the smoothness assumptions that the researcher imposes, including any smoothness constants. This approach is "honest" in the sense that its validity doesn't rely on any asymptotic promises about the tuning parameters; our CIs are valid uniformly over the parameter space that the researcher specifies by their smoothness assumptions.  We show that the explicit specification of the smoothness conditions cannot be avoided by the researcher: we derive a sharp efficiency bound which implies that one cannot start with a conservative specification for the smoothness, and use the data to tighten the CIs if the regression function turns out to be smooth. We also show that, in the context of inference in regression discontinuity designs, a practically attractive implementation of our CIs is to simply center them around an estimator with MSE-optimal bandwidth, rather than reoptimizing the bandwidth for CI length. This approach also works when the covariates are discrete; in contrast, as we show in work with Christoph Rothe, the standard practice of clustering the standard errors by the running variable can in this context be highly misleading.  We also consider the case in which the source of bias is model misspecification. In particular, we consider inference in generalized method of moments (GMM) models under the weaker assumption that the model is only approximately correct. Our key insight is that because valid CIs need to be widened to account for the potential model misspecification, the optimal weighting matrix differs from the one that is optimal under correct specification: one needs to trade off the precision of the moments against their potential misspecification.  Our work provides practitioners with novel and more robust ways of quantifying uncertainty in common economic models. We have developed software implementing our methods, adding directly to the toolkit of applied researchers in economics and other social sciences.       Last Modified: 11/25/2019       Submitted by: Michal Kolesar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
