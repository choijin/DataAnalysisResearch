<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Software-Defined Data Plane for Datacenters</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many popular cloud applications that power our daily lives, such as Facebook, Google, Amazon, and Twitter, spend a large fraction of their time performing network operations.  Even supposedly computationally intensive applications such as parallel machine learning are often limited by communication performance.  Datacenter network designers have been racing to keep up with this increased reliance on network usage, but they have had only limited success in achieving desirable system properties as they are often constrained by the lack of switch support for deploying new protocols.&lt;br/&gt;&lt;br/&gt;Fortunately, innovation in switch and network interface card (NIC) design is now focused on building not just faster but also more flexible packet processing devices. Whereas traditional switches and NICs typically provide functionality to route and forward packets, many upcoming switches have support for transforming the packet as well as performing computations on the packet before routing it towards its destination.  These devices have the potential to revolutionize the use of networking devices within datacenters as they provide the ability to reconfigure packet processing and deploy new protocols.&lt;br/&gt;&lt;br/&gt;This project will investigate flexible packet processing functionality on NICs and switches and their potential for optimizing high performance networked systems inside the datacenter. This work provides new abstractions and building blocks for the use of flexible packet processing pipelines, while respecting the hardware constraints that will be associated with these technologies.  The researchers will examine how the resulting data plane functionality can be used to implement resource allocation mechanisms inside the datacenter so as to enable congestion control, performance isolation, adaptive routing, and efficient load balancing.  They will also examine implementing on the NICs and switches some of the packet processing traditionally done in end-host software. The goal is to show how and by how much flexible packet processing can benefit widely used datacenter applications and also provide guidance on what features that future iterations of the hardware should provide in order to significantly improve application performance.&lt;br/&gt;&lt;br/&gt;Broader Impact: Network-intensive datacenter applications are used by literally billions of people around the globe on a daily basis. By improving the efficiency of network operations, results from this project can dramatically reduce the cost of provisioning existing public services, like Wikipedia, as well as make it much cheaper for new public services to be developed. By enabling the deployment of more effective resource allocation protocols on flexible switches, this work also has the potential to provide substantial improvements to the networking performance within datacenters.  The researchers will publicly release the developed software and enable a rich set of network protocols and high-performance datacenter applications.</AbstractNarration>
<MinAmdLetterDate>08/29/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1616774</AwardID>
<Investigator>
<FirstName>Arvind</FirstName>
<LastName>Krishnamurthy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arvind Krishnamurthy</PI_FULL_NAME>
<EmailAddress>arvind@cs.washington.edu</EmailAddress>
<PI_PHON>2066160957</PI_PHON>
<NSF_ID>000488256</NSF_ID>
<StartDate>08/29/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xi</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xi Wang</PI_FULL_NAME>
<EmailAddress>xi@cs.washington.edu</EmailAddress>
<PI_PHON>2065435708</PI_PHON>
<NSF_ID>000684160</NSF_ID>
<StartDate>08/29/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981952350</ZipCode>
<StreetAddress><![CDATA[185 Stevens Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Emerging networking architectures are allowing for flexible and reconfigurable packet processing at line rate. These emerging technologies address a key limitation with Software Defined Networking (SDN) solutions such as OpenFlow, which allow for custom handling of flows only as part of the switch's control plane. Many network protocols, such as those that perform resource allocation, require per-packet processing, which is feasible only if the switch's data plane can be customized to the needs of the protocol. These new technologies thus have the potential to truly enable a Software Defined Data Plane, which can be leveraged by network protocols, end host stacks, and applications to achieve greater performance and isolation.</p> <p>&nbsp;</p> <p>The goal of the project is to investigate flexible packet processing functionality on NICs and switches and their potential for optimizing high performance networked systems inside the datacenter. Our work will provide new abstractions and building blocks for the use of flexible packet processing pipelines, while respecting the hardware constraints that will be associated with these upcoming technologies. Our project examines how the resulting data plane functionality can be used to implement resource allocation mechanisms inside the datacenter so as to enable congestion control, performance isolation, adaptive routing, and efficient load balancing.</p> <p><br />In particular, our aim is to understand the implications of this new paradigm for application, operating system, network protocol, and hardware design. What new network protocols are enabled by these flexible packet processing hardware?&nbsp; How to overcome the restrictions in packet processing functionality and state in these network elements? Is there a common set of building blocks that can be developed efficiently on this hardware, which can then be used across a broad class of protocols and applications? How to allow for multiple end-points and applications to install endpoint specific processing operations on these switches without compromising security and performance? How to design end-host stacks that best work with these programmable switches and NICs? And how to co-design datacenter applications to take advantage of the performance benefits enabled by this paradigm? We aim to answer all of these questions in this project.</p> <p>&nbsp;</p> <p>The students involved in the project are a mix of junior and senior students who are getting experience in all aspects of research ? ranging from problem definition, devising solutions, implementing systems, and writing technical papers. Many of them have also started giving public talks at conferences to help disseminate their work. They are also closely working with our industry partners to better understand the hardware innovations that are happening and to perform tech transfer back to the industry. One of them just finished his dissertation and has joined Google.</p> <p>&nbsp;</p> <p>Our industry partner Cavium has started adopting many of the building blocks that we developed as part of the project as well as started supporting new hardware features on their upcoming switches based on our analysis of the limitations of today's switches.</p> <p>&nbsp;</p> <p>Network-intensive datacenter applications are used by literally billions of people around the globe on a daily basis. By improving the efficiency of network operations and reducing the overhead of I/O, we can dramatically reduce the cost of provisioning existing public services, like Wikipedia, as well as make it much cheaper for new public services to be developed.</p><br> <p>            Last Modified: 10/21/2019<br>      Modified by: Arvind&nbsp;Krishnamurthy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Emerging networking architectures are allowing for flexible and reconfigurable packet processing at line rate. These emerging technologies address a key limitation with Software Defined Networking (SDN) solutions such as OpenFlow, which allow for custom handling of flows only as part of the switch's control plane. Many network protocols, such as those that perform resource allocation, require per-packet processing, which is feasible only if the switch's data plane can be customized to the needs of the protocol. These new technologies thus have the potential to truly enable a Software Defined Data Plane, which can be leveraged by network protocols, end host stacks, and applications to achieve greater performance and isolation.     The goal of the project is to investigate flexible packet processing functionality on NICs and switches and their potential for optimizing high performance networked systems inside the datacenter. Our work will provide new abstractions and building blocks for the use of flexible packet processing pipelines, while respecting the hardware constraints that will be associated with these upcoming technologies. Our project examines how the resulting data plane functionality can be used to implement resource allocation mechanisms inside the datacenter so as to enable congestion control, performance isolation, adaptive routing, and efficient load balancing.   In particular, our aim is to understand the implications of this new paradigm for application, operating system, network protocol, and hardware design. What new network protocols are enabled by these flexible packet processing hardware?  How to overcome the restrictions in packet processing functionality and state in these network elements? Is there a common set of building blocks that can be developed efficiently on this hardware, which can then be used across a broad class of protocols and applications? How to allow for multiple end-points and applications to install endpoint specific processing operations on these switches without compromising security and performance? How to design end-host stacks that best work with these programmable switches and NICs? And how to co-design datacenter applications to take advantage of the performance benefits enabled by this paradigm? We aim to answer all of these questions in this project.     The students involved in the project are a mix of junior and senior students who are getting experience in all aspects of research ? ranging from problem definition, devising solutions, implementing systems, and writing technical papers. Many of them have also started giving public talks at conferences to help disseminate their work. They are also closely working with our industry partners to better understand the hardware innovations that are happening and to perform tech transfer back to the industry. One of them just finished his dissertation and has joined Google.     Our industry partner Cavium has started adopting many of the building blocks that we developed as part of the project as well as started supporting new hardware features on their upcoming switches based on our analysis of the limitations of today's switches.     Network-intensive datacenter applications are used by literally billions of people around the globe on a daily basis. By improving the efficiency of network operations and reducing the overhead of I/O, we can dramatically reduce the cost of provisioning existing public services, like Wikipedia, as well as make it much cheaper for new public services to be developed.       Last Modified: 10/21/2019       Submitted by: Arvind Krishnamurthy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
