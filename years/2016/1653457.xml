<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Spatial Ensemble Structure in Visual Working Memory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2017</AwardEffectiveDate>
<AwardExpirationDate>02/28/2022</AwardExpirationDate>
<AwardTotalIntnAmount>571380.00</AwardTotalIntnAmount>
<AwardAmount>571380</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Hout</SignBlockName>
<PO_EMAI>mhout@nsf.gov</PO_EMAI>
<PO_PHON>7032922163</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Visual working memory allows people to hold visual information in mind for a brief period of time, making it available for other cognitive tasks. Research investigating this memory system has found that people are capable of storing only a few of the many objects that we see in most visual scenes. However, memory does not hold only objects - we also remember large-scale spatial relationships ("spatial ensembles") that provide us with information about where objects are located and what they are like on average. The project will introduce new research methods designed to gather information about visual working memory for ensembles as well as individual objects. Visual working memory is critical for everyday functioning and closely related to fluid intelligence and academic achievement. Disruptions of working memory are common in clinical disorders like AHDH and schizophrenia. Thus, understanding how the human visual system stores information about objects and ensembles in working memory is critical for understanding important differences between individuals as well as improving our understanding of visual skills, such as those involved in driving and other complex tasks that require remembering and monitoring multiple objects and their respective locations. Understanding how memories for objects and ensembles interact can also inform the design of artificial vision systems. The research plan includes a significant outreach component, featuring both the recruitment and training of first-generation college students from underrepresented groups and the development of tools to allow scientists to conduct online experiments and teach them how to do so.&lt;br/&gt;&lt;br/&gt;The research aims to broadly understand how the working memory system makes use of ensemble structure. First, the research investigates whether memory for objects is dissociable from memory for ensemble structure (e.g., whether object memory can be preserved when ensemble memory is impaired). Second, the research asks what broader cognitive capacities might be related to working memory for ensembles. In particular, it focuses on scene recognition, with the hypothesis that rapid recognition of visual scenes may be related to ensemble representations in working memory. To investigate these issues, a set of rigorous experimental and computational techniques will be used, including a novel paradigm based on 3d-viewpoint manipulations, as well as probabilistic/Bayesian models of visual memory that can be used to dissociate object vs. ensemble contributions to performance on working memory tasks. These techniques will allow for quantitative tests of the way in which ensembles and individual objects interact in visual working memory and the way in which they relate to broader cognitive abilities.</AbstractNarration>
<MinAmdLetterDate>03/08/2017</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1653457</AwardID>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>Brady</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy Brady</PI_FULL_NAME>
<EmailAddress>timbrady@ucsd.edu</EmailAddress>
<PI_PHON>5169870465</PI_PHON>
<NSF_ID>000631287</NSF_ID>
<StartDate>03/08/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>San Diego</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930109</ZipCode>
<StreetAddress><![CDATA[Psychology, 9500 Gilman Drive, 0]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~436458</FUND_OBLG>
<FUND_OBLG>2021~134922</FUND_OBLG>
</Award>
</rootTag>
