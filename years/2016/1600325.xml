<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Early Stage Research on Automatically Identifying Instructional Moves in Mathematics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2016</AwardEffectiveDate>
<AwardExpirationDate>05/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>299928.00</AwardTotalIntnAmount>
<AwardAmount>299928</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cherniavsky</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This is an Early-concept Grant for Exploratory Research research project to develop automated tools to aid in the development of mathematics teaching expertise in preservice teachers. Current research on preservice mathematics teacher instruction relies on observing preservice teachers interacting with students and recording their mathematical interactions to provide guidance and advice as how the preservice teachers can improve their teaching. This research requires highly trained observers and highly trained analysts to record and interpret the student teacher verbal interactions in order to give teachers feed back in how to improve their instruction. The aim of this project is to automate the observation, recording, and interpretation of student-teacher interactions. This would result in more effective research on instructional strategies for the preservice teachers and ultimately lead to changes in teacher professional development when feedback only available in research environments becomes feasible for all preservice teacher professional development. &lt;br/&gt;&lt;br/&gt;The project will use as an initial basis the observation toolkit Accountablity Talk for providing teachers with both formative and summative feedback on their instruction. Automatic speech recognition and natural language technologies will be used to record and interpret student teacher verbal interactions. The results of this research have the potential to democratize preservice mathematics teacher professional development and, over time, provide insight into teacher learning that can result in restructuring teacher learning environment to make them more effective in developing high quality mathematics teachers.</AbstractNarration>
<MinAmdLetterDate>06/06/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/06/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1600325</AwardID>
<Investigator>
<FirstName>Wayne</FirstName>
<LastName>Ward</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wayne H Ward</PI_FULL_NAME>
<EmailAddress>wayne.ward@colorado.edu</EmailAddress>
<PI_PHON>3037355070</PI_PHON>
<NSF_ID>000264998</NSF_ID>
<StartDate>06/06/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tamara</FirstName>
<LastName>Sumner</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tamara R Sumner</PI_FULL_NAME>
<EmailAddress>sumner@colorado.edu</EmailAddress>
<PI_PHON>3037354469</PI_PHON>
<NSF_ID>000455689</NSF_ID>
<StartDate>06/06/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>William</FirstName>
<LastName>Penuel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>William Penuel</PI_FULL_NAME>
<EmailAddress>william.penuel@colorado.edu</EmailAddress>
<PI_PHON>3034924541</PI_PHON>
<NSF_ID>000348592</NSF_ID>
<StartDate>06/06/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Boulder</Name>
<CityName>Boulder</CityName>
<ZipCode>803031058</ZipCode>
<PhoneNumber>3034926221</PhoneNumber>
<StreetAddress>3100 Marine Street, Room 481</StreetAddress>
<StreetAddress2><![CDATA[572 UCB]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>007431505</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF COLORADO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431505</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Colorado Boulder]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803031058</ZipCode>
<StreetAddress><![CDATA[3100 Marine Street, Room 479]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8244</Code>
<Text>EHR CL Opportunities (NSF 14-302)</Text>
</ProgramReference>
<ProgramReference>
<Code>8817</Code>
<Text>STEM Learning &amp; Learning Environments</Text>
</ProgramReference>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~299928</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-ce0b10b6-7fff-8319-d2c8-4873bad0d73a"> </span></p> <p dir="ltr"><span>This project builds on advances in deep learning for natural language processing to automatically analyze transcribed classroom discourse and reliably generate information about teachers&rsquo; uses of specific discursive strategies called &rdquo;talk moves.&rdquo; At the heart of accountable talk is the notion that teachers should organize classroom discussions that promote students&rsquo; equitable participation in a rigorous learning environment. Talk moves can be used by both teachers and learners to construct conversations in which students share their thinking, actively consider the ideas of others, and engage in sustained reasoning. Table 1 lists the six focal talk moves considered in this study, along with an example of each move.</span></p> <p dir="ltr"><span>&nbsp;</span>Currently, providing teachers with detailed feedback about the talk moves in their lessons requires highly trained observers to hand code transcripts of classroom recordings and analyze talk moves and/or one-on-one expert coaching, a time-consuming and expensive process that is unlikely to scale. Tools capable of automating parts of this complex coding and analysis process would amplify the research process and democratize access to quality feedback by putting this type of feedback into the reach of teachers.</p> <p dir="ltr">A central premise of this research is that personalized, automated feedback has the potential to dramatically enhance teacher learning and support improvements in their instruction. In addition, the targeted instructional practices, focused on engagement in equitable discourse practices, have important implications for teachers&rsquo; ability to provide high-quality opportunities to learn mathematics to children who have historically not been exposed to the instructional practices experienced by their more privileged peers.</p> <p dir="ltr">The project investigated the critical components for a new form of educational cyberinfrastructure based on the automatic processing of classroom transcripts. Specifically, the project created a bidirectional long short-term memory (bi-LSTM) network that can automate the annotation of talk moves. Figure 1 shows how information flows through the model architecture.</p> <p><span id="docs-internal-guid-91499794-7fff-1d7c-d6a6-aee5fc91d0ba"> </span></p> <p dir="ltr"><span> The data used for training the talk moves classification model were sourced from multiple, existing professional learning resources for math teachers. These data include 100,683 sentences, of which 60,241 are teacher sentences and 40,442 are student sentences. Of the teacher sentences, 54.49% contain one of the six talk moves included in this study. </span></p> <p dir="ltr">To develop the BiLSTM model, the project used a standard supervised machine learning procedure with the following steps: (1) Preprocess the data to prepare it for input into the model, (2) Divide the pre-processed data into training, validation and test sets, where 80% of the data was used for model training; 10% was used for adjusting model parameters (validation); and 10% was reserved for model evaluation. (3) Run the trained model on the test set, comparing the model&rsquo;s predicted talk move labels to the labels assigned by our expert human annotators. To determine what the model has learned, calculate model performance on the test set, as measured by F1 scores, across all the sentences with talk move labels. (4) Analyze model performance and make enhancements to model architecture. (5) Iterate process to see how accuracy improves, adding new data as they become available.</p> <p dir="ltr"><span>Project results demonstrate the feasibility of this deep learning approach to reliably identify a set of teacher talk moves at the sentence level with an F1 measure of 65%, representing up to 74% gain over the class baseline. &nbsp;Overall, this level of model performance is very encouraging, particularly considering that the amount of training data (100k sentences) used is relatively modest by deep learning standards and, to date, only a few basic features were included to represent the data. Analyses to assess the impact of additional data on model performance indicate linear growth corresponding to an increase in training data, as shown in Figure 2. </span></p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/15/2018<br>      Modified by: Tamara&nbsp;R&nbsp;Sumner</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364185231_OutcomesTable1jpg--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364185231_OutcomesTable1jpg--rgov-800width.jpg" title="Table 1."><img src="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364185231_OutcomesTable1jpg--rgov-66x44.jpg" alt="Table 1."></a> <div class="imageCaptionContainer"> <div class="imageCaption">The six talk moves used in this study</div> <div class="imageCredit">None</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tamara&nbsp;R&nbsp;Sumner</div> <div class="imageTitle">Table 1.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364043277_OutcomesFig1jpg--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364043277_OutcomesFig1jpg--rgov-800width.jpg" title="Figure 1."><img src="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364043277_OutcomesFig1jpg--rgov-66x44.jpg" alt="Figure 1."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Model flow used to generate a probability distribution of talk Moves</div> <div class="imageCredit">None</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tamara&nbsp;R&nbsp;Sumner</div> <div class="imageTitle">Figure 1.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364260095_Outcomesfig2jpg--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364260095_Outcomesfig2jpg--rgov-800width.jpg" title="Figure 2."><img src="/por/images/Reports/POR/2018/1600325/1600325_10431333_1534364260095_Outcomesfig2jpg--rgov-66x44.jpg" alt="Figure 2."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Projected model performance for different proportions of training samples</div> <div class="imageCredit">None</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tamara&nbsp;R&nbsp;Sumner</div> <div class="imageTitle">Figure 2.</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   This project builds on advances in deep learning for natural language processing to automatically analyze transcribed classroom discourse and reliably generate information about teachers? uses of specific discursive strategies called "talk moves." At the heart of accountable talk is the notion that teachers should organize classroom discussions that promote students? equitable participation in a rigorous learning environment. Talk moves can be used by both teachers and learners to construct conversations in which students share their thinking, actively consider the ideas of others, and engage in sustained reasoning. Table 1 lists the six focal talk moves considered in this study, along with an example of each move.  Currently, providing teachers with detailed feedback about the talk moves in their lessons requires highly trained observers to hand code transcripts of classroom recordings and analyze talk moves and/or one-on-one expert coaching, a time-consuming and expensive process that is unlikely to scale. Tools capable of automating parts of this complex coding and analysis process would amplify the research process and democratize access to quality feedback by putting this type of feedback into the reach of teachers. A central premise of this research is that personalized, automated feedback has the potential to dramatically enhance teacher learning and support improvements in their instruction. In addition, the targeted instructional practices, focused on engagement in equitable discourse practices, have important implications for teachers? ability to provide high-quality opportunities to learn mathematics to children who have historically not been exposed to the instructional practices experienced by their more privileged peers. The project investigated the critical components for a new form of educational cyberinfrastructure based on the automatic processing of classroom transcripts. Specifically, the project created a bidirectional long short-term memory (bi-LSTM) network that can automate the annotation of talk moves. Figure 1 shows how information flows through the model architecture.     The data used for training the talk moves classification model were sourced from multiple, existing professional learning resources for math teachers. These data include 100,683 sentences, of which 60,241 are teacher sentences and 40,442 are student sentences. Of the teacher sentences, 54.49% contain one of the six talk moves included in this study.  To develop the BiLSTM model, the project used a standard supervised machine learning procedure with the following steps: (1) Preprocess the data to prepare it for input into the model, (2) Divide the pre-processed data into training, validation and test sets, where 80% of the data was used for model training; 10% was used for adjusting model parameters (validation); and 10% was reserved for model evaluation. (3) Run the trained model on the test set, comparing the model?s predicted talk move labels to the labels assigned by our expert human annotators. To determine what the model has learned, calculate model performance on the test set, as measured by F1 scores, across all the sentences with talk move labels. (4) Analyze model performance and make enhancements to model architecture. (5) Iterate process to see how accuracy improves, adding new data as they become available. Project results demonstrate the feasibility of this deep learning approach to reliably identify a set of teacher talk moves at the sentence level with an F1 measure of 65%, representing up to 74% gain over the class baseline.  Overall, this level of model performance is very encouraging, particularly considering that the amount of training data (100k sentences) used is relatively modest by deep learning standards and, to date, only a few basic features were included to represent the data. Analyses to assess the impact of additional data on model performance indicate linear growth corresponding to an increase in training data, as shown in Figure 2.                    Last Modified: 08/15/2018       Submitted by: Tamara R Sumner]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
