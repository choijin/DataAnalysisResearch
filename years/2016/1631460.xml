<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: NCS-FO: Learning Efficient Visual Representations From Realistic Environments Across Time Scales</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>479015.00</AwardTotalIntnAmount>
<AwardAmount>479015</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
<PO_EMAI>jdonlon@nsf.gov</PO_EMAI>
<PO_PHON>7032928074</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer vision algorithms examine images and make sense of what these images depict. Current computer vision algorithms  are able to interpret images at the level of a typical middle school student for many image interpretation tasks.  Recent advances in computer vision have led to rapid technological advances which are still unfolding but affect not only the technology industry, but education,  national security and health care. However, these new algorithms are as yet poorly understood and do not describe how natural learners such as a typical middle school student learn to understand the visual world.  This proposal draws together a team of cognitive psychologists, neuroscientists, and computer scientists to develop a new class of algorithms for computer vision inspired by the way people learn.  &lt;br/&gt;&lt;br/&gt;The key insight of this proposal is that human learners, unlike many leading computer vision techniques, make extensive use of the temporal structure of visual experience to extract structure.  In the real world the image  on the human retina is almost never static.   Changes in eye position and movements of the head and body create a rich and complex temporal structure over a range of scales from hundreds of milliseconds up to days and weeks. This proposal a) develops databases of realistic and dynamically changing images in the real world and in immersive virtual reality environments, b) develops computational models for learning visual representations from temporally structured experiences  and, c) examines the brain structures supporting representations integrating time and space across scales using fMRI. The algorithms pursued in this project are inspired by recent theoretical work in the neuroscience of scale-invariant memory.  However, because the databases will be made publicly available, other researchers will be able to develop other algorithms that exploit temporal and spatial correlations.  Taken together, these efforts are intended to catalyze a new generation of techniques for human-like machine learning algorithms with applications in computer vision.</AbstractNarration>
<MinAmdLetterDate>08/10/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/10/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1631460</AwardID>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Howard</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marc W Howard</PI_FULL_NAME>
<EmailAddress>marc777@bu.edu</EmailAddress>
<PI_PHON>6175551212</PI_PHON>
<NSF_ID>000596243</NSF_ID>
<StartDate>08/10/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022151300</ZipCode>
<StreetAddress><![CDATA[881 Commonwealth Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>8551</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~479015</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project was a collaboration between cognitive neuroscientists studying the brain, cognitive scientists studying how people perceive and think, and machine learning researchers studying computational algorithms used in artificial intelligence.&nbsp; The project resulted in progress towards a set of brain-inspired computational tools that may one day improve machine intelligence.&nbsp;&nbsp;</p> <p>In typical artificial intelligence applications, memory for recent events is stored in a buffer of fixed capacity.&nbsp; If the buffer has N slots, it holds perfect memory for the last N events but has no information about the N+1.&nbsp; For instance in an application to learn to play video games, the buffer might hold the last N frames of the display leading up to the present.&nbsp; A limitation of this approach is that if the information that one needs to predict the future was more than N steps in the past, it cannot help to guide behavior.&nbsp; In our brain-inspired buffer, which we refer to as a SITH (Scale-Invariant Temporal History) buffer, memory decays gradually.&nbsp; The most recent slot holds the most recent event with precision but additional slots hold an average over the past with decreasing accuracy.&nbsp; The way the memory is distributed means that with N slots, the SITH buffer holds some information about frames e^N steps in the past, an exponential growth.&nbsp; The idea is that the decrease in precision about the time of an event far in the past is worth the ability to know something about the recent past.&nbsp; Colloquially, although it might be a big help to know whether something happened one second ago or two seconds ago, it does not make much difference to know whether an event happened 1000 seconds ago or 1001 seconds ago.&nbsp; By sacrificing relative accuracy the model can gain some information about time steps in the distant past.&nbsp; Figure 1 shows an example of a simple video game application equipped with different forms of memory.&nbsp; The SITH buffer enables the model to perform well even when the last several frames of the video are obscured.</p> <p>This project has pursued related ideas in the fields of natural language processing, memory, and vision.</p><br> <p>            Last Modified: 01/08/2021<br>      Modified by: Marc&nbsp;W&nbsp;Howard</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1631460/1631460_10449104_1610127308069_Figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1631460/1631460_10449104_1610127308069_Figure1--rgov-800width.jpg" title="Figure 1"><img src="/por/images/Reports/POR/2021/1631460/1631460_10449104_1610127308069_Figure1--rgov-66x44.jpg" alt="Figure 1"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Brain-inspired memory enhances the ability of AI applications.  A video-game-learning program was equipped with several kinds of memory and then different numbers of frames were obscured.  The SITH buffer, a brain-inspired memory, performed well even with many frames obscured.</div> <div class="imageCredit">Spears et al., 2017, bioRxiv</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Marc&nbsp;W&nbsp;Howard</div> <div class="imageTitle">Figure 1</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project was a collaboration between cognitive neuroscientists studying the brain, cognitive scientists studying how people perceive and think, and machine learning researchers studying computational algorithms used in artificial intelligence.  The project resulted in progress towards a set of brain-inspired computational tools that may one day improve machine intelligence.    In typical artificial intelligence applications, memory for recent events is stored in a buffer of fixed capacity.  If the buffer has N slots, it holds perfect memory for the last N events but has no information about the N+1.  For instance in an application to learn to play video games, the buffer might hold the last N frames of the display leading up to the present.  A limitation of this approach is that if the information that one needs to predict the future was more than N steps in the past, it cannot help to guide behavior.  In our brain-inspired buffer, which we refer to as a SITH (Scale-Invariant Temporal History) buffer, memory decays gradually.  The most recent slot holds the most recent event with precision but additional slots hold an average over the past with decreasing accuracy.  The way the memory is distributed means that with N slots, the SITH buffer holds some information about frames e^N steps in the past, an exponential growth.  The idea is that the decrease in precision about the time of an event far in the past is worth the ability to know something about the recent past.  Colloquially, although it might be a big help to know whether something happened one second ago or two seconds ago, it does not make much difference to know whether an event happened 1000 seconds ago or 1001 seconds ago.  By sacrificing relative accuracy the model can gain some information about time steps in the distant past.  Figure 1 shows an example of a simple video game application equipped with different forms of memory.  The SITH buffer enables the model to perform well even when the last several frames of the video are obscured.  This project has pursued related ideas in the fields of natural language processing, memory, and vision.       Last Modified: 01/08/2021       Submitted by: Marc W Howard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
