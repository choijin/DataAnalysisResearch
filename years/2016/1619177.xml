<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Collaborative Research: Optimizing the Human-Machine System for Citizen Science</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>359560.00</AwardTotalIntnAmount>
<AwardAmount>359560</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research aims to improve the efficiency, accuracy, and usability of online systems supporting citizen science, in which communities organized around serious scientific research projects combine the contributions of amateurs and professionals.  In order to respond most efficiently to the increasing data deluge across multiple domains, citizen science platforms need to be more dynamic and complex - incorporating intelligent task assignment and machine learning strategies. Systems that make use of both human and machine intelligence are of interest to scientists from a wide range of disciplines. Whether viewed as social machines or as active learning systems in which progressive input from humans improves machine learning, these hybrid systems exhibit complex behavior which needs to be understood for effective system design. For example, machine learning researchers have concentrated on using the large training sets produced by citizen science projects in order to train algorithms that are later applied to a full dataset. Yet this serial processing may not be the most efficient use of the human or machine effort. The main research goal of this project is to investigate how the overall efficiency of the combined human-machine system is impacted by the separate components and their related properties and what the implications are for either human or machine classifiers or both. This process will test the hypothesis that improved overall efficiency will actually reduce the load on expert human classifiers instead of, as currently required, needing larger expert training sets for machines.&lt;br/&gt; &lt;br/&gt;This project will investigate the dynamic combination of human and machine classifiers, gaining for the first time knowledge of how load can be optimally shared in a real, flexible citizen science platform. This research effort will be supported by building and deploying software modules on the existing Zooniverse infrastructure, the world-leading platform for online citizen science.  It will  (1) carry out efficient and dynamic task assignment, distinguishing in near-real time between experienced and inexperienced, and between skilled and less skilled classifiers; and (2) combine human and machine classifications dynamically, periodically training automatic classification routines on the increasing volume of training data produced by volunteers. This new software will then be utilized in a novel "cascade filtering" mode that reduces complex classification problems into a series of single binary tasks.  The software developed in this project will provide domain scientists and social machine researchers who wish to exploit the new infrastructure with a fully flexible suite of functions appropriate to the needs defined by their specific problems.</AbstractNarration>
<MinAmdLetterDate>07/06/2016</MinAmdLetterDate>
<MaxAmdLetterDate>09/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1619177</AwardID>
<Investigator>
<FirstName>Claudia</FirstName>
<LastName>Neuhauser</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Claudia M Neuhauser</PI_FULL_NAME>
<EmailAddress>cmneuhau@central.uh.edu</EmailAddress>
<PI_PHON>7137436961</PI_PHON>
<NSF_ID>000162761</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lucy</FirstName>
<LastName>Fortson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lucy Fortson</PI_FULL_NAME>
<EmailAddress>fortson@physics.umn.edu</EmailAddress>
<PI_PHON>6126249587</PI_PHON>
<NSF_ID>000079170</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554552021</ZipCode>
<StreetAddress><![CDATA[115 Union Street SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>9199</Code>
<Text>Unallocated Program Costs</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~359560</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-d82a4b75-7fff-1a21-f7b1-caf167673c15"> </span></p> <p dir="ltr"><span>Citizen Science is a method of scientific research that incorporates contributions from volunteers often by performing structured tasks such as image classification related to data presented in an online manner.&nbsp; Over the past decade, citizen science has become a proven method of distributed data analysis, enabling research teams from diverse domains to solve problems involving large quantities of data with complexity levels requiring human pattern recognition capabilities. However, human labelers alone will not be able to contend with the enormous data sets looming on the horizon with upcoming new astronomical observatories or the accelerated deployment of sensing devices for ecological monitoring goals. In fact, machine learning or artificial intelligence has advanced to the point where machine classifiers are as good in certain circumstances as human labelers - and much faster at labeling an entire data set. Nonetheless, machine classifiers are only as good as the training they receive - the best machines require large amounts of training labels (often generated by humans) covering the full range of possible answers. Human labelers are still better equipped to handle cases in which the machine lacks training data such as with complex images that may contain previously unknown astronomical phenomena or very rare species of animals.&nbsp; The best system therefore would be a system that combined the strengths of both human and machine classifiers. Thus, the work carried out by this grant focused on the research and development of a combined human-machine approach to analyzing large complex data sets - the next major step required for citizen science to operate as a critical component of knowledge production pipelines. The effort was carried out by key members of the Zooniverse.org citizen science platform including researchers and software developers at the University of Minnesota, the Adler Planetarium and the University of Oxford in the UK. The Zooniverse platform engages nearly 2 million volunteers contributing classifications on over 120 research projects ranging from astronomy to zoology.</span></p> <p dir="ltr"><span>The efforts succeeded in (1) building a system capable of efficient classification of objects, combining human and machine classification through the expansion of specific Zooniverse software and (2) with this new infrastructure, investigating the dynamic combination of human and machine classifiers, gaining knowledge of how load can be shared between the two in a real, flexible citizen science platform and gaining insights into how to best improve the efficiency of the overall combined system through implementation of specific machine classifiers. The investigations were carried out on projects in astronomy, ecology, physics and the transcription of historical texts. Specific examples of key outcomes are (1) deployment of new infrastructure within the Zooniverse.org platform to combine human and machine efforts; (2) efficiency gains in ecology camera trap projects can be made by pre-training a machine model on human labels from one ecosystem (such as the Serengeti in Africa) and applying the model on data from another ecosystem (such as the Wisconsin woods) requiring in that case only a small amount of human labels for a highly accurate animal detector; (3) increasing efficiency by nearly 50% of&nbsp; identification of images with no animals present by presenting images on the Zooniverse Mobile App that have been pre-screened by machine algorithms and asking volunteers to simply validate the machine classification; (4) deployment of an algorithm that uses information inherent in the data to cluster different types of images together and then ask volunteers to "purify" the clusters by selecting which ones don't belong together leading to classification efficiency gains of up to 80%; (5) deployment of an algorithm that only asks human labelers for information on images that the machine algorithm is highly uncertain about.  The work through this grant led to the publication of ten articles in a peer-reviewed journal or juried conference proceedings, the training of five data science masters students and four undergraduate researchers, and the career development of two female software developers.</span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/29/2019<br>      Modified by: Lucy&nbsp;Fortson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Citizen Science is a method of scientific research that incorporates contributions from volunteers often by performing structured tasks such as image classification related to data presented in an online manner.  Over the past decade, citizen science has become a proven method of distributed data analysis, enabling research teams from diverse domains to solve problems involving large quantities of data with complexity levels requiring human pattern recognition capabilities. However, human labelers alone will not be able to contend with the enormous data sets looming on the horizon with upcoming new astronomical observatories or the accelerated deployment of sensing devices for ecological monitoring goals. In fact, machine learning or artificial intelligence has advanced to the point where machine classifiers are as good in certain circumstances as human labelers - and much faster at labeling an entire data set. Nonetheless, machine classifiers are only as good as the training they receive - the best machines require large amounts of training labels (often generated by humans) covering the full range of possible answers. Human labelers are still better equipped to handle cases in which the machine lacks training data such as with complex images that may contain previously unknown astronomical phenomena or very rare species of animals.  The best system therefore would be a system that combined the strengths of both human and machine classifiers. Thus, the work carried out by this grant focused on the research and development of a combined human-machine approach to analyzing large complex data sets - the next major step required for citizen science to operate as a critical component of knowledge production pipelines. The effort was carried out by key members of the Zooniverse.org citizen science platform including researchers and software developers at the University of Minnesota, the Adler Planetarium and the University of Oxford in the UK. The Zooniverse platform engages nearly 2 million volunteers contributing classifications on over 120 research projects ranging from astronomy to zoology. The efforts succeeded in (1) building a system capable of efficient classification of objects, combining human and machine classification through the expansion of specific Zooniverse software and (2) with this new infrastructure, investigating the dynamic combination of human and machine classifiers, gaining knowledge of how load can be shared between the two in a real, flexible citizen science platform and gaining insights into how to best improve the efficiency of the overall combined system through implementation of specific machine classifiers. The investigations were carried out on projects in astronomy, ecology, physics and the transcription of historical texts. Specific examples of key outcomes are (1) deployment of new infrastructure within the Zooniverse.org platform to combine human and machine efforts; (2) efficiency gains in ecology camera trap projects can be made by pre-training a machine model on human labels from one ecosystem (such as the Serengeti in Africa) and applying the model on data from another ecosystem (such as the Wisconsin woods) requiring in that case only a small amount of human labels for a highly accurate animal detector; (3) increasing efficiency by nearly 50% of  identification of images with no animals present by presenting images on the Zooniverse Mobile App that have been pre-screened by machine algorithms and asking volunteers to simply validate the machine classification; (4) deployment of an algorithm that uses information inherent in the data to cluster different types of images together and then ask volunteers to "purify" the clusters by selecting which ones don't belong together leading to classification efficiency gains of up to 80%; (5) deployment of an algorithm that only asks human labelers for information on images that the machine algorithm is highly uncertain about.  The work through this grant led to the publication of ten articles in a peer-reviewed journal or juried conference proceedings, the training of five data science masters students and four undergraduate researchers, and the career development of two female software developers.             Last Modified: 10/29/2019       Submitted by: Lucy Fortson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
