<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps:  Real-Time Graphical Presentation for Visually Impaired STEM Students</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/18/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>20030.00</AwardTotalIntnAmount>
<AwardAmount>20030</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Steven Konsek</SignBlockName>
<PO_EMAI>skonsek@nsf.gov</PO_EMAI>
<PO_PHON>7032927021</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Visually impaired (VI) students are challenged with learning highly visual content in Science, Technology, Engineering, and Math (STEM) courses using nonvisual technologies that portray only limited details and cannot be presented in real-time. Though there is a rising number of VI individuals seeking higher educational experiences, just under a third have attained a high school diploma. This situation is exaggerated in STEM fields, where much of the content relies heavily on graphical information presented visually. These unfortunate events are not due to VI individuals being incapable of high academic achievement, but rather, due to inadequate technologies and resources provided to them. Subsequently, there exists a dire need for a portable, refreshable real-time display of graphical information via nonvisual feedback that can be easily integrated within a classroom setting. This Innovation Corps for Learning Team project aims to assess the commercial viability, market potential, and technological impact of touchscreen-based educational curriculum that will enable real-time graphical  information presentation through visual, auditory, and vibratory feedback. The proposed innovation leverages commercially available touchscreens and custom software created in the form of Android applications to translate visual content displayed on-screen into content that can be felt (through vibrations) and heard (through sound). &lt;br/&gt;&lt;br/&gt;The proposed innovation has the potential to bridge this technological gap and open up these new learning opportunities for VI students. &lt;br/&gt;The infrastructure and software in this work will promote a transformed classroom in which students with VI are independently interacting with their sighted peers and primary classroom teacher, in real-time via touchscreens. Each student would have a touchscreen that is wirelessly networked to their peers' and teacher's touchscreens (or smart board or laptop). As the teacher draws a graph or figure on his or her input device, this same image will immediately "appear," in a multimodal sense, on all of the students' touchscreens. While sighted students may primarily use the visual display of the information, students with VI can leverage vibratory and/or auditory feedback (using headphones) to explore the graphical content. This work lays the foundation for the creation of touchscreen-based educational curriculum in the form of Android applications that will (1) meet the customer need of a portable, multimodal, real-time platform for graphical information presentation, (2) enable classroom integration through the use of existing hardware, and (3) encourage widespread adoption through distribution in online application markets. The impacts of this work will not only address several barriers of graphical information transfer for VI students (a significantly underrepresented population in STEM), but will also lay the foundation for the creation of a universally-designed, learner-centered framework for touchscreens that may benefit all people, enhancing the fidelity and creating new dimensions of learning right at our fingertips.</AbstractNarration>
<MinAmdLetterDate>07/14/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/14/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1632787</AwardID>
<Investigator>
<FirstName>Jenna</FirstName>
<LastName>Gorlewicz</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jenna Gorlewicz</PI_FULL_NAME>
<EmailAddress>jenna.gorlewicz@slu.edu</EmailAddress>
<PI_PHON>3149778185</PI_PHON>
<NSF_ID>000656195</NSF_ID>
<StartDate>07/14/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Saint Louis University</Name>
<CityName>St Louis</CityName>
<ZipCode>631032006</ZipCode>
<PhoneNumber>3149773925</PhoneNumber>
<StreetAddress>221 N. Grand Blvd.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050220722</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SAINT LOUIS UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050220722</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Saint Louis University]]></Name>
<CityName>St Louis</CityName>
<StateCode>MO</StateCode>
<ZipCode>631032006</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~20030</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Consider the mainstream classroom today. The incorporation of digital technologies has opened up numerous new pathways for teaching and learning, but it inherently relies on accessing information using tools such as computers and tablets. This on-screen, visual display leaves much of the content largely inaccessible to students with special needs, and particularly, those with blindness or visual impairments. This Innovation Corps for Learning Team project assessed the commercial viability, market potential, and technological impact of a new touchscreen-based learning technology for use in Science, Technology, Engineering, and Mathematics (STEM) education that addresses this need and brings the digital classroom into a multi-sensory experience.&nbsp; This new technology uses commercially available touchscreens and custom software created in the form of Android applications to translate existing course content into accessible content that can be felt (through vibrations), heard (through sound), and seen (through vision). Conveying this information via multiple senses enables the inclusion of students of numerous learning styles, affording them opportunities to participate and succeed in the general classroom at new levels. The impacts of this work will also uncover the potential of new touchscreen technologies to transform the learning of students, particularly those with blindness and visual impairments, from passive, limited exposures into interactive, real-time classroom experiences.</p> <p>In this project, the team conducted over 140+ customer interviews with potential users of their technology, including numerous teachers of the visually impaired, assistive technology coordinators, administrators at organizations for the blind, and other influencers who offered insightful feedback which helped drive the vision of the proposed touchscreen software. These interviews also enabled the team to build out an agile business model to support the growth and sustainable scaling of the technology in the educational ecosystem. In addition to the customer discovery that was conducted, the team produced an alpha version of the software, which was demonstrated to numerous interested parties to convey the idea behind the team&rsquo;s innovation. As a result of this I-Corps L project, the team is continuing to grow and scale the innovation. Notable outcomes that were a result of the work conducted in this I-Corps L project include acceptance into Start-Up Next (a pre-accelerator sponsored by Google), the formation of a start-up company centered on bringing the technology to market, successful securing of additional funding to support the work, and continuous refinements to sustainably scale the innovation and the business. In turn, these efforts are addressing the need for a portable, refreshable, economically viable platform that provides real-time graphical information interaction for individuals with blindness and visual impairments, with the mission to provide more equal opportunities for these individuals to excel in STEM classrooms and STEM professions.</p><br> <p>            Last Modified: 08/31/2016<br>      Modified by: Jenna&nbsp;Gorlewicz</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Consider the mainstream classroom today. The incorporation of digital technologies has opened up numerous new pathways for teaching and learning, but it inherently relies on accessing information using tools such as computers and tablets. This on-screen, visual display leaves much of the content largely inaccessible to students with special needs, and particularly, those with blindness or visual impairments. This Innovation Corps for Learning Team project assessed the commercial viability, market potential, and technological impact of a new touchscreen-based learning technology for use in Science, Technology, Engineering, and Mathematics (STEM) education that addresses this need and brings the digital classroom into a multi-sensory experience.  This new technology uses commercially available touchscreens and custom software created in the form of Android applications to translate existing course content into accessible content that can be felt (through vibrations), heard (through sound), and seen (through vision). Conveying this information via multiple senses enables the inclusion of students of numerous learning styles, affording them opportunities to participate and succeed in the general classroom at new levels. The impacts of this work will also uncover the potential of new touchscreen technologies to transform the learning of students, particularly those with blindness and visual impairments, from passive, limited exposures into interactive, real-time classroom experiences.  In this project, the team conducted over 140+ customer interviews with potential users of their technology, including numerous teachers of the visually impaired, assistive technology coordinators, administrators at organizations for the blind, and other influencers who offered insightful feedback which helped drive the vision of the proposed touchscreen software. These interviews also enabled the team to build out an agile business model to support the growth and sustainable scaling of the technology in the educational ecosystem. In addition to the customer discovery that was conducted, the team produced an alpha version of the software, which was demonstrated to numerous interested parties to convey the idea behind the team?s innovation. As a result of this I-Corps L project, the team is continuing to grow and scale the innovation. Notable outcomes that were a result of the work conducted in this I-Corps L project include acceptance into Start-Up Next (a pre-accelerator sponsored by Google), the formation of a start-up company centered on bringing the technology to market, successful securing of additional funding to support the work, and continuous refinements to sustainably scale the innovation and the business. In turn, these efforts are addressing the need for a portable, refreshable, economically viable platform that provides real-time graphical information interaction for individuals with blindness and visual impairments, with the mission to provide more equal opportunities for these individuals to excel in STEM classrooms and STEM professions.       Last Modified: 08/31/2016       Submitted by: Jenna Gorlewicz]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
