<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>STTR Phase I:  Real-time Automatic Analysis of Electroencephalograms in an Intensive Care Environment Using Deep Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>223897.00</AwardTotalIntnAmount>
<AwardAmount>223897</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jesus Soriano Molla</SignBlockName>
<PO_EMAI>jsoriano@nsf.gov</PO_EMAI>
<PO_PHON>7032927795</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact / commercial potential of this Small Business Technology Transfer Phase I project is enabling real-time seizure detection in intensive care units ? especially units at hospitals without 24/7 neurologist coverage to interpret scans in a timely manner. High performance real-time detection of critical EEG events in an ICU setting will increase the use of brain monitoring in critical care, thereby improving patient outcomes, increasing the efficiency of healthcare and decreasing the cognitive burden placed on caregivers. Current approaches to automatic detection suffer from unacceptably high false alarm rates that overwhelm care providers, and are of limited use in this environment. A reliable service would expand access to quality care for 877,500 neurologically compromised critical care patients in 4,000+ community hospitals in the United States. The market opportunity for real-time seizure detection in the ICU is approximately $80M per year. &lt;br/&gt; &lt;br/&gt;The proposed project will develop an assistive technology for EEG analysis to support clinicians in evaluating EEG signals for medically important events in an ICU environment. Analysis of EEG signals requires a highly trained neurologist, and is time consuming and expensive since identifying rare clinical events requires analysis of long data streams. Most community hospitals do not have 24/7 access to trained neurologists and can not provide continuous EEG monitoring to detect non-convulsive seizures in neurologically compromised patients. Reliable automatic detection improves patient access to long-term brain monitoring by auto-scanning EEG signals and flagging sections of the signal that need further review by a clinician. The tool reduces the amount of data needing manual review by two orders of magnitude, offering substantial productivity gains in a clinical setting. The project will leverage an innovative approach for integrating hidden Markov models, deep learning and active learning to allow the rapid development of a high performance machine learning system from minimal amounts of manually annotated data.  The resulting automatic analysis will achieve 95% detection accuracy for seizures with a false alarm rate of 1 per 8-hour period.</AbstractNarration>
<MinAmdLetterDate>06/29/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1622765</AwardID>
<Investigator>
<FirstName>Joseph</FirstName>
<LastName>Picone</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joseph Picone</PI_FULL_NAME>
<EmailAddress>joseph.picone@gmail.com</EmailAddress>
<PI_PHON>6623124209</PI_PHON>
<NSF_ID>000301445</NSF_ID>
<StartDate>06/29/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meysam</FirstName>
<LastName>Golmohammadi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meysam Golmohammadi</PI_FULL_NAME>
<EmailAddress>tuf76412@temple.edu</EmailAddress>
<PI_PHON>6099023633</PI_PHON>
<NSF_ID>000709190</NSF_ID>
<StartDate>06/29/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>BioSignal Analytics, Inc</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191045532</ZipCode>
<PhoneNumber>6099023633</PhoneNumber>
<StreetAddress>3711 Market St Ste 800</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079939241</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BIOSIGNAL ANALYTICS, INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[BioSignal Analytics, Inc.]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191045532</ZipCode>
<StreetAddress><![CDATA[3711 Market Street, Suite 800]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1505</Code>
<Text>STTR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>1505</Code>
<Text>STTR PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8023</Code>
<Text>Health Care Enterprise Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8042</Code>
<Text>Health and Safety</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~223897</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The Phase I STTR was executed by BioSignal Analytics, Inc. (BSA) &ndash; a startup company located in Philadelphia, Pennsylvania. This company was a spinoff of research conducted by the Neural Engineering Data Consortium (NEDC) located at Temple University (TU). The startup was initially funded through a seed investment from a joint venture between TU and Phase 1 Ventures (P1V) of University City Science Center (UCSC). BSA collaborates very closely with TU, and the original PIs at TU are major shareholders in the company. BSA&rsquo;s first full-time employee, PI Golmohammadi, was a PhD student at NEDC prior to the Phase I award.</p> <p>There were four major goals of our Phase I STTR project: (1) develop an annotated corpus that can be used for both technology development and evaluation; (2) transform our event detection system into a seizure detection system; (3) extend these architectures to use deep learning; and (4) collect feedback from experts.</p> <p>We developed the TUH EEG Seizure Detection Corpus to support technology development and evaluation. This resource was placed into the public domain and has over 400 subscribers. It represents a highly accurate model of the variety of EEG data seen in clinical settings. It has generated a significant amount of interest in this application. We have also acquired data from Emory University and Duke University and shown that performance is comparable across all three data sets, even though they were collected with different instrumentation and at different hospitals. Hence, we are very confident that our performance is indicative of what a typical clinical setting will see. Channel robustness appears to be excellent.</p> <p>We evaluated a variety of deep learning structures designed to exploit spatial and temporal context in the signal. We demonstrated that performance for many of the newest deep learning structures is comparable. Our flagship architecture operates on feature vectors extracted from the signal using a standard frequency domain approach, followed by Convolutional Neural Networks (CNN) and Long Short-Term Networks (LTSM). LSTM networks attempt to integrate long and short-term dependencies. These are crucial to the detection of sustained seizure events.</p> <p>We also spent a significant amount of effort developing a comprehensive evaluation paradigm. We used these tools to benchmark our annotation team and demonstrate that our ability to annotate data rivaled, and often exceeded, expert neurologists. We also used these tools to monitor inter-rater agreement to provide evidence of the accuracy of our reference annotations and evaluation paradigm. We introduced several new performance metrics, including Actual Term-Weighted Value, Time-Aligned Event Scoring and Kappa/Fleiss statistics. This suite of scoring software provides us with a detailed analysis of system performance.</p> <p>The needed levels of performance are extremely challenging for even conventional machine learning systems. However, inter-rater agreement on this task is moderate. Sensitivity is on the order of 75% and kappa statistics hover in the range of 0.4 to 0.6. When you couple this with the fact that providers are overwhelmed with data when EEGs are conducted for long periods of time (e.g. 72 hours), it becomes clear that human performance is focused on detecting major events, but not minor events such as short seizures lasting less than 10 secs. Further, human review occurs only periodically &ndash; from 2 hours to 12 hours &ndash; so there can be a long latency from the start of a seizure to when a physician is aware that the patient is seizing. Our primary objective is to achieve a level of sensitivity and specificity that approaches human performance and is acceptable for clinical applications.</p> <p>The best overall system was the combination of CNN and LSTM. This doubly deep recurrent convolutional structure models both spatial relationships (e.g., cross-channel dependencies) and temporal dynamics (e.g., spikes). The depth of the convolutional network is important since the top convolutional layers tend to learn generic features while the deeper layers learn dataset specific features. Performance degrades if a single convolutional layer is removed. We further reduced the error rate by reconfiguring the training process. By manually segmenting the data so that there is a proper balance between background and seizure events, we reduced the false alarm rate to 10 false alarms per 24 hours at a 30% sensitivity. This represents our overall best result at the end of our Phase I STTR project.</p> <p>Our evaluation data contains a higher incidence of seizures as well as annotations of both long and short seizures. If we were to evaluate on typical clinical data and focus on long seizures, our false alarm rates approach our long-term goal of 1 per 24 hours at a sensitivity of approximately 50%. Inter-rater agreement for humans is approximately 75% under optimal conditions. Our sensitivity on these long events is approaching human performance though there is still a gap. Feedback from experts on this level of performance has been encouraging.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/29/2017<br>      Modified by: Joseph&nbsp;Picone</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The Phase I STTR was executed by BioSignal Analytics, Inc. (BSA) &ndash; a startup company located in Philadelphia, Pennsylvania. This company was a spinoff of research conducted by the Neural Engineering Data Consortium (NEDC) located at Temple University (TU). The startup was initially funded through a seed investment from a joint venture between TU and Phase 1 Ventures (P1V) of University City Science Center (UCSC). BSA collaborates very closely with TU, and the original PIs at TU are major shareholders in the company. BSA?s first full-time employee, PI Golmohammadi, was a PhD student at NEDC prior to the Phase I award.  There were four major goals of our Phase I STTR project: (1) develop an annotated corpus that can be used for both technology development and evaluation; (2) transform our event detection system into a seizure detection system; (3) extend these architectures to use deep learning; and (4) collect feedback from experts.  We developed the TUH EEG Seizure Detection Corpus to support technology development and evaluation. This resource was placed into the public domain and has over 400 subscribers. It represents a highly accurate model of the variety of EEG data seen in clinical settings. It has generated a significant amount of interest in this application. We have also acquired data from Emory University and Duke University and shown that performance is comparable across all three data sets, even though they were collected with different instrumentation and at different hospitals. Hence, we are very confident that our performance is indicative of what a typical clinical setting will see. Channel robustness appears to be excellent.  We evaluated a variety of deep learning structures designed to exploit spatial and temporal context in the signal. We demonstrated that performance for many of the newest deep learning structures is comparable. Our flagship architecture operates on feature vectors extracted from the signal using a standard frequency domain approach, followed by Convolutional Neural Networks (CNN) and Long Short-Term Networks (LTSM). LSTM networks attempt to integrate long and short-term dependencies. These are crucial to the detection of sustained seizure events.  We also spent a significant amount of effort developing a comprehensive evaluation paradigm. We used these tools to benchmark our annotation team and demonstrate that our ability to annotate data rivaled, and often exceeded, expert neurologists. We also used these tools to monitor inter-rater agreement to provide evidence of the accuracy of our reference annotations and evaluation paradigm. We introduced several new performance metrics, including Actual Term-Weighted Value, Time-Aligned Event Scoring and Kappa/Fleiss statistics. This suite of scoring software provides us with a detailed analysis of system performance.  The needed levels of performance are extremely challenging for even conventional machine learning systems. However, inter-rater agreement on this task is moderate. Sensitivity is on the order of 75% and kappa statistics hover in the range of 0.4 to 0.6. When you couple this with the fact that providers are overwhelmed with data when EEGs are conducted for long periods of time (e.g. 72 hours), it becomes clear that human performance is focused on detecting major events, but not minor events such as short seizures lasting less than 10 secs. Further, human review occurs only periodically &ndash; from 2 hours to 12 hours &ndash; so there can be a long latency from the start of a seizure to when a physician is aware that the patient is seizing. Our primary objective is to achieve a level of sensitivity and specificity that approaches human performance and is acceptable for clinical applications.  The best overall system was the combination of CNN and LSTM. This doubly deep recurrent convolutional structure models both spatial relationships (e.g., cross-channel dependencies) and temporal dynamics (e.g., spikes). The depth of the convolutional network is important since the top convolutional layers tend to learn generic features while the deeper layers learn dataset specific features. Performance degrades if a single convolutional layer is removed. We further reduced the error rate by reconfiguring the training process. By manually segmenting the data so that there is a proper balance between background and seizure events, we reduced the false alarm rate to 10 false alarms per 24 hours at a 30% sensitivity. This represents our overall best result at the end of our Phase I STTR project.  Our evaluation data contains a higher incidence of seizures as well as annotations of both long and short seizures. If we were to evaluate on typical clinical data and focus on long seizures, our false alarm rates approach our long-term goal of 1 per 24 hours at a sensitivity of approximately 50%. Inter-rater agreement for humans is approximately 75% under optimal conditions. Our sensitivity on these long events is approaching human performance though there is still a gap. Feedback from experts on this level of performance has been encouraging.          Last Modified: 08/29/2017       Submitted by: Joseph Picone]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
