<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: Fostering Self-Correcting Reasoning with Reflection Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>549958.00</AwardTotalIntnAmount>
<AwardAmount>549958</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amy Baylor</SignBlockName>
<PO_EMAI>abaylor@nsf.gov</PO_EMAI>
<PO_PHON>7032925126</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research project is exploring how to support reasoning about wicked problems. These are societal important problems that are characterized by incomplete or contradictory knowledge, have a large body of differing opinion on the problem, have a large economic burden, and are intimately interconnected with other problems. An example of such a problem is poverty.  Poverty is linked with education, nutrition to poverty, the economy with nutrition, etc.  Reasoning about such problems and coming up with partial solutions is an important learning activity. One aspect of approaching wicked problems is through the use of reflection to guide argumentation. This project explores supporting reflection in undergraduate students with software that supports the reflection process and software that aims to improve the quality of arguments. This software builds upon both visualizations of arguments and a structured format, known as the Vee diagram, that structures good argumentation through a process of studying, questions synthesis, and finally analysis and reflection. &lt;br/&gt;&lt;br/&gt;More specifically, the researchers analyze how experts approach wicked problems, how they engage in reflection, and how they assess and improve the quality of their arguments. Results of these experiments with experts will be incorporated into Computer Supported Argument Visualization (CSAV) tools. The approaches explored in this project are of two types: the use of templates to trigger reflection and the use of scripts to provide a structure to reason about an issue. As a starting point, the researchers build upon the argumentation Vee diagram for the first approach and the AGORA software, which has been developed by the PI, as an approach for a script-based approach.   Results of the experiments will contribute to an understanding of how reflective learning and self-correcting reasoning can be fostered by assessing specific features of reflection tools and interactions scripts. Research results enable known obstacles to self-improvement, such as students' implicit assumptions about the nature and certainty of knowledge and bias, to be addressed through educational interventions.</AbstractNarration>
<MinAmdLetterDate>08/31/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1623419</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Catrambone</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard Catrambone</PI_FULL_NAME>
<EmailAddress>richard.catrambone@psych.gatech.edu</EmailAddress>
<PI_PHON>4048942680</PI_PHON>
<NSF_ID>000222775</NSF_ID>
<StartDate>08/31/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Hoffmann</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael H Hoffmann</PI_FULL_NAME>
<EmailAddress>michael.hoffmann@pubpolicy.gatech.edu</EmailAddress>
<PI_PHON>4043856083</PI_PHON>
<NSF_ID>000066947</NSF_ID>
<StartDate>08/31/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeremy</FirstName>
<LastName>Lingle</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeremy Lingle</PI_FULL_NAME>
<EmailAddress>jeremy.lingle@ceismc.gatech.edu</EmailAddress>
<PI_PHON>4048944819</PI_PHON>
<NSF_ID>000656970</NSF_ID>
<StartDate>08/31/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8244</Code>
<Text>EHR CL Opportunities (NSF 14-302)</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~549958</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Reflection and self-correcting reasoning are a crucial foundation for critical thinking and self-regulated learning. They are at the core of scientific reasoning and a precondition for participating competently and confidently in civic deliberation. To correct thinking errors, to identify gaps and weaknesses in reasoning, to counter the influence of biases, and to take new information and alternative points of view into account, students need to cultivate reflection and self-correcting reasoning skills.</p> <p>To provide, for the first time, an educational opportunity that focuses specifically on acquiring these skills, the project created the Reflect! platform which is now available at <a href="https://reflect.gatech.edu/">https://reflect.gatech.edu/</a>. The platform is a &ldquo;reflection system,&rdquo; a new kind of socio-technical system in which software tools with reflection-promoting user guidance are integrated in specifically designed social interaction scripts that scaffold the activities of students in a sequence of steps to optimize learning.</p> <p>The Reflect! platform organizes activities and collaboration in multiple teams in a class; each with about four students who engage in problem-based learning. They work on a specific kind of problem, so-called wicked problems. Wicked problems&mdash;that is, problems that can be framed in a number of different ways, depending on who is considering them&mdash;require ongoing reflection and self-correction. Wicked problems are all around us: How should we design AI systems that are used in education? How should we deal with specific environmental challenges? Even though wicked problems pose both ethical challenges (overlooking people who might be harmed) and cognitive ones (complexity, confusion), there are hardly any educational approaches that prepare students for dealing with these problems.</p> <p>With the Reflect! platform, students can be familiarized with a particular strategy to approach wicked problems. This strategy is implemented in a variety of &ldquo;work plans&rdquo; that guide both individual students and teams through activities such as problem framing, stakeholder analysis, and the creation of a consensus proposal that might satisfy all stakeholders. Depending on the work plan, projects can last from four to fourteen team meetings. A detailed discussion of the Reflect! approach to wicked problems and how the platform can be used in the classroom has been published by Michael Hoffmann in a peer-reviewed article<em></em>: <a href="https://doi.org/10.1007/s11948-019-00132-0">https://doi.org/10.1007/s11948-019-00132-0</a>.</p> <p>Besides creating, testing, and continuously improving the Reflect! platform, the project contributed to research in philosophy, education, and computer science:</p> <p>Philosophy:</p> <ul> <li>We contributed to research on the definition of wicked problems, their ethical challenges, and strategies for coping with them.</li> <li>Based on Task Analysis by Problem Solving (TAPS), we were able to create and define a list of seven criteria that will be important for research on argument quality.</li> </ul> <p>Education:</p> <ul> <li>By implementing these seven criteria into a first version of an Argument Assessment Tutor (<a href="https://reflect.gatech.edu/aat/">https://reflect.gatech.edu/aat/</a>), we created an online learning tool with which students can train the assessment of arguments.</li> <li>With the Reflect! platform, we created the first broadly usable tool to familiarize students with strategies to cope with wicked problems.</li> </ul> <p>Computer science:</p> <ul> <li>With the development of the Argument Assessment Tutor (AAT), we contribute to research on intelligent tutoring systems (ITS)</li> <li> </li> <li>With the Reflect! platform, we contribute to research on scripted user guidance in online learning systems and on the integration of various visualization techniques that are designed to reduce cognitive load in these systems.</li> </ul> <p>Finally, we conducted two empirical studies. In the first one we developed an instrument&mdash;the Self-correcting Reasoning Assessment (SecRA)&mdash;to measure whether working with the Reflect! platform has an effect on self-correcting reasoning compared to a control group, and we tried to measure such an effect. In the second study we tried to show that students who worked for four weeks with an argument mapping tool that was specifically designed, in an earlier project, to promote reflection, are able to create argument maps of higher quality than students in two control conditions.</p> <p>The SecRA instrument did not reveal superior self-correcting reasoning by students who worked with the Reflect! platform. In addition, students using the argument mapping tool did not create superior argument maps. This suggests to us at least two fruitful avenues to pursue in future research.</p> <p>The first is to improve our instruments and interventions. We believe the SecRA can be revised to be more sensitive to picking up changes in self-correcting reasoning. We also believe that the argument mapping tool can be improved to emphasize the disconnect between the reasons and conclusion students frequently offer in arguments.</p> <p>The second avenue of research is based on the recognition that we conducted our experiments only with students at our Research I university. They, obviously, managed to get into our Institute with just those highly developed argument skills that we tried to foster with our intervention. It would be prudent in future work to include students of varying skill levels, pursuing a variety of academic degrees, and in diverse educational settings.</p><br> <p>            Last Modified: 11/30/2020<br>      Modified by: Michael&nbsp;H&nbsp;Hoffmann</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Reflection and self-correcting reasoning are a crucial foundation for critical thinking and self-regulated learning. They are at the core of scientific reasoning and a precondition for participating competently and confidently in civic deliberation. To correct thinking errors, to identify gaps and weaknesses in reasoning, to counter the influence of biases, and to take new information and alternative points of view into account, students need to cultivate reflection and self-correcting reasoning skills.  To provide, for the first time, an educational opportunity that focuses specifically on acquiring these skills, the project created the Reflect! platform which is now available at https://reflect.gatech.edu/. The platform is a "reflection system," a new kind of socio-technical system in which software tools with reflection-promoting user guidance are integrated in specifically designed social interaction scripts that scaffold the activities of students in a sequence of steps to optimize learning.  The Reflect! platform organizes activities and collaboration in multiple teams in a class; each with about four students who engage in problem-based learning. They work on a specific kind of problem, so-called wicked problems. Wicked problems&mdash;that is, problems that can be framed in a number of different ways, depending on who is considering them&mdash;require ongoing reflection and self-correction. Wicked problems are all around us: How should we design AI systems that are used in education? How should we deal with specific environmental challenges? Even though wicked problems pose both ethical challenges (overlooking people who might be harmed) and cognitive ones (complexity, confusion), there are hardly any educational approaches that prepare students for dealing with these problems.  With the Reflect! platform, students can be familiarized with a particular strategy to approach wicked problems. This strategy is implemented in a variety of "work plans" that guide both individual students and teams through activities such as problem framing, stakeholder analysis, and the creation of a consensus proposal that might satisfy all stakeholders. Depending on the work plan, projects can last from four to fourteen team meetings. A detailed discussion of the Reflect! approach to wicked problems and how the platform can be used in the classroom has been published by Michael Hoffmann in a peer-reviewed article: https://doi.org/10.1007/s11948-019-00132-0.  Besides creating, testing, and continuously improving the Reflect! platform, the project contributed to research in philosophy, education, and computer science:  Philosophy:  We contributed to research on the definition of wicked problems, their ethical challenges, and strategies for coping with them. Based on Task Analysis by Problem Solving (TAPS), we were able to create and define a list of seven criteria that will be important for research on argument quality.   Education:  By implementing these seven criteria into a first version of an Argument Assessment Tutor (https://reflect.gatech.edu/aat/), we created an online learning tool with which students can train the assessment of arguments. With the Reflect! platform, we created the first broadly usable tool to familiarize students with strategies to cope with wicked problems.   Computer science:  With the development of the Argument Assessment Tutor (AAT), we contribute to research on intelligent tutoring systems (ITS)   With the Reflect! platform, we contribute to research on scripted user guidance in online learning systems and on the integration of various visualization techniques that are designed to reduce cognitive load in these systems.   Finally, we conducted two empirical studies. In the first one we developed an instrument&mdash;the Self-correcting Reasoning Assessment (SecRA)&mdash;to measure whether working with the Reflect! platform has an effect on self-correcting reasoning compared to a control group, and we tried to measure such an effect. In the second study we tried to show that students who worked for four weeks with an argument mapping tool that was specifically designed, in an earlier project, to promote reflection, are able to create argument maps of higher quality than students in two control conditions.  The SecRA instrument did not reveal superior self-correcting reasoning by students who worked with the Reflect! platform. In addition, students using the argument mapping tool did not create superior argument maps. This suggests to us at least two fruitful avenues to pursue in future research.  The first is to improve our instruments and interventions. We believe the SecRA can be revised to be more sensitive to picking up changes in self-correcting reasoning. We also believe that the argument mapping tool can be improved to emphasize the disconnect between the reasons and conclusion students frequently offer in arguments.  The second avenue of research is based on the recognition that we conducted our experiments only with students at our Research I university. They, obviously, managed to get into our Institute with just those highly developed argument skills that we tried to foster with our intervention. It would be prudent in future work to include students of varying skill levels, pursuing a variety of academic degrees, and in diverse educational settings.       Last Modified: 11/30/2020       Submitted by: Michael H Hoffmann]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
