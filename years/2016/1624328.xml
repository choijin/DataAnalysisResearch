<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS: Synergy: Collaborative Research: Autonomy Protocols: From Human Behavioral Modeling to Correct-By-Construction, Scalable Control</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2016</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>515512.00</AwardTotalIntnAmount>
<AwardAmount>515512</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Corman</SignBlockName>
<PO_EMAI>dcorman@nsf.gov</PO_EMAI>
<PO_PHON>7032928754</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer systems are increasingly coming to be relied upon to augment or replace human operators in controlling mechanical devices in contexts such as transportation systems, chemical plants, and medical devices, where safety and correctness are critical. A central problem is how to verify that such partially automated or fully autonomous cyber-physical systems (CPS) are worthy of our trust. One promising approach involves synthesis of the computer implementation codes from formal specifications, by software tools. This project contributes to this "correct-by-construction" approach, by developing scalable, automated methods for the synthesis of control protocols with provable correctness guarantees, based on insights from models of human behavior. It targets: (i) the gap between the capabilities of today's hardly autonomous, unmanned systems and the levels of capability at which they can make an impact on our use of monetary, labor, and time resources; and (ii) the lack of computational, automated, scalable tools suitable for the specification, synthesis and verification of such autonomous systems.&lt;br/&gt;&lt;br/&gt;The research is based on study of modular reinforcement learning-based models of human behavior derived through experiments designed to elicit information on how humans control complex interactive systems in dynamic environments, including automobile driving. Architectural insights and stochastic models from this study are incorporated with a specification language based on linear temporal logic, to guide the synthesis of adaptive autonomous controllers. Motion planning and other dynamic decision-making are by algorithms based on computational engines that represent the underlying physics, with provision for run-time adaptation to account for changing operational and environmental conditions. Tools implementing this methodology are validated through experimentation in a virtual testing facility in the context of autonomous driving in urban environments and multi-vehicle autonomous navigation of micro-air vehicles in dynamic environments. Education and outreach activities include involvement of undergraduate and graduate students in the research, integration of the research into courses, demonstrations for K-12 students, and recruitment of research participants from under-represented demographic groups. Data, code, and teaching materials developed by the project are disseminated publicly on the Web.</AbstractNarration>
<MinAmdLetterDate>02/05/2016</MinAmdLetterDate>
<MaxAmdLetterDate>02/05/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1624328</AwardID>
<Investigator>
<FirstName>Behcet</FirstName>
<LastName>Acikmese</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Behcet Acikmese</PI_FULL_NAME>
<EmailAddress>behcet@uw.edu</EmailAddress>
<PI_PHON>6263181002</PI_PHON>
<NSF_ID>000667284</NSF_ID>
<StartDate>02/05/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName/>
<StateCode>WA</StateCode>
<ZipCode>981950001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>8235</Code>
<Text>CPS-Synergy</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~515512</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main goal of this project is to develop mathemtical methods and algorithms to model decision making for control of autonomous robots and vehicles. Our initial hypothesis was that human behavior in similar decision-making contexts can reveal &nbsp;useful insights that can be leveraged by engineered autonomous control systems. To study this further, we have considered human decision making in limited context, specifically, in motion planning scenarios where humans make simple decisions on what targets to seek or what obstacles to avoid. To study this human behavior, we have utilized our laboratory facilities at University of Texas at Austin, which is directed by Prof. Mary Hayhoe. In this laboratory, human subjects are embedded into a virtual environment by wearing a headset. In thi set up, they are constantly presented with targets as well as obstacles in real-time. Then their eye and head motion is captured &nbsp;by the interface with the virtual environment. This data reveals how human subjects collect information and act on it in such motion scenarios. By using this data and using the reinforcement learning methods of machine learning, we have developed mathematical models to encode this human decision-making behavior. Later we have utilized these mathematical models within the general framework of Markov Decision Processes (MDPs). Such MDP models enable us to merge these insights obtained from human behavior consistently to guide the development of autonomy protocols for robots or vehicles. A key insight we obtained is that human behavior modeling can provide the basis of the MDP modeling that guide the high-level behavior of the autonomous system, e.g., how to prioritize targets to seek or obstacles to avoid. &nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/29/2018<br>      Modified by: Behcet&nbsp;Acikmese</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main goal of this project is to develop mathemtical methods and algorithms to model decision making for control of autonomous robots and vehicles. Our initial hypothesis was that human behavior in similar decision-making contexts can reveal  useful insights that can be leveraged by engineered autonomous control systems. To study this further, we have considered human decision making in limited context, specifically, in motion planning scenarios where humans make simple decisions on what targets to seek or what obstacles to avoid. To study this human behavior, we have utilized our laboratory facilities at University of Texas at Austin, which is directed by Prof. Mary Hayhoe. In this laboratory, human subjects are embedded into a virtual environment by wearing a headset. In thi set up, they are constantly presented with targets as well as obstacles in real-time. Then their eye and head motion is captured  by the interface with the virtual environment. This data reveals how human subjects collect information and act on it in such motion scenarios. By using this data and using the reinforcement learning methods of machine learning, we have developed mathematical models to encode this human decision-making behavior. Later we have utilized these mathematical models within the general framework of Markov Decision Processes (MDPs). Such MDP models enable us to merge these insights obtained from human behavior consistently to guide the development of autonomy protocols for robots or vehicles. A key insight we obtained is that human behavior modeling can provide the basis of the MDP modeling that guide the high-level behavior of the autonomous system, e.g., how to prioritize targets to seek or obstacles to avoid.            Last Modified: 12/29/2018       Submitted by: Behcet Acikmese]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
