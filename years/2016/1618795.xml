<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Small: Algorithms and Information Theory for Causal Inference</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>A. Funda Ergun</SignBlockName>
<PO_EMAI>fergun@nsf.gov</PO_EMAI>
<PO_PHON>7032922216</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is concerned, firstly, with algorithmic and information-theoretic aspects of Causal Inference. With the exception of some scientific data that is gathered purely for knowledge, most data is gathered for the purpose of potential intervention: this holds for medicine, public health, environmental regulations, market research, legal remedies for discrimination, and in many other domains. A decision-maker cannot take advantage of correlations and other structural characterizations that are discovered in data without knowing about causal relationships between variables. Historically, causality has been teased apart from correlation through controlled experiments. However there are several good reasons that one must often make do with passive observation: ethical reasons; governance constraints; and uniqueness of the system and the inability to re-run history. Absent experiments, we are without the principal arsenal of the scientific method.&lt;br/&gt;&lt;br/&gt;Yet there is a special class of systems in which it is possible to perform causality inference purely from passive observation of the statistics. For a system to fall in this class one must be able to establish on physical grounds that certain observable variables are statistically independent of certain others, conditional on a third set being held fixed; the formalism for this is ``semi-Markovian graphical models". It is known which semi-Markovian models fall in this class, subject to the assumption of perfect statistics. From this starting point there remain significant theoretical challenges before these ideas can have the greatest possible impact on practice. Some of the challenges to be addressed include:&lt;br/&gt;&lt;br/&gt;(1) The PI will aim to quantify how the stability (condition number) of causal identification depends on the various sources of uncertainty (statistical error; numerical error; model error) and as a function of the structure of the graphical model. The purpose is both to understand what inference is justifiable from existing data, and to impact study design so that data with the greatest leverage is collected. For the former objective, in particular, the PI seeks an efficient algorithm to compute the condition number of a given semi-Markovian model at the specific observed statistics. For the last objective the PI seeks an efficient algorithm to compute the worst-case condition number of a given semi-Markovian model.&lt;br/&gt;&lt;br/&gt;(2) Existing causal identification algorithms, applied to data inconsistent with the model (which is unavoidable due to statistical error, and normally also due to model error), will yield an inference inconsistent with the model. The project will help to understand if projection onto the model may improve stability.&lt;br/&gt;&lt;br/&gt;(3) One of the obstacles to use of existing methods is that they require sample size exponential in the size of the graphical model. The project aims to determine when it is possible to infer causality using only the marginal distributions over small subsets of the observable variables; this will reduce sample size and likely improve condition number.&lt;br/&gt;&lt;br/&gt;(4) In the majority of semi-Markovian models, causality is not identifiable. This leaves open however the possibility of determining (or giving a nontrivial outer bound for) the feasible interval of causal effects. No effective algorithm is currently known for this problem, and we wish to provide one. Such an algorithm could be used to show that an intervention is favorable despite the effect not being fully identifiable.&lt;br/&gt;&lt;br/&gt;(5) The project aims to lift the causal-inference algorithm to time series, as well as study the connections with the distinct techniques (Granger causality and Massey's directed information) normally used in this setting.&lt;br/&gt;&lt;br/&gt;Secondary emphases of the project include broader research in theoretical computer science. In particular, studying connections between ``boosting" or ``multiplicative weights" methods used in algorithms and machine learning, and their variants which arise out of selection or self-interest in the system dynamics of ecosystems (``weak selection") and economic marketplaces (``tatonnement").&lt;br/&gt;&lt;br/&gt;Inseparably from the research effort, the PI will train students and postdocs in these and related areas of the theory of computation.</AbstractNarration>
<MinAmdLetterDate>06/03/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/03/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1618795</AwardID>
<Investigator>
<FirstName>Leonard</FirstName>
<LastName>Schulman</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Leonard J Schulman</PI_FULL_NAME>
<EmailAddress>schulman@caltech.edu</EmailAddress>
<PI_PHON>6263956839</PI_PHON>
<NSF_ID>000191144</NSF_ID>
<StartDate>06/03/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>California Institute of Technology</Name>
<CityName>PASADENA</CityName>
<ZipCode>911250600</ZipCode>
<PhoneNumber>6263956219</PhoneNumber>
<StreetAddress>1200 E California Blvd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code 273-6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009584210</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CALIFORNIA INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009584210</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[California Institute of Technology]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>911250001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~450000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p style="text-indent: 0px; line-height: 100%; margin: 0px;">&nbsp;</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">This research covered multiple projects at the intersections of Theoretical Computer Science with allied disciplines including Statistics, Coding Theory, and Economics.</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">&nbsp;</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">In Statistics, or its computational sibling Machine Learning, one of the most fundamental classes of probability distributions whose parameters we would like to identify from empirical statistics, is the class of ``mixtures of product distributions.'' These are probability distributions which ``mix'' the outputs of much simpler distributions. Each of the simpler distributions is what you would see if you had n different dice lined up, each possibly biased, and you got to toss each die once, and record the n outcomes; then you can repeat this experiment many times. Identifying the biases of the dice in the simple version of the experiment is easy, but when you have a mixture---i.e., when your set of dice changes in an unknown way from trial to trial---the problem of identifying the source becomes difficult, and has been the focus of much research in the last few decades. We have given an identification algorithm with the best known runtime and sample complexity for the problem.</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">&nbsp;</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">In Coding Theory, one of the outstanding problems of the field is to replicate, for arbitrary interactive communication protocols among multiple agents, the successes in both communication rate, and encoding/decoding complexity, which Coding Theory has brought to the simpler setting of message transmission (i.e., unidirectional communication). An interactive version of the Shannon Coding Theorem has been known for over two decades, but it has the following shortcomings. (a) We can prove the needed class of codes, ``Tree Codes,'' exist, but we have no algorithm to construct them. (b) We do not know how to efficiently decode tree code transmissions. A solution to part (b) is contingent on the design in (a), but in this research project we succeeded in making considerable progress on (a). We brought the rate overhead (for communication protocols for time T) down from log T, to log log T. (Reaching a constant remains a key open problem.) Building on our work, other authors have already managed to address part (b) by producing a highly nontrivial decoding algorithm for our codes.</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">&nbsp;</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">In Economics, we have been interested in the actual dynamics by which networks of participants in a marketplace, each participant acting in a simple self-interested way, might succeed nonetheless in driving the market toward an equilibrium. This is very much a question of whether the so-called ``Invisible Hand'' of Adam Smith is just wishful thinking, or can actually be justified from micro-economic principles. The question shares considerable overlap with Computer Science and with Control Theory, because some of the same gradient-descent type processes are used in a variety of algorithms and control mechanisms. We have provided two results in this area: first, a result showing that even if participants try to outcompete others using ``k-ply lookahead'' (something that has support from experimental studies of human behavior), a certain class of markets (Fisher markets) will equilibrate rapidly. In the second result, we study tatonnement dynamics in large networks of agents, and show that the equilibration rates and price stability, depend in an essential way on how well-connected the marketplace is. The concept of well-connected used here is that of edge-connectivity or conductance, which has its roots in theory of Markov Chain Monte Carlo (MCMC) algorithms, but here applied in quite a different arena.</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">&nbsp;</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;">In connection with the last project, a question arose concerning the relationship between the edge expansion and the spectral gaps of Markov chains. For so-called reversible chains (which are all we usually need for MCMC), a strong connection, the Cheeger Inequalities, was long known between these concepts. In the Economics setting, reversibility is a very bad assumption to make, as it limits one to entirely unrealistic economies. This drove us to study whether the Cheeger inequalities still hold for non-reversible chains. One side continues to hold (as was long known). What we showed, though, is that the other side fails dramatically. This means there is much richness yet to be understood about the dynamics of non-reversible Markov chains.</p> <p style="text-indent: 0px; line-height: 100%; margin: 0px;"><br /><br /></p><br> <p>            Last Modified: 11/27/2020<br>      Modified by: Leonard&nbsp;J&nbsp;Schulman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This research covered multiple projects at the intersections of Theoretical Computer Science with allied disciplines including Statistics, Coding Theory, and Economics.   In Statistics, or its computational sibling Machine Learning, one of the most fundamental classes of probability distributions whose parameters we would like to identify from empirical statistics, is the class of ``mixtures of product distributions.'' These are probability distributions which ``mix'' the outputs of much simpler distributions. Each of the simpler distributions is what you would see if you had n different dice lined up, each possibly biased, and you got to toss each die once, and record the n outcomes; then you can repeat this experiment many times. Identifying the biases of the dice in the simple version of the experiment is easy, but when you have a mixture---i.e., when your set of dice changes in an unknown way from trial to trial---the problem of identifying the source becomes difficult, and has been the focus of much research in the last few decades. We have given an identification algorithm with the best known runtime and sample complexity for the problem.   In Coding Theory, one of the outstanding problems of the field is to replicate, for arbitrary interactive communication protocols among multiple agents, the successes in both communication rate, and encoding/decoding complexity, which Coding Theory has brought to the simpler setting of message transmission (i.e., unidirectional communication). An interactive version of the Shannon Coding Theorem has been known for over two decades, but it has the following shortcomings. (a) We can prove the needed class of codes, ``Tree Codes,'' exist, but we have no algorithm to construct them. (b) We do not know how to efficiently decode tree code transmissions. A solution to part (b) is contingent on the design in (a), but in this research project we succeeded in making considerable progress on (a). We brought the rate overhead (for communication protocols for time T) down from log T, to log log T. (Reaching a constant remains a key open problem.) Building on our work, other authors have already managed to address part (b) by producing a highly nontrivial decoding algorithm for our codes.   In Economics, we have been interested in the actual dynamics by which networks of participants in a marketplace, each participant acting in a simple self-interested way, might succeed nonetheless in driving the market toward an equilibrium. This is very much a question of whether the so-called ``Invisible Hand'' of Adam Smith is just wishful thinking, or can actually be justified from micro-economic principles. The question shares considerable overlap with Computer Science and with Control Theory, because some of the same gradient-descent type processes are used in a variety of algorithms and control mechanisms. We have provided two results in this area: first, a result showing that even if participants try to outcompete others using ``k-ply lookahead'' (something that has support from experimental studies of human behavior), a certain class of markets (Fisher markets) will equilibrate rapidly. In the second result, we study tatonnement dynamics in large networks of agents, and show that the equilibration rates and price stability, depend in an essential way on how well-connected the marketplace is. The concept of well-connected used here is that of edge-connectivity or conductance, which has its roots in theory of Markov Chain Monte Carlo (MCMC) algorithms, but here applied in quite a different arena.   In connection with the last project, a question arose concerning the relationship between the edge expansion and the spectral gaps of Markov chains. For so-called reversible chains (which are all we usually need for MCMC), a strong connection, the Cheeger Inequalities, was long known between these concepts. In the Economics setting, reversibility is a very bad assumption to make, as it limits one to entirely unrealistic economies. This drove us to study whether the Cheeger inequalities still hold for non-reversible chains. One side continues to hold (as was long known). What we showed, though, is that the other side fails dramatically. This means there is much richness yet to be understood about the dynamics of non-reversible Markov chains.          Last Modified: 11/27/2020       Submitted by: Leonard J Schulman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
