<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: User Interfaces for Improving Collaboration Between Blind and Sighted People</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>499997.00</AwardTotalIntnAmount>
<AwardAmount>499997</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Inaccessible graphical user interfaces hinder participation by blind and visually impaired people in work, education, and other aspects of public life.  Alternative user interface technology such as screen reader software can address this problem by converting inaccessible visual content into synthesized speech, but can introduce other issues when used in a shared setting; blind users are unable to follow along when their sighted partners use a graphical user interface, while most sighted users lack the training to use a screen reader.  This gap makes it difficult for blind and sighted peers to collaborate on shared tasks, as each user may have a significantly different view of the task and may have difficulty following their partner's actions.  The PI's goals in this research are to understand the barriers to collaboration between users of different visual abilities, and to create and evaluate new tools to facilitate such collaborations.  Enabling blind and sighted people to work collaboratively will significantly improve educational and employment outcomes for millions of people.  The PI will work with partners, the AccessComputing Alliance and the Colorado Center for the Blind, to directly involve individuals with disabilities as part of the research team, and will release an open source toolkit for creating software to support blind/sighted collaboration.  Educational activities will include summer workshops with blind and sighted students to explore how students with mixed abilities can learn to co-design and co-develop more accessible software together.&lt;br/&gt;&lt;br/&gt;Little prior research has explored how blind and sighted people collaborate synchronously using computers.  The PI's preliminary work has identified several significant obstacles to synchronous collaboration between blind and sighted individuals using existing tools: maintaining joint attention without visual feedback, lack of awareness of actions taken by others, and crosstalk between a screen reader's speech output and out-of-band conversations between activity partners.  In this project, the PI will develop and test a set of metrics and reference tasks for evaluating collaborative activities between a sighted partner using a graphical user interface and a blind partner using a screen reader.  The PI will develop tools to support equal and effective blind/sighted collaboration through sharing information about each user's activities with the group.  This approach will connect users' computing devices (and related assistive technology) over a network, so that each user can maintain awareness of their partner's activities when interacting with shared resources.  The PI will prototype various means of integrating this information into existing user interfaces, and implement a toolkit which enables software developers to support blind/sighted collaboration in their applications.  The PI will validate these tools through user testing with mixed groups of blind and sighted users, and will demonstrate the robustness of the approach by applying it to synchronous co-located collaboration, asynchronous online collaboration, and micro-tasking using crowd workers.</AbstractNarration>
<MinAmdLetterDate>08/01/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/15/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1619384</AwardID>
<Investigator>
<FirstName>Shaun</FirstName>
<LastName>Kane</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shaun Kane</PI_FULL_NAME>
<EmailAddress>shaun.kane@colorado.edu</EmailAddress>
<PI_PHON>3037357209</PI_PHON>
<NSF_ID>000611397</NSF_ID>
<StartDate>08/01/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Boulder</Name>
<CityName>Boulder</CityName>
<ZipCode>803031058</ZipCode>
<PhoneNumber>3034926221</PhoneNumber>
<StreetAddress>3100 Marine Street, Room 481</StreetAddress>
<StreetAddress2><![CDATA[572 UCB]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>007431505</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF COLORADO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431505</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Colorado at Boulder]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803031058</ZipCode>
<StreetAddress><![CDATA[3100 Marine Street, Room 481]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~164585</FUND_OBLG>
<FUND_OBLG>2017~335412</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Graphical user interfaces are often designed in a way that is not accessible by blind and visually impaired people. For these individuals, interacting with graphical user interfaces and other visual media often requires converting this information into a non-visual form such as speech, non-speech audio, Braille, or a tactile graphic.</p> <p>While advances in accessible technology have made it easier for blind and visually impaired people to use computing devices independently, doing so often involves using these devices via text-to-speech, Braille, or another non-visual format. These alternative modes of interaction often work well for the blind or visually impaired user, but can be confusing to that user's coworkers. As a result, the blind or visually impaired user could be isolated from their coworkers and forced to work alone, which could prevent these individuals from participating fully in collaborative activities at home, school, and work. In our initial research, which involved observing and interviewing blind professionals who work with sighted colleagues, we found that these professionals did in fact experience accessibility barriers that made it more difficult for them to work together with their colleagues. As a response to these accessibility problems, this project focused on identifying accessibility barriers in collaborative work as well as building and testing technology prototypes that directly support collaboration between blind and sighted individuals.</p> <p>Over the course of this project, our research team explored accessibility barriers to collaborative work in several settings, including studying how blind and sighted individuals work together to generate descriptions of images; exploring ways to present scientific charts, graphics, and other media via touch; developing tools that enable families of blind and visually impaired children to learn and play together; and creating new computer programming tools that enable blind students to code games and other programs and to share them with friends.</p> <p>The outcomes of this work include a deeper understanding of how technologies can support collaborative work between blind and sighted individuals, as well as proof-of-concept prototypes of more accessible and collaborative learning tools. By making it easier for blind and visually impaired individuals to work with their sighted peers, we believe this work can remove some of the barriers they currently experience, and to make a more level playing field for everyone.</p><br> <p>            Last Modified: 05/25/2021<br>      Modified by: Shaun&nbsp;Kane</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Graphical user interfaces are often designed in a way that is not accessible by blind and visually impaired people. For these individuals, interacting with graphical user interfaces and other visual media often requires converting this information into a non-visual form such as speech, non-speech audio, Braille, or a tactile graphic.  While advances in accessible technology have made it easier for blind and visually impaired people to use computing devices independently, doing so often involves using these devices via text-to-speech, Braille, or another non-visual format. These alternative modes of interaction often work well for the blind or visually impaired user, but can be confusing to that user's coworkers. As a result, the blind or visually impaired user could be isolated from their coworkers and forced to work alone, which could prevent these individuals from participating fully in collaborative activities at home, school, and work. In our initial research, which involved observing and interviewing blind professionals who work with sighted colleagues, we found that these professionals did in fact experience accessibility barriers that made it more difficult for them to work together with their colleagues. As a response to these accessibility problems, this project focused on identifying accessibility barriers in collaborative work as well as building and testing technology prototypes that directly support collaboration between blind and sighted individuals.  Over the course of this project, our research team explored accessibility barriers to collaborative work in several settings, including studying how blind and sighted individuals work together to generate descriptions of images; exploring ways to present scientific charts, graphics, and other media via touch; developing tools that enable families of blind and visually impaired children to learn and play together; and creating new computer programming tools that enable blind students to code games and other programs and to share them with friends.  The outcomes of this work include a deeper understanding of how technologies can support collaborative work between blind and sighted individuals, as well as proof-of-concept prototypes of more accessible and collaborative learning tools. By making it easier for blind and visually impaired individuals to work with their sighted peers, we believe this work can remove some of the barriers they currently experience, and to make a more level playing field for everyone.       Last Modified: 05/25/2021       Submitted by: Shaun Kane]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
