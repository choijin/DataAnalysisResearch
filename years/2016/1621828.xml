<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Innovative visual search and similarity for decor, apparel, and style</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to develop and commercialize visual search for fine-grained recognition of products and style in interior decor and apparel.  The technology will help the broader public find items that may be difficult to search for using traditional text-based search.  In many markets (home decor, fashion, etc.), customers seek products that have unique visual appearances that cannot easily be expressed with a text-based search. This project will develop visual search tools for the home decor and apparel markets. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will develop software based on deep learning for product and apparel recognition and style recognition. Our prior prototype uses deep learning to recognize specific products from "regular" photographs taken by customers, where the challenge is that these regular photos of products can have many different backgrounds, sizes, orientations, or lighting when compared to the iconic product image, and the product could be significantly occluded by clutter in the scene.  The goal of this project is to generalize the work to achieve broad applicability through four major objectives: Generalizing the settings and product categorization and taxonomy to support a broad range of customers and product types (Objective 1); semi-automatic detection of products in scene images to scale to large photo collections (Objective 2); refining the trained models for fine-grained matches to meet customer needs (Objective 3); and deploying the system live to companies (Objective 4).</AbstractNarration>
<MinAmdLetterDate>06/22/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1621828</AwardID>
<Investigator>
<FirstName>Sean</FirstName>
<LastName>Bell</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sean Bell</PI_FULL_NAME>
<EmailAddress>founders@grokstyle.com</EmailAddress>
<PI_PHON>6072806026</PI_PHON>
<NSF_ID>000713237</NSF_ID>
<StartDate>06/22/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Grokstyle LLC</Name>
<CityName>Ithaca</CityName>
<ZipCode>148501064</ZipCode>
<PhoneNumber>6072806026</PhoneNumber>
<StreetAddress>29 WEDGEWOOD DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080040519</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GROKSTYLE LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Grokstyle LLC]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148501064</ZipCode>
<StreetAddress><![CDATA[29 WEDGEWOOD DR]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>GrokStyle is developing software that allows a consumer to search for products using &ldquo;visual search,&rdquo; which enables instance recognition of an object and provides visual matches to desired products. The company&rsquo;s current focus is on furniture and interior d&eacute;cor; however, this technology has shown promise on a variety of applications and industries. There are clear benefits of being able to visually recognize an object, as compared to traditional text-based searches.&nbsp; First, search users are able to save time searching while quickly accessing desirable products. Retailers and designers using the technology also benefit through increased sales due to the customer&rsquo;s ability to quickly and accurately locate items for sale. GrokStyle also facilitates customer and retailer connection with designers, by allowing users to search for how others have used and combined furniture and decor products.</p> <p>GrokStyle&rsquo;s technology is unique in that it utilizes deep learning coupled with the rich data available online to build a tool for visual and style-based search of products and interior designs. The software addresses product recognition by providing consumers answers to the &ldquo;What&rdquo;, &ldquo;Where&rdquo;, and &ldquo;Compatible&rdquo; questions associated with visual search. Only by correctly identifying specific decor products in photos, can consumers find examples of a specific product being used in many different ways, or search for products that complement that specific product (e.g., coffee tables that look great with a specific couch). By understanding style&mdash;to the point of knowing which products look visually similar&mdash;GrokStyle gives the consumer access to an even wider variety of products, and lets them comparison-shop to find the best deals.</p> <p>Under this Phase I project, GrokStyle aimed to expand the capabilities to match real-world considerations, with a primary focus on furniture and interior decor. The goal was to generalize prior work to achieve broad applicability through four major objectives: To expand GrokStyle&rsquo;s database of products (Objective 1), to find in which scene images products appear (Objective 2), to refine trained models for fine-grained matches to meet customer needs (Objective 3), and to deploy the system live to companies (Objective 4). Each of these goals was achieved in Phase I.</p> <p>Specifically, Phase I resulted in the modification of GrokStyle&rsquo;s deep learning algorithms for greater accuracy as the company has increased its training data.&nbsp; GrokStyle&rsquo;s database of products was expanded to include 9,580,773 home and apparel products and 16,877,796 photos. Furthermore, a new crowdsourcing pipeline, the Search-Assisted Labeling Pipeline, was created to fully label all images. After a month of iteration, GrokStyle now has a final crowdsourcing pipeline that is very robust and powerful. This pipeline was successfully deployed to workers, who collected dense data for 10,000 images. With the much higher quality data collected in Phase I, a significantly more accurate object detector will be able to be trained going forward.</p> <p>Phase I also resulted in the development of an innovative range of new networks and algorithms to address various needs. For example, finding exact product matches including color matching, and grouping visually similar products based on categories for better search exploration by the customer. The metric used to evaluate pipeline improvements is the Mean Reciprocal Rank, which is the average reciprocal rank. The optimized pipeline and new training algorithms as a result of this Phase I project improved the Mean Reciprocal Rank from 0.3 to 0.588, a significant improvement. Essentially, on average, the correct result was returned in the second position of the search&mdash;a huge improvement over state-of-the-art and GrokStyle&rsquo;s prior work.</p> <p>Most notably, GrokStyle was able to build a complete product that has been deployed into production use with a 250-person sub-unit of a global leader in retail. GrokStyle is using the data being collected to understand the inaccuracies of the system, and to better understand customer needs and queries moving forward.</p><br> <p>            Last Modified: 07/21/2017<br>      Modified by: Sean&nbsp;Bell</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ GrokStyle is developing software that allows a consumer to search for products using "visual search," which enables instance recognition of an object and provides visual matches to desired products. The company?s current focus is on furniture and interior d&eacute;cor; however, this technology has shown promise on a variety of applications and industries. There are clear benefits of being able to visually recognize an object, as compared to traditional text-based searches.  First, search users are able to save time searching while quickly accessing desirable products. Retailers and designers using the technology also benefit through increased sales due to the customer?s ability to quickly and accurately locate items for sale. GrokStyle also facilitates customer and retailer connection with designers, by allowing users to search for how others have used and combined furniture and decor products.  GrokStyle?s technology is unique in that it utilizes deep learning coupled with the rich data available online to build a tool for visual and style-based search of products and interior designs. The software addresses product recognition by providing consumers answers to the "What", "Where", and "Compatible" questions associated with visual search. Only by correctly identifying specific decor products in photos, can consumers find examples of a specific product being used in many different ways, or search for products that complement that specific product (e.g., coffee tables that look great with a specific couch). By understanding style&mdash;to the point of knowing which products look visually similar&mdash;GrokStyle gives the consumer access to an even wider variety of products, and lets them comparison-shop to find the best deals.  Under this Phase I project, GrokStyle aimed to expand the capabilities to match real-world considerations, with a primary focus on furniture and interior decor. The goal was to generalize prior work to achieve broad applicability through four major objectives: To expand GrokStyle?s database of products (Objective 1), to find in which scene images products appear (Objective 2), to refine trained models for fine-grained matches to meet customer needs (Objective 3), and to deploy the system live to companies (Objective 4). Each of these goals was achieved in Phase I.  Specifically, Phase I resulted in the modification of GrokStyle?s deep learning algorithms for greater accuracy as the company has increased its training data.  GrokStyle?s database of products was expanded to include 9,580,773 home and apparel products and 16,877,796 photos. Furthermore, a new crowdsourcing pipeline, the Search-Assisted Labeling Pipeline, was created to fully label all images. After a month of iteration, GrokStyle now has a final crowdsourcing pipeline that is very robust and powerful. This pipeline was successfully deployed to workers, who collected dense data for 10,000 images. With the much higher quality data collected in Phase I, a significantly more accurate object detector will be able to be trained going forward.  Phase I also resulted in the development of an innovative range of new networks and algorithms to address various needs. For example, finding exact product matches including color matching, and grouping visually similar products based on categories for better search exploration by the customer. The metric used to evaluate pipeline improvements is the Mean Reciprocal Rank, which is the average reciprocal rank. The optimized pipeline and new training algorithms as a result of this Phase I project improved the Mean Reciprocal Rank from 0.3 to 0.588, a significant improvement. Essentially, on average, the correct result was returned in the second position of the search&mdash;a huge improvement over state-of-the-art and GrokStyle?s prior work.  Most notably, GrokStyle was able to build a complete product that has been deployed into production use with a 250-person sub-unit of a global leader in retail. GrokStyle is using the data being collected to understand the inaccuracies of the system, and to better understand customer needs and queries moving forward.       Last Modified: 07/21/2017       Submitted by: Sean Bell]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
