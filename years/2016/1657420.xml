<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CIF: Limits and Robustness of Nonconvex Low-Rank Estimation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/15/2017</AwardEffectiveDate>
<AwardExpirationDate>01/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The objective of this research is to significantly broaden the algorithms and theory for nonconvex low-rank estimation. Low-rank estimation problems are ubiquitous in science and engineering. Recently developed nonconvex methods promise great computational gains on large-scale datasets, but the algorithmic and theoretical foundation has not yet reached the same level of maturity as their convex counterpart. This research attacks this deficit in two research thrusts: pushing the limits of nonconvex methods for greater flexibility through a unified theoretical framework, and developing new algorithms robust to data corruption. &lt;br/&gt;&lt;br/&gt;To achieve greater flexibility and generality for the nonconvex approach, the investigator develops a new unifying paradigm that explains when and why nonconvex methods succeed. This is accomplished by a novel reinterpretation of various nonconvex methods through a two-step procedure. This flexible framework unifies several existing algorithms including gradient descent and alternating minimization, and opens the door for designing new algorithms. Theoretically this unified view allows for a decoupling of the statistical and optimization analysis. The investigator will explore the consequences of this approach by (a) providing a simpler and modular analysis of the convergence and statistical properties of existing algorithms, (b) studying the global behaviors of nonconvex methods and the role of initialization, and (c) designing new algorithms that are more efficient and general. The second thrust of this project studies the robustness of nonconvex methods. To protect against arbitrary corruption in data, the investigator designs new robust nonconvex formulations by viewing corruption as a superimposed structure and leveraging sparsity in the optimization objectives. This result will be further expanded through the use of nonsmooth nonconvex formulations and a complete rethinking of existing analytic techniques.</AbstractNarration>
<MinAmdLetterDate>02/10/2017</MinAmdLetterDate>
<MaxAmdLetterDate>02/10/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1657420</AwardID>
<Investigator>
<FirstName>Yudong</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yudong Chen</PI_FULL_NAME>
<EmailAddress>yc2272@cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000704374</NSF_ID>
<StartDate>02/10/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>7797</Code>
<Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~175000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project we considered data analytic and machine learning problems that involve a challenging type of optimization problem called non-convex optimization. The goals of this project include: (1) to study for what types of machine learning tasks this problem is tractable given typical data that arises in real-world applications, and (2) to develop algorithms that can solve this problem in the face of noisy and corrupted data.&nbsp;</p> <p>For goal (1), we developed a genearal algorithmic framework, based on simple and efficient iterative procedures, that can be applied to a broad range of large-scale non-convex matrix problems including those that arise in online personalized recommendation systems. We also developed a unified analytic framework for estabhising performance guarantees of the above algorithm, withiout relying on unrealisitic assumptions on the data or impractical modificaiton to the algorithm.&nbsp;</p> <p>For goal (2), we developed a general and novel framework based on a preveiouly less studied type of technique called non-smooth optimization. this framework led to a suit of algorithms that are robust to data corruption. We showed that these algorithms are flexible, computationally efficient, and easy to analyze. In particular, we obtained rigourous performance guarantees on the speed of these algorithms, as well as on their robustness against missing data, correlated data and datasets that are adversarially manipulated.</p> <p>The results of the project can be used to speed up the computation in a wide range of data analytic problems with large and non-ideal datasets, and moreover to provide quality assurance on output of the algorithms, which are important in many critical real-world applications.&nbsp;The results of the project have been disseminated through preprints, review papers, journal/conference publications and seminar presentations.&nbsp;The project provided research and training opportunities for several students including those from underrepresented groups.</p><br> <p>            Last Modified: 07/13/2020<br>      Modified by: Yudong&nbsp;Chen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project we considered data analytic and machine learning problems that involve a challenging type of optimization problem called non-convex optimization. The goals of this project include: (1) to study for what types of machine learning tasks this problem is tractable given typical data that arises in real-world applications, and (2) to develop algorithms that can solve this problem in the face of noisy and corrupted data.   For goal (1), we developed a genearal algorithmic framework, based on simple and efficient iterative procedures, that can be applied to a broad range of large-scale non-convex matrix problems including those that arise in online personalized recommendation systems. We also developed a unified analytic framework for estabhising performance guarantees of the above algorithm, withiout relying on unrealisitic assumptions on the data or impractical modificaiton to the algorithm.   For goal (2), we developed a general and novel framework based on a preveiouly less studied type of technique called non-smooth optimization. this framework led to a suit of algorithms that are robust to data corruption. We showed that these algorithms are flexible, computationally efficient, and easy to analyze. In particular, we obtained rigourous performance guarantees on the speed of these algorithms, as well as on their robustness against missing data, correlated data and datasets that are adversarially manipulated.  The results of the project can be used to speed up the computation in a wide range of data analytic problems with large and non-ideal datasets, and moreover to provide quality assurance on output of the algorithms, which are important in many critical real-world applications. The results of the project have been disseminated through preprints, review papers, journal/conference publications and seminar presentations. The project provided research and training opportunities for several students including those from underrepresented groups.       Last Modified: 07/13/2020       Submitted by: Yudong Chen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
