<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: Collaborative Research: F: Foundations of Nonconvex Problems in BigData Science and Engineering: Models, Algorithms, and Analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Victor Roytburd</SignBlockName>
<PO_EMAI>vroytbur@nsf.gov</PO_EMAI>
<PO_PHON>7032928584</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In today's digital world, huge amounts of data, i.e., big data, can be found in almost every aspect of scientific research and human activity.  These data need to be managed effectively for reliable prediction and inference to improve decision making.  Statistical learning is an emergent scientific discipline wherein mathematical modeling, computational algorithms, and statistical analysis are jointly employed to address these challenging data management problems.  Invariably, quantitative criteria need to be introduced for the overall learning process in order to gauge the quality of the solutions obtained. This research focuses on two important criteria: data fitness and sparsity representation of the underlying learning model.  Potential applications of the results can be found in computational statistics, compressed sensing, imaging, machine learning, bio-informatics, portfolio selection, and decision making under uncertainty, among many areas involving big data.&lt;br/&gt;&lt;br/&gt;Till now, convex optimization has been the dominant methodology for statistical learning in which the two criteria employed are expressed by convex functions either to be optimized and/or set as constraints of the variables being sought.  Recently, non-convex functions of the difference-of-convex (DC) type and the difference-of-convex algorithm (DCA) have been shown to yield superior results in many contexts and serve as the motivation for this project.  The goal is to develop a solid foundation and a unified framework to address many fundamental issues in big data problems in which non-convexity and non-differentiability are present in the optimization problems to be solved. These two non-standard features in computational statistical learning are challenging and their rigorous treatment requires the fusion of expertise from different domains of mathematical sciences.  Technical issues to be investigated will cover the optimality, sparsity, and statistical properties of computable solutions to the non-convex, non-smooth optimization problems arising from statistical learning and its many applications.  Novel algorithms will be developed and tested first on synthetic data sets for preliminary experimentation and then on publicly available data sets for realism; comparisons will be made among different formulations of the learning problems.</AbstractNarration>
<MinAmdLetterDate>08/17/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1632951</AwardID>
<Investigator>
<FirstName>Yufeng</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yufeng Liu</PI_FULL_NAME>
<EmailAddress>yfliu@email.unc.edu</EmailAddress>
<PI_PHON>9198431899</PI_PHON>
<NSF_ID>000274908</NSF_ID>
<StartDate>08/17/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Chapel Hill]]></Name>
<CityName>Chapel Hill</CityName>
<StateCode>NC</StateCode>
<ZipCode>275991350</ZipCode>
<StreetAddress><![CDATA[354 Hanes Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major goals of the project, &ldquo;BIGDATA: Collaborative Research: F: Foundations of Nonconvex Problems in BigData Science and Engineering: Models, Algorithms, and Analysis&rdquo;, was to provide unified formulation for many statistical learning problems as a structured, nonconvex and possibly nondifferentiable DC optimization problem; analyze the nonconvex optimization problems with rigorous theoretical foundations and study their statistical properties of the solutions; develop and implement efficient algorithms for solving the nonconvex problems and apply the results to various problems which involve nonconvex problems; and develop education material on nonconvex statistical learning and disseminate the results.</p> <p>&nbsp;</p> <p>Intellectual Merits:</p> <p>&nbsp;</p> <p>During the entire project period, the PI and the whole team made important contributions in development of methods and theory for nonconvex statistical learning problems. In particular, the research team developed new techniques for individualized decision rules, classification, variable selection, and clustering. Many of these new developments have been reported in publications as well as disseminated in research conferences. This project leaded to 13 publications in major statistics, machine learning and optimization journals. These methods will be widely used in the community.</p> <p>&nbsp;</p> <p>Broader impacts:</p> <p>&nbsp;</p> <p>The developed methods and theory through this project made important contributions to the field of statistics, machine learning, optimization, and beyond. Through collaboration with domain scientists such as genetics, and neuroimaging, the methods have been introduced and applied to other fields. In terms of education, the new research developments of the project were incorporated into the undergraduate and graduate courses on statistical machine learning and optimization at University of North Carolina at Chapel Hill as well as the other collaborating institutes. Furthermore, the project has directly benefited Ph.D. student research training. Two graduated Ph.D. students mentored by the PI were involved in the research developments of this project.</p> <p>&nbsp;</p> <p>In summary, the original proposed goals of this project have been achieved, and the project resulted in fruitful outcomes both in terms of intellectual merit and broader impacts. The project leaded to productive research development and effective training and education.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/25/2020<br>      Modified by: Yufeng&nbsp;Liu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goals of the project, "BIGDATA: Collaborative Research: F: Foundations of Nonconvex Problems in BigData Science and Engineering: Models, Algorithms, and Analysis", was to provide unified formulation for many statistical learning problems as a structured, nonconvex and possibly nondifferentiable DC optimization problem; analyze the nonconvex optimization problems with rigorous theoretical foundations and study their statistical properties of the solutions; develop and implement efficient algorithms for solving the nonconvex problems and apply the results to various problems which involve nonconvex problems; and develop education material on nonconvex statistical learning and disseminate the results.     Intellectual Merits:     During the entire project period, the PI and the whole team made important contributions in development of methods and theory for nonconvex statistical learning problems. In particular, the research team developed new techniques for individualized decision rules, classification, variable selection, and clustering. Many of these new developments have been reported in publications as well as disseminated in research conferences. This project leaded to 13 publications in major statistics, machine learning and optimization journals. These methods will be widely used in the community.     Broader impacts:     The developed methods and theory through this project made important contributions to the field of statistics, machine learning, optimization, and beyond. Through collaboration with domain scientists such as genetics, and neuroimaging, the methods have been introduced and applied to other fields. In terms of education, the new research developments of the project were incorporated into the undergraduate and graduate courses on statistical machine learning and optimization at University of North Carolina at Chapel Hill as well as the other collaborating institutes. Furthermore, the project has directly benefited Ph.D. student research training. Two graduated Ph.D. students mentored by the PI were involved in the research developments of this project.     In summary, the original proposed goals of this project have been achieved, and the project resulted in fruitful outcomes both in terms of intellectual merit and broader impacts. The project leaded to productive research development and effective training and education.           Last Modified: 08/25/2020       Submitted by: Yufeng Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
