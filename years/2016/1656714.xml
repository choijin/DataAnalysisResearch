<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Proposal: Visual Attention in an Invertebrate Predator</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2017</AwardEffectiveDate>
<AwardExpirationDate>03/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08090200</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>IOS</Abbreviation>
<LongName>Division Of Integrative Organismal Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sridhar Raghavachari</SignBlockName>
<PO_EMAI>sraghava@nsf.gov</PO_EMAI>
<PO_PHON>7032924845</PO_PHON>
</ProgramOfficer>
<AbstractNarration>All visual animals face the problem of distinguishing relevant from distracting stimuli quickly and efficiently. One way that visual systems accomplish this task is through selective attention, where an animal attends to a portion of the available visual stimuli at a time. Tiny jumping spiders have microminiature eyes that are nearly as acute as a human's and, like humans, pays attention and discriminates among visual targets. This project investigates how jumping spiders pay attention to and identify moving visual objects.  The simplicity of the jumping spider eye and brain makes it easier to learn how the brain's neural networks "compute" visual movement and object identification, than in humans.  In humans AND jumping spiders, selective visual attention is measured by rapid movements of their eyes to focus on targets of interest. This study employs an innovative eyetracker to measure the direction of a spider's gaze as it views video images. In addition, neural techniques are used to measure the activity of the spider's brain while its gaze is being monitored: specific parts of the brain respond differentially to particular images and sounds. Thus, it is possible to see both what engages a spider's visual attention as well as how different stimuli are interpreted. Understanding this elegant, miniaturized and extremely effective visual system will be of interest to roboticists and engineers, for whom micro-miniaturization of biosensors is a premium in small, self-autonomous robots. In addition, the PI will train a graduate student, a postdoc, and undergraduates, and will create videos for a project called "Faces and Voices of Science" that highlight the personal stories of researchers from different backgrounds. The videos will be made available online for teachers and professors to incorporate in lectures.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Visual animals face the problem of distinguishing relevant from distracting stimuli quickly and efficiently.  One way to do this is through selective attention, where the animal attends to only part of the visual field at a time, through a process of saccadic eye movements and selective target scan.  This is true for humans and at the behavioral level seems true for jumping spiders.  These spiders are highly visual and are among the rare invertebrate animals that have moveable eyes.  The PIs have developed two novel technologies that allow a comprehensive study of selective visual attention.  These include an innovative spider eyetracker can monitor with precision a spider's eye movements in real time as they scan a stimulus image and the first electrophysiological recordings in the brain of a living spider as it observes visual stimuli. The eyetracker will be deployed to monitor eye movements while simultaneously recordings from single units in the brain are recorded.  The PIs will thus test explicit hypotheses about visual attention, eye movements, and correlated brain activity.  These include "bottom-up" stimulus-driven attentional processes by testing how different visual stimuli influence eye movements and neural processes in the brain, as well as "top-down" processes by presenting cross-modal cues and measuring eye movements and neural processes as the spider searches for relevant stimuli among distractors.</AbstractNarration>
<MinAmdLetterDate>04/05/2017</MinAmdLetterDate>
<MaxAmdLetterDate>04/16/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1656714</AwardID>
<Investigator>
<FirstName>Elizabeth</FirstName>
<LastName>Jakob</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elizabeth M Jakob</PI_FULL_NAME>
<EmailAddress>ejakob@umass.edu</EmailAddress>
<PI_PHON>4135770707</PI_PHON>
<NSF_ID>000114902</NSF_ID>
<StartDate>04/05/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<CountyName/>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<CountyName/>
<StateCode>MA</StateCode>
<ZipCode>010039255</ZipCode>
<StreetAddress><![CDATA[Middlesex House]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7713</Code>
<Text>Activation</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~166668</FUND_OBLG>
<FUND_OBLG>2018~166666</FUND_OBLG>
<FUND_OBLG>2019~166666</FUND_OBLG>
</Award>
</rootTag>
