<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS: FULL: Collaborative Research: PARAGRAPH: Parallel, Scalable Graph Analytics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>546875.00</AwardTotalIntnAmount>
<AwardAmount>546875</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many real world problems can be effectively modeled as complex relationship networks or graphs where nodes represent entities of interest and edges mimic the interactions or relationships among them. The number of such problems and the diversity of domains from which they arise is growing. However developing high-performance applications to extract useful information from such datasets is very challenging.  Graphical processing units are very attractive for such applications because they offer higher computational performance and energy efficiency than standard multi-core processors. However, the development of high-performance applications for them is currently much more challenging than  parallel program development for standard  multi-core processors. Effective  application development to use graphical processing units generally requires that developers possess considerable expertise on their architectural characteristics and use specialized programming models and performance optimization techniques. Thus, simultaneously achieving high performance and high user productivity for data analytics applications for such devices is a daunting challenge.&lt;br/&gt;&lt;br/&gt;This project proposes a scalable high-level software framework to enable the productive development of high-performance applications for graphical processing units. It features two distinct abstractions to address the performance and productivity challenges in developing graph/data analytics applications: 1) a frontier-centric abstraction that is based on a common iterative characteristic of many of these applications, with a dynamically moving active frontier of vertices (or edges) where computation is centered, and 2) an abstraction based on sparse linear algebra primitives, exploiting the dual relationship between sparse matrices and graphs. A benchmark suite of graph analytics applications will be developed and evaluated using both abstractions, enabling insights into the effectiveness of these alternate high-level abstractions for a range of analytics applications. The benchmark suite and the software framework will be publicly released.</AbstractNarration>
<MinAmdLetterDate>08/12/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/12/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1629548</AwardID>
<Investigator>
<FirstName>Ponnuswamy</FirstName>
<LastName>Sadayappan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ponnuswamy Sadayappan</PI_FULL_NAME>
<EmailAddress>saday@cs.utah.edu</EmailAddress>
<PI_PHON>6142164213</PI_PHON>
<NSF_ID>000182536</NSF_ID>
<StartDate>08/12/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Srinivasan</FirstName>
<LastName>Parthasarathy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Srinivasan Parthasarathy</PI_FULL_NAME>
<EmailAddress>srini@cse.ohio-state.edu</EmailAddress>
<PI_PHON>6142922568</PI_PHON>
<NSF_ID>000227551</NSF_ID>
<StartDate>08/12/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Louis-Noel</FirstName>
<LastName>Pouchet</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Louis-Noel Pouchet</PI_FULL_NAME>
<EmailAddress>pouchet.2@osu.edu</EmailAddress>
<PI_PHON>6142923805</PI_PHON>
<NSF_ID>000681435</NSF_ID>
<StartDate>08/12/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101063</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8283</Code>
<Text>Exploiting Parallel&amp;Scalabilty</Text>
</ProgramElement>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~546875</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px 'Andale Mono'; color: #2fff12; background-color: #000000; background-color: rgba(0, 0, 0, 0.9)} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px 'Andale Mono'; color: #2fff12; background-color: #000000; background-color: rgba(0, 0, 0, 0.9); min-height: 19.0px} span.s1 {font-variant-ligatures: no-common-ligatures} span.s2 {font-variant-ligatures: no-common-ligatures; background-color: #dc0005} --> <p class="p1"><span class="s1">The project investigated performance optimization for graph analytics computations, with special emphasis on achieving high performance on GPUs. Two broad alternatives were explored: edge/vertex centric expression of algorithms versus matrix/tensor centric implementations casting operations on graphs in terms of sparse matrix/tensor operators.<span>&nbsp;</span></span></p> <p class="p2"><span class="s1">&nbsp;</span>The key project outcomes of the project include:</p> <p class="p1"><span class="s1">1)&nbsp; High-performance GPU implementations were developed&nbsp;and publicly released for&nbsp;several sparse matrix/tensor kernels useful for graph analytics, including matrix factorization, sparse-dense matrix-matrix product, sparse-sparse matrix-matrix product, and </span><span class="s2">matricized</span><span class="s1"> tensor times </span><span class="s2">Khatri</span><span class="s1">-</span><span class="s2">Rao</span><span class="s1"> product.</span></p> <p class="p1"><span class="s1">2) High-performance GPU implementations were developed&nbsp;and publicly released for&nbsp;supporting machine learning models, including </span><span class="s2">NMF</span><span class="s1"> (Non-negative Matrix Factorization) and </span><span class="s2">LDA</span><span class="s1"> (Latent Dirichlet Allocation).</span></p> <p class="p1"><span class="s1">3) While tiling of dense matrix computations is well understood and widely used for data-locality optimization in production libraries for dense linear algebra, convolutional neural networks, etc., its effective application to sparse matrix computations is not yet the case.&nbsp;The research from this project has adavnced the state-of-the-art in developing techniques for tiling of sparse matrix computations on GPUs and multicore CPUs.</span></p> <p class="p1"><span class="s1">4) Techniques were developed for accelerating graph embeddings by use of sparsification as a pre-processing step before embedding.</span></p> <p class="p1"><span class="s1">5) Four Ph.D. students (including one female) and one post-doctoral scholar were trained.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 01/23/2020<br>      Modified by: Ponnuswamy&nbsp;Sadayappan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project investigated performance optimization for graph analytics computations, with special emphasis on achieving high performance on GPUs. Two broad alternatives were explored: edge/vertex centric expression of algorithms versus matrix/tensor centric implementations casting operations on graphs in terms of sparse matrix/tensor operators.   The key project outcomes of the project include: 1)  High-performance GPU implementations were developed and publicly released for several sparse matrix/tensor kernels useful for graph analytics, including matrix factorization, sparse-dense matrix-matrix product, sparse-sparse matrix-matrix product, and matricized tensor times Khatri-Rao product. 2) High-performance GPU implementations were developed and publicly released for supporting machine learning models, including NMF (Non-negative Matrix Factorization) and LDA (Latent Dirichlet Allocation). 3) While tiling of dense matrix computations is well understood and widely used for data-locality optimization in production libraries for dense linear algebra, convolutional neural networks, etc., its effective application to sparse matrix computations is not yet the case. The research from this project has adavnced the state-of-the-art in developing techniques for tiling of sparse matrix computations on GPUs and multicore CPUs. 4) Techniques were developed for accelerating graph embeddings by use of sparsification as a pre-processing step before embedding. 5) Four Ph.D. students (including one female) and one post-doctoral scholar were trained.          Last Modified: 01/23/2020       Submitted by: Ponnuswamy Sadayappan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
