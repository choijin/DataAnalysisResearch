<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Small: Collaborative Research: Adaptive Motion Planning and Decision-Making for Human-Robot Collaboration in Manufacturing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>109031.00</AwardTotalIntnAmount>
<AwardAmount>167016</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project addresses manufacturing tasks that cannot be fully automated because of either the limitations of current algorithms or prohibitive cost and set-up time. Such tasks generally require workers to collaborate in close proximity and adapt to each other's decisions and motions. This project explores accomplishing these tasks through human-robot collaboration. Recent hardware developments in robotics have made human-robot collaboration physically possible, but robots still require new algorithms to ensure safety, efficiency, and fluency when working with people. Creating such algorithms is difficult because there can be high uncertainty in what a person is going to do and how they are going to do it. This project explores the integration of reasoning about how a person moves and how he or she makes decisions into a robot motion planning and decision-making framework. The research centers on the development of new algorithmic frameworks for modeling, simulating, and planning for human-robot collaboration, which requires advances in robot training, task modeling, human motion understanding, high-dimensional motion planning with uncertainty, and metrics to assess human-robot joint action. The results of this project have the potential to signi&amp;#64257;cantly improve American competitiveness in manufacturing; especially for small-batch manufacturing and burst production, where the cost and set-up time of fully-autonomous solutions is prohibitive. The work will be disseminated in research papers and integrated into curricula. The project is guided by an advisory board from the manufacturing industry, which provides another avenue for dissemination.</AbstractNarration>
<MinAmdLetterDate>09/15/2016</MinAmdLetterDate>
<MaxAmdLetterDate>09/15/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1658635</AwardID>
<Investigator>
<FirstName>Dmitry</FirstName>
<LastName>Berenson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dmitry Berenson</PI_FULL_NAME>
<EmailAddress>berenson@eecs.umich.edu</EmailAddress>
<PI_PHON>9493515648</PI_PHON>
<NSF_ID>000231987</NSF_ID>
<StartDate>09/15/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName/>
<StateCode>MI</StateCode>
<ZipCode>481091274</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7298</Code>
<Text>International Research Collab</Text>
</ProgramElement>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>5918</Code>
<Text>FRANCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~109030</FUND_OBLG>
<FUND_OBLG>2014~8000</FUND_OBLG>
<FUND_OBLG>2015~49985</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>This project addressed a large space of manufacturing tasks that are tedious or strenuous for humans&nbsp;to perform, and that cannot be fully automated because of either the limitations of current algorithms or&nbsp;prohibitive cost and set-up time. Our collaboration with MIT separated the problem into two parts: 1) Task planning; i.e. determining which task the human/robot would do next (MIT), and 2) human motion inference and robot motion planning (WPI/UM). For the motion level, we sought to develop methods that predict how humans reach in shared workspaces and then to integrate those methods with robot motion planning and control so that the robot performs its task without interfering with the human. Our accomplishments include developing a method that could infer a cost function from human reaching data, which could be used to predict how a human reaches for a target in a shared workspace with another human. We also created a method that builds a library of human motions online and uses this library to recognize the human's current motion and predict the remainder of the current motion. The library can be quickly updated with new data and does not require manual classification of trajectories. Our experiments showed that this library method was useful in human-robot collaborative reaching experiments, where it allowed the robot to quickly predict the human's motion and choose a complimentary motion of its own.</span></p><br> <p>            Last Modified: 10/31/2017<br>      Modified by: Dmitry&nbsp;Berenson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project addressed a large space of manufacturing tasks that are tedious or strenuous for humans to perform, and that cannot be fully automated because of either the limitations of current algorithms or prohibitive cost and set-up time. Our collaboration with MIT separated the problem into two parts: 1) Task planning; i.e. determining which task the human/robot would do next (MIT), and 2) human motion inference and robot motion planning (WPI/UM). For the motion level, we sought to develop methods that predict how humans reach in shared workspaces and then to integrate those methods with robot motion planning and control so that the robot performs its task without interfering with the human. Our accomplishments include developing a method that could infer a cost function from human reaching data, which could be used to predict how a human reaches for a target in a shared workspace with another human. We also created a method that builds a library of human motions online and uses this library to recognize the human's current motion and predict the remainder of the current motion. The library can be quickly updated with new data and does not require manual classification of trajectories. Our experiments showed that this library method was useful in human-robot collaborative reaching experiments, where it allowed the robot to quickly predict the human's motion and choose a complimentary motion of its own.       Last Modified: 10/31/2017       Submitted by: Dmitry Berenson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
