<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative proposal: Variable Selection in the high dimensional, low sample size setting -- Beyond the Linear Regression and Normal Errors Model</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Revolutionary new technologies are producing high-throughput biological data at a resolution that was unthinkable only a decade ago. These new forms of data pose enormous challenges and opportunities for statisticians and computer scientists. This project develops new sophisticated statistical methods and computational algorithms for analyzing and integrating complex high-dimensional data. The work is motivated by collaborations with leading biological scientists at Cornell-Ithaca and Weill Cornell Medical College working in diverse research areas including plant biology, nutrition, neurology, cancer epigenomics, and veterinary medicine. &lt;br/&gt;&lt;br/&gt;The goal of this project is to develop new statistical models and computational algorithms for high-dimensional, low sample size, high-throughput biological data, including new methods for the analysis of microarrays, the identification of quantitative trait loci, association mapping, label-free shotgun proteomics and metabolomics. The proposed methods involve innovative extensions of modern statistical building blocks, including the use of random effects for regularization, shrinkage estimation, Bayesian statistics, and mixtures for posterior classification and prediction. Novel modifications of the expectation-maximization algorithm are proposed for scalable and efficient model fitting and inference.</AbstractNarration>
<MinAmdLetterDate>08/19/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1612625</AwardID>
<Investigator>
<FirstName>Haim</FirstName>
<LastName>Bar</LastName>
<PI_MID_INIT>Y</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Haim Y Bar</PI_FULL_NAME>
<EmailAddress>haim.bar@uconn.edu</EmailAddress>
<PI_PHON>8604865455</PI_PHON>
<NSF_ID>000667489</NSF_ID>
<StartDate>08/19/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Connecticut</Name>
<CityName>Storrs</CityName>
<ZipCode>062691133</ZipCode>
<PhoneNumber>8604863622</PhoneNumber>
<StreetAddress>438 Whitney Road Ext.</StreetAddress>
<StreetAddress2><![CDATA[Unit 1133]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>614209054</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CONNECTICUT</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004534830</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Connecticut]]></Name>
<CityName>Storrs</CityName>
<StateCode>CT</StateCode>
<ZipCode>062691133</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<ProgramElement>
<Code>8011</Code>
<Text>Systems and Synthetic Biology</Text>
</ProgramElement>
<ProgramReference>
<Code>7465</Code>
<Text>NANOSCALE BIO CORE</Text>
</ProgramReference>
<ProgramReference>
<Code>8007</Code>
<Text>BioMaPS</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Revolutionary new technologies are producing high-throughput `omic data at a resolution that was unthinkable only a decade ago. These new forms of data pose enormous challenges and opportunities for statisticians and computer scientists. Our objective in this project was to develop general statistical methodology principles that will aide in the understanding human, microbial, and plant gene expression, metabolomic and proteomic dynamics, and association mapping of complex traits that have broad application in a variety of high-throughput measurement settings.</p> <p>We developed a novel model and a computationally efficient R-package for variable selection for high dimensional, low sample size data (the so-called "large <em>P</em>, small <em>n</em>" problem.) Our method, which we call SEMMS (Scalable EMpirical Bayes Model Selection), is able to determine with high accuracy which of the <em>P</em> predictors should be included in a linear (or generalized linear) model, and which predictors are irrelevant. In statistical terminology, SEMMS is very powerful and maintains a low false positive rate. A freely-available, open-source R-package is available from <a href="https://haim-bar.uconn.edu/software/">https://haim-bar.uconn.edu/software/</a></p> <p>While developing SEMMS, we investigated potential applications to classification problems in the high-dimensional settings (namely, when the number of potential predictors is very large). We found that it is very important to perform variable selection before running the classification algorithm. SEMMS is particularly useful as a screening tool in such applications, because it has a high true positive rate and very low false positive rate, which means that after the variable selection step, the classifier does not have to consider irrelevant predictors (a large number of which, has an adverse effect on classification algorithms such as Support Vector Machines, and random forest), while the useful predictors are found by SEMMS with high probability.</p> <p>In order to implement variable selection for quantile regression in the "large P, small n" setting, we developed a novel statistical method to perform quantile regression. We obtained a closed-form regression estimator, which facilitates statistical inference for the relationship between predictors and the quantiles of some outcome (response) variable. Our method also makes it easy to perform quantile regression in mixed models and in generalized additive models. Our approach also allows researchers to apply model diagnostic techniques in quantile regression, akin to the ones used in the more familiar linear regression setting. We believe that analysis of quantiles, rather than just the mean, can yield very interesting results in all areas of science, and our method makes it easy to extend quantile regression to a wide range of models.</p> <p>Published papers:</p> <ul> <li>Bar, H.; Booth, J.; Wells, M. T.; Liu, K. <em>Facilitating High Dimensional Transparent Classification Via Empirical Bayes Variable Selection</em>. 2018. Applied Stochastic Models in Business and Industry. Volume 34, Issue 6. Pages 949-961</li> <li>Bar, H.; Liu, K. <em>Empirical Bayes Methods in Variable Selection</em>. 2019. WIREs Computational Statistics. Volume 11, Issue 2. doi: 10.1002/wics.1455</li> </ul> <p>Under review:</p> <ul> <li>Bar, H.; Booth, J.; Wells, M.T. <em>A Scalable Empirical Bayes Approach to Variable Selection in Generalized Linear Models</em>. <a href="https://arxiv.org/abs/1803.09735">https://arxiv.org/abs/1803.09735</a> </li> <li>Bar, H.; Booth, J.; Wells, M.T. <em>Quantile Regression Modelling via Location and Scale Mixtures of Normal Distributions</em>. <a href="https://arxiv.org/pdf/1910.11479.pdf">https://arxiv.org/pdf/1910.11479.pdf</a></li> </ul><br> <p>            Last Modified: 11/05/2019<br>      Modified by: Haim&nbsp;Y&nbsp;Bar</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1612625/1612625_10452300_1572993993072_B12SEMMS--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1612625/1612625_10452300_1572993993072_B12SEMMS--rgov-800width.jpg" title="Variable selection with SEMMS"><img src="/por/images/Reports/POR/2019/1612625/1612625_10452300_1572993993072_B12SEMMS--rgov-66x44.jpg" alt="Variable selection with SEMMS"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Riboflavin (vitamin B12) data - a graphical representation of the model found by SEMMS.</div> <div class="imageCredit">Haim Bar</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Haim&nbsp;Y&nbsp;Bar</div> <div class="imageTitle">Variable selection with SEMMS</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Revolutionary new technologies are producing high-throughput `omic data at a resolution that was unthinkable only a decade ago. These new forms of data pose enormous challenges and opportunities for statisticians and computer scientists. Our objective in this project was to develop general statistical methodology principles that will aide in the understanding human, microbial, and plant gene expression, metabolomic and proteomic dynamics, and association mapping of complex traits that have broad application in a variety of high-throughput measurement settings.  We developed a novel model and a computationally efficient R-package for variable selection for high dimensional, low sample size data (the so-called "large P, small n" problem.) Our method, which we call SEMMS (Scalable EMpirical Bayes Model Selection), is able to determine with high accuracy which of the P predictors should be included in a linear (or generalized linear) model, and which predictors are irrelevant. In statistical terminology, SEMMS is very powerful and maintains a low false positive rate. A freely-available, open-source R-package is available from https://haim-bar.uconn.edu/software/  While developing SEMMS, we investigated potential applications to classification problems in the high-dimensional settings (namely, when the number of potential predictors is very large). We found that it is very important to perform variable selection before running the classification algorithm. SEMMS is particularly useful as a screening tool in such applications, because it has a high true positive rate and very low false positive rate, which means that after the variable selection step, the classifier does not have to consider irrelevant predictors (a large number of which, has an adverse effect on classification algorithms such as Support Vector Machines, and random forest), while the useful predictors are found by SEMMS with high probability.  In order to implement variable selection for quantile regression in the "large P, small n" setting, we developed a novel statistical method to perform quantile regression. We obtained a closed-form regression estimator, which facilitates statistical inference for the relationship between predictors and the quantiles of some outcome (response) variable. Our method also makes it easy to perform quantile regression in mixed models and in generalized additive models. Our approach also allows researchers to apply model diagnostic techniques in quantile regression, akin to the ones used in the more familiar linear regression setting. We believe that analysis of quantiles, rather than just the mean, can yield very interesting results in all areas of science, and our method makes it easy to extend quantile regression to a wide range of models.  Published papers:  Bar, H.; Booth, J.; Wells, M. T.; Liu, K. Facilitating High Dimensional Transparent Classification Via Empirical Bayes Variable Selection. 2018. Applied Stochastic Models in Business and Industry. Volume 34, Issue 6. Pages 949-961 Bar, H.; Liu, K. Empirical Bayes Methods in Variable Selection. 2019. WIREs Computational Statistics. Volume 11, Issue 2. doi: 10.1002/wics.1455   Under review:  Bar, H.; Booth, J.; Wells, M.T. A Scalable Empirical Bayes Approach to Variable Selection in Generalized Linear Models. https://arxiv.org/abs/1803.09735  Bar, H.; Booth, J.; Wells, M.T. Quantile Regression Modelling via Location and Scale Mixtures of Normal Distributions. https://arxiv.org/pdf/1910.11479.pdf        Last Modified: 11/05/2019       Submitted by: Haim Y Bar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
