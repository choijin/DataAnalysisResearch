<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAPSI: Developing a Semantic Attributes Learner through Machine Learning Approaches</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2016</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>5400.00</AwardTotalIntnAmount>
<AwardAmount>5400</AwardAmount>
<AwardInstrument>
<Value>Fellowship Award</Value>
</AwardInstrument>
<Organization>
<Code>01090000</Code>
<Directorate>
<Abbreviation>O/D</Abbreviation>
<LongName>Office Of The Director</LongName>
</Directorate>
<Division>
<Abbreviation>OISE</Abbreviation>
<LongName>Office Of Internatl Science &amp;Engineering</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anne Emig</SignBlockName>
<PO_EMAI>aemig@nsf.gov</PO_EMAI>
<PO_PHON>7032927241</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to prove that machine learning approaches in computer vision can discover two key components of fine art classification: first, how humans recognize and classify different visual styles for a target object, and second, what semantic visual attributes they use to finalize their classification decision. Working with a large data set of fine art paintings, the project will investigate a computational procedure to identify a list of word descriptions of different visual styles that is interpretable to humans and is further valid to encode all styles of painting. It can be difficult to provide objective grounds that necessarily determine a visual style: even for the art expert, it is not easy to explain why Claude Monet?s Poppies is classified as impressionist based on its attributes. If the computational algorithm automatically finds semantic attributes determining visual styles that are recognizable to human observers, the result will provide scientific analysis of the human visual perceptual process which is known to be complex to specify. After stabilization, the algorithm will generate annotations describing visual styles for a massive image data set without expensive human work. This data set will be useful data set for future computer vision research. This project will be conducted in collaboration with Professor Seung Wan Hwang in the Data Intelligence Lab at Yonsei University in Korea. Professor Hwang has devised qualitative and quantitative methods to find semantic attributes through data pattern analysis.&lt;br/&gt;&lt;br/&gt;This award supports a research study to design an attributes learner algorithm from datasets that will enable classification of fine art painting styles, and produce extended datasets containing valuable features of the art work that can be annotated automatically via learned attributes generators. Rather than an expensive training set of annotations to learn the attributes of interest, the PI will design a learner which automatically harvests attributes without human supervision. This approach eliminates the need for a predefined (and potentially subjective) vocabulary of semantic attributes which require expert annotation. The project will use numeric high dimensional data gotten through a Deep Artificial Neural Net (ANN) model. The ANN model is trained through a big image data targeting art style inference. With the unsupervised deep architecture that correlates images and textural data through a shared hidden layer, it is expected that the hidden layer?s positive or negative variables will be interpreted as informative attributes. The data set will include some amount of redundant and hard-to-decipher information, so it requires compression and translation to human-interpretable concepts. Since available ground truth information of the data set is limited to authors, year, and art style, cooperative work with the hosting researcher will focus on the extraction of pattern information between the ground truth information and numeric data. There has been similar research work related to feature extraction in academia, but regarding the new subject of Fine Art style and unsupervised attributes learning, this research will be innovative. &lt;br/&gt;&lt;br/&gt;This award under the East Asia and Pacific Summer Institutes program supports summer research by a U.S. graduate student and is jointly funded by NSF and the National Research Foundation of Korea.</AbstractNarration>
<MinAmdLetterDate>05/25/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/25/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.079</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1614279</AwardID>
<Investigator>
<FirstName>Diana</FirstName>
<LastName>Kim</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Diana S Kim</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>9083004582</PI_PHON>
<NSF_ID>000709517</NSF_ID>
<StartDate>05/25/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Kim                     Diana          S</Name>
<CityName>Branchburg</CityName>
<ZipCode>088769998</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM/>
<ORG_LGL_BUS_NAME/>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Kim                     Diana          S]]></Name>
<CityName>Branchburg</CityName>
<StateCode>NJ</StateCode>
<ZipCode>088769998</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramElement>
<ProgramReference>
<Code>5942</Code>
<Text>KOREA</Text>
</ProgramReference>
<ProgramReference>
<Code>5978</Code>
<Text>EAST ASIA AND PACIFIC PROGRAM</Text>
</ProgramReference>
<ProgramReference>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~5400</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>As defined by an American art historian, Meyer Schapiro(1904-1996), the style is a conceptual system synthesizing atomic forms, elements, qualities, and expressions which show consistency in the art of an individual or groups. Finding the components which determine styles is an essential subject which historian has been invested because the combination of the factors becomes fundamental grounds to measure uniqueness and creativity of the pieces as an art by finding consistent or distinctive features between comparison artworks.</p> <p>However, there is no exact formulation existed to represent the systematic relation between constant features and styles, and in practice, styles are not usually defined in a strictly logical way. Even though, there were some historical works to build objective elements determining styles, such as Swiss art historian Henrich Wolf (1864-1945)'s 5 principals (linearly to painterly, plane to recession, closed form to open form, multiplicity to unity, and absolute clarity to relative clarity), the 5 elements are not fully universal, as they were initially devised to discriminate only for Baroque and Renaissance styles. Also, &nbsp;the degree of each element cannot be evaluated accurately by human perceptions. Thus, in constructive purpose, if we can extract semantic elements from the machinery features that classify the styles with acceptable accuracy rate, then the research will provide a reliable baseline to disclose universal forms.</p> <p>Hence, PI &nbsp;investigated a methodology that finds visual attributes from the deep neural network's features for styles by using a number of sophisticated techniques in machine learning and data science. As one of the approaches, PI and host researcher examined multimodal autoencoder that can find correlations between visual attributes and textual concepts corresponding to the attributes. We expected that the model can automatically discover mapping relations between visual and textual features without any human supervision: unsupervised learning. In attributes learning, previous computer vision methods have required a lot of manual annotations so some limitations have existed in their approaches. In this context, &nbsp;we defined the same problem in different point of view so examined a new way to extract visual semantic without predefined attributes information.</p> <p>With&nbsp;&nbsp;65000 fine art images and Wikipedia articles about 17 artistic styles, we finished the training of autoencoder and discovered that our approach can find mapping relations between visual and textual features. However, the found degree of correlation was not enough to generalize our results as robust methodology, so we have conducted an additional experiment&nbsp;with modifications of the modeling structure and refined methods of collecting texture features.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/15/2017<br>      Modified by: Diana&nbsp;S&nbsp;Kim</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ As defined by an American art historian, Meyer Schapiro(1904-1996), the style is a conceptual system synthesizing atomic forms, elements, qualities, and expressions which show consistency in the art of an individual or groups. Finding the components which determine styles is an essential subject which historian has been invested because the combination of the factors becomes fundamental grounds to measure uniqueness and creativity of the pieces as an art by finding consistent or distinctive features between comparison artworks.  However, there is no exact formulation existed to represent the systematic relation between constant features and styles, and in practice, styles are not usually defined in a strictly logical way. Even though, there were some historical works to build objective elements determining styles, such as Swiss art historian Henrich Wolf (1864-1945)'s 5 principals (linearly to painterly, plane to recession, closed form to open form, multiplicity to unity, and absolute clarity to relative clarity), the 5 elements are not fully universal, as they were initially devised to discriminate only for Baroque and Renaissance styles. Also,  the degree of each element cannot be evaluated accurately by human perceptions. Thus, in constructive purpose, if we can extract semantic elements from the machinery features that classify the styles with acceptable accuracy rate, then the research will provide a reliable baseline to disclose universal forms.  Hence, PI  investigated a methodology that finds visual attributes from the deep neural network's features for styles by using a number of sophisticated techniques in machine learning and data science. As one of the approaches, PI and host researcher examined multimodal autoencoder that can find correlations between visual attributes and textual concepts corresponding to the attributes. We expected that the model can automatically discover mapping relations between visual and textual features without any human supervision: unsupervised learning. In attributes learning, previous computer vision methods have required a lot of manual annotations so some limitations have existed in their approaches. In this context,  we defined the same problem in different point of view so examined a new way to extract visual semantic without predefined attributes information.  With  65000 fine art images and Wikipedia articles about 17 artistic styles, we finished the training of autoencoder and discovered that our approach can find mapping relations between visual and textual features. However, the found degree of correlation was not enough to generalize our results as robust methodology, so we have conducted an additional experiment with modifications of the modeling structure and refined methods of collecting texture features.                    Last Modified: 03/15/2017       Submitted by: Diana S Kim]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
