<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Robustness in Social Network Analysis: Models, Inference, and Algorithms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>507996.00</AwardTotalIntnAmount>
<AwardAmount>507996</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The burgeoning field of "Social Network Analysis" focuses on extracting useful insights from such social network data. Implemented or envisioned applications range from learning about the nature and driving forces behind human interactions, to targeted product or activity recommendations and even homeland security. Contrary to other networks, such as transportation or computer networks, massive uncertainty and noise are practically always associated with social network data: data pertaining to individuals are often not observable, or are observed incorrectly. The primary goal of this project is to understand the risks and implications of such noisy data, and to design network analysis algorithms that are significantly more robust to noise and missing data. Given the importance that mathematical models play in social networks analysis, a closely related thread of the project is to analyze the fit between typical social network models and real-world data, in particular regarding high-level connectivity properties. The project website will be used to disseminate research prototypes and data that are collected as part of the project.&lt;br/&gt;&lt;br/&gt;Specifically, three connected research thrusts that integrate the PIs' expertise in machine learning and theoretical computer science will be explored: (1) How well do standard random graph models fit real-world social network data, in particular with regard to expansion and spectral properties? Since the answer likely is "poorly," how well do modifications based on requiring local or global structure remedy this problem? (2) What is the impact of missing observations of diffusion or activation processes on the inferred social networks when learning from some contagious behavior? How can this impact be mitigated by algorithms that take the possibility of missing data into account? (3) If social network data are observed with significant (and possibly non-random) noise, under what conditions can stability of an algorithmic output be ensured? How "obvious" does the right answer have to be to not get obscured by noise in the data? Can "obvious" answers be found more efficiently? The proposed research has the potential to impact the way in which social network inference and optimization are addressed. The PIs are committed to a suite of activities, among them inclusion of undergraduate students in the proposed research and outreach to local high school students, for broader impacts.</AbstractNarration>
<MinAmdLetterDate>06/28/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/28/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1619458</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Kempe</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David M Kempe</PI_FULL_NAME>
<EmailAddress>David.M.Kempe@gmail.com</EmailAddress>
<PI_PHON>2137406438</PI_PHON>
<NSF_ID>000230684</NSF_ID>
<StartDate>06/28/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yan</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yan Liu</PI_FULL_NAME>
<EmailAddress>yanliu.cs@usc.edu</EmailAddress>
<PI_PHON>2137407762</PI_PHON>
<NSF_ID>000572301</NSF_ID>
<StartDate>06/28/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900890001</ZipCode>
<StreetAddress><![CDATA[3720 S. Flower Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~507996</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Outcomes Report:<br /><br />The high-level goal of the grant was to understand both the theoretical foundations and applications of information dissemination processes on networks. Particular interest was devoted to dealing with missing or uncertain information. More specifically, the project team made the following contributions.<br /><br />1. At a fundamental level, the team proposed and investigated in depth network generative models with a focus on global (as opposed to local) network properties. Many network generative models focus on matching local features (such as node degrees or small motifs); yet, most network processes of interest, such as spreads of diseases or information, are much more closely characterized by global properties such as the partition of a network into sparsely connected communities. The team's work proposed different sophisticated models which explicitly aim to match the high-level connectivity structure of a given input graph. These models are based on techniques such as non-convex optimization, linear programming, deep generative neural networks, random walks, and local search techniques. Comprehensive experimental evaluation shows that indeed, these models produce networks that match an input network not only in the network's spectrum (the explicit optimization goal) but also in various other related quantities.<br /><br />2. The team carried out a comprehensive study of algorithmic techniques for inference and optimization of network influence when input data are missing or uncertain. These techniques were based on both more theoretical algorithms (such as PAC learning algorithms of network influence parameters) and more practical heuristics. In order to model such processes accurately, the team formulated various novel influence processes, including mutually influencing point processes and mixtures of cascade models. These models were shown to often result in better fits with real-world data than prior models.<br /><br />3. Building on the comprehensive study of network influence processes, the team carried out an investigation of the dissemination of misinformation from a network point of view. In particular, the team exhibited significant differences in the patterns and timings of retweets and posts between real news and coordinated disinformation campaigns. These analyses both drew on and informed the models based on mixed influence processes. Experimental evaluation confirmed that using such a network-based approach, it is possible to identify coordinated misinformation campaigns using labeled data or other human annotation. This line of work may have significant applications beyond the immediate scientific interest.<br /><br />4. In particular, the team leveraged the techniques described above to carry out the first large-scale analysis of coordinated disinformation campaigns about the Covid-19 pandemic. Building on the network models, the team developed a dashboard that allows visualization of coordinated campaigns by the public and by decisionmakers. This dashboard has the potential to reduce the impact of disinformation campaigns, and thereby to lead to significantly more informed decision making.<br /><br />5. Finally, the team studied how to deal with missing information in learning settings more fundamentally. The team focus on a model of interactive learning, in which an algorithm must repeatedly choose a combinatorial structure, and learns about its mistakes. This setting naturally models learning of classifiers, permutations, or stable matchings, but also the inference of latent network structures by trial and error. The power of the general framework is that it allows the incorporation of incorrect responses as well as dynamic changes in the ground truth while learning happens. Rather than treating each application separately, the framework provides a universal algorithmic approach when can be easily customized.</p><br> <p>            Last Modified: 11/07/2020<br>      Modified by: David&nbsp;M&nbsp;Kempe</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Outcomes Report:  The high-level goal of the grant was to understand both the theoretical foundations and applications of information dissemination processes on networks. Particular interest was devoted to dealing with missing or uncertain information. More specifically, the project team made the following contributions.  1. At a fundamental level, the team proposed and investigated in depth network generative models with a focus on global (as opposed to local) network properties. Many network generative models focus on matching local features (such as node degrees or small motifs); yet, most network processes of interest, such as spreads of diseases or information, are much more closely characterized by global properties such as the partition of a network into sparsely connected communities. The team's work proposed different sophisticated models which explicitly aim to match the high-level connectivity structure of a given input graph. These models are based on techniques such as non-convex optimization, linear programming, deep generative neural networks, random walks, and local search techniques. Comprehensive experimental evaluation shows that indeed, these models produce networks that match an input network not only in the network's spectrum (the explicit optimization goal) but also in various other related quantities.  2. The team carried out a comprehensive study of algorithmic techniques for inference and optimization of network influence when input data are missing or uncertain. These techniques were based on both more theoretical algorithms (such as PAC learning algorithms of network influence parameters) and more practical heuristics. In order to model such processes accurately, the team formulated various novel influence processes, including mutually influencing point processes and mixtures of cascade models. These models were shown to often result in better fits with real-world data than prior models.  3. Building on the comprehensive study of network influence processes, the team carried out an investigation of the dissemination of misinformation from a network point of view. In particular, the team exhibited significant differences in the patterns and timings of retweets and posts between real news and coordinated disinformation campaigns. These analyses both drew on and informed the models based on mixed influence processes. Experimental evaluation confirmed that using such a network-based approach, it is possible to identify coordinated misinformation campaigns using labeled data or other human annotation. This line of work may have significant applications beyond the immediate scientific interest.  4. In particular, the team leveraged the techniques described above to carry out the first large-scale analysis of coordinated disinformation campaigns about the Covid-19 pandemic. Building on the network models, the team developed a dashboard that allows visualization of coordinated campaigns by the public and by decisionmakers. This dashboard has the potential to reduce the impact of disinformation campaigns, and thereby to lead to significantly more informed decision making.  5. Finally, the team studied how to deal with missing information in learning settings more fundamentally. The team focus on a model of interactive learning, in which an algorithm must repeatedly choose a combinatorial structure, and learns about its mistakes. This setting naturally models learning of classifiers, permutations, or stable matchings, but also the inference of latent network structures by trial and error. The power of the general framework is that it allows the incorporation of incorrect responses as well as dynamic changes in the ground truth while learning happens. Rather than treating each application separately, the framework provides a universal algorithmic approach when can be easily customized.       Last Modified: 11/07/2020       Submitted by: David M Kempe]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
