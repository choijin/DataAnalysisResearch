<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Next Generation Connected and Smart Cyber Fire Fighter System</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>199920.00</AwardTotalIntnAmount>
<AwardAmount>199920</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Corman</SignBlockName>
<PO_EMAI>dcorman@nsf.gov</PO_EMAI>
<PO_PHON>7032928754</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to demonstrate that advanced information and sensor technology can improve operational efficiency and increase the security and safety of fire fighters.   Existing firefighting systems will be augmented by exploiting the information capabilities of hardware and software components that can be attached to the existing fire fighter equipment, with minimal physical burden and required training.  The system will provide a model of the emergency scenario that will allow the commander to evaluate possible alternative actions based on their experience and available resources. This situation awareness will be created from the data provided by the fighter gear (microphones, cameras, body and ambient sensors), and will include the estimation of the fighter situation (including fighters' incidents, oxygen reserve or estimated time left to leave the scenario) and the scenario itself (including the presence of victims, evaluation hazardous object or environments, as hot surfaces, toxic gas and others).   This proposal is highly relevant for smart and connected communities.  It addresses problem space of great relevance in emergency operations with a technology solution that faces significant research and operational challenges.  The project engages technical communities, non-profit partners and local government institutions.  It is a cooperation between various departments of the University of New Mexico, in collaboration with the City of Santa Fe and the City of Albuquerque Fire departments and the National Fire Protection Association. &lt;br/&gt;&lt;br/&gt;The project integrates a hardware layout that collects the data from each fire fighter on duty with a software engine for extracting data and processing.  Data from infrared cameras, body and ambient sensors' will be interfaced to a communication node to transmit extracted and compressed information using a mesh structure for communications based on software defined radio supporting heterogeneous communication assets, instant deployment and hot reconfiguration, resiliency and recovery abilities.  The software engine will integrate machine learning based feature extraction and prediction methods that will process the ambient data, audio and speech, to sense the fighter's condition, detect relevant keywords whose meaning can be transmitted, or give orders to the system.  Video will be locally processed to extract relevant features (civilians, heat surfaces, hazardous objects and others). Machine learning algorithms will then be used to construct the situational awareness that will be served to the commander and fire fighters, including scenario and fire fighters' situation.  The system will be tested in a variety of operational scenarios to evaluate the potential for transition and application in other emergency domains.</AbstractNarration>
<MinAmdLetterDate>07/06/2016</MinAmdLetterDate>
<MaxAmdLetterDate>02/11/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1637092</AwardID>
<Investigator>
<FirstName>Ramiro</FirstName>
<LastName>Jordan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ramiro Jordan</PI_FULL_NAME>
<EmailAddress>rjordan@unm.edu</EmailAddress>
<PI_PHON>5052772630</PI_PHON>
<NSF_ID>000409923</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yin</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yin Yang</PI_FULL_NAME>
<EmailAddress>yin5@clemson.edu</EmailAddress>
<PI_PHON>8646563444</PI_PHON>
<NSF_ID>000663449</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Manel</FirstName>
<LastName>Martinez-Ramon</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Manel Martinez-Ramon</PI_FULL_NAME>
<EmailAddress>manel@unm.edu</EmailAddress>
<PI_PHON>5052773008</PI_PHON>
<NSF_ID>000669493</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of New Mexico</Name>
<CityName>Albuquerque</CityName>
<ZipCode>871310001</ZipCode>
<PhoneNumber>5052774186</PhoneNumber>
<StreetAddress>1700 Lomas Blvd. NE, Suite 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<StateCode>NM</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NM01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>868853094</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NEW MEXICO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>784121725</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of New Mexico]]></Name>
<CityName>ALBUQUERQUE</CityName>
<StateCode>NM</StateCode>
<ZipCode>871310001</ZipCode>
<StreetAddress><![CDATA[1 UNIVERSITY OF NEW MEXICO]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NM01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>033Y</Code>
<Text>S&amp;CC: Smart &amp; Connected Commun</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~199920</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div>The present project is intended to produce a situational awareness system specific for fire fighter systems. The methodology is based on the application of artificial intelligence to process the images and data generated by the fire fighter gear. The system detects the respiration and voice of the fire fighter among other signals to determine the level of exhaustion. The images collected by the fire fighter camera are used to detect persons in the scene and objects of interest, as ladders, doors or windows, and fire, The fire and smoke present in the scene are also characterized. The team also developed a nodal communications prototype that is intended to transmit the data to be processed in a hub. The system advances in the application of artificial intelligence to first responders, and the main product consist of the automatic description of the scene, which is achieved by the collection of the different features of the fire ground. The team applied a specific neural network system that is able to describe in a short sentence the scene, for example saying "Two fire fighters and one in a window and fire in the scene", or "firefighter crawling in the scene". We also developed a methodology to determine the emotional state of persons in the scene provided their faces are visible in the image.&nbsp; The novel fire segmentation system and object detection and description from infrared images can be also applied to surveillance systems, law enforcement and other applications that use thermal images where visible light is not available or the vision is impaired by smoke, dust, steam or other situations in an emergency scenario.&nbsp;</div> <div>This project is intended to save lives. The automatic production of situational awareness can help to improve the safety of first responders by providing a propmt and accurate automatic descriptio of the scene, to attract the attention of the commanders to the scenes that require action. Also, the monitoring of the health of the firefighters can prevent injuries or death due to strokes in the fire scene, a situation that is unfortunately not unseen. We also developed methodologies to determine the path of a fire fighter and elements for rescue aid that use artificial intelligence to guid a rescuer in a fire scene to the possible safe paths.</div><br> <p>            Last Modified: 10/26/2019<br>      Modified by: Manel&nbsp;Martinez-Ramon</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572114370835_sceneUnderstandingResult--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572114370835_sceneUnderstandingResult--rgov-800width.jpg" title="Scene understanding"><img src="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572114370835_sceneUnderstandingResult--rgov-66x44.jpg" alt="Scene understanding"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The scenes detected by the fire fighter camera are processed to detect the objects of interest and produce a short sentence to describe the situation.</div> <div class="imageCredit">Manish Bhattarai/Manel Mart?nez-Ram?n, UNM</div> <div class="imageSubmitted">Manel&nbsp;Martinez-Ramon</div> <div class="imageTitle">Scene understanding</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572114889652_MaskRCNNSegnentation--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572114889652_MaskRCNNSegnentation--rgov-800width.jpg" title="Object segmentation."><img src="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572114889652_MaskRCNNSegnentation--rgov-66x44.jpg" alt="Object segmentation."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Every instance of significant object is enclosed with different masks. The instances of fire fighter detection are shaded with distinct colors. Doors and windows are bounded. This is to be used in path planning and navigation.</div> <div class="imageCredit">Manish Bhattarai/Manel Martinez-Ramon, UNM</div> <div class="imageSubmitted">Manel&nbsp;Martinez-Ramon</div> <div class="imageTitle">Object segmentation.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572115681564_sensenom--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572115681564_sensenom--rgov-800width.jpg" title="Architecture of the artificial intelligence system for object detection."><img src="/por/images/Reports/POR/2019/1637092/1637092_10438268_1572115681564_sensenom--rgov-66x44.jpg" alt="Architecture of the artificial intelligence system for object detection."></a> <div class="imageCaptionContainer"> <div class="imageCaption">The architecture shares a common Region ProposalNetwork (RPN) for significant feature extraction. For object tracking, the processed output of the RPNis fed to a classifier and a regressor to output class scores and bounding box co-ordinates respectively.</div> <div class="imageCredit">Manish Bhattarai/Manel Mart?nez-Ram?n, UNM</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Manel&nbsp;Martinez-Ramon</div> <div class="imageTitle">Architecture of the artificial intelligence system for object detection.</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The present project is intended to produce a situational awareness system specific for fire fighter systems. The methodology is based on the application of artificial intelligence to process the images and data generated by the fire fighter gear. The system detects the respiration and voice of the fire fighter among other signals to determine the level of exhaustion. The images collected by the fire fighter camera are used to detect persons in the scene and objects of interest, as ladders, doors or windows, and fire, The fire and smoke present in the scene are also characterized. The team also developed a nodal communications prototype that is intended to transmit the data to be processed in a hub. The system advances in the application of artificial intelligence to first responders, and the main product consist of the automatic description of the scene, which is achieved by the collection of the different features of the fire ground. The team applied a specific neural network system that is able to describe in a short sentence the scene, for example saying "Two fire fighters and one in a window and fire in the scene", or "firefighter crawling in the scene". We also developed a methodology to determine the emotional state of persons in the scene provided their faces are visible in the image.  The novel fire segmentation system and object detection and description from infrared images can be also applied to surveillance systems, law enforcement and other applications that use thermal images where visible light is not available or the vision is impaired by smoke, dust, steam or other situations in an emergency scenario.  This project is intended to save lives. The automatic production of situational awareness can help to improve the safety of first responders by providing a propmt and accurate automatic descriptio of the scene, to attract the attention of the commanders to the scenes that require action. Also, the monitoring of the health of the firefighters can prevent injuries or death due to strokes in the fire scene, a situation that is unfortunately not unseen. We also developed methodologies to determine the path of a fire fighter and elements for rescue aid that use artificial intelligence to guid a rescuer in a fire scene to the possible safe paths.       Last Modified: 10/26/2019       Submitted by: Manel Martinez-Ramon]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
