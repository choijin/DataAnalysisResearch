<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Machine Vision for Content-based Video Marketing Analytics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>224632.00</AwardTotalIntnAmount>
<AwardAmount>224632</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to protect consumer privacy while continuing to enable the ad-supported Internet model. Current tracking-based consumer targeting approaches inherently erode consumer privacy, surreptitiously tracking users across many different web sites in an effort to gather demographic and behavioral data. On the flip side of the coin, marketers need to collect such data to successfully reach their audiences, and the revenue that marketers pour into advertising online has become an essential component of the economics of the internet. Today, this delicate balance of competing pros and cons is further threatened by the rise of ad-blocking software, which erodes the value of internet ad placement. The video marketing analytics capability developed in this project will limit marketers' need for invasive consumer data, while improving consumer experience. In the commercial realm, marketers would value the opportunity to target their ads in the most emotionally consonant, least disruptive, and most engaging manner possible. This technology will provide marketers with the capability to watch millions of videos algorithmically, thus enabling a more streamlined and customized viewer experience than has ever before been possible on television or on the Internet. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research Phase I project seeks to develop commercial applications for Perceptual Annotation, a technology developed with NSF funding that allows detailed measurements of human performance to be infused into a machine learning process, allowing the machine learner to both perform better and to perform in a way that is more consistent with humans. By adding this new category of human-derived supervisory signal into a machine learning process, the proposers have demonstrated that it is possible to significantly boost machine vision performance, allowing machines to generalize better to new, previously unseen images. While the company's technology has been rigorously validated on large-scale "in the wild" academic datasets, a major technical drive in the proposed SBIR Phase I activities will be to shift the company's efforts to the analysis of "live," enormous, and ever-expanding data sets such as online videos. A second major drive of the proposed Phase I work will be the construction of "second stage" machine learning models that take perceptual-annotation-based machine ratings as an input and output actionable marketing decisions.</AbstractNarration>
<MinAmdLetterDate>06/24/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1621689</AwardID>
<Investigator>
<FirstName>Samuel</FirstName>
<LastName>Anthony</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Samuel E Anthony</PI_FULL_NAME>
<EmailAddress>santhony@perceptiveautomata.com</EmailAddress>
<PI_PHON/>
<NSF_ID>000707993</NSF_ID>
<StartDate>06/24/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Perceptive Automata, Inc.</Name>
<CityName>Cambridge</CityName>
<ZipCode>021421190</ZipCode>
<PhoneNumber>6172991296</PhoneNumber>
<StreetAddress>1 Broadway 5th Fl</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080016534</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PERCEPTIVE AUTOMATA, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>080016534</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Perceptive Automata, Inc.]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021631002</ZipCode>
<StreetAddress><![CDATA[125 Western Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~224632</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project conducted computer vision and machine learning research based on neuroscience and behavioral science approaches developed by the PI Samuel Anthony at Perceptive Automata. This SBIR Phase I project sought to continue development of commercial applications for Perceptual Annotation, a technology developed with prior NSF funding that allows detailed measurements of human performance to be infused into a machine learning process, allowing the machine learner to both perform better and to perform in a way that is more consistent with humans. By adding this new category of human-derived supervisory signal into a machine learning process, we have demonstrated that it is possible to significantly boost machine vision performance, allowing machines to generalize better to new, previously unseen situations.&nbsp;</p> <p>This NSF Phase I project led to academic publications in leading computer vision journals and conferences such as the IEEE Face and Gesture Conference 2017. The grant was used to support both academic researchers and enable the hiring of full time employees by the small business. The work also provided training opportunities for undergraduate students.</p> <p>This project proved the existence of a novel avenue for commercialization of behavioral science research. The project also resulted in commercial validation of this approach to machine learning and is now achieving significant commercial traction with customers. The applications of this approach were targeted at several industries including marketing technology, security, corporate recruitment, and robotics. Within several of these application areas, the research conducted in this project created pathways for future commercial products enabling socially beneficial outcomes. Examples of the broader societal impacts enabled by this research include more unbiased and inclusive corporate recruitment, improved human-robot interaction, prevention of inventory loss due to theft, and privacy protection in online ad targeting.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/15/2017<br>      Modified by: Samuel&nbsp;E&nbsp;Anthony</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project conducted computer vision and machine learning research based on neuroscience and behavioral science approaches developed by the PI Samuel Anthony at Perceptive Automata. This SBIR Phase I project sought to continue development of commercial applications for Perceptual Annotation, a technology developed with prior NSF funding that allows detailed measurements of human performance to be infused into a machine learning process, allowing the machine learner to both perform better and to perform in a way that is more consistent with humans. By adding this new category of human-derived supervisory signal into a machine learning process, we have demonstrated that it is possible to significantly boost machine vision performance, allowing machines to generalize better to new, previously unseen situations.   This NSF Phase I project led to academic publications in leading computer vision journals and conferences such as the IEEE Face and Gesture Conference 2017. The grant was used to support both academic researchers and enable the hiring of full time employees by the small business. The work also provided training opportunities for undergraduate students.  This project proved the existence of a novel avenue for commercialization of behavioral science research. The project also resulted in commercial validation of this approach to machine learning and is now achieving significant commercial traction with customers. The applications of this approach were targeted at several industries including marketing technology, security, corporate recruitment, and robotics. Within several of these application areas, the research conducted in this project created pathways for future commercial products enabling socially beneficial outcomes. Examples of the broader societal impacts enabled by this research include more unbiased and inclusive corporate recruitment, improved human-robot interaction, prevention of inventory loss due to theft, and privacy protection in online ad targeting.           Last Modified: 12/15/2017       Submitted by: Samuel E Anthony]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
