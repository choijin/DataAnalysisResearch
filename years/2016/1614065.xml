<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAPSI: Real-time 3D Reconstruction for Autonomous Underwater Manipulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2016</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>5400.00</AwardTotalIntnAmount>
<AwardAmount>5400</AwardAmount>
<AwardInstrument>
<Value>Fellowship Award</Value>
</AwardInstrument>
<Organization>
<Code>01090000</Code>
<Directorate>
<Abbreviation>O/D</Abbreviation>
<LongName>Office Of The Director</LongName>
</Directorate>
<Division>
<Abbreviation>OISE</Abbreviation>
<LongName>Office Of Internatl Science &amp;Engineering</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anne Emig</SignBlockName>
<PO_EMAI>aemig@nsf.gov</PO_EMAI>
<PO_PHON>7032927241</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The focus of this project is to develop and test algorithms to enable an underwater robotic system with a manipulator to sense, recognize, and retrieve an object from the seafloor, in real-time, with no user input. This work will be conducted in collaboration with Dr. Stefan Williams of the Australian Center for Field Robotics (ACFR) at the University of Sydney, Australia. Dr. Williams is an expert in the field of perception and navigation for underwater robotics, and ACFR has vehicles and facilities ideal for carrying out this work. Several applications of this work include deep-sea scientific sampling and exploration, and construction and maintenance of offshore equipment.&lt;br/&gt;&lt;br/&gt;The objective of this project is to develop novel methods for real-time underwater perception to enable autonomous intervention in aqueous environments. Methods will be developed for real-time underwater 3D reconstruction using input stereo-vision imagery for the application of autonomous grasping underwater.  These novel methods will be validated through testing on a remotely operated vehicle (ROV) equipped with stereo-vision cameras and a single function manipulator. The main goals will be to visually reconstruct an object on the seafloor in real-time and then pick up that object. Results of the 3D reconstruction will be compared to laser-acquired ground truth and through observing the interaction task with an external set of cameras to determine effectiveness in grasping. Ultimately, the results will demonstrate closed loop grasping underwater, a fundamental task for autonomous intervention, which is necessary for applications such as deep-sea scientific sampling and maintenance of offshore equipment.&lt;br/&gt;&lt;br/&gt;This award under the East Asia and Pacific Summer Institutes program supports summer research by a U.S. graduate student and is jointly funded by NSF and the Australian Academy of Science.</AbstractNarration>
<MinAmdLetterDate>06/07/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/07/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.079</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1614065</AwardID>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Skinner</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katherine A Skinner</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>7346150312</PI_PHON>
<NSF_ID>000709277</NSF_ID>
<StartDate>06/07/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Skinner                 Katherine      A</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481042414</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM/>
<ORG_LGL_BUS_NAME/>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Skinner                 Katherine      A]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481042414</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramElement>
<ProgramReference>
<Code>5912</Code>
<Text>AUSTRALIA</Text>
</ProgramReference>
<ProgramReference>
<Code>5978</Code>
<Text>EAST ASIA AND PACIFIC PROGRAM</Text>
</ProgramReference>
<ProgramReference>
<Code>7316</Code>
<Text>EAPSI</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~5400</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Autonomous underwater manipulation has a wide range of applications from deep-sea scientific sampling to offshore resource extraction. Autonomous systems, which operate without user input, rely on real-time perception for interpreting their environment in order to carry out a task. In underwater environments, this is especially challenging due to the complex physical model of light propagation through the water column. Effects such as absorption and scattering of light cause attenuation of a light ray as it travels from the camera to the scene and back, resulting in hazy, low contrast images, often blue-green in color due to the relatively high attenuation of the red channel. Due to this complex process of image formation, real-time perception is a challenge in subsea environments. The main objective of this project is to develop novel methods for enabling real-time underwater perception. Our prior work demonstrated the capabilities of using light field, or plenoptic, cameras in a real-time 3D reconstruction pipeline for subsea applications. Unlike traditional cameras, light field cameras feature a micro-lens array between the main lens and the image sensor, allowing capture of images and depth (RGB-D) data from a single passive optical sensor. This prior work incorporated a model of underwater image formation into the 3D reconstruction step to correct for effects of underwater light propagation; however, it did not account for these effects in the light field processing step, which takes raw sensor data, decodes this data to retrieve angular and spatial information about the light field, and then constructs high resolution images and depth maps of the scene. To improve upon prior work, this project presents a novel algorithm for the first stage of light field processing, decoding. The algorithm is efficient, easy to implement, and can be incorporated into the current framework for real-time underwater 3D reconstruction with a light field camera. This method will enable improvements to the current framework by allowing adaptation for water column effects in the light field processing stage of the 3D reconstruction pipeline. To validate the proposed and future work, an artificial rock platform was surveyed with a Raytrix R5 light field camera at video framerate. The survey was done in air, and in a saltwater sea pool in Sydney, Australia. The rock platform was also imaged with a traditional camera in air to provide a ground truth colored 3D model for quantitative evaluation. Overall, the outcome of this project is a novel algorithm for efficiently decoding raw light field data, including software and datasets for quantitative evaluation of methods for light field processing in underwater environments. The intellectual merit of this work is to enable improvements to a state-of-the-art real-time underwater 3D reconstruction pipeline. The broader impact of this project is to work towards the end application of achieving safe and precise autonomous underwater manipulation.</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/09/2017<br>      Modified by: Katherine&nbsp;A&nbsp;Skinner</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Autonomous underwater manipulation has a wide range of applications from deep-sea scientific sampling to offshore resource extraction. Autonomous systems, which operate without user input, rely on real-time perception for interpreting their environment in order to carry out a task. In underwater environments, this is especially challenging due to the complex physical model of light propagation through the water column. Effects such as absorption and scattering of light cause attenuation of a light ray as it travels from the camera to the scene and back, resulting in hazy, low contrast images, often blue-green in color due to the relatively high attenuation of the red channel. Due to this complex process of image formation, real-time perception is a challenge in subsea environments. The main objective of this project is to develop novel methods for enabling real-time underwater perception. Our prior work demonstrated the capabilities of using light field, or plenoptic, cameras in a real-time 3D reconstruction pipeline for subsea applications. Unlike traditional cameras, light field cameras feature a micro-lens array between the main lens and the image sensor, allowing capture of images and depth (RGB-D) data from a single passive optical sensor. This prior work incorporated a model of underwater image formation into the 3D reconstruction step to correct for effects of underwater light propagation; however, it did not account for these effects in the light field processing step, which takes raw sensor data, decodes this data to retrieve angular and spatial information about the light field, and then constructs high resolution images and depth maps of the scene. To improve upon prior work, this project presents a novel algorithm for the first stage of light field processing, decoding. The algorithm is efficient, easy to implement, and can be incorporated into the current framework for real-time underwater 3D reconstruction with a light field camera. This method will enable improvements to the current framework by allowing adaptation for water column effects in the light field processing stage of the 3D reconstruction pipeline. To validate the proposed and future work, an artificial rock platform was surveyed with a Raytrix R5 light field camera at video framerate. The survey was done in air, and in a saltwater sea pool in Sydney, Australia. The rock platform was also imaged with a traditional camera in air to provide a ground truth colored 3D model for quantitative evaluation. Overall, the outcome of this project is a novel algorithm for efficiently decoding raw light field data, including software and datasets for quantitative evaluation of methods for light field processing in underwater environments. The intellectual merit of this work is to enable improvements to a state-of-the-art real-time underwater 3D reconstruction pipeline. The broader impact of this project is to work towards the end application of achieving safe and precise autonomous underwater manipulation.          Last Modified: 03/09/2017       Submitted by: Katherine A Skinner]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
