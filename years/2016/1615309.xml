<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  A scale-out data transfer solution for data-intensive enterprises</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will be to enable data-intensive engineering and science organizations to enhance their data transfer speeds without having to administer premature, costly, and disruptive network upgrades. In addition, the findings and results from this project shed a much needed light to the members of data-intensive communities (both commercial and research) regarding the importance of treating data movement as the 4th critical IT dimension, besides the traditional three: storage, compute, and networking. Furthermore, the project's outcome will show that the 4th-dimension must be defined by balanced interactions of the first three to achieve a desired data transfer speed - an important and elusive concept to grasp, but critical in using high-speed digital communications cost-effectively. Compared to the current state-of-the-art, the product resulting from this project will be far more scalable, space and energy efficient, cost-effective, and easy to deploy and use. Finally, the product will demonstrate that it can meet the data transfer needs of major scientific and commercial endeavors of this decade. This should foster accelerated progress in science and engineering, and thus also the overall national economic health.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project addresses the need in modern distributed data-intensive engineering and science operations for a 4th IT dimension - data movement - besides storage, compute, and networking. To match the exponential data-growth trend, the product resulting from this project will provide high-performance data transfer and encryption. The design balances and scales in: IOPS, computation power, and network interfaces. It has a cluster-oriented architecture, using peer-to-peer technologies to ease deployment, operation, and usage. Two patent-pending algorithms help tackle data sets containing a mix of small files and very large files, and provide insensitivity to network latency. Its unique optimizations enable effective use of flash storage. The project will develop a simple, effective, and scale-out capable storage tiering software, a scale-out high-speed data encryption approach, and a scale-out approach for implementing more efficient storage I/O intensive applications. It is anticipated that data rates between two existing Data Transfer Nodes (DTNs) front ending parallel data file systems will be comparable with those from two commonly used high performance data transfer applications. With two four-node clusters, the product is anticipated to achieve 155Gbps memory-to-memory over a 16x10Gbps aggregated link and 70Gbps file-to-file with encryption over a 5000 mile 100Gbps link.</AbstractNarration>
<MinAmdLetterDate>06/22/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1615309</AwardID>
<Investigator>
<FirstName>Chin</FirstName>
<LastName>Fang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chin Fang</PI_FULL_NAME>
<EmailAddress>fangchin@zettar.com</EmailAddress>
<PI_PHON>6506449722</PI_PHON>
<NSF_ID>000707992</NSF_ID>
<StartDate>06/22/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Zettar Inc.</Name>
<CityName>Mountain View</CityName>
<ZipCode>940412055</ZipCode>
<PhoneNumber>6506449722</PhoneNumber>
<StreetAddress>650 Castro Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 120-470]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>059480123</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ZETTAR, INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[SLAC National Accelerator Laboratory]]></Name>
<CityName>Menlo Park</CityName>
<StateCode>CA</StateCode>
<ZipCode>940257015</ZipCode>
<StreetAddress><![CDATA[2575 Sand Hill Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Zettar carried out R&amp;D during this IT2 Phase I project to realize the following two goals:</p> <ol> <li><strong>A simple, effective, and scale-out capable all NVMe HPC storage tier (aka burst buffer) reference design and implementation, together with a scale-out capable high-speed Hierarchy Storage Management (HSM) software prototype.</strong></li> <li><strong><strong>A scale-out data encryption approach for high-speed massive data transfers that keeps the cost, computational power, and energy consumption for required CPUs as modest as possible.</strong><br /></strong></li> </ol> <p>For goal 1, the reference design and impementation completely eliminated the need of a built-in RAID in each data transfer node (aka DTN). &nbsp;Instead, a parallel file system, BeeGFS, was employed for aggregating distributed NVMe SSDs across the cluster in the actual reference implementation. &nbsp;To demonstrate that the scale-out part of the reference design, the "burst buffer" is formed using two 1U all-NVMe storage servers populated with Intel DC P3700 2.5" NVMe SSDs. &nbsp;The implementation is capable of supplying enough IOPS to support very high data transfer rate (file-to-file 100Gbps). &nbsp;This Intel IT Peer Network Article, "<a title="Transferring data at 100Gbps and beyond for distributed data-intensive engineering and sciences" href="https://itpeernetwork.intel.com/transferring-data-for-distributed-data-intensive-engineering/" target="_blank">Transferring data at 100Gbps and beyond for distributed data-intensive engineering and sciences</a>", published in November 2016 provides further details and a functional diagram of the innovative and flexible testbed.</p> <p>For goal 2, Zettar used the popular, but not the most optimal and fastest OpenSSL library as the baseline, and then carefully and methodologically evaluated the use of two other new candidate crypto libraries: Botan, and BoringSSL, for their performance boosting potential. Furthermore, all evaluations were done in a parallel computing context. &nbsp;As such, the research is unique and highly innovative. The successful outcome of the research convincingly proved that it is completely feasible to eliminate the need of purchasing and using special purpose encryption acceleration hardware for reduced cost, hardware count, and energy consumption.</p> <p>Both project goals have been achieved, especially the first one. &nbsp;It is of interest to note that "burst buffer" is an approach commonly employed by highly expensive supercomputers. &nbsp;Zettar has created a reference design and a fully working implementation that is based on commercial-off-the-shelf (COTS) hardware. &nbsp;They can be used by general enterprises. &nbsp;</p> <p>In fact, the reference implementation has proven to be superior in performance than even some commercially available entities. For this part of project, Zettar got support from a few well-established hardware vendors, AIC Inc., Intel NSG, Mellanox, ThinkParQ. &nbsp;All of them were impressed and pleased with the implementation's high performance levels. &nbsp;Thus, all of them asked Zettar to work with them on product related blogs and white papers. For example, combining the results from both goals, Mellanox published a blog "<a title="Mellanox and Zettar Crush World Record LOSF Performance Using ESnet OSCARS Test Circuit" href="https://www.mellanox.com/blog/2016/12/mellanox-and-zettar-crush-world-record-losf-performance-using-esnet-oscars-test-circuit/" target="_blank">Mellanox and Zettar Crush World Record LOSF Performance Using ESnet OSCARS Test Circuit</a>"; AIC and Intel commissioned Zettar to write a white paper "<a title="Using AIC SB122A-PH 1U 10-Bay NVMe Storage Servers as the Building Blocks of High-Performance Scale-out Storage for HPC Applications" href="http://www.aicipc.com/image/images/header/Using%20AIC%20SB122A-PH%201U%2010-Bay%20NVMe%20Storage%20Servers%20as%20the%20Building%20Blocks%20of%20High-Performance%20Scale-out%20Storage%20for%20HPC%20Applications.pdf" target="_blank">Using AIC SB122A-PH 1U 10-Bay NVMe Storage Servers as the Building Blocks of High-Performance Scale-out Storage for HPC Applications</a>" &nbsp;</p> <p>During the prestigious <a title="SC16" href="http://sc16.supercomputing.org/">Supercomputing 2016 (SC16) Conference</a>, all of them also asked Zettar to show live demos and give talks in their respective booth. For example, see the Zettar kiosk in Mellanox's SC16 booth.</p> <p>In early May, 2017, during the <a title="ESCC Spring 2017" href="https://escc.es.net/?q=node/3" target="_blank">ESCC Spring 2017</a>, Zettar used a slightly modified testbed, with the "burst buffer" designed and built in late 2016, accomplished transferring 1PB in 34 hours over a 5000-mile, 100Gbps production network provided by US DOE's <a title="Energy Science Network" href="http://es.net/">Energy Science Network</a>. &nbsp;With this, Zettar's entire data transfer software platform became likely the world's first petescale-proven commercial hyperscale (PB and larger) data distribution platform. &nbsp;Again, the feat was highly welcomed by Zettar's vendor partners. AIC for example, made <a title="AIC press release" href="http://www.prnewswire.com/news-releases/zettar-transferred-1-petabyte-of-data-in-just-34-hours-using-aic-servers-300463058.html">a press release</a> which as of this writing is ranked first using the Google search phase "<a title="petabyte data transfer" href="https://www.google.com/search?q=petabyte+data+transfer">petabyte data transfer</a>". &nbsp;The PI would like to acknowledge the support of this NSF SBIR Phase I grant for all have been accomplished during the project.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/08/2017<br>      Modified by: Chin&nbsp;Fang</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1615309/1615309_10435186_1499490251271_20161115_074132--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1615309/1615309_10435186_1499490251271_20161115_074132--rgov-800width.jpg" title="The Zettar kiosk in Mellanox SC16 booth"><img src="/por/images/Reports/POR/2017/1615309/1615309_10435186_1499490251271_20161115_074132--rgov-66x44.jpg" alt="The Zettar kiosk in Mellanox SC16 booth"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Zettar kiosk in the SC16 booth of Mellanox Technologies</div> <div class="imageCredit">Zettar Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Chin&nbsp;Fang</div> <div class="imageTitle">The Zettar kiosk in Mellanox SC16 booth</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Zettar carried out R&amp;D during this IT2 Phase I project to realize the following two goals:  A simple, effective, and scale-out capable all NVMe HPC storage tier (aka burst buffer) reference design and implementation, together with a scale-out capable high-speed Hierarchy Storage Management (HSM) software prototype. A scale-out data encryption approach for high-speed massive data transfers that keeps the cost, computational power, and energy consumption for required CPUs as modest as possible.    For goal 1, the reference design and impementation completely eliminated the need of a built-in RAID in each data transfer node (aka DTN).  Instead, a parallel file system, BeeGFS, was employed for aggregating distributed NVMe SSDs across the cluster in the actual reference implementation.  To demonstrate that the scale-out part of the reference design, the "burst buffer" is formed using two 1U all-NVMe storage servers populated with Intel DC P3700 2.5" NVMe SSDs.  The implementation is capable of supplying enough IOPS to support very high data transfer rate (file-to-file 100Gbps).  This Intel IT Peer Network Article, "Transferring data at 100Gbps and beyond for distributed data-intensive engineering and sciences", published in November 2016 provides further details and a functional diagram of the innovative and flexible testbed.  For goal 2, Zettar used the popular, but not the most optimal and fastest OpenSSL library as the baseline, and then carefully and methodologically evaluated the use of two other new candidate crypto libraries: Botan, and BoringSSL, for their performance boosting potential. Furthermore, all evaluations were done in a parallel computing context.  As such, the research is unique and highly innovative. The successful outcome of the research convincingly proved that it is completely feasible to eliminate the need of purchasing and using special purpose encryption acceleration hardware for reduced cost, hardware count, and energy consumption.  Both project goals have been achieved, especially the first one.  It is of interest to note that "burst buffer" is an approach commonly employed by highly expensive supercomputers.  Zettar has created a reference design and a fully working implementation that is based on commercial-off-the-shelf (COTS) hardware.  They can be used by general enterprises.    In fact, the reference implementation has proven to be superior in performance than even some commercially available entities. For this part of project, Zettar got support from a few well-established hardware vendors, AIC Inc., Intel NSG, Mellanox, ThinkParQ.  All of them were impressed and pleased with the implementation's high performance levels.  Thus, all of them asked Zettar to work with them on product related blogs and white papers. For example, combining the results from both goals, Mellanox published a blog "Mellanox and Zettar Crush World Record LOSF Performance Using ESnet OSCARS Test Circuit"; AIC and Intel commissioned Zettar to write a white paper "Using AIC SB122A-PH 1U 10-Bay NVMe Storage Servers as the Building Blocks of High-Performance Scale-out Storage for HPC Applications"    During the prestigious Supercomputing 2016 (SC16) Conference, all of them also asked Zettar to show live demos and give talks in their respective booth. For example, see the Zettar kiosk in Mellanox's SC16 booth.  In early May, 2017, during the ESCC Spring 2017, Zettar used a slightly modified testbed, with the "burst buffer" designed and built in late 2016, accomplished transferring 1PB in 34 hours over a 5000-mile, 100Gbps production network provided by US DOE's Energy Science Network.  With this, Zettar's entire data transfer software platform became likely the world's first petescale-proven commercial hyperscale (PB and larger) data distribution platform.  Again, the feat was highly welcomed by Zettar's vendor partners. AIC for example, made a press release which as of this writing is ranked first using the Google search phase "petabyte data transfer".  The PI would like to acknowledge the support of this NSF SBIR Phase I grant for all have been accomplished during the project.          Last Modified: 07/08/2017       Submitted by: Chin Fang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
