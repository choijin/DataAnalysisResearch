<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Co-Designing Distributed Coordination Systems and the Datacenter Network</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>428214.00</AwardTotalIntnAmount>
<AwardAmount>428214</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Datacenter applications must remain continuously available and keep data consistent despite the fact that individual servers may fail. This is one of the fundamental challenges of distributed systems design: coordinating accesses to distributed services. Today's systems solve these problems with sophisticated distributed algorithms like Paxos and two-phase commit, yet these are frequently considered too expensive for practical use. This is because these algorithms are designed independently from -- and must make worst-case assumptions about -- the underlying network.&lt;br/&gt;&lt;br/&gt;This project will explore a new approach to designing distributed systems for the datacenter: co-designing distributed protocols with the network layer. This includes designing new network-level primitives to enable datacenter networks to provide stronger semantics, e.g., an approximately synchronous mode of execution. Then these primitives will be used to design high-performance distributed systems, including state machine replication protocols and transactional storage systems.&lt;br/&gt;&lt;br/&gt;This work will improve the ability of distributed systems to provide fault tolerance with high performance, increasing the robustness of critical datacenter infrastructure. It will also reduce the cost of strongly-consistent transactional storage, making it easier for application developers to reason about concurrent accesses to shared data, and thereby encourage innovation.</AbstractNarration>
<MinAmdLetterDate>08/08/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/08/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1615102</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Ports</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Ports</PI_FULL_NAME>
<EmailAddress>drkp@cs.washington.edu</EmailAddress>
<PI_PHON>2065433069</PI_PHON>
<NSF_ID>000655870</NSF_ID>
<StartDate>08/08/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981952350</ZipCode>
<StreetAddress><![CDATA[185 Stevens Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~428214</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Today's most important applications are built as distributed systems running in datacenters. These systems rely on distributed coordination protocols. Key infrastructure services use distributed replication protocols to ensure that they are highly available, even as servers fail. Advanced distributed databases and storage services use distributed transaction protocols to coordinate accesses to shared data. However, today's protocols come with a substantial performance cost. This project showed that it is possible to build faster coordination systems by taking advantage of the datacenter environment.<br /><br />Traditional distributed protocols are designed independently from the network, treating it simply as an unreliable communications channel. This forces them to make worst-case assumptions about network behavior, e.g., asynchrony -- an approach well-suited for the traditional Internet. However, many distributed applications today ar edeployed in datacenters, where the network is more reliable, predictable, and extensible. Recent advances in programmable network hardware allow custom logic to be placed in network devices themselves, and run at extremely high speed. This means that in datacenter environments, there is now an opportunity to co-design distributed systems with the network layer.<br /><br />This project had two goals: 1) to show that it is possible to achieve new levels of approximately synchronous network behavior in the datacenter, and 2) to show that faster distributed systems can be built by taking advantage of this behavior. The former was achieved by prototyping new network primitives using programmable network devices, and the latter by building new distributed algorithms and systems.<br /><br />A key concept developed as part of this project is the idea of network sequencing. This is a conceptually simple idea: a network device assigns an increasing sequence number to each packet that it processes. But it is powerful for distributed system designers, as transforming the network from an asynchronous model to an ordered but unreliable model enables new distributed algorithms with important applications.<br /><br />We initially demonstrated the power of network sequencing by building a protocol called Network-Ordered Paxos (NOPaxos). NOPaxos is a state machine replication protocol for making systems fault tolerant. Traditional approaches (Multi-Paxos or Viewstamped Replication) come with high throughput and latency cost. By relying on network sequencing, NOPaxos can use a faster protocol in the common case, yielding a 4.7x throughput improvement and offering replication with less than 2% overhead.<br /><br />Subsequently, we demonstrated that an extended version of network sequencing can be applied to transaction process in distributed database systems. This is a more complex coordination problem as these databases use not only use cross-shard distributed transaction coordination protocols (e.g., two-phase commit) to make the system scalable yet consistent, but also inter-shard replication using replication protocols like Paxos. Our new protocol, Eris, replaces both with a simpler protocol that leverages network sequencing. We used it to build a prototype database that can implement certain strongly consistent distributed transactions without coordination, offering a 35x performance improvement over existing systems.<br /><br />In-network coordination support enables new optimizations for replicated systems. Ideally, it would be possible to build a replicated system where any server can process a read request, allowing system throughput to scale with the number of servers. Unfortunately, existing systems cannot do this safely, and indeed their throughput usually drops as the number of replicas increases. We addressed this by designing the Harmonia storage architecture. Its main insight is that an in-network primitive can track which objects in a storage system are currently being modified, making it possible to use a single-replica read optimization only when safe. The resulting system integrates with existing replication protocols and databases, and allows them to scale near-linearly for read requests.<br /><br />Finally, we showed that a new in-network coordination system can help storage systems handle skewed workloads, where some objects are much more popular than others. Traditionally, systems must provision each server for the most popular objects, wasting resources. Our design moves the mapping between objects and the servers that store them into an in-network coherence directory, allowing it to easily move or replicate objects for better load balancing. The Pegasus system implements this in-network coherence directory and protocol, demonstrating that a storage system can use it to tolerate skewed workloads with as many as 90% fewer servers.<br /><br />In sum, this project demonstrated the feasibility and benefits of a co-design approach between distributed coordination systems and datacenter network primitives. This approach makes it possible to build systems that are more than the sum of their parts: they achieve performance results impossible with traditional designs, enabling faster systems with better fault tolerance.<br /><br />The research described in this report is described in detail in papers published in systems and data management venues (the OSDI, SOSP, and VLDB conferences). Research artifacts, including implementations of the Network-Ordered Paxos, Eris, and Pegasus systems, have been released as open-source software and made available on GitHub.</p><br> <p>            Last Modified: 02/24/2021<br>      Modified by: Daniel&nbsp;Ports</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Today's most important applications are built as distributed systems running in datacenters. These systems rely on distributed coordination protocols. Key infrastructure services use distributed replication protocols to ensure that they are highly available, even as servers fail. Advanced distributed databases and storage services use distributed transaction protocols to coordinate accesses to shared data. However, today's protocols come with a substantial performance cost. This project showed that it is possible to build faster coordination systems by taking advantage of the datacenter environment.  Traditional distributed protocols are designed independently from the network, treating it simply as an unreliable communications channel. This forces them to make worst-case assumptions about network behavior, e.g., asynchrony -- an approach well-suited for the traditional Internet. However, many distributed applications today ar edeployed in datacenters, where the network is more reliable, predictable, and extensible. Recent advances in programmable network hardware allow custom logic to be placed in network devices themselves, and run at extremely high speed. This means that in datacenter environments, there is now an opportunity to co-design distributed systems with the network layer.  This project had two goals: 1) to show that it is possible to achieve new levels of approximately synchronous network behavior in the datacenter, and 2) to show that faster distributed systems can be built by taking advantage of this behavior. The former was achieved by prototyping new network primitives using programmable network devices, and the latter by building new distributed algorithms and systems.  A key concept developed as part of this project is the idea of network sequencing. This is a conceptually simple idea: a network device assigns an increasing sequence number to each packet that it processes. But it is powerful for distributed system designers, as transforming the network from an asynchronous model to an ordered but unreliable model enables new distributed algorithms with important applications.  We initially demonstrated the power of network sequencing by building a protocol called Network-Ordered Paxos (NOPaxos). NOPaxos is a state machine replication protocol for making systems fault tolerant. Traditional approaches (Multi-Paxos or Viewstamped Replication) come with high throughput and latency cost. By relying on network sequencing, NOPaxos can use a faster protocol in the common case, yielding a 4.7x throughput improvement and offering replication with less than 2% overhead.  Subsequently, we demonstrated that an extended version of network sequencing can be applied to transaction process in distributed database systems. This is a more complex coordination problem as these databases use not only use cross-shard distributed transaction coordination protocols (e.g., two-phase commit) to make the system scalable yet consistent, but also inter-shard replication using replication protocols like Paxos. Our new protocol, Eris, replaces both with a simpler protocol that leverages network sequencing. We used it to build a prototype database that can implement certain strongly consistent distributed transactions without coordination, offering a 35x performance improvement over existing systems.  In-network coordination support enables new optimizations for replicated systems. Ideally, it would be possible to build a replicated system where any server can process a read request, allowing system throughput to scale with the number of servers. Unfortunately, existing systems cannot do this safely, and indeed their throughput usually drops as the number of replicas increases. We addressed this by designing the Harmonia storage architecture. Its main insight is that an in-network primitive can track which objects in a storage system are currently being modified, making it possible to use a single-replica read optimization only when safe. The resulting system integrates with existing replication protocols and databases, and allows them to scale near-linearly for read requests.  Finally, we showed that a new in-network coordination system can help storage systems handle skewed workloads, where some objects are much more popular than others. Traditionally, systems must provision each server for the most popular objects, wasting resources. Our design moves the mapping between objects and the servers that store them into an in-network coherence directory, allowing it to easily move or replicate objects for better load balancing. The Pegasus system implements this in-network coherence directory and protocol, demonstrating that a storage system can use it to tolerate skewed workloads with as many as 90% fewer servers.  In sum, this project demonstrated the feasibility and benefits of a co-design approach between distributed coordination systems and datacenter network primitives. This approach makes it possible to build systems that are more than the sum of their parts: they achieve performance results impossible with traditional designs, enabling faster systems with better fault tolerance.  The research described in this report is described in detail in papers published in systems and data management venues (the OSDI, SOSP, and VLDB conferences). Research artifacts, including implementations of the Network-Ordered Paxos, Eris, and Pegasus systems, have been released as open-source software and made available on GitHub.       Last Modified: 02/24/2021       Submitted by: Daniel Ports]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
