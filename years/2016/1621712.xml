<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Virtual Learning Assistants for Constructed Response Assessment</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Benaiah Schrag</SignBlockName>
<PO_EMAI>bschrag@nsf.gov</PO_EMAI>
<PO_PHON>7032928323</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This SBIR Phase I project focuses on creating scalable Virtual Learning Assistant (VLA) technology for constructed response assessment. The best pedagogies responsible for improving learning outcomes generally involve (i) constructed response assessments and (ii) one-to-one tutoring. Students learn the best when they are given an opportunity to construct answers in their own words (instead of selecting from multiple choices) and when they receive immediate guidance and coaching in a one-to-one conversation with a human tutor. However, the costs and time associated with the constructed response assessment and one-to-one tutoring are significant, making them very difficult to scale. The proposed project will apply the most advanced technologies such as Artificial Intelligence and Natural Language Processing to solve both these problems. Students will benefit from the interactive formative assessment that engages them in a natural language conversation. This innovation is applicable across the grade levels in K-12, higher education, and adult learning and across the subjects areas such as English language arts, STEM and humanities. It will facilitate implementation of more rigorous academic standards and make online education more effective. This innovation will improve students' learning outcomes, save teachers' time and reduce the cost of delivering high quality engaging education on a large scale. &lt;br/&gt;&lt;br/&gt;This project will create a new type of virtual assistant technology that is exclusively focused on education. The proposed Virtual Learning Assistant (VLA) will advance the conversational AI technology to create pedagogically rich learning and assessment environments for any topic in a content area. The VLA is uniquely distinct from general purpose virtual assistants in its ability to evaluate an answer instead of merely serving information. This project will investigate and create various algorithms for processing natural language input arising in an educational setting across different subjects or topics. The resulting web based product will allow teachers to create new high quality assessment items with minimal input and assign them to their students. When a student answers a question, the VLA will analyze it instantly for linguistic syntax and semantics using statistical and deterministic knowledge representations. The VLA will generate not only a numerical score reflecting the accuracy of the answer, but also a qualitative feedback that will guide the student towards conceptual mastery of the topic. As part of this Phase I research, a pilot study will be conducted involving teachers and students to study the efficacy of the VLA and to verify its usability and feasibility.</AbstractNarration>
<MinAmdLetterDate>06/22/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1621712</AwardID>
<Investigator>
<FirstName>Dharmendra</FirstName>
<LastName>Kanejiya</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dharmendra Kanejiya</PI_FULL_NAME>
<EmailAddress>dharm@cognii.com</EmailAddress>
<PI_PHON>6178991744</PI_PHON>
<NSF_ID>000711526</NSF_ID>
<StartDate>06/22/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cognii, Inc.</Name>
<CityName>San Francisco</CityName>
<ZipCode>941032533</ZipCode>
<PhoneNumber>6178991744</PhoneNumber>
<StreetAddress>169 11th St</StreetAddress>
<StreetAddress2><![CDATA[Office 12]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079690746</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COGNII, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cognii, Inc.]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021164155</ZipCode>
<StreetAddress><![CDATA[31 St James Ave Suite 920]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8031</Code>
<Text>Education Products</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8039</Code>
<Text>Information, Communication &amp; Computing</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This NSF SBIR Phase I project determined the feasibility of an AI powered scalable Virtual Learning Assistant(VLA) technology for open response assessments based interactive learning and tutoring.&nbsp;The project pursued the following technical objectives:</p> <ul> <li> <p>Research &amp; Development of Natural Language Processing algorithms for creating scalable VLA technology for open response assessment</p> </li> <li> <p>Create a teacher-facing interface for authoring open response items</p> </li> <li> <p>Create a student-facing interface for students to practice the open-response questions, receive instant automatic formative assessment, and engage in a tutoring conversation with the VLA towards conceptual mastery&nbsp;</p> </li> <li> <p>Test the effectiveness of VLA in an authentic education setting to measure the relevance and validity of the product</p> </li> </ul> <p>During the Phase I project, we focused on the Biology subject. We worked with three public schools in Boston, MA area&nbsp;for implementing the pilot test. At each school, we collaborated with one high school Biology teacher to create a number of open-response questions from the recent standardized tests of MCAS(Massachusetts Comprehensive Assessment System). Additionally, we also worked with a professor of Biology at a local public University to validate the relevance of the product in higher education. In all, the product was used by 225 high school students and 400 college students.&nbsp;</p> <p>After the pilot test, the teachers felt that the VLA served an important need in education. All the teachers liked using the pre-authered questions, as well as authoring new questions, and administering the questions to their students. They agreed that the VLA helped them monitor students' progress more closely than before. They strongly agreed that the VLA provided more opportunities for their students to practice open-response questions and it helped improve the students' knowledge retention and critical thinking skills. They also felt that the VLA can help them personalize the instruction, and help their students prepare better for the state summative tests. They also agreed that the time required to make a question student-ready, reduced as more questions got implemented, thus validating the scalability of the VLA platform.</p> <p>One teacher said they liked, <em>"the [VLA's] ability to offer in the moment feedback that helps students practice answering the whole question. I think this will help them see the whole picture of an MCAS question and make sure that their answers are comprehensive."</em> Another teacher said the VLA, <em>"helped studets get instant feedback on questions that would take me at least a day to grade for all students."</em></p> <p>In terms of the students' experience, 91% of the students said it was easy for them to submit answers and get instant feedback. 92% said that the VLA feedback helped them improve their answer. 73% said that when they re-practiced certain questions, they needed less number of attempts to reach mastery because of prior feedback. 79% students felt that the VLA can be a useful tool for them to prepare for standardised tests, or the college course exams. 87% of the students believed that Artificial Intelligence technology can help improve the education system.</p> <p>One student said, <em>"I liked how if you got the answer partially right, the VLA would hint at what you were missing. This really helped me see if i was even heading in the right direction with my answers.&rdquo;</em> Another student said, <em>"I liked how it told me the parts I was missing in my answer, I learned a lot with these questions than I did in the classroom. I loved using cognii, I hope it becomes a useful tool in every classroom soon.&rdquo;</em> Another student said, <em>"It provided instant feedback. And it had to be an answer you thought of. You could not guess because it was not multiple choice."</em></p> <p><strong>Broader Societal Impact</strong></p> <p>Education researchers and policy makers have long believed that the open(constructed)-response questions are a superior form of assessments for inculcating the critical thinking and problem solving skills - important for 21st century workforce. However, due to the time and cost constraints in grading, they are not as frequently used as desirable. This project provided a usable and feasible solution to this problem and has the potential to transform the education practices across the entire education ecosystem.</p> <p>The original research validation plan for Phase I was for testing the prototype with a teacher and 30 students, but we exceeded it by testing with 4 teachers and 600 students representing both the K-12 and the Higher Education systems, which indicates that the product is scalable. The positive results of the Phase I pilot tests are signs of encouragement that the education market is ready for innovative AI based learning and assessment tools. Based on the results and the valuable suggestions received from the teachers and the students, a number of product enhancements as well as scalability across subject areas are worth pursuing during a Phase II project.&nbsp;</p><br> <p>            Last Modified: 02/25/2018<br>      Modified by: Dharmendra&nbsp;Kanejiya</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600607859_Cognii-VLA-teacher-question-authoring-tutorial--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600607859_Cognii-VLA-teacher-question-authoring-tutorial--rgov-800width.jpg" title="Cognii VLA Teacher interface for authoring a tutorial"><img src="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600607859_Cognii-VLA-teacher-question-authoring-tutorial--rgov-66x44.jpg" alt="Cognii VLA Teacher interface for authoring a tutorial"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This screenshot of the Cognii VLA product shows a teacher viewing a tutorial made up from a list of questions they have authored.</div> <div class="imageCredit">Cognii, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Dharmendra&nbsp;Kanejiya</div> <div class="imageTitle">Cognii VLA Teacher interface for authoring a tutorial</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600746143_Cognii-VLA-student-practice-1--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600746143_Cognii-VLA-student-practice-1--rgov-800width.jpg" title="Cognii VLA student interface for practice"><img src="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600746143_Cognii-VLA-student-practice-1--rgov-66x44.jpg" alt="Cognii VLA student interface for practice"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This screenshot of Cognii VLA product shows a student practicing an open response question in Biology, and receiving a qualitative feedback to help them complete the answer.</div> <div class="imageCredit">Cognii, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Dharmendra&nbsp;Kanejiya</div> <div class="imageTitle">Cognii VLA student interface for practice</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600886035_Cognii-VLA-teacher-replay-session-1--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600886035_Cognii-VLA-teacher-replay-session-1--rgov-800width.jpg" title="Cognii VLA teacher replaying a session"><img src="/por/images/Reports/POR/2018/1621712/1621712_10435174_1519600886035_Cognii-VLA-teacher-replay-session-1--rgov-66x44.jpg" alt="Cognii VLA teacher replaying a session"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This screenshot shows a teacher replaying an interactive session between a student and Cognii to understand how the VLA was tutoring the student.</div> <div class="imageCredit">Cognii, Inc.</div> <div class="imageSubmitted">Dharmendra&nbsp;Kanejiya</div> <div class="imageTitle">Cognii VLA teacher replaying a session</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This NSF SBIR Phase I project determined the feasibility of an AI powered scalable Virtual Learning Assistant(VLA) technology for open response assessments based interactive learning and tutoring. The project pursued the following technical objectives:    Research &amp; Development of Natural Language Processing algorithms for creating scalable VLA technology for open response assessment    Create a teacher-facing interface for authoring open response items    Create a student-facing interface for students to practice the open-response questions, receive instant automatic formative assessment, and engage in a tutoring conversation with the VLA towards conceptual mastery     Test the effectiveness of VLA in an authentic education setting to measure the relevance and validity of the product    During the Phase I project, we focused on the Biology subject. We worked with three public schools in Boston, MA area for implementing the pilot test. At each school, we collaborated with one high school Biology teacher to create a number of open-response questions from the recent standardized tests of MCAS(Massachusetts Comprehensive Assessment System). Additionally, we also worked with a professor of Biology at a local public University to validate the relevance of the product in higher education. In all, the product was used by 225 high school students and 400 college students.   After the pilot test, the teachers felt that the VLA served an important need in education. All the teachers liked using the pre-authered questions, as well as authoring new questions, and administering the questions to their students. They agreed that the VLA helped them monitor students' progress more closely than before. They strongly agreed that the VLA provided more opportunities for their students to practice open-response questions and it helped improve the students' knowledge retention and critical thinking skills. They also felt that the VLA can help them personalize the instruction, and help their students prepare better for the state summative tests. They also agreed that the time required to make a question student-ready, reduced as more questions got implemented, thus validating the scalability of the VLA platform.  One teacher said they liked, "the [VLA's] ability to offer in the moment feedback that helps students practice answering the whole question. I think this will help them see the whole picture of an MCAS question and make sure that their answers are comprehensive." Another teacher said the VLA, "helped studets get instant feedback on questions that would take me at least a day to grade for all students."  In terms of the students' experience, 91% of the students said it was easy for them to submit answers and get instant feedback. 92% said that the VLA feedback helped them improve their answer. 73% said that when they re-practiced certain questions, they needed less number of attempts to reach mastery because of prior feedback. 79% students felt that the VLA can be a useful tool for them to prepare for standardised tests, or the college course exams. 87% of the students believed that Artificial Intelligence technology can help improve the education system.  One student said, "I liked how if you got the answer partially right, the VLA would hint at what you were missing. This really helped me see if i was even heading in the right direction with my answers." Another student said, "I liked how it told me the parts I was missing in my answer, I learned a lot with these questions than I did in the classroom. I loved using cognii, I hope it becomes a useful tool in every classroom soon." Another student said, "It provided instant feedback. And it had to be an answer you thought of. You could not guess because it was not multiple choice."  Broader Societal Impact  Education researchers and policy makers have long believed that the open(constructed)-response questions are a superior form of assessments for inculcating the critical thinking and problem solving skills - important for 21st century workforce. However, due to the time and cost constraints in grading, they are not as frequently used as desirable. This project provided a usable and feasible solution to this problem and has the potential to transform the education practices across the entire education ecosystem.  The original research validation plan for Phase I was for testing the prototype with a teacher and 30 students, but we exceeded it by testing with 4 teachers and 600 students representing both the K-12 and the Higher Education systems, which indicates that the product is scalable. The positive results of the Phase I pilot tests are signs of encouragement that the education market is ready for innovative AI based learning and assessment tools. Based on the results and the valuable suggestions received from the teachers and the students, a number of product enhancements as well as scalability across subject areas are worth pursuing during a Phase II project.        Last Modified: 02/25/2018       Submitted by: Dharmendra Kanejiya]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
