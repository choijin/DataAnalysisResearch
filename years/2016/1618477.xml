<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Unraveling and Building Top-Down Generators in Deep Convolutional Neural Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>449999.00</AwardTotalIntnAmount>
<AwardAmount>449999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Deep learning has recently significantly advanced research fields that are closely related to artificial intelligence. The fundamental problem of knowledge representation however remains open and the role of top-down process in deep learning is yet not very clear. For example, to train a deep learning algorithm to detect simply the translation of a dog in an image, a data-driven way of training deep learning would require generating thousands of samples by moving the dog around in the image. However, a top-down model, if available, can directly detect translation using two variables along the axes. The main goal of this project is to explore a path to discover, learn, and build embedded deep learning models, accounting for a rich family of top-down spatial transformation and geometric composition in convolutional neural networks. The resulting models provide a transparent way of understanding the embedded top-down transformation process through neural network layers. The learned neurally-inspired top-down knowledge representation will benefit studies across multiple disciplines, including visual perception, brain sciences, cognitive modeling, and decision making. &lt;br/&gt;&lt;br/&gt;The current practice in deep learning, for example convolutional neural networks (CNN), is largely dominated by data-driven bottom-up approaches. While the performances of various applications using convolutional neural networks (CNN) are impressive, there nevertheless exists a big gap between what bottom CNN can offer and what comprehensive intelligence requires. These strongly bottom-up CNN characteristics leave a big room for one to provide deep learning with the ability to also incorporate top-down information for effective knowledge representation, network learning, cognitive modeling, and visual inference. This project is about building a roadmap towards developing top-down generators. This is done by unraveling the role of explicit top-down knowledge representation and propagation, by studying the feature flows produced inside the convolutional neural networks, by building robust analysis-by-synthesis methods that combine top-down and bottom-up processes, and by creating explicit generative models to assist a wide range of applications. The benefit of studying the top-down generators to a broad family of applications is greatly intriguing, including but not limited to: creating network internal data augmentation, building object detection, developing scene understanding systems; modeling compositional and contextual object configurations; and performing zero-shot learning.</AbstractNarration>
<MinAmdLetterDate>06/28/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/28/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1618477</AwardID>
<Investigator>
<FirstName>Zhuowen</FirstName>
<LastName>Tu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhuowen Tu</PI_FULL_NAME>
<EmailAddress>zhuowen.tu@gmail.com</EmailAddress>
<PI_PHON>8584298057</PI_PHON>
<NSF_ID>000083010</NSF_ID>
<StartDate>06/28/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930515</ZipCode>
<StreetAddress><![CDATA[9500 Gilman Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~449999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Under the support of this award, the PI's group at UC San Diego has developed new deep learning representations/algorithms that are guided by the top-down process and information. A sequence of methods have been developed to: 1) learn a direct top-down feature transformer; 2) provide top-down generative capability to the bottom-up convolutional neural network models; 3) guide the latent varies in variational autoencoder with disentanglement learning; 4) introduce topology-awareness to shape reconstruction.</p> <p>We have developed an introspective convolutional neural network model that provides the top-down generative capability to the bottom-up classifier. The generative capability brought to the convolutional neural networks results in an enhancement of the robustness of the discriminative classifier.</p> <p>We have developed a new CNN model, ResNeXt, by using highly modularized network architecture for image classification. ResNeXt improves the basic ResNet model and it has become a widely adopted CNN model in computer vision and deep learning.</p> <p>We have also developed a number of methods that are effective in their own task domains including: controllable top-down feature transformer, object-detection-free instance segmentation with labeling transformations, attentional ShapeContextNet for point cloud recognition, local binary pattern networks, geometry-aware end-to-end skeleton detection, instance occlusion for panoptic segmentation, and guided variational autoencoder for disentanglement learning.</p> <p><br />The result of this project has pointed to an exciting direction by integrating the top-down process within the end-to-end deep learning frameworks for addressing the fundamental representation problems to develop robust, transparent, effective, and efficient image representations.</p> <p><br />Broader impact:</p> <p>This project has overall made a strong impact in the computer vision, machine learning, and deep learning community by proposing algorithms to tackle the fundamental problem of top-down information/guidance to convolutional neural networks. The impact includes research and educational for training students and researchers. The scope of the proposed models goes beyond computer vision and it has been applied to various problems of modeling/computing in machine learning. The proposed activities have strengthened the educational and research program in the Department of Cognitive Science and Department of Computer Science and Engineering at University of California San Diego.</p><br> <p>            Last Modified: 10/29/2020<br>      Modified by: Zhuowen&nbsp;Tu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Under the support of this award, the PI's group at UC San Diego has developed new deep learning representations/algorithms that are guided by the top-down process and information. A sequence of methods have been developed to: 1) learn a direct top-down feature transformer; 2) provide top-down generative capability to the bottom-up convolutional neural network models; 3) guide the latent varies in variational autoencoder with disentanglement learning; 4) introduce topology-awareness to shape reconstruction.  We have developed an introspective convolutional neural network model that provides the top-down generative capability to the bottom-up classifier. The generative capability brought to the convolutional neural networks results in an enhancement of the robustness of the discriminative classifier.  We have developed a new CNN model, ResNeXt, by using highly modularized network architecture for image classification. ResNeXt improves the basic ResNet model and it has become a widely adopted CNN model in computer vision and deep learning.  We have also developed a number of methods that are effective in their own task domains including: controllable top-down feature transformer, object-detection-free instance segmentation with labeling transformations, attentional ShapeContextNet for point cloud recognition, local binary pattern networks, geometry-aware end-to-end skeleton detection, instance occlusion for panoptic segmentation, and guided variational autoencoder for disentanglement learning.   The result of this project has pointed to an exciting direction by integrating the top-down process within the end-to-end deep learning frameworks for addressing the fundamental representation problems to develop robust, transparent, effective, and efficient image representations.   Broader impact:  This project has overall made a strong impact in the computer vision, machine learning, and deep learning community by proposing algorithms to tackle the fundamental problem of top-down information/guidance to convolutional neural networks. The impact includes research and educational for training students and researchers. The scope of the proposed models goes beyond computer vision and it has been applied to various problems of modeling/computing in machine learning. The proposed activities have strengthened the educational and research program in the Department of Cognitive Science and Department of Computer Science and Engineering at University of California San Diego.       Last Modified: 10/29/2020       Submitted by: Zhuowen Tu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
