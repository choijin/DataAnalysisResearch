<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NCS-FO: Collaborative Research: Flexible Rule-Based Categorization in Neural Circuits and Neural Network Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>414233.00</AwardTotalIntnAmount>
<AwardAmount>414233</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kurt Thoroughman</SignBlockName>
<PO_EMAI>kthoroug@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Categorization is the brain's ability to recognize the meaning of objects and events in our environment, and is an essential cognitive process underlying decision making. Categorical decisions are often flexible, and depend on the demands on the task at hand. The current project aims to understand the brain mechanisms which underlie flexible categorical decision making, as well as computational algorithms for making such decisions my artificially intelligent systems. Experiments will record from ensembles of cortical neurons during flexible categorization tasks. Computational modeling work will train recurrent neural networks to perform the same flexible categorization tasks used in the experiments, with parameters of the model inspired by the experimental data. This will result in a greater understanding of the neural mechanisms underlying categorization and decision making, as well as improvements in computational algorithms for flexible categorization by artificially intelligent systems. The broader impacts of the project include substantial training opportunities for undergraduates, Ph.D. students, and postdoctoral researchers in both experimental and computational approaches to flexible decision making. The project will also generate new experimental data and computational tools that will be shared with the broader scientific community. &lt;br/&gt;&lt;br/&gt;This project combines multi-channel neurophysiological recordings and neural circuit modeling to investigate the neural circuit mechanisms of flexibility and generalization in visual categorization. The project leverages a collaboration by the researchers that has proven fruitful in our previous joint research on category learning. The focus of the present project is on flexible task switching between discrimination and categorization, and between categorization rules, in the behavioral, experimental, and computational work. The task paradigms will also directly test the 'exemplar model' of categorization from cognitive psychology, linking behavioral models to neural circuit processes. The project will develop a novel modeling framework, based on training recurrent neural networks to learn to perform multiple tasks. This approach offers a potentially powerful data analysis tool and conceptualization of neural circuit computation in terms of neural population trajectories in a high-dimensional state space, and this perspective is urgently needed to analyze simultaneous recording from many single neurons during performance of complex cognitive tasks, a major thread of modern Data-Intensive Neuroscience and Cognitive Science.</AbstractNarration>
<MinAmdLetterDate>08/17/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1631586</AwardID>
<Investigator>
<FirstName>Xiao-Jing</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiao-Jing Wang</PI_FULL_NAME>
<EmailAddress>xjwang@nyu.edu</EmailAddress>
<PI_PHON>2037101305</PI_PHON>
<NSF_ID>000454268</NSF_ID>
<StartDate>08/17/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100034339</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>8551</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~414233</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Deep networks at the core of today's AI revolution were initially inspired by discoveries about the visual system in the brain. The commonly used architecture is purely feedforward, without feedback from a higher layer to a lower layer in a linear hierarchy. This is in sharp contrast with the biological visual circuit endowed with many feedbacks, their functions are poorly understood. This is mainly because top-down signaling is difficult to identify in neuroscientific studies. In the present work, we combined a monkey experiment and neural circuit modeling to investigate a phenomenon called categorical perception, as a signature of top-down signaling. Categorical perception refers to the interplay between analog feature-based perception and discrete categorization. In the experiment, monkeys first learnt to discriminate direction of a visual moving pattern, which is an analog feature. Then, the subjects learnt to categorize possible directional angles (from 0 to 360 degrees) into two classes (for instance, A if the angle is between 0 and 180; B otherwise). Afterwards, discrimination was re-assessed. It was found that after category learning, differences in appearance between stimuli that belong to different categories are exaggerated (expansion), while differences within the same category are deemphasized (compression). Since category selective neurons are in association areas higher in the cortical hierarchy than sensory areas where stimulus features are encoded, we posited that categorical perception effect is a result of a top-down influence. Under this assumption we developed a neural circuit model for the categorical perpcetion, and showed that the model can account for salient behavioral observations from the monkey experiment. Our findings point to a promising way to elucidate the role of top-down signaling in sensory information processing, with broad implications for understanding feedbacks in the brain as well as inspiring new machine algorithms in articifial intelligence.</p><br> <p>            Last Modified: 02/23/2020<br>      Modified by: Xiao-Jing&nbsp;Wang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Deep networks at the core of today's AI revolution were initially inspired by discoveries about the visual system in the brain. The commonly used architecture is purely feedforward, without feedback from a higher layer to a lower layer in a linear hierarchy. This is in sharp contrast with the biological visual circuit endowed with many feedbacks, their functions are poorly understood. This is mainly because top-down signaling is difficult to identify in neuroscientific studies. In the present work, we combined a monkey experiment and neural circuit modeling to investigate a phenomenon called categorical perception, as a signature of top-down signaling. Categorical perception refers to the interplay between analog feature-based perception and discrete categorization. In the experiment, monkeys first learnt to discriminate direction of a visual moving pattern, which is an analog feature. Then, the subjects learnt to categorize possible directional angles (from 0 to 360 degrees) into two classes (for instance, A if the angle is between 0 and 180; B otherwise). Afterwards, discrimination was re-assessed. It was found that after category learning, differences in appearance between stimuli that belong to different categories are exaggerated (expansion), while differences within the same category are deemphasized (compression). Since category selective neurons are in association areas higher in the cortical hierarchy than sensory areas where stimulus features are encoded, we posited that categorical perception effect is a result of a top-down influence. Under this assumption we developed a neural circuit model for the categorical perpcetion, and showed that the model can account for salient behavioral observations from the monkey experiment. Our findings point to a promising way to elucidate the role of top-down signaling in sensory information processing, with broad implications for understanding feedbacks in the brain as well as inspiring new machine algorithms in articifial intelligence.       Last Modified: 02/23/2020       Submitted by: Xiao-Jing Wang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
