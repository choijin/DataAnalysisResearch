<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Computational Techniques for Large Multi-Step Incomplete-Information Games</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
<PO_EMAI>jdonlon@nsf.gov</PO_EMAI>
<PO_PHON>7032928074</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Game-theoretic solution concepts provide a sound definition of how rational agents should act and update their beliefs in multiagent settings. The ability to compute such solutions in large incomplete-information games is a key capability in a myriad of applications, such as in negotiations, cybersecurity, physical security, medicine, and auctions. To achieve such strategically robust intelligence, the solution concepts must be accompanied by computational techniques for finding such solutions.  Only then will the definitions be truly operational. The PI proposes a host of techniques for this. The proposed work will enable game theory to be an operational tool for analyzing large-scale settings. The methodology is application independent, so it has extremely broad applicability. To ensure scalability, the techniques will be benchmarked on very-large-scale games. This is on a path to a vision where software agents conduct commerce on behalf of humans and companies, or advise them. That leads to  increased social welfare (or increase in other measures of desirability of outcomes) through better decision making. It also enables broader and fairer access because it helps put less experienced/educated people/companies on an equal footing with expert market participants. Broader access, in turn, increases the benefits of (electronic) commerce further, and the benefits get distributed more fairly across segments of society. The proposed algorithms can also help others in their research by 1) providing counter-examples to incorrect hypotheses (by rapidly generating and solving games within the class of interest, and observing properties of the equilibria) and 2) helping guide the formulation of new theorems by solving numerous cases.&lt;br/&gt;&lt;br/&gt;The proposed research has four high-level technical prongs: (1) The PI will leverage his recent breakthrough (with S. Singh) that enables game abstraction algorithms (which have to be lossy in order to create small enough models to solve) to create strategies that have bounds on exploitability.  He proposes to broaden the framework to general sequential games, to develop better action and state abstraction algorithms, and to study abstraction both for scalability and modeling purposes.  He also proposes algorithms that create imperfect-recall abstractions that have bounds, are potential-aware, support efficient distributed equilibrium finding, and have compact representations.  In addition, he proposes techniques for optimal action abstraction and ways to do abstraction during equilibrium finding and during execution of the game strategy. (2) He proposes directions around the question of how opponents' actions should be mapped to the abstract model.  He also plans to determine why making one's strategy less randomized can---surprisingly---be beneficial. (3) He proposes parallelization and sampling techniques for the counterfactual regret equilibrium-finding algorithm, and ways to solve imperfect-recall game abstractions.  He also proposes techniques for effective, detailed endgame and midgame solving, as well as techniques that leverage endgame solving in finding an equilibrium for the entire game.  He also proposes a new computationally feasible equilibrium refinement. (4) He proposes major scalability enhancements to algorithms that combine game-theoretic reasoning and opponent modeling.  He proposes new directions based on a recent breakthrough (with S. Ganzfried) that shows that fully safe opponent exploitation is possible.  He also proposes to study the three-way tradeoff among exploitation, exploitability, and exploration.</AbstractNarration>
<MinAmdLetterDate>06/27/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1617590</AwardID>
<Investigator>
<FirstName>Tuomas</FirstName>
<LastName>Sandholm</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tuomas Sandholm</PI_FULL_NAME>
<EmailAddress>sandholm@cs.cmu.edu</EmailAddress>
<PI_PHON>4122681111</PI_PHON>
<NSF_ID>000096107</NSF_ID>
<StartDate>06/27/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~450000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Most real-world settings are imperfect-information games in that there are two or more interacting parties and they have to make decisions under imperfect information. This project developed the leading algorithms for solving multi-step (a.k.a. extensive-form) imperfect-information games. The algorithms include abstraction techniques with solution quality guarantees, the fastest equilibrium-finding techniques, sound depth-limited search algorithms for imperfect-information games, and a new approach to adapting to opponents by fixing weaknesses in one's own strategy (as opposed to the traditional machine learning approach of trying to learn to exploit the opponents' weaknesses). AIs were generated with these algorithms, for example, for the main benchmark and long-standing challenge problem in the field, no-limit Texa hold'em. The AI <em>Libratus </em>[published in Science in 2018] became the first and only AI to beat the top human professionals at the two-player variant of the game.&nbsp;The AI <em>Pluribus&nbsp;</em>[published in Science in 2019] became the first and only AI to beat the top human professionals at the multi-player game. This is t<span>he first superhuman AI game-playing system for games beyond two-player zero-sum games.&nbsp;</span></p> <p><span>Algorithms and theory for a host of other game-solving problem classes were also developed such as extensive-form leader-follower games and extensive-form correlated equilibria. The first scalable algorithm for equilibrium refinement in imperfect-information games was developed (specifically, for several forms of trembling-hand refinements).</span></p> <p>The PI spun out from Carnegie Mellon University two startup companies based on these application-independent technologies: Strategic Machine, Inc. (for gaming and business applicatoins) and Strategy Robot, Inc. (for defense applications).</p><br> <p>            Last Modified: 10/06/2019<br>      Modified by: Tuomas&nbsp;Sandholm</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Most real-world settings are imperfect-information games in that there are two or more interacting parties and they have to make decisions under imperfect information. This project developed the leading algorithms for solving multi-step (a.k.a. extensive-form) imperfect-information games. The algorithms include abstraction techniques with solution quality guarantees, the fastest equilibrium-finding techniques, sound depth-limited search algorithms for imperfect-information games, and a new approach to adapting to opponents by fixing weaknesses in one's own strategy (as opposed to the traditional machine learning approach of trying to learn to exploit the opponents' weaknesses). AIs were generated with these algorithms, for example, for the main benchmark and long-standing challenge problem in the field, no-limit Texa hold'em. The AI Libratus [published in Science in 2018] became the first and only AI to beat the top human professionals at the two-player variant of the game. The AI Pluribus [published in Science in 2019] became the first and only AI to beat the top human professionals at the multi-player game. This is the first superhuman AI game-playing system for games beyond two-player zero-sum games.   Algorithms and theory for a host of other game-solving problem classes were also developed such as extensive-form leader-follower games and extensive-form correlated equilibria. The first scalable algorithm for equilibrium refinement in imperfect-information games was developed (specifically, for several forms of trembling-hand refinements).  The PI spun out from Carnegie Mellon University two startup companies based on these application-independent technologies: Strategic Machine, Inc. (for gaming and business applicatoins) and Strategy Robot, Inc. (for defense applications).       Last Modified: 10/06/2019       Submitted by: Tuomas Sandholm]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
