<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: RI: Methods for Learning and Recovering Partially Embedded Logical Representations for Question Answering</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>191000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>D.  Langendoen</SignBlockName>
<PO_EMAI>dlangend@nsf.gov</PO_EMAI>
<PO_PHON>7032925088</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Providing effective access to non-experts to the ever-increasing amount of publicly available information is a challenging open problem. While search has been the dominant mode of access, it does not support complex queries, and provides a poor interface for natural language interaction with the growing number of virtual and embodied agents. The goal of this project is to develop representations and learning methods to enable systems that can respond accurately to complex natural language questions. This work will advance the field of natural language processing and have impact through the development of algorithms, linguistic representations, and applications, including natural language question answering interfaces for large knowledge bases. &lt;br/&gt;&lt;br/&gt;A common approach to question answering, commonly known as semantic parsing, is to map questions to expressive logical representations. This is a challenging task that requires deriving the meaning of words, and combining them following the compositional structure of the sentence. Despite increasing research attention, building systems capable of such understanding requires significant expertise, and state-of-the-art systems are limited by the coverage of existing manually-curated knowledge bases, largely failing to benefit from unstructured text. This project proposes an approach that will (a) significantly reduce the engineering effort and expertise required to build question answering systems, (b) generalize beyond curated data to learn to answer complex factoid questions without a knowledge base, and (c) lay the foundations for a new general approach to recover semantic meaning. The key to this approach is the integration of logical and embedded representations of meaning. It is expected that mapping sentences to representations that combine logical and embedded elements will greatly reduce the amount of representation engineering required, enable complex sentence-level reasoning, and allow effective learning from raw text without access to a structured knowledge base.</AbstractNarration>
<MinAmdLetterDate>03/01/2017</MinAmdLetterDate>
<MaxAmdLetterDate>03/26/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1656998</AwardID>
<Investigator>
<FirstName>Yoav</FirstName>
<LastName>Artzi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yoav Artzi</PI_FULL_NAME>
<EmailAddress>yoav@cs.cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000703736</NSF_ID>
<StartDate>03/01/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell Tech]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100115201</ZipCode>
<StreetAddress><![CDATA[111 8th Ave #302]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~175000</FUND_OBLG>
<FUND_OBLG>2018~8000</FUND_OBLG>
<FUND_OBLG>2019~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed methods and resources to study compositional reasoning for querying systems using natural language, for example for question answering applications. The project resulted is several outcomes that address the intellectual merit criteria. First, we developed a learning method to represent language meaning within conversational interactions, focusing on responding to natural language questions presented to a database system. While learning methods for such problems often require hand-crafted linguistic representations, we showed that representation learning methods can skip the need to design such linguistic representations, but still reason effectively about the history of the interaction. In a separate part of this project, we presented modeling and learning methods to execute sequences of instructions by manipulating objects in an experimental environment. The key advantage of our approach is that it uses low-level actions, completely bypassing the knowledge representation effort required by prior methods. Our work also highlighted existing open problems in language understanding, with focus on complex reasoning about visual scenes. We designed scalable methods to collect large datasets that display diverse semantic phenomena and require complex reasoning. Our datasets define benchmarks that are used broadly to develop new models and learning methods to reason about grounded language meaning. We also developed methods to study the type of reasoning deployed by neural language acquisition models. Using these methods, we showed that existing state-of-the-art methods learn a simplistic model of language structure, and largely fail to capture the complexities of natural language. The project outcomes addressing the broader impact criteria include conducting research with undergraduate students from under-presented groups and constructing research-enabling data resources that are used in other communities, such as the computer vision and machine learning communities.</p><br> <p>            Last Modified: 10/20/2020<br>      Modified by: Yoav&nbsp;Artzi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed methods and resources to study compositional reasoning for querying systems using natural language, for example for question answering applications. The project resulted is several outcomes that address the intellectual merit criteria. First, we developed a learning method to represent language meaning within conversational interactions, focusing on responding to natural language questions presented to a database system. While learning methods for such problems often require hand-crafted linguistic representations, we showed that representation learning methods can skip the need to design such linguistic representations, but still reason effectively about the history of the interaction. In a separate part of this project, we presented modeling and learning methods to execute sequences of instructions by manipulating objects in an experimental environment. The key advantage of our approach is that it uses low-level actions, completely bypassing the knowledge representation effort required by prior methods. Our work also highlighted existing open problems in language understanding, with focus on complex reasoning about visual scenes. We designed scalable methods to collect large datasets that display diverse semantic phenomena and require complex reasoning. Our datasets define benchmarks that are used broadly to develop new models and learning methods to reason about grounded language meaning. We also developed methods to study the type of reasoning deployed by neural language acquisition models. Using these methods, we showed that existing state-of-the-art methods learn a simplistic model of language structure, and largely fail to capture the complexities of natural language. The project outcomes addressing the broader impact criteria include conducting research with undergraduate students from under-presented groups and constructing research-enabling data resources that are used in other communities, such as the computer vision and machine learning communities.       Last Modified: 10/20/2020       Submitted by: Yoav Artzi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
