<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Geometric Approach to Bayesian Modeling and Inference with the Nonparametric Fisher-Rao Metric</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>120000.00</AwardTotalIntnAmount>
<AwardAmount>120000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Bayesian modeling and inference are commonly used statistical approaches to the analyses of complex high-dimensional data from many scientific fields including computer vision, biology, biometrics, bioinformatics and medicine. This research project is concerned with developing geometry-based, computationally efficient and scalable tools for Bayesian modeling of such datasets that have high potential for revealing novel insights. An example is a Bayesian model for statistical analysis of tumor heterogeneity in cancer with the possibility for improved disease characterization and new treatment approaches. The novelty and potential for high impact of this project come from the utility of an area of mathematics called differential geometry in the study of Bayesian statistical models and inferences. &lt;br/&gt;&lt;br/&gt;While much progress has been made in the area of Bayesian modeling and inference both in terms of theory and computation, little attention has been given to studying the underlying geometry of such models. In this project, the PIs focus on developing a practical, unified Riemannian-geometric framework for three main problems: (1) Bayesian sensitivity analysis, (2) geometric variational inference, and (3) geometric nonparametric prior construction; these problems culminate in a fourth one of Bayesian density estimation, wherein the tools described in the first three can be used with obvious advantages. For a Bayesian model with prior, sampling and posterior densities, the geometric properties of the model are investigated and exploited through a square-root transformation, under which the nonlinear manifold of probability densities endowed with the nonparametric Fisher-Rao metric simplifies to the positive orthant of the unit sphere endowed with the Euclidean metric. Because the geometry of the sphere is well-known, important tools for analysis (e.g., exponential and inverse exponential maps, parallel transport, geodesics) are available in closed-form. As a result, this framework is versatile computationally and applicable to parametric, semiparametric and nonparametric Bayesian models. More importantly, it provides a formal mathematical background for defining distances between densities and developing geometrically calibrated measures. Thus, the two main contributions of this project are the development of (1) metric-based inferential methods for Bayesian models that may permit a more intuitive explanation of prior and posterior beliefs, and (2) a geometric quantification of various aspects of posterior inference through intrinsic analysis on the space of all probability densities.</AbstractNarration>
<MinAmdLetterDate>09/06/2016</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1613054</AwardID>
<Investigator>
<FirstName>Sebastian</FirstName>
<LastName>Kurtek</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sebastian A Kurtek</PI_FULL_NAME>
<EmailAddress>kurtek.1@osu.edu</EmailAddress>
<PI_PHON>6142920463</PI_PHON>
<NSF_ID>000654649</NSF_ID>
<StartDate>09/06/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Karthik</FirstName>
<LastName>Bharath</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Karthik Bharath</PI_FULL_NAME>
<EmailAddress>Karthik.Bharath@nottingham.ac.uk</EmailAddress>
<PI_PHON/>
<NSF_ID>000684457</NSF_ID>
<StartDate>09/06/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101247</ZipCode>
<StreetAddress><![CDATA[1958 Neil Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~120000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Bayesian modeling and inference is commonly used to analyze complex high-dimensional data from many scientific fields including computer vision, biology, biometrics, bioinformatics and medicine. History, through pioneering works in frequentist statistics in the latter half of the last century, has demonstrated that dramatic improvements in statistical analyses are possible when explicitly accounting for geometry of statistical models. The chief aim of this research project focused on an extension of such a program to Bayesian models, both parametric and nonparametric.</p> <p>The practical importance of the aim can be understood through an application in radiogenomics. A Bayesian model for uncovering associations between survival times of patients diagnosed with&nbsp;brain cancer and genetic variables is influenced by the choice of a prior probability density on the chances of survival with changing genetic composition. How does one quantify the influence on the conclusions of such a choice of a prior density? If in addition MRI scans of the tumors are available, a better survival model is possible.&nbsp; It is well-known that modeling inter- and intra-tumor heterogeneity is of vital importance for better diagnosis and prognosis. Currently, the most popular way to represent heterogeneity is through a density estimate of pixel intensity values of the tumor in an MRI. How can one incorporate a density estimate into the above survival model consisting of genetic variables? On the flip side, complexity of the Bayesian model greatly increases when adding functional variables such as probability densities, and accessing relevant posterior quantities through sampling becomes very difficult. Can we instead approximate the relevant posterior density by a simpler one on the parameter space?</p> <p>The application demonstrates the benefits in understanding the space of probability densities for improved Bayesian modeling, which is a nonlinear manifold with non-trivial geometry.&nbsp; Armed with tools from the mathematical area of differential geometry to study the space of probability densities, three candidate problems were chosen: (1) geometry-based quantification of influence of choices of components of a Bayesian model, i.e. sensitivity analysis; (2) variational approximation of Bayesian models; (3) construction of a geometry-driven prior distribution on densities and functions.</p> <p>Approaches to the three problems were founded on the nonparametric Fisher-Rao metric, and the resulting geometry, on the set of probability density functions. A square-root transformation leads to a simplified geometry such that important quantities such as distances and paths are available in closed form. The first stage of the project focused on problem (1) and led to two publications that laid the foundations for sensitivity analysis of Bayesian parametric and nonparametric models, in addition to a method for identifying outlying observations in a dataset.</p> <p>In the second stage of the project,&nbsp;problem (2) was considered. Variational approximations to posterior distributions in complex, high-dimensional Bayesian models are assuming importance, especially within Machine Learning. The novel approach to variational inference based on the Fisher-Rao metric resulted in a paper that not only demonstrates the importance of geometry in the variational problem, but also provides some significant improvements in the quality of approximations, both theoretical and numerical. Additionally, in the second stage of the project, the PIs furthered the range of applicability of the developed geometric tools in related statistical tasks such as data visualization and summarization of estimation and inference results.</p> <p>The final stage of the project considered problem (3) and related variants. Leveraging on an extension of the Fisher-Rao metric used on probability densities to arbitrary functions, the PIs and their collaborators developed a Bayesian model for simultaneous estimation and registration of functional data under general observational regimes including sparsity, noise and fragmentation. To accomplish this, they defined strongly informative prior distributions on the shape of functions that led to a posterior distribution which allowed for structured uncertainty quantification in the estimation/registration. The developed Bayesian models were applied with considerable success to real data from many different disciplines including environmetrics, computer vision, biology and medical imaging, among others.</p><br> <p>            Last Modified: 12/29/2020<br>      Modified by: Sebastian&nbsp;A&nbsp;Kurtek</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Bayesian modeling and inference is commonly used to analyze complex high-dimensional data from many scientific fields including computer vision, biology, biometrics, bioinformatics and medicine. History, through pioneering works in frequentist statistics in the latter half of the last century, has demonstrated that dramatic improvements in statistical analyses are possible when explicitly accounting for geometry of statistical models. The chief aim of this research project focused on an extension of such a program to Bayesian models, both parametric and nonparametric.  The practical importance of the aim can be understood through an application in radiogenomics. A Bayesian model for uncovering associations between survival times of patients diagnosed with brain cancer and genetic variables is influenced by the choice of a prior probability density on the chances of survival with changing genetic composition. How does one quantify the influence on the conclusions of such a choice of a prior density? If in addition MRI scans of the tumors are available, a better survival model is possible.  It is well-known that modeling inter- and intra-tumor heterogeneity is of vital importance for better diagnosis and prognosis. Currently, the most popular way to represent heterogeneity is through a density estimate of pixel intensity values of the tumor in an MRI. How can one incorporate a density estimate into the above survival model consisting of genetic variables? On the flip side, complexity of the Bayesian model greatly increases when adding functional variables such as probability densities, and accessing relevant posterior quantities through sampling becomes very difficult. Can we instead approximate the relevant posterior density by a simpler one on the parameter space?  The application demonstrates the benefits in understanding the space of probability densities for improved Bayesian modeling, which is a nonlinear manifold with non-trivial geometry.  Armed with tools from the mathematical area of differential geometry to study the space of probability densities, three candidate problems were chosen: (1) geometry-based quantification of influence of choices of components of a Bayesian model, i.e. sensitivity analysis; (2) variational approximation of Bayesian models; (3) construction of a geometry-driven prior distribution on densities and functions.  Approaches to the three problems were founded on the nonparametric Fisher-Rao metric, and the resulting geometry, on the set of probability density functions. A square-root transformation leads to a simplified geometry such that important quantities such as distances and paths are available in closed form. The first stage of the project focused on problem (1) and led to two publications that laid the foundations for sensitivity analysis of Bayesian parametric and nonparametric models, in addition to a method for identifying outlying observations in a dataset.  In the second stage of the project, problem (2) was considered. Variational approximations to posterior distributions in complex, high-dimensional Bayesian models are assuming importance, especially within Machine Learning. The novel approach to variational inference based on the Fisher-Rao metric resulted in a paper that not only demonstrates the importance of geometry in the variational problem, but also provides some significant improvements in the quality of approximations, both theoretical and numerical. Additionally, in the second stage of the project, the PIs furthered the range of applicability of the developed geometric tools in related statistical tasks such as data visualization and summarization of estimation and inference results.  The final stage of the project considered problem (3) and related variants. Leveraging on an extension of the Fisher-Rao metric used on probability densities to arbitrary functions, the PIs and their collaborators developed a Bayesian model for simultaneous estimation and registration of functional data under general observational regimes including sparsity, noise and fragmentation. To accomplish this, they defined strongly informative prior distributions on the shape of functions that led to a posterior distribution which allowed for structured uncertainty quantification in the estimation/registration. The developed Bayesian models were applied with considerable success to real data from many different disciplines including environmetrics, computer vision, biology and medical imaging, among others.       Last Modified: 12/29/2020       Submitted by: Sebastian A Kurtek]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
