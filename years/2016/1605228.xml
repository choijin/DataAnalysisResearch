<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Shared Autonomy Approach to Robotic Arm Assistance with Daily Activities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>298503.00</AwardTotalIntnAmount>
<AwardAmount>298503</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Grace Hwang</SignBlockName>
<PO_EMAI>ghwang@nsf.gov</PO_EMAI>
<PO_PHON>7032924271</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Persons with high-level paralysis rely on the care of others and the modification of their environment for accomplishing the activities of daily living (ADL). Due to the degree of support required, paralysis is costly to provide care for. Recovering the ability to manipulate through technological means would lead to significant improvements to the quality of life for the user, and would reduce the long-term economic impact of paralysis and contribute to society by freeing up caregiver time and labor (usually a family-member or friend). To that end, the project proposes to design and validate a wheelchair-mounted robotic-arm with an augmented reality interface for enabling non-tactile human-robot interaction. Importantly, the design will involve a multi-modal interface approach, which includes a recently developed tongue drive interface, a head orientation sensor, and a speech recognition system. User-centric and participatory design methods will ensure that the engineered system will be seen favorably by persons with tetraplegia. The award also supports fundamental research into the design of collaborative human-robot assistive devices, including the interface design and the underlying robot vision and planning algorithms. The research contribution includes improved understanding on how to effectively coordinate the higher level reasoning and thought processes of humans with the autonomous operation capabilities and limitations of current robotic arms. The social significance of the robotics application will be capitalized to create engaging educational and outreach activities in promotion of engineering mathematics.&lt;br/&gt;&lt;br/&gt;The long-term goal is to transform the lives of wheelchair bound persons with limited to no manipulation abilities by enabling them to independently perform the activities of daily living (ADL) irrespective of their environment. Technology meeting the varied needs of the ADL tends to have high control complexity, which impedes adoption. It is essential for these technologies to request high-level (guiding) commands rather than low-level control signals, and to request feedback in a manner compatible with the user's conception of the world. The research goal is to engineer and validate a wheelchair-fitted robotic-arm with an augmented reality interface and a multi-modal user interface for coupling the human command and intent control loop with the robotic-arm decision and control loop.  The novelty of the proposed system is that it is a shared control and a shared sensing assistive technology. The coupled system requires human input to overcome the perceptual limitations of robot vision, and employs robotic planning and manipulation to overcome the physical limitations of the user. By involving the human for scene interpretation and by providing ego-centric information to the robot arm, the coupled system minimizes and simplifies user input during complex manipulation tasks. The associated research objectives are to (I) engineer a human-robot augmented reality interface system with coupled feedback to the two systems (human and robot) for communicating intent and requesting high-level user feedback for complex manipulation tasks, (II) identify the manipulation assistance needs and user interface design through a participatory design process, (III) evaluate the user interface with respect to the desired command and control objectives, and (IV) assess the impact of the operational system with respect to task performance and cognitive burden. Engineering the unique shared control and shared sensing system and achieving the proposed research objectives would transform the way that assistive robotic technologies couple the user to technology. Incorporating the research into existing education and outreach activities would promote engineering and robotics to students and prepare them for participation in an increasingly automated world.</AbstractNarration>
<MinAmdLetterDate>08/23/2016</MinAmdLetterDate>
<MaxAmdLetterDate>11/05/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1605228</AwardID>
<Investigator>
<FirstName>Patricio</FirstName>
<LastName>Vela</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Patricio A Vela</PI_FULL_NAME>
<EmailAddress>pvela@ece.gatech.edu</EmailAddress>
<PI_PHON>4048948749</PI_PHON>
<NSF_ID>000495667</NSF_ID>
<StartDate>08/23/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Maysam</FirstName>
<LastName>Ghovanloo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Maysam Ghovanloo</PI_FULL_NAME>
<EmailAddress>mgh@getech.edu</EmailAddress>
<PI_PHON>4043857048</PI_PHON>
<NSF_ID>000320172</NSF_ID>
<StartDate>08/23/2016</StartDate>
<EndDate>09/09/2019</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320250</ZipCode>
<StreetAddress><![CDATA[85 Fifth Street NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5342</Code>
<Text>Disability &amp; Rehab Engineering</Text>
</ProgramElement>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~298503</FUND_OBLG>
</Award>
</rootTag>
