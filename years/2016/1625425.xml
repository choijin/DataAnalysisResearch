<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Promoting a Growth Mindset Using Automated Feedback</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>367382.00</AwardTotalIntnAmount>
<AwardAmount>367382</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Tymann</SignBlockName>
<PO_EMAI>ptymann@nsf.gov</PO_EMAI>
<PO_PHON>7032922832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The "Promoting a Growth Mindset Using Automated Feedback" project will develop and evaluate a new strategy for generating automated feedback on programming assignments that will provide a more welcoming experience for students, recognizing the effort they put in as they work on solutions.  The goal of the project will be to promote the adoption of a "growth mindset" - a belief that one's abilities will improve with practice and hard work, which is associated with a range of improved educational outcomes.  This strategy will encompass four key ideas: a measurement approach for assessing student effort; the use of non-points-based bonuses to reward effort and recognize hard work for positive reinforcement; heat maps of student code to highlight where bugs are located; and a strategy for clearly identifying the top priority for students to tackle in order to make progress. &lt;br/&gt;&lt;br/&gt;During the first year of the project, all three schools will collect baseline data using existing "conventional" feedback approaches. The new feedback intervention will be evaluated in years two and three of the project.  Quantitative and qualitative data will be collected and analyzed to examine changes in performance and students' behavior.  A mixed-method data collection plan will triangulate the quantitative and qualitative data with the review of literature and the researchers' direct experience in teaching these courses to reach conclusions regarding research questions of the study and provide the framework for the design of a scalable and replicable intervention to improve students' performance in the programming projects.</AbstractNarration>
<MinAmdLetterDate>08/25/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/25/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1625425</AwardID>
<Investigator>
<FirstName>Stephen</FirstName>
<LastName>Edwards</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stephen H Edwards</PI_FULL_NAME>
<EmailAddress>edwards@cs.vt.edu</EmailAddress>
<PI_PHON>5402315723</PI_PHON>
<NSF_ID>000246007</NSF_ID>
<StartDate>08/25/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Polytechnic Institute and State University</Name>
<CityName>BLACKSBURG</CityName>
<ZipCode>240610001</ZipCode>
<PhoneNumber>5402315281</PhoneNumber>
<StreetAddress>Sponsored Programs 0170</StreetAddress>
<StreetAddress2><![CDATA[300 Turner Street NW, Suite 4200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003137015</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003137015</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Virginia Polytechnic Institute and State University]]></Name>
<CityName>Blacksburg</CityName>
<StateCode>VA</StateCode>
<ZipCode>240606356</ZipCode>
<StreetAddress><![CDATA[2202 Kraft Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1998</Code>
<Text>IUSE</Text>
</ProgramElement>
<ProgramReference>
<Code>8209</Code>
<Text>Improv Undergrad STEM Ed(IUSE)</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~367382</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Automated grading tools used to generate feedback on programming assignments currently focus on objectively assessing functional correctness and other features of student work, pointing out errors that are discovered and assigning some portion of the points or marks. However, this encourages students to adopt performance-oriented goals, which are characteristic of a fixed mindset. Further, existing systems do nothing to recognize hard work or effort, or to reinforce growth mindset practices that indicate a student is practicing and developing skills. By presenting only objective, performance-oriented feedback based on solution correctness, existing approaches often result in initial program scores that are very low (&ldquo;I got a zero&rdquo;), further discouraging students, leading to frustration, and prompting thoughts of giving up, speaking directly to the tendencies of fixed-mindset students.</p> <p>This project developed a new strategy for generating automated feedback that is intended to provide a more welcoming experience for students, recognizing the effort they put in and the accomplishments they make as they work on solutions, rather than simply looking at &ldquo;are you done yet?&rdquo; We developed a set of indicators that allow automatic assessment of student effort and development practices, so that students can receive growth-oriented feedback on every submission, including encouragement for areas where improvement is needed. Inspired by features of mobile games, we also developed strategies for non-points-based bonuses to reward effort and recognize the work students put into developing solutions as they go, so that students receive positive reinforcement outside of pure grading of the end product. Inspired by software engineering research, we designed and evaluated heat maps of student code that highlight where bugs are located, and refined the result based on evaluation. To help students turn feedback into an actionable plan for what to do next, we will develop a strategy for visually identifying the top priority for students to tackle in order to make progress on their solution, helping beginners formulate goals about where to focus their energy and how to improve their solution. To encourage students to start earlier and spread their work out instead of working in one marathon &ldquo;all nighter&rdquo; session before the due date, we incorporated a game-inspired energy limiting system. Our evaluation results show positive impacts on encouraging students to start earlier, reducing late work, and encouraging students to spend more time thinking about their changes before making additional submissions. We also built a &ldquo;daily mission&rdquo; mechanism that encourages students to regularly focus on practicing and demonstrating skills that move them forward, which will directly result in corresponding growth mindset feedback to reinforce good practices. Evaluation results for daily missions show that they do encourage students to demonstrate positive skills more frequently, that students believe daily missions help them think of ways to improve their code, reinforced the things they were doing well, and encouraged them to work on assignments more frequently. All of these strategies are practical because they are automated and deployed using Web-CAT, an open-source tool for submitting and grading computer science assignments used by more than 50 thousand people at over 130 universities worldwide.</p> <p>A general strategy for encouraging a growth mindset is a critical need that CS education researchers can use across the board. Integration with existing open-source tools facilitates adoption by a large, pre-existing potential user base. The proposal team includes two partner universities who served as early adopters, who provided feedback on all aspects of the design and implementation, and who worked as evaluation sites to measure impact on students from underrepresented groups. The project produced 11 conference papers, 1 dissertation, and 4 MS theses, and graduated 6 graduate students. At the end of the project, nearly 1500 students per year were already using these new feedback mechanisms, with adoption continuing to grow.</p><br> <p>            Last Modified: 02/04/2021<br>      Modified by: Stephen&nbsp;H&nbsp;Edwards</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Automated grading tools used to generate feedback on programming assignments currently focus on objectively assessing functional correctness and other features of student work, pointing out errors that are discovered and assigning some portion of the points or marks. However, this encourages students to adopt performance-oriented goals, which are characteristic of a fixed mindset. Further, existing systems do nothing to recognize hard work or effort, or to reinforce growth mindset practices that indicate a student is practicing and developing skills. By presenting only objective, performance-oriented feedback based on solution correctness, existing approaches often result in initial program scores that are very low ("I got a zero"), further discouraging students, leading to frustration, and prompting thoughts of giving up, speaking directly to the tendencies of fixed-mindset students.  This project developed a new strategy for generating automated feedback that is intended to provide a more welcoming experience for students, recognizing the effort they put in and the accomplishments they make as they work on solutions, rather than simply looking at "are you done yet?" We developed a set of indicators that allow automatic assessment of student effort and development practices, so that students can receive growth-oriented feedback on every submission, including encouragement for areas where improvement is needed. Inspired by features of mobile games, we also developed strategies for non-points-based bonuses to reward effort and recognize the work students put into developing solutions as they go, so that students receive positive reinforcement outside of pure grading of the end product. Inspired by software engineering research, we designed and evaluated heat maps of student code that highlight where bugs are located, and refined the result based on evaluation. To help students turn feedback into an actionable plan for what to do next, we will develop a strategy for visually identifying the top priority for students to tackle in order to make progress on their solution, helping beginners formulate goals about where to focus their energy and how to improve their solution. To encourage students to start earlier and spread their work out instead of working in one marathon "all nighter" session before the due date, we incorporated a game-inspired energy limiting system. Our evaluation results show positive impacts on encouraging students to start earlier, reducing late work, and encouraging students to spend more time thinking about their changes before making additional submissions. We also built a "daily mission" mechanism that encourages students to regularly focus on practicing and demonstrating skills that move them forward, which will directly result in corresponding growth mindset feedback to reinforce good practices. Evaluation results for daily missions show that they do encourage students to demonstrate positive skills more frequently, that students believe daily missions help them think of ways to improve their code, reinforced the things they were doing well, and encouraged them to work on assignments more frequently. All of these strategies are practical because they are automated and deployed using Web-CAT, an open-source tool for submitting and grading computer science assignments used by more than 50 thousand people at over 130 universities worldwide.  A general strategy for encouraging a growth mindset is a critical need that CS education researchers can use across the board. Integration with existing open-source tools facilitates adoption by a large, pre-existing potential user base. The proposal team includes two partner universities who served as early adopters, who provided feedback on all aspects of the design and implementation, and who worked as evaluation sites to measure impact on students from underrepresented groups. The project produced 11 conference papers, 1 dissertation, and 4 MS theses, and graduated 6 graduate students. At the end of the project, nearly 1500 students per year were already using these new feedback mechanisms, with adoption continuing to grow.       Last Modified: 02/04/2021       Submitted by: Stephen H Edwards]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
