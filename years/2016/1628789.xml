<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research:   Articulation and Altered Auditory Feedback</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>12744.00</AwardTotalIntnAmount>
<AwardAmount>12744</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Individuals vary from one another in how they speak. Speakers listen to themselves while talking, and they constantly use this auditory feedback to correct their speech. This project examines two factors that influence the way that speakers are able to effectively use this auditory feedback: vocal tract shape and native language. The shape of the hard palate, which is an important factor in the relationship between articulation and acoustics, will be used as a measure of individual anatomical variation. Two similar sounds with comparable articulatory variation in American English and Tamil are compared to test the role of native language.&lt;br/&gt;&lt;br/&gt;In this experiment, participants say words containing the speech sounds of interest, and their auditory feedback is altered in real time by a computer so speakers hear themselves saying something different from what they actually produced. Previous studies (e.g. Houde and Jordan 1998) show that speakers change their articulation in response to altered auditory feedback, but it is not known how. Here, the novel addition of simultaneous ultrasound imaging will reveal how speakers compensate.&lt;br/&gt;&lt;br/&gt;The results of these studies stand to improve models of how we modify our motor plans while speaking. A complete model of typical speech serves as a baseline for understanding motor control in populations with disordered speech, such as those with apraxia of speech or Parkinson's Disease. This research will also contribute to our understanding of the role of auditory feedback in motor control, which has direct implications for people with hearing loss. Comparing English and Tamil helps to support generalizations about motor control in speech without confining results to English alone. This research also addresses long-standing questions concerning the instigation of language change. Exploring the factors that cause individuals to be fundamentally differently from each other in their speech production may provide an explanation for why some individuals might be more likely than others to contribute to the pool of language variation that results in sound change.</AbstractNarration>
<MinAmdLetterDate>06/30/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/30/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1628789</AwardID>
<Investigator>
<FirstName>Keith</FirstName>
<LastName>Johnson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Keith Johnson</PI_FULL_NAME>
<EmailAddress>keithjohnson@berkeley.edu</EmailAddress>
<PI_PHON>5103331575</PI_PHON>
<NSF_ID>000362546</NSF_ID>
<StartDate>06/30/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Susan</FirstName>
<LastName>Lin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Susan Lin</PI_FULL_NAME>
<EmailAddress>susanlin@berkeley.edu</EmailAddress>
<PI_PHON>5106428109</PI_PHON>
<NSF_ID>000699204</NSF_ID>
<StartDate>06/30/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sarah</FirstName>
<LastName>Bakst</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sarah Bakst</PI_FULL_NAME>
<EmailAddress>bakst@berkeley.edu</EmailAddress>
<PI_PHON>5106428109</PI_PHON>
<NSF_ID>000714897</NSF_ID>
<StartDate>06/30/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Regents of the University of California]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947202650</ZipCode>
<StreetAddress><![CDATA[1203 Dwinelle Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8374</Code>
<Text>DDRI Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~12744</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>We listen to ourselves while we are speaking, comparing what we say with our internal representations of our speech targets. When this auditory feedback is experimentally altered and fed back to participants in real time, speakers will automatically change their well-practiced motor plans so that the altered version of their own speech better-matches the target (e.g. Houde &amp; Jordan 1998). The experiment presented here adds ultrasound imaging to find out&nbsp;</span><span>how&nbsp;</span><span>speakers adapt to altered feedback.&nbsp;</span></p> <p>&nbsp;</p> <p><span>The purpose of this study was to understand the role of native language in how speakers respond to this altered feedback, both with respect to which parts of the speech signal speakers are senstive to, and also in the ways that speakers control their articulators. The experiment compared participants who spoke American English with speakers who spoke Tamil, which is a Dravidian language spoken mainly in southern parts of India and Sri Lanka. Tamil is crucially different from English in that it has a different set of vowels, which emphasizes a different part of the speech signal. Further, Tamil has a set of "retroflex" consonants, where the tongue tip curls back. These consonants differ from their non-retroflex consonants in a part of the speech signal that in English mainly serves to distinguish l and r. We hypothesized that if this part of the speech signal were altered, Tamil speakers would adapt to this perturbation more strongly, and that they may have access to different articulations than English speakers. We also hypothesized that differences in vowel distributions may also affect how speakers compensate.</span></p> <p>&nbsp;</p> <p>The experimenter performed this experiment in Berkeley, California, with American English speakers, and this NSF grant supported the corollary experiment in Chennai, India, with Tamil speakers. There were between-language differences in amount of vowel compensation, but both sets of speakers had similar articulatory strategies for counteracting this feedback. In the consonant portion of the experiment, Tamil speakers were not only more successful in their compensation, but the analysis thus far shows that Tamil speakers may have access to fundamentally different motor plans than the American English speakers. We conclude that while compensation to altered auditory feedback is a low-level, automatic process, factors such as native language may affect the parts of the speech signal that speakers use to assess the accuracy of their productions.</p> </div> </div> </div><br> <p>            Last Modified: 10/30/2018<br>      Modified by: Sarah&nbsp;Bakst</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    We listen to ourselves while we are speaking, comparing what we say with our internal representations of our speech targets. When this auditory feedback is experimentally altered and fed back to participants in real time, speakers will automatically change their well-practiced motor plans so that the altered version of their own speech better-matches the target (e.g. Houde &amp; Jordan 1998). The experiment presented here adds ultrasound imaging to find out how speakers adapt to altered feedback.      The purpose of this study was to understand the role of native language in how speakers respond to this altered feedback, both with respect to which parts of the speech signal speakers are senstive to, and also in the ways that speakers control their articulators. The experiment compared participants who spoke American English with speakers who spoke Tamil, which is a Dravidian language spoken mainly in southern parts of India and Sri Lanka. Tamil is crucially different from English in that it has a different set of vowels, which emphasizes a different part of the speech signal. Further, Tamil has a set of "retroflex" consonants, where the tongue tip curls back. These consonants differ from their non-retroflex consonants in a part of the speech signal that in English mainly serves to distinguish l and r. We hypothesized that if this part of the speech signal were altered, Tamil speakers would adapt to this perturbation more strongly, and that they may have access to different articulations than English speakers. We also hypothesized that differences in vowel distributions may also affect how speakers compensate.     The experimenter performed this experiment in Berkeley, California, with American English speakers, and this NSF grant supported the corollary experiment in Chennai, India, with Tamil speakers. There were between-language differences in amount of vowel compensation, but both sets of speakers had similar articulatory strategies for counteracting this feedback. In the consonant portion of the experiment, Tamil speakers were not only more successful in their compensation, but the analysis thus far shows that Tamil speakers may have access to fundamentally different motor plans than the American English speakers. We conclude that while compensation to altered auditory feedback is a low-level, automatic process, factors such as native language may affect the parts of the speech signal that speakers use to assess the accuracy of their productions.          Last Modified: 10/30/2018       Submitted by: Sarah Bakst]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
