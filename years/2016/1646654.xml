<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Causal Bayesian Network-Based Discrimination Discovery and Prevention</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei Ding</SignBlockName>
<PO_EMAI>weiding@nsf.gov</PO_EMAI>
<PO_PHON>7032928017</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Various business models have been built around the collection and use of customer data to make important decisions like employment, credit, and insurance. There are increasing worries of discrimination as data analytics technologies could be used to unfairly treat individuals based on their demographic information such as gender, age, marital status, race, religion or belief, membership in a national minority, disability, or illness. It is imperative to develop predictive decision models, such that the data that goes into them and the decisions made with their assistance are not subject to discrimination. This EAGER research designs practical techniques to accurately detect and remove discrimination from the datasets used to build decision models. A primary outcome of this research is a unifying framework and a prototype system for discrimination discovery and removal. This system can help individuals from disadvantaged groups determine whether they are fairly treated and help decision makers from organizations ensure their predictive decision models are discrimination free. &lt;br/&gt;&lt;br/&gt;Existing discrimination discovery approaches are mainly based on correlation or association and cannot accurately discover the true discrimination. In addition, each of them targets on one or two types of discrimination only. This research categorizes discrimination based on whether discrimination is across the whole system, occurs in one subsystem, or happens to one individual, and whether discrimination is a direct effect or an indirect effect on the decision. This research then develops a unifying causal Bayesian network based framework that takes into consideration the distinctions between discrimination and general causalities and models both direct discrimination and indirect discrimination as causal effects via different paths between protected attributes and the decision. It can accurately capture and measure various types of discrimination at system, group, and individual levels. The research then develops novel discrimination discovery and prevention models and algorithms. The research also builds a testing framework for simulating different types of discrimination and evaluating the approaches based on various metrics, and integrates the discrimination discovery and prevention algorithms into an open source data mining and machine learning software system.</AbstractNarration>
<MinAmdLetterDate>08/24/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1646654</AwardID>
<Investigator>
<FirstName>Xintao</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xintao Wu</PI_FULL_NAME>
<EmailAddress>xintaowu@uark.edu</EmailAddress>
<PI_PHON>4795756519</PI_PHON>
<NSF_ID>000244983</NSF_ID>
<StartDate>08/24/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lu</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lu Zhang</PI_FULL_NAME>
<EmailAddress>lz006@uark.edu</EmailAddress>
<PI_PHON>4795754382</PI_PHON>
<NSF_ID>000702991</NSF_ID>
<StartDate>08/24/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arkansas</Name>
<CityName>Fayetteville</CityName>
<ZipCode>727013124</ZipCode>
<PhoneNumber>4795753845</PhoneNumber>
<StreetAddress>1125 W. Maple Street</StreetAddress>
<StreetAddress2><![CDATA[316 Administration Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arkansas</StateName>
<StateCode>AR</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AR03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>191429745</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARKANSAS SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>055600001</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arkansas]]></Name>
<CityName>Fayetteville</CityName>
<StateCode>AR</StateCode>
<ZipCode>727011201</ZipCode>
<StreetAddress><![CDATA[516 J.B. Hunt Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arkansas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~200000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Various business models have been built around the collection and use of individual data to make important decisions like employment, credit, and insurance. There are increasing worries of discrimination as data analytics technologies could be used to unfairly treat individuals based on their demographic information such as gender, age, marital status, race, religion or belief, membership in a national minority, disability, or illness. It is imperative to develop discrimination discovery and removal techniques to ensure the data that are used to build predictive models and the decisions made from the predictive models are not subject to discrimination.</p> <p>The major goals of this project include: (1) develop a unifying causal modeling-based framework that can model and measure both direct discrimination and indirect discrimination at system, group, and individual levels as causal effects; (2) develop novel causal modeling-based discrimination discovery and removal algorithms; and (3) build a testing framework and prototype for simulating different types of discrimination and evaluating the approaches based on various metrics.</p> <p>We conducted research on causal modeling based fairness aware machine learning and developed 1) an anti-discrimination learning framework that categorizes discrimination based on system, group, and individual levels and direct, indirect, and counterfactual manners; 2) a unified definition, the path-specific counterfactual fairness (PC fairness), which covers most of previous causality-based fairness metrics; 3) discovery and removal techniques for various types of discrimination from decision data and ranked data; 4) a two-phase framework for constructing a discrimination-free classifier; and 5) a constrained optimization formulation framework that guarantees fairness in classifiers that adopt surrogate functions as fair constraints; and 6) bounding techniques to estimate causal effect and discrimination in unidentifiable situations. We also developed fair generative adversarial networks models that achieve both data generation and fair classifiers and deep learning models to detect and remove discrimination from text data. &nbsp;&nbsp;</p> <p>Our research findings pushed the state-of-the-art in the area of fairness aware machine learning and advanced theoretical understanding of fundamental issues related to causal effect identification and causal inference as well as the design and implementation of practical techniques to effectively detect and remove discrimination from data and predictive models. The techniques we developed also have impact on areas beyond fair machine learning and developed causal modeling techniques could adapt to other domains such as detecting adverse drug effects and removing disparate health outcomes. We outreached to the broader community of computer science, data science, and social science and gave presentations of our research work at major conferences, university visits, campus showcase on data analytics, and industry companies. This project has also contributed to training graduate students and postdocs in computer science at University of Arkansas.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/07/2019<br>      Modified by: Xintao&nbsp;Wu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1646654/1646654_10454314_1575754083962_ACausalModelingFrameworkforAchievingFairnessinTrainingDataandDecisionModel--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1646654/1646654_10454314_1575754083962_ACausalModelingFrameworkforAchievingFairnessinTrainingDataandDecisionModel--rgov-800width.jpg" title="A Causal Modeling Framework for Achieving Fairness in Training Data and Decision Model"><img src="/por/images/Reports/POR/2019/1646654/1646654_10454314_1575754083962_ACausalModelingFrameworkforAchievingFairnessinTrainingDataandDecisionModel--rgov-66x44.jpg" alt="A Causal Modeling Framework for Achieving Fairness in Training Data and Decision Model"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A Causal Modeling Framework for Achieving Fairness in Training Data and Decision Model</div> <div class="imageCredit">Yongkai Wu, Lu Zhang, Xintao Wu</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Xintao&nbsp;Wu</div> <div class="imageTitle">A Causal Modeling Framework for Achieving Fairness in Training Data and Decision Model</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Various business models have been built around the collection and use of individual data to make important decisions like employment, credit, and insurance. There are increasing worries of discrimination as data analytics technologies could be used to unfairly treat individuals based on their demographic information such as gender, age, marital status, race, religion or belief, membership in a national minority, disability, or illness. It is imperative to develop discrimination discovery and removal techniques to ensure the data that are used to build predictive models and the decisions made from the predictive models are not subject to discrimination.  The major goals of this project include: (1) develop a unifying causal modeling-based framework that can model and measure both direct discrimination and indirect discrimination at system, group, and individual levels as causal effects; (2) develop novel causal modeling-based discrimination discovery and removal algorithms; and (3) build a testing framework and prototype for simulating different types of discrimination and evaluating the approaches based on various metrics.  We conducted research on causal modeling based fairness aware machine learning and developed 1) an anti-discrimination learning framework that categorizes discrimination based on system, group, and individual levels and direct, indirect, and counterfactual manners; 2) a unified definition, the path-specific counterfactual fairness (PC fairness), which covers most of previous causality-based fairness metrics; 3) discovery and removal techniques for various types of discrimination from decision data and ranked data; 4) a two-phase framework for constructing a discrimination-free classifier; and 5) a constrained optimization formulation framework that guarantees fairness in classifiers that adopt surrogate functions as fair constraints; and 6) bounding techniques to estimate causal effect and discrimination in unidentifiable situations. We also developed fair generative adversarial networks models that achieve both data generation and fair classifiers and deep learning models to detect and remove discrimination from text data.     Our research findings pushed the state-of-the-art in the area of fairness aware machine learning and advanced theoretical understanding of fundamental issues related to causal effect identification and causal inference as well as the design and implementation of practical techniques to effectively detect and remove discrimination from data and predictive models. The techniques we developed also have impact on areas beyond fair machine learning and developed causal modeling techniques could adapt to other domains such as detecting adverse drug effects and removing disparate health outcomes. We outreached to the broader community of computer science, data science, and social science and gave presentations of our research work at major conferences, university visits, campus showcase on data analytics, and industry companies. This project has also contributed to training graduate students and postdocs in computer science at University of Arkansas.          Last Modified: 12/07/2019       Submitted by: Xintao Wu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
