<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SCH: INT: Collaborative Research: Computer Guided Laparoscopy Training</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>769382.00</AwardTotalIntnAmount>
<AwardAmount>769382</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>IIS-1622589 SCH: INT: Collaborative Research: Computer Guided Laparoscopy Training&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Laparoscopic surgery, when performed by a well-trained surgeon, is a remarkably effective procedure that minimizes complications associated with open incisions, blood loss and post-operative pain. It also reduces recovery time. However, the procedure is more challenging than conventional surgery due to restricted vision, hand-eye coordination problems, limited working space, and lack of tactile sensation. Therefore, effective training and guidance methods are needed to minimize the potential risks inherent in such procedures. The goal of this project is to develop and validate techniques for computer-guided laparoscopic surgical training in a simulated, non-patient based environment. A computer-aided surgical trainer (CAST) will physically guide trainees' instruments during surgical skills practice sessions by utilizing assistive force with augmented reality displays. Guided training will be validated through a pilot experimental study, in which the expertise of computer-guided trainees will be compared to that of instructor-guided trainees. Data such as the time it takes a trainee to execute a particular surgical task, how accurate he or she is, etc., will be collected to analyze task performance precisely and objectively. New scientific methods for motion trajectory planning and path following using assistive force and augmented reality techniques will result from this work. It is anticipated that computer-guided practice will speed up learning and reinforce appropriate techniques, ultimately, leading to better surgical outcomes and improved patient safety. The CAST system should serve as a sophisticated, yet still low-cost, training solution for fundamental medical skills training.  &lt;br/&gt;&lt;br/&gt;The specific objectives are a) to refine and implement a memory- and time-efficient hybrid offline-online optimal path planner for computer-guided training of basic laparoscopic skills. In this task, collision-free trajectory planning methods (such as those used in robotics) will be generated by incorporating offline-online hybrid techniques with memory and computational time efficient path repository. Thus, basic laparoscopic tasks can be planned and guided automatically, using haptic force and augmented reality visualization; b) to design and implement an intelligent, adaptive guidance controller for surgical space navigation, where a fuzzy logic and machine learning-based methods will be developed that will take into account trainees' skill levels so that optimal amount of training assistance can be provided in mastering surgical tasks; c) to design and implement visual guidance techniques through augmented reality overlays that provide 'navigational' cues, supplementing force-based control of surgical instruments; and d) to validate guided training through a pilot study. In this task, trainees' performance using computer guidance methods will be compared, using statistical analysis, to that of unguided trainees. The principal investigators will aim to increase the participation of undergraduate students, and in particular of underrepresented groups, through collaboration with the well-established programs at both PIs'  institutions and through sponsorship of senior projects and independent study courses.</AbstractNarration>
<MinAmdLetterDate>08/01/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1622515</AwardID>
<Investigator>
<FirstName>Henry</FirstName>
<LastName>Fuchs</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Henry Fuchs</PI_FULL_NAME>
<EmailAddress>fuchs@cs.unc.edu</EmailAddress>
<PI_PHON>9199714951</PI_PHON>
<NSF_ID>000451367</NSF_ID>
<StartDate>08/01/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<CountyName>ORANGE</CountyName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Chapel Hill]]></Name>
<CityName>Chapel Hill</CityName>
<CountyName>ORANGE</CountyName>
<StateCode>NC</StateCode>
<ZipCode>275993175</ZipCode>
<StreetAddress><![CDATA[201 S. Columbia St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8062</Code>
<Text>SCH Type II: INT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~769382</FUND_OBLG>
</Award>
</rootTag>
