<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Large-Scale Behavioral Analysis Utilizing Convolutional Neural Networks and Its Application to In-store Retail Marketing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to develop an infrastructure for exposing and interpreting a previously unavailable dataset: fine-grained human interaction with a physical environment. Humans are continuously building and shaping the world but there exists little data to examine these effects. Beyond retail, this technology could affect how teachers layout classrooms, how disaster workers provide relief, or how factories keep their workers safe. The subtle physical details that affect humans everyday will be understood and investigated in ways not possible without the proposed system. This technology will benefit society specifically by improving the economic efficiency of retailers and broadly by increasing scientific understanding of how humans interact with their physical environments.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project uses a neural network and generic 3D scene reconstruction in combination with low-cost, wireless cameras to model an environment with accurate object classification and spatial relationships. Recently, neural networks have proven adept at a variety of image classification tasks but their applications in video classification, namely for human actions, have been less explored. 3D scene reconstruction has made similar advances, progressing from images to videos but has always required some prior knowledge of the physical scene. Within the past year, multiple groups have proposed methods for completely generic scene reconstruction from multiple view cameras. Finally, energy harvesting methods for devices such as cameras and wireless transmitters have been demonstrated to be feasible in laboratory experiments but have not been incorporated into commercial products. In this project the two computer vision algorithms will be developed in parallel with camera hardware so that the software and hardware systems may be integrated and demonstrated by the end of the project.</AbstractNarration>
<MinAmdLetterDate>06/22/2016</MinAmdLetterDate>
<MaxAmdLetterDate>06/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1622082</AwardID>
<Investigator>
<FirstName>Everett</FirstName>
<LastName>Berry</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Everett Berry</PI_FULL_NAME>
<EmailAddress>everett@perceiveinc.com</EmailAddress>
<PI_PHON>7654308561</PI_PHON>
<NSF_ID>000713539</NSF_ID>
<StartDate>06/22/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Perceive, Inc.</Name>
<CityName>Fishers</CityName>
<ZipCode>460382828</ZipCode>
<PhoneNumber>7654308561</PhoneNumber>
<StreetAddress>9059 Technology Ln</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080057977</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PERCEIVE, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Perceive, Inc.]]></Name>
<CityName>West Lafeytte</CityName>
<StateCode>IN</StateCode>
<ZipCode>479066503</ZipCode>
<StreetAddress><![CDATA[1904 King Eider Ct]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-1a389e78-6b66-fba5-7115-10e9acc87c7a"> </span></p> <p dir="ltr"><span>Perceive is building a customer service assistant for retail stores using computer vision, machine learning, and other technologies with the potential to make any physical space (factories, hospitals, restaurants, etc.) safer and more productive. During its Phase I SBIR award, Perceive completed two of its three technical objectives in multi-view geometry and cost-effective camera installation and the majority of a third objective in action recognition. The team conducted research into convolutional neural networks, 3D scene reconstruction and mesh networks and developed engineering solutions for a scalable video processing pipeline and simple hardware installation. Perceive also deployed a prototype of its hardware and software to a retail customer during a paid pilot of the technology.</span></p> <p dir="ltr"><span>In recent years, convolutional neural networks have been extraordinarily successful on single image tasks such as classification and object detection. However, results on video sequences have been mixed and researchers have yet to settle on an architecture which works well for classifying events that take place over time. For example, it is easy with modern networks to detect the number of people in a single image but difficult to detect actions such as &ldquo;people shopping&rdquo; or &ldquo;people walking&rdquo;. A major goal of this grant was to research the possibilities of convolutional networks for action recognition with an idea that they would be commercially useful in retail environments where shoppers, retail associates, and merchandise all interact with to conduct commerce. Many months of investigation revealed that although convolutional networks for action recognition work in some limited cases, they are far from being general purpose or performant enough to be useful for retail video. Instead other technologies were developed which address the challenge of action recognition through a multi-stage pipeline.</span></p> <p dir="ltr"><span>Other technologies are important for the commercial development of this system. First, it is not enough to know what is happening: it is also important to know where it is happening. To this end Perceive investigated 3D multi-view scene reconstruction algorithms which could combine the inputs of multiple camera views to create one 3D model of an environment. A key challenge is to require as little configuration of the cameras as possible so that the system can be installed effortlessly. In the course of this grant Perceive has leveraged its knowledge of 3D geometry for computer vision and the specific constraints of the retail environment to develop calibration, point matching, and pixel error correction algorithms for this challenge. A second important technology is camera hardware which is cost-effective to install. Perceive designed and deployed a proprietary power solution which does not require any technicians to install and can be setup by the employees of the store in a few hours. This solution is similar in complexity and time to the re-merchandising that frequently happens in stores where, for example, the holiday merchandise and displays are brought in and the autumn items are taken down.</span></p> <p dir="ltr"><span>Perceive believes that systems which extend into the physical world from the digital world are just beginning to be created. These systems will augment human abilities and enable service personel, factory workers, and others to be more efficient and more effective. The technologies developed under this Phase I SBIR Grant, including sensors, algorithms, and software infrastructure, represent key pieces of this future and by commercializing them Perceive endeavors to drive their adoption in society and advance human potential.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 12/18/2017<br>      Modified by: Everett&nbsp;Berry</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Perceive is building a customer service assistant for retail stores using computer vision, machine learning, and other technologies with the potential to make any physical space (factories, hospitals, restaurants, etc.) safer and more productive. During its Phase I SBIR award, Perceive completed two of its three technical objectives in multi-view geometry and cost-effective camera installation and the majority of a third objective in action recognition. The team conducted research into convolutional neural networks, 3D scene reconstruction and mesh networks and developed engineering solutions for a scalable video processing pipeline and simple hardware installation. Perceive also deployed a prototype of its hardware and software to a retail customer during a paid pilot of the technology. In recent years, convolutional neural networks have been extraordinarily successful on single image tasks such as classification and object detection. However, results on video sequences have been mixed and researchers have yet to settle on an architecture which works well for classifying events that take place over time. For example, it is easy with modern networks to detect the number of people in a single image but difficult to detect actions such as "people shopping" or "people walking". A major goal of this grant was to research the possibilities of convolutional networks for action recognition with an idea that they would be commercially useful in retail environments where shoppers, retail associates, and merchandise all interact with to conduct commerce. Many months of investigation revealed that although convolutional networks for action recognition work in some limited cases, they are far from being general purpose or performant enough to be useful for retail video. Instead other technologies were developed which address the challenge of action recognition through a multi-stage pipeline. Other technologies are important for the commercial development of this system. First, it is not enough to know what is happening: it is also important to know where it is happening. To this end Perceive investigated 3D multi-view scene reconstruction algorithms which could combine the inputs of multiple camera views to create one 3D model of an environment. A key challenge is to require as little configuration of the cameras as possible so that the system can be installed effortlessly. In the course of this grant Perceive has leveraged its knowledge of 3D geometry for computer vision and the specific constraints of the retail environment to develop calibration, point matching, and pixel error correction algorithms for this challenge. A second important technology is camera hardware which is cost-effective to install. Perceive designed and deployed a proprietary power solution which does not require any technicians to install and can be setup by the employees of the store in a few hours. This solution is similar in complexity and time to the re-merchandising that frequently happens in stores where, for example, the holiday merchandise and displays are brought in and the autumn items are taken down. Perceive believes that systems which extend into the physical world from the digital world are just beginning to be created. These systems will augment human abilities and enable service personel, factory workers, and others to be more efficient and more effective. The technologies developed under this Phase I SBIR Grant, including sensors, algorithms, and software infrastructure, represent key pieces of this future and by commercializing them Perceive endeavors to drive their adoption in society and advance human potential.          Last Modified: 12/18/2017       Submitted by: Everett Berry]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
