<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NCS-FO: Collaborative Research: Operationalizing Students' Textbooks Annotations to Improve Comprehension and Long-Term Retention</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregg Solomon</SignBlockName>
<PO_EMAI>gesolomo@nsf.gov</PO_EMAI>
<PO_PHON>7032928333</PO_PHON>
</ProgramOfficer>
<AbstractNarration>While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read. With a better understanding of a learner's state of mind, textbooks can make personalized recommendations for further study and review. How can the learner's state of mind be determined? Open a used printed textbook and the answer is clear: students feel compelled to engage with their texts by annotating key passages with highlights, tags, questions, and notes. Despite students' spontaneous desire to annotate as they read, this form of interaction has reaped few educational benefits in the past. At best, highlighted passages are re-read to study for exams, a strategy not nearly as effective as other strategies such as self-quizzing. This project will develop a new methodology that: assesses student knowledge level automatically based on annotations, transforms highlighted passages into appropriate study questions, and provides each student with well-timed, personalized review. Because the project is based on free, peer-reviewed, openly licensed materials from OpenStax that have been widely adopted at a range of institutions, particularly community colleges, the technology will reach beyond elite institutions to provide a broad spectrum of underserved students with access to a potentially powerful learning tool.&lt;br/&gt;&lt;br/&gt;This project adopts a big-data approach that involves collecting annotations from a population of learners to draw inferences about individual learners. The project will determine how to exploit these data to model cognitive state, enabling the team to infer students' depth of understanding of facts and concepts, predict subsequent test performance, and perform interventions that improve learning outcomes. A tool will be developed that administers appropriately timed quizzes on material related to a student's highlights. A collaborative-filtering methodology will be employed that leverages population data to suggest specific passages for an individual to review. The proposed tool will reformulate selected passages into review questions that encourage the active reconstruction and elaboration of knowledge. The design and implementation of the tool will be informed by both randomized controlled studies within the innovative OpenStax textbook platform and coordinated laboratory studies. These studies will address basic scientific questions pertaining to why students annotate, how to improve their annotation skills, and techniques to optimize the use of annotations for guiding active review.</AbstractNarration>
<MinAmdLetterDate>08/17/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1631681</AwardID>
<Investigator>
<FirstName>Harold</FirstName>
<LastName>Pashler</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Harold E Pashler</PI_FULL_NAME>
<EmailAddress>hpashler@ucsd.edu</EmailAddress>
<PI_PHON>8585343974</PI_PHON>
<NSF_ID>000128988</NSF_ID>
<StartDate>08/17/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<CountyName>SAN DIEGO</CountyName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Regents of the Univ. of Calif., U.C. San Diego]]></Name>
<CityName>La Jolla</CityName>
<CountyName>SAN DIEGO</CountyName>
<StateCode>CA</StateCode>
<ZipCode>920930109</ZipCode>
<StreetAddress><![CDATA[9500 Gilman Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>8551</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramReference>
<ProgramReference>
<Code>8817</Code>
<Text>STEM Learning &amp; Learning Environments</Text>
</ProgramReference>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~300000</FUND_OBLG>
</Award>
</rootTag>
