<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Nonlinear and Data-Adaptive Compressive Sampling for Big Data Processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>12/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>114204.00</AwardTotalIntnAmount>
<AwardAmount>114204</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>chengshan xiao</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>As pervasive sensors continuously collect and record massive amounts of&lt;br/&gt;high-dimensional data from communication, social, and biological networks,&lt;br/&gt;and growing storage as well as processing capacities of modern computers&lt;br/&gt;have provided new and powerful ways to dig into such huge quantities of&lt;br/&gt;information, the need for novel analytic tools to comb through these "big&lt;br/&gt;data" becomes imperative. The objective of this project is to develop a&lt;br/&gt;novel framework for nonlinear, data-adaptive (de)compression algorithms to&lt;br/&gt;learn the latent structure within large-scale, incomplete or corrupted&lt;br/&gt;datasets for compressing and storing only the essential information, for&lt;br/&gt;running analytics in real time, inferring missing pieces of a dataset, and&lt;br/&gt;for reconstructing the original data from their compressed renditions. &lt;br/&gt;&lt;br/&gt;The intellectual merit lies in the exploration of the fertile but largely&lt;br/&gt;unexplored areas of manifold learning, nonlinear dimensionality reduction,&lt;br/&gt;and sparsity-aware techniques for compression and recovery of missing and&lt;br/&gt;compromised measurements. Capitalizing on recent advances in machine&lt;br/&gt;learning and signal processing, differential geometry, sparsity, and&lt;br/&gt;dictionary learning are envisioned as key enablers. Effort will be put also&lt;br/&gt;into developing online and distributed (non)linear dimensionality reduction&lt;br/&gt;algorithms to allow for streaming analytics of sequential measurements&lt;br/&gt;using parallel processors. &lt;br/&gt;&lt;br/&gt;The broader impact is to contribute to the development of novel &lt;br/&gt;computational methods and tools useful for data inference, cleansing, &lt;br/&gt;forecasting, and collaborative filtering, with direct impact to &lt;br/&gt;statistical signal processing and machine learning applications&lt;br/&gt;to large-scale data analysis, including communication, social, and&lt;br/&gt;biological networks.</AbstractNarration>
<MinAmdLetterDate>02/29/2016</MinAmdLetterDate>
<MaxAmdLetterDate>02/29/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1632865</AwardID>
<Investigator>
<FirstName>Konstantinos</FirstName>
<LastName>Slavakis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Konstantinos Slavakis</PI_FULL_NAME>
<EmailAddress>kslavaki@buffalo.edu</EmailAddress>
<PI_PHON>7166451012</PI_PHON>
<NSF_ID>000637068</NSF_ID>
<StartDate>02/29/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Buffalo</Name>
<CityName>Buffalo</CityName>
<ZipCode>142282567</ZipCode>
<PhoneNumber>7166452634</PhoneNumber>
<StreetAddress>520 Lee Entrance</StreetAddress>
<StreetAddress2><![CDATA[Suite 211]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY26</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>038633251</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Buffalo]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>142607016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY26</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>154E</Code>
<Text>Computat systems &amp; security</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~114204</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The turn of the decade has trademarked society and computing research with a ``data deluge.'' As the number of smart and internet-capabledevices increases, so does the amount of data that is generated andcollected. While it is desirable to mine information from this data,their sheer amount and dimensionality introduces numerous challengesin their processing, since available statistical inference and machinelearning approaches do not necessarily scale well with the number ofdata and their dimensionality. In addition, as the cost of cloudcomputing is rapidly declining, there is a need for redesigning thosetraditional approaches to take advantage of the flexibility that hasemerged from distributing required computations to multiple nodes, aswell as reducing the per-node computational burden.&nbsp;This project aimed at novel methods for revealing nonlinear,data-adaptive (de)compression, and (unsupervised) learning fromhigh-dimensional data, as well as fundamental insights into thevarious mathematical and statistical trade-offs involved, and atoffering algorithms which overcome the emerging practicalissues. Capitalizing on advances in machine learning and signalprocessing, topics such as stochastic optimization, differentialgeometry, sparsity, dictionary learning, and randomized algorithmsplayed key roles in the development of the development of theresearch. Emphasis was placed on the following research thrusts:</p> <p><br />(R1) Clustering (unsupervised classification) methods which identifylatent information within high-dimensional data, where a novelmulti-manifold modeling (MMM) approach was developed to accommodatedata that lie in Riemannian manifolds;</p> <p><br />(R2) Data-adaptive random-sketching techniques for efficient learningfrom voluminous data, where a general framework for efficientclustering of huge sets of (possibly high-dimensional) data based onthe random sampling and consensus (RANSAC) ideas was established; and</p> <p><br />(R3) Online (non)linear dimensionality reduction algorithms to allowfor streaming analytics of sequential measurements, where a highlymodular, online-learning framework for block-wise convex (non-convexin general) tasks was developed by jointly leveraging the stochasticapproximation paradigm with advances on acceleration schemes that relyon the first-order information of convex objective functions.</p> <p><br />The developed methods have facilitated several application domainssuch as computer vision, (functional) magnetic resonance imaging, andsequential non-linear system identification, among others. Moreover,they have layed solid foundations and spurred discussions for furtheradvancements on dimensionality-reduction methods and algorithms inmachine learning and signal processing. More specifically, they haveestablished firm links between modern statistical tools, includingdictionary and manifold learning, with the fundamental tasks of signalcompression and recovery at computationally affordable and scalablelevels. The present research has helped also three PhD students,(co-)advised by the PI, to develop a better understanding ofcutting-edge research tools related to signal-processing andmachine-learning tasks. Concluding, the application of the developedtheoretical tools to important applications such as medical imagingand brain-network analytics will also play a principal role inpromoting the societal embracing of the recently emerging big-datascience.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/28/2016<br>      Modified by: Konstantinos&nbsp;Slavakis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The turn of the decade has trademarked society and computing research with a ``data deluge.'' As the number of smart and internet-capabledevices increases, so does the amount of data that is generated andcollected. While it is desirable to mine information from this data,their sheer amount and dimensionality introduces numerous challengesin their processing, since available statistical inference and machinelearning approaches do not necessarily scale well with the number ofdata and their dimensionality. In addition, as the cost of cloudcomputing is rapidly declining, there is a need for redesigning thosetraditional approaches to take advantage of the flexibility that hasemerged from distributing required computations to multiple nodes, aswell as reducing the per-node computational burden. This project aimed at novel methods for revealing nonlinear,data-adaptive (de)compression, and (unsupervised) learning fromhigh-dimensional data, as well as fundamental insights into thevarious mathematical and statistical trade-offs involved, and atoffering algorithms which overcome the emerging practicalissues. Capitalizing on advances in machine learning and signalprocessing, topics such as stochastic optimization, differentialgeometry, sparsity, dictionary learning, and randomized algorithmsplayed key roles in the development of the development of theresearch. Emphasis was placed on the following research thrusts:   (R1) Clustering (unsupervised classification) methods which identifylatent information within high-dimensional data, where a novelmulti-manifold modeling (MMM) approach was developed to accommodatedata that lie in Riemannian manifolds;   (R2) Data-adaptive random-sketching techniques for efficient learningfrom voluminous data, where a general framework for efficientclustering of huge sets of (possibly high-dimensional) data based onthe random sampling and consensus (RANSAC) ideas was established; and   (R3) Online (non)linear dimensionality reduction algorithms to allowfor streaming analytics of sequential measurements, where a highlymodular, online-learning framework for block-wise convex (non-convexin general) tasks was developed by jointly leveraging the stochasticapproximation paradigm with advances on acceleration schemes that relyon the first-order information of convex objective functions.   The developed methods have facilitated several application domainssuch as computer vision, (functional) magnetic resonance imaging, andsequential non-linear system identification, among others. Moreover,they have layed solid foundations and spurred discussions for furtheradvancements on dimensionality-reduction methods and algorithms inmachine learning and signal processing. More specifically, they haveestablished firm links between modern statistical tools, includingdictionary and manifold learning, with the fundamental tasks of signalcompression and recovery at computationally affordable and scalablelevels. The present research has helped also three PhD students,(co-)advised by the PI, to develop a better understanding ofcutting-edge research tools related to signal-processing andmachine-learning tasks. Concluding, the application of the developedtheoretical tools to important applications such as medical imagingand brain-network analytics will also play a principal role inpromoting the societal embracing of the recently emerging big-datascience.          Last Modified: 11/28/2016       Submitted by: Konstantinos Slavakis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
