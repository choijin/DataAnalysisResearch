<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Structured Methods for Multi-Task Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>250050.00</AwardTotalIntnAmount>
<AwardAmount>250050</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei Ding</SignBlockName>
<PO_EMAI>weiding@nsf.gov</PO_EMAI>
<PO_PHON>7032928017</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ability of human to learn from and transfer knowledge across related learning tasks enables us to grasp complex concepts from only a few examples. For instance, a three-year old child is able to discriminate chairs from tables without having been exposed to hundreds of different examples. In contrast, computer learning programs typically require training on a large number of examples in order to achieve similar levels of recognition. This prompts the study of multi-task learning in which multiple related tasks are learned simultaneously, thereby facilitating inter-task knowledge transfer. However, most multi-task learning studies are restricted to problems with well-defined tasks and structures. This project aims at developing algorithms and tools (including open source software) to attack problems that are not traditionally treated, but can potentially be reformulated and solved more effectively by multi-task learning. This allows a broad class of challenging machine learning problems to benefit from multi-task learning techniques. This project also develops a new curriculum that incorporates the proposed research into the classroom. In addition, this project will allow the PIs to continue the ongoing efforts of actively recruiting and advising students from under-represented groups.&lt;br/&gt;&lt;br/&gt;To achieve these goals, this project focuses on an innovative, integrated research and education plan that includes the following components: (1) providing principled guidelines for reformulating problems into the multi-task learning formalism; (2) developing robust and clustered multi-task learning models to identify and prevent false interactions among unrelated tasks; (3) developing sparsity-inducing multi-task learning models to capture richly structured task interactions; (4) developing high-order multi-task learning models to capture task relatedness from interactions between features; and (5) investigating computational algorithms and theoretical properties of multi-task learning. The outcome of this project includes the capabilities of reformulating diverse machine learning problems into the multi-task learning framework and providing radically new ways to attack challenging problems that cannot be solved effectively by traditional methods. The systematic study of multi-task learning in this project is expected to generate novel reformulations, structured mathematical models, efficient optimization algorithms, and principled theoretical analyses, which will lead to significant practical and theoretical advances in multi-task learning.</AbstractNarration>
<MinAmdLetterDate>07/21/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1615597</AwardID>
<Investigator>
<FirstName>Jiayu</FirstName>
<LastName>Zhou</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jiayu Zhou</PI_FULL_NAME>
<EmailAddress>dearjiayu@gmail.com</EmailAddress>
<PI_PHON>4803345283</PI_PHON>
<NSF_ID>000694372</NSF_ID>
<StartDate>07/21/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName>East Lansing</CityName>
<StateCode>MI</StateCode>
<ZipCode>488241226</ZipCode>
<StreetAddress><![CDATA[428 S. Shaw Lane, Rm 3115]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~250050</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-387c42a7-7fff-bc4c-8086-c7bc65c23ee9"> <p dir="ltr"><span>Human learning is highly effective partly due to its capability to efficiently leverage experiences from related learning problems. When there are restricted data samples available for machines to learn a model, multi-task learning (MTL) provides a capable learning paradigm to leverage related machine learning tasks. By learning the related tasks simultaneously, MTL extracts shared knowledge into a shared structure and leverages it to improve the model performance for all tasks involved. The project outcomes include a suite of theoretical advancements, algorithmic developments, and application validations of MTL.&nbsp;</span></p> <br /><span>The intellectual merit is highlighted with the delivery of 1) multi-task interaction learning that explores high-order task relationships; 2) distributed MTL that allows efficient asynchronous coordinated learning from distributed participants; 3) privacy-preserving MTL that seeks to protect privacy during a collaborated and distributed MTL process; 4) enabling learning of nested feature structures in MTL; 5) a subspace network for MTL that performs layer-by-layer learning of a deep MTL model with small-sized training data. Besides, the project successfully validated the broad applicability and competitive performance of MTL in multiple domains, including medical informatics, disease studies, transportation research. The project outcomes have been disseminated in various conference venues, workshops, and journals in the fields of machine learning, data mining, and medical informatics. The software produced from this project is integrated into the MALSAR (multi-task learning via structural regularization) project (</span><a href="http://malsar.org/"><span>http://malsar.org/</span></a><span>). The project has supported two graduate students towards their dissertations and the completion of their doctoral studies. </span></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 08/13/2020<br>      Modified by: Jiayu&nbsp;Zhou</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Human learning is highly effective partly due to its capability to efficiently leverage experiences from related learning problems. When there are restricted data samples available for machines to learn a model, multi-task learning (MTL) provides a capable learning paradigm to leverage related machine learning tasks. By learning the related tasks simultaneously, MTL extracts shared knowledge into a shared structure and leverages it to improve the model performance for all tasks involved. The project outcomes include a suite of theoretical advancements, algorithmic developments, and application validations of MTL.   The intellectual merit is highlighted with the delivery of 1) multi-task interaction learning that explores high-order task relationships; 2) distributed MTL that allows efficient asynchronous coordinated learning from distributed participants; 3) privacy-preserving MTL that seeks to protect privacy during a collaborated and distributed MTL process; 4) enabling learning of nested feature structures in MTL; 5) a subspace network for MTL that performs layer-by-layer learning of a deep MTL model with small-sized training data. Besides, the project successfully validated the broad applicability and competitive performance of MTL in multiple domains, including medical informatics, disease studies, transportation research. The project outcomes have been disseminated in various conference venues, workshops, and journals in the fields of machine learning, data mining, and medical informatics. The software produced from this project is integrated into the MALSAR (multi-task learning via structural regularization) project (http://malsar.org/). The project has supported two graduate students towards their dissertations and the completion of their doctoral studies.           Last Modified: 08/13/2020       Submitted by: Jiayu Zhou]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
