<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Probabilistic Hierarchical Models for Multi-Task Visual Recognition</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>449989.00</AwardTotalIntnAmount>
<AwardAmount>449989</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project studies biologically-inspired architectures for visual recognition. The human visual system can perform a remarkable number of tasks, from estimating the 3D shape of an object that is grasped to inferring subtle differences between two similar makes and models of cars. Such diverse sets of visual tasks are required of a range of autonomous agents, including self-driving cars or humanoid robotics. Such autonomous platforms have the potential to increase general welfare and health of the overall population. This project attempts to build a computational model capable of such diverse visual tasks. Motivated by biological evidence, this project explores the use of feedback logic to enable such computational reasoning. The project provides research opportunities for both undergraduate and graduate students and for increasing diversity in the fields of computer and human vision.  &lt;br/&gt;&lt;br/&gt;This research focuses on development of a unified hierarchical probabilistic model that can be used to solve multiple fine-grained visual tasks. Feedforward hierarchical models, of which the most ubiquitous are Convolutional Neural Nets (CNNs), have demonstrated remarkable performance in recent history. This project introduces hierarchical models for vision-with-scrutiny tasks, such as 3D articulated pose estimation and part segmentation. Rather than focusing on increasing performance on established benchmark performance, this research provides a theoretical framework for analyzing bottom-up (feedforward) CNNs and imbuing them with novel top-down reasoning capabilities. It does so by exploring a link between three dominant but disparate paradigms for visual recognition: feedforward neural models, generative probabilistic models (Boltzmann machines), and discriminative latent-variable models (deformable part models). The models introduced in this proposal allow CNNs to be used for large-scale multi-task learning, where tasks span both coarse-grained tasks (such as rapid scene categorization) and fine-grained tasks (such as 3D articulated pose estimation). By addressing multiple fine-grained tasks with a single hierarchical architecture, resource requirements for memory and speed are vastly decreased, important for embedded visual perception applications such as autonomous robots and vehicles.</AbstractNarration>
<MinAmdLetterDate>07/06/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1618903</AwardID>
<Investigator>
<FirstName>Deva</FirstName>
<LastName>Ramanan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Deva Ramanan</PI_FULL_NAME>
<EmailAddress>deva@cs.cmu.edu</EmailAddress>
<PI_PHON>4122686966</PI_PHON>
<NSF_ID>000083629</NSF_ID>
<StartDate>07/06/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~449989</FUND_OBLG>
</Award>
</rootTag>
