<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Additive Parts-based Data Representation with Nonnegative Sparse Autoencoders</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>233235.00</AwardTotalIntnAmount>
<AwardAmount>233235</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Goldberg</SignBlockName>
<PO_EMAI>lgoldber@nsf.gov</PO_EMAI>
<PO_PHON>7032928339</PO_PHON>
</ProgramOfficer>
<AbstractNarration>One of the long-standing open problems of computational learning is its inability to produce solutions that are intuitively understandable.  Because of the limited transparency, most computed predictions are not easily justifiable by humans who need to render final decisions. This project addresses this shortcoming of machine learning predictions by investigating a class of machine learning algorithms that mimics natural processing and leads to more interpretable representations of data. Such processing decomposes visual patterns or other data into parts through unsupervised learning and produces non-negative parts only.  Since this approach allows only additive recombination of parts to reconstruct the original data, it mimics natural processing in human perception and cognition. The project advances novel data representation beyond standard computational learning approaches.  Tests are conducted with planar images or tabulated data that describe specific domain of interest. The tests objectives are to produce useful and understandable features, logic rules or verbal explanations in lower dimensional space. &lt;br/&gt;&lt;br/&gt;This work aims at evaluating how rich data can be explored in order to be better understood. The novel paradigm is to generate non-negative, sparse and localized features and receptive fields within hierarchies of features. This is achieved through autoencoder-based transformations of visual images or of typical non-negative data matrices.  The novel autoencoders are constrained to have non-negative weights. Specific conditions to be tested include pooling, rectifying-type activation functions of neurons and select norms of activations sparsity. The project advances the following transformational challenges at the intersection of computational and human systems: (1) Representation of data with non-negative encodings only, (2)  Complexity of layers and of receptive filters (more simpler filters vs. fewer complex filters), (3) Choice of the number of layers, also in the context of hyper-parameter tuning, (4) Pooling for non-negative processing,  (5) Connections between the autoencoder-based learning and related biological evidence, and finally (6) Ability to generate explanations or understandable rules for select domains</AbstractNarration>
<MinAmdLetterDate>07/28/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/28/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1641042</AwardID>
<Investigator>
<FirstName>Jacek</FirstName>
<LastName>Zurada</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jacek M Zurada</PI_FULL_NAME>
<EmailAddress>jmzura02@louisville.edu</EmailAddress>
<PI_PHON>5028526314</PI_PHON>
<NSF_ID>000352478</NSF_ID>
<StartDate>07/28/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tamer</FirstName>
<LastName>Inanc</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tamer Inanc</PI_FULL_NAME>
<EmailAddress>t.inanc@louisville.edu</EmailAddress>
<PI_PHON>5028527508</PI_PHON>
<NSF_ID>000434619</NSF_ID>
<StartDate>07/28/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Louisville Research Foundation Inc</Name>
<CityName>Louisville</CityName>
<ZipCode>402021959</ZipCode>
<PhoneNumber>5028523788</PhoneNumber>
<StreetAddress>Atria Support Center</StreetAddress>
<StreetAddress2><![CDATA[300 East Market St, Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>KY03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>057588857</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF LOUISVILLE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>057588857</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Louisville]]></Name>
<CityName>Louisville</CityName>
<StateCode>KY</StateCode>
<ZipCode>402920001</ZipCode>
<StreetAddress><![CDATA[2301 South Third Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>KY03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~233235</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Feature extraction through constrained learning of receptive fields (RFs) offers special promise and has recently become one of the important tenets of deep learning. In deep autoencoding, autoencoder (AE) performs unsupervised learning to detect feature hierarchies which shatter the data, generate distinctive features and support a recognition of an object, or allocate it to a certain class. In this process each AE layer adds an abstract representation of inputs, in effect producing a cascade of encodings. In general, as a result of learning for minimum error of reconstruction or classification, the RFs manifest themselves as quasi basis functions that are usually sparse and of the same dimensionality as the input layer (or, in general, of dimensionality of the preceding processing layer).</p> <p>Deep autoencoding attempts to decompose the input samples into a number of binary and/or continuous but preferably sparse concepts. The reconstruction is then achieved by adding ??parts??: ideally, it could be an additive linear combination of a number of scaled basis functions by the decoder that provides scaling coefficients. This concept has been demonstrated using a number of AE architectures with non-negative weights that produce additive decompositions layer-wise.&nbsp; Such non-negative decompositions enable better understanding and enhance explanations when inspecting the deep learning processing.</p> <p>This project proposed new techniques for data representation in the context of DL for stacked AEs by leveraging on the ability to agglomerate regularized sparse RFs and also by enhancing the feature generation process at the output layer via controlled feature compression. The performance of the proposed method in terms of decomposing data into parts and non-redundant feature extraction was compared for the conventional Sparse Auto-Encoder with constrained AEs (Dropout AE), Nonnegativity-Constrained Auto-Encoder, and L1/L2-AEs. This concept was illustrated using the NORB normalized-uniform object dataset, MNIST handwritten digits data and Yale Face Dataset.</p> <p>In sum, it has been observed that encouraging non-negativity in AEs and other deep architecture forces the layers to learn part-based representation of their input and leads to a comparable classification accuracy of the deep network and not-so-significant accuracy deterioration after fine-tuning. It has also been shown on select examples that concurrent so called L1 and L2 regularizations improve the network interpretability.</p> <p>More details of this project are available via summaries and full content of five articles in technical journals IEEE Transactions on Neural Networks and Learning Systems, IEEE Systems, Man and Cybernetics Magazine and Neural Networks here:</p> <p><a href="https://10.0.3.248/j.neunet.2017.04.012">https://doi.org/10.1016/j.neunet.2017.04.012</a></p> <p><a href="file:///C:/Users/Zurada/Desktop/$$$$/2016-18-EAGER-awarded/2-FINAL-REPORT/PROJECT-OUTCOMES/10.1109/MSMC.2017.2701578">10.1109/MSMC.2017.2701578</a><span style="text-decoration: underline;">&nbsp; </span></p> <p><a href="file:///C:/Users/Zurada/Desktop/$$$$/2016-18-EAGER-awarded/2-FINAL-REPORT/PROJECT-OUTCOMES/10.1109/TNNLS.2017.2747861">10.1109/TNNLS.2017.2747861</a></p> <p><a href="https://doi.org/10.1016/j.neunet.2019.04.021">https://doi.org/10.1016/j.neunet.2019.04.021</a></p> <p><a href="https://doi.org/10.1109/TNNLS.2018.2885972" target="_blank">10.1109/TNNLS.2018.2885972</a></p> <p>Select figures on attached images show examples of receptive fields and their significance for a single written digit recognition taken from the data base MNIST (Fig 2), examples of isolated receptive fields for all MNIST digits classifier (Fig 4), and example processing of Reuters bulletin boards text processing that discovers the topic of the posting (Fig 10).&nbsp;</p> <p>The color picture without caption was taken on June 26, 2019 for the INSPIRE program participants from Louisville area high schools who have attended a lecture and lab demos on Deep Learning by Professor Jacek Zurada (PI) and by William Funke (Graduate Research Assistant) as a part of broadening activities.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/30/2019<br>      Modified by: Jacek&nbsp;M&nbsp;Zurada</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577746517343_Capture2--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577746517343_Capture2--rgov-800width.jpg" title="Filtering the bitmap of digit 2 via an AE"><img src="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577746517343_Capture2--rgov-66x44.jpg" alt="Filtering the bitmap of digit 2 via an AE"></a> <div class="imageCaptionContainer"> <div class="imageCaption">See the caption under the figure for details</div> <div class="imageCredit">IEEE Trans on NN and Learning Systems</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Jacek&nbsp;M&nbsp;Zurada</div> <div class="imageTitle">Filtering the bitmap of digit 2 via an AE</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577746915298_Capture4--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577746915298_Capture4--rgov-800width.jpg" title="Display of receptive fields for MNIST digit classifiers with AE"><img src="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577746915298_Capture4--rgov-66x44.jpg" alt="Display of receptive fields for MNIST digit classifiers with AE"></a> <div class="imageCaptionContainer"> <div class="imageCaption">See the detailed caption underneath the figure</div> <div class="imageCredit">IEEE Transactions on NN and LS</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Jacek&nbsp;M&nbsp;Zurada</div> <div class="imageTitle">Display of receptive fields for MNIST digit classifiers with AE</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577747024837_Capture10--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577747024837_Capture10--rgov-800width.jpg" title="Reuters newsgroups data base processing example"><img src="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577747024837_Capture10--rgov-66x44.jpg" alt="Reuters newsgroups data base processing example"></a> <div class="imageCaptionContainer"> <div class="imageCaption">See the detailed caption underneath the figure</div> <div class="imageCredit">IEEE Transactions on NN and LS</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Jacek&nbsp;M&nbsp;Zurada</div> <div class="imageTitle">Reuters newsgroups data base processing example</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577747217876_IMG_20190626-inspire-broad-act--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577747217876_IMG_20190626-inspire-broad-act--rgov-800width.jpg" title="After the Deep Learning Lecture and Demo"><img src="/por/images/Reports/POR/2019/1641042/1641042_10444912_1577747217876_IMG_20190626-inspire-broad-act--rgov-66x44.jpg" alt="After the Deep Learning Lecture and Demo"></a> <div class="imageCaptionContainer"> <div class="imageCaption">June 26, 2019: INSPIRE program participants from Louisville, KY area high schools who have attended a lecture and lab demos on Deep Learning by Professor Jacek Zurada (PI) and by William Funke (Graduate Research Assistant) as a part of broadening activities</div> <div class="imageCredit">Jacek Zurada</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jacek&nbsp;M&nbsp;Zurada</div> <div class="imageTitle">After the Deep Learning Lecture and Demo</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Feature extraction through constrained learning of receptive fields (RFs) offers special promise and has recently become one of the important tenets of deep learning. In deep autoencoding, autoencoder (AE) performs unsupervised learning to detect feature hierarchies which shatter the data, generate distinctive features and support a recognition of an object, or allocate it to a certain class. In this process each AE layer adds an abstract representation of inputs, in effect producing a cascade of encodings. In general, as a result of learning for minimum error of reconstruction or classification, the RFs manifest themselves as quasi basis functions that are usually sparse and of the same dimensionality as the input layer (or, in general, of dimensionality of the preceding processing layer).  Deep autoencoding attempts to decompose the input samples into a number of binary and/or continuous but preferably sparse concepts. The reconstruction is then achieved by adding ??parts??: ideally, it could be an additive linear combination of a number of scaled basis functions by the decoder that provides scaling coefficients. This concept has been demonstrated using a number of AE architectures with non-negative weights that produce additive decompositions layer-wise.  Such non-negative decompositions enable better understanding and enhance explanations when inspecting the deep learning processing.  This project proposed new techniques for data representation in the context of DL for stacked AEs by leveraging on the ability to agglomerate regularized sparse RFs and also by enhancing the feature generation process at the output layer via controlled feature compression. The performance of the proposed method in terms of decomposing data into parts and non-redundant feature extraction was compared for the conventional Sparse Auto-Encoder with constrained AEs (Dropout AE), Nonnegativity-Constrained Auto-Encoder, and L1/L2-AEs. This concept was illustrated using the NORB normalized-uniform object dataset, MNIST handwritten digits data and Yale Face Dataset.  In sum, it has been observed that encouraging non-negativity in AEs and other deep architecture forces the layers to learn part-based representation of their input and leads to a comparable classification accuracy of the deep network and not-so-significant accuracy deterioration after fine-tuning. It has also been shown on select examples that concurrent so called L1 and L2 regularizations improve the network interpretability.  More details of this project are available via summaries and full content of five articles in technical journals IEEE Transactions on Neural Networks and Learning Systems, IEEE Systems, Man and Cybernetics Magazine and Neural Networks here:  https://doi.org/10.1016/j.neunet.2017.04.012  10.1109/MSMC.2017.2701578    10.1109/TNNLS.2017.2747861  https://doi.org/10.1016/j.neunet.2019.04.021  10.1109/TNNLS.2018.2885972  Select figures on attached images show examples of receptive fields and their significance for a single written digit recognition taken from the data base MNIST (Fig 2), examples of isolated receptive fields for all MNIST digits classifier (Fig 4), and example processing of Reuters bulletin boards text processing that discovers the topic of the posting (Fig 10).   The color picture without caption was taken on June 26, 2019 for the INSPIRE program participants from Louisville area high schools who have attended a lecture and lab demos on Deep Learning by Professor Jacek Zurada (PI) and by William Funke (Graduate Research Assistant) as a part of broadening activities.                Last Modified: 12/30/2019       Submitted by: Jacek M Zurada]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
