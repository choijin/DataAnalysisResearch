<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: IA: Democratizing Massive Fluid Flow Simulations via Open Numerical Laboratories and Applications to Turbulent Flow and Geophysical Modeling</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2016</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>952570.00</AwardTotalIntnAmount>
<AwardAmount>952570</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>06040300</Code>
<Directorate>
<Abbreviation>GEO</Abbreviation>
<LongName>Directorate For Geosciences</LongName>
</Directorate>
<Division>
<Abbreviation>OCE</Abbreviation>
<LongName>Division Of Ocean Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Baris Uz</SignBlockName>
<PO_EMAI>bmuz@nsf.gov</PO_EMAI>
<PO_PHON>7032924557</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer simulations of turbulent fluid flows are playing an increasingly vital role in engineering applications (e.g. reducing drag forces on vehicles and predicting wind turbine aerodynamic efficiency) and in geophysical sciences (e.g. describing the fate of pollutant dispersion or Lagrangian transport and mixing in the ocean). Simulations consist of discretizing and integrating the partial differential equations governing fluid flow and transport forward in time, providing solutions for physical variables (fields such as velocity and pressure) as function of time and space in the entire domain of interest. Since such simulations generate enormous amounts of data, the prevailing approach has been for researchers to analyze the data "on the fly" during the simulation runs while only a small subset of time-steps are stored for subsequent analysis. As a result, often large simulations of the same process must be repeated after new questions arise that were not initially obvious. Many (or even most) breakthrough concepts cannot be anticipated in advance, as they will be motivated in part by output data and must then be tested against it. As a result, there is a need for methods to store entire space-time data from such simulations.  This project develops innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling and makes these available to the entire community. Several of the datasets to be included into the Open Numerical Laboratory will be contributed by external researchers. In addition to enhancing engineering and geophysical fluid mechanics and turbulence research, democratized access to large-scale turbulent flow simulation data will also play a crucial role in education and training for the next generation of researchers. Active learning through new educational modules that allow students to query simulation datasets in unprecedented detail will provide new educational paradigms. More broadly, the lessons learned from this project will be generalizable to many other fields where numerical simulations generate very large datasets that are difficult to access using prevailing approaches. In this way, the project will enhance the scientific and broader impacts of the US high-performance scientific computing infrastructure. &lt;br/&gt;&lt;br/&gt;This project will develop innovative tools for the efficient creation of open numerical databases that contain massive outputs from computational fluid dynamics simulations used in turbulence research and geophysical transport modeling. An ingest pipeline to be developed will enable users to transfer data from file systems containing the output of their massive direct numerical simulations, build a database, and serve it to the community for open exploratory data analysis and innovative turbulence and oceanic mixing research. To date, the investigators involved in this project have built an Open Numerical Laboratory focusing on direct numerical simulations (DNS) of canonical turbulent flows, in which the entire space-time data are available to the wider research community. However, the existing datasets are few in number and databases have been created one by one, using methodologies difficult to replicate on a massive scale.  Moreover, emerging Exascale simulations will potentially result in data sets of unprecedented scale (tens to hundreds of PetaBytes). Advanced computer science algorithms will be required to tackle these challenges. This project will (a) develop automated, and scalable data management algorithms to ingest, index and serve very large data sets generated by a wide range of groups, (b) explore novel algorithms using spatio-temporal subsampling combined with online interpolation with re-simulation, yielding large compression factors depending on the subsampling stride, and (c) use machine learning algorithms to identify localized regions of interest in the simulations and save these 4D domains in a database for detailed follow-up analytics. The new databases will include data from (1) the largest channel flow DNS, (2) rotating and stratified turbulence of geophysical interest, (3) a DNS of developing wall boundary layer and (4) detailed ocean circulation models with complex boundary conditions. As part of the innovative domain science applications, data sets will be used to improve turbulence models using data-assimilation concepts, study Lagrangian vortex dynamics, and explore geophysical transport in a regional general circulation model of the North Atlantic Ocean.</AbstractNarration>
<MinAmdLetterDate>09/13/2016</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.050</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1633124</AwardID>
<Investigator>
<FirstName>Alexander</FirstName>
<LastName>Szalay</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexander S Szalay</PI_FULL_NAME>
<EmailAddress>aszalay1@jhu.edu</EmailAddress>
<PI_PHON>4105167217</PI_PHON>
<NSF_ID>000472256</NSF_ID>
<StartDate>09/13/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gregory</FirstName>
<LastName>Eyink</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gregory L Eyink</PI_FULL_NAME>
<EmailAddress>eyink@jhu.edu</EmailAddress>
<PI_PHON>4105167201</PI_PHON>
<NSF_ID>000284054</NSF_ID>
<StartDate>09/13/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Charles</FirstName>
<LastName>Meneveau</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Charles V Meneveau</PI_FULL_NAME>
<EmailAddress>meneveau@jhu.edu</EmailAddress>
<PI_PHON>4105167802</PI_PHON>
<NSF_ID>000113441</NSF_ID>
<StartDate>09/13/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Randal</FirstName>
<LastName>Burns</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Randal Burns</PI_FULL_NAME>
<EmailAddress>randal@cs.jhu.edu</EmailAddress>
<PI_PHON>4104936312</PI_PHON>
<NSF_ID>000461531</NSF_ID>
<StartDate>09/13/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tamer</FirstName>
<LastName>Zaki</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tamer A Zaki</PI_FULL_NAME>
<EmailAddress>t.zaki@jhu.edu</EmailAddress>
<PI_PHON>4105168668</PI_PHON>
<NSF_ID>000656179</NSF_ID>
<StartDate>09/13/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName/>
<StateCode>MD</StateCode>
<ZipCode>212182608</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1610</Code>
<Text>PHYSICAL OCEANOGRAPHY</Text>
</ProgramElement>
<ProgramElement>
<Code>8074</Code>
<Text>EarthCube</Text>
</ProgramElement>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>4444</Code>
<Text>INTERDISCIPLINARY PROPOSALS</Text>
</ProgramReference>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~952570</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main goals of this project were to develop innovative tools to facilitate open database creation to easily build, analyze, and visualize data sets from high-performance numerical simulations of various fluid flows, and to place them in open database environments for broad availability. Such open numerical laboratories have proven invaluable in allowing anyone to access the results from high-performance numerical simulations using only an internet connection. Using traditional methods the access to such data has been highly restrictive: users have to download flat files form a server, worry about file format, and then still they have to use massive parallel computing facilities for any further analysis. Open numerical laboratories provide a low entry bar to large datasets and thus democratize access to massive fluid dynamics simulations. Users of the open numerical laboratory can specify positions and times at which data (e.g. fluid velocity and pressure) are desired (at &ldquo;virtual sensor&rdquo; locations and times), and a Web Services enabled database returns field variables. Also as part of the project, new turbulence datasets as well as simulations of the circulation in the subpolar North Atlantic Ocean were included and made available in the numerical laboratories. Based on the unique database capabilities, several research topics were pursued to advance fluid science along various directions.</p> <p>For new datasets in the Johns Hopkins Turbulence Databases (JHTDB) we use the new FileDB system to organize data according to an optimal spatial arrangement but in files stored in a regular file system. The new approach greatly facilitates data ingestion. The following new datasets were added to JHTDB using FileDB: (i) Snapshots of forced isotropic turbulence data set on 4096<sup>3</sup> and 8192<sup>3</sup> grids, (ii) snapshots of rotating stratified turbulence dataset on 4096<sup>3</sup> grid, (iii) snapshots of a turbulent channel flow at Re<sub>t</sub>=5200, and (iv) the full space-time evolution of a transitional boundary layer flow. Altogether the system now comprises 1/2 Petabytes. Also, two simulations of the circulation in the subpolar North Atlantic Ocean were stored on the SciServer platform. A new year&shy;long, high&shy;resolution (&sim;2 km) numerical simulation covering the east Greenland shelf and the Iceland and Irminger Seas has been run. The new simulation dataset has been made publicly available with a suite of analysis tools. A Python software package, called OceanSpy, to facilitate the analysis and visualization of ocean general circulation models has been developed and integrated into SciServer.</p> <p>We developed modules that facilitate 3D visualization of data from JHTDB with open source software (Python Jupyter Notebooks). We include volume rendering and 3D iso-surfaces to analyze flows. Also, we developed new techniques that perform feature extraction of vortices for a simulation of turbulent fluid dynamics based on file access from stored snapshots. During the project we also developed and extensively tested a new data compression tool based on spatio-temporal sub-sampling and local re-simulation. We anticipate this technique will become cost-effective for actual implementation in the future for significantly larger datasets than those currently available in JHTDB.</p> <p>The various datasets were used to advance scientific objectives. For instance, we used the channel flow data on JHTDB and our unique, database-enabled backward-in-time tracking capabilities to elucidate how vorticity is generated and transported in wall-bounded flows.<strong> </strong>Regarding ocean mixing, the main findings from analyzing the datasets advance the understanding of the dense overflow through Denmark Strait, which is important for global climate. Specifically, the current pathways approaching and passing through the overflow were analyzed. On the topic of database-augmented wall and subgrid-scale modeling for Large Eddy Simulations, we developed ensemble-variational techniques that use available statistical data to optimize subgrid-scale models and provide uncertainty bounds for our predictions.</p> <p>Analysis of turbulent spots in the transitional turbulence dataset has allowed us to address a long-standing question whether incipient turbulent spots already contain properties of high-Reynolds-number, developed turbulence. In this study, and using a new unsupervised machine-learning method that can identify spot interfaces without setting arbitrary thresholds, we show that spot interfaces have a fractal dimension of D ~ 2.36, very similar to high Reynolds number behavior. Results thus provide evidence that turbulent spots exhibit high-Reynolds-number fractal-scaling properties already during early transitional stages of the flow evolution.</p> <p>Broader Impacts: In terms of dissemination and outreach, the project led to 14 peer-reviewed publications, 11 conference papers, and over 50 presentations. For outreach, a Turbulence Summer School with over 50 participants was organized in 2017 that utilized access to the JHTDB for purposes of studying boundary layer turbulence. Usage of JHTDB has continued to grow. From 2016 to September 2020, the number of peer-reviewed papers by authors and research groups world-wide that have been based on data from JHTDB are, respectively: 19, 15, 44, 49 and 30.&nbsp; Overall, more than 200 papers have been published using JHTDB data illustrating the considerable benefits of democratizing access to large-scale simulation datasets.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/09/2020<br>      Modified by: Charles&nbsp;V&nbsp;Meneveau</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main goals of this project were to develop innovative tools to facilitate open database creation to easily build, analyze, and visualize data sets from high-performance numerical simulations of various fluid flows, and to place them in open database environments for broad availability. Such open numerical laboratories have proven invaluable in allowing anyone to access the results from high-performance numerical simulations using only an internet connection. Using traditional methods the access to such data has been highly restrictive: users have to download flat files form a server, worry about file format, and then still they have to use massive parallel computing facilities for any further analysis. Open numerical laboratories provide a low entry bar to large datasets and thus democratize access to massive fluid dynamics simulations. Users of the open numerical laboratory can specify positions and times at which data (e.g. fluid velocity and pressure) are desired (at "virtual sensor" locations and times), and a Web Services enabled database returns field variables. Also as part of the project, new turbulence datasets as well as simulations of the circulation in the subpolar North Atlantic Ocean were included and made available in the numerical laboratories. Based on the unique database capabilities, several research topics were pursued to advance fluid science along various directions.  For new datasets in the Johns Hopkins Turbulence Databases (JHTDB) we use the new FileDB system to organize data according to an optimal spatial arrangement but in files stored in a regular file system. The new approach greatly facilitates data ingestion. The following new datasets were added to JHTDB using FileDB: (i) Snapshots of forced isotropic turbulence data set on 40963 and 81923 grids, (ii) snapshots of rotating stratified turbulence dataset on 40963 grid, (iii) snapshots of a turbulent channel flow at Ret=5200, and (iv) the full space-time evolution of a transitional boundary layer flow. Altogether the system now comprises 1/2 Petabytes. Also, two simulations of the circulation in the subpolar North Atlantic Ocean were stored on the SciServer platform. A new year&shy;long, high&shy;resolution (&sim;2 km) numerical simulation covering the east Greenland shelf and the Iceland and Irminger Seas has been run. The new simulation dataset has been made publicly available with a suite of analysis tools. A Python software package, called OceanSpy, to facilitate the analysis and visualization of ocean general circulation models has been developed and integrated into SciServer.  We developed modules that facilitate 3D visualization of data from JHTDB with open source software (Python Jupyter Notebooks). We include volume rendering and 3D iso-surfaces to analyze flows. Also, we developed new techniques that perform feature extraction of vortices for a simulation of turbulent fluid dynamics based on file access from stored snapshots. During the project we also developed and extensively tested a new data compression tool based on spatio-temporal sub-sampling and local re-simulation. We anticipate this technique will become cost-effective for actual implementation in the future for significantly larger datasets than those currently available in JHTDB.  The various datasets were used to advance scientific objectives. For instance, we used the channel flow data on JHTDB and our unique, database-enabled backward-in-time tracking capabilities to elucidate how vorticity is generated and transported in wall-bounded flows. Regarding ocean mixing, the main findings from analyzing the datasets advance the understanding of the dense overflow through Denmark Strait, which is important for global climate. Specifically, the current pathways approaching and passing through the overflow were analyzed. On the topic of database-augmented wall and subgrid-scale modeling for Large Eddy Simulations, we developed ensemble-variational techniques that use available statistical data to optimize subgrid-scale models and provide uncertainty bounds for our predictions.  Analysis of turbulent spots in the transitional turbulence dataset has allowed us to address a long-standing question whether incipient turbulent spots already contain properties of high-Reynolds-number, developed turbulence. In this study, and using a new unsupervised machine-learning method that can identify spot interfaces without setting arbitrary thresholds, we show that spot interfaces have a fractal dimension of D ~ 2.36, very similar to high Reynolds number behavior. Results thus provide evidence that turbulent spots exhibit high-Reynolds-number fractal-scaling properties already during early transitional stages of the flow evolution.  Broader Impacts: In terms of dissemination and outreach, the project led to 14 peer-reviewed publications, 11 conference papers, and over 50 presentations. For outreach, a Turbulence Summer School with over 50 participants was organized in 2017 that utilized access to the JHTDB for purposes of studying boundary layer turbulence. Usage of JHTDB has continued to grow. From 2016 to September 2020, the number of peer-reviewed papers by authors and research groups world-wide that have been based on data from JHTDB are, respectively: 19, 15, 44, 49 and 30.  Overall, more than 200 papers have been published using JHTDB data illustrating the considerable benefits of democratizing access to large-scale simulation datasets.          Last Modified: 12/09/2020       Submitted by: Charles V Meneveau]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
