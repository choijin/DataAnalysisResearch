<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: The structure of the ASL lexicon: Experimental and statistical evidence from a large lexical database (ASL-LEX)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
<AwardExpirationDate>02/29/2020</AwardExpirationDate>
<AwardTotalIntnAmount>287454.00</AwardTotalIntnAmount>
<AwardAmount>332037</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tyler Kendall</SignBlockName>
<PO_EMAI>tkendall@nsf.gov</PO_EMAI>
<PO_PHON>7032922434</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This collaborative project will record and study the properties of lexical forms in American Sign Language. Almost everything we know about human language comes from the study of spoken languages. However, only by studying sign languages is it possible to discover which linguistic rules and constraints are universal to all human languages and which depend on the particular properties of an individual language. By studying sign languages researchers can uncover language patterns that are tied to the nature of the articulators (i.e., the hands vs. the vocal tract) or that are linked to the specific way a language is perceived (i.e., visually vs. auditorally). Researchers can also uncover language patterns that result from properties that systematically vary between spoken and signed languages, such as the high prevalence of iconic forms (words that resemble what they mean) in sign languages. Psychological and linguistic research on spoken languages has relied on lexical databases--repositories of information about the words of a language--to identify factors that influence how words are comprehended and produced, to understand how words are organized and structured in the mind and brain (in our "mental lexicon"), and to discover the linguistic patterns that are present in languages. Unfortunately however, there is currently no comparably large lexical database for American Sign Language (ASL), the sign language used by deaf and hearing people in the United States.&lt;br/&gt;&lt;br/&gt;A primary aim of this project is to create a large, searchable, and publically available database of approximately 2,500 ASL signs. The database (called ASL-LEX) will contain the following information for each sign: subjective frequency-of-use ratings, iconicity ratings from both deaf signers and hearing non-signers, sign duration measures, lexical category information (e.g., noun, verb, etc.), and codes for sign-based phonological features (e.g., location, handshape, movement) that can be used to calculate whether the form of a sign is relatively common (has many form 'neighbors') or relatively unique (has few 'neighbors'). A second aim is to use ASL-LEX to conduct the first quantitative analysis of the ASL lexicon in order to uncover regularities in the way that phonological features appear (or do not appear) in ASL signs and how these patterns are influenced by sign properties such as frequency and iconicity. A third aim is to conduct experiments to determine the psychological reality of these phonological patterns (e.g., do signers unconsciously know which patterns are common and which are rare?) and to discover how phonological and lexical properties impact how quickly a sign is recognized (using a novel sign recognition technique) and produced (using a picture-naming task). Data from these experiments and related materials (e.g. picture stimuli) will be made available to the public through ASL-LEX. These materials constitute essential tools that will allow scientists and educators to create well-controlled ASL stimuli for use in research and the classroom. ASL-LEX can also be used by educators and early intervention specialists to develop benchmarks for assessing vocabulary development in signing children, (e.g., do children know the most frequent signs?) and to support literacy development (e.g., to find sign-based "rhymes"). A parallel aim of the project is to increase the representation of deaf people in science by including deaf researchers on the project and by providing an accessible environment for deaf students to gain training and research experience.</AbstractNarration>
<MinAmdLetterDate>08/12/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1625954</AwardID>
<Investigator>
<FirstName>Karen</FirstName>
<LastName>Emmorey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Karen Emmorey</PI_FULL_NAME>
<EmailAddress>kemmorey@mail.sdsu.edu</EmailAddress>
<PI_PHON>6195948080</PI_PHON>
<NSF_ID>000458134</NSF_ID>
<StartDate>08/12/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>San Diego State University Foundation</Name>
<CityName>San Diego</CityName>
<ZipCode>921822190</ZipCode>
<PhoneNumber>6195945731</PhoneNumber>
<StreetAddress>5250 Campanile Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>53</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA53</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073371346</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SAN DIEGO STATE UNIVERSITY FOUNDATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[San Diego State University]]></Name>
<CityName>San Diego</CityName>
<StateCode>CA</StateCode>
<ZipCode>921820001</ZipCode>
<StreetAddress><![CDATA[5500 Campanile Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>53</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA53</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~287454</FUND_OBLG>
<FUND_OBLG>2017~32583</FUND_OBLG>
<FUND_OBLG>2018~12000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual Merit: Almost everything we know about human language comes from the study of spoken languages. However, only by studying sign languages is it possible to discover which linguistic properties are universal to <strong><em>all</em></strong> human languages and which depend on the input (visual or auditory) or output (manual or vocal) mechanisms for language. This project created a large, searchable, and publicly available database of 2,723 signs from American Sign Language (ASL). The database (called ASL-LEX) contains the following information for each sign: subjective frequency-of-use ratings by deaf signers, iconicity ratings (how much a sign looks like what it means) from both deaf signers and hearing non-signers, transparency (&ldquo;guessability&rdquo;) ratings from non-signers, sign duration measures, lexical category information (e.g., noun, verb, etc.), and codes for sign-based phonological features (e.g., location, handshape, movement) that can be used to calculate phonological complexity, as well as whether the form of a sign is relatively common (has many form &lsquo;neighbors&rsquo;) or relatively unique (has very few &lsquo;neighbors&rsquo;). An analysis of this large set of ASL signs revealed that most signs were not considered very iconic, and only a handful (of a subset of 430 signs) could be guessed correctly by non-signers. Most signs had few phonological neighbors and were not complex (parallel to the patterns for spoken words). Correlation analyses revealed that frequent signs were less iconic and phonologically simpler than infrequent signs and iconic signs tended to be phonologically simpler than less iconic signs. The complete ASL-LEX dataset and supplementary materials are available through the Open Science Framework, and an interactive visualization of the entire lexicon can be accessed on the ASL-LEX webpage. Another aim of the study was to use information from ASL-LEX to discover how phonological and lexical properties impact how quickly a sign can be retrieved from memory in a large-scale picture-naming study with deaf signers. Like speakers, signers named object pictures faster and more accurately than action pictures. In addition, iconic signs, frequent signs, and phonologically simple signs were retrieved faster than less iconic, less frequent, or phonologically complex signs. These findings highlight modality-specific effects (e.g., iconicity) and modality-independent effects (e.g., frequency, lexical class, articulatory complexity) on language production.</p> <p>&nbsp;Broader Impacts: Lexical databases (repositories of information about words in a language) have been crucial for testing hypotheses about the structure of the lexicon and the nature of word recognition and production and to making advances in linguistic and psycholinguistic research. ASL-LEX represents the first large-scale lexical database for a signed language that is available to researchers, educators, students, and the general public. The accompanying interactive website, which also includes tutorials in English and ASL, was designed to be accessible and relatively jargon-free, and is intended for multiple uses by a variety of audiences. For example, scientists and educators can use ASL-LEX to create well-controlled stimuli for use in research and the classroom; clinicians and early intervention specialists might utilize it to develop benchmarks for assessing vocabulary development in signing children and to support literacy development (e.g., to find sign-based &ldquo;rhymes&rdquo;). Another broader impact of this project is the training and inclusion of an underrepresented group: individuals with hearing loss. Deafness has a substantial impact on the ability of students to gain access to research careers because of communication roadblocks that hamper interaction with hearing scientists. During this NSF project, the researchers have provided a unique educational environment (all communication occurs in ASL), training by both deaf and hearing researchers, and mentoring for several deaf students who gained research skills and experience that have helped them succeed in entering a Ph.D. program or gain employment in a STEM field.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/27/2020<br>      Modified by: Karen&nbsp;Emmorey</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit: Almost everything we know about human language comes from the study of spoken languages. However, only by studying sign languages is it possible to discover which linguistic properties are universal to all human languages and which depend on the input (visual or auditory) or output (manual or vocal) mechanisms for language. This project created a large, searchable, and publicly available database of 2,723 signs from American Sign Language (ASL). The database (called ASL-LEX) contains the following information for each sign: subjective frequency-of-use ratings by deaf signers, iconicity ratings (how much a sign looks like what it means) from both deaf signers and hearing non-signers, transparency ("guessability") ratings from non-signers, sign duration measures, lexical category information (e.g., noun, verb, etc.), and codes for sign-based phonological features (e.g., location, handshape, movement) that can be used to calculate phonological complexity, as well as whether the form of a sign is relatively common (has many form ‘neighbors’) or relatively unique (has very few ‘neighbors’). An analysis of this large set of ASL signs revealed that most signs were not considered very iconic, and only a handful (of a subset of 430 signs) could be guessed correctly by non-signers. Most signs had few phonological neighbors and were not complex (parallel to the patterns for spoken words). Correlation analyses revealed that frequent signs were less iconic and phonologically simpler than infrequent signs and iconic signs tended to be phonologically simpler than less iconic signs. The complete ASL-LEX dataset and supplementary materials are available through the Open Science Framework, and an interactive visualization of the entire lexicon can be accessed on the ASL-LEX webpage. Another aim of the study was to use information from ASL-LEX to discover how phonological and lexical properties impact how quickly a sign can be retrieved from memory in a large-scale picture-naming study with deaf signers. Like speakers, signers named object pictures faster and more accurately than action pictures. In addition, iconic signs, frequent signs, and phonologically simple signs were retrieved faster than less iconic, less frequent, or phonologically complex signs. These findings highlight modality-specific effects (e.g., iconicity) and modality-independent effects (e.g., frequency, lexical class, articulatory complexity) on language production.   Broader Impacts: Lexical databases (repositories of information about words in a language) have been crucial for testing hypotheses about the structure of the lexicon and the nature of word recognition and production and to making advances in linguistic and psycholinguistic research. ASL-LEX represents the first large-scale lexical database for a signed language that is available to researchers, educators, students, and the general public. The accompanying interactive website, which also includes tutorials in English and ASL, was designed to be accessible and relatively jargon-free, and is intended for multiple uses by a variety of audiences. For example, scientists and educators can use ASL-LEX to create well-controlled stimuli for use in research and the classroom; clinicians and early intervention specialists might utilize it to develop benchmarks for assessing vocabulary development in signing children and to support literacy development (e.g., to find sign-based "rhymes"). Another broader impact of this project is the training and inclusion of an underrepresented group: individuals with hearing loss. Deafness has a substantial impact on the ability of students to gain access to research careers because of communication roadblocks that hamper interaction with hearing scientists. During this NSF project, the researchers have provided a unique educational environment (all communication occurs in ASL), training by both deaf and hearing researchers, and mentoring for several deaf students who gained research skills and experience that have helped them succeed in entering a Ph.D. program or gain employment in a STEM field.          Last Modified: 07/27/2020       Submitted by: Karen Emmorey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
