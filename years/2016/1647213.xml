<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>US Ignite: Focus Area 1: A Networked Virtual Reality Platform for Immersive Online Social Learning of Youth with Autism Spectrum Disorders</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2017</AwardEffectiveDate>
<AwardExpirationDate>01/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>599160.00</AwardTotalIntnAmount>
<AwardAmount>599160</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Deepankar Medhi</SignBlockName>
<PO_EMAI>dmedhi@nsf.gov</PO_EMAI>
<PO_PHON>7032922935</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project explores a high-speed network-enabled, immersive, and smart virtual reality application, called vSocial, to connect children with autism spectrum disorder (ASD) from different geographical regions for online social training.  The 2015 National Health Interview Survey (NHIS) suggests that 1 in 45 children (&gt;2%) have been diagnosed with ASD.  Children with ASD are characterized by impairments in social skills, which can result in low quality of life, bringing emotional, financial, and physical stress and burden on the children, families, schools, and society. This project builds on project team's work during the past five years within which we have successfully developed and evaluated a social competence intervention (SCI) curriculum and a computer-based virtual learning application called iSocial. The iSocial application makes the face-to-face SCI curriculum available online to youth with ASD and public schools, who would otherwise, due to geographical and personal limitations, have no access to such programs provided by experts.&lt;br/&gt;&lt;br/&gt;vSocial will use an immersive Virtual Reality (VR) medium for application delivery over high-speed networking infrastructures at schools as well as cloud technologies available within Global Environment for Network Innovation (GENI) Racks.  Such a transformation will allow us to study how end-to-end network performance tuning needs to be orchestrated across multi-provider paths and how to troubleshoot last-mile network bottlenecks (e.g., at schools or homes) for field-deployment of demanding gigabit applications such as vSocial. Specifically, (a) it will bridge the knowledge generalization gap between online social training and real-world social skills for students with ASD through use of a networked immersive VR system. (b) It will provide smart sensing capabilities for effective monitoring and tracking of the cognitive-affective states of student learners at remote ends for early individualized pedagogical interventions and outcome assessment. Through vSocial application prototype experimentation in the field (at actual schools with teachers and students involvement), this project will investigate the use of cognitive-affective sensing for online social training in education of students with ASD, use of VR glasses, and Unity3D VR content creation platform to assess immersive learning experience.</AbstractNarration>
<MinAmdLetterDate>09/16/2016</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1647213</AwardID>
<Investigator>
<FirstName>Prasad</FirstName>
<LastName>Calyam</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Prasad Calyam</PI_FULL_NAME>
<EmailAddress>calyamp@missouri.edu</EmailAddress>
<PI_PHON>6142705254</PI_PHON>
<NSF_ID>000268773</NSF_ID>
<StartDate>09/16/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zhihai</FirstName>
<LastName>He</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhihai He</PI_FULL_NAME>
<EmailAddress>hezhi@missouri.edu</EmailAddress>
<PI_PHON>5738823495</PI_PHON>
<NSF_ID>000388185</NSF_ID>
<StartDate>09/16/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Janine</FirstName>
<LastName>Stichter</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Janine P Stichter</PI_FULL_NAME>
<EmailAddress>stichterj@missouri.edu</EmailAddress>
<PI_PHON>5738827560</PI_PHON>
<NSF_ID>000296890</NSF_ID>
<StartDate>09/16/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Missouri-Columbia</Name>
<CityName>COLUMBIA</CityName>
<ZipCode>652110001</ZipCode>
<PhoneNumber>5738827560</PhoneNumber>
<StreetAddress>115 Business Loop 70 W</StreetAddress>
<StreetAddress2><![CDATA[Mizzou North, Room 501]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153890272</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Missouri-Columbia]]></Name>
<CityName>Columbia</CityName>
<StateCode>MO</StateCode>
<ZipCode>652110001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2890</Code>
<Text>CISE Research Resources</Text>
</ProgramElement>
<ProgramReference>
<Code>015Z</Code>
<Text>US Ignite</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~599160</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we developed a high-speed network-enabled, immersive, and smart virtual reality application, called vSocial, to connect children with autism spectrum disorder (ASD) from different geographical regions for online social training. We have successfully leveraged a social competence intervention (SCI) curriculum that makes the face-to-face SCI curriculum available online to youth with ASD and public schools, who would otherwise, due to geographical and personal limitations, have no access to such programs provided by experts.</p> <p>Details of the key outcomes of the project are as follows:</p> <p>1) &nbsp;Based on the High-Fidelity platform, we have successfully developed 4 curriculum units, including orientation, group coordination, and facial recognition, for online VR social training of ASD kids.</p> <p>2) We have developed a set of high-speed networking, security, management, computer vision, VR-based human-computer interaction methods and tools to support our online VR training course development. These tools include:</p> <p>(a) devices and deep learning-based algorithms to capture eyes images inside the VR headsets and recognize face expression from faces coved by the VR headsets. For five facial expressions: neutral, happy, angry, disgusting, and surprised, we have achieved an average classification accuracy of 88%;&nbsp;</p> <p>(b) machine learning algorithms and hardware-software interfaces to support natural human-VR interactions, which capture the body pose and motion of the body, and mapping the body pose and gesture into the command and control in &nbsp;the VR worlds, such as walking, running, turning, approve (OK), etc;&nbsp;</p> <p>(c) tools and VR world gadget for student-instruction interactions, such as virtual iPad for students to search browse information, audio ball for students to seek audio message while walking; a strike system for instructors to provide prize or penalty for students; audio attenuation to mimic the audio fading over distance or across walls or walking away.</p> <p>(d) network security methods and tools using a novel risk assessment framework that utilizes attack trees to calculate a risk score for varied VR learning threats with rate and duration of threats as inputs.</p> <p>3) We have conducted 8 usability tests and surveys to obtain feedback about our system user experience and improve the system, as well as the comfort level and cyber sickness of wearing the VR headset.</p> <p>4) The team joined the Pose Challenge competition, developing deep learning methods for accurate human pose estimation, and ranked 4th in the world.</p> <p>The project work received news coverage both at the U. of Missouri College level (https://engineering.missouri.edu/2018/08/mu-researchers-working-on-groundbreaking-vr-classroom) and at the Campus level (https://news.missouri.edu/2018/creating-a-virtual-reality).&nbsp;</p> <p>We have made open various datasets, code and testbed scripts of &ldquo;OnTimeSocial&rdquo;, a Social Network Portal at - https://github.com/mizzou-viman-lab/ontimesocial-sgc. The OnTimeSocial web application can be used by vSocial instructors to keep track of progress of the remote students logging into a VRLE.</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/24/2021<br>      Modified by: Zhihai&nbsp;He</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we developed a high-speed network-enabled, immersive, and smart virtual reality application, called vSocial, to connect children with autism spectrum disorder (ASD) from different geographical regions for online social training. We have successfully leveraged a social competence intervention (SCI) curriculum that makes the face-to-face SCI curriculum available online to youth with ASD and public schools, who would otherwise, due to geographical and personal limitations, have no access to such programs provided by experts.  Details of the key outcomes of the project are as follows:  1)  Based on the High-Fidelity platform, we have successfully developed 4 curriculum units, including orientation, group coordination, and facial recognition, for online VR social training of ASD kids.  2) We have developed a set of high-speed networking, security, management, computer vision, VR-based human-computer interaction methods and tools to support our online VR training course development. These tools include:  (a) devices and deep learning-based algorithms to capture eyes images inside the VR headsets and recognize face expression from faces coved by the VR headsets. For five facial expressions: neutral, happy, angry, disgusting, and surprised, we have achieved an average classification accuracy of 88%;   (b) machine learning algorithms and hardware-software interfaces to support natural human-VR interactions, which capture the body pose and motion of the body, and mapping the body pose and gesture into the command and control in  the VR worlds, such as walking, running, turning, approve (OK), etc;   (c) tools and VR world gadget for student-instruction interactions, such as virtual iPad for students to search browse information, audio ball for students to seek audio message while walking; a strike system for instructors to provide prize or penalty for students; audio attenuation to mimic the audio fading over distance or across walls or walking away.  (d) network security methods and tools using a novel risk assessment framework that utilizes attack trees to calculate a risk score for varied VR learning threats with rate and duration of threats as inputs.  3) We have conducted 8 usability tests and surveys to obtain feedback about our system user experience and improve the system, as well as the comfort level and cyber sickness of wearing the VR headset.  4) The team joined the Pose Challenge competition, developing deep learning methods for accurate human pose estimation, and ranked 4th in the world.  The project work received news coverage both at the U. of Missouri College level (https://engineering.missouri.edu/2018/08/mu-researchers-working-on-groundbreaking-vr-classroom) and at the Campus level (https://news.missouri.edu/2018/creating-a-virtual-reality).   We have made open various datasets, code and testbed scripts of "OnTimeSocial", a Social Network Portal at - https://github.com/mizzou-viman-lab/ontimesocial-sgc. The OnTimeSocial web application can be used by vSocial instructors to keep track of progress of the remote students logging into a VRLE.          Last Modified: 03/24/2021       Submitted by: Zhihai He]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
