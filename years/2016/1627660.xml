<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Three Projects in Econometric Theory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>199260.00</AwardTotalIntnAmount>
<AwardAmount>199260</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nancy Lutz</SignBlockName>
<PO_EMAI>nlutz@nsf.gov</PO_EMAI>
<PO_PHON>7032927280</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Most empirical methods in economics and the social sciences derive their validity from the thought experiment on how they would perform in very large samples. The implicit hope is that ensuring good performance in large samples leads to acceptable performance in moderately small data sets as well. For some inference problems, however, it is known that the standard large sample approximation is too inaccurate to be a reliable guide for the sample sized typically encountered in empirical work. As a constructive remedy, it is sometimes possible to embed the original problem in an alternative large sample approximation that better captures the small sample features. This project aims at developing such alternative large sample approximations in three empirically relevant econometric problems: How to conduct inference with persistent time series; how to account for the presence of a large number of control variates in a linear regression; and how to conduct inference about the probability and properties of extreme events. &lt;br/&gt;&lt;br/&gt;Recent advances in econometric theory often consider sequences of parameter or tuning parameter values that lead to a different form of large sample approximations. Prominent examples include weak instrument asymptotics, local-to-unity time series asymptotics where the largest autoregressive root takes on values ever closer to one, and heteroskedasticity and autocorrelations robust inference with a bandwidth equal to a fixed fraction of the sample size. This research develops similar alternative asymptotics in three distinct inference problems: The first project generalizes the local-to-unity model by letting p autoregressive roots, as well as p-1 MA roots, converge to unity at the appropriate rate. The second project studies inference about a linear regression coefficient in the presence of a large number of potential controls, where the control coefficients are known to satisfy a particular L_2 bound that can be interpreted as a bound on the R^2 in a regression of the outcome on the controls. The third project concerns the problem of inference about tail properties based on an i.i.d. sample, under the sole assumption that extreme value theory to hold for the largest k observations, for a given and fixed k.</AbstractNarration>
<MinAmdLetterDate>07/13/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/13/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1627660</AwardID>
<Investigator>
<FirstName>Ulrich</FirstName>
<LastName>Mueller</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ulrich K Mueller</PI_FULL_NAME>
<EmailAddress>umueller@princeton.edu</EmailAddress>
<PI_PHON>6092584026</PI_PHON>
<NSF_ID>000488827</NSF_ID>
<StartDate>07/13/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Department of Economics]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085441045</ZipCode>
<StreetAddress><![CDATA[Fisher Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1320</Code>
<Text>Economics</Text>
</ProgramElement>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramReference>
<Code>1320</Code>
<Text>ECONOMICS</Text>
</ProgramReference>
<ProgramReference>
<Code>1333</Code>
<Text>METHOD, MEASURE &amp; STATS</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~199260</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Most empirical methods in economics and the social sciences derive their validity from the thought experiment how they would perform in very large samples. The implicit hope is that ensuring good performance in large samples leads to acceptable performance also in moderately small data sets. For some inference problems, however, it is known that the &ldquo;standard&rdquo; large sample approximation is too inaccurate to be a reliable guide for the sample sized typically encountered in empirical work. As a constructive remedy, it is sometimes possible to embed the original problem in an alternative large sample approximation that better captures the small sample features. This grant has developed such alternative embeddings in three empirically relevant econometric problems: How to conduct inference with persistent time series; how to account for the presence of a large number of control variates in a linear regression; and how to conduct inference about the probability and properties of extreme events. This alternative embedding led to the development of new inference methods, which more reliably allow to learn from data in small samples. As such, the research sponsored in this grant has provided the econometric community with novel and constructive ways of thinking about standard problems, and also added directly to the toolkit of applied researchers in the social sciences.</p><br> <p>            Last Modified: 09/13/2019<br>      Modified by: Ulrich&nbsp;K&nbsp;Mueller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Most empirical methods in economics and the social sciences derive their validity from the thought experiment how they would perform in very large samples. The implicit hope is that ensuring good performance in large samples leads to acceptable performance also in moderately small data sets. For some inference problems, however, it is known that the "standard" large sample approximation is too inaccurate to be a reliable guide for the sample sized typically encountered in empirical work. As a constructive remedy, it is sometimes possible to embed the original problem in an alternative large sample approximation that better captures the small sample features. This grant has developed such alternative embeddings in three empirically relevant econometric problems: How to conduct inference with persistent time series; how to account for the presence of a large number of control variates in a linear regression; and how to conduct inference about the probability and properties of extreme events. This alternative embedding led to the development of new inference methods, which more reliably allow to learn from data in small samples. As such, the research sponsored in this grant has provided the econometric community with novel and constructive ways of thinking about standard problems, and also added directly to the toolkit of applied researchers in the social sciences.       Last Modified: 09/13/2019       Submitted by: Ulrich K Mueller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
