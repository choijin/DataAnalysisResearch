<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: Understanding Computational Thinking Process and Practices in Open-Ended Programming Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>549882.00</AwardTotalIntnAmount>
<AwardAmount>608024</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Russell</SignBlockName>
<PO_EMAI>rlrussel@nsf.gov</PO_EMAI>
<PO_PHON>7032922995</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. This project brings together two approaches to help K-12 students learn programming and computer science: open-ended learning environments, and computer-based learning analytics, to help create a setting where youth can get help and scaffolding tailored to what they know about programming without having to take tests or participate in rigid textbook exercises for the system to know what they know. &lt;br/&gt;&lt;br/&gt;The project proposes to use techniques from educational data mining and learning analytics to process student data in the Alice programming environment. Building on the assessment design model of Evidence-Centered Design, student log data will be used to construct a model of individual students' computational thinking practices, aligned with emerging standards including NGSS and research on assessment of computational thinking. Initially, the system will be developed based on an existing corpus of pair-programming log data from approximately 600 students, triangulating with manually-coded performance assessments of programming through game design exercises. In the second phase of the work, curricula and professional development will be created to allow the system to be tested with underrepresented girls at Stanford's CS summer workshops and with students from diverse high schools implementing the Exploring Computer Science curriculum. Direct observation and interviews will be used to improve the model. Research will address how learners enact computational thinking practices in building computational artifacts, what patters of behavior serve as evidence of learning CT practices, and how to better design constructionist programming environments so that personalized learner scaffolding can be provided. By aligning with a popular programming environment (Alice) and a widely-used computer science curriculum (Exploring Computer Science), the project can have broad impact on computer science education; software developed will be released under a BSD-style license so others can build on it.</AbstractNarration>
<MinAmdLetterDate>08/25/2015</MinAmdLetterDate>
<MaxAmdLetterDate>10/23/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1522990</AwardID>
<Investigator>
<FirstName>Marie</FirstName>
<LastName>Bienkowski</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marie A Bienkowski</PI_FULL_NAME>
<EmailAddress>marie.bienkowski@sri.com</EmailAddress>
<PI_PHON>6508595485</PI_PHON>
<NSF_ID>000329037</NSF_ID>
<StartDate>10/11/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marie</FirstName>
<LastName>Bienkowski</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marie A Bienkowski</PI_FULL_NAME>
<EmailAddress>marie.bienkowski@sri.com</EmailAddress>
<PI_PHON>6508595485</PI_PHON>
<NSF_ID>000329037</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate>10/11/2017</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>John</FirstName>
<LastName>Stamper</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John Stamper</PI_FULL_NAME>
<EmailAddress>jstamper@cs.cmu.edu</EmailAddress>
<PI_PHON>4122689690</PI_PHON>
<NSF_ID>000591821</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Shuchi</FirstName>
<LastName>Grover</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shuchi Grover</PI_FULL_NAME>
<EmailAddress>shuchi.grover@gmail.com</EmailAddress>
<PI_PHON>6175496586</PI_PHON>
<NSF_ID>000688029</NSF_ID>
<StartDate>10/23/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Shuchi</FirstName>
<LastName>Grover</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shuchi Grover</PI_FULL_NAME>
<EmailAddress>shuchi.grover@gmail.com</EmailAddress>
<PI_PHON>6175496586</PI_PHON>
<NSF_ID>000688029</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate>10/11/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SRI International</Name>
<CityName>Menlo Park</CityName>
<ZipCode>940253493</ZipCode>
<PhoneNumber>7032478529</PhoneNumber>
<StreetAddress>333 RAVENSWOOD AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009232752</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SRI INTERNATIONAL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009232752</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SRI International]]></Name>
<CityName>Menlo Park</CityName>
<StateCode>CA</StateCode>
<ZipCode>940253493</ZipCode>
<StreetAddress><![CDATA[333 Ravenswood Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>005Y</Code>
<Text>STEM + Computing (STEM+C) Part</Text>
</ProgramElement>
<ProgramElement>
<Code>7298</Code>
<Text>International Research Collab</Text>
</ProgramElement>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>5905</Code>
<Text>ISRAEL</Text>
</ProgramReference>
<ProgramReference>
<Code>5946</Code>
<Text>UNITED KINGDOM</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8244</Code>
<Text>EHR CL Opportunities (NSF 14-302)</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0415</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~549882</FUND_OBLG>
<FUND_OBLG>2016~58142</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The  Understanding Computational Thinking Process and Practices in  Open-Ended Programming Environments project studied computer science  (CS)&nbsp;in K-12 classrooms and specifically programming, a key part  of CS curricula. In these curricula, open-ended block-based programming  environments (BBPEs) such as Alice and Scratch are commonly used. These  environments lack supports to help learners who are new to programming.  This project made progress toward environments that can provide  formative supports and give feedback to students and teachers about  students' programming process.&nbsp;</p> <p dir="ltr"><span>To provide help  for learners, we first need to understand students' programming process: how do learners apply computational thinking  (CT) practices as they build programs in BBPEs? In order to understand  programming process well, we need to capture and interpret "big data"  (log data) that tracks actions in the environment. This task is  especially difficult to automate when students are given open-ended  programming tasks, such as "build a game," that do not have a clear end  state. Thus, the main goal of this exploratory research, a collaboration  between SRI International (lead), Carnegie Mellon University, and  Looking Glass Ventures LLC, was to understand this process, and more  specifically, identify viable and effective ways to capture, store, and  interpret log data, and to discern patterns or "anti-patterns" of  actions that can be interpreted as CT practices or misconceptions  thereof.&nbsp;</span></p> <p dir="ltr"><span>The project first examined  programming log data and graded student work on the "Fairy Assessment"  from a prior NSF project (DRL-0909733). This data was used to (a) create  new ways to transform the raw data into representations and  visualizations of code state, (b) develop a prototype teacher dashboard  for showing student progress, (c) build computational models of student  behavior to explore data-driven assessment and peer-tutoring, and (d)  understand (through 'sequence mining') the nature and relevance of  frequency of testing/debugging and other indicators with respect to  student learning.</span></p> <p dir="ltr"><span>The project's work also  involved development of both new programming tasks for high school  students and software to capture and interpret log data from the Alice  programming environment. The tasks were designed to measure student's  understanding of programming by adapting SRI's prior work on "design  patterns" of CT practices created using Evidence-Centered Design, thus  demonstrating their reusability in multiple measurement domains,  including computational data analytics. A multidisciplinary team of  educational researchers, high school CS teachers, and computer  scientists co-designed three programming tasks and instrumented the  Alice programming environment to collect data on student actions. The  programming tasks were tested in 'Exploring Computer Science' classrooms  that used the Alice programming language: three teachers and over 150  students used the three programming tasks. The final anonymized dataset  logged included 16GB of 363,522 individual Alice transactions accounting  for around 1584 hours of programming from ~100 students. These were  cleaned and stored (using new storage formats) in DataShop@CMU (an open  repository for research). It is the first such dataset from an  open-ended BBPE.</span></p> <p dir="ltr"><span>The data collected (log  data in various formats, Alice program snapshots, test scores, student  interviews, and screen capture recordings) was analyzed in the final two  years of the project using mixed-methods and manual methods as well as  computational analyses. Our analyses demonstrated the difficulties  students face during programming, the nature of help they would have  liked, and incorrect patterns of actions ("anti-patterns") that can  trigger environmental supports.&nbsp; Additionally, analyses demonstrated  that computational models built using data from one task were able to  predict grades for another task.&nbsp;</span></p> <p dir="ltr"><span>The  project developed a novel framework for learning analytics research: a  blend of "top-down" hypothesis-driven analyses of programming tasks with  "bottom-up" data-driven analyses of data logs from the programming  environment as students work on those tasks. The project created  generalizable guidelines for logging and parsing data in various formats  from open-ended BBPEs and created models for storing and sharing  anonymized data from such environments. This was significant because standards did not exist for sharing this type of programming log data and  associated tools in ways that analytics techniques can leverage. We  showed that we could use computational methods to create and  predict scores for rubrics that were similar to those that educators  created for introductory CS activities. In addition to a shareable  dataset, project findings have been actively disseminated to the  research community through 12 papers, posters, and workshops at AERA,  LAK, ICLS, EDM conferences, as well as a journal article and book  chapter on the blended analytics framework.</span></p> <p dir="ltr"><span>This  exploratory project helped build the foundation for future work to  develop intelligent open-ended programming environments  powered by analytics. Our work helps achieve a balance between the  open-ended nature of student work with guidance for a process- and  practices-focused approach to learning of CT during programming  in K-12 classrooms. The results of this work contribute to the field of  automated measurement and assessment of CT by helping us make sense of  the evidence collected in block-based programming environments.</span></p><br> <p>            Last Modified: 06/28/2019<br>      Modified by: Marie&nbsp;A&nbsp;Bienkowski</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The  Understanding Computational Thinking Process and Practices in  Open-Ended Programming Environments project studied computer science  (CS) in K-12 classrooms and specifically programming, a key part  of CS curricula. In these curricula, open-ended block-based programming  environments (BBPEs) such as Alice and Scratch are commonly used. These  environments lack supports to help learners who are new to programming.  This project made progress toward environments that can provide  formative supports and give feedback to students and teachers about  students' programming process.  To provide help  for learners, we first need to understand students' programming process: how do learners apply computational thinking  (CT) practices as they build programs in BBPEs? In order to understand  programming process well, we need to capture and interpret "big data"  (log data) that tracks actions in the environment. This task is  especially difficult to automate when students are given open-ended  programming tasks, such as "build a game," that do not have a clear end  state. Thus, the main goal of this exploratory research, a collaboration  between SRI International (lead), Carnegie Mellon University, and  Looking Glass Ventures LLC, was to understand this process, and more  specifically, identify viable and effective ways to capture, store, and  interpret log data, and to discern patterns or "anti-patterns" of  actions that can be interpreted as CT practices or misconceptions  thereof.  The project first examined  programming log data and graded student work on the "Fairy Assessment"  from a prior NSF project (DRL-0909733). This data was used to (a) create  new ways to transform the raw data into representations and  visualizations of code state, (b) develop a prototype teacher dashboard  for showing student progress, (c) build computational models of student  behavior to explore data-driven assessment and peer-tutoring, and (d)  understand (through 'sequence mining') the nature and relevance of  frequency of testing/debugging and other indicators with respect to  student learning. The project's work also  involved development of both new programming tasks for high school  students and software to capture and interpret log data from the Alice  programming environment. The tasks were designed to measure student's  understanding of programming by adapting SRI's prior work on "design  patterns" of CT practices created using Evidence-Centered Design, thus  demonstrating their reusability in multiple measurement domains,  including computational data analytics. A multidisciplinary team of  educational researchers, high school CS teachers, and computer  scientists co-designed three programming tasks and instrumented the  Alice programming environment to collect data on student actions. The  programming tasks were tested in 'Exploring Computer Science' classrooms  that used the Alice programming language: three teachers and over 150  students used the three programming tasks. The final anonymized dataset  logged included 16GB of 363,522 individual Alice transactions accounting  for around 1584 hours of programming from ~100 students. These were  cleaned and stored (using new storage formats) in DataShop@CMU (an open  repository for research). It is the first such dataset from an  open-ended BBPE. The data collected (log  data in various formats, Alice program snapshots, test scores, student  interviews, and screen capture recordings) was analyzed in the final two  years of the project using mixed-methods and manual methods as well as  computational analyses. Our analyses demonstrated the difficulties  students face during programming, the nature of help they would have  liked, and incorrect patterns of actions ("anti-patterns") that can  trigger environmental supports.  Additionally, analyses demonstrated  that computational models built using data from one task were able to  predict grades for another task.  The  project developed a novel framework for learning analytics research: a  blend of "top-down" hypothesis-driven analyses of programming tasks with  "bottom-up" data-driven analyses of data logs from the programming  environment as students work on those tasks. The project created  generalizable guidelines for logging and parsing data in various formats  from open-ended BBPEs and created models for storing and sharing  anonymized data from such environments. This was significant because standards did not exist for sharing this type of programming log data and  associated tools in ways that analytics techniques can leverage. We  showed that we could use computational methods to create and  predict scores for rubrics that were similar to those that educators  created for introductory CS activities. In addition to a shareable  dataset, project findings have been actively disseminated to the  research community through 12 papers, posters, and workshops at AERA,  LAK, ICLS, EDM conferences, as well as a journal article and book  chapter on the blended analytics framework. This  exploratory project helped build the foundation for future work to  develop intelligent open-ended programming environments  powered by analytics. Our work helps achieve a balance between the  open-ended nature of student work with guidance for a process- and  practices-focused approach to learning of CT during programming  in K-12 classrooms. The results of this work contribute to the field of  automated measurement and assessment of CT by helping us make sense of  the evidence collected in block-based programming environments.       Last Modified: 06/28/2019       Submitted by: Marie A Bienkowski]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
