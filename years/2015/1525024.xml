<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF:  Small: Efficient Algorithms for Querying Noisy Distributed/Streaming Datasets</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2015</AwardEffectiveDate>
<AwardExpirationDate>05/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>444320.00</AwardTotalIntnAmount>
<AwardAmount>444320</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to study the design of efficient query algorithms for noisy datasets in distributed and streaming applications.  Noisy data is universal in today's world. Imprecise and varying references to the same real-world entities are ubiquitous in scientific and commercial databases.  This noise poses significant obstructions to accurate data analytics.  As an example of "noisy data," consider YouTube videos. YouTube tracks the views of individual videos. However, there are frequently many similar versions of the same event and answering a basic question such as "How many people viewed this event?" is challenging using current techniques.  This project will provide new techniques and insights to combat the noisy nature of large datasets, and hence will enhance our ability to process the ever-increasing quantity of business and scientific data. The products of this project will be integrated into a trilogy of graduate and undergraduate courses on algorithms, databases, and data mining. The PI will disseminate research outcomes by giving talks at conferences/workshops, universities, industrial labs, as well as online media.&lt;br/&gt;&lt;br/&gt;More technically, this project tries to answer the following question: can we run distributed and streaming algorithms directly on the noisy datasets, resolve the noise "on the fly", and retain communication and space efficiency compared with the noise-free setting?  The PI plans to study statistical, relational and graph problems.  This project has the potential to impact a wide range of active research areas in theoretical computer science, including distributed and streaming algorithms, group testing, compressed sensing, communication complexity, clustering, and locality sensitive hashing.</AbstractNarration>
<MinAmdLetterDate>06/11/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1525024</AwardID>
<Investigator>
<FirstName>Qin</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qin Zhang</PI_FULL_NAME>
<EmailAddress>qzhangcs@indiana.edu</EmailAddress>
<PI_PHON>8128552567</PI_PHON>
<NSF_ID>000662627</NSF_ID>
<StartDate>06/11/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474057104</ZipCode>
<StreetAddress><![CDATA[150 S. Woodlawn Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7934</Code>
<Text>PARAL/DISTRIBUTED ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~444320</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project explores the design of efficient algorithms for real world datasets that are massive and noisy.&nbsp; Noisy data is universal in the big data era; same real world entities may appear in different forms in different data sources, which poses significant obstructions to accurate data analytics.&nbsp; Motivated by the fact that a comprehensive data cleaning step is infeasible on distributed and streaming models (the standard big data models), this project aims to design distributed and streaming algorithms that run directly on the noisy datasets, resolve the noise "on the fly", and retain communication and space efficiency compared with the noise-free setting.</p> <p>Major results of this project include: (1) The first set of communication-efficient solutions for fundamental statistical problems on distributed noisy datasets, including algorithms for distinct elements, L0-sampling, heavy hitters, frequency moments, and empirical entropy.&nbsp; (2) A novel noise-resilient algorithmic framework for the distinct elements problem in the streaming model; the framework builds connections to the rich theory of locality-sensitive hashing (LSH), and applies to a number of metric spaces.&nbsp; (3) The first sublinear-size sketch for threshold edit distance (a metric that does not admit efficient LSH); the sketch can also be computed in the streaming model. This result answers a major open problem on data sketching, and can be used for edit similarity joins whose goal is to find all near-duplicates under edit distance.&nbsp; (4) The first set of algorithms for distinct sampling on noisy streaming data.&nbsp; (5) A novel algorithmic framework for communication-efficient distributed clustering.</p> <p>As a byproduct, the algorithms developed for edit similarity joins find applications in bioinformatics, in particular, in detecting overlapping pairs of error-prone reads produced by single molecule real time sequencing (SMRT), which is the first and most critical step of the de novo fragment assembly of SMRT reads.</p> <p>The results in this project have been disseminated to the science disciplines and community at large through publications, open source libraries, and presentations. A number of undergraduate and graduate students were supported by this project, and participated in various research activities related to the project in the form of research assistants, summer interns, and research-focused workshops.&nbsp; One Ph.D. student has defended his thesis with a topic closely related to this project.&nbsp; Research results in this project have been integrated into a trilogy of graduate and undergraduate courses on algorithms, databases, and data mining.&nbsp; All publications, posters, presentations and code libraries are available at the project website: http://homes.sice.indiana.edu/qzhangcs/robust.html</p><br> <p>            Last Modified: 06/04/2019<br>      Modified by: Qin&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project explores the design of efficient algorithms for real world datasets that are massive and noisy.  Noisy data is universal in the big data era; same real world entities may appear in different forms in different data sources, which poses significant obstructions to accurate data analytics.  Motivated by the fact that a comprehensive data cleaning step is infeasible on distributed and streaming models (the standard big data models), this project aims to design distributed and streaming algorithms that run directly on the noisy datasets, resolve the noise "on the fly", and retain communication and space efficiency compared with the noise-free setting.  Major results of this project include: (1) The first set of communication-efficient solutions for fundamental statistical problems on distributed noisy datasets, including algorithms for distinct elements, L0-sampling, heavy hitters, frequency moments, and empirical entropy.  (2) A novel noise-resilient algorithmic framework for the distinct elements problem in the streaming model; the framework builds connections to the rich theory of locality-sensitive hashing (LSH), and applies to a number of metric spaces.  (3) The first sublinear-size sketch for threshold edit distance (a metric that does not admit efficient LSH); the sketch can also be computed in the streaming model. This result answers a major open problem on data sketching, and can be used for edit similarity joins whose goal is to find all near-duplicates under edit distance.  (4) The first set of algorithms for distinct sampling on noisy streaming data.  (5) A novel algorithmic framework for communication-efficient distributed clustering.  As a byproduct, the algorithms developed for edit similarity joins find applications in bioinformatics, in particular, in detecting overlapping pairs of error-prone reads produced by single molecule real time sequencing (SMRT), which is the first and most critical step of the de novo fragment assembly of SMRT reads.  The results in this project have been disseminated to the science disciplines and community at large through publications, open source libraries, and presentations. A number of undergraduate and graduate students were supported by this project, and participated in various research activities related to the project in the form of research assistants, summer interns, and research-focused workshops.  One Ph.D. student has defended his thesis with a topic closely related to this project.  Research results in this project have been integrated into a trilogy of graduate and undergraduate courses on algorithms, databases, and data mining.  All publications, posters, presentations and code libraries are available at the project website: http://homes.sice.indiana.edu/qzhangcs/robust.html       Last Modified: 06/04/2019       Submitted by: Qin Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
