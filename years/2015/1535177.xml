<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  Personalized Benchmarks for High Performance Computing Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>309000.00</AwardTotalIntnAmount>
<AwardAmount>330000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Edward Walker</SignBlockName>
<PO_EMAI>edwalker@nsf.gov</PO_EMAI>
<PO_PHON>7032924863</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As high-performance computing applications target ever-larger problems, data input and output (I/O) takes up more and more run time. Users, software developers, and platform administrators often find it difficult to understand what an application's I/O code is doing, why it is slow, how it might be improved, or how well it would perform on a different platform. I/O benchmarks help address this problem, but they are expensive to produce and thus are not available for most applications. This project is providing user-friendly personalized I/O benchmarks for all applications, by leveraging existing lightweight I/O profilers that already monitor the behavior of applications on high-performance computing platforms. The resulting personalized benchmarks will help researchers, developers, and purchasers in evaluating potential new storage system architectures, evaluating existing or new versions of storage systems and I/O libraries, planning for purchases, comparing performance of application clusters or workloads across platforms, and improving the performance of parallel I/O libraries and applications. The analytics and benchmark generation software, and example benchmarks, will be publicly released.&lt;br/&gt; &lt;br/&gt;This project uses two methods to construct personalized I/O benchmarks. First, the project is making existing applications self-benchmarking across all of their runs, by providing analytics and visualization facilities to convey to stakeholders the information already automatically captured by lightweight I/O profilers such as Darshan during each run. Second, the project is creating platform-customized benchmark suites that represent the mix of application-level workloads observed on a given platform. To accomplish this, the project is clustering observed production jobs based on their I/O behavior and using both new and existing I/O kernel generation techniques to generate a compact benchmark for each cluster. The resulting benchmark suite will advance the state of the art by serving as a proxy for real-world, platform-specific production I/O workloads, and by providing previously unavailable insight into how prevalent those workloads are at a given facility.</AbstractNarration>
<MinAmdLetterDate>08/14/2015</MinAmdLetterDate>
<MaxAmdLetterDate>11/06/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1535177</AwardID>
<Investigator>
<FirstName>Marianne</FirstName>
<LastName>Winslett</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marianne Winslett</PI_FULL_NAME>
<EmailAddress>winslett@illinois.edu</EmailAddress>
<PI_PHON>2173333536</PI_PHON>
<NSF_ID>000443748</NSF_ID>
<StartDate>08/14/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7684</Code>
<Text>CESER-Cyberinfrastructure for</Text>
</ProgramElement>
<ProgramReference>
<Code>7684</Code>
<Text>STRATEGIC TECHNOLOGIES FOR CI</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~309000</FUND_OBLG>
<FUND_OBLG>2016~21000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Parallel I/O is a common performance bottleneck for applications that  run on supercomputers.&nbsp; To help in understanding parallel I/O behavior,  the lightweight Darshan profiler captures both a coarse-grained and  fine-grained picture of the I/O behavior of jobs.&nbsp; Darshan profiling is  enabled by default on many major US supercomputers, and has proved to be  very helpful for providing platform-level situational awareness and  application-level data to help identify and resolve performance  bottlenecks.&nbsp; However, due to its volume and complexity, Darshan data is  not always easy to use in parallel I/O research.</p> <p>This project addressed that problem by building an easily queryable  SQL database that contains the data from profiling all Darshan-enabled  jobs on the Blue Waters supercomputer from 2014 to 2019.&nbsp; The tens of  millions of jobs in the database are a valuable resource for researchers  studying benchmarking issues or any other aspect of parallel I/O.</p> <p>The project also used profiling to evaluate the overhead of  collective I/O operations, and designed and evaluated ways to greatly  reduce the communication overhead of the most common types of collective  I/O calls, including write calls for 2D arrays made of non-overlapping  2D tiles.&nbsp; The project also proposed new ways of using machine learning  to select representative jobs and applications, to serve as parallel I/O  benchmarks.</p><br> <p>            Last Modified: 07/11/2020<br>      Modified by: Marianne&nbsp;Winslett</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Parallel I/O is a common performance bottleneck for applications that  run on supercomputers.  To help in understanding parallel I/O behavior,  the lightweight Darshan profiler captures both a coarse-grained and  fine-grained picture of the I/O behavior of jobs.  Darshan profiling is  enabled by default on many major US supercomputers, and has proved to be  very helpful for providing platform-level situational awareness and  application-level data to help identify and resolve performance  bottlenecks.  However, due to its volume and complexity, Darshan data is  not always easy to use in parallel I/O research.  This project addressed that problem by building an easily queryable  SQL database that contains the data from profiling all Darshan-enabled  jobs on the Blue Waters supercomputer from 2014 to 2019.  The tens of  millions of jobs in the database are a valuable resource for researchers  studying benchmarking issues or any other aspect of parallel I/O.  The project also used profiling to evaluate the overhead of  collective I/O operations, and designed and evaluated ways to greatly  reduce the communication overhead of the most common types of collective  I/O calls, including write calls for 2D arrays made of non-overlapping  2D tiles.  The project also proposed new ways of using machine learning  to select representative jobs and applications, to serve as parallel I/O  benchmarks.       Last Modified: 07/11/2020       Submitted by: Marianne Winslett]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
