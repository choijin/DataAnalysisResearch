<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CSR: Pervasive Gesture Recognition Using Ambient Light</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2016</AwardEffectiveDate>
<AwardExpirationDate>04/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>174878.00</AwardTotalIntnAmount>
<AwardAmount>174878</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As computing devices are becoming smaller, smarter, and more ubiquitous, computing has started to embed into our environment in various forms such as intelligent thermostats, smart appliances, remotely controllable household equipment, and weather based automated lawn irrigation systems. Consequently, we need new ways to seamlessly and effectively communicate and interact with such ubiquitous and always-available computing devices. A natural choice for such communication and interaction is human gestures because gestures are an integral part of the way humans communicate and interact with each other in their daily lives. This project aims at using ambient light and cheap commercial off-the-shelf light sensors to develop a gesture recognition system. The intuition behind this approach is that as a user performs a gesture in a room that is lit with light, the amount of light that he/she reflects and blocks changes, resulting in changes in the intensity of light in all parts of the room. The patterns of change in the intensity of light are different for different gestures, which can be learnt and used to recognize the gestures.&lt;br/&gt;&lt;br/&gt;In developing the ambient light based gesture recognition system, this project has two primary objectives: (1) environment independence, i.e., making the system agnostic to the characteristics of the environment, such as different lighting conditions, and (2) user independence, i.e., making the system agnostic to the number of users in a room and their routine activities. Several challenges arise in developing the ambient light based gesture recognition system, such as automatically detecting the start and end of a gesture, removing noise from the time-series of sensor values, handling the varying time durations of the different occurrences of the same gesture, simultaneously recognizing the gestures of multiple people, and recognizing the gestures of non-stationary users. This project will not only address these and other similar challenges, but will also advance the knowledge and understanding of the use of ambient light for novel systems by yielding a theoretical foundation for modeling human gestures and routine activities using changes in the intensity of light.&lt;br/&gt;&lt;br/&gt;The successful completion of this project will greatly benefit our society. First, this project will make the data set collected during this project publicly available for research. Second, the proposed ambient light based gesture recognition system will introduce a new and convenient way for users to interact with the computing embedded in their environments. Third, the proposed project will bridge several different communities such as systems, signal processing, machine learning, mobile computing, and human computer interaction; and foster interaction and communication among them. Fourth, the educational side of the project will integrate the research findings into the undergraduate and graduate curricula at North Carolina State University.</AbstractNarration>
<MinAmdLetterDate>03/18/2016</MinAmdLetterDate>
<MaxAmdLetterDate>03/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1565609</AwardID>
<Investigator>
<FirstName>Muhammad</FirstName>
<LastName>Shahzad</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Muhammad Shahzad</PI_FULL_NAME>
<EmailAddress>mshahza@ncsu.edu</EmailAddress>
<PI_PHON>9195158766</PI_PHON>
<NSF_ID>000702062</NSF_ID>
<StartDate>03/18/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276958206</ZipCode>
<StreetAddress><![CDATA[890 Oval Drive, Campus Box 8206]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~174878</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>As the computing devices are becoming smaller, smarter, and more ubiquitous, computing has started to embed into our environment in various forms such as intelligent thermostats, smart appliances, remotely controllable household equipment, and weather based automated lawn irrigation systems. Consequently, we need new ways to seamlessly and effectively communicate and interact with such ubiquitous and always-available computing devices. A natural choice for such communication and interaction is human gestures because gestures are an integral part of the way humans communicate and interact with each other in their daily lives. The overarching goal of this project is to use ambient light along with cheap commercial off-the-shelf light sensors to recognize human gestures.</p> <p><br />The work conducted during this project has significantly advanced our understanding of how various human movements manifest in our shadows in multi-light-source environments and what are the impacts of the changes in the 1) positions of light sources, 2) intensity of light sources, 3) number of light sources, and 4) position and orientation of users. This knowledge has been successfully applied to develop ambient light-based gesture recognition systems. The project has also resulted in developing our understanding of the impact of human movements on ambient infrared light. The PI and has team has leveraged this understanding to enable gesture recognition in unlit environments using passive infrared sensors. The research conducted during this project has also made significant contributions in understanding the impact of human motion on wireless signals, another ambient modality prevalent almost ubiquitously around us. In that direction, the project has resulted in several single and multi-user gesture recognition systems that leverage the distinctness of variations introduced by different human movements to WiFi signals to recognize human gestures.&nbsp;</p> <p>The research results from this project have been published in top tier computer science conferences and journals, including MobiSys, UbiComp/IMWUT, IEEE Transactions on Mobile Computing, and IEEE Journal on Selected Areas in Communications. The key concepts, methods, and algorithms that the PI and his team has developed will potentially motivate more research work from the community in the area of ambient light based computing and sensing. The methods that the PI and his team have developed for removing the effects of changes in the user's position and orientation, and intensity, number, and position of light sources from the time-series of light sensor values will free the research community from dwelling on the task of handling such changes and enable the community to focus on other tasks such as improving the accuracy and handling practical issues that deteriorate this accuracy.&nbsp;</p> <p><br />Through this project, the students have learnt how to build real world sensing systems, acquire data from such sensing systems, manage that data, and analyze it. The students have also learnt skills to develop and use machine-learning techniques for real world sensing systems. These hand-on system building skills along with the knowledge of developing and applying machine learning techniques for such sensing systems will be very helpful to the students when they pursue careers in academia, national laboratories, industry, and other research setups after their graduation. This, in turn, will contribute towards building a skilled workforce for the nation. The PI has also incorporated several modules and course projects based on this project into the undergraduate course, CSC 453: Introduction to IoT Systems, and the graduate course, CSC 591: Internet of Things - Applications &amp; Implementation.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/18/2020<br>      Modified by: Muhammad&nbsp;Shahzad</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ As the computing devices are becoming smaller, smarter, and more ubiquitous, computing has started to embed into our environment in various forms such as intelligent thermostats, smart appliances, remotely controllable household equipment, and weather based automated lawn irrigation systems. Consequently, we need new ways to seamlessly and effectively communicate and interact with such ubiquitous and always-available computing devices. A natural choice for such communication and interaction is human gestures because gestures are an integral part of the way humans communicate and interact with each other in their daily lives. The overarching goal of this project is to use ambient light along with cheap commercial off-the-shelf light sensors to recognize human gestures.   The work conducted during this project has significantly advanced our understanding of how various human movements manifest in our shadows in multi-light-source environments and what are the impacts of the changes in the 1) positions of light sources, 2) intensity of light sources, 3) number of light sources, and 4) position and orientation of users. This knowledge has been successfully applied to develop ambient light-based gesture recognition systems. The project has also resulted in developing our understanding of the impact of human movements on ambient infrared light. The PI and has team has leveraged this understanding to enable gesture recognition in unlit environments using passive infrared sensors. The research conducted during this project has also made significant contributions in understanding the impact of human motion on wireless signals, another ambient modality prevalent almost ubiquitously around us. In that direction, the project has resulted in several single and multi-user gesture recognition systems that leverage the distinctness of variations introduced by different human movements to WiFi signals to recognize human gestures.   The research results from this project have been published in top tier computer science conferences and journals, including MobiSys, UbiComp/IMWUT, IEEE Transactions on Mobile Computing, and IEEE Journal on Selected Areas in Communications. The key concepts, methods, and algorithms that the PI and his team has developed will potentially motivate more research work from the community in the area of ambient light based computing and sensing. The methods that the PI and his team have developed for removing the effects of changes in the user's position and orientation, and intensity, number, and position of light sources from the time-series of light sensor values will free the research community from dwelling on the task of handling such changes and enable the community to focus on other tasks such as improving the accuracy and handling practical issues that deteriorate this accuracy.    Through this project, the students have learnt how to build real world sensing systems, acquire data from such sensing systems, manage that data, and analyze it. The students have also learnt skills to develop and use machine-learning techniques for real world sensing systems. These hand-on system building skills along with the knowledge of developing and applying machine learning techniques for such sensing systems will be very helpful to the students when they pursue careers in academia, national laboratories, industry, and other research setups after their graduation. This, in turn, will contribute towards building a skilled workforce for the nation. The PI has also incorporated several modules and course projects based on this project into the undergraduate course, CSC 453: Introduction to IoT Systems, and the graduate course, CSC 591: Internet of Things - Applications &amp; Implementation.          Last Modified: 06/18/2020       Submitted by: Muhammad Shahzad]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
