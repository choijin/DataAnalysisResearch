<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Addressing End-system Bottlenecks in High-speed Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2015</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>514616</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The rate at which a single processor in a computer can execute instructions has not changed much in years, and major technological breakthroughs will be required to double the current best rates. On the other hand, the rate at which the network can deliver data is increasing rapidly and is expected to grow by an order of magnitude in the next few years. Because of the widening gap between the rate at which the network can deliver data and the rate at which a processor can process the data, it is becoming increasingly difficult for a single processor to keep up using current protocols and computer architectures.  Computer architects have compensated for the fact that processor speeds are no longer increasing by putting multiple processor cores on each die, and while these multicore systems have high aggregate processing capacities, attaining predictable performance for the commonly adopted communication protocols requires complex manual tuning.  In prior work, the concept of affinity (intelligently binding processes to processors) was leveraged to exploit the hardware parallelism of current and next generation computers.  This project will build upon this prior expertise and leverage statistical and control theoretic methods to manage end-to-end performance of high-speed flows. The process of careful characterization of current technology, followed by analysis, and finally middleware tool development will affords the maximum impact on shaping best practices while minimizing any impact on distributed application development processes.&lt;br/&gt;&lt;br/&gt;This project will characterize the end-system bottlenecks that arise during data transfers required in different distributed scientific and business applications. What is learnt will drive the development of introspective end-system aware models, which will allow the auto-tuning of data transfers. This tuning will consider both latency and throughput requirements of the applications. Flow striping methods that exploit multicore end-systems and adapt to the end-system bottlenecks will be developed. This will require addressing many new issues, such as assigning flows to cores while taking into account various (application, cache, and interrupt) affinities. Additionally, the underlying topology of the cache (inclusive vs. exclusive), the memory organization, and the heterogeneity of the cores will be considered when controlling the end-to-end flows.  Memory-mapped network channels, such as Remote Direct Memory Access over Converged Ethernet will be investigated, for data transfers over wide-area networks. Towards this end, memory management, message synchronization and end-to-end flow control to enable remote messaging for different types of network flows will be designed, implemented and evaluated. From the end-system architectural perspective, cache architectures that can significantly improve the network I/O performance will be proposed and investigated.&lt;br/&gt;&lt;br/&gt;Broader Impacts: This project, which lies at the intersection of computer networks, computer systems, operating systems, and distributed applications, will provide a platform to train graduate students in both analytical and experimental methods. Senior Design projects for undergraduates will be defined that will be closely related to the project and involve profiling distributed applications in high-speed network testbeds.  Industry partnerships will be established to design new protocols and optimize the performance of distributed applications, as well as contribute to the design of next generation networked computer system.</AbstractNarration>
<MinAmdLetterDate>08/24/2015</MinAmdLetterDate>
<MaxAmdLetterDate>05/29/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1528087</AwardID>
<Investigator>
<FirstName>Dipak</FirstName>
<LastName>Ghosal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dipak Ghosal</PI_FULL_NAME>
<EmailAddress>dghosal@ucdavis.edu</EmailAddress>
<PI_PHON>5307549251</PI_PHON>
<NSF_ID>000359453</NSF_ID>
<StartDate>08/24/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Farrens</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew K Farrens</PI_FULL_NAME>
<EmailAddress>mkfarrens@ucdavis.edu</EmailAddress>
<PI_PHON>5307529678</PI_PHON>
<NSF_ID>000405318</NSF_ID>
<StartDate>08/24/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Davis</Name>
<CityName>Davis</CityName>
<ZipCode>956186134</ZipCode>
<PhoneNumber>5307547700</PhoneNumber>
<StreetAddress>OR/Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1850 Research Park Dr., Ste 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>047120084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, DAVIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University Of California, Davis]]></Name>
<CityName>Davis</CityName>
<StateCode>CA</StateCode>
<ZipCode>956165270</ZipCode>
<StreetAddress><![CDATA[One Shields Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~500000</FUND_OBLG>
<FUND_OBLG>2018~14616</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The rate at which the network can deliver data is increasing rapidly and outpacing the rate at which a single core in a computer&nbsp; can execute instructions to process that data. This can result in a bottleneck in the receiving computer that can impact the performance of the data transfer.&nbsp; This objective of this project was to characterize the end-system bottlenecks that arise during data transfers required in different distributed scientific and business applications. The overall goal was drive the development of introspective end-system aware models, which will allow the auto-tuning of data transfers and make them more predictable.&nbsp;<br /><br />Intellectual Merits: Research efforts supported under this grant has resulted in a number of publications outlining important contributions. We have published a detailed&nbsp; survey paper on the principle discipline of this research project. This document will be relevant to systems architects, protocol designers, and distributed application developers who are interested in the performance bottlenecks and the state-of-the-art in performance improvement for high-speed end-to-end flows and high-performance network workflows over commodity hardware. Our study demonstrate the extent to which data transfer performance can change&nbsp; depending on how the various tasks of the receive process are assigned to cores in a multicore end-system. The study also illustrates how processor features such as Dynamic Voltage Frequency Scaling (DVFS)&nbsp; can be leveraged to speed up receiving data from a high speed network. Our work on the model driven optimization show how a simple optimization model to determine the server parameters can be used to determine parameters under real bursty network traffic. In another important outcome we have demonstrated how heterogeneous multicore processors (HMPs) can be exploited in edge computing to co-optimize strict latency guarantees&nbsp; and energy efficiency. Finally, our work on Model Predictive Control based congestion control algorithm is step towards achieving predictable data transfers to meet deadlines in data transfers and to achieve high utilization of the network capacity.&nbsp;<br /><br />Broader Impacts: This project, which lies at the intersection of computer networks, computer systems, operating systems, and distributed applications, provided a platform to train graduate students in both analytical and experimental methods. The project has supported one postdoc student, three PhD students, two MS students, and two Undergraduate students. These students have graduated (one remaining will graduate soon) and are employed in some of&nbsp; the top companies including Cray, Microsoft, and Facebook and&nbsp; Lawrence Livermore National Laboratory (LLNL).&nbsp; One of the undergraduate student will start his PhD with the PI.&nbsp; More importantly, these students are working on&nbsp; projects close to the principle discipline of this research project and are leveraging the skills and expertise they developed through this research project.&nbsp; Through this project we have also established close collaboration with Lawrence Berkeley National Laboratory which has fostered partnerships and technology transfer.&nbsp;</p><br> <p>            Last Modified: 12/21/2019<br>      Modified by: Dipak&nbsp;Ghosal</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The rate at which the network can deliver data is increasing rapidly and outpacing the rate at which a single core in a computer  can execute instructions to process that data. This can result in a bottleneck in the receiving computer that can impact the performance of the data transfer.  This objective of this project was to characterize the end-system bottlenecks that arise during data transfers required in different distributed scientific and business applications. The overall goal was drive the development of introspective end-system aware models, which will allow the auto-tuning of data transfers and make them more predictable.   Intellectual Merits: Research efforts supported under this grant has resulted in a number of publications outlining important contributions. We have published a detailed  survey paper on the principle discipline of this research project. This document will be relevant to systems architects, protocol designers, and distributed application developers who are interested in the performance bottlenecks and the state-of-the-art in performance improvement for high-speed end-to-end flows and high-performance network workflows over commodity hardware. Our study demonstrate the extent to which data transfer performance can change  depending on how the various tasks of the receive process are assigned to cores in a multicore end-system. The study also illustrates how processor features such as Dynamic Voltage Frequency Scaling (DVFS)  can be leveraged to speed up receiving data from a high speed network. Our work on the model driven optimization show how a simple optimization model to determine the server parameters can be used to determine parameters under real bursty network traffic. In another important outcome we have demonstrated how heterogeneous multicore processors (HMPs) can be exploited in edge computing to co-optimize strict latency guarantees  and energy efficiency. Finally, our work on Model Predictive Control based congestion control algorithm is step towards achieving predictable data transfers to meet deadlines in data transfers and to achieve high utilization of the network capacity.   Broader Impacts: This project, which lies at the intersection of computer networks, computer systems, operating systems, and distributed applications, provided a platform to train graduate students in both analytical and experimental methods. The project has supported one postdoc student, three PhD students, two MS students, and two Undergraduate students. These students have graduated (one remaining will graduate soon) and are employed in some of  the top companies including Cray, Microsoft, and Facebook and  Lawrence Livermore National Laboratory (LLNL).  One of the undergraduate student will start his PhD with the PI.  More importantly, these students are working on  projects close to the principle discipline of this research project and are leveraging the skills and expertise they developed through this research project.  Through this project we have also established close collaboration with Lawrence Berkeley National Laboratory which has fostered partnerships and technology transfer.        Last Modified: 12/21/2019       Submitted by: Dipak Ghosal]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
