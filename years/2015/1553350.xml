<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>How Scientists Shape Science-Based Environmental Assessments for Policy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2016</AwardEffectiveDate>
<AwardExpirationDate>04/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>95921.00</AwardTotalIntnAmount>
<AwardAmount>95921</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Frederick Kronz</SignBlockName>
<PO_EMAI>fkronz@nsf.gov</PO_EMAI>
<PO_PHON>7032927283</PO_PHON>
</ProgramOfficer>
<AbstractNarration>General Audience Summary &lt;br/&gt;&lt;br/&gt;This research project proposes to use ethnographic, archival, and interview methods to understand the authorial and decision-making work of scientific assessors, particularly those of the upcoming Sixth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC). This project marks the first time social scientists will observe the processes of the IPCC in real time, from the inside. The researchers will have a sustained opportunity to observe, analyze, and communicate how expert assessors shape climate assessments during the writing process. In turn, this research will be distributed among researchers as well as climate policy practitioners to help improve the application of climate science to policy, including the inclusion of diverse representation in the assessment process as well as the portrayal and communication of consensus, conflict, bias, error, risk, and uncertainty. This project will inform curricular development of a program in Climate Studies for undergraduate students, improve representation and capacity building among diverse climate scholars including undergraduate students and social science researchers in developing countries, communicate research findings to the public, and feed research findings back to the assessor community. &lt;br/&gt;&lt;br/&gt;Technical Summary &lt;br/&gt;&lt;br/&gt;The primary purpose of this project is to contribute to ongoing scholarly attempts to understanding scientific knowledge production. The field of science studies has provided ample evidence of the empirical inadequacy of algorithmic models of scientific knowledge production, and has of late come to stress the importance of expert judgment within diverse communities. This project explicitly addresses the practice of expert judgment in a major domain of contemporary scientific activity. It will also provide suggestions to improve the assessment and decision process. Assessments are expensive in terms of time, money, and scientific human capital, and it important for the scientific community re-assess the commitment that has been made to them. The researchers will produce policy-relevant and scientist-relevant papers to convey project findings to the IPCC and involved scientist assessors. They will also present to user communities, such as at the American Association for the Advancement of Science meetings.</AbstractNarration>
<MinAmdLetterDate>04/01/2016</MinAmdLetterDate>
<MaxAmdLetterDate>04/01/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1553350</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Oppenheimer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Oppenheimer</PI_FULL_NAME>
<EmailAddress>omichael@princeton.edu</EmailAddress>
<PI_PHON>6092583090</PI_PHON>
<NSF_ID>000498729</NSF_ID>
<StartDate>04/01/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName/>
<StateCode>NJ</StateCode>
<ZipCode>085405228</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7603</Code>
<Text>STS-Sci, Tech &amp; Society</Text>
</ProgramElement>
<ProgramReference>
<Code>7567</Code>
<Text>SOC STUDIES OF SCI, ENG &amp; TECH</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~95921</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>OUTCOMES REPORT</strong></p> <p><strong>GRANT 1553350: </strong><strong>How Scientists Shape Science-Based Environmental Assessments for Policy</strong></p> <p>Through the study of the IPCC, our research aimed (among other objectives) to: 1) understand the institutional framework within which science-based environmental assessments take place, 2) understand the process of assessment creation from planning to publication, 3) analyze decision making in writing groups and assessment organizations, 4) characterize the ways in which assessors handle consensus formation and conflict among experts, both in the assessment writing process and in the final texts.</p> <p>We found that institutional factors are critically important to the findings of an assessment. Such matters as scientific balance or lack thereof in author selection, chapter subject divisions of the assessment report, and rules for the degree of knowledge creation that authors can exercise exert a significant influence on assessment judgments. Assessments&rsquo; findings may differ depending on the particulars of the institutional arrangements under which the assessment is organized.</p> <p>&nbsp;</p> <p>We found that organizers and authors view bias in two ways: bias related to scientific positions and perception of bias related to public expression of policy related positions. Both attitudes have influenced the author selection process. In the case of scientific bias, assessments, including IPCC&rsquo;s, appear to operate by &ldquo;balance of bias&rdquo; in the expectation that distinct sets of opposing scientific beliefs and perspectives will essentially cancel each other, much as random errors cancel, if authors are chosen with explicitly different scientific views. Political or policy bias is viewed as problematic as a matter of public, sponsor, or stakeholder perception of the outcome of an assessment.&nbsp; The usual approach is to simply avoid picking as authors those experts who have an expressed view abut policy on the subject to be assessed.</p> <p>We found that excluding authors with a publicly expressed view probably biases assessment findings in a different and more serious way than the problem it aims to cure, namely eliminating those who often have thought longest and most deeply about the problem at hand and who are most expert at assessing it.</p> <p>&nbsp;</p> <p>Authors and assessment organizers appear to believe that a consensus model provides a powerful way to deliver messages to governments and avoid affording critics of the process ammunition derived from differences among authors, and this may well be the case. However, consensus also has the undesirable effect of discouraging dissent and cutting off part of the spectrum of expert beliefs and limiting the information available to policy makers, especially with regard to low-likelihood/high impact outcomes.</p> <p>We explored other potential models for rendering expert judgments (e.g., the Supreme Court model which highlights dissent, structured expert elicitation) and recommended that alternative approaches be implemented on a trial basis.</p> <p>&nbsp;</p> <p>Contrary to general belief and explicit policy, we found that some of the most successful assessments in terms of utility to policy makers operate in a manner that implicitly allows authors to develop new knowledge about the subject at hand.&nbsp; Sometimes, this results in breakthroughs in understanding.&nbsp; At other times, the new knowledge developed is a matter of application of existing understanding in a new way that turns it to a policy-relevant use for the first time.</p> <p>&nbsp;</p> <p>Implicit or explicit rules against knowledge creation by assessors has a negative impact on assessment outcomes by severely limiting their utility, as in the case of IPCC chapters related to ice sheets and sea level rise in its Fourth Assessment Report. We strongly recommend that this practice be abandoned.</p><br> <p>            Last Modified: 06/07/2019<br>      Modified by: Michael&nbsp;Oppenheimer</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ OUTCOMES REPORT  GRANT 1553350: How Scientists Shape Science-Based Environmental Assessments for Policy  Through the study of the IPCC, our research aimed (among other objectives) to: 1) understand the institutional framework within which science-based environmental assessments take place, 2) understand the process of assessment creation from planning to publication, 3) analyze decision making in writing groups and assessment organizations, 4) characterize the ways in which assessors handle consensus formation and conflict among experts, both in the assessment writing process and in the final texts.  We found that institutional factors are critically important to the findings of an assessment. Such matters as scientific balance or lack thereof in author selection, chapter subject divisions of the assessment report, and rules for the degree of knowledge creation that authors can exercise exert a significant influence on assessment judgments. Assessments? findings may differ depending on the particulars of the institutional arrangements under which the assessment is organized.     We found that organizers and authors view bias in two ways: bias related to scientific positions and perception of bias related to public expression of policy related positions. Both attitudes have influenced the author selection process. In the case of scientific bias, assessments, including IPCC?s, appear to operate by "balance of bias" in the expectation that distinct sets of opposing scientific beliefs and perspectives will essentially cancel each other, much as random errors cancel, if authors are chosen with explicitly different scientific views. Political or policy bias is viewed as problematic as a matter of public, sponsor, or stakeholder perception of the outcome of an assessment.  The usual approach is to simply avoid picking as authors those experts who have an expressed view abut policy on the subject to be assessed.  We found that excluding authors with a publicly expressed view probably biases assessment findings in a different and more serious way than the problem it aims to cure, namely eliminating those who often have thought longest and most deeply about the problem at hand and who are most expert at assessing it.     Authors and assessment organizers appear to believe that a consensus model provides a powerful way to deliver messages to governments and avoid affording critics of the process ammunition derived from differences among authors, and this may well be the case. However, consensus also has the undesirable effect of discouraging dissent and cutting off part of the spectrum of expert beliefs and limiting the information available to policy makers, especially with regard to low-likelihood/high impact outcomes.  We explored other potential models for rendering expert judgments (e.g., the Supreme Court model which highlights dissent, structured expert elicitation) and recommended that alternative approaches be implemented on a trial basis.     Contrary to general belief and explicit policy, we found that some of the most successful assessments in terms of utility to policy makers operate in a manner that implicitly allows authors to develop new knowledge about the subject at hand.  Sometimes, this results in breakthroughs in understanding.  At other times, the new knowledge developed is a matter of application of existing understanding in a new way that turns it to a policy-relevant use for the first time.     Implicit or explicit rules against knowledge creation by assessors has a negative impact on assessment outcomes by severely limiting their utility, as in the case of IPCC chapters related to ice sheets and sea level rise in its Fourth Assessment Report. We strongly recommend that this practice be abandoned.       Last Modified: 06/07/2019       Submitted by: Michael Oppenheimer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
