<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS: FULL: FP: Write-Efficient Parallel Algorithms for Emerging Memory Technologies</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>845000.00</AwardTotalIntnAmount>
<AwardAmount>845000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Chip manufacturers in the past ten years have been enhancing computing performance by including multiple processor cores per chip.  Given that all the cores have to access a shared memory, however, this access has increasingly become a bottleneck in terms of energy, latency, and bandwidth.  To help deal with these and other problems, industry has been developing a variety of new memory technologies such as phase-change memory, Spin-Torque Transfer Magnetic RAM, and Memristor-based Resistive RAM.  These technologies offer the promise of significantly lower energy and higher density than standard DRAM memory technology.  One of the key issues, however, is that writing to memory based on the technologies is significantly more costly than reading from memory, suffering from higher latency, lower per-chip bandwidth, and higher energy costs.&lt;br/&gt;&lt;br/&gt;The goal of this project is to develop new sequential and parallel algorithms and algorithm design techniques that are efficient in terms of the number of writes they perform, and hence make better use of these new technologies by reducing energy consumption and improving performance.  This contrasts with 50 years of research on algorithms in which writes are assumed to be no more costly than reads.  If successful the research will have a broad impact on future users of such technologies, which could be very many, as well as on the models and approaches for future algorithm design.  The PIs also plan to develop efficient implementations of algorithms that they will make freely and openly available.  The project includes an educational outreach component in which, as part of courses on databases and applied algorithms, the PIs will teach students about the new memory technologies and algorithms that can take advantage of them.&lt;br/&gt;&lt;br/&gt;Within the scope of work the PIs will (1) develop appropriate abstract models for capturing the asymmetric costs in memories, (2) develop and analyze algorithms in the models, (3) prove lower bounds, (4) develop programming abstractions that help express such algorithms, (5) develop working applications (e.g., in graph analytics and databases) based on the algorithms developed, and (6) experimentally verify the utility of the models and abstractions in guiding the development of efficient algorithms.  The intellectual challenge within this context will be in developing such models, algorithms, and programming abstractions that are simultaneously simple, elegant, and practical, while at the same time gaining insights into fundamental limits and trade-offs.</AbstractNarration>
<MinAmdLetterDate>07/27/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1533858</AwardID>
<Investigator>
<FirstName>Guy</FirstName>
<LastName>Blelloch</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Guy E Blelloch</PI_FULL_NAME>
<EmailAddress>guyb@cs.cmu.edu</EmailAddress>
<PI_PHON>4122686245</PI_PHON>
<NSF_ID>000196851</NSF_ID>
<StartDate>07/27/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Phillip</FirstName>
<LastName>Gibbons</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Phillip Gibbons</PI_FULL_NAME>
<EmailAddress>gibbons@cs.cmu.edu</EmailAddress>
<PI_PHON>4122686354</PI_PHON>
<NSF_ID>000270775</NSF_ID>
<StartDate>07/27/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8283</Code>
<Text>Exploiting Parallel&amp;Scalabilty</Text>
</ProgramElement>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~845000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>For nearly two decades, chip manufacturers have been enhancing computing performance by increasing the number of processing cores per chip. Because all these cores share the available memory (traditionally, DRAM memory), performance is often bottlenecked by the capacity of that memory (exceeding the capacity can slow down the computation by at least an order of magnitude), while dramatically increasing the amount of DRAM adds significant purchasing and energy costs.</span></p> <p><span> </span></p> <p><span>To help deal with these and other problems, industry has been developing a variety of new memory technologies (NVRAMs) that offer the promise of significantly lower energy and lower cost/byte than standard DRAM memory technologies. One of the key issues with such NVRAMs, however, is that writing is significantly more costly than reading, suffering from higher latency, lower per-chip bandwidth, higher energy costs, and wear out problems.</span></p> <p><span> </span></p> <p><span>Anticipating the arrival of NVRAMs with costly writes, this project conducted an extensive study of techniques and fundamental trade-offs for memories with costly writes.&nbsp; Fifty years of algorithm design had focused on the setting where writes and reads were of equal cost, so such a study was needed to understand how to design algorithms and data structures for these forthcoming NVRAMs.</span></p> <p><span> </span></p> <p><span>The PIs (1) developed effective abstract models for capturing the read-write cost asymmetry, for both sequential and parallel computations, (2) developed and analyzed algorithms in these models for dozens of fundamental computation problems, especially for computations on large graphs, and (3) proved lower bounds showing fundamental trade-offs between the amount of reading and the amount of writing needed to solve various computational problems.</span></p> <p><span>On the systems side, the PIs (4) developed and implemented programming abstractions and frameworks that help express such algorithms, (5) developed effective caching policies that account for the high cost of evicting data that must be written back to NVRAM, and (6) experimentally verified that the developed models, frameworks, and algorithms resulted in the fastest codes on real machines with NVRAM, </span><span><span>once the first NVRAM memories <span>(Intel's Optane DC memory)</span><strong> </strong>became available in the final year of the project.</span></span></p> <p>The project further explored research questions arising from another key advantage of NVRAM--namely, that unlike DRAM, NVRAM does not lose its contents on a power outage or major crash.&nbsp; The project developed effective techniques for making use of this non-volatile nature of NVRAM to recover from the loss of cache and DRAM memory on a power outage or major crash.</p> <p>The project resulted in 19 published papers, including 13 full papers in highly selective algorithms or parallel programming conferences.</p> <p>The project helped support eight PhD students (including two women), and resulted in significant research experience for each of them. Course materials were developed, two invited keynote talks and a tutorial were given at major conferences, a benchmark suite was released open source, and presentations were given to over 20 interested companies.</p> <p>&nbsp;</p> <p><strong>&nbsp;</strong><em>&nbsp;</em></p> <p>&nbsp;</p><br> <p>            Last Modified: 06/14/2020<br>      Modified by: Phillip&nbsp;Gibbons</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ For nearly two decades, chip manufacturers have been enhancing computing performance by increasing the number of processing cores per chip. Because all these cores share the available memory (traditionally, DRAM memory), performance is often bottlenecked by the capacity of that memory (exceeding the capacity can slow down the computation by at least an order of magnitude), while dramatically increasing the amount of DRAM adds significant purchasing and energy costs.     To help deal with these and other problems, industry has been developing a variety of new memory technologies (NVRAMs) that offer the promise of significantly lower energy and lower cost/byte than standard DRAM memory technologies. One of the key issues with such NVRAMs, however, is that writing is significantly more costly than reading, suffering from higher latency, lower per-chip bandwidth, higher energy costs, and wear out problems.     Anticipating the arrival of NVRAMs with costly writes, this project conducted an extensive study of techniques and fundamental trade-offs for memories with costly writes.  Fifty years of algorithm design had focused on the setting where writes and reads were of equal cost, so such a study was needed to understand how to design algorithms and data structures for these forthcoming NVRAMs.     The PIs (1) developed effective abstract models for capturing the read-write cost asymmetry, for both sequential and parallel computations, (2) developed and analyzed algorithms in these models for dozens of fundamental computation problems, especially for computations on large graphs, and (3) proved lower bounds showing fundamental trade-offs between the amount of reading and the amount of writing needed to solve various computational problems.  On the systems side, the PIs (4) developed and implemented programming abstractions and frameworks that help express such algorithms, (5) developed effective caching policies that account for the high cost of evicting data that must be written back to NVRAM, and (6) experimentally verified that the developed models, frameworks, and algorithms resulted in the fastest codes on real machines with NVRAM, once the first NVRAM memories (Intel's Optane DC memory) became available in the final year of the project.  The project further explored research questions arising from another key advantage of NVRAM--namely, that unlike DRAM, NVRAM does not lose its contents on a power outage or major crash.  The project developed effective techniques for making use of this non-volatile nature of NVRAM to recover from the loss of cache and DRAM memory on a power outage or major crash.  The project resulted in 19 published papers, including 13 full papers in highly selective algorithms or parallel programming conferences.  The project helped support eight PhD students (including two women), and resulted in significant research experience for each of them. Course materials were developed, two invited keynote talks and a tutorial were given at major conferences, a benchmark suite was released open source, and presentations were given to over 20 interested companies.                 Last Modified: 06/14/2020       Submitted by: Phillip Gibbons]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
