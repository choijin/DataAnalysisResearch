<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: A Mathematical Model of Privacy Decisions: A Behavioral Economic Perspective</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>275769.00</AwardTotalIntnAmount>
<AwardAmount>275769</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
<PO_EMAI>skiesler@nsf.gov</PO_EMAI>
<PO_PHON>7032928643</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When making decisions about information privacy, people do not always act rationally according to their best interests. It is thus important to understand why people express concerns about privacy, but often act contrary to their stated intentions. This research investigates individuals' privacy decisions, from a behavioral economic perspective, by: 1) investigating how two systems of thinking in human minds, affective (system 1) and cognitive (system 2), operate during privacy decisions; 2) developing affective-cognitive algorithms to mathematically describe the operation of systems 1 and 2 in privacy decisions; and 3) testing and evaluating the accuracy of these algorithms. This is the first step in forming a new mathematical theory of privacy that can describe how people actually make privacy decisions versus how they are expected to make such decisions. &lt;br/&gt;&lt;br/&gt;Using techniques from discrete mathematics, theoretical computer science and behavioral economics, and adapting the concept of bounded rationality, the PIs will develop affective-cognitive algorithms to model human experienced-utility in privacy decisions (i.e., risks and benefits they perceive in disclosing privacy). This is fundamentally different from the existing mathematical models of privacy decisions that assume humans have stable preferences and always choose the option with the highest expected utility (i.e., the option with the maximum privacy). The PIs use techniques from behavioral game theory to rigorously test and evaluate the accuracy of their algorithms. The PIs apply findings of behavioral economics, mathematical psychology, and previous research on information privacy to translate operation of systems 1 and 2 into mathematical models.  This research is intended to bridge three streams of research, namely information privacy, theoretical computer science, and behavioral and experimental economics. The impacts of this research have translational potential for application to real online environments and implementation in decision support tools, such as recommender systems.</AbstractNarration>
<MinAmdLetterDate>08/21/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/08/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1544090</AwardID>
<Investigator>
<FirstName>Dana</FirstName>
<LastName>Randall</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dana J Randall</PI_FULL_NAME>
<EmailAddress>randall@cc.gatech.edu</EmailAddress>
<PI_PHON>4048943156</PI_PHON>
<NSF_ID>000164506</NSF_ID>
<StartDate>08/21/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fariborz</FirstName>
<LastName>Farahmand</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fariborz Farahmand</PI_FULL_NAME>
<EmailAddress>fariborz@ece.gatech.edu</EmailAddress>
<PI_PHON>4048948364</PI_PHON>
<NSF_ID>000258871</NSF_ID>
<StartDate>08/21/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tibor</FirstName>
<LastName>Besedes</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tibor Besedes</PI_FULL_NAME>
<EmailAddress>besedes@gatech.edu</EmailAddress>
<PI_PHON>4043850866</PI_PHON>
<NSF_ID>000084576</NSF_ID>
<StartDate>08/21/2015</StartDate>
<EndDate>08/08/2016</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avene, SW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~275769</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>A common presumption when analyzing how people make privacy decisions is that they are rational economic agents who always choose the option with maximum utility. This assumption also extends to the mathematical models that we apply to privacy decisions. These models are based on expected utility theory, and can safely be equated with the von Neumann-Morgenstern perspective on "decision utility" (preference or desire for the outcome). However, the challenges of the assumption of rationality and utility maximization in describing human decisions, as well as the striking facts about privacy behaviors, lead to a fundamental question: What is utility in the eye of an individual in a privacy-related decision? For instance, why is it that while most people claim to be concerned about their privacy, they do not consistently take actions to protect it? This research addresses this fundamental question, and makes several contributions into understanding privacy behaviors, and human information processing.</p> <p>First, based on Daniel Kahneman and his colleagues' proposal to define the value of actions as a function of the total pleasure and pain it elicited, weighted by its duration, certainty, and the time of occurrence, this research introduces the concept of "experienced utility", or likability, to the privacy research community. Experienced utility describes the pleasure and pain elicited by a chosen stimulus while remembering, experiencing, or anticipating it. This research formally captured experienced utility and affective-cognitive evaluations and the relation between decision utility and experienced utility, in privacy decisions, using prospect theory, and decision field theory.</p> <p>Second, we also formally captured the interplay between affective and cognitive systems, using two objective functions operating simultaneously. Collecting data from hundreds of online users about various electronic activities, we experimentally investigated this interplay, and found a significant inverse relationship between their assessed risks and benefits.</p> <p>Third, we found the existing statistical analysis methods of privacy decisions only indicate the two events are mutually correlated, or dependent, that is, if we can find one, we can expect to encounter the other. They are unable to explain the "actual cause" or specific instances and the outcomes of privacy decisions. Additionally, they do not include counterfactual analysis&#8208;&#8208;a prediction of what would have happened in the absence of the treatment, a critical step in any experimental causal analysis of privacy decisions. Additionally, we investigated how security and privacy research can apply the mathematical formalism of quantum cognition to model the observed deviations from classicality in human reasoning. Quantum cognition is based on the work of von Neumann who replaced the set theoretic structure of classical probability theory with the projective geometric structure of vector spaces.</p> <p>The outcomes of this project have bridged different cultures of scholarship and research, such as information privacy, theoretical computer science, and behavioral and experimental economics. The outcomes of this project have translated findings of the information systems and social science communities in privacy area into mathematical theories of choice and decision making. This research took the first step in forming a new mathematical theory of privacy that can describe how people actually make privacy decisions versus how they are expected to make such decisions. These results will assist computer and information science and engineering researchers and social, behavioral and economic science to better understand real-world privacy issues.</p> <p>The impacts of this work are expected to be far reaching, as the outcomes of this research have obvious translational potential for application to real online environments and implementation in decision support tools (e.g., recommender systems). This interdisciplinary research provides a new perspective to information privacy, computer science, and economics, giving the potential for truly impactful breakthroughs in each discipline.</p><br> <p>            Last Modified: 11/26/2018<br>      Modified by: Fariborz&nbsp;Farahmand</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ A common presumption when analyzing how people make privacy decisions is that they are rational economic agents who always choose the option with maximum utility. This assumption also extends to the mathematical models that we apply to privacy decisions. These models are based on expected utility theory, and can safely be equated with the von Neumann-Morgenstern perspective on "decision utility" (preference or desire for the outcome). However, the challenges of the assumption of rationality and utility maximization in describing human decisions, as well as the striking facts about privacy behaviors, lead to a fundamental question: What is utility in the eye of an individual in a privacy-related decision? For instance, why is it that while most people claim to be concerned about their privacy, they do not consistently take actions to protect it? This research addresses this fundamental question, and makes several contributions into understanding privacy behaviors, and human information processing.  First, based on Daniel Kahneman and his colleagues' proposal to define the value of actions as a function of the total pleasure and pain it elicited, weighted by its duration, certainty, and the time of occurrence, this research introduces the concept of "experienced utility", or likability, to the privacy research community. Experienced utility describes the pleasure and pain elicited by a chosen stimulus while remembering, experiencing, or anticipating it. This research formally captured experienced utility and affective-cognitive evaluations and the relation between decision utility and experienced utility, in privacy decisions, using prospect theory, and decision field theory.  Second, we also formally captured the interplay between affective and cognitive systems, using two objective functions operating simultaneously. Collecting data from hundreds of online users about various electronic activities, we experimentally investigated this interplay, and found a significant inverse relationship between their assessed risks and benefits.  Third, we found the existing statistical analysis methods of privacy decisions only indicate the two events are mutually correlated, or dependent, that is, if we can find one, we can expect to encounter the other. They are unable to explain the "actual cause" or specific instances and the outcomes of privacy decisions. Additionally, they do not include counterfactual analysis&#8208;&#8208;a prediction of what would have happened in the absence of the treatment, a critical step in any experimental causal analysis of privacy decisions. Additionally, we investigated how security and privacy research can apply the mathematical formalism of quantum cognition to model the observed deviations from classicality in human reasoning. Quantum cognition is based on the work of von Neumann who replaced the set theoretic structure of classical probability theory with the projective geometric structure of vector spaces.  The outcomes of this project have bridged different cultures of scholarship and research, such as information privacy, theoretical computer science, and behavioral and experimental economics. The outcomes of this project have translated findings of the information systems and social science communities in privacy area into mathematical theories of choice and decision making. This research took the first step in forming a new mathematical theory of privacy that can describe how people actually make privacy decisions versus how they are expected to make such decisions. These results will assist computer and information science and engineering researchers and social, behavioral and economic science to better understand real-world privacy issues.  The impacts of this work are expected to be far reaching, as the outcomes of this research have obvious translational potential for application to real online environments and implementation in decision support tools (e.g., recommender systems). This interdisciplinary research provides a new perspective to information privacy, computer science, and economics, giving the potential for truly impactful breakthroughs in each discipline.       Last Modified: 11/26/2018       Submitted by: Fariborz Farahmand]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
