<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER-NEON: Image-Based Ecological Information System (IBEIS) for Animal Sighting Data for NEON</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08040000</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>EF</Abbreviation>
<LongName>Emerging Frontiers</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michelle Elekonich</SignBlockName>
<PO_EMAI>melekoni@nsf.gov</PO_EMAI>
<PO_PHON>7032927202</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The National Ecological Observatory Network (NEON) is coming online and will provide atmospheric and ecological data locally, regionally and continent wide. At the same time, images are rapidly becoming the most abundant, widely available, and cheapest source of information about the natural world, especially about animals. This project will extend NEON's data, scientific, and citizen science capacity with image-based animal sighting data to scalably collect, manage, and analyze data for individually identifiable wildlife using the Image-Based Ecological Information System (IBEIS) prototype recently developed under another NSF award. Combined with other ecological data, the image data offer the promise of addressing big questions about animal ecology, behavior, and conservation - who? where? when? what? and why? - at high resolution and at fine-grained scale, across landscapes and ecosystems, from an individual animal to regional and global systems. As part of this project, undergraduate and graduate students from ecology and computer science at four institutions will produce and test the application interface, and will develop a suite of companion applications and training tools to allow greater involvement of citizen scientists.&lt;br/&gt;&lt;br/&gt;These tools will allow NEON to connect its database to data derived from large volumes of animal photographic images. Although this is primarily a proof of concept proposal focused on connecting whale shark images to NEONs atmospheric data, it will provide the means to be able to apply IBEIS algorithms and databases on images of distinctly marked North American species such as tortoises, monarch butterflies, salamanders, spotted skunk, bobcat, lynx, and humpback whales, thereby connecting these to NEON?s other data streams related to organisms, land use, hydrology and biogeochemistry. The proposed suite of tools includes: 1. an infrastructure and a mechanism for collecting images from scientists, automated remote cameras, citizen scientists and other sources; 2. a data management system for storing, accessing and manipulating images and derived data; 3. computer vision techniques for extracting information from the images about the identity of species and individual animals, as well as techniques for combining that information with other relevant data to derive information about ecological units such as animals, populations, species, and habitats; 4. a software application-program interface integrating the image and derived data with and within NEON; 5. a framework for engaging citizen scientists in data collection, derived science, and interaction with nature. Previous funding from NSF allowed building and testing of an IBEIS prototype.  This project will focus on the detection and identification methods for the identifiable US species, on integrating the system with NEON, and on scaling the system to many thousands of daily images from a variety of sources.</AbstractNarration>
<MinAmdLetterDate>08/07/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1550881</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Rubenstein</LastName>
<PI_MID_INIT>I</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel I Rubenstein</PI_FULL_NAME>
<EmailAddress>dir@princeton.edu</EmailAddress>
<PI_PHON>6092585698</PI_PHON>
<NSF_ID>000124640</NSF_ID>
<StartDate>08/07/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName/>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7959</Code>
<Text>MacroSysBIO &amp; NEON-Enabled Sci</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>7959</Code>
<Text>MACROSYSTEM BIOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~50000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the project is to extend NEON's data, scientific, and citizen science capacity with Image based animal sighting data to collect, manage, and analyze data for individually identifiable wildlife using our recently developed Image Based Ecological Information System (IBEIS). &nbsp;In order to do this, the aim is to create tools that would allow NEON to manage and analyze large volumes of photographic data, especially for terrestrial and marine species that can be individually identified from visual markings, such as tortoises, monarch butterflies, salamanders, spotted skunk, bobcat, lynx, grey whales, and whale sharks. Funded by NSF, we are building and field testing an IBEIS prototype on uniquely identifiable species in Africa. For the scope of this project, we focus on the detection and identification methods for the more subtle US species by testing the system on African species in different ecological and cultural settings and then on integrating the system with NEON, and on scaling the system to many thousands of daily images from a variety of sources.</p> <p>As the field animal behaviorist and ecologist on the NEON project, my role was to explore ways that images can be used to increase the scale and scope of field research, one of the central aims of NEON. To date, NEON collects a large streams of data on specific taxa, in a variety of habitats and biomes using standardized techniques and protocols. &nbsp;Issues associated with predicting animal movement trajectories, especially with respect to differences in age, sex and reproductive state, determining why species, and individuals within species are 'here' and not 'there' and understanding how actions of individuals shape the action of collectives and with what consequences are on a few of the hard problems to study given the standard technologies of today. &nbsp;Using images which are easy to collect and curate could be game changers as long as individuals within the images can be detected and identified to species before further being identified as unique individuals. &nbsp;Our Image Based Ecological Information System (IBEIS) has been built around two computer algorithms: &nbsp;1) the detection pipeline that identifies animals and marks them for identity processing; and 2) the 'Hotspotter' identification algorithm that compares individuals and identifies individuals as resighted or new. &nbsp;</p> <p>This type of artificial intelligence (AI) has allowed us to make a number of advances. &nbsp;First, we have been able to demonstrate its power in producing population size estimates that are more reliable than the normal total count approach that ecologists normally deploy. &nbsp;Second, we have been able to identify home ranges and territories of the majority--rather than the minority--of individuals in populations which in turn has allowed us to account for differences in risk of parasitic infection as well as being targeted by predators. &nbsp;And third, we have shown that the system works for principal investigators working alone as well as for remote camera traps and collective citizen science bioblitzes and rallies. &nbsp;</p> <p>The overarching objective of our NEON project was to determine if and how image analysis can enhance the data stream at NEON sites. &nbsp;Because understanding the evolutionary ecology of many species, communities and populations relies on the actions and decisions of&nbsp;&nbsp;individual animals, we wanted to assess how data from GPS and time stamped images of individuals could add to, and expand upon, the standard data normally collected at NEON sites.</p> <p>The results of our analyses of images show: &nbsp;1) that the accuracy of population size estimates is enhanced when images are used in sight-resight censuses; 2) the assumptions underlying closed population size estimation using simple and easy to use Lincoln-Peterson estimates hold when rallies ,or bioblitzes, are run in close succession since no birth or deaths or immigrations or emigrations occur, but more importantly, recatchabiility, although not equal for individuals, comes close since the percentage of individuals resighted&nbsp;within a day reached 90% with some animals being resighted as many as 70 times; and 3) the ability to use the patterns of long-term locations as well as daily and seasonal movements to better construct species niches within communities, understand the risk of parasite infection as well as predation prospects are all possible.</p> <p>To make the use of images precise and effective, large volumes of images are needed to avoid bias and minimize variance surrounding population size estimates. &nbsp;Individual scientists working alone or in small teams cannot generate the pool of images needed. &nbsp;But the deployment of large arrays of camera traps or drawing on the efforts of collective behavior of hundreds of eager and well-trained citizen scientists can provide the tens, if not hundreds, of thousands of images needed.</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/31/2019<br>      Modified by: Daniel&nbsp;I&nbsp;Rubenstein</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the project is to extend NEON's data, scientific, and citizen science capacity with Image based animal sighting data to collect, manage, and analyze data for individually identifiable wildlife using our recently developed Image Based Ecological Information System (IBEIS).  In order to do this, the aim is to create tools that would allow NEON to manage and analyze large volumes of photographic data, especially for terrestrial and marine species that can be individually identified from visual markings, such as tortoises, monarch butterflies, salamanders, spotted skunk, bobcat, lynx, grey whales, and whale sharks. Funded by NSF, we are building and field testing an IBEIS prototype on uniquely identifiable species in Africa. For the scope of this project, we focus on the detection and identification methods for the more subtle US species by testing the system on African species in different ecological and cultural settings and then on integrating the system with NEON, and on scaling the system to many thousands of daily images from a variety of sources.  As the field animal behaviorist and ecologist on the NEON project, my role was to explore ways that images can be used to increase the scale and scope of field research, one of the central aims of NEON. To date, NEON collects a large streams of data on specific taxa, in a variety of habitats and biomes using standardized techniques and protocols.  Issues associated with predicting animal movement trajectories, especially with respect to differences in age, sex and reproductive state, determining why species, and individuals within species are 'here' and not 'there' and understanding how actions of individuals shape the action of collectives and with what consequences are on a few of the hard problems to study given the standard technologies of today.  Using images which are easy to collect and curate could be game changers as long as individuals within the images can be detected and identified to species before further being identified as unique individuals.  Our Image Based Ecological Information System (IBEIS) has been built around two computer algorithms:  1) the detection pipeline that identifies animals and marks them for identity processing; and 2) the 'Hotspotter' identification algorithm that compares individuals and identifies individuals as resighted or new.    This type of artificial intelligence (AI) has allowed us to make a number of advances.  First, we have been able to demonstrate its power in producing population size estimates that are more reliable than the normal total count approach that ecologists normally deploy.  Second, we have been able to identify home ranges and territories of the majority--rather than the minority--of individuals in populations which in turn has allowed us to account for differences in risk of parasitic infection as well as being targeted by predators.  And third, we have shown that the system works for principal investigators working alone as well as for remote camera traps and collective citizen science bioblitzes and rallies.    The overarching objective of our NEON project was to determine if and how image analysis can enhance the data stream at NEON sites.  Because understanding the evolutionary ecology of many species, communities and populations relies on the actions and decisions of  individual animals, we wanted to assess how data from GPS and time stamped images of individuals could add to, and expand upon, the standard data normally collected at NEON sites.  The results of our analyses of images show:  1) that the accuracy of population size estimates is enhanced when images are used in sight-resight censuses; 2) the assumptions underlying closed population size estimation using simple and easy to use Lincoln-Peterson estimates hold when rallies ,or bioblitzes, are run in close succession since no birth or deaths or immigrations or emigrations occur, but more importantly, recatchabiility, although not equal for individuals, comes close since the percentage of individuals resighted within a day reached 90% with some animals being resighted as many as 70 times; and 3) the ability to use the patterns of long-term locations as well as daily and seasonal movements to better construct species niches within communities, understand the risk of parasite infection as well as predation prospects are all possible.  To make the use of images precise and effective, large volumes of images are needed to avoid bias and minimize variance surrounding population size estimates.  Individual scientists working alone or in small teams cannot generate the pool of images needed.  But the deployment of large arrays of camera traps or drawing on the efforts of collective behavior of hundreds of eager and well-trained citizen scientists can provide the tens, if not hundreds, of thousands of images needed.          Last Modified: 05/31/2019       Submitted by: Daniel I Rubenstein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
