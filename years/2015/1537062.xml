<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF:Small:Collaborative Research:Exploring Energy-Efficient GPGPUs Through Emerging Technology Integration</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>12/01/2014</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>226875.00</AwardTotalIntnAmount>
<AwardAmount>226875</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Nowadays, graphics processing units (GPUs) have been widely adopted for general-purpose computing, and are known as GPGPUs. However, current and future GPGPUs confront power and energy as the dominant constraints. The number of transistors integrated on a single GPU chip continues to increase due to shrinking feature size and the demand for massively parallel computing cores to increase throughput. On the other hand, the continuous decrease of transistor supply voltage at each new technology node has largely stalled because of leakage constraints, leading to an ever-increasing power density. Therefore, future GPGPUs must become more inherently energy efficient to avoid hitting the power wall. &lt;br/&gt;&lt;br/&gt;To meet the increasing demands on performance and energy-efficiency, emerging technologies such as non-volatile memory, inter-bank tunneling field effect transistors (TFETs), silicon nanophotonics, and three-dimensional (3D) integration are being deployed in hardware design and promise realization of power efficiency at a scale never expected before. The investigators are exploring a synergetic program to holistically and hierarchically improve the GPGPU's energy efficiency through emerging technology integration. The project objectives include (1) non-volatile memory in the GPU computing cores and low-power mechanisms to substantially reduce leakage and dynamic power consumption; (2) a hybrid TFET-CMOS (complementary metal-oxide semiconductor) methodology to effectively address the energy challenge at both intra- and inter-core levels; (3) a novel 3D-stacked throughput architecture based on silicon-nanophotonics technology to improve memory access performance yet reduce power consumption; (4) integration of the key research innovations and cross-technology optimizations to fully explore the potential of GPGPU design enabled by these emerging technologies. The proposed research will facilitate GPGPUs staying on track with deep sub-micron scaling and meeting the increasing demand for high-performance computing, and will hence benefit numerous real-life applications. This project will also contribute to society through engaging high-school and undergraduate students from minority-serving institutions in research, attracting women and other under-represented groups into graduate education, expanding the computer engineering curriculum with GPGPU power modeling and optimization techniques, disseminating research infrastructure for education and training, and collaborating with the GPU R&amp;D industry.</AbstractNarration>
<MinAmdLetterDate>05/19/2015</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1537062</AwardID>
<Investigator>
<FirstName>Xin</FirstName>
<LastName>Fu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xin Fu</PI_FULL_NAME>
<EmailAddress>xfu8@central.uh.edu</EmailAddress>
<PI_PHON>7137436104</PI_PHON>
<NSF_ID>000583715</NSF_ID>
<StartDate>05/19/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Houston</Name>
<CityName>Houston</CityName>
<ZipCode>772042015</ZipCode>
<PhoneNumber>7137435773</PhoneNumber>
<StreetAddress>4800 Calhoun Boulevard</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>036837920</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF HOUSTON SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042916627</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Houston]]></Name>
<CityName>Houston</CityName>
<StateCode>TX</StateCode>
<ZipCode>772042015</ZipCode>
<StreetAddress><![CDATA[4800 Calhoun Rd.  316 E. Cullen]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1675</Code>
<Text>NANOSCALE: SCIENCE &amp; ENGIN CTR</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~226875</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The objective of this research is to explore a synergetic program to holistically and hierarchically improve the General-Purpose Computing on Graphics Processing Units (GPGPUs) energy efficiency by integrating emerging technologies, such as the inter-bank tunneling field effect transistors (TFETs), three-dimensional (3D) integration, and non-volatile memory. We have made the following three major achievements:</p> <p>(1)&nbsp; &nbsp;TFET-based computing units for GPGPUs power saving: Supply voltage scaling is the fundamental technique to reduce the dynamic power consumption, but it is limited by the leakage constraints in CMOS digital circuits. Recently, TFETs have shown to be the attractive candidates to operate at low supply voltages (e.g. 0.3V) with ultra-low leakage and higher frequency than CMOS. However, at higher supply voltage, CMOS devices are able to achieve much better performance than TFETs. Therefore, building the pure TFET based computing cores in GPGPUs and running at low voltage will significantly degrade the performance. We explored the hybrid TFET-CMOS GPGPUs by using TFET to build a number of computing units while the remaining units are CMOS based. We explored a set of warp scheduling mechanisms to hide the long execution time in TFET-based units, thus, achieving the low power computing with little performance loss.</p> <p>(2)&nbsp; &nbsp;Energy and Reliability co-optimization for GPGPUs register file using non-volatile memory: register file is known as the power-hungry structure in GPGPUs, and becomes the major contributor to the overall soft-error rate of GPUs, and also is known as the power-hungry structure in GPGPUs. The non-volatile memory (e.g., spin-transfer torque RAM (STT-RAM)) offers several benefits such as extremely low leakage power, and immunity to soft error attacks. We explored LESS, which LEverages reSistive Memory to effectively mitigate both the registers energy consumption and soft-error vulnerability. As its disadvantage, STT-RAM experiences significantly slower write latency than SRAM. We built the hybrid STT-RAM and SRAM based register file in LESS, and explored the unique characteristics of GPGPU applications to hide the long write latency to STT-RAM and obtain the win-win gains: achieving the near-full soft-error protection for the register file, and meanwhile substantially reducing the power consumption without hurting the performance.</p> <p>(3)&nbsp; &nbsp;Exploring Low-Power L2 Cache in GPGPUs: GPGPUs support thousands of concurrent threads and require a large cache to hold the thread states and contents. It is well known that cache is power hungry, and effectively reducing its power consumption is critical to the overall GPGPUs power saving. We leveraged the unique features in GPUs architecture to achieve significant power savings for GPGPUs L2 cache. We found that the L2 cache in GPGPUs has low data locality since major data locality among threads occurs at intra-CTA (cooperative thread array) level which is able to be captured by L1 cache, therefore, data saved in L2 cache are rarely reused. In other words, a large portion of leakage power is consumed in L2 cache to hold the contents of the dead data (i.e., the data that will not be accessed in the future). This motivated us to reduce the L2 energy consumption by power gating the dead cache blocks after their last access. In order to accurately predict the cache block&rsquo;s last access time, we explored the PC-based reference time prediction based on our observation that different threads tend to show similar memory access behaviors when executing the same instruction. By doing this, we maximized the L2 cache leakage power saving while still maintaining the performance.</p><br> <p>            Last Modified: 10/11/2017<br>      Modified by: Xin&nbsp;Fu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The objective of this research is to explore a synergetic program to holistically and hierarchically improve the General-Purpose Computing on Graphics Processing Units (GPGPUs) energy efficiency by integrating emerging technologies, such as the inter-bank tunneling field effect transistors (TFETs), three-dimensional (3D) integration, and non-volatile memory. We have made the following three major achievements:  (1)   TFET-based computing units for GPGPUs power saving: Supply voltage scaling is the fundamental technique to reduce the dynamic power consumption, but it is limited by the leakage constraints in CMOS digital circuits. Recently, TFETs have shown to be the attractive candidates to operate at low supply voltages (e.g. 0.3V) with ultra-low leakage and higher frequency than CMOS. However, at higher supply voltage, CMOS devices are able to achieve much better performance than TFETs. Therefore, building the pure TFET based computing cores in GPGPUs and running at low voltage will significantly degrade the performance. We explored the hybrid TFET-CMOS GPGPUs by using TFET to build a number of computing units while the remaining units are CMOS based. We explored a set of warp scheduling mechanisms to hide the long execution time in TFET-based units, thus, achieving the low power computing with little performance loss.  (2)   Energy and Reliability co-optimization for GPGPUs register file using non-volatile memory: register file is known as the power-hungry structure in GPGPUs, and becomes the major contributor to the overall soft-error rate of GPUs, and also is known as the power-hungry structure in GPGPUs. The non-volatile memory (e.g., spin-transfer torque RAM (STT-RAM)) offers several benefits such as extremely low leakage power, and immunity to soft error attacks. We explored LESS, which LEverages reSistive Memory to effectively mitigate both the registers energy consumption and soft-error vulnerability. As its disadvantage, STT-RAM experiences significantly slower write latency than SRAM. We built the hybrid STT-RAM and SRAM based register file in LESS, and explored the unique characteristics of GPGPU applications to hide the long write latency to STT-RAM and obtain the win-win gains: achieving the near-full soft-error protection for the register file, and meanwhile substantially reducing the power consumption without hurting the performance.  (3)   Exploring Low-Power L2 Cache in GPGPUs: GPGPUs support thousands of concurrent threads and require a large cache to hold the thread states and contents. It is well known that cache is power hungry, and effectively reducing its power consumption is critical to the overall GPGPUs power saving. We leveraged the unique features in GPUs architecture to achieve significant power savings for GPGPUs L2 cache. We found that the L2 cache in GPGPUs has low data locality since major data locality among threads occurs at intra-CTA (cooperative thread array) level which is able to be captured by L1 cache, therefore, data saved in L2 cache are rarely reused. In other words, a large portion of leakage power is consumed in L2 cache to hold the contents of the dead data (i.e., the data that will not be accessed in the future). This motivated us to reduce the L2 energy consumption by power gating the dead cache blocks after their last access. In order to accurately predict the cache block?s last access time, we explored the PC-based reference time prediction based on our observation that different threads tend to show similar memory access behaviors when executing the same instruction. By doing this, we maximized the L2 cache leakage power saving while still maintaining the performance.       Last Modified: 10/11/2017       Submitted by: Xin Fu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
