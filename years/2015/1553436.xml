<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Low Latency, Parallel, and Context Aware Vision in Computed Tomography</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2016</AwardEffectiveDate>
<AwardExpirationDate>04/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>472513.00</AwardTotalIntnAmount>
<AwardAmount>472513</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alan Sussman</SignBlockName>
<PO_EMAI>alasussm@nsf.gov</PO_EMAI>
<PO_PHON>7032927563</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The increasing availability and maturity of non-invasive volumetric imaging techniques has provided the scientific, engineering, and medical communities with powerful methods of acquiring dense quantitative representations of both animate and inanimate objects---providing us with powerful methods of information capture.  This research effort concentrates on approaches for identifying and labeling representations within the captured data that integrate a priori structural and spatial configuration knowledge.  The automatic identification and labeling of volumetric pixels (voxels) produced by volumetric scanners presents challenging ill-posed problems that presently remain unsolved.  Even for well trained clinicians, determining organ boundaries when applying anatomical labels to low contrast medical images can be highly subjective, despite possessing strong prior anatomical knowledge of structure and shape.  Consequently, an anatomical delineation performed by different clinicians, even for the same patient image, fails to provide consistency.  More difficult ill-posed problems, such as matching corresponding voxels between images of a patient taken at different times---or, more difficult yet, between two entirely different patients---are so subjective that humans rarely provide consistent answers.  This research effort aims to develop algorithmic solutions to these problems in order to provide consistent quantitative analysis across volumes; thereby removing subjectivity attributable to inattentional blindness or unintentional bias.  With further advancement, such algorithms will be adequately fast and robust to extract anatomic structural information and perform patient correspondence autonomously at massive scales; thereby enabling powerful data analytics paving the way for the future of data driven medicine.  Through classroom integration and curriculum development, the PI will train science and engineering students to work with this next generation of image processing algorithms.  The PI will recruit and mentor researchers at both the undergraduate and graduate levels with emphasis on the recruitment of underrepresented groups within STEM related fields.  Therefore, this research aligns with the NSF mission to promote the progress of science and to advance the national health, prosperity and welfare.&lt;br/&gt;&lt;br/&gt;This research project consists of three primary efforts: first, the simultaneous segmentation of multiple structures using spatial relationship priors (i.e. situationally aware segmentation); second, the development of structurally aware registration algorithms (leveraging segmentation results); and third, the development of these algorithms specifically targeted to data parallel computer architectures.  Situationally aware algorithms developed by the PI will aim to perform simultaneous multi-target segmentations as well as anatomically specialized inference of organ deformation and motion that are robust to imaging inconsistencies, setup variations, and low-dose imaging.  The PI will investigate algorithmic methods possessing robustness to noisy, incomplete, or otherwise challenging image acquisitions by solving multiple inverse problems simultaneously and achieving higher accuracy through the coupling of solutions and exploitation of signal sparsity under certain basises.  The algorithms produced by this research will have broad societal impacts on fields employing computed tomography including archeology, soil sciences, the timber industry, biological sciences, industrial X-ray based inspection, and the aviation security industry.  In addition to the dissemination of the novel algorithms, the PI will develop high-performance parallel implementations as a library released under a permissive open-source license.  Development will occur in the open using Git; thereby enabling agile decentralized development that encourages increased utilization by and contributions from scientists and developers extramural to the project.  Algorithmic facilities initially selected for inclusion are areas of principal investigator's expertise and cover a wide spectrum of applications including motion estimation, image stitching, segmentation, 3D volume reconstruction (computed tomography), and registration/image fusion.  Through consortia and workshops, domain experts will be encouraged to contribute their expertise in established and emerging fields (e.g.  digital image forensics); enabling scientific cross-fertilization and collaboration across domain specific fields.</AbstractNarration>
<MinAmdLetterDate>05/17/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/17/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1553436</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Shackleford</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James Shackleford</PI_FULL_NAME>
<EmailAddress>shack@drexel.edu</EmailAddress>
<PI_PHON>2155714269</PI_PHON>
<NSF_ID>000638207</NSF_ID>
<StartDate>05/17/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Drexel University</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191021119</ZipCode>
<PhoneNumber>2158956342</PhoneNumber>
<StreetAddress>1505 Race St, 10th Floor</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002604817</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DREXEL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002604817</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Drexel University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>191042875</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~472513</FUND_OBLG>
</Award>
</rootTag>
