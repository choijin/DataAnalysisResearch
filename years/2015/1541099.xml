<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Large Scale Stochastic Optimization and Statistics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>208669.00</AwardTotalIntnAmount>
<AwardAmount>208669</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Stochastic optimization offers a general framework to study many fundamental statistical problems related to prediction such as regression, classification and density estimation. Furthermore, it is a natural framework to import powerful algorithms from numerical optimization, especially for large scale problems. The broad goal of this project is to understand the fundamental interactions between statistics and stochastic optimization. To accomplish this task the investigator (a) identifies new problems from statistics, especially with complex structure, that can be recast as stochastic optimization problems; (b) develops new algorithms that optimally and efficiently solve large scale problems; (c) determines essential characteristics of the problems that govern the performance of algorithms and their fundamental limitations; and (d) explores peripheral problems of stochastic optimization including stochastic optimization with stochastic constraints and stochastic optimization with limited feedback. &lt;br/&gt;&lt;br/&gt;The information era has witnessed an explosion in the collection of data and large scale data sets are ubiquitous in a wide range of applications including biology, networks, environmental science, sociology and marketing. This results in an acute need of new statistical methods to analyze these data sets of unprecedented size. While techniques from numerical optimization can be used in several scenarios, their analysis remains largely dissociated from that of the statistical task at hand. This research aims at providing a unified treatment of a number of large scale problems emerging from statistical learning and from optimization under uncertainty in general. Therefore, the project will not only result in new and effective algorithms, but also in a novel theoretical framework that supports the analysis of stochastic optimization problems and enables further improvements of said algorithms.</AbstractNarration>
<MinAmdLetterDate>04/16/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/14/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1541099</AwardID>
<Investigator>
<FirstName>Philippe</FirstName>
<LastName>Rigollet</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Philippe Rigollet</PI_FULL_NAME>
<EmailAddress>rigollet@math.mit.edu</EmailAddress>
<PI_PHON>6092165758</PI_PHON>
<NSF_ID>000515280</NSF_ID>
<StartDate>04/16/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~5471</FUND_OBLG>
<FUND_OBLG>2014~100079</FUND_OBLG>
<FUND_OBLG>2015~103119</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the last decade, statistics and computation have become increasingly intertwined: Statistical models that are not supported by efficient algorithms are often incapable of taking advantage of the growing amounts of available data.</p> <p>This projects has shed a new light on the interplay between statistics and a prime framework for algorithmic design, namely optimization in a variety of modern, large scale, statistical questions, ranging from fundamental ones such as model section and sparse regression, to more advanced ones such as multi-reference alignment and determinantal point processes. Indeed, during the time of this project, data driven scientific questions have become more and more pervasive and the project has evolved with its environment: Early questions that were under investigation in this project, led to discoveries that were subsequently applied to new statistical problems. On the way, fundamental discoveries were made. A few notable ones are:</p> <p>-Establishing the fundamental limitations of sparse linear regression, arguably the most common tool for large scale statistical prediction nowadays,</p> <p>-Developing a new general purpose method for model selection---a fundamental statistical question---called Q-aggregation that bypasses the limitations of all previous methods and can be implemented using fast optimization algorithms.</p> <p>-Discovering the first statistical/computational tradeoffs in the context of sparse principal component analysis by making a new connection between high-dimensional statistics and computational complexity,</p> <p>-Developing and studying a new model for community detection based on known models for particle interactions that arise in statistical physics,</p> <p>-Deriving the first statistical analysis for learning discrete determinantal point processes, a model for correlated binary observations that has become central to several machine learning applications where *diversity* plays an important role.</p> <p>This project has also allowed the training of<span>&nbsp;a new generation of scientists at the intersection of the key fields for data science: statistics, optimization and computer science. Moreover, several courses were developed under this project with lecture notes that are available online freely. This project has also supported the PI during the development of an online course on data science, targeted to professionals and that has been already attended by 2,500 students. It uses a new format and distills complex ideas of data science into simple, geometric principles that can be conveyed in short videos.</span></p> <p>The findings of this projects have generated a lot more questions that are still under investigation not only by the PI but also by various other research groups worldwide.</p> <p><span><br /></span></p> <p><span><br /></span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/07/2017<br>      Modified by: Philippe&nbsp;Rigollet</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the last decade, statistics and computation have become increasingly intertwined: Statistical models that are not supported by efficient algorithms are often incapable of taking advantage of the growing amounts of available data.  This projects has shed a new light on the interplay between statistics and a prime framework for algorithmic design, namely optimization in a variety of modern, large scale, statistical questions, ranging from fundamental ones such as model section and sparse regression, to more advanced ones such as multi-reference alignment and determinantal point processes. Indeed, during the time of this project, data driven scientific questions have become more and more pervasive and the project has evolved with its environment: Early questions that were under investigation in this project, led to discoveries that were subsequently applied to new statistical problems. On the way, fundamental discoveries were made. A few notable ones are:  -Establishing the fundamental limitations of sparse linear regression, arguably the most common tool for large scale statistical prediction nowadays,  -Developing a new general purpose method for model selection---a fundamental statistical question---called Q-aggregation that bypasses the limitations of all previous methods and can be implemented using fast optimization algorithms.  -Discovering the first statistical/computational tradeoffs in the context of sparse principal component analysis by making a new connection between high-dimensional statistics and computational complexity,  -Developing and studying a new model for community detection based on known models for particle interactions that arise in statistical physics,  -Deriving the first statistical analysis for learning discrete determinantal point processes, a model for correlated binary observations that has become central to several machine learning applications where *diversity* plays an important role.  This project has also allowed the training of a new generation of scientists at the intersection of the key fields for data science: statistics, optimization and computer science. Moreover, several courses were developed under this project with lecture notes that are available online freely. This project has also supported the PI during the development of an online course on data science, targeted to professionals and that has been already attended by 2,500 students. It uses a new format and distills complex ideas of data science into simple, geometric principles that can be conveyed in short videos.  The findings of this projects have generated a lot more questions that are still under investigation not only by the PI but also by various other research groups worldwide.                   Last Modified: 08/07/2017       Submitted by: Philippe Rigollet]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
