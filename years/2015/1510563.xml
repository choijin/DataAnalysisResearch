<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>UNS: Collaborative Research: Prosodic Control of Speech Synthesis for Assistive Communication in Severe Paralysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>217670.00</AwardTotalIntnAmount>
<AwardAmount>217670</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Aleksandr Simonian</SignBlockName>
<PO_EMAI>asimonia@nsf.gov</PO_EMAI>
<PO_PHON>7032922191</PO_PHON>
</ProgramOfficer>
<AbstractNarration>1510563(Stepp) &amp; 1509791 (Koch Fager)&lt;br/&gt;&lt;br/&gt;This work will develop and evaluate a system to allow individuals with unintelligible speech due to severe paralysis to control a speech synthesizer that includes prosody (changes in the pitch, loudness, and duration in speech that convey meaning). This advancement to the synthetic speech and the ease of its control by users will facilitate improved functionality of clinical communication systems, thus improving the quality of life of users. Natural and intelligible speech production in these individuals will increase their ability to participate actively in society and empower them to self-advocate for their own medical management.&lt;br/&gt;&lt;br/&gt;The research objective of this proposal is to test the hypothesis that providing users of alternative and augmentative communication (AAC) with a method for prosodic control will result in speech synthesis that is more natural to listeners and provides greater function to users. Up to 1.2% of the population is unable to meet daily communication needs using typical speech due to stroke or other neurological injury, requiring AAC to meet their communication needs. Their quality of life is strongly dependent on access to this communication, both for social interaction as well as to relay information about urgent medical needs. The most advanced AAC devices incorporate speech synthesis, allowing the users to communicate orally with others. However, the resulting synthetic speech is both unnatural and difficult for others to understand, and is often described as "robotic". Specifically, synthetic speech does not vary in pitch, loudness, or rhythm, the prosodic features utilized in typical speech to relay emotional state, utterance form (statement vs. question), irony, and emphasis.&lt;br/&gt;Asking AAC users to control each of these dimensions individually would result in an intractably slow and complex system, an unacceptable burden for individuals who already have considerably reduced communication rates. Instead, this project will leverage the fact that typical speech predictably uses these prosodic markers (pitch, loudness, rhythm) in concert. A novel AAC interface will be developed to allow users to modify the overall "stress" of synthetic speech output as a single dimension, in order to provide easily controlled, natural, and intelligible speech synthesis. The co-PIs will use their combined expertise in speech technology, clinical application of AAC, and real-time control of human-machine-interfaces to enable essential advancements in AAC technology to achieve three goals. In Research Goal 1, a multi-stress speech bank for concatenative speech synthesis will be created via a novel interactive procedure in which speech productions of healthy speakers are "misunderstood", thus prompting speakers to naturally emphasize specific target sounds in their repeated responses. This will result in a bank of triphones (sounds with a specific left and right context, based on surrounding sounds) with all potential combinations of sounds and stresses. Research Goal 2 is to develop an AAC interface that allows users to select phonemes (individual sounds of speech) using two-dimensional cursor control (e.g., head-tracking, eye-tracking) in which the stress of individual phonemes will be based on cursor dwell time. In Research Goal 3, the functionality of the AAC interface will be evaluated by testing its effect on the naturalness of communicative interactions.</AbstractNarration>
<MinAmdLetterDate>07/15/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1510563</AwardID>
<Investigator>
<FirstName>Cara</FirstName>
<LastName>Stepp</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Cara E Stepp</PI_FULL_NAME>
<EmailAddress>cstepp@bu.edu</EmailAddress>
<PI_PHON>6173537487</PI_PHON>
<NSF_ID>000600202</NSF_ID>
<StartDate>07/15/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022151605</ZipCode>
<StreetAddress><![CDATA[635 Commonwealth Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5342</Code>
<Text>Disability &amp; Rehab Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>010E</Code>
<Text>DISABILITY RES &amp; HOMECARE TECH</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~95593</FUND_OBLG>
<FUND_OBLG>2016~69487</FUND_OBLG>
<FUND_OBLG>2017~52590</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Synthetic speech is often robotic, unnatural, and at times, unintelligible since current text-to-speech (TTS) augmentative and alternative communication (AAC) systems fail to incorporate prosodic cues, such as varied pitch or duration, into synthesized speech. AAC users must expend more effort to convey urgent needs, while a higher cognitive processing load is placed on the listener to accurately understand the message being communicated. This project aimed to improve the quality of speech output for users of text-to-speech assistive communication. </span></p> <p><span>The results of our project support a trade-off between social and functional speech: speech produced with sentence-level F0 variation was less intelligible and less efficiently communicated, but perceived as more natural compared to speech produced at a fixed F0 level. Additionally, decreasing speech rate reduced the ability of speech to be efficiently communicated, in addition to reducing word recognition ability and perceived naturalness. Overall, the results from the current investigation highlight the importance of considering multiple measures to evaluate the effects of prosody on synthesized speech, in addition to demonstrating preliminary evidence for the differential effects of basic prosodic manipulation on the social and functional reception of synthesized speech. The intellectual merit of this work is such that the results will impact new directions for improving speech output in AAC devices.</span></p> <p><span>The broader impacts of this work relate to the translation of research findings to AAC users and the career development of trainees. </span><span>Several junior scientific trainees have been able to develop their scientific and engineering skills through association with this award. Two teams of undergraduate design teams have created custom solutions for current AAC users at the Madonna Rehabilitation Hospital. In addition to contributing to the students&rsquo; development, this has allowed potential users to be a part of the design process and to benefit directly from the research.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 10/29/2018<br>      Modified by: Cara&nbsp;E&nbsp;Stepp</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Synthetic speech is often robotic, unnatural, and at times, unintelligible since current text-to-speech (TTS) augmentative and alternative communication (AAC) systems fail to incorporate prosodic cues, such as varied pitch or duration, into synthesized speech. AAC users must expend more effort to convey urgent needs, while a higher cognitive processing load is placed on the listener to accurately understand the message being communicated. This project aimed to improve the quality of speech output for users of text-to-speech assistive communication.   The results of our project support a trade-off between social and functional speech: speech produced with sentence-level F0 variation was less intelligible and less efficiently communicated, but perceived as more natural compared to speech produced at a fixed F0 level. Additionally, decreasing speech rate reduced the ability of speech to be efficiently communicated, in addition to reducing word recognition ability and perceived naturalness. Overall, the results from the current investigation highlight the importance of considering multiple measures to evaluate the effects of prosody on synthesized speech, in addition to demonstrating preliminary evidence for the differential effects of basic prosodic manipulation on the social and functional reception of synthesized speech. The intellectual merit of this work is such that the results will impact new directions for improving speech output in AAC devices.  The broader impacts of this work relate to the translation of research findings to AAC users and the career development of trainees. Several junior scientific trainees have been able to develop their scientific and engineering skills through association with this award. Two teams of undergraduate design teams have created custom solutions for current AAC users at the Madonna Rehabilitation Hospital. In addition to contributing to the students? development, this has allowed potential users to be a part of the design process and to benefit directly from the research.          Last Modified: 10/29/2018       Submitted by: Cara E Stepp]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
