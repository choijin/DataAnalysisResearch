<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>INSPIRE: Not Unbiased: The Implications of Human-Algorithm Interaction on Training Data and Algorithm Performance</AwardTitle>
<AwardEffectiveDate>10/01/2015</AwardEffectiveDate>
<AwardExpirationDate>09/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>813222.00</AwardTotalIntnAmount>
<AwardAmount>829222</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei Ding</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This INSPIRE award is partially funded by the Information Integration and Informatics program in the Division of Information and Intelligent Systems in the Directorate for Computer &amp; Information Science &amp; Engineering, the Perception, Action &amp; Cognition program in the Division of Behavioral and Cognitive Sciences in the Directorate for Social, Behavioral &amp; Economic Sciences, and the Office of Integrative Activities in the Office of the Director.&lt;br/&gt;&lt;br/&gt;One of the most common uses of machine learning is to learn to replicate human decisions, a common example is recommender systems. In these systems, computers are trained to replicate the recommendation a collaboration of hundreds or thousands of humans would give, if that were possible.  Most of the data used to train these systems are not from a controlled random sample, but are obtained from users based on outputs of algorithms (e.g., which search engine results do users click on?), which introduces bias into the process and ultimately impacts the quality of the results.  This project addresses this problem by examining how the human decision process that creates these data in the first place is affected by the data coming from machine algorithms, how this in turn impacts the algorithms themselves, and how to ultimately adjust for human bias in the machine learning process.  Specific areas tackled are filtering (e.g., web search) and recommender systems.  The deep research into how the human decision process affects machine learning, and how machine learning impacts the human decision process, can provide significant advances in the accuracy and utility of systems using machine learning.&lt;br/&gt;&lt;br/&gt;The project builds on analysis of machine learning algorithms based on Hidden Markov Models (HMMs).  The formal analysis initially looks at "blind spots" - the impact of bias from users not getting complete (or a random sample) of data.  Further analysis will be based on the outcome of two human experiments:  Two category recommendation (labeling items, with items to be labelled chosen by random, active learning, and filter-based algorithms), and movie recommendation.  The results will be used to develop improved machine learning approaches based on antidotes (altering learned models to reduce bias) and reactive learning (active learning that takes into account the human and machine biases).  The PIs also have plans to capitalize on the lessons learned by providing examples of the use of cognitive science in a Web Mining course, and of the impact of machine learning in Data Science for Psychologists courses.</AbstractNarration>
<MinAmdLetterDate>09/14/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/03/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1549981</AwardID>
<Investigator>
<FirstName>Olfa</FirstName>
<LastName>Nasraoui</LastName>
<EmailAddress>olfa.nasraoui@louisville.edu</EmailAddress>
<StartDate>09/14/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Patrick</FirstName>
<LastName>Shafto</LastName>
<EmailAddress>patrick.shafto@gmail.com</EmailAddress>
<StartDate>09/14/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Louisville Research Foundation Inc</Name>
<CityName>Louisville</CityName>
<ZipCode>402021959</ZipCode>
<PhoneNumber>5028523788</PhoneNumber>
<StreetAddress>Atria Support Center</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
</Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramElement>
<Code>8078</Code>
<Text>INSPIRE</Text>
</ProgramElement>
<ProgramReference>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8653</Code>
<Text>INSPIRE Track-1 Creative</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
</Appropriation>
<Appropriation>
<Code>0116</Code>
</Appropriation>
</Award>
</rootTag>
