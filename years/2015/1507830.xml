<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Extracting Knowledge from 100 years of Microstructural Images: Using Machine Vision and Machine Learning to Address the Microstructural Big Data Challenge</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03070000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMR</Abbreviation>
<LongName>Division Of Materials Research</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Daryl Hess</SignBlockName>
<PO_EMAI>dhess@nsf.gov</PO_EMAI>
<PO_PHON>7032924942</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Division of Materials Research; the Civil, Mechanical, and Manufacturing Innovation Division; and the Division of Advanced Cyberinfrastructure contribute funds to this award. It supports research and education to collect, analyze, and compare data on materials from vast sources. All solid objects - from an airplane wing to a frying pan - have a microscopic structure that is usually not visible to the naked eye. This structure determines the properties of the material as a whole - whether it is strong or weak, for example. For the past century, materials scientists have studied these structures by using microscopes to take pictures (called micographs) of them. They then measure the important features seen in the microscopic images and relate those measurements to the properties of the material.&lt;br/&gt;Just as in personal photography, digital cameras have enabled materials scientists to take more pictures and do more with them than ever before. Moreover, older micrographs have been scanned in to digital archives. Materials scientists are now confronted with a set of images that is too large and too diverse to analyze manually. Fortunately, computer scientists have developed "machine vision" computer programs that identify similarities in large sets of images by in a sense mimicking how humans see objects. This project will gather micrographs from many sources into an open archive and use machine vision programs to search, sort, and classify them automatically without significant human intervention.&lt;br/&gt;By synthesizing microscopic image data at a previously impossible scale, this project creates a foundation for discovering new connections between microscopic structures and materials properties. The results will help improve current materials and even develop new ones. The data will be made available to the broader community.&lt;br/&gt;&lt;br/&gt;The Division of Materials Research; the Civil, Mechanical, and Manufacturing Innovation Division; and the Division of Advanced Cyberinfrastructure contribute funds to this award. It supports research and education to collect, analyze, and compare data on materials from vast sources. Over the past 100 years, materials scientists have made great progress in acquiring, analyzing, and comparing microstructural images. Much of this effort has been directed toward deep understanding of particular materials systems or classes of microstructures. When the catalog of possible microstructural features is known, imaging techniques can take advantage of well-defined feature characteristics to analyze microstructures with high precision. However, when the features of interest are not known a priori, these methods become intractable, inaccurate, or fail completely. Thus, typically, they are applied only to a pre-selected set of micrographs, chosen by a human expert. In contrast, the goal of this effort is to develop a general method to find useful relationships between micrographs without assumptions about what features may be present. Such an approach can leverage the explosion in digital data over the past two decades to survey the breadth of available microstructures efficiently and without significant human intervention.&lt;br/&gt;Capitalizing on recent advances in computer science, this project applies a subset of data science concepts - including data harvesting, machine vision, and machine learning - to advance the science of microstructure. The result will be a framework for finding connections between microstructural images within and across material systems, which will support outcomes ranging from computational tools to discovery science, including:&lt;br/&gt;- New open source tools for extracting micrographs and associated metadata from various digital archives, including the internet, PDF documents, and local storage media.&lt;br/&gt;- A comprehensive database of publicly available micrographs with traditional text-based search and novel image-based search functions. &lt;br/&gt;- Optimized, high throughput, automatic machine vision techniques to identify microstructural features that are salient to image analysis and microstructural science.&lt;br/&gt;- Automatic and objective machine learning systems that find relationships between microstructures in order to discover new structure-property and structure-performance connections.&lt;br/&gt;The goal of microstructural science is to understand the connection between microstructural features and materials properties. By developing an open-access, automatic, and objective machine learning system for finding relationships between microstructural images, this project creates a foundation for discovering new connections that may inspire deeper understanding or predictive capabilities.</AbstractNarration>
<MinAmdLetterDate>09/09/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/11/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1507830</AwardID>
<Investigator>
<FirstName>Elizabeth</FirstName>
<LastName>Holm</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Elizabeth A Holm</PI_FULL_NAME>
<EmailAddress>eaholm@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122689527</PI_PHON>
<NSF_ID>000632549</NSF_ID>
<StartDate>09/09/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1765</Code>
<Text>CONDENSED MATTER &amp; MAT THEORY</Text>
</ProgramElement>
<ProgramElement>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~300000</FUND_OBLG>
<FUND_OBLG>2017~100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Normaltext">All solid objects - from an airplane wing to a frying pan - have a microscopic structure that is usually not visible to the naked eye. This structure determines the properties of the material as a whole ? whether it is strong or weak, for example. For the past century, materials scientists have studied these structures by using microscopes to take pictures (called micographs) of them. They then measure the important features seen in the microscopic images and relate those measurements to the properties of the material.</p> <p class="Normaltext">Just as in personal photography, digital cameras have enabled materials scientists to take more pictures and do more with them than ever before. Moreover, older micrographs have been scanned in to digital archives. Materials scientists are now confronted with a set of images that is too large and too diverse to analyze manually. Fortunately, computer scientists have developed ?computer vision? computer programs that identify similarities in large sets of images by mimicking how humans see objects. Familiar examples of computer vision are programs that recognize faces in pictures posted to social media platforms.</p> <p class="Normaltext">In this project, we gathered micrographs from many sources and used computer vision programs along with machine learning to search, sort, and classify them automatically without significant human intervention. We were able to use these programs to solve a variety of materials science problems. For example, we were able to predict locations where a material was most likely to start to break under stress. We showed that how a piece of steel is made affects how its substructure looks. And we discovered new ways to measure metallic powders used for 3D printing.</p> <p>This was the first time that computer vision and machine learning were applied to such a diverse group of materials science problems. The expertise we gained from this study enabled us to form perspective about the uses of these technologies that are useful to scientists and engineers more generally.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/21/2019<br>      Modified by: Elizabeth&nbsp;A&nbsp;Holm</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1507830/1507830_10397113_1561148661525_DMR-ProjectOutcomeImage--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1507830/1507830_10397113_1561148661525_DMR-ProjectOutcomeImage--rgov-800width.jpg" title="Connecting steel substructure to how it is made"><img src="/por/images/Reports/POR/2019/1507830/1507830_10397113_1561148661525_DMR-ProjectOutcomeImage--rgov-66x44.jpg" alt="Connecting steel substructure to how it is made"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A computer vision program groups pictures of the substructure of steel by their visual similarity, so that images that look alike are placed close together. The color of the border indicates how the steel was made. As we might expect, images that look alike also were made the same way.</div> <div class="imageCredit">Carnegie Mellon University</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Elizabeth&nbsp;A&nbsp;Holm</div> <div class="imageTitle">Connecting steel substructure to how it is made</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[All solid objects - from an airplane wing to a frying pan - have a microscopic structure that is usually not visible to the naked eye. This structure determines the properties of the material as a whole ? whether it is strong or weak, for example. For the past century, materials scientists have studied these structures by using microscopes to take pictures (called micographs) of them. They then measure the important features seen in the microscopic images and relate those measurements to the properties of the material. Just as in personal photography, digital cameras have enabled materials scientists to take more pictures and do more with them than ever before. Moreover, older micrographs have been scanned in to digital archives. Materials scientists are now confronted with a set of images that is too large and too diverse to analyze manually. Fortunately, computer scientists have developed ?computer vision? computer programs that identify similarities in large sets of images by mimicking how humans see objects. Familiar examples of computer vision are programs that recognize faces in pictures posted to social media platforms. In this project, we gathered micrographs from many sources and used computer vision programs along with machine learning to search, sort, and classify them automatically without significant human intervention. We were able to use these programs to solve a variety of materials science problems. For example, we were able to predict locations where a material was most likely to start to break under stress. We showed that how a piece of steel is made affects how its substructure looks. And we discovered new ways to measure metallic powders used for 3D printing.  This was the first time that computer vision and machine learning were applied to such a diverse group of materials science problems. The expertise we gained from this study enabled us to form perspective about the uses of these technologies that are useful to scientists and engineers more generally.          Last Modified: 06/21/2019       Submitted by: Elizabeth A Holm]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
