<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Scaling Insight into Science: Assessing the value and effectiveness of machine assisted classification within a statistical system</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/28/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>174993.00</AwardTotalIntnAmount>
<AwardAmount>174993</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04030000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>NCSE</Abbreviation>
<LongName>National Center For S&amp;E Statistics</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Mark Fiegener</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The project develops and compares cutting edge methods for the classification and analysis of American scientific research and compares them to existing manually generated approaches.  The project examines the strengths and weaknesses of four computational approaches: topic models, network-based partitioning methods, Wikipedia-based labeling, and an active-learning approach. In particular, the research examines whether or not the different approaches can correctly classify established research areas and discover emerging fields across a broad range of disciplines.  Each approach is evaluated based on a set of metrics measuring effectiveness, computational costs, human oversight costs, and the need to retain consistency with existing classification frameworks. &lt;br/&gt;&lt;br/&gt;The work directly responds to a number of National Academies recommendations and National Center for Science and Engineering Statistics (NCSES) reports that suggest using computational approaches to classify scientific research fields. A longer-term impact is improvement in data collection, processing, and reporting of key national statistics on science and engineering.</AbstractNarration>
<MinAmdLetterDate>09/02/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/02/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1557745</AwardID>
<Investigator>
<FirstName>Julia</FirstName>
<LastName>Lane</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Julia Lane</PI_FULL_NAME>
<EmailAddress>julia.lane@nyu.edu</EmailAddress>
<PI_PHON>2129926523</PI_PHON>
<NSF_ID>000620356</NSF_ID>
<StartDate>09/02/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100121009</ZipCode>
<StreetAddress><![CDATA[70 Washington Square S]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8800</Code>
<Text>SCIENCE RESOURCES STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~174993</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Managing the research portfolios of agencies and countries is not easy.&nbsp; &nbsp;How is it possible to describe the millions of grants, and millions of publications that are produced by American scientists?&nbsp;Federal agencies still use 20<sup>th</sup> century tools in the 21<sup>st</sup> century - they rely on people filling out forms to figure out what science is being done and with what results.&nbsp; &nbsp;Federal agencies can do better - they can use new computational techniques to describe the landscape of written text and apply machine learning to describe science. In the famous words of Lew Platt, the former CEO of Hewlett-Packard &ldquo;<em>If HP knew what HP knows, it would be three times more profitable</em>".&nbsp;&nbsp;</p> <p>Our work investigated whether modern text analysis approaches could be used to make sense of grant data from NSF, NIH and USDA. &nbsp;We were particularly interested in whether it was possible to validate the analyses using multiple approaches - that is, how robust and sensible the analyses were.</p> <p>We produced two major books.&nbsp; One is forthcoming (forthcoming by Cambridge University Press), major book published in the CRC Statistics series by Taylor and Francis, a number of opinion pieces including in Nature and Significance, two non refereed publications, a paper submitted to the Journal of Public Economics, six conference presentations and five keynote speeches The techniques that were developed were also used as the basis for five training classes for 75 statistical agency staff as well as over 170 staff from over 50 government agencies in 11 states.&nbsp; &nbsp;The textbook has sold almost 2000 copies and is being used in a number of data science classes across the nation and the world</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/30/2017<br>      Modified by: Julia&nbsp;Lane</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1557745/1557745_10340277_1511988679496_Picture1--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1557745/1557745_10340277_1511988679496_Picture1--rgov-800width.jpg" title="Measuring the Economic Value of Research"><img src="/por/images/Reports/POR/2017/1557745/1557745_10340277_1511988679496_Picture1--rgov-66x44.jpg" alt="Measuring the Economic Value of Research"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Measuring the Economic Value of Research: The Case of Food Safety</div> <div class="imageCredit">Cambridge University Press</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Julia&nbsp;Lane</div> <div class="imageTitle">Measuring the Economic Value of Research</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Managing the research portfolios of agencies and countries is not easy.   How is it possible to describe the millions of grants, and millions of publications that are produced by American scientists? Federal agencies still use 20th century tools in the 21st century - they rely on people filling out forms to figure out what science is being done and with what results.   Federal agencies can do better - they can use new computational techniques to describe the landscape of written text and apply machine learning to describe science. In the famous words of Lew Platt, the former CEO of Hewlett-Packard "If HP knew what HP knows, it would be three times more profitable".    Our work investigated whether modern text analysis approaches could be used to make sense of grant data from NSF, NIH and USDA.  We were particularly interested in whether it was possible to validate the analyses using multiple approaches - that is, how robust and sensible the analyses were.  We produced two major books.  One is forthcoming (forthcoming by Cambridge University Press), major book published in the CRC Statistics series by Taylor and Francis, a number of opinion pieces including in Nature and Significance, two non refereed publications, a paper submitted to the Journal of Public Economics, six conference presentations and five keynote speeches The techniques that were developed were also used as the basis for five training classes for 75 statistical agency staff as well as over 170 staff from over 50 government agencies in 11 states.   The textbook has sold almost 2000 copies and is being used in a number of data science classes across the nation and the world          Last Modified: 11/30/2017       Submitted by: Julia Lane]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
