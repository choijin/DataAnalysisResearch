<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>VEC: Small: Collaborative Research: Joint Compressive Spectral Imaging and 3D Ranging Sensing Using a Commodity Time-Of-Flight Range Sensor</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>484952.00</AwardTotalIntnAmount>
<AwardAmount>484952</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The commercial Kinect input device uses both a camera and a time-of-flight depth sensor to capture 3d interactions -- initially for gaming, it has found novel applications, including autism diagnosis and allowing surgeons to control imaging in the operating room. This project aims to integrate the time-of-flight (TOF) depth with Coded Aperture Snapshot Spectral Imaging (CASSI) in a single sensor, giving 3d images not only of visible light, but extending into the infrared.  This will have advantages of improving the resolution of the depth information, allowing the two sensors to work together to improve the quality of both.  The result will be the first generation of 3D-based 'spectrophotographic' cameras for use on robotic platforms and as the heart of machine vision systems used in manufacturing and metrology.  With their higher spatial and spectral resolution, these could open new and unexplored markets. &lt;br/&gt;&lt;br/&gt;This project develops a time-of-flight, spectral imaging camera by addressing the problems of (a) novel coded aperture design and optimization under light level constraints; (b) fast compressive inverse reconstruction algorithms for real-time implementations; (c) characterization on non-ideal optical elements and calibration mechanisms, and (d) super-resolution enhancement schemes. The PIs will design and assemble a proof-of-concept prototype camera that integrates a DMD array with a CMOS, TOF image sensor in a package comparable to a pico-projector light engine. In order to mitigate the computational complexity of CS inverse image reconstruction algorithms that often preclude their use in real-time implementations, the PIs will build on their history of developing coded aperture schemes that give rise to divide-and-conquer image reconstruction algorithms that can be implemented on GPU and other multi-core processors.   This project also incorporates education activities including: (1) the development of a compressive optical imaging course with an emphasis on spectral and TOF modalities; (2) technical seminars at the annual Society of Hispanic Professional Engineers (SHPE) Conference; (3) open-source algorithms and measurement data for the scientific community.</AbstractNarration>
<MinAmdLetterDate>08/27/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/11/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1539157</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Lau</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel L Lau</PI_FULL_NAME>
<EmailAddress>dllau@uky.edu</EmailAddress>
<PI_PHON>8592571787</PI_PHON>
<NSF_ID>000206470</NSF_ID>
<StartDate>08/27/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>J. Todd</FirstName>
<LastName>Hastings</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>J. Todd Hastings</PI_FULL_NAME>
<EmailAddress>todd.hastings@uky.edu</EmailAddress>
<PI_PHON>8592186544</PI_PHON>
<NSF_ID>000341865</NSF_ID>
<StartDate>08/27/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Kentucky Research Foundation</Name>
<CityName>Lexington</CityName>
<ZipCode>405260001</ZipCode>
<PhoneNumber>8592579420</PhoneNumber>
<StreetAddress>109 Kinkead Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>KY06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>939017877</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF KENTUCKY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007400724</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Kentucky Research Foundation]]></Name>
<CityName>Lexington</CityName>
<StateCode>KY</StateCode>
<ZipCode>405260001</ZipCode>
<StreetAddress><![CDATA[500 S Limestone 109 Kinkead Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>KY06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>002Z</Code>
<Text>Intel/NSF VEC Partnership</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~201990</FUND_OBLG>
<FUND_OBLG>2016~136510</FUND_OBLG>
<FUND_OBLG>2017~146452</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Multispectral and hyperspectral (MS/HS) imaging refer to vision systems that record color in more than three primaries and, typically, involve recording scenes in light wavelengths outside the visible color spectrum such as the near-infrared as well as short and long-wave infrared.&nbsp; Capturing these wavelengths allows MS/HS cameras to recognize features of objects in terms of their material compositions.&nbsp; Alternatively, 3D or depth cameras capture the shape and position of objects in a scene.&nbsp; In the case of time-of-flight (ToF) cameras, depth is determined by indirectly measuring the time it takes light to travel from an emitter or flash source to the target surface and back to the sensor.&nbsp; To date, MS/HS cameras and ToF imaging has always implied using separate cameras placed side by side such that the MS/HS image can be warped or registered to match the scene as captured by the ToF sensor.<br /><br />This research focused on using a ToF image sensor in a coded apature spectral snapshop camera which is a MS/HS camera that is modeled after a traditional spectrophotometer and records all wavelengths simultaneously. Here a ray of light emanating from the scene is passed through a series of optical elements culminating in a prism that spreads that single ray of light over a lateral sequence of sensor pixels, in a wavelength dependent manner, just like a spectrophotometer would spread light across a linear array. Allowing for multiple rays of light simultaneously incident upon the sensor means that the camera can resolve a two dimensional image; however, because the spreading of light rays across lateral sequences of pixels means a single pixel will collect light from multiple sources, compressive sensing techniques must decouple the spectral profiles of neighboring pixels<br /><br />By incorporating a ToF sensor into a CASSI, we have demonstrated, for the first time, that MS/HS and depth can be observed with a single sensor, and as such, its possible to record these modalities without the processing and corresponding distortion of one modality as it is registered with the other.&nbsp; While a testbed prototype of this combined imaging was developed at the University of Delaware, our work at the University of Kentucky focused on the design and manufacture of a miniaturized ToF CASSI.&nbsp; This design included optical modeling of the associated imaging elements as well as the calibration of said elements and electronic control of the associated components and the processing of captured images to produce the final MS/HS + depth images. As an illustration of our contributions, Fig. 1 shows the optical model of our miniaturized camera that fits inside a 60 mm by 60 mm enclosure and that spans the near-IR light range from 450 to 1050 nm.&nbsp; With this optical design, we have included Fig. 2 that shows a picture of our machine vision camera with HDMI-pass through that can be used to control the digital mirror device of our ToF-CASSI and synchronize the sensor.&nbsp; This PCB interfaces with a Zynq 7000-based microzed-board for which we included our FPGA system diagram.&nbsp; <br /><br />This research effort was carried by undergraduate, MS, and PhD degree students who where recruited to carry out the research.&nbsp; Two of the undergraduate students were from underrepresented groups.&nbsp; Finally, a graduate level compressive sensing course in Electrical and Computer Engineering was offered in the Fall of 2019 at the University of Kentucky by the PI.</p><br> <p>            Last Modified: 12/04/2019<br>      Modified by: Daniel&nbsp;L&nbsp;Lau</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1539157/1539157_10393131_1575501063686_cameraPCBDiagramA--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1539157/1539157_10393131_1575501063686_cameraPCBDiagramA--rgov-800width.jpg" title="Optical Design"><img src="/por/images/Reports/POR/2019/1539157/1539157_10393131_1575501063686_cameraPCBDiagramA--rgov-66x44.jpg" alt="Optical Design"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The (left) design for miniaturized TOF-CASSI system which achieves a tiny footprint (60 ? 60 mm) by using the same prism to couple light to the DMD and to disperse light for hyperspectral imaging and the (right) spot matrix at three field points (on axis and ?25o) for wavelengths ranging from 450 nm</div> <div class="imageCredit">J. Todd Hastings and Daniel Lau</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Daniel&nbsp;L&nbsp;Lau</div> <div class="imageTitle">Optical Design</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1539157/1539157_10393131_1575501115909_cameraPCBDiagramB--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1539157/1539157_10393131_1575501115909_cameraPCBDiagramB--rgov-800width.jpg" title="PCB Design"><img src="/por/images/Reports/POR/2019/1539157/1539157_10393131_1575501115909_cameraPCBDiagramB--rgov-66x44.jpg" alt="PCB Design"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The (left) assembled machine vision camera and HDMI-pass and its (center) corresponding cad design and (right) FPGA system diagram.</div> <div class="imageCredit">Daniel Lau</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Daniel&nbsp;L&nbsp;Lau</div> <div class="imageTitle">PCB Design</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Multispectral and hyperspectral (MS/HS) imaging refer to vision systems that record color in more than three primaries and, typically, involve recording scenes in light wavelengths outside the visible color spectrum such as the near-infrared as well as short and long-wave infrared.  Capturing these wavelengths allows MS/HS cameras to recognize features of objects in terms of their material compositions.  Alternatively, 3D or depth cameras capture the shape and position of objects in a scene.  In the case of time-of-flight (ToF) cameras, depth is determined by indirectly measuring the time it takes light to travel from an emitter or flash source to the target surface and back to the sensor.  To date, MS/HS cameras and ToF imaging has always implied using separate cameras placed side by side such that the MS/HS image can be warped or registered to match the scene as captured by the ToF sensor.  This research focused on using a ToF image sensor in a coded apature spectral snapshop camera which is a MS/HS camera that is modeled after a traditional spectrophotometer and records all wavelengths simultaneously. Here a ray of light emanating from the scene is passed through a series of optical elements culminating in a prism that spreads that single ray of light over a lateral sequence of sensor pixels, in a wavelength dependent manner, just like a spectrophotometer would spread light across a linear array. Allowing for multiple rays of light simultaneously incident upon the sensor means that the camera can resolve a two dimensional image; however, because the spreading of light rays across lateral sequences of pixels means a single pixel will collect light from multiple sources, compressive sensing techniques must decouple the spectral profiles of neighboring pixels  By incorporating a ToF sensor into a CASSI, we have demonstrated, for the first time, that MS/HS and depth can be observed with a single sensor, and as such, its possible to record these modalities without the processing and corresponding distortion of one modality as it is registered with the other.  While a testbed prototype of this combined imaging was developed at the University of Delaware, our work at the University of Kentucky focused on the design and manufacture of a miniaturized ToF CASSI.  This design included optical modeling of the associated imaging elements as well as the calibration of said elements and electronic control of the associated components and the processing of captured images to produce the final MS/HS + depth images. As an illustration of our contributions, Fig. 1 shows the optical model of our miniaturized camera that fits inside a 60 mm by 60 mm enclosure and that spans the near-IR light range from 450 to 1050 nm.  With this optical design, we have included Fig. 2 that shows a picture of our machine vision camera with HDMI-pass through that can be used to control the digital mirror device of our ToF-CASSI and synchronize the sensor.  This PCB interfaces with a Zynq 7000-based microzed-board for which we included our FPGA system diagram.    This research effort was carried by undergraduate, MS, and PhD degree students who where recruited to carry out the research.  Two of the undergraduate students were from underrepresented groups.  Finally, a graduate level compressive sensing course in Electrical and Computer Engineering was offered in the Fall of 2019 at the University of Kentucky by the PI.       Last Modified: 12/04/2019       Submitted by: Daniel L Lau]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
