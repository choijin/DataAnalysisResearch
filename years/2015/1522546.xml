<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Collaborative Research: Software Defined Network Function Virtualization (SDNFV) - Flexible, High Performance Network and Data Center Virtualization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2015</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Darleen Fisher</SignBlockName>
<PO_EMAI>dlfisher@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Traditional computer networks have been built from hardware appliances, such as routers, firewalls, and switches, to implement functionality. These devices can process network packets at high speed, but provide little flexibility since they are based on purpose-built hardware. Recent improvements in multi-core processors and high-speed network interface cards have enabled Network Function Virtualization (NFV), which allows these network components to run instead on commodity compute servers.  NFV makes the network data processing elements run as software, allowing them to be deployed dynamically or easily modified and tuned with changes in network workloads.  At the same time, Software Defined Networking (SDN) has grown in popularity as a way to manage more easily network services by centralizing control plane functions.  This research investigates how the convergence of NFV and SDN can enable a new breed of highly dynamic network services for customers of Internet Service Providers (ISPs), and also grant cloud computing customers far greater control over data center resources.  The work will explore both the software mechanisms needed to support network components running at speeds well beyond 10 Gbps inside of virtual machines, and the algorithms and control architectures required to coordinate these components with high performance and low cost. &lt;br/&gt;&lt;br/&gt;The project targets two application areas for Software Defined Network Function Virtualization (SDNFV). The first is dynamic services for network providers for which the principal investigators (PIs) are developing a SDNFV platform that enables line-rate packet processing within virtual machines by exploiting network interface controller (NIC) polling and shared memory for zero-copy communication. This flexible infrastructure will allow packets to be redirected based on complex policies, packet data, or service state, which is not currently possible in hardware-based solutions.  The second focus area is on cloud computing data centers in which SDNFV will enable cloud data center operators to easily partition and multiplex network resources in the same way they currently virtualize servers and storage devices. In this application area the PIs are developing virtualization-layer trust boundaries that provide strict performance and data isolation, while still permitting the optimizations required for SDNFV?s fast packet processing. They will also study the new resource management and scheduling algorithms required to ensure a group of virtual machine-based network services can meet their strict latency requirements. Finally the PIs will evaluate their ideas by building prototypes and testing them using realistic benchmark workloads and traces.&lt;br/&gt;&lt;br/&gt;The proposed work has the potential to redefine how networks are built and managed, by transitioning away from single-purpose hardware to flexible software-based network components. This research could make the connected, digital world we rely on more efficient and more responsive to workload changes, attacks, and policy decisions.  The research will be paired with an educational program to enhance the networking and distributed systems curriculum at the researchers' institutions. This will help prepare undergraduate, Masters, and Ph.D. students to enter the work force with highly sought-after experience in the latest networking technologies.</AbstractNarration>
<MinAmdLetterDate>12/16/2014</MinAmdLetterDate>
<MaxAmdLetterDate>12/16/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1522546</AwardID>
<Investigator>
<FirstName>Kadangode</FirstName>
<LastName>Ramakrishnan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kadangode Ramakrishnan</PI_FULL_NAME>
<EmailAddress>kkrama84@gmail.com</EmailAddress>
<PI_PHON>9518272480</PI_PHON>
<NSF_ID>000662605</NSF_ID>
<StartDate>12/16/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Riverside</Name>
<CityName>RIVERSIDE</CityName>
<ZipCode>925210217</ZipCode>
<PhoneNumber>9518275535</PhoneNumber>
<StreetAddress>Research &amp; Economic Development</StreetAddress>
<StreetAddress2><![CDATA[245 University Office Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>44</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA44</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>627797426</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Riverside]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>925210001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>41</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA41</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Networks are moving to be more software based, enabling them to be more flexible and nimbler, exploiting the capability of common-off-the-shelf (COTS) platforms to take advantage of their lower cost-performance curve. The overall goal of our project is to better integrate Software Defined Networks (SDN) and Network Function Virtualization (NFV) to create more efficient and powerful networks. We expect more of the traditional (and evolving) network middlebox network functionality will migrate to high-performance NFV middleboxes running in cloud data centers.</p> <p>Our effort has been towards building a "Smart Dataplane", that takes advantage of efficient NFV processing to allow middleboxes to both transform and reroute network flows. To build a smart data plane that is efficient and intelligent enough to make localized decisions, we have been developing new systems techniques that allow software-based networks to perform comparably to traditional hardware devices, and designing new protocols between SDN and NFV.&nbsp;</p> <p>To this end, we have developed the OpenNetVM NFV platform which uses Intel's Data Plane Development Kit (DPDK, whose development and support has since migrated to the Linux Foundation)) for efficient I/O, and Docker lightweight containers to provide the virtualization framework for Network Functions (like deep-packet inspection, caches, firewalls, intrusion detection systems, even switches, etc.). It has been released as an open-source (BSD license) software. This activity has been a joint effort involving both George Washington University and the University of California, Riverside. OpenNetVM provides high-level abstractions on an underlying framework that provides wire-speed performance. OpenNetVM runs network functions in lightweight containers, easily combined to form complex "service chains". &nbsp;The code is available at https://github.com/sdnfv/openNetVM and continues to be updated as we add new features and users report bugs.</p> <p>We have published a total of 18 conference and workshop papers, 3 journal papers, 2 demos, and 2 posters at conferences throughout the project. We have also given a total of 6 tutorials that were given by PI K. K. Ramakrishnan and PI Tim Wood at conferences and other venues. The project also had collaborations with researchers from industry, including those from HP, AT&amp;T, Huawei, IBM, and Intel. A number of other researchers use the OpenNetVM platform for their research, as evidenced by the OpenNetVM Github repository having187 clones, being forked 51 times, and having 7597 total views in the last 6 months. The project supported four Ph.D. students at UC Riverside at various stages (including one that visited for 6 months from Germany) and two M.S. students throughout the project.</p> <p>In this reporting period, we have developed NFVnice that provides primitives for scheduling, and scalability in OpenNetVM, thus enabling automated resource management for NFs. Given flows have different rates and packets of each flow can have varying service requirements, it is important to meet their processing needs in an efficient and fair manner. We seek to achieve both rate and cost proportional fair service for a large number of flows that may be supported by different service chains on a single OpenNetVM platform. We combine an enhanced scheduling algorithm along with a novel backpressure scheme within a system supporting the service chain. NFVNice ensures that resources are not wasted if a downstream NF is the bottleneck in the service chain and packets are dropped. While a major part of this work was published in ACM SIGCOMM 2017, we have continued this work to improve the latency impact of context switching and scheduling multiple NFs on a core. This has helped us understand the benefit of scheduling on the same core to derive the benefit of cache hits. On the other hand, when the processing on a CPU core is a bottleneck, it is better to allocate the NFs on different cores.</p> <p>In this reporting period, we have also used the OpenNetVM platform to implement a re-architected version of the Evolved Packet Core for next generation cellular networks.&nbsp; The current cellular architecture and protocols are complex, with a number of different entities (mobile device, base station, the packet gateways and mobility management) involved in setting up forwarding state for every session, and every flow ('bearer') across multiple entities in a consistent manner. With the use of smaller cell-sites with the next generation cellular technology (beyond 5G), user mobility will involve more frequent hand-offs. Further, there will be increased use of control messages for supporting Internet of Things traffic. We proposed CleanG, a simplified software-based architecture for the Evolved Packet Core (EPC) that consolidates the EPC control functions and enables a simplified control plane protocol, substantially reducing the number of control messages. CleanG exploits Network Function Virtualization to simplify the EPC architecture and allows dynamic management of capacity for the control plane to adapt to changing workloads. We have published 2 workshop papers and one conference paper is under submission.</p><br> <p>            Last Modified: 12/25/2018<br>      Modified by: Kadangode&nbsp;Ramakrishnan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Networks are moving to be more software based, enabling them to be more flexible and nimbler, exploiting the capability of common-off-the-shelf (COTS) platforms to take advantage of their lower cost-performance curve. The overall goal of our project is to better integrate Software Defined Networks (SDN) and Network Function Virtualization (NFV) to create more efficient and powerful networks. We expect more of the traditional (and evolving) network middlebox network functionality will migrate to high-performance NFV middleboxes running in cloud data centers.  Our effort has been towards building a "Smart Dataplane", that takes advantage of efficient NFV processing to allow middleboxes to both transform and reroute network flows. To build a smart data plane that is efficient and intelligent enough to make localized decisions, we have been developing new systems techniques that allow software-based networks to perform comparably to traditional hardware devices, and designing new protocols between SDN and NFV.   To this end, we have developed the OpenNetVM NFV platform which uses Intel's Data Plane Development Kit (DPDK, whose development and support has since migrated to the Linux Foundation)) for efficient I/O, and Docker lightweight containers to provide the virtualization framework for Network Functions (like deep-packet inspection, caches, firewalls, intrusion detection systems, even switches, etc.). It has been released as an open-source (BSD license) software. This activity has been a joint effort involving both George Washington University and the University of California, Riverside. OpenNetVM provides high-level abstractions on an underlying framework that provides wire-speed performance. OpenNetVM runs network functions in lightweight containers, easily combined to form complex "service chains".  The code is available at https://github.com/sdnfv/openNetVM and continues to be updated as we add new features and users report bugs.  We have published a total of 18 conference and workshop papers, 3 journal papers, 2 demos, and 2 posters at conferences throughout the project. We have also given a total of 6 tutorials that were given by PI K. K. Ramakrishnan and PI Tim Wood at conferences and other venues. The project also had collaborations with researchers from industry, including those from HP, AT&amp;T, Huawei, IBM, and Intel. A number of other researchers use the OpenNetVM platform for their research, as evidenced by the OpenNetVM Github repository having187 clones, being forked 51 times, and having 7597 total views in the last 6 months. The project supported four Ph.D. students at UC Riverside at various stages (including one that visited for 6 months from Germany) and two M.S. students throughout the project.  In this reporting period, we have developed NFVnice that provides primitives for scheduling, and scalability in OpenNetVM, thus enabling automated resource management for NFs. Given flows have different rates and packets of each flow can have varying service requirements, it is important to meet their processing needs in an efficient and fair manner. We seek to achieve both rate and cost proportional fair service for a large number of flows that may be supported by different service chains on a single OpenNetVM platform. We combine an enhanced scheduling algorithm along with a novel backpressure scheme within a system supporting the service chain. NFVNice ensures that resources are not wasted if a downstream NF is the bottleneck in the service chain and packets are dropped. While a major part of this work was published in ACM SIGCOMM 2017, we have continued this work to improve the latency impact of context switching and scheduling multiple NFs on a core. This has helped us understand the benefit of scheduling on the same core to derive the benefit of cache hits. On the other hand, when the processing on a CPU core is a bottleneck, it is better to allocate the NFs on different cores.  In this reporting period, we have also used the OpenNetVM platform to implement a re-architected version of the Evolved Packet Core for next generation cellular networks.  The current cellular architecture and protocols are complex, with a number of different entities (mobile device, base station, the packet gateways and mobility management) involved in setting up forwarding state for every session, and every flow ('bearer') across multiple entities in a consistent manner. With the use of smaller cell-sites with the next generation cellular technology (beyond 5G), user mobility will involve more frequent hand-offs. Further, there will be increased use of control messages for supporting Internet of Things traffic. We proposed CleanG, a simplified software-based architecture for the Evolved Packet Core (EPC) that consolidates the EPC control functions and enables a simplified control plane protocol, substantially reducing the number of control messages. CleanG exploits Network Function Virtualization to simplify the EPC architecture and allows dynamic management of capacity for the control plane to adapt to changing workloads. We have published 2 workshop papers and one conference paper is under submission.       Last Modified: 12/25/2018       Submitted by: Kadangode Ramakrishnan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
