<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Collaborative Research: Resilient Computing Systems Using Deep Learning Techniques</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>234959.00</AwardTotalIntnAmount>
<AwardAmount>234959</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yuanyuan Yang</SignBlockName>
<PO_EMAI>yyang@nsf.gov</PO_EMAI>
<PO_PHON>7032928067</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Over the past decade, computer systems have become prone to a variety of hardware failures. Traditionally, hardware failures were circumvented by operating the system at less than peak computing efficiency, effectively compromising efficiency to achieve reliability. Such a conservative approach is no longer a viable option because it leads to significant energy inefficiency. Since datacenters containing thousands of computers are one of the largest and fastest growing consumers of electricity, it is important to decouple the relationship between hardware failures and energy efficiency. &lt;br/&gt;&lt;br/&gt;The PIs' research will lay the groundwork for an intelligent computing system that operates at peak efficiency, but manages its fault resiliency and reliability using machine-learning based deep learning techniques. In effect, the system learns to steer itself clear of danger whenever its deep neural nets anticipate a failure. The research will address several important issues involving the scalability, flexibility and efficiency of deep learning techniques for various types of hardware failures. If successful, the research product will minimize, if not eliminate, penalties to the system that stem from the various circuit and micro-architectural techniques that are commonly used to mitigate and overcome hardware failures.</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526399</AwardID>
<Investigator>
<FirstName>Sek</FirstName>
<LastName>Chai</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Ph.D</PI_SUFX_NAME>
<PI_FULL_NAME>Sek Chai</PI_FULL_NAME>
<EmailAddress>sek.chai@sri.com</EmailAddress>
<PI_PHON>6097342317</PI_PHON>
<NSF_ID>000664384</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SRI International</Name>
<CityName>Menlo Park</CityName>
<ZipCode>940253493</ZipCode>
<PhoneNumber>7032478529</PhoneNumber>
<StreetAddress>333 RAVENSWOOD AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009232752</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SRI INTERNATIONAL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009232752</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SRI International]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085406449</ZipCode>
<StreetAddress><![CDATA[201 Washington Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~234959</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our main contribution is the development of an approach to processor design using deep learning techniques to learn processor data as a time-series representation. Much like natural language processing (NLP), processor data can be treated as a language, with similar mechanisms for sentence completion based on a learnt vocabulary. Such an approach supports a fully data-driven methodology for processor design, with affordance to learn and predict processor events. We show comparisons using several deep learning models with promising simulation results.</p> <p>Our original goal was to study the use of deep learning algorithms to predict voltage emergencies. By considering voltage emergencies more generically as processor events, we are able to take a broader view on our approach beyond just hardware fault detection. In doing so, we focused on developing deep learning algorithms to learn any processor behavior. We show that our methodology can learn complex processor behaviors using &ldquo;raw&rdquo; processor signal data (e.g. instruction type, buffer fill, etc.) from the processor. We were also able to predict future internal state of the processor using advance deep learning techniques.</p> <p>Our work enables deep learning tools for computer architects. The tools act as a force multiplier, enabling machine analysis at the semantic level, to affect more premised designs. From this perspective, we make the workforce more efficient and effective. That is, to maintain Moore&rsquo;s Law and address Dennard Scaling, we provide additional tools for the architects to sustain processor performance growth, by making the human workforce efficient. Furthermore, our work also enables more efficient processors because our deep learning approach can analyze more complex interactions. Towards that end, processors designed to be more power efficient, and able to sustain greener footprint in the long term.</p> <p>The project has brought together both computer architecture and machine learning domains. There has been a recent push in research of making deep learning processing efficient, but there is a disproportionate amount of research using deep networks for computing. Our results demonstrate that deep learning can be applied to the computer designs itself, e.g. deep learning <strong>for</strong> computer design, rather than the other way around.</p><br> <p>            Last Modified: 10/14/2018<br>      Modified by: Sek&nbsp;Chai</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our main contribution is the development of an approach to processor design using deep learning techniques to learn processor data as a time-series representation. Much like natural language processing (NLP), processor data can be treated as a language, with similar mechanisms for sentence completion based on a learnt vocabulary. Such an approach supports a fully data-driven methodology for processor design, with affordance to learn and predict processor events. We show comparisons using several deep learning models with promising simulation results.  Our original goal was to study the use of deep learning algorithms to predict voltage emergencies. By considering voltage emergencies more generically as processor events, we are able to take a broader view on our approach beyond just hardware fault detection. In doing so, we focused on developing deep learning algorithms to learn any processor behavior. We show that our methodology can learn complex processor behaviors using "raw" processor signal data (e.g. instruction type, buffer fill, etc.) from the processor. We were also able to predict future internal state of the processor using advance deep learning techniques.  Our work enables deep learning tools for computer architects. The tools act as a force multiplier, enabling machine analysis at the semantic level, to affect more premised designs. From this perspective, we make the workforce more efficient and effective. That is, to maintain Moore?s Law and address Dennard Scaling, we provide additional tools for the architects to sustain processor performance growth, by making the human workforce efficient. Furthermore, our work also enables more efficient processors because our deep learning approach can analyze more complex interactions. Towards that end, processors designed to be more power efficient, and able to sustain greener footprint in the long term.  The project has brought together both computer architecture and machine learning domains. There has been a recent push in research of making deep learning processing efficient, but there is a disproportionate amount of research using deep networks for computing. Our results demonstrate that deep learning can be applied to the computer designs itself, e.g. deep learning for computer design, rather than the other way around.       Last Modified: 10/14/2018       Submitted by: Sek Chai]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
