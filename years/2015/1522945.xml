<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: Promoting Learning through Annotation of Embodiment (PLAE)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>554030.00</AwardTotalIntnAmount>
<AwardAmount>554030</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Russell</SignBlockName>
<PO_EMAI>rlrussel@nsf.gov</PO_EMAI>
<PO_PHON>7032922995</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The Cyberlearning and Future Learning Technologies Program funds efforts that will help envision the next generation of learning technologies and advance what we know about how people learn in technology-rich environments. Cyberlearning Exploration (EXP) Projects explore the viability of new kinds of learning technologies by designing and building new kinds of learning technologies and studying their possibilities for fostering learning and challenges to using them effectively. The Promoting Learning through Annotation of Embodiment (PLAE) project will research how new motion-tracking technologies and augmented reality can be adapted to support young children's science learning in the classroom. Embodied resources - gesture, physical motion, and one's location in space - are increasingly recognized as important modalities for students to engage and better understand science and mathematics concepts. However, these embodied resources need to be connected to other intellectual resources more readily recognized by school-notation systems, mathematical equations, graphs, and scientific vocabulary. The project will investigate how the ability to label, identify, and view key elements of activity within augmented reality learning environments support student reflection on scientific content in the physical sciences.  Project research will help develop the foundations for the application of technology systems employing embodied resources combined with annotation to support children's learning of basic science concepts. Because of the popularity of motion-tracking interfaces for commercial computer gaming (e.g. the Xbox Kinect and Wii), the capabilities of less expensive motion-tracking systems are rapidly advancing to the point where practical classroom applications can be developed in the near future.&lt;br/&gt;&lt;br/&gt;The project will research how annotations of embodied play simulations in an augmented reality environment can direct student attention towards key scientific concepts while providing them with opportunities to reflect upon and revise their understanding of those concepts. After development and pilot testing of the system, students will be assigned to one of two conditions that involve either: (1) all student-generated annotations or (2) all teacher- and researcher-created annotations. By contrasting these two models, the project will be able to explore in detail the role of annotation in supporting students' reflection within embodied modeling activities, and to further demonstrate the value that is added by allowing students to design and negotiate their own annotations. There will be two main sources of data for each of the experiments: (1) a pre-post content measure to assess overall growth in student understanding of the particulate nature of matter, and (2) project coding and analysis of videos of student activity to analyze the types of learning processes promoted by the technology and curriculum, with a focus on how the annotation features support reflection about the underlying rules of the system. The results of this research will inform the design of future educational technologies which rely upon embodied motion.</AbstractNarration>
<MinAmdLetterDate>08/25/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/25/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1522945</AwardID>
<Investigator>
<FirstName>Ben</FirstName>
<LastName>Loh</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ben T Loh</PI_FULL_NAME>
<EmailAddress>ben@inquirium.net</EmailAddress>
<PI_PHON>7732208889</PI_PHON>
<NSF_ID>000470394</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Noel</FirstName>
<LastName>Enyedy</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Noel D Enyedy</PI_FULL_NAME>
<EmailAddress>noel.d.enyedy@vanderbilt.edu</EmailAddress>
<PI_PHON>6153438833</PI_PHON>
<NSF_ID>000451380</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Brown</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew W Brown</PI_FULL_NAME>
<EmailAddress>matt@inquirium.net</EmailAddress>
<PI_PHON>7737430679</PI_PHON>
<NSF_ID>000295832</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Burke</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeffrey A Burke</PI_FULL_NAME>
<EmailAddress>jburke@ucla.edu</EmailAddress>
<PI_PHON>3107945358</PI_PHON>
<NSF_ID>000449994</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Joshua</FirstName>
<LastName>Danish</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joshua A Danish</PI_FULL_NAME>
<EmailAddress>jdanish@indiana.edu</EmailAddress>
<PI_PHON>8128568330</PI_PHON>
<NSF_ID>000528547</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474051005</ZipCode>
<StreetAddress><![CDATA[201 North Rose Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7645</Code>
<Text>Discovery Research K-12</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8244</Code>
<Text>EHR CL Opportunities (NSF 14-302)</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0415</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~554030</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-32f9c0ad-7fff-1a8a-8a1c-ed109c4c0072"> <p dir="ltr"><strong>Intellectual merit</strong><span><strong>:</strong> We have long known that the body is an important part of how we think and learn. This has led to a rise in learning designs that leverage technology to support content learning by enhancing students&rsquo; embodied play activities so students gain new insights into the content they are studying. For example, when a student in our learning environment pretends to be a water particle, the software tracks their motion so they see an avatar of a water particle on the screen. If two students do this and stand near each other, they see that two water particles that are a medium distance but not moving might make ice. If they begin moving quickly, they will see how this movement is related to articles that make up a gas when they see thin red lines connecting their avatars on-screen, and a &ldquo;state meter&rdquo; indicating that they are now a gas. Because they are moving and moving quickly, we have demonstrated that this helps them connect the ideas of particle motion, speed, and energy to states of matter.</span></p> <p dir="ltr"><span><span> </span></span><span>However, many embodied learning experiences are designed for only a small number of students, making it difficult for them to be deployed in classroom contexts. One goal of our work has been to extend this kind of experience to increasingly larger groups of students so that classroom implementations are possible.&nbsp; The PLAE project aimed to support this move by exploring how students might be supported in observing their peers&rsquo; embodied activities by using an iPad interface to annotate the embodied simulation as it takes place, thus supporting further reflection. This way, while part of the class is pretending to be water particles to learn about states of matter, part of the class is watching this, while indicating on their iPad how quickly the particles are moving. This serves two purposes: 1) it helps students to attend to the importance of speed in understanding states of matter, and 2) it provides opportunities for the teacher to guide the students in revisiting their embodied activities to discuss their import. For example, the teacher might point out that observers had used their iPad to indicate that many students were moving quickly about &frac12; way into the simulation. Rewinding the simulation to this point the whole class can see that they were moving quickly, and that the software indicates that this means they were producing a gas, helping the students to reflect on the relationship between speed of particles and state of matter.</span></p> <p dir="ltr"><span><span> </span></span><span>We implemented these tools in classrooms exploring both the states of matter and honeybees collecting nectar. Generally, we found that students used the provided annotations effectively to attend to how their peers were embodying the content. In addition, we found that there were benefits to both guidance about what to represent (students had similar, comparable representations targeting a key feature), and allowing students to choose their own focus (students noticed new patterns that they could share with their peers, that the teachers might not have been attending to). Similarly, we found that free drawing was engaging, but often led students to focus on a single state whereas using buttons to indicate a key moment helped them to attend to those moments. We also found that students benefited from being assigned a specific peer to track rather than being asked to represent the classroom as a whole. Finally, we noticed students struggled with being asked to represent discrete moments (e.g., when a particle shifted from slow to fast) but instead appeared inclined to try and use the iPad interface to represent ideas in an embodied manner - clicking frequently to represent high speed, and slowly to represent a decline in speed. This suggests a new avenue for future design where we incorporate embodiment in our annotations to further engage students in observing and annotating their peers&rsquo; work.&nbsp;</span></p> <p dir="ltr"><span>Our findings demonstrate that it is possible to support a full classroom of students in engaging in embodied learning activities by asking them to alternate between participating and observing their peers&rsquo; participation, and that annotation tools tied to the computer simulation are a promising approach to help students to attend to the concepts they are learning about through embodiment.</span></p> <strong>Broader impact</strong><span><strong>:</strong> While embodied learning is quite powerful, it has been limited in how it has been taken up in part because it is challenging to support more than 1-2 students in embodied learning activities with the current commercial options available. This work demonstrates that it is possible to support classroom-level implementations in new ways, helping to increase the likelihood that students can benefit from these technologies in the future. We have further demonstrated an approach using annotation and observation that can help teachers and students to engage with whole classrooms in learning through this promising avenue.</span></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 03/27/2020<br>      Modified by: Joshua&nbsp;A&nbsp;Danish</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Intellectual merit: We have long known that the body is an important part of how we think and learn. This has led to a rise in learning designs that leverage technology to support content learning by enhancing students’ embodied play activities so students gain new insights into the content they are studying. For example, when a student in our learning environment pretends to be a water particle, the software tracks their motion so they see an avatar of a water particle on the screen. If two students do this and stand near each other, they see that two water particles that are a medium distance but not moving might make ice. If they begin moving quickly, they will see how this movement is related to articles that make up a gas when they see thin red lines connecting their avatars on-screen, and a "state meter" indicating that they are now a gas. Because they are moving and moving quickly, we have demonstrated that this helps them connect the ideas of particle motion, speed, and energy to states of matter.  However, many embodied learning experiences are designed for only a small number of students, making it difficult for them to be deployed in classroom contexts. One goal of our work has been to extend this kind of experience to increasingly larger groups of students so that classroom implementations are possible.  The PLAE project aimed to support this move by exploring how students might be supported in observing their peers’ embodied activities by using an iPad interface to annotate the embodied simulation as it takes place, thus supporting further reflection. This way, while part of the class is pretending to be water particles to learn about states of matter, part of the class is watching this, while indicating on their iPad how quickly the particles are moving. This serves two purposes: 1) it helps students to attend to the importance of speed in understanding states of matter, and 2) it provides opportunities for the teacher to guide the students in revisiting their embodied activities to discuss their import. For example, the teacher might point out that observers had used their iPad to indicate that many students were moving quickly about &frac12; way into the simulation. Rewinding the simulation to this point the whole class can see that they were moving quickly, and that the software indicates that this means they were producing a gas, helping the students to reflect on the relationship between speed of particles and state of matter.  We implemented these tools in classrooms exploring both the states of matter and honeybees collecting nectar. Generally, we found that students used the provided annotations effectively to attend to how their peers were embodying the content. In addition, we found that there were benefits to both guidance about what to represent (students had similar, comparable representations targeting a key feature), and allowing students to choose their own focus (students noticed new patterns that they could share with their peers, that the teachers might not have been attending to). Similarly, we found that free drawing was engaging, but often led students to focus on a single state whereas using buttons to indicate a key moment helped them to attend to those moments. We also found that students benefited from being assigned a specific peer to track rather than being asked to represent the classroom as a whole. Finally, we noticed students struggled with being asked to represent discrete moments (e.g., when a particle shifted from slow to fast) but instead appeared inclined to try and use the iPad interface to represent ideas in an embodied manner - clicking frequently to represent high speed, and slowly to represent a decline in speed. This suggests a new avenue for future design where we incorporate embodiment in our annotations to further engage students in observing and annotating their peers’ work.  Our findings demonstrate that it is possible to support a full classroom of students in engaging in embodied learning activities by asking them to alternate between participating and observing their peers’ participation, and that annotation tools tied to the computer simulation are a promising approach to help students to attend to the concepts they are learning about through embodiment. Broader impact: While embodied learning is quite powerful, it has been limited in how it has been taken up in part because it is challenging to support more than 1-2 students in embodied learning activities with the current commercial options available. This work demonstrates that it is possible to support classroom-level implementations in new ways, helping to increase the likelihood that students can benefit from these technologies in the future. We have further demonstrated an approach using annotation and observation that can help teachers and students to engage with whole classrooms in learning through this promising avenue.          Last Modified: 03/27/2020       Submitted by: Joshua A Danish]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
