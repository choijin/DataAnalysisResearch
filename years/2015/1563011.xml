<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: CSR: Medium: Collaborative Research: Enabling Flexible and High Performance Big Data Analytics Over Geo-Distributed Clouds</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2016</AwardEffectiveDate>
<AwardExpirationDate>05/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Large organizations and small enterprises alike leverage datacenters across the globe to offer Internet services to their users. These sites routinely gather data pertaining to end user activities to provide better services, and they collect server monitoring logs and performance counters to ensure uninterrupted service. Although fast, efficient, and cost-effective analyses of these large datasets can significantly improve users' quality of experience and enable novel applications, the wide area network (WAN) that connects the datacenters poses a considerable challenge: because WAN bandwidth is limited and expensive, and WAN latency is high and variable, both the performance and timeliness of analytics are affected by the WAN.&lt;br/&gt;&lt;br/&gt;This project aims to build a new WAN-aware big data stack customized for flexible geo-distributed data analytics. The project will not impose any constraints on the set of queries that can be issued, and it will support a variety of performance objectives including obtaining timely responses, minimizing batch completion times, or using minimal bandwidth. To account for unpredictable and fine-timescale changes to WAN conditions and to enable coordination among the actions taken by different layers of the analytics stack, this project will enable holistic, cross-layer visibility and optimizations. It will incorporate awareness of the geo-distributed setting in the stack's upper layers (e.g., query optimization) and of application-level objectives in the lower layers (e.g., networking). This will result in a radical re-factoring of the API and interfaces between query optimization, query execution, resource negotiation, wide-area storage, and network routing/scheduling.&lt;br/&gt;&lt;br/&gt;Software artifacts from this project will be incorporated into existing open source big data stacks, making the research outcomes broadly available for public reuse. The experimental harnesses will be made available to ensure repeatability and to foster follow up research. The research outcomes will guide industry evolution as the industry slowly shifts from single-datacenter to geo-distributed settings. The project has a substantial educational component involving the introduction of new courses on big data systems at both graduate and undergraduate levels that will involve hands-on exercises with state-of-the-art big data software, and it will reach out to high-school students, women, and underrepresented minorities through big data boot camps.</AbstractNarration>
<MinAmdLetterDate>05/17/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/16/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1563011</AwardID>
<Investigator>
<FirstName>Aditya</FirstName>
<LastName>Akella</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Aditya Akella</PI_FULL_NAME>
<EmailAddress>akella@cs.utexas.edu</EmailAddress>
<PI_PHON>4128183779</PI_PHON>
<NSF_ID>000204197</NSF_ID>
<StartDate>05/17/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Wisconsin-Madison</Name>
<CityName>MADISON</CityName>
<ZipCode>537151218</ZipCode>
<PhoneNumber>6082623822</PhoneNumber>
<StreetAddress>21 North Park Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 6401]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>161202122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WISCONSIN SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041188822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Wisconsin-Madison]]></Name>
<CityName/>
<StateCode>WI</StateCode>
<ZipCode>537061000</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~186713</FUND_OBLG>
<FUND_OBLG>2018~105451</FUND_OBLG>
<FUND_OBLG>2019~107836</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Large organizations and small enterprises alike are leveraging datacenters and edge clusters across the globe to offer services to their users. These sites routinely gather data pertaining to end users' sessions, server monitoring logs, and various performance counters.&nbsp; If this data can be analyzed and personalized in a fast, efficient, and cost-effective manner, it can provide tremendous value both by improving users' quality of experience when accessing services, and by enabling novel applications.&nbsp;&nbsp;</p> <p><br />Unfortunately, the traditional model of transferring all pertinent data to a single datacenter and analyzing them using standard single-datacenter analytics stacks like Hadoop or Spark is severely constraining in&nbsp; this geo-distributed context.&nbsp; This is because wide-area network&nbsp; (WAN) bandwidth is limited, expensive, and variable, which can impact the performance and timeliness of analytics, and regulatory constraints can prohibit raw data movements altogether.</p> <p><br />In this project, we built a first-of-a-kind big data stack customized for flexible geo-distributed data analytics. Flexibility implies that there are no constraints on the set of queries that applications can issue, and applications must be able to meet a variety of strict performance objectives including obtaining timely responses, minimizing batch completion times, or using minimal bandwidth, and adhere to various applicable regulatory constraints.&nbsp; The main challenges we overcame in realizing this vision are accounting for unpredictable and fine-timescale changes to the bandwidth and latency of WAN links connecting different sites, dealing with significant churn and diversity in the active queries, and ensuring coordination among the actions taken by different layers of the analytics stack. Our&nbsp;stack relies on holistic, cross-layer visibility and optimizations, and incorporates awareness of the geo-distributed setting in the stack's upper layers and of application-level objectives in the lower layers.&nbsp; Two key design&nbsp; principles guided our research were: (i) late binding, which allows decisions to be delayed until they must be acted upon, and (ii) dynamic adaptation, whereby ongoing actions can be drastically modified to react to sudden variations.</p> <p><br />Intellectual Merit:<br />The project enabled high performance geo-distributed analytics of large datasets, an increasingly important workload. It lead to fundamental algorithmic contributions toward bringing awareness of WAN characteristics and application objectives throughout big data stacks.&nbsp; It also resulted in a re-factoring of the APIs among the different layers of big data stacks today to enable cross-layer optimizations.&nbsp;&nbsp;</p> <p><br />Broader Impact:</p> <p><br />The PIs incorporated software from the project into existing open source big data stacks, making the research outcomes broadly available for public reuse.&nbsp; The PIs also made their experimental harnesses available as public images on CloudLab, thereby ensuring repeatability.&nbsp; The PIs ntroduced new courses on big data systems at both graduate and undergraduate levels that involved hands-on exercises with state of-the-art big data software. The PIs organized big data boot camps aimed at students from high-schools and under-represented universities.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/28/2020<br>      Modified by: Srinivasa&nbsp;A&nbsp;Akella</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Large organizations and small enterprises alike are leveraging datacenters and edge clusters across the globe to offer services to their users. These sites routinely gather data pertaining to end users' sessions, server monitoring logs, and various performance counters.  If this data can be analyzed and personalized in a fast, efficient, and cost-effective manner, it can provide tremendous value both by improving users' quality of experience when accessing services, and by enabling novel applications.     Unfortunately, the traditional model of transferring all pertinent data to a single datacenter and analyzing them using standard single-datacenter analytics stacks like Hadoop or Spark is severely constraining in  this geo-distributed context.  This is because wide-area network  (WAN) bandwidth is limited, expensive, and variable, which can impact the performance and timeliness of analytics, and regulatory constraints can prohibit raw data movements altogether.   In this project, we built a first-of-a-kind big data stack customized for flexible geo-distributed data analytics. Flexibility implies that there are no constraints on the set of queries that applications can issue, and applications must be able to meet a variety of strict performance objectives including obtaining timely responses, minimizing batch completion times, or using minimal bandwidth, and adhere to various applicable regulatory constraints.  The main challenges we overcame in realizing this vision are accounting for unpredictable and fine-timescale changes to the bandwidth and latency of WAN links connecting different sites, dealing with significant churn and diversity in the active queries, and ensuring coordination among the actions taken by different layers of the analytics stack. Our stack relies on holistic, cross-layer visibility and optimizations, and incorporates awareness of the geo-distributed setting in the stack's upper layers and of application-level objectives in the lower layers.  Two key design  principles guided our research were: (i) late binding, which allows decisions to be delayed until they must be acted upon, and (ii) dynamic adaptation, whereby ongoing actions can be drastically modified to react to sudden variations.   Intellectual Merit: The project enabled high performance geo-distributed analytics of large datasets, an increasingly important workload. It lead to fundamental algorithmic contributions toward bringing awareness of WAN characteristics and application objectives throughout big data stacks.  It also resulted in a re-factoring of the APIs among the different layers of big data stacks today to enable cross-layer optimizations.     Broader Impact:   The PIs incorporated software from the project into existing open source big data stacks, making the research outcomes broadly available for public reuse.  The PIs also made their experimental harnesses available as public images on CloudLab, thereby ensuring repeatability.  The PIs ntroduced new courses on big data systems at both graduate and undergraduate levels that involved hands-on exercises with state of-the-art big data software. The PIs organized big data boot camps aimed at students from high-schools and under-represented universities.          Last Modified: 07/28/2020       Submitted by: Srinivasa A Akella]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
