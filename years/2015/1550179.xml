<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: New Directions for Metric Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/07/2015</AwardEffectiveDate>
<AwardExpirationDate>02/28/2018</AwardExpirationDate>
<AwardTotalIntnAmount>211313.00</AwardTotalIntnAmount>
<AwardAmount>211313</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Quantifying similarity is a fundamental challenge in artificial intelligence and machine learning which - if performed perfectly - would reduce many tasks to a trivial nearest neighbor search. For example, determining whether an email were spam would be as simple as searching a labeled database of emails and assigning it the same label (spam or not) as the email considered most similar to it. But how can one measure the similarity of two email messages? Does the same measurement still apply when comparing medical images? How does our understanding of similarity depend on the problem specification? Metric learning optimizes distance functions specifically for a given task, taking into account both the learning problem and the data. Initial successes with linear metrics show great improvements on many "k-nearest neighbors"-based learning tasks. &lt;br/&gt;&lt;br/&gt;This project pursues four research directions that strengthen the theoretical understanding of metric learning within the research community, broaden its impact and significantly improve the current state-of-the-art: &lt;br/&gt;&lt;br/&gt;1. Are there non-linear transformations that lead to equally elegant and efficient optimization problems as existing linear metrics? As data sets grow and become increasingly complex, linear metrics are no longer sufficient to capture similarity relations. By exploring the use of non-linear metrics, this research can substantially improve the impact of metric learning and the accuracy of similarity relations. &lt;br/&gt;&lt;br/&gt;2. Can the impact of metric learning be extended to machine learning frameworks beyond nearest neighbors? Designing new metric learning algorithms that explicitly optimize distances for a broad variety of machine learning algorithms will significantly increase the number of applications and learning methods that can directly benefit from metric learning. &lt;br/&gt;&lt;br/&gt;3. Can metrics be learned from weak supervision? Removing the dependency on labeled data will reduce the cost of metric learning and increase its applicability. &lt;br/&gt;&lt;br/&gt;4. Can one develop a solid theoretical framework to explain preliminary empirical successes and to direct future research? This will strengthen the theoretical understanding of metric learning within the research community. &lt;br/&gt;&lt;br/&gt;Successful resolution of the proposed problems will lead to novel learning methods which will be immediately applicable to ongoing high-impact medical research collaborations of the principal investigator. In conjunction with these research directions, the principal investigator will also pursue educational goals, including the co-development of a K-12 curriculum module estimated to impact 2,500 high-school students. Many topics in the proposed research plan have components ideal for introducing the research process to undergraduate and graduate students, and the principal investigator plans to use his research as a vehicle to instruct and inspire future computer scientists and next-generation researchers.</AbstractNarration>
<MinAmdLetterDate>09/22/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/22/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1550179</AwardID>
<Investigator>
<FirstName>Kilian</FirstName>
<LastName>Weinberger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kilian Weinberger</PI_FULL_NAME>
<EmailAddress>kilianweinberger@cornell.edu</EmailAddress>
<PI_PHON>6072550983</PI_PHON>
<NSF_ID>000576980</NSF_ID>
<StartDate>09/22/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148537501</ZipCode>
<StreetAddress><![CDATA[402 Gates hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~38076</FUND_OBLG>
<FUND_OBLG>2015~173237</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This grant has funded research in metric learning. Metric learning is a fundamental part of artificial intelligence and a crucial component of comparing data instances. The research funded by this grant was focused on refining and improving such similarities as an algorithm is exposed to more data. Outcomes of this research span many different sub areas of artificial intelligence.The PI and his students investigated how novel machine learning algorithms can be used to learn metrics, especially, if the data lies on nonlinear manifolds. &nbsp;The work on nonlinear metric learning combines results in gradient boosting with metric learning and introduces highly effective metrics for histogram data. &nbsp;It has also led to the development of any-time metrics, &nbsp;distances that can be improved if more computation time is available.&nbsp;In artificial intelligence, the work funded by this grant has given rise to new heuristics that speed up search problems dramatically. In particular, the distance to a goal in a complicated search space is approximated by a Euclidean distance in a much simpler (learned) space. &nbsp;The authors show that in many cases search spaces can be embedded into much simpler and low dimensional Euclidean spaces with strong guarantees.&nbsp;In natural language processing, the grant has led to new innovations on how to compare text documents with each other. One of the proposed methods, the word mover's distance, represents words in low dimensional spaces and computes distances between documents as the minimum distance that all words from one document have to traverse to reach words from the other document.&nbsp;In computer vision this grant has funded research in representational learning through convolutional neural networks. This research has resulted in a new connectivity pattern, named density connected convolutional neural networks. Densely connected convolutional neural networks tend to be more accurate and far more parameter efficient then there layer by layer connected counterparts.&nbsp;<br />On the educational front, this grant has funded the development of a high school module &nbsp;to playfully explain higher math concepts to high school seniors. &nbsp;It also helped support four PhD thesis and the development of a popular machine learning undergraduate course, now taught at Washington University in St. Louis and Cornell University.&nbsp;</p><br> <p>            Last Modified: 05/29/2018<br>      Modified by: Kilian&nbsp;Weinberger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This grant has funded research in metric learning. Metric learning is a fundamental part of artificial intelligence and a crucial component of comparing data instances. The research funded by this grant was focused on refining and improving such similarities as an algorithm is exposed to more data. Outcomes of this research span many different sub areas of artificial intelligence.The PI and his students investigated how novel machine learning algorithms can be used to learn metrics, especially, if the data lies on nonlinear manifolds.  The work on nonlinear metric learning combines results in gradient boosting with metric learning and introduces highly effective metrics for histogram data.  It has also led to the development of any-time metrics,  distances that can be improved if more computation time is available. In artificial intelligence, the work funded by this grant has given rise to new heuristics that speed up search problems dramatically. In particular, the distance to a goal in a complicated search space is approximated by a Euclidean distance in a much simpler (learned) space.  The authors show that in many cases search spaces can be embedded into much simpler and low dimensional Euclidean spaces with strong guarantees. In natural language processing, the grant has led to new innovations on how to compare text documents with each other. One of the proposed methods, the word mover's distance, represents words in low dimensional spaces and computes distances between documents as the minimum distance that all words from one document have to traverse to reach words from the other document. In computer vision this grant has funded research in representational learning through convolutional neural networks. This research has resulted in a new connectivity pattern, named density connected convolutional neural networks. Densely connected convolutional neural networks tend to be more accurate and far more parameter efficient then there layer by layer connected counterparts.  On the educational front, this grant has funded the development of a high school module  to playfully explain higher math concepts to high school seniors.  It also helped support four PhD thesis and the development of a popular machine learning undergraduate course, now taught at Washington University in St. Louis and Cornell University.        Last Modified: 05/29/2018       Submitted by: Kilian Weinberger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
