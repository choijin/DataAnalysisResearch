<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Towards Interactive Data Visualization Management Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>266000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Interactive visualizations are a powerful way to explore and draw insights from data. As the data available to practitioners continues to grow in complexity and size, existing systems find it harder and harder to maintain a highly interactive experience. The goal of this project is to develop an interactive visual data exploration system designed and optimized to take human perception into account. The aim of this research is to model human perception as perceptual functions. These functions help the system avoid unnecessarily computing visualization results that are more accurate than what can be perceived by the end user. By developing and using these functions, the system can provide highly accurate yet interactive visualizations for large datasets in domains such as business intelligence, data-driven sciences, and healthcare analytics.  In addition, research results from these efforts will contribute towards the development of new curriculum topics at the graduate level.&lt;br/&gt;&lt;br/&gt;A commonly overlooked element of interactive visualization systems is the human in the loop. Although data sizes and computational capabilities have dramatically increased over time, human perceptual limits have remained relatively constant. Although previous work has presented guidelines for effective animations [Heer et al., VCG 2007; Fisher et al., ICGA 2012] and projects such as M4 [Jugel et al., VLDB 2014] used perceptual insights to justify approximation algorithms, our goal is to build a multi-layered data analysis system that unifies interactive visualization clients with backend data management systems, and explicitly takes human perceptual models into account. These models can be used to develop perceptually-aware optimizations such as (1) automatically approximate data transformations that are perceptually indistinguishable, (2) model queries generated by an interaction (e.g., dragging a scrollbar to the right) as a single session and optimize across the entire set of queries, and (3) apply interaction-oriented caching and rewrite strategies to minimize latency. Ultimately, these techniques can ensure high frame-rate interactions for data exploration without negatively impacting the insights that users draw from their visualizations. Further information, publications and results of this research are available at the project web site (http://perceptvis.github.io).</AbstractNarration>
<MinAmdLetterDate>08/27/2015</MinAmdLetterDate>
<MaxAmdLetterDate>01/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1527779</AwardID>
<Investigator>
<FirstName>Arnab</FirstName>
<LastName>Nandi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arnab Nandi</PI_FULL_NAME>
<EmailAddress>arnab@cse.ohio-state.edu</EmailAddress>
<PI_PHON>6142923805</PI_PHON>
<NSF_ID>000623779</NSF_ID>
<StartDate>08/27/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~250000</FUND_OBLG>
<FUND_OBLG>2017~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-c4f1c41c-7fff-9e7e-31f9-2ab0e8fe34a6"> <span id="docs-internal-guid-c4f1c41c-7fff-9e7e-31f9-2ab0e8fe34a6"> <p dir="ltr"><span>Interactive visualizations are a powerful way to explore and draw insights from data, and research has shown that responsiveness is a crucial factor in ensuring that visual data exploration systems are usable and effective.&nbsp; However, as the data available to practitioners continues to grow in complexity and size, existing systems find it harder and harder to maintain a highly interactive experience due to the costs of data processing and transmission.&nbsp; Although accelerating database query execution is a crucial component towards responsive visualizations, it is not sufficient because the database is only one component in the visualization system.  Further, query execution performance overlooks the key element in the system -- the human that drives the analysis loop.</span></p> <br /> <p dir="ltr"><span>The goal of this project was to develop an interactive visual data exploration system designed and optimized to take human perception into account. As part of this, the major outcomes of this project included:</span></p> <br /> <p dir="ltr"><span>- Studies to understand and quantify the limitations in human perception of data visualizations</span></p> <br /> <p dir="ltr"><span>- Tools and techniques to accelerate visualization systems by leveraging human perception limitations</span></p> <br /> <p dir="ltr"><span>- Tools and systems that integrate optimizations such as caching, approximation, and prediction to ensure the responsiveness and interactivity of visualization systems</span></p> <br /> <p dir="ltr"><span>- Tutorials and evaluation benchmarks for building interactive visual data analysis systems</span></p> <br /> <p dir="ltr"><span>- Community-building efforts in this area, including the organization of Dagstuhl workshops, and the organization of the leading Human-in-the-loop-data-analysis workshop (HILDA), co-located with one of the leading data management conferences, ACM SIGMOD.</span></p> <br /> <p dir="ltr"><span>The publications, methodologies, tools, and techniques we have developed for this project are all publicly available at our project website:</span></p> <br /> <p dir="ltr"><span>http://perceptvis.github.io</span></p> </span></span></p><br> <p>            Last Modified: 02/16/2020<br>      Modified by: Arnab&nbsp;Nandi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Interactive visualizations are a powerful way to explore and draw insights from data, and research has shown that responsiveness is a crucial factor in ensuring that visual data exploration systems are usable and effective.  However, as the data available to practitioners continues to grow in complexity and size, existing systems find it harder and harder to maintain a highly interactive experience due to the costs of data processing and transmission.  Although accelerating database query execution is a crucial component towards responsive visualizations, it is not sufficient because the database is only one component in the visualization system.  Further, query execution performance overlooks the key element in the system -- the human that drives the analysis loop.   The goal of this project was to develop an interactive visual data exploration system designed and optimized to take human perception into account. As part of this, the major outcomes of this project included:   - Studies to understand and quantify the limitations in human perception of data visualizations   - Tools and techniques to accelerate visualization systems by leveraging human perception limitations   - Tools and systems that integrate optimizations such as caching, approximation, and prediction to ensure the responsiveness and interactivity of visualization systems   - Tutorials and evaluation benchmarks for building interactive visual data analysis systems   - Community-building efforts in this area, including the organization of Dagstuhl workshops, and the organization of the leading Human-in-the-loop-data-analysis workshop (HILDA), co-located with one of the leading data management conferences, ACM SIGMOD.   The publications, methodologies, tools, and techniques we have developed for this project are all publicly available at our project website:   http://perceptvis.github.io        Last Modified: 02/16/2020       Submitted by: Arnab Nandi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
