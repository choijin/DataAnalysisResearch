<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS/Synergy/Collaborative Research: Safe and Efficient Cyber-Physical Operation System for Construction Equipment</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2016</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>325000.00</AwardTotalIntnAmount>
<AwardAmount>325000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Bruce Kramer</SignBlockName>
<PO_EMAI>bkramer@nsf.gov</PO_EMAI>
<PO_PHON>7032925348</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Equipment operation represents one of the most dangerous tasks on a construction sites and accidents related to such operation often result in death and property damage on the construction site and the surrounding area. Such accidents can also cause considerable delays and disruption, and negatively impact the efficiency of operations. This award will conduct research to improve the safety and efficiency of cranes by integrating advances in robotics, computer vision, and construction management. It will create tools for quick and easy planning of crane operations and incorporate them into a safe and efficient system that can monitor a crane's environment and provide control feedback to the crane and the operator. Resulting gains in safety and efficiency wil reduce fatal and non-fatal crane accidents. Partnerships with industry will also ensure that these advances have a positive impact on  construction practice, and can be extended broadly to smart infrastructure, intelligent manufacturing, surveillance, traffic monitoring, and other application areas. The research will involve undergraduates and includes outreach to K-12 students.&lt;br/&gt;&lt;br/&gt;The work is driven by the hypothesis that the monitoring and control of cranes can be performed autonomously using robotics and computer vision algorithms, and that detailed and continuous monitoring and control feedback can lead to improved planning and simulation of equipment operations. It will particularly focus on developing methods for (a) planning construction operations while accounting for safety hazards through simulation; (b) estimating and providing analytics on the state of the equipment; (c) monitoring equipment surrounding the crane operating environment, including detection of safety hazards, and proximity analysis to dynamic resources including materials, equipment, and workers; (d) controlling crane stability in real-time; and (e) providing feedback to the user and equipment operators in a "transparent cockpit" using visual and haptic cues. It will address the underlying research challenges by improving the efficiency and reliability of planning through failure effects analysis and creating methods for contact state estimation and equilibrium analysis; improving monitoring through model-driven and real-time 3D reconstruction techniques, context-driven object recognition, and forecasting motion trajectories of objects; enhancing reliability of control through dynamic crane models, measures of instability, and algorithms for finding optimal controls; and, finally, improving efficiency of feedback loops through methods for providing visual and haptic cues.</AbstractNarration>
<MinAmdLetterDate>08/21/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1544999</AwardID>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>Bretl</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy W Bretl</PI_FULL_NAME>
<EmailAddress>tbretl@illinois.edu</EmailAddress>
<PI_PHON>2172443126</PI_PHON>
<NSF_ID>000380917</NSF_ID>
<StartDate>08/21/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mani</FirstName>
<LastName>Golparvar-Fard</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mani Golparvar-Fard</PI_FULL_NAME>
<EmailAddress>mgolpar@illinois.edu</EmailAddress>
<PI_PHON>2173005226</PI_PHON>
<NSF_ID>000586985</NSF_ID>
<StartDate>08/21/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207406</ZipCode>
<StreetAddress><![CDATA[1901 South First Street, Suite A]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>030E</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>034E</Code>
<Text>Dynamical systems</Text>
</ProgramReference>
<ProgramReference>
<Code>5188</Code>
<Text>SAFETY</Text>
</ProgramReference>
<ProgramReference>
<Code>7339</Code>
<Text>COMPUTER VISION</Text>
</ProgramReference>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>8235</Code>
<Text>CPS-Synergy</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~325000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-16301a92-7fff-f6ee-33a0-6429c7d7dc2f"> </span></p> <p dir="ltr"><span>The objective of this project was to improve the safety and efficiency of construction equipment operations through advances in robotics, computer vision, and construction management. Equipment operation is one of the most dangerous tasks on a construction site. Accidents related to equipment operation often result in death and property damage on the site and the surrounding area, as well as cause delay and disruption that negatively impact operational efficiency. This project focused on safety in construction operations involving equipment and workers by improving the <em>frequency</em>, <em>detail</em>, and <em>applicability</em> of safety planning, monitoring, and control, with four key components: 1) Improving safety via better planning by creating virtual models of the physical environment on construction sites and simulating the location and working condition of equipment and workers to make sure their operations are safe and efficient; 2) estimating and analyzing the state of equipment and workers as well as their surroundings through sensory data; 3) monitoring the work environment via detecting and tracking current and forecasted location of workers, equipment, materials, and other site objects (e.g., power lines) by analyzing site video feeds; and 4) offering control feedback to workers and equipment operators so that they are informed of potential incidents. The accomplished work contributes to science by addressing fundamental underlying research challenges in robotics, computer vision, and construction improvement: improving the efficiency and reliability of planning through new Failure Model Effects Analysis and Fault Tree Analysis&#894; creating new methods for joint recognition and pose estimation, contact state estimation, and equilibrium analysis&#894; improving monitoring through model-driven and real-time 3D reconstruction techniques, context-driven object recognition, forecasting motion trajectories of objects by leveraging appearance and geometry&#894; enhancing efficiency and reliability of control through new dynamic crane models, novel measures of instability, and new algorithms for finding optimal controls&#894; and finally new methods for providing visual and haptic cues to improve efficiency of feedback loops.</span></p> <p dir="ltr"><span>The work also provided&nbsp; a unique opportunity for interdisciplinary research and teaching. Methods from construction management, computer vision, and robotics are being applied to problems of significant relevance to the construction industry. Graduate students were involved in mentoring undergraduate students. Undergraduate students and particularly those from underrepresented groups were involved in research activities. Research findings are disseminated to both academic researchers and industry practitioners. Material from this research is being introduced in classes that the investigators are teaching/contributing to. Beyond construction, the findings from this work have applications to traffic monitoring, smart infrastructure, intelligent manufacturing, and other areas that require continuous monitoring of operations, safety analysis, and hazard mitigation.</span></p> <div></div> <p>&nbsp;</p><br> <p>            Last Modified: 02/03/2021<br>      Modified by: Mani&nbsp;Golparvar-Fard</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383599919_NSFImage0--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383599919_NSFImage0--rgov-800width.jpg" title="A safe and Efficient Operation System for construction Equipment"><img src="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383599919_NSFImage0--rgov-66x44.jpg" alt="A safe and Efficient Operation System for construction Equipment"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A safe and Efficient Operation System for construction Equipment</div> <div class="imageCredit">Mani Golparvar-Fard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">A safe and Efficient Operation System for construction Equipment</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383642577_NSFImage2--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383642577_NSFImage2--rgov-800width.jpg" title="Detecting, Tracking and Analyzing Motion Trajectory of Workers and Equipment"><img src="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383642577_NSFImage2--rgov-66x44.jpg" alt="Detecting, Tracking and Analyzing Motion Trajectory of Workers and Equipment"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Detecting, Tracking and Analyzing Motion Trajectory of Workers and Equipment</div> <div class="imageCredit">Mani Golparvar-Fard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Detecting, Tracking and Analyzing Motion Trajectory of Workers and Equipment</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383698592_NSFImage3--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383698592_NSFImage3--rgov-800width.jpg" title="Worker-Tool Interaction Model for Worker Safety Analysis"><img src="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383698592_NSFImage3--rgov-66x44.jpg" alt="Worker-Tool Interaction Model for Worker Safety Analysis"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Worker-Tool Interaction Model for Worker Safety and Ergonomics Analysis</div> <div class="imageCredit">Mani Golparvar-Fard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Worker-Tool Interaction Model for Worker Safety Analysis</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383870781_NSFImage4--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383870781_NSFImage4--rgov-800width.jpg" title="Computer Vision Activity Analysis for Improving Efficiency and Safety of Construction Equipment"><img src="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612383870781_NSFImage4--rgov-66x44.jpg" alt="Computer Vision Activity Analysis for Improving Efficiency and Safety of Construction Equipment"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Computer Vision Activity Analysis for Improving Efficiency and Safety of Construction Equipment</div> <div class="imageCredit">Mani Golparvar-Fard</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Computer Vision Activity Analysis for Improving Efficiency and Safety of Construction Equipment</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612384471244_NSFImage1--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612384471244_NSFImage1--rgov-800width.jpg" title="Worker-Tool Interaction Model for Worker Safety Analysis"><img src="/por/images/Reports/POR/2021/1544999/1544999_10390443_1612384471244_NSFImage1--rgov-66x44.jpg" alt="Worker-Tool Interaction Model for Worker Safety Analysis"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Worker-Tool Interaction Model for Worker Safety Analysis</div> <div class="imageCredit">Mani Golparvar-Fard</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Worker-Tool Interaction Model for Worker Safety Analysis</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The objective of this project was to improve the safety and efficiency of construction equipment operations through advances in robotics, computer vision, and construction management. Equipment operation is one of the most dangerous tasks on a construction site. Accidents related to equipment operation often result in death and property damage on the site and the surrounding area, as well as cause delay and disruption that negatively impact operational efficiency. This project focused on safety in construction operations involving equipment and workers by improving the frequency, detail, and applicability of safety planning, monitoring, and control, with four key components: 1) Improving safety via better planning by creating virtual models of the physical environment on construction sites and simulating the location and working condition of equipment and workers to make sure their operations are safe and efficient; 2) estimating and analyzing the state of equipment and workers as well as their surroundings through sensory data; 3) monitoring the work environment via detecting and tracking current and forecasted location of workers, equipment, materials, and other site objects (e.g., power lines) by analyzing site video feeds; and 4) offering control feedback to workers and equipment operators so that they are informed of potential incidents. The accomplished work contributes to science by addressing fundamental underlying research challenges in robotics, computer vision, and construction improvement: improving the efficiency and reliability of planning through new Failure Model Effects Analysis and Fault Tree Analysis&#894; creating new methods for joint recognition and pose estimation, contact state estimation, and equilibrium analysis&#894; improving monitoring through model-driven and real-time 3D reconstruction techniques, context-driven object recognition, forecasting motion trajectories of objects by leveraging appearance and geometry&#894; enhancing efficiency and reliability of control through new dynamic crane models, novel measures of instability, and new algorithms for finding optimal controls&#894; and finally new methods for providing visual and haptic cues to improve efficiency of feedback loops. The work also provided  a unique opportunity for interdisciplinary research and teaching. Methods from construction management, computer vision, and robotics are being applied to problems of significant relevance to the construction industry. Graduate students were involved in mentoring undergraduate students. Undergraduate students and particularly those from underrepresented groups were involved in research activities. Research findings are disseminated to both academic researchers and industry practitioners. Material from this research is being introduced in classes that the investigators are teaching/contributing to. Beyond construction, the findings from this work have applications to traffic monitoring, smart infrastructure, intelligent manufacturing, and other areas that require continuous monitoring of operations, safety analysis, and hazard mitigation.           Last Modified: 02/03/2021       Submitted by: Mani Golparvar-Fard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
