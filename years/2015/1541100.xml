<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Statistical and Computational Tradeoffs in High Dimensional Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927902</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For various statistical procedures, mostly involving searching for a sparse structure in a high-dimensional parameter space, a gap between the performance attained by computationally efficient procedures and  optimal ones has been observed. Examples include sparse regression, sparse principal component analysis, community detection, clustering,  network analysis and matrix completion. This observation hints at the existence of an inherent statistical price to pay for using computationally efficient methods. The investigators study how large this price can be by drawing new bridges between theoretical computer science and statistical learning theory. Practically, this agenda requires shifting the current notion of statistical optimality to have more relevance under limited computational power and developing new algorithms that achieve said optimality.&lt;br/&gt;&lt;br/&gt;The recent establishment of big-data as the new norm is causing a paradigm shift in statistics: computational power is the new bottleneck, not the lack of observations. The investigators lay theoretical foundations to study this new tradeoff between statistical and computational performance. A direct benefit of this research is to help statisticians and practitioners navigate the ocean of available heuristics and avoid the common pitfalls associated with using them.</AbstractNarration>
<MinAmdLetterDate>04/16/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1541100</AwardID>
<Investigator>
<FirstName>Philippe</FirstName>
<LastName>Rigollet</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Philippe Rigollet</PI_FULL_NAME>
<EmailAddress>rigollet@math.mit.edu</EmailAddress>
<PI_PHON>6092165758</PI_PHON>
<NSF_ID>000515280</NSF_ID>
<StartDate>04/16/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~64172</FUND_OBLG>
<FUND_OBLG>2014~297200</FUND_OBLG>
<FUND_OBLG>2015~88628</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>With the rise of large scale data, computation is playing a more and more preponderant role in statistics. This begs a fundamental question: can methods be statistically optimal and computationally optimal at the same time or is there an inherent tradeoff between the two.</p> <p>This project has contributed to drawing a contrasted answer to this question: in some problems there is an inherent statistical price to pay for computational efficiency, whereas in others, apparently computationally hard problems can be solved using shrewd optimization methods. Both sides of the coin have led to significant advances in our understanding of the interplay between information and computation.</p> <p>In particular, this project has contributed to starting a new research trend that consists in studying computational problems in the context of statistical models. This framework has allowed not only to explain the good practical performance of several&nbsp;heuristics but also to deploy a cohesive set of algorithmic tools based on optimization techniques.</p> <p>Looking at statistical problems under this new lens has allowed the scientific community to push the computational boundaries that were previously limiting the scale of problems that could be studied. In particular, while unforeseen&nbsp;in early stages of the project, this past year has witnessed development in statistical problems emerging in cutting-edge data-driven science such as cryo-electron-microscopy, for which the 2017 Nobel Prize in Chemistry was awarded. Advances in this field were made possible by combining statistics and computation in new ways.</p> <p>This project has also allowed the training of<span>&nbsp;a new generation of scientists at the intersection of the key fields for data science: statistics, mathematics and computer science. Moreover, several courses were developed under this project with lecture notes that are available online freely. This project has also supported the PI during the development of an online course on data science, targeted to professionals and that has been already attended by 2,500 students. It uses a new format and distills complex ideas of data science into simple, geometric principles that can be conveyed in short videos.</span></p> <p>The findings of this projects have generated a lot more questions that are still under investigation not only by the PI but also by various other research groups worldwide.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/09/2017<br>      Modified by: Philippe&nbsp;Rigollet</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With the rise of large scale data, computation is playing a more and more preponderant role in statistics. This begs a fundamental question: can methods be statistically optimal and computationally optimal at the same time or is there an inherent tradeoff between the two.  This project has contributed to drawing a contrasted answer to this question: in some problems there is an inherent statistical price to pay for computational efficiency, whereas in others, apparently computationally hard problems can be solved using shrewd optimization methods. Both sides of the coin have led to significant advances in our understanding of the interplay between information and computation.  In particular, this project has contributed to starting a new research trend that consists in studying computational problems in the context of statistical models. This framework has allowed not only to explain the good practical performance of several heuristics but also to deploy a cohesive set of algorithmic tools based on optimization techniques.  Looking at statistical problems under this new lens has allowed the scientific community to push the computational boundaries that were previously limiting the scale of problems that could be studied. In particular, while unforeseen in early stages of the project, this past year has witnessed development in statistical problems emerging in cutting-edge data-driven science such as cryo-electron-microscopy, for which the 2017 Nobel Prize in Chemistry was awarded. Advances in this field were made possible by combining statistics and computation in new ways.  This project has also allowed the training of a new generation of scientists at the intersection of the key fields for data science: statistics, mathematics and computer science. Moreover, several courses were developed under this project with lecture notes that are available online freely. This project has also supported the PI during the development of an online course on data science, targeted to professionals and that has been already attended by 2,500 students. It uses a new format and distills complex ideas of data science into simple, geometric principles that can be conveyed in short videos.  The findings of this projects have generated a lot more questions that are still under investigation not only by the PI but also by various other research groups worldwide.          Last Modified: 10/09/2017       Submitted by: Philippe Rigollet]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
