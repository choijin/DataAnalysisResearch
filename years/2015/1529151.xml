<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Error-Correction Reinterpretation and Efficient Estimation of Dynamic Stochastic General Equilibrium Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2016</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>112284.00</AwardTotalIntnAmount>
<AwardAmount>112284</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nancy Lutz</SignBlockName>
<PO_EMAI>nlutz@nsf.gov</PO_EMAI>
<PO_PHON>7032927280</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Dynamic Stochastic General Equilibrium (DSGE) models are workhorses of empirical macroeconomics, and are widely used for policy analysis. The PI's research seeks to reinterpret DSGE models within a more flexible mathematical framework. The goal is to provide methods that address some key deficiencies of DSGE models and provide a more robust framework for understanding business cycle fluctuations and the effects of government policies. &lt;br/&gt;&lt;br/&gt;The PI plans to develop a method that is in some ways similar to the Bank of England Quarterly Model, in which steady state core solutions are embedded within Error Correction Mechanism (ECM) equations using detrended data.  There is a key difference; rather than detrending data and constructing ECM equations for core solutions, the PI plans to use as ECM targets balanced growth (log) ratios between core solutions. There are two reasons for proceeding in this way.  First, these rations are obvious candidates for co-integrating relationships, and second, the advantages of formally accounting for (near) unit roots are well understood.  They robustify inference of key structural parameters and play a key role in separating persistent from less persistent movements in the data.  The PI will also continue to develop numerically efficient filtering techniques applicable to ECM/DSGE models.</AbstractNarration>
<MinAmdLetterDate>05/25/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/25/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1529151</AwardID>
<Investigator>
<FirstName>Jean-Francois</FirstName>
<LastName>Richard</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jean-Francois Richard</PI_FULL_NAME>
<EmailAddress>fantin@pitt.edu</EmailAddress>
<PI_PHON>4126481750</PI_PHON>
<NSF_ID>000252459</NSF_ID>
<StartDate>05/25/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152600001</ZipCode>
<StreetAddress><![CDATA[4200 5th avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1320</Code>
<Text>Economics</Text>
</ProgramElement>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~112284</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Background: </strong>Dynamic Stochastic General Equilibrium (DSGE) models are the workhorses of modern macroeconomics and are commonly used for forecasting and policy simulation by a wide range of researchers, central banks and other policy agencies. They assume a very high degree of theoretical rationality from economic agents but often exhibit poor empirical performance, especially in times of changes and crises. Alternative data based models with very limited theoretical foundation but richer dynamic specifications typically outperform DSGE models in terms of empirical performance.</p> <p><strong>Project: </strong>My project aimed at developing empirically more performant&nbsp; alternatives to DSGE models with special emphasis on prediction in times of changes. On the theory side I adopt a less rigid framework, whereby economic agents are assumed to reason in terms of targets, such as consumption to income and work to leisure ratios, that would be optimal under tentative (balanced) growth scenarios. Foremost, they understand that these targets depend on the economic environment and, therefore, can move over time. They use a simple tracking mechanism known as Error-Correction to adjust to such moving targets. The underlying movements of the targets are modeled in the form of densely parametrized dynamic state space models.</p> <p><strong>Achievements: </strong>Last year was devoted to refining the proposed framework, testing alternatives, developing an integrated computer software and applying it to a conventional Real Business Cycles (RBC) pilot model for aggregate per capita real income, real consumption and hours worked using US <em>unfiltered </em>quarterly data from 1948:1 to 2016:2. The use of unfiltered data turns out to be critical in order to fully capture the dynamic evolution of the economy. The results are exceptionally encouraging. First and foremost, I estimated the model sequentially by adding the observations from 2007:4 to 2016:2 one by one and re-estimating each time the complete model. This is a very demanding sequential test of the validity of the model since,in particular, the test period includes the latest great recession, which has caused numerous DSGE models to fail. The model passes the test with flying colors, exhibiting outstanding parameter stabiltiy over the entire excercise. This is particularly critical in order to validate its use for forecasting and policy simulation in times of rapid changes.</p> <p>Moreover, the estimated model correctly identifies all eleven post-war recessions with no false positives. In addition to variations in the underlying growth rate of the US economy, the model offers two alternative explanations for the observed movements of&nbsp; the agents'&nbsp; targets: variations in their relative preference for labor versus leisure (whether voluntary or unvoluntary) or variations in the capital's share of output. Both interpretations appear to make economic sense but are mutually exclusive in the current pilot version of the model.</p> <p>Extensive computer programs were developed that incorporate a generic and integrated combination of modern statistical techniques as needed for identification, sequential estimation, testing and validation of the model, soon to be followed by forecasting and simulation. Special attention has been paid to organizing these programs into modular forms that can be customized for other models. All programs (FORTRAN and MATLAB) will be fully documented, including detailed pseudo-codes, and made available together with the data.</p> <p>All&nbsp; in all, these resutts are exceptionally encouraging and would indicate that the proposed approach offers an operational, performant and well-balanced compromise between theoretical coherence and empirical performance. As for the diffusion of these results it appears that a book might be preferable to journal articles, in view of the volume of material to report.</p> <p>I should add that I have already incorporated some of this material in my graduate advance econometrics time series class, where it has been well received. I am also benefitting from the assistance of an oustanding GRA who unquestionably will qualify for full co-authorship of the output of the project.</p><br> <p>            Last Modified: 06/16/2017<br>      Modified by: Jean-Francois&nbsp;Richard</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Background: Dynamic Stochastic General Equilibrium (DSGE) models are the workhorses of modern macroeconomics and are commonly used for forecasting and policy simulation by a wide range of researchers, central banks and other policy agencies. They assume a very high degree of theoretical rationality from economic agents but often exhibit poor empirical performance, especially in times of changes and crises. Alternative data based models with very limited theoretical foundation but richer dynamic specifications typically outperform DSGE models in terms of empirical performance.  Project: My project aimed at developing empirically more performant  alternatives to DSGE models with special emphasis on prediction in times of changes. On the theory side I adopt a less rigid framework, whereby economic agents are assumed to reason in terms of targets, such as consumption to income and work to leisure ratios, that would be optimal under tentative (balanced) growth scenarios. Foremost, they understand that these targets depend on the economic environment and, therefore, can move over time. They use a simple tracking mechanism known as Error-Correction to adjust to such moving targets. The underlying movements of the targets are modeled in the form of densely parametrized dynamic state space models.  Achievements: Last year was devoted to refining the proposed framework, testing alternatives, developing an integrated computer software and applying it to a conventional Real Business Cycles (RBC) pilot model for aggregate per capita real income, real consumption and hours worked using US unfiltered quarterly data from 1948:1 to 2016:2. The use of unfiltered data turns out to be critical in order to fully capture the dynamic evolution of the economy. The results are exceptionally encouraging. First and foremost, I estimated the model sequentially by adding the observations from 2007:4 to 2016:2 one by one and re-estimating each time the complete model. This is a very demanding sequential test of the validity of the model since,in particular, the test period includes the latest great recession, which has caused numerous DSGE models to fail. The model passes the test with flying colors, exhibiting outstanding parameter stabiltiy over the entire excercise. This is particularly critical in order to validate its use for forecasting and policy simulation in times of rapid changes.  Moreover, the estimated model correctly identifies all eleven post-war recessions with no false positives. In addition to variations in the underlying growth rate of the US economy, the model offers two alternative explanations for the observed movements of  the agents'  targets: variations in their relative preference for labor versus leisure (whether voluntary or unvoluntary) or variations in the capital's share of output. Both interpretations appear to make economic sense but are mutually exclusive in the current pilot version of the model.  Extensive computer programs were developed that incorporate a generic and integrated combination of modern statistical techniques as needed for identification, sequential estimation, testing and validation of the model, soon to be followed by forecasting and simulation. Special attention has been paid to organizing these programs into modular forms that can be customized for other models. All programs (FORTRAN and MATLAB) will be fully documented, including detailed pseudo-codes, and made available together with the data.  All  in all, these resutts are exceptionally encouraging and would indicate that the proposed approach offers an operational, performant and well-balanced compromise between theoretical coherence and empirical performance. As for the diffusion of these results it appears that a book might be preferable to journal articles, in view of the volume of material to report.  I should add that I have already incorporated some of this material in my graduate advance econometrics time series class, where it has been well received. I am also benefitting from the assistance of an oustanding GRA who unquestionably will qualify for full co-authorship of the output of the project.       Last Modified: 06/16/2017       Submitted by: Jean-Francois Richard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
