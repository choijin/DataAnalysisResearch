<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI:  Development of Heterogeneous Cluster for Cyber-Physical System Hybrid Analytics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>180674.00</AwardTotalIntnAmount>
<AwardAmount>180674</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita Rodriguez</SignBlockName>
<PO_EMAI>rrodrigu@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;The proposed instrument provides a foundation for new research activities enhancing existing research efforts, and fuels new collaboration within and the beyond institution. It comprise a uniquely capable high performance computing resource in the state and in the region.  The heterogeneous cluster will be leveraged to yield superior modeling and understanding of seismic events, improve neuro-image analysis capabilities, enhance cyber-security tools, and inspire new vehicle crash-reconstruction methodologies. The educational activities augment the offerings of the institution and provide a template for development of a curriculum to prepare individuals for careers in the field of heterogeneous computing. Further, access to the cluster and the analytic tools developed for it fortify theoretic and applied courses, allowing students to approach and study real-world problems of a larger scale.&lt;br/&gt;&lt;br/&gt;This project builds a novel computational resource in the form of a heterogeneous cluster (CPU/MIC co-processor /FPGA), as a platform for research and innovation spanning several lines of inquiry across multitude fields in science and engineering. Specifically, this experimental hybrid cluster aims to service and advance research in emerging cyber-physical systems that have diverse computational needs. This work addresses current computing problems that continue to grow in size and scope, and quickly exhaust the capabilities of traditional homogeneous architectures in terms of execution time and cost. While various computing platforms exist, including the traditional CPU, field programmable gate arrays (FPGAs), many integrated core (MIC) co-processors, and graphic processing units (GPUs), these problems often possess traits that would benefit from a distribution of work based on the algorithmic needs and the capabilities of the underlying hardware. Thus, this development combines traditional CPUs with FPGAs, MICs, and GPUs forming a heterogeneous architecture capable of delivering the next advance in computational performance. The instrument allows investigators to address larger and more complex problems through computer simulation and analysis spanning the areas of cyber-physical system security, seismic modeling, neuroinformatics, crash reconstruction, and chemical reaction modeling. CPUs excel at complex multi-threaded applications with significant numbers of control (branch) instructions; MICs excel at problems with high spatial locality and that fit the SIMD mold; and FPGAs provide a blank canvas that can be configured to best fit the needs of a particular problem. Current hard problems require the strengths of each of these types of devices and this instrument provides a platform to solve such problems and to research how best to use the proposed heterogeneous platform. These results will advance the theoretical understanding of these processes. The heterogeneous cluster will expand understanding in the areas of the design of future heterogeneous clusters and interconnect architecture, in unified programming platforms and languages, and in workload division among diverse computational elements. Finally, the heterogeneous cluster will support advances in the science of Honeynets for security analysis, the implementation of bump-in-the-wire cyber-security monitoring tools, and advanced security vulnerability discovery. &lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/26/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1531270</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Tapp</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James B Tapp</PI_FULL_NAME>
<EmailAddress>jbt@utulsa.edu</EmailAddress>
<PI_PHON>9186313018</PI_PHON>
<NSF_ID>000362868</NSF_ID>
<StartDate>08/26/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>John</FirstName>
<LastName>Hale</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John C Hale</PI_FULL_NAME>
<EmailAddress>john-hale@utulsa.edu</EmailAddress>
<PI_PHON>9186312745</PI_PHON>
<NSF_ID>000362150</NSF_ID>
<StartDate>08/26/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mauricio</FirstName>
<LastName>Papa</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr</PI_SUFX_NAME>
<PI_FULL_NAME>Mauricio Papa</PI_FULL_NAME>
<EmailAddress>mauricio-papa@utulsa.edu</EmailAddress>
<PI_PHON>9186312987</PI_PHON>
<NSF_ID>000364835</NSF_ID>
<StartDate>08/26/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jingyi</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jingyi Chen</PI_FULL_NAME>
<EmailAddress>jingyi-chen@utulsa.edu</EmailAddress>
<PI_PHON>9186313014</PI_PHON>
<NSF_ID>000564653</NSF_ID>
<StartDate>08/26/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Hawrylak</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter J Hawrylak</PI_FULL_NAME>
<EmailAddress>peter-hawrylak@utulsa.edu</EmailAddress>
<PI_PHON>9186313277</PI_PHON>
<NSF_ID>000572044</NSF_ID>
<StartDate>08/26/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Tulsa</Name>
<CityName>Tulsa</CityName>
<ZipCode>741049700</ZipCode>
<PhoneNumber>9186312192</PhoneNumber>
<StreetAddress>800 S. Tucker Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Oklahoma</StateName>
<StateCode>OK</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OK01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072420433</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TULSA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072420433</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Tulsa]]></Name>
<CityName/>
<StateCode>OK</StateCode>
<ZipCode>741049700</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oklahoma</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OK01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1189</Code>
<Text>Major Research Instrumentation</Text>
</ProgramElement>
<ProgramElement>
<Code>9150</Code>
<Text>EPSCoR Co-Funding</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~180674</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">Computationally intensive applications and programs driven by industry, defense, and scientific research enterprises increasingly demand high performance computing capabilities.&nbsp; Massive simulations, deep-learning, analytics over large data sets, and real-time analysis can tax even the most robust super-computers.&nbsp; The computer industry has tried to keep pace with this growing demand through advances in multi-core chip architectures, networking, and memory and storage solutions.&nbsp; However, not all computing platforms and devices are created equal.&nbsp; GPUs excel at vector and matrix computations.&nbsp; CPUs are designed for general purpose computing concerns, and reconfigurable logic units such as Field Programmable Gate Arrays (FPGAs) permit custom &ldquo;software as a circuit&rdquo; functionality.&nbsp; Programmers skilled in the art of fully exploiting the differential capabilities of each of these kinds of components can unleash the full potential of their computing power.&nbsp; More intriguing still is the prospect of &ldquo;heterogeneous computing,&rdquo; wherein a single problem is decomposed and distributed to differential processing elements optimally suited for their respective tasks.&nbsp; A number of challenges make this an elusive goal &mdash; most notably, a viable hardware and networking architecture and practical toolchain for unified application development and algorithm implementation. &nbsp;</p> <p class="p2">The instrument developed in this project is a heterogeneous compute node cluster conceived to offer a novel platform with which to explore solutions to these challenges under a range of scientific application domains, including those of cyber-physical system security, seismic modeling, neuroinformatics, crash reconstruction, and chemical reaction modeling.&nbsp; Each of the 16 nodes in this cluster is equipped with a CPU, a GPU and a FPGA.&nbsp; Open source cluster management software and parallel programming platforms (OpenMPI, OpenMP, OpenCL) supported on the cluster offer a powerful array of composable toolchains to programmers.&nbsp; The instrument has accordingly allowed investigators to experiment with different strategies for heterogeneous parallel programming, and will be a valuable resource for scientists in a range of fields to tackle high performance computing challenges in fundamentally new ways.&nbsp; In addition, the instrument has been used in a course on High Performance Computing, and inspired the development of a minor in High Performance Computing at The University of Tulsa.&nbsp; Due in no small part to the presence of this unique resource on campus, The University of Tulsa has been invited to join the Oklahoma Friction Free Network (OFFN) - a high speed Science DMZ linking universities in the region with HPC facilities.&nbsp; In the coming years, we project that the instrument will play a vital role in high performance computing research and education initiatives at The University of Tulsa and beyond.</p><br> <p>            Last Modified: 12/04/2017<br>      Modified by: John&nbsp;C&nbsp;Hale</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Computationally intensive applications and programs driven by industry, defense, and scientific research enterprises increasingly demand high performance computing capabilities.  Massive simulations, deep-learning, analytics over large data sets, and real-time analysis can tax even the most robust super-computers.  The computer industry has tried to keep pace with this growing demand through advances in multi-core chip architectures, networking, and memory and storage solutions.  However, not all computing platforms and devices are created equal.  GPUs excel at vector and matrix computations.  CPUs are designed for general purpose computing concerns, and reconfigurable logic units such as Field Programmable Gate Arrays (FPGAs) permit custom "software as a circuit" functionality.  Programmers skilled in the art of fully exploiting the differential capabilities of each of these kinds of components can unleash the full potential of their computing power.  More intriguing still is the prospect of "heterogeneous computing," wherein a single problem is decomposed and distributed to differential processing elements optimally suited for their respective tasks.  A number of challenges make this an elusive goal &mdash; most notably, a viable hardware and networking architecture and practical toolchain for unified application development and algorithm implementation.   The instrument developed in this project is a heterogeneous compute node cluster conceived to offer a novel platform with which to explore solutions to these challenges under a range of scientific application domains, including those of cyber-physical system security, seismic modeling, neuroinformatics, crash reconstruction, and chemical reaction modeling.  Each of the 16 nodes in this cluster is equipped with a CPU, a GPU and a FPGA.  Open source cluster management software and parallel programming platforms (OpenMPI, OpenMP, OpenCL) supported on the cluster offer a powerful array of composable toolchains to programmers.  The instrument has accordingly allowed investigators to experiment with different strategies for heterogeneous parallel programming, and will be a valuable resource for scientists in a range of fields to tackle high performance computing challenges in fundamentally new ways.  In addition, the instrument has been used in a course on High Performance Computing, and inspired the development of a minor in High Performance Computing at The University of Tulsa.  Due in no small part to the presence of this unique resource on campus, The University of Tulsa has been invited to join the Oklahoma Friction Free Network (OFFN) - a high speed Science DMZ linking universities in the region with HPC facilities.  In the coming years, we project that the instrument will play a vital role in high performance computing research and education initiatives at The University of Tulsa and beyond.       Last Modified: 12/04/2017       Submitted by: John C Hale]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
