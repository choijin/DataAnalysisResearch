<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Automated Public Speaking Assessment</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>179995</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Glenn H. Larsen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This SBIR Phase I project will study the feasibility of automated speaking assessment to help students improve their oral communication skills.  According to a survey of human resource officials, only 25 percent of today's college graduates enter the workforce with well-developed speaking skills. This means many people are unable to effectively persuade an audience of their position, thus limiting their ability to sell new ideas and be successful in their jobs.  The project will investigate novel research in speech technology that enables students to receive objective, personalized feedback at any time.  By reinforcing communication skills through self-paced practice and feedback, users will be better prepared with the communications skills necessary to perform job tasks and move into leadership roles.  The completed system will initially be offered to over two million people in the United States who participate in public speaking training annually.  Potential future applications for the technology include teacher assessments, call center monitoring, interview training, role playing, human resources assessments, patient care, services for the deaf, language learning and student assessments.&lt;br/&gt;&lt;br/&gt;This project will develop key concepts for automated public speaking assessment such that a student's vocal delivery can be objectively measured and presented in a manner that creates an independent, personalized learning experience.  Linking listener perceptions to speech behaviors is a novel direction in automated assessment for speech.  Automated assessment for speech has already been demonstrated in the area of spoken language proficiency, which leverages automated speech recognition and semantic analysis.  Automated voice assessment has also been utilized in lie detection and emotion detection, which focus on autonomic responses in the user's voice, such as when stress affects the vocal cords.  The hypothesis behind this SBIR project is that software can help speakers to consciously use and modify non-semantic speech behaviors to produce more desirable listener perceptions.  The Phase 1 objectives are to identify key features of voice that can be used to predict audience perception and develop initial software models to estimate aspects of audience perception.  To achieve these objectives, a combination of expert feature enumeration, deep learning feature identification and machine learning will be applied and iteratively tested against a large corpus of actor voices and human perception ratings.</AbstractNarration>
<MinAmdLetterDate>05/19/2015</MinAmdLetterDate>
<MaxAmdLetterDate>12/14/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1520228</AwardID>
<Investigator>
<FirstName>Debra</FirstName>
<LastName>Cancro</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME>Mrs.</PI_SUFX_NAME>
<PI_FULL_NAME>Debra B Cancro</PI_FULL_NAME>
<EmailAddress>debra@myvoicevibes.com</EmailAddress>
<PI_PHON>4107461696</PI_PHON>
<NSF_ID>000716326</NSF_ID>
<StartDate>05/19/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Autonomy Engine LLC</Name>
<CityName>Marriottsville</CityName>
<ZipCode>211041171</ZipCode>
<PhoneNumber>4107461696</PhoneNumber>
<StreetAddress>7224 Shub Farm Rd</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>964769314</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AUTONOMY ENGINE LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Autonomy Engine LLC]]></Name>
<CityName>Marriottsville</CityName>
<StateCode>MD</StateCode>
<ZipCode>211041171</ZipCode>
<StreetAddress><![CDATA[7224 Shub Farm Rd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>118E</Code>
<Text>GRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>163E</Code>
<Text>SBIR Phase IB</Text>
</ProgramReference>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8031</Code>
<Text>Education Products</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8039</Code>
<Text>Information, Communication &amp; Computing</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~150000</FUND_OBLG>
<FUND_OBLG>2016~29995</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Oral expression is the most highly valued ability throughout the economy and ranks as the second most highly-valued skill for high-wage, high-growth, high-skill occupations.&nbsp; Despite this fact, human resource officials reported that only 25% of college graduates enter the workforce with sufficient oral communication skills. &nbsp;To address this skills gap, students need more opportunities to practice and develop their public speaking skills.</p> <p>Autonomy Engine, LLC was awarded an NSF SBIR grant to develop the key concepts of automated public speaking assessment such that a student&rsquo;s vocal delivery can be objectively measured and presented in a manner that creates an independent, personalized learning experience.&nbsp; Unlike traditional methods of public speaking assessment, the proposed system can be available at any time, provide objective feedback and track student practice and improvement.</p> <p><strong>INTELLECTUAL MERRIT</strong></p> <p>The Phase I objective was to demonstrate the feasibility of an automated public speaking assessment system by investigating the links between speech behaviors and audience perception. The Phase I project tackled the questions: "Can software be developed to detect speech behaviors or voice features related to an audience&rsquo;s perception?" and "Can software be developed to predict audience perception of a speaker?" &nbsp;</p> <p>Automated voice assessment has previously been utilized in lie detection and emotion detection, which focus on autonomic responses in the user&rsquo;s voice, such as when stress affects the vocal cords. The novel hypothesis behind this SBIR project is that speakers can consciously use and modify non-semantic speech behaviors to produce more desirable listener perceptions. Automatically linking listener perception to speech behaviors represents a novel direction in automated assessment for speech and a key part to develop automated public speaking assessment.</p> <p><strong>Important Outcomes of this work include:</strong></p> <ol> <li><strong>Vibe Models</strong> &nbsp;- In this Phase I SBIR, Autonomy Engine LLC demonstrated software that can predict aspects of audience perception, such as perceived speaker confidence or personability. Automated models were developed that can rate a student on a scale of 1 (low)-10 (high) for 20 separate audience perception types, called &ldquo;vibes&rdquo;, such that the models rate within one standard deviation of a mean human audience rating more than 90% of the time.&nbsp;</li> <li><strong>Product Feedback</strong> - Web-based dashboards and recording apps for both major smartphone platforms were developed in order to create a personalized learning experience.&nbsp; This minimum viable product was tested by practicing public speakers at the Toastmasters International Conference and used by college professors and their students as part of their basic Public Speaking courses.&nbsp; Through these interactions, the company has collected feedback necessary to turn the Phase 1 research capability into a commercial product.</li> </ol> <p><strong>BROADER IMPACTS</strong></p> <p>The VoiceVibes&reg; product will help provide students with public speaking skills necessary to perform twenty-first century job tasks. &nbsp;The number of people who could potentially benefit from such help not only includes the estimated 5.7 million people taking public speaking courses in the U.S. each year, but also the 74% of Americans who suffer from speech anxiety. &nbsp;This technology can better prepare people in a variety of roles who need to sell ideas and communicate effectively, including entrepreneurs, teachers, STEM students, English language learners, and the leaders of tomorrow.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/04/2016<br>      Modified by: Debra&nbsp;B&nbsp;Cancro</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galC...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Oral expression is the most highly valued ability throughout the economy and ranks as the second most highly-valued skill for high-wage, high-growth, high-skill occupations.  Despite this fact, human resource officials reported that only 25% of college graduates enter the workforce with sufficient oral communication skills.  To address this skills gap, students need more opportunities to practice and develop their public speaking skills.  Autonomy Engine, LLC was awarded an NSF SBIR grant to develop the key concepts of automated public speaking assessment such that a studentÆs vocal delivery can be objectively measured and presented in a manner that creates an independent, personalized learning experience.  Unlike traditional methods of public speaking assessment, the proposed system can be available at any time, provide objective feedback and track student practice and improvement.  INTELLECTUAL MERRIT  The Phase I objective was to demonstrate the feasibility of an automated public speaking assessment system by investigating the links between speech behaviors and audience perception. The Phase I project tackled the questions: "Can software be developed to detect speech behaviors or voice features related to an audienceÆs perception?" and "Can software be developed to predict audience perception of a speaker?"    Automated voice assessment has previously been utilized in lie detection and emotion detection, which focus on autonomic responses in the userÆs voice, such as when stress affects the vocal cords. The novel hypothesis behind this SBIR project is that speakers can consciously use and modify non-semantic speech behaviors to produce more desirable listener perceptions. Automatically linking listener perception to speech behaviors represents a novel direction in automated assessment for speech and a key part to develop automated public speaking assessment.  Important Outcomes of this work include:  Vibe Models  - In this Phase I SBIR, Autonomy Engine LLC demonstrated software that can predict aspects of audience perception, such as perceived speaker confidence or personability. Automated models were developed that can rate a student on a scale of 1 (low)-10 (high) for 20 separate audience perception types, called "vibes", such that the models rate within one standard deviation of a mean human audience rating more than 90% of the time.  Product Feedback - Web-based dashboards and recording apps for both major smartphone platforms were developed in order to create a personalized learning experience.  This minimum viable product was tested by practicing public speakers at the Toastmasters International Conference and used by college professors and their students as part of their basic Public Speaking courses.  Through these interactions, the company has collected feedback necessary to turn the Phase 1 research capability into a commercial product.   BROADER IMPACTS  The VoiceVibes&reg; product will help provide students with public speaking skills necessary to perform twenty-first century job tasks.  The number of people who could potentially benefit from such help not only includes the estimated 5.7 million people taking public speaking courses in the U.S. each year, but also the 74% of Americans who suffer from speech anxiety.  This technology can better prepare people in a variety of roles who need to sell ideas and communicate effectively, including entrepreneurs, teachers, STEM students, English language learners, and the leaders of tomorrow.          Last Modified: 07/04/2016       Submitted by: Debra B Cancro]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
