<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: SCH: Accelerating Human Microbiome Analysis using Lightning-Fast Cloud Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2016</AwardEffectiveDate>
<AwardExpirationDate>03/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>174174.00</AwardTotalIntnAmount>
<AwardAmount>174174</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Nontechnical description: Humans carry ten times more bacterial cells than human cells, and a hundred times more bacterial genes than the inherited human genome. Human microbes also hold secrets for maintaining health and preventing disease. For the last decade, a cultivation-independent metagenomics approach, in which all microorganisms in a sample are directly sequenced together, has been intensely applied to understand microbes' impact on human health. A new generation of sequencing technologies accelerated research, but left a vast amount of metagenomic sequencing data to be analyzed. Software and high-performance computing systems that could speed analysis are still lacking. The PI proposes to develop novel computational algorithms and cloud computing software to decipher terabytes of metagenomic sequencing data for studying the human microbiome. Experience from these pursuits will accelerate development of the proposed tools for better understanding the ecosystem in our bodies. Ultimately, this may contribute to better diagnosis, prevention, and treatment of disease. Furthermore, the proposed cloud computing algorithms and techniques could be adapted to many other applications demanding high computation complexity. A key proposal ingredient is offering graduate and undergraduate computer science students a unique opportunity for interdisciplinary research designing algorithms and software to solve biological problems. &lt;br/&gt;&lt;br/&gt;Novel computational algorithms and a cloud computing software tool are proposed, to analyze large-scale metagenomic sequencing data to study the human microbiome. The project would feature Apache Spark, a cutting-edge, open-source cluster computing framework for large-scale data processing. It supports a rich set of high-level tools including scalable machine learning and graph processing libraries. The primary novelty is a cloud scalable de novo assembler, and the ability to compare assembled sequences to existing reference genomes using Spark libraries. This new approach will speed identification of novel genomes and composition of microbes from large metagenomic data. Most existing metagenomic analysis methods separately execute de novo sequence assembly and taxonomy classification with many existing reference genomes. Key technical innovations of the proposed work are (i) cloud computing algorithms enabling a fast and scalable metagenome assembler, (ii) taking assembled sequences directly for taxonomy to dramatically reduce computation time, and (iii) a cloud container package allowing researchers to analyze metagenomic data easily and cheaply. Providing a cloud container package with a simple Web interface will enable researchers to analyze their large-scale metagenomic sequence data readily and quickly for human health, biosurveillance, and pan-genomic analysis of microbiota.</AbstractNarration>
<MinAmdLetterDate>03/21/2016</MinAmdLetterDate>
<MaxAmdLetterDate>03/21/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1566292</AwardID>
<Investigator>
<FirstName>Tae Hyuk</FirstName>
<LastName>Ahn</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tae Hyuk Ahn</PI_FULL_NAME>
<EmailAddress>ahnt@slu.edu</EmailAddress>
<PI_PHON>3149773633</PI_PHON>
<NSF_ID>000702439</NSF_ID>
<StartDate>03/21/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Saint Louis University</Name>
<CityName>St Louis</CityName>
<ZipCode>631032006</ZipCode>
<PhoneNumber>3149773925</PhoneNumber>
<StreetAddress>221 N. Grand Blvd.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050220722</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SAINT LOUIS UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050220722</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Saint Louis University]]></Name>
<CityName>St Louis</CityName>
<StateCode>MO</StateCode>
<ZipCode>631032006</ZipCode>
<StreetAddress><![CDATA[221 N. Grand Blvd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~174174</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The primary research goal of this project is to develop novel computational algorithms and a cloud computing software tool to analyze large-scale metagenomic sequencing data to study the human microbiome. The advances would feature Apache Spark, a cutting-edge, open-source cluster computing framework for large-scale data processing with machine learning methods. Experience from these pursuits will accelerate development of the proposed tools for better understanding the ecosystem in our bodies. Ultimately, this may contribute to better diagnosis, prevention, and treatment of disease. The primary education goal is offering graduate and undergraduate computer science students a unique opportunity for interdisciplinary research designing algorithms and software to solve biological problems.</p> <p>&nbsp;</p> <p>The exponential advances in the sequencing technologies and informatics tools for generating and processing large biological data sets is promoting a paradigm shift in the way we approach biomedical problems. Next-generation sequencing (NGS) allows rapid, cost-effective sequencing of large amounts of DNA. Metagenomic data can contain more than 10,000 divergent species with different abundance of sequences for each species, complicating analysis. Taxonomy classification in metagenomics refers to identifying microbial genomes from closely related organisms in the metagenomic samples. In environmental microbiology, a number of algorithms have been developed for taxonomy classification of community members from metagenomics data as above, but developing fast, accurate and versatile sequence classification system is evolving. Application of machine learning in analysis of sequences holds a great promise in identifying patterns (biomarkers) to study human health, diseases, and ecosystem of nature. However, using machine learning in the metagenomic studies for sample classification and disease prediction is challenging due to the difficulty of feature extraction, model generation, methods selection, and results validation.</p> <p>&nbsp;</p> <p>The PI investigated scalable overlap-graph reduction algorithms for correct genome assembly using Apache Spark on cloud or local cluster system, SORA. Using Spark graph library, we have applied and tested the overlap-graph reduction algorithms especially for the genome assembly with very large-scale data sets on distributed commodity cloud computing. "Transitive Edge Reduction," "Dead-End Removal," and "Composite Edge Contraction" algorithms are addressed and implemented. There are two main thrusts in this project. Using the advantages of scalable Spark graph processing library, a cloud scalable de novo genome assembler can be designed and implemented. The second thrust is that the proposed algorithms and techniques could be adapted to many other applications using graph theory.</p> <p>&nbsp;</p> <p>To distinguish the metagenomic profiling among different samples and also predict unknown samples precisely based on the profiling, two different approaches are proposed using machine learning techniques; one is a read-based taxonomy profiling of each sample and prediction method, and the other is a reduced representation assembly-based method. Among various machine learning techniques tested, the random forest technique showed promising results as a suitable classifier for both approaches. The PI also developed a versatile machine learning package to analyze large scale metagenomic data set for deriving microbiome-phenotype associations including disease prediction capability.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/30/2019<br>      Modified by: Tae Hyuk&nbsp;Ahn</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The primary research goal of this project is to develop novel computational algorithms and a cloud computing software tool to analyze large-scale metagenomic sequencing data to study the human microbiome. The advances would feature Apache Spark, a cutting-edge, open-source cluster computing framework for large-scale data processing with machine learning methods. Experience from these pursuits will accelerate development of the proposed tools for better understanding the ecosystem in our bodies. Ultimately, this may contribute to better diagnosis, prevention, and treatment of disease. The primary education goal is offering graduate and undergraduate computer science students a unique opportunity for interdisciplinary research designing algorithms and software to solve biological problems.     The exponential advances in the sequencing technologies and informatics tools for generating and processing large biological data sets is promoting a paradigm shift in the way we approach biomedical problems. Next-generation sequencing (NGS) allows rapid, cost-effective sequencing of large amounts of DNA. Metagenomic data can contain more than 10,000 divergent species with different abundance of sequences for each species, complicating analysis. Taxonomy classification in metagenomics refers to identifying microbial genomes from closely related organisms in the metagenomic samples. In environmental microbiology, a number of algorithms have been developed for taxonomy classification of community members from metagenomics data as above, but developing fast, accurate and versatile sequence classification system is evolving. Application of machine learning in analysis of sequences holds a great promise in identifying patterns (biomarkers) to study human health, diseases, and ecosystem of nature. However, using machine learning in the metagenomic studies for sample classification and disease prediction is challenging due to the difficulty of feature extraction, model generation, methods selection, and results validation.     The PI investigated scalable overlap-graph reduction algorithms for correct genome assembly using Apache Spark on cloud or local cluster system, SORA. Using Spark graph library, we have applied and tested the overlap-graph reduction algorithms especially for the genome assembly with very large-scale data sets on distributed commodity cloud computing. "Transitive Edge Reduction," "Dead-End Removal," and "Composite Edge Contraction" algorithms are addressed and implemented. There are two main thrusts in this project. Using the advantages of scalable Spark graph processing library, a cloud scalable de novo genome assembler can be designed and implemented. The second thrust is that the proposed algorithms and techniques could be adapted to many other applications using graph theory.     To distinguish the metagenomic profiling among different samples and also predict unknown samples precisely based on the profiling, two different approaches are proposed using machine learning techniques; one is a read-based taxonomy profiling of each sample and prediction method, and the other is a reduced representation assembly-based method. Among various machine learning techniques tested, the random forest technique showed promising results as a suitable classifier for both approaches. The PI also developed a versatile machine learning package to analyze large scale metagenomic data set for deriving microbiome-phenotype associations including disease prediction capability.          Last Modified: 07/30/2019       Submitted by: Tae Hyuk Ahn]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
