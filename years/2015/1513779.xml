<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: An Analysis of the Consequences of Cortical Structure on Computation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>706320.00</AwardTotalIntnAmount>
<AwardAmount>706320</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Networks of cortical neurons are clearly organized into layers and columns, but relatively little is known about how these arrangements affect cortical computations. To approach this issue, a 512 micro-electrode array will be used to stimulate and record activity from hundreds of cortical neurons. With this, the inputs and outputs of a cortical network can be experimentally controlled. A recently-developed framework for understanding neural computation known as "reservoir computing" permits the computational power of neural networks to be quantified based on knowledge of their inputs and outputs. The 512-electrode system allows input stimulation to be localized to different cortical layers or columns. Similarly, outputs can be selected by recording from different layers or columns. Thus, the contributions of layers and columns to computations, and the types of computations they perform, can be measured and compared. The results of this research are expected to increase the understanding of how the cortex attains its remarkable computational power. In addition, the results of this work are expected to inform future designs of brain-like computing circuits. To promote scientific education and outreach, an existing software package called "Simbrain" will be further developed and disseminated. This package will allow students from high school level and above to understand how cortical networks transform inputs into outputs as they perform computations.&lt;br/&gt;&lt;br/&gt;Three specific aims will be pursued. First, the measurement of computational capacity must be based on realistic levels of random background stimulation. The high-conductance state is a well-known phenomenon in vivo resulting from constant random synaptic inputs, and is also a common feature in many (particularly reservoir computing) neural circuit models. The 512-electrode array will be used to deliver background stimulation to determine levels that will improve computational performance. Second, layer input and output locations will be studied. Using kernel quality and VC-dimension metrics, the computational power and role of each layer taken individually or as a whole will be assessed. It is possible that some layers more strongly generalize input patterns while others separate them. Thus it will be possible to dissect the computational contribution of each layer. Third, the same metrics will be applied to stimulation to one column which feeds to another. Here the computational power and role of multiple columns will be assessed, and any computational differences between columns directly stimulated by the array and columns stimulated by other columns can be observed.</AbstractNarration>
<MinAmdLetterDate>09/01/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/19/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1513779</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Beggs</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John M Beggs</PI_FULL_NAME>
<EmailAddress>jmbeggs@indiana.edu</EmailAddress>
<PI_PHON>8128557359</PI_PHON>
<NSF_ID>000317259</NSF_ID>
<StartDate>09/01/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474013654</ZipCode>
<StreetAddress><![CDATA[509 E. Third Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7327</Code>
<Text>CRCNS-Computation Neuroscience</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~568753</FUND_OBLG>
<FUND_OBLG>2017~137567</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Overview: </strong>This research was aimed at understanding how networks of neurons in the brain compute. More specifically, we were interested in how the <em><span style="text-decoration: underline;">pattern of connections</span></em> between brain cells influenced <em><span style="text-decoration: underline;">how much they would compute</span></em>. First, let us describe more about how brain cells are connected, and how we measure computation. Then we will can explain what we found.</p> <p><strong>The pattern of connections</strong>: A typical neuron in the cortex is connected by synapses to thousands of other neurons. But not all these connections are used equally. We and others have found that usually only a few strong connections carry most of the information between neurons. A small fraction of neurons have many strong connections, and we call these hub neurons, in analogy to hub airports like LAX and ORD that have many flights arriving and leaving. &nbsp;Most neurons, though, are not hubs. It turns out that the hub neurons are much more likely to be connected to each other than you would expect by chance, forming what is called a rich club (Fig. 1). Given this interesting pattern of connections among neurons, we wanted to know where the computations would occur in the network. Would the hub neurons do most of the computing, or would the hubs merely route the information?</p> <p><strong>Measuring computation</strong>: The brain is, above all, a computing device that processes information for our survival. While many of the brain&rsquo;s computations are large and complex, they are always made up of smaller and simpler operations that we can measure. The logical AND operation is one of these basic computational atoms. For example, consider that a plane will take off only if (1) it has enough speed, AND (2) it is tilted upward at the proper angle; either (1) or (2) by themselves will be insufficient. &nbsp;A neuron can implement this AND operation in the following way: If neuron 1 AND neuron 2 send a signal to neuron 3, then it will turn on. A signal from only neuron 1 or only from neuron 2 will be insufficient. Most broadly, computations occur when the whole contains more information than the sum of information from the parts. Many types of logical operations, beyond the AND example here, have this property (OR, XOR, NAND). We can detect when this happens between triads of neurons using a measure called synergy. Using this measure, we were able to quantify the synergy between all triads of neurons in the network, including hub neurons and non-hub neurons. This allowed us to report, for the first time, a relationship between the network structure and the computations performed by the network.</p> <p><strong>What we found</strong>: We observed that computations occur most often at neurons that <em>receive</em> inputs from hub neurons. Notice that this does not say hub neurons are performing the computations themselves. Rather, hub neurons are feeding inputs to the neurons that are doing most of the computing (Fig. 2). Hub neurons are broadcasters of important information, and computations occur wherever two streams of important information collide. Follow up studies revealed that these two important streams produced the most computation when they had moderate levels of overlap. An analogy would be that creative ideas occur when two pieces of somewhat related information are combined. If the two pieces are completely unrelated or merely copies of each other, then no creation can occur.</p> <p><strong>Intellectual merit: </strong>These findings are important because they give us the first glimpse of how the brain is performing computations at the smallest scale, containing networks of a hundred or more interconnected neurons. While we know a great deal about how computers perform computations because we designed them, we know much less about how the brain performs computations. This research has allowed us to peer into the brain&rsquo;s central processing unit (CPU) for the first time. We expect this will spur more research into this interesting domain, where many new questions can now be asked: Why does the brain use this arrangement? Do neurons that compute a lot change over time, or are they stable? How might learning new information affect this arrangement in networks of cortical neurons?</p> <p><strong>Broader impacts</strong>: We expect that our findings will be relevant for the design of artificial neural networks that are increasingly used by artificial intelligence applications. Such applications currently do things like voice recognition, language translation, facial recognition, and driving autonomous vehicles. Because artificial neural networks are loosely based on the structure of the brain, learning more about how the brain actually performs computations is likely to improve these applications, thereby helping society more broadly. A total of 13 papers and two data sets from this work were made freely available. Part of this funding was also used to further develop and improve a software package called Simbrain for educators and researchers for constructing neural network models.&nbsp;</p><br> <p>            Last Modified: 09/30/2020<br>      Modified by: John&nbsp;M&nbsp;Beggs</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1513779/1513779_10394320_1601486182225_NSFLayDescriptionFigsRobustIntelligenceFig1--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1513779/1513779_10394320_1601486182225_NSFLayDescriptionFigsRobustIntelligenceFig1--rgov-800width.jpg" title="Hub neurons"><img src="/por/images/Reports/POR/2020/1513779/1513779_10394320_1601486182225_NSFLayDescriptionFigsRobustIntelligenceFig1--rgov-66x44.jpg" alt="Hub neurons"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The pattern of information traffic from hundreds of neurons in a sample of cortical tissue. The blue neurons are "hubs" with the most and strongest connections. Although relatively few in number, most of the information traffic flows through hubs.</div> <div class="imageCredit">John M. Beggs</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">John&nbsp;M&nbsp;Beggs</div> <div class="imageTitle">Hub neurons</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1513779/1513779_10394320_1601486317341_NSFLayDescriptionFigsRobustIntelligenceFig2--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1513779/1513779_10394320_1601486317341_NSFLayDescriptionFigsRobustIntelligenceFig2--rgov-800width.jpg" title="Computation occurs where streams from hub neurons converge"><img src="/por/images/Reports/POR/2020/1513779/1513779_10394320_1601486317341_NSFLayDescriptionFigsRobustIntelligenceFig2--rgov-66x44.jpg" alt="Computation occurs where streams from hub neurons converge"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Schematic showing that computations do not necessarily occur in hub neurons themselves, but rather in neurons that receive converging inputs from multiple hubs.</div> <div class="imageCredit">John M. Beggs</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">John&nbsp;M&nbsp;Beggs</div> <div class="imageTitle">Computation occurs where streams from hub neurons converge</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Overview: This research was aimed at understanding how networks of neurons in the brain compute. More specifically, we were interested in how the pattern of connections between brain cells influenced how much they would compute. First, let us describe more about how brain cells are connected, and how we measure computation. Then we will can explain what we found.  The pattern of connections: A typical neuron in the cortex is connected by synapses to thousands of other neurons. But not all these connections are used equally. We and others have found that usually only a few strong connections carry most of the information between neurons. A small fraction of neurons have many strong connections, and we call these hub neurons, in analogy to hub airports like LAX and ORD that have many flights arriving and leaving.  Most neurons, though, are not hubs. It turns out that the hub neurons are much more likely to be connected to each other than you would expect by chance, forming what is called a rich club (Fig. 1). Given this interesting pattern of connections among neurons, we wanted to know where the computations would occur in the network. Would the hub neurons do most of the computing, or would the hubs merely route the information?  Measuring computation: The brain is, above all, a computing device that processes information for our survival. While many of the brain’s computations are large and complex, they are always made up of smaller and simpler operations that we can measure. The logical AND operation is one of these basic computational atoms. For example, consider that a plane will take off only if (1) it has enough speed, AND (2) it is tilted upward at the proper angle; either (1) or (2) by themselves will be insufficient.  A neuron can implement this AND operation in the following way: If neuron 1 AND neuron 2 send a signal to neuron 3, then it will turn on. A signal from only neuron 1 or only from neuron 2 will be insufficient. Most broadly, computations occur when the whole contains more information than the sum of information from the parts. Many types of logical operations, beyond the AND example here, have this property (OR, XOR, NAND). We can detect when this happens between triads of neurons using a measure called synergy. Using this measure, we were able to quantify the synergy between all triads of neurons in the network, including hub neurons and non-hub neurons. This allowed us to report, for the first time, a relationship between the network structure and the computations performed by the network.  What we found: We observed that computations occur most often at neurons that receive inputs from hub neurons. Notice that this does not say hub neurons are performing the computations themselves. Rather, hub neurons are feeding inputs to the neurons that are doing most of the computing (Fig. 2). Hub neurons are broadcasters of important information, and computations occur wherever two streams of important information collide. Follow up studies revealed that these two important streams produced the most computation when they had moderate levels of overlap. An analogy would be that creative ideas occur when two pieces of somewhat related information are combined. If the two pieces are completely unrelated or merely copies of each other, then no creation can occur.  Intellectual merit: These findings are important because they give us the first glimpse of how the brain is performing computations at the smallest scale, containing networks of a hundred or more interconnected neurons. While we know a great deal about how computers perform computations because we designed them, we know much less about how the brain performs computations. This research has allowed us to peer into the brain’s central processing unit (CPU) for the first time. We expect this will spur more research into this interesting domain, where many new questions can now be asked: Why does the brain use this arrangement? Do neurons that compute a lot change over time, or are they stable? How might learning new information affect this arrangement in networks of cortical neurons?  Broader impacts: We expect that our findings will be relevant for the design of artificial neural networks that are increasingly used by artificial intelligence applications. Such applications currently do things like voice recognition, language translation, facial recognition, and driving autonomous vehicles. Because artificial neural networks are loosely based on the structure of the brain, learning more about how the brain actually performs computations is likely to improve these applications, thereby helping society more broadly. A total of 13 papers and two data sets from this work were made freely available. Part of this funding was also used to further develop and improve a software package called Simbrain for educators and researchers for constructing neural network models.        Last Modified: 09/30/2020       Submitted by: John M Beggs]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
