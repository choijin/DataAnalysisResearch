<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CC*DNI Engineer: Cyberinfrastructure Engineer at Case Western Reserve University</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2016</AwardEffectiveDate>
<AwardExpirationDate>02/28/2019</AwardExpirationDate>
<AwardTotalIntnAmount>399524.00</AwardTotalIntnAmount>
<AwardAmount>399524</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kevin Thompson</SignBlockName>
<PO_EMAI>kthompso@nsf.gov</PO_EMAI>
<PO_PHON>7032924220</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Case Western Reserve University (CWRU) has made significant investment in its campus cyberinfrastructure to support research that is increasingly compute-, data-, and network-intensive. The NSF-funded Cyberinfrastructure Engineer (CIE) collaborates closely with researchers to understand their needs and guide their use of cyberinfrastructure to ensure optimal benefit, and also works with university network engineers to make architectural, design, and configuration changes to the cyberinfrastructure to better serve the research community and ensure they are able to fully leverage local, regional, and national cyberinfrastructure. The CIE is part of an emerging program that embeds staff from the university's Research Computing and Cyberinfrastructure (RCCI) unit within key research groups to provide a liaison between these groups and to provide collaborative technical support for their needs in cyberinfrastructure, including high performance computing, data-intensive computing, private cloud, peta-scale storage, and end-to-end network performance. The CIE engages not only with CWRU research groups, but also with their collaborators at other institutions to ensure the optimal use of cyberinfrastructure resources at all institutions and along the network paths that link them. Such activity is a critically important success factor as researchers tackle increasingly large problems and collaborate in geographically distributed research teams, and as they work to converge data-intensive and numerically intensive computing within the National Strategic Computing Initiative. Finally, the CIE participates in formal classroom presentations to students who rely on campus cyberinfrastructure in their research and learning experience in STEM education.&lt;br/&gt;&lt;br/&gt;At CWRU, the CIE has primary responsibility for the university Science DMZ , perfSONAR, and data transfer node services.  As the Science DMZ is tightly integrated with the university's high performance computing, data-intensive computing, private cloud, peta-scale online research storage, and near-line research data archive services, the CIE's responsibility extends into all areas of campus cyberinfrastructure and requires close coordination and collaboration with staff having primary responsibility in those areas.  To ensure optimal end-to-end network performance, the CIE routinely works in collaboration with peers at other universities, government institutions, and regional and national networking organizations including Internet2, the Ohio Academic and Research Network, Ohio Supercomputing Center, NIH facilities such as NCBI, DoE facilities such as ORNL, and the NSF-funded national supercomputer centers. The CIE is involved in the university's efforts in IPv6, identity and access management, SDN, and OpenFlow, and works closely with information security and the network security groups.</AbstractNarration>
<MinAmdLetterDate>03/10/2016</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1541170</AwardID>
<Investigator>
<FirstName>Roger</FirstName>
<LastName>Bielefeld</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Roger A Bielefeld</PI_FULL_NAME>
<EmailAddress>Roger.Bielefeld@case.edu</EmailAddress>
<PI_PHON>2163683971</PI_PHON>
<NSF_ID>000587845</NSF_ID>
<StartDate>03/10/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sue</FirstName>
<LastName>Workman</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sue B Workman</PI_FULL_NAME>
<EmailAddress>sue.workman@case.edu</EmailAddress>
<PI_PHON>2163684510</PI_PHON>
<NSF_ID>000688559</NSF_ID>
<StartDate>03/10/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Case Western Reserve University</Name>
<CityName>CLEVELAND</CityName>
<ZipCode>441064901</ZipCode>
<PhoneNumber>2163684510</PhoneNumber>
<StreetAddress>Nord Hall, Suite 615</StreetAddress>
<StreetAddress2><![CDATA[10900 Euclid Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH11</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>077758407</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CASE WESTERN RESERVE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>077758407</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Case Western Reserve University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>441064901</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH11</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8080</Code>
<Text>Campus Cyberinfrastructure</Text>
</ProgramElement>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~399524</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-18651d38-7fff-17f3-9de4-c2beadbfa342"> <span id="docs-internal-guid-18dd05d3-7fff-643c-1b11-93d739e43d01"> <span id="docs-internal-guid-e28b9c38-7fff-f76f-9cc7-a8d8ce2eafae"> <span id="docs-internal-guid-dd8eab79-7fff-7aae-00fe-c77f96a150d5"> <span id="docs-internal-guid-b0fdf564-7fff-dd36-b358-822e57c68ce0"> <span id="docs-internal-guid-191f5f3e-7fff-bca3-91a1-a44ddeffdd6c"> <span id="docs-internal-guid-cdca04b0-7fff-4ae7-3b92-ee748c0ded0e"> <span id="docs-internal-guid-526d84b3-7fff-c39a-8ce7-4674d5d1ccc8"> <span id="docs-internal-guid-5a8f9886-7fff-357f-4524-7d18eba7017b"> <span id="docs-internal-guid-71668f54-7fff-cfbd-8fa5-cba5fa3ac0a3"> <span id="docs-internal-guid-a4fbb927-7fff-0480-aead-1318bccfc131"> </span></span></span></span></span></span></span></span></span></span></span></p> <p><span id="docs-internal-guid-43a9a641-7fff-ed95-de06-4992241f72a9">&nbsp;</span></p> <p><span id="docs-internal-guid-7ef58b96-7fff-3ff1-f862-e054811454a0"> <p dir="ltr"><span>This award provided funding for a Cyberinfrastructure Engineer (CIE) within the Research Computing and Cyberinfrastructure (RCCI) group at Case Western Reserve University (CWRU) for two years. The CIE&rsquo;s activities, intended to benefit facult</span><span>y and researchers who use the university&rsquo;s cyberinfrastructure, fell into three categories.</span></p> <p dir="ltr"><span>First, the CIE worked directly with researchers to understand their needs</span><span> related to use of the campus network and then made changes to researcher practices, end-point networking equipment, and network infrastructure, to bring demonstrable improvement. </span><span>While significant impact occurred in many areas, including materials science, cryo-electron microscopy, pharmacology, biomedical engineering, computer science, pathology imaging, physics, and biology, some notable successes stand out.</span></p> <p dir="ltr"><span>School of Medicine: In the Department of Genetics and Genomic Sciences, CIE intervention led to ten-fold increase in speed of transfers of massive genetic and genomic datasets. In the Cleveland Center for Membrane and Structural Biology, t</span><span>he CIE is involved in planning for installation of a Titan Krios electron microscope in the summer of 2019. The CIE analyzed the existing network path from the installation site to the high performance computing (HPC) data center where data will be hosted and processed, recommended changes to the path, and worked with the network engineering group on an equipment upgrade for the building and to ensure the path was error free and capable of sustained 10 Gbps transfers.</span></p> <p dir="ltr"><span>School of Engineering: The CIE worked with researchers in the Great Lakes Energy Institute and the Department of Materials Science and Engineering to add network infrastructure and reconfigure laboratory networking to facilitate the import of large data files from power generating plants throughout the world.</span></p> <p dir="ltr"><span>Secure Research Environment: The CIE worked with the staff of the university&rsquo;s Secure Research Environment (SRE) to troubleshoot data flows into that facility. The SRE, which operates in a commercial Tier 3 data center, warehouses records containing personal health information and other regulated data and supports research in areas such as cancer, neurodegenerative diseases, causes and prevention of violence, causes and effects of poverty, biology of microorganisms, and clinical and translational science. The CIE installed a perfSONAR node in a virtual machine in the SRE to aid in detecting reported performance issues and to monitor the speed and quality of future data transmission. With the success of this somewhat non-standard installation, another VM-based perfSONAR node was installed in the AWS cloud to enable improved monitoring of external connections to the SRE.</span></p> <p dir="ltr"><span>Second, the CIE served as a key member of a group that redesigned the network infrastructure serving the university&rsquo;s HPC cluster and research storage systems. &nbsp;The redesign provides bandwidth of 100 gigabits per second at the spine of the network and 25 gigabits per second bandwidth to each connected device, and added security and scalability features. </span><span>The CIE led the installation and configuration effort and continues with monitoring and ongoing support.</span></p> <p dir="ltr"><span>Third, the CIE was a key person in designing and supporting the new &ldquo;Research VM&rdquo; service that provid</span><span>es virtual machines to faculty for research use in alignment with new security standards adopted by the university. This service is critical to the success of the university&rsquo;s IT centralization effort that requires moving faculty-operated research servers to a university data center and virtualizing them when possible. </span><span>The CIE is helping to socialize the changes to researchers and acts as their advocate in the context of IT centralization.</span></p> <p dir="ltr"><span>Beyond these on-campus activities, the CIE was active locally, regionally, and nationally. In 2016 she attended the </span><span>OIN workshop in Nashville and the Arista Cloud Builders Conference in Columbus, Ohio. In 2017, she attended the Ohio Supercomputer Center's Statewide Users Group meeting to learn how their resources are used by researchers at CWRU, and collaborated with the CIEs from the University of Cincinnati and OARnet on a presentation at the Ohio Higher Education Computing Conference entitled "Fostering use of high-speed networks, HPCs, and Science DMZs". Later in 2017, at the Quilt workshop&rsquo;s Cyberinfrastructure Engineer breakout session in Albuquerque, the CIE participated on the panel "CI Engineering Support in a Campus or Region" and the PI participated on the panel &ldquo;What Does Success Look Like for the CI Engineer Position?&rdquo;.</span></p> <p dir="ltr"><span>In 2018, the CIE attended a training class &ldquo;VMware NSX: Install, Configure, Manage plus Troubleshooting and Operations Fast Track [V6.2]&rdquo;, attended the 2018 PEARC (Practice &amp; Experience in Advanced Research Computing) conference, attended the Internet2 Global Summit, and attended training for VMware vSphere: Install, Configure, Manage [V6.5]. The PI moderated a panel discussion on CC* Project Sustainability at the NSF Campus Cyberinfrastructure and Cybersecurity Innovation for Cyberinfrastructure PI Workshop in College Park, MD in September 2018.</span></p> <p dir="ltr"><span>This NSF funding helped to secure university funding for a second, similar CIE position - in addition to the university taking on the full salary of the first CIE when NSF funding expired.</span></p> </span></p><br> <p>            Last Modified: 05/23/2019<br>      Modified by: Roger&nbsp;A&nbsp;Bielefeld</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[                  This award provided funding for a Cyberinfrastructure Engineer (CIE) within the Research Computing and Cyberinfrastructure (RCCI) group at Case Western Reserve University (CWRU) for two years. The CIE?s activities, intended to benefit faculty and researchers who use the university?s cyberinfrastructure, fell into three categories. First, the CIE worked directly with researchers to understand their needs related to use of the campus network and then made changes to researcher practices, end-point networking equipment, and network infrastructure, to bring demonstrable improvement. While significant impact occurred in many areas, including materials science, cryo-electron microscopy, pharmacology, biomedical engineering, computer science, pathology imaging, physics, and biology, some notable successes stand out. School of Medicine: In the Department of Genetics and Genomic Sciences, CIE intervention led to ten-fold increase in speed of transfers of massive genetic and genomic datasets. In the Cleveland Center for Membrane and Structural Biology, the CIE is involved in planning for installation of a Titan Krios electron microscope in the summer of 2019. The CIE analyzed the existing network path from the installation site to the high performance computing (HPC) data center where data will be hosted and processed, recommended changes to the path, and worked with the network engineering group on an equipment upgrade for the building and to ensure the path was error free and capable of sustained 10 Gbps transfers. School of Engineering: The CIE worked with researchers in the Great Lakes Energy Institute and the Department of Materials Science and Engineering to add network infrastructure and reconfigure laboratory networking to facilitate the import of large data files from power generating plants throughout the world. Secure Research Environment: The CIE worked with the staff of the university?s Secure Research Environment (SRE) to troubleshoot data flows into that facility. The SRE, which operates in a commercial Tier 3 data center, warehouses records containing personal health information and other regulated data and supports research in areas such as cancer, neurodegenerative diseases, causes and prevention of violence, causes and effects of poverty, biology of microorganisms, and clinical and translational science. The CIE installed a perfSONAR node in a virtual machine in the SRE to aid in detecting reported performance issues and to monitor the speed and quality of future data transmission. With the success of this somewhat non-standard installation, another VM-based perfSONAR node was installed in the AWS cloud to enable improved monitoring of external connections to the SRE. Second, the CIE served as a key member of a group that redesigned the network infrastructure serving the university?s HPC cluster and research storage systems.  The redesign provides bandwidth of 100 gigabits per second at the spine of the network and 25 gigabits per second bandwidth to each connected device, and added security and scalability features. The CIE led the installation and configuration effort and continues with monitoring and ongoing support. Third, the CIE was a key person in designing and supporting the new "Research VM" service that provides virtual machines to faculty for research use in alignment with new security standards adopted by the university. This service is critical to the success of the university?s IT centralization effort that requires moving faculty-operated research servers to a university data center and virtualizing them when possible. The CIE is helping to socialize the changes to researchers and acts as their advocate in the context of IT centralization. Beyond these on-campus activities, the CIE was active locally, regionally, and nationally. In 2016 she attended the OIN workshop in Nashville and the Arista Cloud Builders Conference in Columbus, Ohio. In 2017, she attended the Ohio Supercomputer Center's Statewide Users Group meeting to learn how their resources are used by researchers at CWRU, and collaborated with the CIEs from the University of Cincinnati and OARnet on a presentation at the Ohio Higher Education Computing Conference entitled "Fostering use of high-speed networks, HPCs, and Science DMZs". Later in 2017, at the Quilt workshop?s Cyberinfrastructure Engineer breakout session in Albuquerque, the CIE participated on the panel "CI Engineering Support in a Campus or Region" and the PI participated on the panel "What Does Success Look Like for the CI Engineer Position?". In 2018, the CIE attended a training class "VMware NSX: Install, Configure, Manage plus Troubleshooting and Operations Fast Track [V6.2]", attended the 2018 PEARC (Practice &amp; Experience in Advanced Research Computing) conference, attended the Internet2 Global Summit, and attended training for VMware vSphere: Install, Configure, Manage [V6.5]. The PI moderated a panel discussion on CC* Project Sustainability at the NSF Campus Cyberinfrastructure and Cybersecurity Innovation for Cyberinfrastructure PI Workshop in College Park, MD in September 2018. This NSF funding helped to secure university funding for a second, similar CIE position - in addition to the university taking on the full salary of the first CIE when NSF funding expired.        Last Modified: 05/23/2019       Submitted by: Roger A Bielefeld]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
