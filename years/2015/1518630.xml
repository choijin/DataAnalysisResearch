<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Large: Collaborative Research: TextureShop: Tools for the Composition and Display of Virtual Texture</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>328243.00</AwardTotalIntnAmount>
<AwardAmount>328243</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When we interact with the physical world touch is a vitally important sensory channel, but when we interact with the digital world that is not yet the case.  Historically, this situation may have been principally due to inadequate tactile displays, but that limitation is quickly disappearing.  Increasingly, the principal limitation is the lack of tactile content.  The goal of this collaborative research that involves scientists at three institutions is to empower the content creator, by enabling people to perform the same sorts of operations with tactile textures that they routinely perform with photographs.  Those operations include "capturing" a texture, building a mathematical representation of it, creating and displaying synthetic versions that feel very much like the original, enhancing it in various ways (e.g., making it rougher or more velvety), and ultimately "composing" novel textures that nonetheless feel realistic and credible.  As a tangible step in this direction, an open source, open hardware project begun under prior NSF support will be continued and expanded.  That project resulted in the distribution of surface haptic devices to about a dozen different labs, leading to a variety of research studies.  In this project, a low-cost surface haptic display and a variety of applications and software tools will be distributed to about 50 early adopters in the research community.  Those individuals will be engaged in this research (e.g., by helping to "tag" various textures), and will be empowered to carry out their own research.  In addition, workshops will be organized at major human-computer interaction conferences to support the growing surface haptics community.&lt;br/&gt;&lt;br/&gt;This work is timely and compelling for a number of reasons.  One, scientific understanding of the physical and neuronal bases of texture perception has advanced considerably in recent years.  For instance, the relationships between vibrations on the skin (produced when a finger slides across a surface), spike timing in afferent neurons, and high-level percepts such as recognition of a specific texture, have recently been elucidated.  Two, "surface haptic" technologies for displaying texture to the bare fingertips have also advanced significantly and can now display complex stimuli across the full bandwidth of tactile acuity.  Three, the prevalence of touch screen interfaces has created a plethora of applications such as children's e-books, interfaces for the blind, games, and automobile control panels, which would be well-served by high quality tactile content.  The merit of this research is that it will provide a principled foundation for both the creation and manipulation of that content.  Contributions will include: the development of a "tactile camera" that is able to capture the relevant frictional and vibratory data from which realistic textures can be recreated; a novel mathematical representation of the salient aspects of texture as well as algorithms for synthesizing artificial textures on the basis of that representation; a suite of techniques for enhancing aspects of texture by direct operation on the mathematical representation, interpolation between multiple textures, and interaction with audio cues; and finally a set of tools for composing novel textures including search, texture combination and scale transformation.</AbstractNarration>
<MinAmdLetterDate>07/13/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1518630</AwardID>
<Investigator>
<FirstName>Roberta</FirstName>
<LastName>Klatzky</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Roberta L Klatzky</PI_FULL_NAME>
<EmailAddress>klatzky@cmu.edu</EmailAddress>
<PI_PHON>4122688026</PI_PHON>
<NSF_ID>000330465</NSF_ID>
<StartDate>07/13/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave WQED Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~80334</FUND_OBLG>
<FUND_OBLG>2016~80442</FUND_OBLG>
<FUND_OBLG>2017~167467</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The TextureShop project was dedicated to developing and evaluating new technologies for creating textures on a device with a glass surface, like a tablet computer or smart phone.&nbsp; Technological developments allow us to create textures by programming the device to change the friction of the glass from moment to moment, which makes it more or less difficult to move one's fingers across it.&nbsp; By controlling changes in friction, we aimed to produce a sense of texture on the surface of what otherwise would feel like a flat glass plate.&nbsp;&nbsp;Engineers and cognitive scientists worked together to develop these devices and conduct scientific experiments to determine how effective they are, and why.&nbsp;&nbsp;</p> <p>Our outcomes include developing computer algorithms that allow people to feel a broad array of textures: rough and smooth, patterns or buzzes, changing in one sweep direction or the other, and so on.&nbsp; Our research extends to understanding how the biological sense of touch responds to changing friction on the glass surface, ultimately giving rise to an impression that there is actually a textured material there.&nbsp;</p> <p>The broader impacts of our research are to&nbsp;enable people to use their phones and tablets as real "touch screens," which not only sense touch, but deliver tactual impressions to the users.&nbsp; This could be valuable in on-line marketing, where people are currently restricted to seeing products they might like to touch.&nbsp; Touch input is also of potential use in aiding people with limited or no vision to find their way on a glass computer screen.&nbsp; Touch-screens could be used in automobiles, allowing people to tune their radio without looking at the control knobs, for example.</p> <p>The broader impacts of this research also include training engineers, computer scientists, and psychological scientists.&nbsp; Engineers, whose basic training focuses on creating and implementing technologies like touch devices, have learned how to study their effects on the human mind and brain.&nbsp; Students of psychology, whose focus is on measuring and analyzing human behavior, have learned to understand new technologies and their impact on the human user.&nbsp; &nbsp;Computer scientists bring their algorithms into new and exciting areas of application.</p><br> <p>            Last Modified: 08/06/2021<br>      Modified by: Roberta&nbsp;L&nbsp;Klatzky</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The TextureShop project was dedicated to developing and evaluating new technologies for creating textures on a device with a glass surface, like a tablet computer or smart phone.  Technological developments allow us to create textures by programming the device to change the friction of the glass from moment to moment, which makes it more or less difficult to move one's fingers across it.  By controlling changes in friction, we aimed to produce a sense of texture on the surface of what otherwise would feel like a flat glass plate.  Engineers and cognitive scientists worked together to develop these devices and conduct scientific experiments to determine how effective they are, and why.    Our outcomes include developing computer algorithms that allow people to feel a broad array of textures: rough and smooth, patterns or buzzes, changing in one sweep direction or the other, and so on.  Our research extends to understanding how the biological sense of touch responds to changing friction on the glass surface, ultimately giving rise to an impression that there is actually a textured material there.   The broader impacts of our research are to enable people to use their phones and tablets as real "touch screens," which not only sense touch, but deliver tactual impressions to the users.  This could be valuable in on-line marketing, where people are currently restricted to seeing products they might like to touch.  Touch input is also of potential use in aiding people with limited or no vision to find their way on a glass computer screen.  Touch-screens could be used in automobiles, allowing people to tune their radio without looking at the control knobs, for example.  The broader impacts of this research also include training engineers, computer scientists, and psychological scientists.  Engineers, whose basic training focuses on creating and implementing technologies like touch devices, have learned how to study their effects on the human mind and brain.  Students of psychology, whose focus is on measuring and analyzing human behavior, have learned to understand new technologies and their impact on the human user.   Computer scientists bring their algorithms into new and exciting areas of application.       Last Modified: 08/06/2021       Submitted by: Roberta L Klatzky]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
