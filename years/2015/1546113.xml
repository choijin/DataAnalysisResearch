<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: F: DeepWalking Graphs for Feature Extraction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2016</AwardEffectiveDate>
<AwardExpirationDate>12/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>731260.00</AwardTotalIntnAmount>
<AwardAmount>731260</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The sparsity of large networks makes it difficult to efficiently extract features for machine learning algorithms. Recent work on network embeddings (DeepWalk) has revealed how neural language modeling can be applied to a very general class of graph analysis problems in data mining and information retrieval.  This project will improve training algorithms and data representation for large-scale networks, creating better, more powerful graph embeddings for weighted and attributed networks.  It will also enable meaningful comparison of the relative performance of network connectivity features vs. more text-oriented features. It is possible that there might be more usable information in links than in the readable content itself.&lt;br/&gt;&lt;br/&gt;This project will develop these methods in several new directions, including extensions to new graph classes and speed/scale enhancements.  The original DeepWalk induced latent representations only from unweighted, undirected, and connected graphs. But there is considerable interest in applying it to more general graphs arising in data analysis. Doing the right thing on such natural networks as bipartite and disconnected graphs presents surprisingly subtle issues of theoretical and practical significance.  This project will also explore several ideas to increase training performance of network embeddings, including more efficient gradient updates and improved graph sampling methods and particularly the power of self-avoiding random walks to oversample otherwise rare nodes.  This project seeks to extend the effective range of DeepWalk by several orders of magnitude, from the 10 million vertex graphs we routinely handle today to web-scale networks on billions of nodes.  The broader impacts of this work are far reaching across data mining and information retrieval, including user profiling/demographic inference, online advertising, and fraud detection.  The software and data resources developed under this research project will be released as open source. They will be directly applicable to the biomedical and social sciences, and serve as both an educational and scholarly resource.  For further information, see the project website at http://www.cs.stonybrook.edu/~skiena/deepwalking.</AbstractNarration>
<MinAmdLetterDate>09/14/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/14/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1546113</AwardID>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Skiena</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven Skiena</PI_FULL_NAME>
<EmailAddress>skiena@cs.sunysb.edu</EmailAddress>
<PI_PHON>5166329026</PI_PHON>
<NSF_ID>000199813</NSF_ID>
<StartDate>09/14/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stony Brook University]]></Name>
<CityName>Stony Brook</CityName>
<StateCode>NY</StateCode>
<ZipCode>117944400</ZipCode>
<StreetAddress><![CDATA[Dept. of Computer Science]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~731260</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-e6d8b0d3-7fff-dd62-c4c8-1101fae7f53e"> </span></p> <p dir="ltr"><span>Many large and important data sets revolve around networks of related entities, including social, communications, and citation networks. &nbsp; Making effective use of such network data for machine learning models is an important intellectual and practical challenge.&nbsp; Graph embeddings are a way to reduce network data to numerical feature vectors which are well suited for building machine learning models.</span></p> <p dir="ltr"><span>Our DeepWalk approach to construct graph embeddings based on random walks revealed how neural language modeling could be applied to a very general class of graph analysis problems in data mining and information retrieval.&nbsp; These techniques have been widely used in industry, and been cited over 4500 times to date. &nbsp; In this project, we developed several directions to build better graph embeddings, including extensions to new graph classes and speed/scale enhancements.</span></p> <p dir="ltr"><span>One important issue in graph embeddings concerns the properties of the random walks employed.&nbsp; Walklets are a technique where we explicitly factor the kth power of a graph, by constructing separate embeddings for different skip lengths. We demonstrate that larger skips are more appropriate for sparse graphs.&nbsp; Another direction concerns graph compression.&nbsp; HARP is a hierarchical approach to constructing embeddings of large graphs, by contracting the graph to a small enough size that its structure can be induced, and using this to guide the embedding of the expanded graph. &nbsp; We show that our methods improve the global structure of embeddings, and can be used to augment all major approaches to graph embeddings.</span></p> <p dir="ltr"><span>Although DeepWalk-style graph embeddings are widely used in industry, they are expensive to compute for large networks. &nbsp; We made dramatic progress towards our goal of faster graph embeddings through a new random projection method, which we have demonstrated can build almost DeepWalk-quality embeddings with a speedup of over 4000 times over previous methods.</span></p> <p dir="ltr"><span>We have also worked on several directions to extend the power of embeddings, including visualization, edge embeddings, multilingual word embeddings, and knowledge graphs.&nbsp; Finally, with our collaborators in neuroscience and sociology, we have employed embeddings to better understand how the brain develops and recent changes in language usage.</span></p> <div><span><br /></span></div> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/09/2021<br>      Modified by: Steven&nbsp;Skiena</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Many large and important data sets revolve around networks of related entities, including social, communications, and citation networks.   Making effective use of such network data for machine learning models is an important intellectual and practical challenge.  Graph embeddings are a way to reduce network data to numerical feature vectors which are well suited for building machine learning models. Our DeepWalk approach to construct graph embeddings based on random walks revealed how neural language modeling could be applied to a very general class of graph analysis problems in data mining and information retrieval.  These techniques have been widely used in industry, and been cited over 4500 times to date.   In this project, we developed several directions to build better graph embeddings, including extensions to new graph classes and speed/scale enhancements. One important issue in graph embeddings concerns the properties of the random walks employed.  Walklets are a technique where we explicitly factor the kth power of a graph, by constructing separate embeddings for different skip lengths. We demonstrate that larger skips are more appropriate for sparse graphs.  Another direction concerns graph compression.  HARP is a hierarchical approach to constructing embeddings of large graphs, by contracting the graph to a small enough size that its structure can be induced, and using this to guide the embedding of the expanded graph.   We show that our methods improve the global structure of embeddings, and can be used to augment all major approaches to graph embeddings. Although DeepWalk-style graph embeddings are widely used in industry, they are expensive to compute for large networks.   We made dramatic progress towards our goal of faster graph embeddings through a new random projection method, which we have demonstrated can build almost DeepWalk-quality embeddings with a speedup of over 4000 times over previous methods. We have also worked on several directions to extend the power of embeddings, including visualization, edge embeddings, multilingual word embeddings, and knowledge graphs.  Finally, with our collaborators in neuroscience and sociology, we have employed embeddings to better understand how the brain develops and recent changes in language usage.               Last Modified: 03/09/2021       Submitted by: Steven Skiena]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
