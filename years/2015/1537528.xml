<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Understanding the Strategic Values of Privacy Practices in Organizations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>239138.00</AwardTotalIntnAmount>
<AwardAmount>239138</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
<PO_EMAI>skiesler@nsf.gov</PO_EMAI>
<PO_PHON>7032928643</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As companies collect consumer data in increasingly larger quantity and mine the data more deeply, trade-offs arise with respect to companies' practices about information privacy.  A company may choose practices that augment targeted advertisements or services.  However, the financial rewards associated with privacy practices are highly uncertain, since they are affected by a company's competition with rivals.  Moreover, such practices expose the company to privacy risks, in that it is burdened with safeguarding sensitive data against theft, and may suffer negative consequences from data loss such as revenue decrease, public outcry and penalty by governments.  This research aims to help companies make strategically valuable and socially responsible decisions about privacy practices.  The researchers develop a broadly applicable analytical framework on making decisions about information privacy under uncertainty by companies, organizations, governmental agencies, and individuals.  In particular, the framework provides the first risk-based analysis on a company's decision-making about privacy practices.  It is also among the first to analyze the strategic values of privacy practices and how such practices affect the relative performance of competing companies.  The results of the research will lead to new conversations and provide a better understanding about the interplay among (1) companies' practices and attitudes toward privacy; (2) companies' competitive behavior and outcome; and (3) new technologies.  The broader impact of the research lies in the development of new methodologies for companies to evaluate their privacy practices and better position themselves in a competitive environment in a socially responsible way.  It also lies in helping policy makers understand the trade-offs faced by companies when proposing privacy regulations to balance company performance and consumer welfare. &lt;br/&gt;&lt;br/&gt;The framework builds on the risk theories in economics, which provide formulations and general tools for analyzing preferences, valuations and choices among risky alternatives.  The analysis is distinct by its formulation of choice under privacy risks, where the risk-model parameters cover the set of consequences, states of nature, set of actions, and the probabilities.  It is useful for studying the effects of privacy-related investments, policies and technology adoptions by examining how they alter the parameters.  The analysis is also augmented with elements from behavioral economics, but focuses on companies' behavioral patterns.  More importantly, the analysis extends the choice under privacy risks by incorporating strategy research on competitive advantage and competitive interactions among rival companies.  It asks whether and how privacy practices can be a source of competitive advantage and affect company performance.</AbstractNarration>
<MinAmdLetterDate>09/03/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/03/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1537528</AwardID>
<Investigator>
<FirstName>Ye</FirstName>
<LastName>Xia</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ye Xia</PI_FULL_NAME>
<EmailAddress>yx1@cise.ufl.edu</EmailAddress>
<PI_PHON>3525051571</PI_PHON>
<NSF_ID>000092304</NSF_ID>
<StartDate>09/03/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gwendolyn</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gwendolyn K Lee</PI_FULL_NAME>
<EmailAddress>gwendolyn.lee@warrington.ufl.edu</EmailAddress>
<PI_PHON>3523923516</PI_PHON>
<NSF_ID>000531920</NSF_ID>
<StartDate>09/03/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Florida</Name>
<CityName>GAINESVILLE</CityName>
<ZipCode>326112002</ZipCode>
<PhoneNumber>3523923516</PhoneNumber>
<StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>969663814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Florida]]></Name>
<CityName>GAINESVILLE</CityName>
<StateCode>FL</StateCode>
<ZipCode>326116120</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~239138</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The broader impact of our research is the development of a broadly applicable analytical framework that helps companies make strategically valuable and socially responsible decisions about privacy practices.&nbsp; The framework that we developed through this research is the first risk-based analysis on a company's decision-making about privacy practices.&nbsp; It's also among the first to analyze the strategic values of privacy practices and how such practices affect the relative performance of competing companies.&nbsp; Our premise is that the consequences of privacy harm are distant and intangible, while the sources of privacy harm originate from data users' potential biases and inaccuracies in data analytics.&nbsp; Privacy harms may arise as consequences of intended and unintended use of data. &nbsp;Data that seemed to raise no, or only manageable, threats to privacy at the time of their collection can later lead to significant privacy harms, when large, diverse data sets and novel inference algorithms are brought together.</p> <p>Our framework has two classes of game-theoretical models, in which risk is a choice companies make in competitive games. &nbsp;One class of models focuses on how sensitive the companies' choices are to the shape of risk-return distribution. &nbsp;The other class addresses consumer risk tolerance of privacy harm, examining how companies spread themselves apart from one another in the space of risk strategies and showing the conditions under which companies would converge toward the same risk strategy, such as collecting as much personally identifiable information (PII) as possible. &nbsp;Our models build on foundational research in strategy science that addresses competitive advantage and competitive interactions among rival companies.&nbsp; The analysis of the choices that companies make under various scenarios informs whether and how privacy practices can be a source of competitive advantage and affect company performance.</p> <p>We illustrate companies' choices of how much PII to collect with the industry context of mobile health, which is the use of mobile computing and communications technologies in the delivery of healthcare. &nbsp;Innovation in data storage and parsing power increases the value of digital health information. &nbsp;Information privacy, however, is a grave concern when PII is collected by mobile devices enhanced with sensors that monitor the data subjects continuously and with software apps that record the data subjects' personal health information including lab test results, diagnostic images, a medication log of drug names, dosages, dispensing pharmacies and dates, diet details, lifestyles, social interactions, family history and possibly genetic profiles. &nbsp;Data elements vary in their sensitivity to data subjects. &nbsp;Genetic profiles, compared to other PII such as full names, medications, health conditions, and treatments received, make data subjects more sensitive about having their genetic profiles collected, as genetic variations are linked to certain cancer types and diseases. &nbsp;Although the profiles are useful to patients and healthcare providers in facilitating the delivery of personalized medicine, consumers face privacy risks of suffering discrimination or other harms from having their genetic profiles revealed. &nbsp;An individual's genetic profile reveals the future health of not only the individual but also their biological relatives such as children and parents.</p> <p>Applying our framework to the context of mobile health, we deduce exactly how far apart the developers of mobile devices enhanced with sensors and software apps would spread out in the space of risk strategies.&nbsp; When very few rivals compete, the developers separate themselves out and space far apart from each other. &nbsp;As the number of rivals increases, the developers continue to avoid each other.&nbsp; No two developers choose the same strategy. &nbsp;The finding that the developers do not converge toward the same strategy uncovers the conditions under which consumer risk tolerance and competitive interaction among rivals would affect the choice of how much PII to collect. &nbsp;However, when the competitive intensity is high, a substantial fraction of the developers would choose to take risks at equal or near the highest level.&nbsp; That is, a highly competitive environment forces many developers toward taking huge privacy risks, thereby resulting in huge privacy risks for the consumers.</p> <p>In addition to developing game-theoretic models, we enrich the framework with empirical data. &nbsp;An empirical analysis of companies' privacy practices that are associated with data breaches, security failures as well as legal enforcements actions and sanctions helps us establish a minimum behavioral standard with respect to the company's relationship to its stakeholders, below which corporate behavior becomes socially irresponsible. &nbsp;The stakeholders notably include data subjects, beyond the conventional categories of employees, customers, suppliers, investors, and the local community within which the companies operate. &nbsp;The issue of causing stakeholders harm (intentionally or not) largely has been ignored in the corporate social responsibility (CSR) literature.&nbsp; One of the intellectual merits of our research is the insights that we derive from the game-theoretic models and the empirical data, contributing to the CSR literature a perspective on the risk of harming the privacy of data subjects as a company's strategic choice.</p><br> <p>            Last Modified: 11/08/2018<br>      Modified by: Gwendolyn&nbsp;K&nbsp;Lee</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1537528/1537528_10395882_1541675423705_NSF_SaTC_Research_Highlight_2017--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1537528/1537528_10395882_1541675423705_NSF_SaTC_Research_Highlight_2017--rgov-800width.jpg" title="Research Highlight"><img src="/por/images/Reports/POR/2018/1537528/1537528_10395882_1541675423705_NSF_SaTC_Research_Highlight_2017--rgov-66x44.jpg" alt="Research Highlight"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Understanding the Strategic Values of Privacy Practices in Organizations</div> <div class="imageCredit">NSF SaTC PI Meeting</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Gwendolyn&nbsp;K&nbsp;Lee</div> <div class="imageTitle">Research Highlight</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1537528/1537528_10395882_1541713279884_NSF_SaTC_PI_Poster_2017--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1537528/1537528_10395882_1541713279884_NSF_SaTC_PI_Poster_2017--rgov-800width.jpg" title="SaTC Poster Session"><img src="/por/images/Reports/POR/2018/1537528/1537528_10395882_1541713279884_NSF_SaTC_PI_Poster_2017--rgov-66x44.jpg" alt="SaTC Poster Session"></a> <div class="imageCaptionContainer"> <div class="imageCaption">National Science Foundation Secure and Trustworthy Cyberspace Principal Investigator Meeting, Poster Session</div> <div class="imageCredit">NSF SaTC PI Meeting</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Gwendolyn&nbsp;K&nbsp;Lee</div> <div class="imageTitle">SaTC Poster Session</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The broader impact of our research is the development of a broadly applicable analytical framework that helps companies make strategically valuable and socially responsible decisions about privacy practices.  The framework that we developed through this research is the first risk-based analysis on a company's decision-making about privacy practices.  It's also among the first to analyze the strategic values of privacy practices and how such practices affect the relative performance of competing companies.  Our premise is that the consequences of privacy harm are distant and intangible, while the sources of privacy harm originate from data users' potential biases and inaccuracies in data analytics.  Privacy harms may arise as consequences of intended and unintended use of data.  Data that seemed to raise no, or only manageable, threats to privacy at the time of their collection can later lead to significant privacy harms, when large, diverse data sets and novel inference algorithms are brought together.  Our framework has two classes of game-theoretical models, in which risk is a choice companies make in competitive games.  One class of models focuses on how sensitive the companies' choices are to the shape of risk-return distribution.  The other class addresses consumer risk tolerance of privacy harm, examining how companies spread themselves apart from one another in the space of risk strategies and showing the conditions under which companies would converge toward the same risk strategy, such as collecting as much personally identifiable information (PII) as possible.  Our models build on foundational research in strategy science that addresses competitive advantage and competitive interactions among rival companies.  The analysis of the choices that companies make under various scenarios informs whether and how privacy practices can be a source of competitive advantage and affect company performance.  We illustrate companies' choices of how much PII to collect with the industry context of mobile health, which is the use of mobile computing and communications technologies in the delivery of healthcare.  Innovation in data storage and parsing power increases the value of digital health information.  Information privacy, however, is a grave concern when PII is collected by mobile devices enhanced with sensors that monitor the data subjects continuously and with software apps that record the data subjects' personal health information including lab test results, diagnostic images, a medication log of drug names, dosages, dispensing pharmacies and dates, diet details, lifestyles, social interactions, family history and possibly genetic profiles.  Data elements vary in their sensitivity to data subjects.  Genetic profiles, compared to other PII such as full names, medications, health conditions, and treatments received, make data subjects more sensitive about having their genetic profiles collected, as genetic variations are linked to certain cancer types and diseases.  Although the profiles are useful to patients and healthcare providers in facilitating the delivery of personalized medicine, consumers face privacy risks of suffering discrimination or other harms from having their genetic profiles revealed.  An individual's genetic profile reveals the future health of not only the individual but also their biological relatives such as children and parents.  Applying our framework to the context of mobile health, we deduce exactly how far apart the developers of mobile devices enhanced with sensors and software apps would spread out in the space of risk strategies.  When very few rivals compete, the developers separate themselves out and space far apart from each other.  As the number of rivals increases, the developers continue to avoid each other.  No two developers choose the same strategy.  The finding that the developers do not converge toward the same strategy uncovers the conditions under which consumer risk tolerance and competitive interaction among rivals would affect the choice of how much PII to collect.  However, when the competitive intensity is high, a substantial fraction of the developers would choose to take risks at equal or near the highest level.  That is, a highly competitive environment forces many developers toward taking huge privacy risks, thereby resulting in huge privacy risks for the consumers.  In addition to developing game-theoretic models, we enrich the framework with empirical data.  An empirical analysis of companies' privacy practices that are associated with data breaches, security failures as well as legal enforcements actions and sanctions helps us establish a minimum behavioral standard with respect to the company's relationship to its stakeholders, below which corporate behavior becomes socially irresponsible.  The stakeholders notably include data subjects, beyond the conventional categories of employees, customers, suppliers, investors, and the local community within which the companies operate.  The issue of causing stakeholders harm (intentionally or not) largely has been ignored in the corporate social responsibility (CSR) literature.  One of the intellectual merits of our research is the insights that we derive from the game-theoretic models and the empirical data, contributing to the CSR literature a perspective on the risk of harming the privacy of data subjects as a company's strategic choice.       Last Modified: 11/08/2018       Submitted by: Gwendolyn K Lee]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
