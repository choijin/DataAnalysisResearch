<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Collaborative Research: Resilient Computing Systems Using Deep Learning Techniques</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>265000.00</AwardTotalIntnAmount>
<AwardAmount>265000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yuanyuan Yang</SignBlockName>
<PO_EMAI>yyang@nsf.gov</PO_EMAI>
<PO_PHON>7032928067</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Over the past decade, computer systems have become prone to a variety of hardware failures. Traditionally, hardware failures were circumvented by operating the system at less than peak computing efficiency, effectively compromising efficiency to achieve reliability. Such a conservative approach is no longer a viable option because it leads to significant energy inefficiency. Since datacenters containing thousands of computers are one of the largest and fastest growing consumers of electricity, it is important to decouple the relationship between hardware failures and energy efficiency. &lt;br/&gt;&lt;br/&gt;The PIs' research will lay the groundwork for an intelligent computing system that operates at peak efficiency, but manages its fault resiliency and reliability using machine-learning based deep learning techniques. In effect, the system learns to steer itself clear of danger whenever its deep neural nets anticipate a failure. The research will address several important issues involving the scalability, flexibility and efficiency of deep learning techniques for various types of hardware failures. If successful, the research product will minimize, if not eliminate, penalties to the system that stem from the various circuit and micro-architectural techniques that are commonly used to mitigate and overcome hardware failures.</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1528045</AwardID>
<Investigator>
<FirstName>Vijay</FirstName>
<LastName>Janapa Reddi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vijay Janapa Reddi</PI_FULL_NAME>
<EmailAddress>vj@eecs.harvard.edu</EmailAddress>
<PI_PHON>4083902790</PI_PHON>
<NSF_ID>000607949</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121532</ZipCode>
<StreetAddress><![CDATA[101 East 27th St., Suite 5.300]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~265000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The PIs laid the groundwork for intelligent computing systems that can operate at extreme energy efficiency operating points. Typically, when running at such peak operating points, the hardware becomes prone to failure. Thus, as a safety mechanism, the processor industry's standard approach is to take a step back from aggressive operating points by introducing guardbands that reduce performance and lower energy-efficiency. But through creative techniques that are implemented via a software-assisted, hardware guarantee mechanism, the PIs show that state of the art processors can operate at extreme efficiency points without becoming prone to failures. And in doing so, the PIs unleash new levels of computer system performance and energy efficiency. Improvements range in the order of 15% to 30%, which is significant, when the microprocessor industry today strives to deliver 30% efficiency improvements one generation after another in gaps of two to three years.</p> <p><br />For intellectual merit, using state of the art AMD and IBM processors, the PIs demonstrate how to handle three fundamental reliability problems when the processor is operating at extreme efficiency points, namely temperature, process, and voltage variation. &nbsp;For temperature variation, the research has yielded a table-lookup based and an associated temperature management scheme at the software layer to minimize power consumption. For voltage variation, the study helped uncover the limiting factors of power saving when operating at peak points and led to novel application scheduling at the operating system level to maximize total system power reduction. For process variation, the research uncovered core-level reconfigurability to automatically expose the variation that limits efficiency improvements and discusses workload scheduling and throttling management to control critical application performance, such as latency sensitive cloud and machine learning workloads.&nbsp;</p> <p><br />On the broader impacts front, we focused on sharing the insights we discovered from our research through a variety of means. Primarily, we improved the college classroom material up to speed, by bringing the research ideas into theory, such that undergraduate students could benefit from the analysis. Issues, such as process, voltage, and thermal variations were introduced in their pure form at the freshman undergraduate course work level as they are applicable to the research challenges described in this award. Furthermore, students were introduced to the concepts of deep learning as relevant to this project, which more specifically meant understanding which learning methods work well for optimizations at the software and hardware level. Moreover, the PIs worked on disseminating the information to the companies through technical talks.&nbsp;</p> <p>In summary, the PIs believe that the optimizations discovered in the intellectual merit can benefit a variety of processors, as the conclusions are based on the reliable measurement on state-of-the-art processors that already have broad applicability in the commercial market place. Also, the education of young engineers in this topic is both timely and relevant. Future engineers have been exposed to the concepts developed as are a result of the research conducted thanks to this award, and the lessons have been disseminated to the relevant industry and future professionals.&nbsp;<br /><br /></p><br> <p>            Last Modified: 05/19/2019<br>      Modified by: Vijay&nbsp;Janapa Reddi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The PIs laid the groundwork for intelligent computing systems that can operate at extreme energy efficiency operating points. Typically, when running at such peak operating points, the hardware becomes prone to failure. Thus, as a safety mechanism, the processor industry's standard approach is to take a step back from aggressive operating points by introducing guardbands that reduce performance and lower energy-efficiency. But through creative techniques that are implemented via a software-assisted, hardware guarantee mechanism, the PIs show that state of the art processors can operate at extreme efficiency points without becoming prone to failures. And in doing so, the PIs unleash new levels of computer system performance and energy efficiency. Improvements range in the order of 15% to 30%, which is significant, when the microprocessor industry today strives to deliver 30% efficiency improvements one generation after another in gaps of two to three years.   For intellectual merit, using state of the art AMD and IBM processors, the PIs demonstrate how to handle three fundamental reliability problems when the processor is operating at extreme efficiency points, namely temperature, process, and voltage variation.  For temperature variation, the research has yielded a table-lookup based and an associated temperature management scheme at the software layer to minimize power consumption. For voltage variation, the study helped uncover the limiting factors of power saving when operating at peak points and led to novel application scheduling at the operating system level to maximize total system power reduction. For process variation, the research uncovered core-level reconfigurability to automatically expose the variation that limits efficiency improvements and discusses workload scheduling and throttling management to control critical application performance, such as latency sensitive cloud and machine learning workloads.    On the broader impacts front, we focused on sharing the insights we discovered from our research through a variety of means. Primarily, we improved the college classroom material up to speed, by bringing the research ideas into theory, such that undergraduate students could benefit from the analysis. Issues, such as process, voltage, and thermal variations were introduced in their pure form at the freshman undergraduate course work level as they are applicable to the research challenges described in this award. Furthermore, students were introduced to the concepts of deep learning as relevant to this project, which more specifically meant understanding which learning methods work well for optimizations at the software and hardware level. Moreover, the PIs worked on disseminating the information to the companies through technical talks.   In summary, the PIs believe that the optimizations discovered in the intellectual merit can benefit a variety of processors, as the conclusions are based on the reliable measurement on state-of-the-art processors that already have broad applicability in the commercial market place. Also, the education of young engineers in this topic is both timely and relevant. Future engineers have been exposed to the concepts developed as are a result of the research conducted thanks to this award, and the lessons have been disseminated to the relevant industry and future professionals.          Last Modified: 05/19/2019       Submitted by: Vijay Janapa Reddi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
