<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BSF: 2014414: New Challenges and Perspectives in Online Algorithms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>40000.00</AwardTotalIntnAmount>
<AwardAmount>40000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>While the traditional design and analysis of algorithms assumes that complete knowledge of the entire input is available to the algorithm, the area of online algorithms deals with the case where the input is revealed in parts, and the online algorithm is required to respond to each new part immediately upon arrival, without knowledge of the future. Previous decisions of the online algorithm cannot be revoked. Thus, the main issue in online computation is obtaining good performance in the face of uncertainty, since the future is unknown to the algorithm. The problems in this setting arise in all of computer science, as well in much of sequential decision-making, machine learning, and many other areas.&lt;br/&gt;&lt;br/&gt;The proposed research is focused on a deeper investigation of the primal-dual approach to online algorithm design. The topics investigated in this project are (a) extending the success of linear optimization to the convex case, (b) relaxing monotonicity of the variables and developing principled approaches for algorithms with preemption, and (c) understanding the connection of online primal-dual approaches and online machine learning algorithms. As part of the broader impact, the research is likely to lead to better algorithms for a variety of problems both in traditional algorithm design and in other areas like machine learning and algorithmic game theory.</AbstractNarration>
<MinAmdLetterDate>08/06/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1540541</AwardID>
<Investigator>
<FirstName>Anupam</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anupam Gupta</PI_FULL_NAME>
<EmailAddress>anupamg@cs.cmu.edu</EmailAddress>
<PI_PHON>4122687127</PI_PHON>
<NSF_ID>000486839</NSF_ID>
<StartDate>08/06/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramReference>
<Code>2878</Code>
<Text>SPECIAL PROJECTS - CCF</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~40000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The field of online algorithms aims to develop efficient decision-making algorithms for sequential decision making: faced with a sequence of requests, the algorithm must make decisions to satisfy each request without knowing the future. This lack of information about the future causes the algorithm's performance to be sub-optimal, so we look at the gap between it and the optimal algorithm in hindsight. There are two ways to measure this gap. One compares to the best fixed decision, and leads to online learning and regret minimization. The other allows the optimal algorithm to also make varying decisions, which leads to competitive analysis. The research of this proposal primarily studied the latter, with an intention to build connections to the former. Moreover, online learning has deep connections to convex optimization, and another goal of the project was to understand convex optimization in an online setting.<br /><br />The results of the project forged new connections in both directions. Firstly, algorithms were developed to minimize convex functions subject to covering constraints that appear over time. These led to (dual) algorithms to maximize certain kinds of concave functions subject to new variables arriving over time, which model problems in item pricing that maximize social welfare in convex markets. Secondly, projection-based algorithms were given that use convex optimization (and specifically, mirror descent) for online optimization problems. These algorithms give a very coarse discretization of a recent continuous-time approach proposed in the literature. Moreover, a new near-optimal algorithm was given for the convex body chasing problem. This problem is a substantial generalization of several widely-studied online optimization problems (such as paging and k-server).<br /><br />The research of this proposal showed new links between the two orthogonal aspects of sequential decision making: competitive analysis and regret minimization, and their connections to convex optimization and convex geometry. A substantial ingredient of this project was the training of graduate and undergraduate students. The educational component of this proposal involved a survey on gradient methods, and the teaching of online algorithms and continuous optimization techniques in both graduate and undergraduate algorithms courses, to bridge the gap between continuous and discrete optimization.</p><br> <p>            Last Modified: 09/01/2019<br>      Modified by: Anupam&nbsp;Gupta</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The field of online algorithms aims to develop efficient decision-making algorithms for sequential decision making: faced with a sequence of requests, the algorithm must make decisions to satisfy each request without knowing the future. This lack of information about the future causes the algorithm's performance to be sub-optimal, so we look at the gap between it and the optimal algorithm in hindsight. There are two ways to measure this gap. One compares to the best fixed decision, and leads to online learning and regret minimization. The other allows the optimal algorithm to also make varying decisions, which leads to competitive analysis. The research of this proposal primarily studied the latter, with an intention to build connections to the former. Moreover, online learning has deep connections to convex optimization, and another goal of the project was to understand convex optimization in an online setting.  The results of the project forged new connections in both directions. Firstly, algorithms were developed to minimize convex functions subject to covering constraints that appear over time. These led to (dual) algorithms to maximize certain kinds of concave functions subject to new variables arriving over time, which model problems in item pricing that maximize social welfare in convex markets. Secondly, projection-based algorithms were given that use convex optimization (and specifically, mirror descent) for online optimization problems. These algorithms give a very coarse discretization of a recent continuous-time approach proposed in the literature. Moreover, a new near-optimal algorithm was given for the convex body chasing problem. This problem is a substantial generalization of several widely-studied online optimization problems (such as paging and k-server).  The research of this proposal showed new links between the two orthogonal aspects of sequential decision making: competitive analysis and regret minimization, and their connections to convex optimization and convex geometry. A substantial ingredient of this project was the training of graduate and undergraduate students. The educational component of this proposal involved a survey on gradient methods, and the teaching of online algorithms and continuous optimization techniques in both graduate and undergraduate algorithms courses, to bridge the gap between continuous and discrete optimization.       Last Modified: 09/01/2019       Submitted by: Anupam Gupta]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
