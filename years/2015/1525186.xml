<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: EXP: Open Corpus Personalized Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>499758.00</AwardTotalIntnAmount>
<AwardAmount>499758</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project challenges the assumption that adaptive hypermedia systems require expensive knowledge engineering for domain and content modeling. It replaces carefully-crafted domain models with automatically-created domain models, lowering the cost of developing adaptive educational hypermedia software while also providing a wider range of instructional paths through the content. Adaptive educational hypermedia is known for its ability to improve learning outcomes and engagement maximizing educational opportunity for learners with different levels of knowledge. The development of this more automatic, open-corpus approach to adaptive educational hypermedia will increase the volume and the variety of resources available for meaningful online learning, especially for individuals learning on their own. Automatic knowledge indexing of educational content makes the system easy to maintain and update over time. These new open corpus user modeling techniques automatically adapt user models and personalized guidance to new materials as they are acquired. The ability to automatically organize, index, and adaptively recommend distributed educational content without the need of manual processing by system developers, enables new material to be integrated dynamically and with minimal effort in response to student needs.&lt;br/&gt; &lt;br/&gt;This project merges research on text analysis, human learning, and personalization to enable open corpus personalized learning. It develops its models of the domain and human learning from an initial set of well-organized, manually selected materials. Automatic text analysis creates an ensemble of domain models with different characteristics. Each individual model may be flawed or incomplete, however collectively they provide comprehensive coverage of the topic from several perspectives, thus reducing the manual effort required to create adaptive educational hypermedia. Multiple perspectives also give the system more flexibility in how to guide each student. These domain models are used as a foundation for building and maintaining dynamic models of user knowledge. The ensemble of domain and user models is used to deliver reactive and proactive adaptive guidance in an open corpus context. The growth of a person's knowledge is inferred by observing learner behavior and obtaining occasional feedback. This exploratory research opens the way to open corpus personalized learning. The domain modeling, user modeling, and personalization techniques developed in this research will be evaluated using a multi-layer framework that includes assessment by subject experts, performance prediction, cross-validation, and user studies.</AbstractNarration>
<MinAmdLetterDate>08/12/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/12/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1525186</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Brusilovsky</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter L Brusilovsky</PI_FULL_NAME>
<EmailAddress>peterb@mail.sis.pitt.edu</EmailAddress>
<PI_PHON>4126249404</PI_PHON>
<NSF_ID>000214546</NSF_ID>
<StartDate>08/12/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daqing</FirstName>
<LastName>He</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daqing He</PI_FULL_NAME>
<EmailAddress>dah44@pitt.edu</EmailAddress>
<PI_PHON>4126242477</PI_PHON>
<NSF_ID>000231445</NSF_ID>
<StartDate>08/12/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152600001</ZipCode>
<StreetAddress><![CDATA[350 Thackeray Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~499758</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-d82ba733-7fff-f661-6577-077e7d72c924"> <p dir="ltr"><span>Over the last 10 years, the world experienced a rapid increase in volume and diversity of digital learning resources. On the one hand, a variety of tutorials, online textbooks, and educational videos were posted online to complement traditional textbooks. On the other hand, almost all traditional textbooks have migrated to digital format and become available online. The abundance of resources could support a range of powerful educational scenarios, which were not available before. For example, if a textbook section is hard for a learner to comprehend, she could instead try a section from a different textbook or tutorial, which explains the same topic in a way that is more adapted to her knowledge and interests. Moreover, if it is the lack of prerequisite knowledge that makes a specific textbook section hard to comprehend, the student could be guided to the readings that introduce or review the missing knowledge. Vice versa, if the current reading looks too easy and the students want to learn deeper or more advanced knowledge and examples on the presented topic, she could be guided to the most appropriate follow-up reading.&nbsp;</span></p> <br /><br /> <p dir="ltr"><span>The ideas of this &ldquo;smart&rdquo; learning have been explored in early projects focused on adaptive textbooks, which demonstrated both the feasibility and the value of knowledge-driven adaptive reading. However, these early attempts never scaled up because of their dependence on expensive expert-driven knowledge analysis of every textbook page. The goal of our project was to move the idea of &ldquo;smart&rdquo; user-adaptive textbook learning closer to reality.&nbsp;</span></p> <br /> <p dir="ltr"><span>To achieve these goals, we focused on two main research directions. First, we investigated text analysis approaches that could automatically extract domain knowledge &ldquo;behind&rdquo; every textbook chapter, section, and page. Second, we attempted to develop the state-of-the art student modeling approaches, which could trace learner&rsquo;s reading behavior and maintain a reliable model of student knowledge at every moment of learning.</span></p> <br /> <p dir="ltr"><span>Over the course of the project we developed a range of approaches for automatically extracting domain knowledge from educational text. Our best performing approaches based on deep learning demonstrated a remarkable improvement of knowledge extraction quality in comparison with existing concept extraction approaches. We also developed the first probabilistic student modeling approach that uses multiple domain concepts associated with each textbook page to model the progress of students&rsquo; learning-by-reading. These two groups of modeling approaches form the foundation of adaptive learning from textbooks, which enabled us to develop several practical personalization scenarios such as recommending relevant sections across multiple textbooks, recommending remedial readings, and recommending external educational resources such as educational videos and Wikipedia articles. After the project completion, we plan to continue further work on implementing and evaluating novel personalization techniques in other domains, including medical and health areas.</span></p> <br /> <p dir="ltr"><span>To achieve the goals of our project, we also developed two valuable resources, which could be useful for other researchers working on similar topics. First, we developed an advanced electronic textbook platform called Reading Mirror, which could be used to deliver the next generations of smart textbooks. The platform is equipped with native support of knowledge and progress tracking and connected to domain and student models. It could be used for both research and practical delivery of adaptive textbooks. We already used Reading Mirror in teaching several classes and plan to continue its use and evaluation. Second, we delivered a full scale dataset for assessing the quality of concept-extraction approaches. We released this dataset publicly as one of the project outcomes to be used by other teams working on extraction of domain knowledge from textbooks.</span></p> <div><span><br /></span></div> </span></p> <p>&nbsp;</p><br> <p>            Last Modified: 03/17/2020<br>      Modified by: Peter&nbsp;L&nbsp;Brusilovsky</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Over the last 10 years, the world experienced a rapid increase in volume and diversity of digital learning resources. On the one hand, a variety of tutorials, online textbooks, and educational videos were posted online to complement traditional textbooks. On the other hand, almost all traditional textbooks have migrated to digital format and become available online. The abundance of resources could support a range of powerful educational scenarios, which were not available before. For example, if a textbook section is hard for a learner to comprehend, she could instead try a section from a different textbook or tutorial, which explains the same topic in a way that is more adapted to her knowledge and interests. Moreover, if it is the lack of prerequisite knowledge that makes a specific textbook section hard to comprehend, the student could be guided to the readings that introduce or review the missing knowledge. Vice versa, if the current reading looks too easy and the students want to learn deeper or more advanced knowledge and examples on the presented topic, she could be guided to the most appropriate follow-up reading.     The ideas of this "smart" learning have been explored in early projects focused on adaptive textbooks, which demonstrated both the feasibility and the value of knowledge-driven adaptive reading. However, these early attempts never scaled up because of their dependence on expensive expert-driven knowledge analysis of every textbook page. The goal of our project was to move the idea of "smart" user-adaptive textbook learning closer to reality.    To achieve these goals, we focused on two main research directions. First, we investigated text analysis approaches that could automatically extract domain knowledge "behind" every textbook chapter, section, and page. Second, we attempted to develop the state-of-the art student modeling approaches, which could trace learner’s reading behavior and maintain a reliable model of student knowledge at every moment of learning.   Over the course of the project we developed a range of approaches for automatically extracting domain knowledge from educational text. Our best performing approaches based on deep learning demonstrated a remarkable improvement of knowledge extraction quality in comparison with existing concept extraction approaches. We also developed the first probabilistic student modeling approach that uses multiple domain concepts associated with each textbook page to model the progress of students’ learning-by-reading. These two groups of modeling approaches form the foundation of adaptive learning from textbooks, which enabled us to develop several practical personalization scenarios such as recommending relevant sections across multiple textbooks, recommending remedial readings, and recommending external educational resources such as educational videos and Wikipedia articles. After the project completion, we plan to continue further work on implementing and evaluating novel personalization techniques in other domains, including medical and health areas.   To achieve the goals of our project, we also developed two valuable resources, which could be useful for other researchers working on similar topics. First, we developed an advanced electronic textbook platform called Reading Mirror, which could be used to deliver the next generations of smart textbooks. The platform is equipped with native support of knowledge and progress tracking and connected to domain and student models. It could be used for both research and practical delivery of adaptive textbooks. We already used Reading Mirror in teaching several classes and plan to continue its use and evaluation. Second, we delivered a full scale dataset for assessing the quality of concept-extraction approaches. We released this dataset publicly as one of the project outcomes to be used by other teams working on extraction of domain knowledge from textbooks.             Last Modified: 03/17/2020       Submitted by: Peter L Brusilovsky]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
