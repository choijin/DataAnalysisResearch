<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: An Animated Agent for Developing the Conversational Skills of Individuals with Social Interaction Difficulties</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>166000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This EArly Grant for Exploratory Research seeks to develop an exploratory version of a computer-based animated agent that simulates a conversational partner, allowing users with social interaction difficulties, such as ones with Asperger syndrome, to practice conversational skills. The interaction will explore establishing friendly rapport with the user through conversation; building such rapport is an important social skill that is difficult for the targeted individuals to acquire. It is hypothesized that such individuals will very significantly benefit from the exploratory agent, by allowing them to practice conversational skills without risk of failure or of making a poor impression. The most exciting part of this exploratory technology is that it puts users in the driver's seat of the interaction with a standardized, objective and repeatable stimulus. The architectural framework for the "getting acquainted" scenario is general enough to be adaptable to many other restricted conversational scenarios of societal importance such as job interviews, customer service, and participating in group decision-making. &lt;br/&gt;&lt;br/&gt;The exploratory agent is a simulated adult responding in the mature, patient manner of an experienced consultant (an expert advisor from the University of Rochester Medical Center consults on the project). The agent correlates the topic and content of the user's utterances with the prosody, facial expressions, gaze direction and head motions accompanying the utterances. The agent also provides helpful real-time feedback via red/green screen icons about these behaviors, and behavioral summaries and suggestions for improving the behavior at the end of a session. The initial domain in this exploratory project is "getting acquainted", i.e., engaging in the sort of small talk that is conventional for individuals who have not previously met. The dialogue framework has some transactional knowledge, independent of topic, to initiate a conversation and to respond appropriately during a conversation. When the user's responses to the agent's questions and prompts deviate from expectations, the agent branches to clusters of strategies including evasive answers, requesting repetition, providing encouragement and prompting further input. The project includes exploration of more general questions such as the architecture required for integrating nonlinguistic and linguistic behavior in an animated agent. The project also leads to new user interfaces that can capture nonverbal behavior analytics reflecting the dynamics of the conversation.</AbstractNarration>
<MinAmdLetterDate>07/23/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1543758</AwardID>
<Investigator>
<FirstName>Lenhart</FirstName>
<LastName>Schubert</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lenhart K Schubert</PI_FULL_NAME>
<EmailAddress>schubert@cs.rochester.edu</EmailAddress>
<PI_PHON>5852758845</PI_PHON>
<NSF_ID>000235732</NSF_ID>
<StartDate>07/23/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mohammed</FirstName>
<LastName>Hoque</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mohammed E Hoque</PI_FULL_NAME>
<EmailAddress>mehoque@cs.rochester.edu</EmailAddress>
<PI_PHON>5852754031</PI_PHON>
<NSF_ID>000654070</NSF_ID>
<StartDate>07/23/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>146270140</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~150000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Default">This EAGER project involved developing a computer-based animated agent that simulates a conversational partner, allowing users with social interaction difficulties, such as ones with Autism Spectrum Disorder (ASD), to practice conversational skills.&nbsp;The agent was developed to observe user&rsquo;s physical behavior while speaking, including facial expressions, head motions, and prosodic features of speech, while at the same understanding enough of the user's utterances to comment appropriately and guide its dialogue behavior. The agent provided real-time feedback via red/green screen icons about the user's behaviors and behavioral summaries and suggestions for improving these behaviors at the end of a session. Concerning dialogue themes, the initial goal was to engage in "getting acquainted" small talk, with a capacity to deploy sub-strategies for dealing with incidental comments, questions, requests for repeating a question that was not understood, etc.&nbsp;</p> <p class="Default">&nbsp;We ran an experiment with seven ASD teens. The system performed well-enough for the participants to feel that they were being understood. Participants rated the system as engaging and natural with a desire to conduct more sessions with the system. 6 of 7 participants felt that they might benefit from practicing their social skills with such a system.</p> <p class="Default">&nbsp;The initial success of this project could potentially lead to societal broader impact by providing a tool for people to understand and practice a range of conversational behaviors, taking account of both verbal and nonverbal aspects. In particular, the interaction can establish a friendly rapport with the user through a conversation. Building such rapport is an important social skill that is difficult for individuals with Asperger syndrome or other social difficulties to acquire. We believe that such individuals will significantly benefit from the proposed agent, by allowing them to practice this skill without risk of failure or of making a poor impression. The most exciting part of this technology is that it puts users in the driver's seat of the interaction with a standardized, objective and repeatable stimulus. The architectural framework that we implemented for the &ldquo;getting acquainted&rdquo; scenario is general enough to be adaptable to many other restricted conversational scenarios, such as job interviews, customer service, testifying in court, and participating in group decision-making.</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/26/2018<br>      Modified by: Mohammed&nbsp;E&nbsp;Hoque</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[This EAGER project involved developing a computer-based animated agent that simulates a conversational partner, allowing users with social interaction difficulties, such as ones with Autism Spectrum Disorder (ASD), to practice conversational skills. The agent was developed to observe user?s physical behavior while speaking, including facial expressions, head motions, and prosodic features of speech, while at the same understanding enough of the user's utterances to comment appropriately and guide its dialogue behavior. The agent provided real-time feedback via red/green screen icons about the user's behaviors and behavioral summaries and suggestions for improving these behaviors at the end of a session. Concerning dialogue themes, the initial goal was to engage in "getting acquainted" small talk, with a capacity to deploy sub-strategies for dealing with incidental comments, questions, requests for repeating a question that was not understood, etc.   We ran an experiment with seven ASD teens. The system performed well-enough for the participants to feel that they were being understood. Participants rated the system as engaging and natural with a desire to conduct more sessions with the system. 6 of 7 participants felt that they might benefit from practicing their social skills with such a system.  The initial success of this project could potentially lead to societal broader impact by providing a tool for people to understand and practice a range of conversational behaviors, taking account of both verbal and nonverbal aspects. In particular, the interaction can establish a friendly rapport with the user through a conversation. Building such rapport is an important social skill that is difficult for individuals with Asperger syndrome or other social difficulties to acquire. We believe that such individuals will significantly benefit from the proposed agent, by allowing them to practice this skill without risk of failure or of making a poor impression. The most exciting part of this technology is that it puts users in the driver's seat of the interaction with a standardized, objective and repeatable stimulus. The architectural framework that we implemented for the "getting acquainted" scenario is general enough to be adaptable to many other restricted conversational scenarios, such as job interviews, customer service, testifying in court, and participating in group decision-making.          Last Modified: 01/26/2018       Submitted by: Mohammed E Hoque]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
