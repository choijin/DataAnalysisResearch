<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CC*DNI Integration: Innovating Network Cyberinfrastructure through Openflow and Content Centric Networking in Nebraska</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2016</AwardEffectiveDate>
<AwardExpirationDate>12/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>572112.00</AwardTotalIntnAmount>
<AwardAmount>572112</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kevin Thompson</SignBlockName>
<PO_EMAI>kthompso@nsf.gov</PO_EMAI>
<PO_PHON>7032924220</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Research and Education networks (R&amp;E) networks are undergoing a major transformation. At the campus level, implementations must balance performance, security, and the flexibility to handle innovative network applications research. Without adequate performance, the core application stakeholders would quickly leave; without security, the university networks would not allow integration of new approaches; without innovations, future leadership is at stake. The Holland Computing Center (HCC) at the University of Nebraska-Lincoln (UNL) campus has identified the need to increase the flexibility of UNL's network to support scientific users and network researchers; UNL addresses this by deploying a production software-defined network (SDN) using OpenFlow.&lt;br/&gt;&lt;br/&gt;This deployment enhances UNL's HCC network through SDN, in three focused areas. First, it enhances resource management for GridFTP transfers by having the applications communicate with an SDN controller to set up paths and path properties for large transfers. By enabling communication between the applications and the network controller, we allow for application-driven bandwidth provisioning. Second, it integrates security with SDN-based dynamic routing so that only flows that require specific middleboxes be routed through them. This increases the scalability of the network by reducing the load on middleboxes and enabling automated reaction to security alerts raised by these devices. Third, it uses Content-Centric Networking (CCN) to provide access to the Compact Muon Solenoid (CMS) experiment data. CCN provides in-network caching and content-based routing. UNL leverages these techniques to efficiently deliver experiment data to scientific applications without always requiring access to the server where the data is stored.</AbstractNarration>
<MinAmdLetterDate>12/24/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1541442</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Swanson</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David R Swanson</PI_FULL_NAME>
<EmailAddress>dswanson4@unl.edu</EmailAddress>
<PI_PHON>4024725006</PI_PHON>
<NSF_ID>000385633</NSF_ID>
<StartDate>12/24/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Byravamurthy</FirstName>
<LastName>Ramamurthy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Byravamurthy Ramamurthy</PI_FULL_NAME>
<EmailAddress>byrav@cse.unl.edu</EmailAddress>
<PI_PHON>4024727791</PI_PHON>
<NSF_ID>000486807</NSF_ID>
<StartDate>12/24/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Bockelman</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian P Bockelman</PI_FULL_NAME>
<EmailAddress>bbockelman@morgridge.org</EmailAddress>
<PI_PHON>4027504235</PI_PHON>
<NSF_ID>000539290</NSF_ID>
<StartDate>12/24/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Nebraska-Lincoln</Name>
<CityName>Lincoln</CityName>
<ZipCode>685031435</ZipCode>
<PhoneNumber>4024723171</PhoneNumber>
<StreetAddress>151 Prem S. Paul Research Center</StreetAddress>
<StreetAddress2><![CDATA[2200 Vine St]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<StateCode>NE</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NE01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555456995</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BOARD OF REGENTS OF THE UNIVERSITY OF NEBRASKA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068662618</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Nebraska-Lincoln]]></Name>
<CityName/>
<StateCode>NE</StateCode>
<ZipCode>685880430</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NE01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8080</Code>
<Text>Campus Cyberinfrastructure</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~572112</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Today, scientific discoveries are increasingly made possible by large-scale data sets (Big Data). Research and Education networks (R&amp;E) networks are undergoing a major transformation to handle such large data transfers. The Holland Computing Center (HCC) at the University of Nebraska-Lincoln (UNL) campus has identified the need to increase the flexibility of its network to support scientific users and network researchers. Software Defined Networking (SDN) promises a new paradigm shift in the control and management of networks. In our project, we applied principles from software defined networking to handle high-capacity data transfers and for enabling security. In addition, we investigated the application of Content Centric Networking, another transformative technology, for High-Energy Physics (HEP) data.</p> <p>Intellectual Merit: In this project, we proposed and implemented an application-aware network architecture based on the software-defined network (SDN) paradigm, SNAG (SDN-managed Network Architecture for GridFTP transfers), an architecture that enables the SDN-based network management of GridFTP file transfers for large-scale science datasets. SNAG is used to efficiently and securely identify science dataset transfers from projects such as Compact Muon Solenoid (CMS) and Laser Interferometer Gravitational-Wave Observatory (LIGO). By enabling communication between the applications and the network controller, we also allow for application-driven bandwidth provisioning.&nbsp; We proposed and implemented a data transfer approach that uses a Content-Centric Networking (CCN) architecture, Named Data Networking (NDN), to provide access to the CMS software. NDN provides in-network caching and content-based routing. We integrated NDN and CERN Virtual Machine File System (CernVM-FS) to efficiently deliver data without always requiring access to the server where the data is stored.</p> <p>Broader Impacts: Our project results were disseminated to the community at &nbsp;relevant technical conferences (e.g. IEEE INFOCOM, ACM SDN-NFVSec, &nbsp;IEEE NetSoft and IEEE ANTS Conferences). Graduate Students employed on this project have been trained in networking and security topics. During the course of this project, they have had the opportunity to work with real scientific data from other disciplines (such as high-energy physics) and with new software and hardware platforms. Our work will lead to a greater understanding of how SDN and CCN are applicable to developing campus networks for high-capacity data transfer applications.</p><br> <p>            Last Modified: 04/04/2019<br>      Modified by: Byravamurthy&nbsp;Ramamurthy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Today, scientific discoveries are increasingly made possible by large-scale data sets (Big Data). Research and Education networks (R&amp;E) networks are undergoing a major transformation to handle such large data transfers. The Holland Computing Center (HCC) at the University of Nebraska-Lincoln (UNL) campus has identified the need to increase the flexibility of its network to support scientific users and network researchers. Software Defined Networking (SDN) promises a new paradigm shift in the control and management of networks. In our project, we applied principles from software defined networking to handle high-capacity data transfers and for enabling security. In addition, we investigated the application of Content Centric Networking, another transformative technology, for High-Energy Physics (HEP) data.  Intellectual Merit: In this project, we proposed and implemented an application-aware network architecture based on the software-defined network (SDN) paradigm, SNAG (SDN-managed Network Architecture for GridFTP transfers), an architecture that enables the SDN-based network management of GridFTP file transfers for large-scale science datasets. SNAG is used to efficiently and securely identify science dataset transfers from projects such as Compact Muon Solenoid (CMS) and Laser Interferometer Gravitational-Wave Observatory (LIGO). By enabling communication between the applications and the network controller, we also allow for application-driven bandwidth provisioning.  We proposed and implemented a data transfer approach that uses a Content-Centric Networking (CCN) architecture, Named Data Networking (NDN), to provide access to the CMS software. NDN provides in-network caching and content-based routing. We integrated NDN and CERN Virtual Machine File System (CernVM-FS) to efficiently deliver data without always requiring access to the server where the data is stored.  Broader Impacts: Our project results were disseminated to the community at  relevant technical conferences (e.g. IEEE INFOCOM, ACM SDN-NFVSec,  IEEE NetSoft and IEEE ANTS Conferences). Graduate Students employed on this project have been trained in networking and security topics. During the course of this project, they have had the opportunity to work with real scientific data from other disciplines (such as high-energy physics) and with new software and hardware platforms. Our work will lead to a greater understanding of how SDN and CCN are applicable to developing campus networks for high-capacity data transfer applications.       Last Modified: 04/04/2019       Submitted by: Byravamurthy Ramamurthy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
