<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Utilizing Memory Parallelism for High Performance Data Processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>191000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yuanyuan Yang</SignBlockName>
<PO_EMAI>yyang@nsf.gov</PO_EMAI>
<PO_PHON>7032928067</PO_PHON>
</ProgramOfficer>
<AbstractNarration>While advances in microprocessor design continue to increase computing speed, improvements in data access speed of computing systems lag far behind. At the same time, data-intensive large-scale applications, such as information retrieval, computer animation, and big data analytics are emerging. Data access delay has become the vital performance bottleneck of modern high performance computing (HPC). Memory concurrency exists at each layer of modern memory hierarchies; however, conventional computing systems are primarily designed to improve CPU utilization and have inherent limitations in addressing the critical issue of data movement in HPC. In this research, the PI proposes the concept of memory parallelism and the customized parallel memory (CuPM) system architecture in order to address data movement bottleneck issues. CuPM is an architecture designed to exploit memory concurrency to support high performance data processing (HPDP). This new abstraction extracts the general principles of parallel memory system by building on the new Concurrent-AMAT metric, a set of fresh theoretical results in data access concurrency, a series of recent successes in parallel I/O optimization, and new technology opportunities. CuPM is a novel cross-layer and cross-cutting approach for exploring and utilizing current and future memory technologies based on opportunities arising from memory concurrency.&lt;br/&gt;&lt;br/&gt;Current HPC systems do not fully recognize or exploit the concurrency that modern memory systems provide. The key new idea of CuPM is to establish a systematic way of exploring, enhancing, utilizing, and customizing memory concurrency to build effective memory systems. It will be developed with two goals: to understand and reveal the memory concurrency and its properties, and to explore and utilize current memory concurrency for HPDP. The former will evaluate the potential of the latter; while the latter will verify and testing the former. Together, they enable CuPM to address a central challenge for extreme computing ? efficient memory systems. The proposed CuPM architecture has the potential to transform systems from application through runtime through architecture.</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/20/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1536079</AwardID>
<Investigator>
<FirstName>Xian-He</FirstName>
<LastName>Sun</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xian-He Sun</PI_FULL_NAME>
<EmailAddress>sun@iit.edu</EmailAddress>
<PI_PHON>3125675260</PI_PHON>
<NSF_ID>000318956</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Illinois Institute of Technology</Name>
<CityName>Chicago</CityName>
<ZipCode>606163717</ZipCode>
<PhoneNumber>3125673035</PhoneNumber>
<StreetAddress>10 West 35th Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 7D71]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042084434</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ILLINOIS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042084434</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Illinois Institute of Technology]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606163732</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~175000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This is a two-year Eager project designed to (1) understand and reveal the memory parallelism and its properties, (2) explore and utilize current memory parallelism for High Performance Data Processing (HPDP). The former will evaluate the potential of the latter; while the latter will verify and testing the former. Together, they enable us to address a central challenge for extreme computing &ndash; efficient memory systems. &nbsp;</p> <p>Through this research, we have gained a better understanding of the newly proposed C-AMAT (Concurrent-Average Memory Access Time) model for memory system systems. Based on our understanding, we have formally proposed the Sluice-Gate Theory for data transfer in a memory hierarchy system. &nbsp;This result is first delivered as a keynote at the HPC-China Conference in 2015 and later appeared in the proceedings of the 29th International Workshop on Languages and Compilers for Parallel Computing (LCPC2016). Working with researchers at the Pacific Northwest National Laboratory (PNNL), a tailored C-AMAT model for GPGPU architecture is established, which layouts the foundation to optimize GPGPU performance based on the newly proposed C-AMAT memory model and the Sluice-Gate theory. &nbsp;Working with researchers at the Argonne National Laboratories, we have been using the C-MATA model on Argonne&rsquo;s advanced machines, especially on the Cooley machine which has a unified global memory system, to optimize and understanding supercomputers performance. A paper entitled &ldquo;Performance Modeling, Evaluation and Optimization of Disaggregated Memory System&rdquo; is submitted for publication.</p> <p>Other publications under this project include "C^2-bound: A Capacity and Concurrency driven Analytical Model for Manycore Design" at the ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis 2015 (SC'15), &nbsp;, "Evaluating the Combined Effect of Memory Capacity and Concurrency for Many-core Chip Design," in ACM Transactions on Modeling and Performance Evaluation of Computing Systems (TOMPECS), vol. 2, no. 2, pp. 9:1-9:25, Apr. 2017, and "CaL: Extending Data Locality to Consider Concurrency for Performance Optimization" is published in IEEE Transactions on Big Data, vol. 5, no. 2, pp. 273-288, June 2018.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/12/2018<br>      Modified by: Xian-He&nbsp;Sun</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This is a two-year Eager project designed to (1) understand and reveal the memory parallelism and its properties, (2) explore and utilize current memory parallelism for High Performance Data Processing (HPDP). The former will evaluate the potential of the latter; while the latter will verify and testing the former. Together, they enable us to address a central challenge for extreme computing &ndash; efficient memory systems.    Through this research, we have gained a better understanding of the newly proposed C-AMAT (Concurrent-Average Memory Access Time) model for memory system systems. Based on our understanding, we have formally proposed the Sluice-Gate Theory for data transfer in a memory hierarchy system.  This result is first delivered as a keynote at the HPC-China Conference in 2015 and later appeared in the proceedings of the 29th International Workshop on Languages and Compilers for Parallel Computing (LCPC2016). Working with researchers at the Pacific Northwest National Laboratory (PNNL), a tailored C-AMAT model for GPGPU architecture is established, which layouts the foundation to optimize GPGPU performance based on the newly proposed C-AMAT memory model and the Sluice-Gate theory.  Working with researchers at the Argonne National Laboratories, we have been using the C-MATA model on Argonne?s advanced machines, especially on the Cooley machine which has a unified global memory system, to optimize and understanding supercomputers performance. A paper entitled "Performance Modeling, Evaluation and Optimization of Disaggregated Memory System" is submitted for publication.  Other publications under this project include "C^2-bound: A Capacity and Concurrency driven Analytical Model for Manycore Design" at the ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis 2015 (SC'15),  , "Evaluating the Combined Effect of Memory Capacity and Concurrency for Many-core Chip Design," in ACM Transactions on Modeling and Performance Evaluation of Computing Systems (TOMPECS), vol. 2, no. 2, pp. 9:1-9:25, Apr. 2017, and "CaL: Extending Data Locality to Consider Concurrency for Performance Optimization" is published in IEEE Transactions on Big Data, vol. 5, no. 2, pp. 273-288, June 2018.          Last Modified: 12/12/2018       Submitted by: Xian-He Sun]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
