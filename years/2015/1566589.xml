<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: SHF: Machine-Learning-Based Test Effectiveness Prediction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2016</AwardEffectiveDate>
<AwardExpirationDate>04/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>174150.00</AwardTotalIntnAmount>
<AwardAmount>174150</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Test effectiveness, which indicates the capability of tests in detecting potential software bugs, is crucial for software testing. More effective tests can detect more potential bugs and thus help prevent economic loss or even physical damage caused by software bugs. Therefore, a huge body of research efforts have been dedicated to test effectiveness evaluation during the past decades. Recently, mutation testing, a powerful methodology that computes the detection rate of artificially injected bugs to measure test effectiveness, is drawing more and more attention from both the academia and industry. Various studies have shown that artificial bugs generated by mutation testing are close to real bugs, demonstrating mutation testing effectiveness in test effectiveness evaluation. However, a major obstacle for mutation testing is the efficiency problem ? mutation testing requires the execution of each artificial buggy version (i.e., mutant) to check whether the test suite can detect that bug, and which is extremely time consuming. Therefore, a light-weight but precise technique for measuring test effectiveness is highly desirable.&lt;br/&gt;&lt;br/&gt;The approach is to automatically extract test effectiveness information (e.g., mutation testing results) from various open-source projects  to directly predict the test effectiveness of the current project without any mutant execution. More specifically, the PI proposes to design a general classification framework based on a suite of static and dynamic features collected according to the PIE theory of fault detection. Furthermore, this research will explore judicious applications of advanced program analysis, machine learning, and software mining techniques for more powerful feature collection, more active learning, as well as more comprehensive training data preparation. The proposed approach will result in efficient but precise test effectiveness evaluation for projects developed using various programming languages and test paradigms, which is crucial for high-quality software. Furthermore, the training of the classification models will require to collect various basic testing, analysis, and mining information from a huge number of open-source projects, and thus may also benefit a large variety of software testing/analysis/mining  techniques that explore open-source software repositories.</AbstractNarration>
<MinAmdLetterDate>05/18/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1566589</AwardID>
<Investigator>
<FirstName>Lingming</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lingming Zhang</PI_FULL_NAME>
<EmailAddress>lingming@illinois.edu</EmailAddress>
<PI_PHON>5125740626</PI_PHON>
<NSF_ID>000683508</NSF_ID>
<StartDate>05/18/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Dallas</Name>
<CityName>Richardson</CityName>
<ZipCode>750803021</ZipCode>
<PhoneNumber>9728832313</PhoneNumber>
<StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX32</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>800188161</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT DALLAS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Dallas]]></Name>
<CityName/>
<StateCode>TX</StateCode>
<ZipCode>750803021</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>7798</Code>
<Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~174150</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual Merit:<br />The project explored the first approach to predict test effectiveness via learning from the test-effectiveness information of other versions of the same project or even other projects. The project has led to the development of a series of effective techniques to speed up mutation testing for lightweight test-effectiveness evaluation. On the evaluation dataset with hundreds of real-world GitHub projects and millions of mutants, the proposed techniques are able to speed up mutation testing by orders of magnitude while only incurring negligible error rate. The PI also studied the impacts of various learning algorithms (including traditional machine learning and deep neural network models), dynamic and static features, as well as benchmark datasets for practical test-effectiveness evaluation.&nbsp; The project has also produced hundreds of real-world GitHub projects with various dynamic and static analysis information, which have enabled the PI to explore novel applications of such large-scale datasets on other related topics, including fault localization and regression testing. In total, the project has resulted in more than 10 publications in top-tier software engineering and programming language conferences and transactions, such as ICSE, FSE, ISSTA, ASE, OOPSLA, and TSE.<br /><br />Broader Impacts:<br />The resulting techniques and empirical findings on learning-based mutation testing are not only helpful for developers to obtain more precise test-effectiveness evaluation more efficiently, but also enable large-scale lightweight mutation analysis of a large number of open-source projects, which in turn can provide extensive datasets for various other related areas for software testing, analysis, and mining. For example, the precise learning-based mutation testing results can potentially enable fast and accurate mutation-based automated debugging. The precise and lightweight test-effectiveness evaluation will also potentially help improve software quality for companies and open-source organizations all over the world, and may in turn affect all aspects of our modern life (which nowadays heavily depend on software). The activities undertaken as part of this project also expanded the educational and research opportunities available at The University of Texas at Dallas. More specifically, it in part supported three PhD students (including one minority student) and two Master students. Furthermore, the datasets collected during the project have also served as the benchmarks for course projects of the graduate-level CS6367 and undergraduate-level CS354 courses.</p><br> <p>            Last Modified: 06/13/2019<br>      Modified by: Lingming&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit: The project explored the first approach to predict test effectiveness via learning from the test-effectiveness information of other versions of the same project or even other projects. The project has led to the development of a series of effective techniques to speed up mutation testing for lightweight test-effectiveness evaluation. On the evaluation dataset with hundreds of real-world GitHub projects and millions of mutants, the proposed techniques are able to speed up mutation testing by orders of magnitude while only incurring negligible error rate. The PI also studied the impacts of various learning algorithms (including traditional machine learning and deep neural network models), dynamic and static features, as well as benchmark datasets for practical test-effectiveness evaluation.  The project has also produced hundreds of real-world GitHub projects with various dynamic and static analysis information, which have enabled the PI to explore novel applications of such large-scale datasets on other related topics, including fault localization and regression testing. In total, the project has resulted in more than 10 publications in top-tier software engineering and programming language conferences and transactions, such as ICSE, FSE, ISSTA, ASE, OOPSLA, and TSE.  Broader Impacts: The resulting techniques and empirical findings on learning-based mutation testing are not only helpful for developers to obtain more precise test-effectiveness evaluation more efficiently, but also enable large-scale lightweight mutation analysis of a large number of open-source projects, which in turn can provide extensive datasets for various other related areas for software testing, analysis, and mining. For example, the precise learning-based mutation testing results can potentially enable fast and accurate mutation-based automated debugging. The precise and lightweight test-effectiveness evaluation will also potentially help improve software quality for companies and open-source organizations all over the world, and may in turn affect all aspects of our modern life (which nowadays heavily depend on software). The activities undertaken as part of this project also expanded the educational and research opportunities available at The University of Texas at Dallas. More specifically, it in part supported three PhD students (including one minority student) and two Master students. Furthermore, the datasets collected during the project have also served as the benchmarks for course projects of the graduate-level CS6367 and undergraduate-level CS354 courses.       Last Modified: 06/13/2019       Submitted by: Lingming Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
