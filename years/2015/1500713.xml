<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER-DynamicData:  Judicious Censoring, Random Sketching, and Efficient Validate for Learning Patterns from Dynamically-Changing and Large-Scale Data Sets</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>akbar sayeed</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Abstract. With pervasive sensors continuously collecting and recording massive amounts of information, there is no doubt this is an era of data deluge. Learning from these dynamic and large volumes of data is expected to bring significant science and engineering advances along with consequent improvements in quality of life. The present early-concept grant for exploratory research aims to develop potentially transformative pattern recognition techniques that will be specifically tested on dynamically deforming (due to e.g., patient motion) cardiac magnetic resonance images, as well as on information extraction from large-scale healthcare datasets. Big challenges that this project addresses, include the sheer volume of online and growing datasets, which makes it impossible to run analytics especially in batch form; and also the facts that large-scale datasets are inevitably noisy, dynamic, incomplete, prone to outliers and (un)intentional misses, as well as vulnerable to cyber-attacks. The project's large-scale analytics will also permeate interdisciplinary benefits to environmental data mining, neuroscience, and the future power grid. At a broader scale, the developed technologies will provide valuable tools for foundational science and engineering research, and promote societal embracing of the emergent big data technologies, along with training the next-generation of data science professionals.&lt;br/&gt;&lt;br/&gt;This early-concept grant for exploratory research aspires to tackle big data challenges by putting forth large-scale learning tools and their performance analyses that leverage two untested, but potentially transformative, ideas for extracting computationally affordable yet informative subsets of massive and dynamic datasets, namely i) adaptive censoring, and ii) random data sketching-and-validation. Data in this project can be stationary or nonstationary; they become available in batch or sequential (a.k.a. online) modes; they can be collected in vectors, matrices or general multi-way arrays (called tensors); noise, possibly outliers and (un)intentional misses are present; and data processing can be linear or nonlinear in adaptive or non-adaptive modes. The proposed high risk-high payoff research lies at the intersection of essential big data tools including compressive sampling, matrix and tensor completion, anomaly and outlier identification, online and parallel optimization techniques. In accordance with the major inference tasks, three intertwined research thrusts will be pursued: T1) Adaptive censoring for large-scale regressions; T2) Subspace tracking and imputation for dynamic large-scale tensors; and T3) Sketch-and-validate for large-scale clustering and classification. The resultant innovative tools will be tested in healthcare data, and multi-dimensional magnetic resonance imaging, having as ultimate goal high-resolution biomedical movies to be acquired, processed, and displayed in real time.</AbstractNarration>
<MinAmdLetterDate>09/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1500713</AwardID>
<Investigator>
<FirstName>Georgios</FirstName>
<LastName>Giannakis</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Georgios B Giannakis</PI_FULL_NAME>
<EmailAddress>georgios@umn.edu</EmailAddress>
<PI_PHON>6126254287</PI_PHON>
<NSF_ID>000472431</NSF_ID>
<StartDate>09/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota Twin-Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554552070</ZipCode>
<StreetAddress><![CDATA[200 Union Street SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramElement>
<Code>O395</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>153E</Code>
<Text>Wireless comm &amp; sig processing</Text>
</ProgramReference>
<ProgramReference>
<Code>5384</Code>
<Text>DATA AND DATA SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>With sensors continuously collecting massive amounts of information, this is undoubtedly an era of ``data deluge.'' Learning from large volumes of data is expected to bring ground-breaking advances in science and engineering along with consequent improvements in quality of life. Magnetic resonance imaging (MRI) is among the principal technologies in this scientific revolution: It allows one to visualize not only structural but also physiological information of living subjects at both macro- and micro-scopic levels unreachable by human vision, thus providing ample opportunities to study biological processes, as well as diagnose and treat diseases. With such a big blessing however, come big challenges. As MRI acquisition speeds are relatively low, only under-sampled corrupted measurements can be collected. The sheer volume of dynamically acquired data can also challenge MRI reconstruction on central processors and storage units. Furthermore, as data are continuously collected in real time, reconstruction must be performed, in contrast to standard dynamic MRI schemes, on-the-fly for&nbsp;visualization purposes.</p> <p>This project contributed to addressing&nbsp;these challenges by putting forth powerful models capturing&nbsp;the characteristics of big dynamic data, and then offering learning algorithms to overcome the emerging practical hurdles, while revealing&nbsp;fundamental insights into various analytical and implementation trade-offs&nbsp;involved. Outcomes with major intellectual merits included: a1) informative censoring to lower the massive size of less informative data; a2) random sketching of the data to cope with learning from large-scale datasets; b1) adaptive censoring for estimating dynamical processes; b2) online categorical subspace learning for sketching big data with misses; b3) identifying topologies of large-scale directed graphs using kernels and tensors; c1) identification of overlapping communities via constrained tensor decompositions; c2) data-adaptive active sampling for efficient graph-cognizant classification; and c3) inference of spatio-temporal functions over graphs via multikernel Kriged Kalman filtering.</p> <p>The proposed framework is capable of extracting salient global trends to enable imputation for missing MRI data entries due to imaging&nbsp;speed limitations, and obtain parsimonious representations to process&nbsp;and draw inferences from big pools of MRI data. Emphasis was laid on concocting online, parallel, and&nbsp;decentralized algorithms based on matrix and tensor models, to enable&nbsp;streaming analytics of sequential measurements using parallel processors, and&nbsp;tracking dynamically evolving datasets. Besides MRI, the results have major impact to applications of data science and network science. Broader impact to education included graduation of 6 PhD students supported by this grant 3 of which joined academia as assistant professors, and 3 pursued a research career in the Data Science industry. &nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/04/2018<br>      Modified by: Georgios&nbsp;B&nbsp;Giannakis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ With sensors continuously collecting massive amounts of information, this is undoubtedly an era of ``data deluge.'' Learning from large volumes of data is expected to bring ground-breaking advances in science and engineering along with consequent improvements in quality of life. Magnetic resonance imaging (MRI) is among the principal technologies in this scientific revolution: It allows one to visualize not only structural but also physiological information of living subjects at both macro- and micro-scopic levels unreachable by human vision, thus providing ample opportunities to study biological processes, as well as diagnose and treat diseases. With such a big blessing however, come big challenges. As MRI acquisition speeds are relatively low, only under-sampled corrupted measurements can be collected. The sheer volume of dynamically acquired data can also challenge MRI reconstruction on central processors and storage units. Furthermore, as data are continuously collected in real time, reconstruction must be performed, in contrast to standard dynamic MRI schemes, on-the-fly for visualization purposes.  This project contributed to addressing these challenges by putting forth powerful models capturing the characteristics of big dynamic data, and then offering learning algorithms to overcome the emerging practical hurdles, while revealing fundamental insights into various analytical and implementation trade-offs involved. Outcomes with major intellectual merits included: a1) informative censoring to lower the massive size of less informative data; a2) random sketching of the data to cope with learning from large-scale datasets; b1) adaptive censoring for estimating dynamical processes; b2) online categorical subspace learning for sketching big data with misses; b3) identifying topologies of large-scale directed graphs using kernels and tensors; c1) identification of overlapping communities via constrained tensor decompositions; c2) data-adaptive active sampling for efficient graph-cognizant classification; and c3) inference of spatio-temporal functions over graphs via multikernel Kriged Kalman filtering.  The proposed framework is capable of extracting salient global trends to enable imputation for missing MRI data entries due to imaging speed limitations, and obtain parsimonious representations to process and draw inferences from big pools of MRI data. Emphasis was laid on concocting online, parallel, and decentralized algorithms based on matrix and tensor models, to enable streaming analytics of sequential measurements using parallel processors, and tracking dynamically evolving datasets. Besides MRI, the results have major impact to applications of data science and network science. Broader impact to education included graduation of 6 PhD students supported by this grant 3 of which joined academia as assistant professors, and 3 pursued a research career in the Data Science industry.             Last Modified: 12/04/2018       Submitted by: Georgios B Giannakis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
