<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Coalitional Game Theory for Co-Locating Software on Shared Hardware</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>266525.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As computing capability grows and computation becomes increasingly task parallel, many small tasks will co-locate on a few big machines. No single computational task can utilize a machine's resources completely, yet all of these resources become available when a machine is powered up. This mismatch leads to the well-known problem of energy disproportionality, when a server is under-utilized and its fixed power costs are amortized over little work. Managing task co-location to ensure performance, to improve power efficiency, and to incentivize desired behavior from strategic users requires new perspectives. &lt;br/&gt;Computing resources increasingly fall into economists? definition of a commons. A commons is a technology used jointly by a set of agents and the problem of the commons is to organize the joint exploitation of this technology. By mapping shared hardware architectures into this problem formulation, the investigators adapt systems management mechanisms to accommodate strategic user behavior. This microeconomic perspective leads to incentives that encourage users to adopt cloud computing for greater performance and efficiency.&lt;br/&gt;&lt;br/&gt;The investigators are committed to integrating research and education. Successes include strong teaching evaluations for classes in energy-efficient computing and classes that rapidly prepare Masters students with weaker backgrounds in computing fundamentals. Successes also include fostering research participation from undergraduates and under-represented minorities. &lt;br/&gt;The investigators study game-theoretic mechanisms for co-locating tasks and mitigating contention between strategic users who share high-performance hardware architectures. First, these mechanisms estimate performance by inferring statistical models for contention penalties that arise from users? behavior combinations. Then, these mechanisms attribute penalties to tasks by using coalitional game theory to determine the extent that each task contributes to system contention. Finally, these mechanisms optimize software co-location for strategic users and ensure game-theoretic desiderata, such as sharing incentives and fairness. &lt;br/&gt;The project is interdisciplinary, linking previously disparate studies in computer architecture, resource management, and algorithmic economics. The research draws on rigorous, analytical frameworks to reason about users' interactions within shared systems and their contributions to overall system outcomes. Moreover, the research translates rigor into operational mechanisms for systems management and task co-location.</AbstractNarration>
<MinAmdLetterDate>08/05/2015</MinAmdLetterDate>
<MaxAmdLetterDate>05/30/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1527610</AwardID>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin Lee</PI_FULL_NAME>
<EmailAddress>leebcc@seas.upenn.edu</EmailAddress>
<PI_PHON>6178522210</PI_PHON>
<NSF_ID>000572761</NSF_ID>
<StartDate>08/05/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Hilton</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew D Hilton</PI_FULL_NAME>
<EmailAddress>adhilton@ee.duke.edu</EmailAddress>
<PI_PHON>9196843030</PI_PHON>
<NSF_ID>000633802</NSF_ID>
<StartDate>08/05/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<StateCode>NC</StateCode>
<ZipCode>277054010</ZipCode>
<StreetAddress><![CDATA[2200 W. Main St, Suite 710]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~263187</FUND_OBLG>
<FUND_OBLG>2017~136813</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div>Intellectual Merit. The research supported by this award has laid the foundations for using multi-agent game theory and statistical learning to better design and management high-performance computer systems. The PI and his students have made several key contributions.</div> <div></div> <div>First, the team has significantly advanced the state-of-the-art in sprint management. Modern datacenters oversubscribe their power supplies to enhance performance and efficiency. Efficient datacenters deploy more servers than it can power fully and rely on varying computational load across servers to modulate demand for power. Such a strategy requires responsive mechanisms for delivering power to the computation that needs it most.&nbsp;</div> <div></div> <div>Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. The team designs a sprint architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chip's thermal limits and the rack&rsquo;s power limits. Moreover, the team formulates the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on computational workload phases and system conditions. The game produces an equilibrium that improves task throughput yet avoids over-subscribing shared power supplies and violating aggregate thermal constraints. We demonstrate the computational sprinting game at multiple scales. At datacenter scale, independent and selfish agents compete for power. At processor scale, independent and selfish agents compete for core power and cache capacity.&nbsp;</div> <div></div> <div>Second, the team has developed novel perspectives on colocating computation on datacenter servers. Modern datacenters, with their increasingly parallel computation and increasingly capable machines, colocate small tasks on big servers. A task partially uses a server&rsquo;s resources, but all resources become available when the server is power.d When a server&rsquo;s large power costs are amortized over little work, energy efficiency suffers. Colocating multiple tasks on each server increases efficiency but introduces contention for shared resources.&nbsp;</div> <div></div> <div>Our new perspectives focus on delivering stronger game-theoretic properties in management decisions and delivering more responsive decisions at run-time. Cooperative games describe how agents&rsquo; interactions dictate shared outcomes and such games are well suited for colocation as interference between tasks dictates performance penalties. Our team develops methods that predict preferences and adapt stable matching algorithms to colocate tasks. Our team also develops reinforcement learning frameworks to design and implement an adaptive controller for managing resource contention. During run-time, the controller observes dynamic system conditions and optimizes control policies that satisfy latency targets yet improve server utilization.&nbsp;</div> <div></div> <div>Finally, team has developed market mechanisms to allocate datacenter processors efficiently and fairly. Systems often determine a user&rsquo;s share of processors with entitlements such that each user is guaranteed a minimum allocation and under-utilized resources re redistributed. Entitlements for datacenters differ from those for a server. Within a server, proportional share schedulers allocate divisible resources. In theory, the datacenter provides a similar abstraction but, in practice, resources are physically distributed across datacenter servers in ways that constrain allocation. Jobs are assigned to servers and resources are partitioned along server boundaries.&nbsp;</div> <div></div> <div>The team addresses this challenge with a market mechanism that divides a user&rsquo;s datacenter-wide entitlement across servers that run her jobs. Users receive budgets in proportion to their entitlements and bid for processor cores on each server. The market sets prices based on bids and users bid on prices. The market&rsquo;s centerpiece is the Amdahl utility function, which we derive from Amdahl&rsquo;s Law to model the value of each server&rsquo;s cores and calculate bids. In equilibrium, all cores are allocated and allocations are optimal. Moreover, this equilibrium is fair because budgets satisfy entitlements and performs well because bids shift more resources to more parallelizable workloads.&nbsp;</div> <div></div> <div>Many of these perspectives and outcomes have laid foundations for work in other distributed systems. In future, the PI and his team will extend their research into collaborative computing for distributed, embedded devices. In this setting, nodes are highly heterogeneous. They differ in processing capability, communication capability, and battery capacity. Determining the most effective assignment of tasks to achieve a shared computational goal remains an open challenge.&nbsp;</div> <div></div> <div>Broader Outcomes. Beyond the specific research accomplishments, the research award supported numerous graduate and undergraduate research assistants. The grant supported research assistants from under-represented groups and funded, in part, three women during their doctoral research and four women during their undergraduate and masters research.&nbsp;</div> <div></div> <div>The graduate research assistants that completed their PhDs under this grant have started academic and research careers as assistant professors (University of Colorado, Boulder and University of Waterloo), research professor (University of Waterloo), and postdoctoral researcher (University of Wisconsin) as a Computing Innovation Fellow. The undergraduate researchers from these projects have often continued to pursue graduate degrees at institutions such as the University of Chicago, Columbia University, Princeton University, Duke University, University of Texas at Austin, and the California Institute of Technology.</div><br> <p>            Last Modified: 09/15/2020<br>      Modified by: Benjamin&nbsp;Lee</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Intellectual Merit. The research supported by this award has laid the foundations for using multi-agent game theory and statistical learning to better design and management high-performance computer systems. The PI and his students have made several key contributions.  First, the team has significantly advanced the state-of-the-art in sprint management. Modern datacenters oversubscribe their power supplies to enhance performance and efficiency. Efficient datacenters deploy more servers than it can power fully and rely on varying computational load across servers to modulate demand for power. Such a strategy requires responsive mechanisms for delivering power to the computation that needs it most.   Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. The team designs a sprint architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chip's thermal limits and the rack’s power limits. Moreover, the team formulates the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on computational workload phases and system conditions. The game produces an equilibrium that improves task throughput yet avoids over-subscribing shared power supplies and violating aggregate thermal constraints. We demonstrate the computational sprinting game at multiple scales. At datacenter scale, independent and selfish agents compete for power. At processor scale, independent and selfish agents compete for core power and cache capacity.   Second, the team has developed novel perspectives on colocating computation on datacenter servers. Modern datacenters, with their increasingly parallel computation and increasingly capable machines, colocate small tasks on big servers. A task partially uses a server’s resources, but all resources become available when the server is power.d When a server’s large power costs are amortized over little work, energy efficiency suffers. Colocating multiple tasks on each server increases efficiency but introduces contention for shared resources.   Our new perspectives focus on delivering stronger game-theoretic properties in management decisions and delivering more responsive decisions at run-time. Cooperative games describe how agents’ interactions dictate shared outcomes and such games are well suited for colocation as interference between tasks dictates performance penalties. Our team develops methods that predict preferences and adapt stable matching algorithms to colocate tasks. Our team also develops reinforcement learning frameworks to design and implement an adaptive controller for managing resource contention. During run-time, the controller observes dynamic system conditions and optimizes control policies that satisfy latency targets yet improve server utilization.   Finally, team has developed market mechanisms to allocate datacenter processors efficiently and fairly. Systems often determine a user’s share of processors with entitlements such that each user is guaranteed a minimum allocation and under-utilized resources re redistributed. Entitlements for datacenters differ from those for a server. Within a server, proportional share schedulers allocate divisible resources. In theory, the datacenter provides a similar abstraction but, in practice, resources are physically distributed across datacenter servers in ways that constrain allocation. Jobs are assigned to servers and resources are partitioned along server boundaries.   The team addresses this challenge with a market mechanism that divides a user’s datacenter-wide entitlement across servers that run her jobs. Users receive budgets in proportion to their entitlements and bid for processor cores on each server. The market sets prices based on bids and users bid on prices. The market’s centerpiece is the Amdahl utility function, which we derive from Amdahl’s Law to model the value of each server’s cores and calculate bids. In equilibrium, all cores are allocated and allocations are optimal. Moreover, this equilibrium is fair because budgets satisfy entitlements and performs well because bids shift more resources to more parallelizable workloads.   Many of these perspectives and outcomes have laid foundations for work in other distributed systems. In future, the PI and his team will extend their research into collaborative computing for distributed, embedded devices. In this setting, nodes are highly heterogeneous. They differ in processing capability, communication capability, and battery capacity. Determining the most effective assignment of tasks to achieve a shared computational goal remains an open challenge.   Broader Outcomes. Beyond the specific research accomplishments, the research award supported numerous graduate and undergraduate research assistants. The grant supported research assistants from under-represented groups and funded, in part, three women during their doctoral research and four women during their undergraduate and masters research.   The graduate research assistants that completed their PhDs under this grant have started academic and research careers as assistant professors (University of Colorado, Boulder and University of Waterloo), research professor (University of Waterloo), and postdoctoral researcher (University of Wisconsin) as a Computing Innovation Fellow. The undergraduate researchers from these projects have often continued to pursue graduate degrees at institutions such as the University of Chicago, Columbia University, Princeton University, Duke University, University of Texas at Austin, and the California Institute of Technology.       Last Modified: 09/15/2020       Submitted by: Benjamin Lee]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
