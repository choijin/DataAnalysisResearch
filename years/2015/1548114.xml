<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Exploring the Use of Deception to Enhance Cyber Security</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>05/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>182299.00</AwardTotalIntnAmount>
<AwardAmount>182299</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
<PO_EMAI>namla@nsf.gov</PO_EMAI>
<PO_PHON>7032927991</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Our computing systems are constantly under attack, by everyone from pranksters to agents of hostile nations.  Many of those systems and networks make the task of the adversary easier by responding to attacks with useful information.  This is because software and protocols have been written for decades to provide informative feedback for error detection and correction.  It is precisely this behavior that enhances the chances of success by attackers, by allowing them to map networks and determine system flaws.  This research addresses the question "Are there uses of deceptive responses that help prevent successful attacks?"  Furthermore, the study investigates if it is possible to characterize and model the types of situations where deception may be useful. The result of this work provides cyber system designers with some new defensive measures, and guidance as to when they are useful to deploy.&lt;br/&gt;&lt;br/&gt;The project includes two related lines of research.  The first of these is to explore some new applications of deceit in system defense. The researchers investigate presenting deceptive responses to attempts to exploit known vulnerabilities, and building a file system that "lies" about the creation and deletion of key files.  Each of these mechanisms should support a system's security by providing early warning of bad behavior as well as blunting attacks.  Deceitful responses to attacks can lead a perpetrator to employ ineffective attacks, thus wasting time and effort.  A deceptive file system can capture forensic data about an attempted attack while only appearing to allow the installation of malicious files.  The second line of research explores how to apply hypergame models to cyber defenses using deceptive techniques.  Hypergames are an extension of game theory that includes incorrect and uncertain information.  By constructing hypergame models we should be able to determine situations where there is a favorable result when deception is employed as a defense.</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1548114</AwardID>
<Investigator>
<FirstName>Eugene</FirstName>
<LastName>Spafford</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eugene H Spafford</PI_FULL_NAME>
<EmailAddress>spaf@purdue.edu</EmailAddress>
<PI_PHON>7654947805</PI_PHON>
<NSF_ID>000148116</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Saurabh</FirstName>
<LastName>Bagchi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Saurabh Bagchi</PI_FULL_NAME>
<EmailAddress>sbagchi@purdue.edu</EmailAddress>
<PI_PHON>7654941741</PI_PHON>
<NSF_ID>000309372</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072086</ZipCode>
<StreetAddress><![CDATA[656 Oval Dr]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~182299</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project was devoted to the exploration of how deception could be used to add to the defenses of computer and network systems ("cyber"). &nbsp;Most current computing systems provide helpful error messages and feedback for purposes of debugging and enhanced user experience, but&nbsp;that same feedback may assist attackers in exploiting weaknesses.<br /><br /><br />Our project examined how providing false information and decoys could be used to slow, mislead, or expose attackers. &nbsp;Our efforts involved four separate but related efforts, described below.<br /><br /><br />The first effort was to develop a formal taxonomy of deceptive practices, including masking, decoys, and providing misleading information. &nbsp;This effort resulted in a published, comprehensive model that can be used to classify every known form of cyber deception.<br /><br /><br />The second effort was to explore the effectiveness of providing false information in patches for security problems. &nbsp;Patching is widely used to fix flaws and functionality, but the patches may be reverse-engineering to find attack points. &nbsp;We explored methods of obfuscating the patches and&nbsp;providing false patches ("ghost patches") to slow or confuse attackers. &nbsp;An extensive analysis and experiments with prototypes showed this had some minor promise, but would not be highly effective against sophisticated attackers.<br /><br />&nbsp;<br />We concluded that providing new instances of the entire software artifact using existing methods of obfuscation and confusion would likely be more effective in slowing reverse engineering analysis and attack than would be releasing "ghost" patches. &nbsp;We determined there might be more involved methods of&nbsp;building false and illusory patches, but we did not fully explore them; we determined that complicated false patching would make legitimate maintenance and debugging more difficult, and thus would be of questionable value.<br /><br /><br />Our third effort was to explore how to provide a misleading view of secondary memory (disk) to an attacker. &nbsp;Attackers often delete system resources, alter logs, and remove malware traces to hide malicious activity. &nbsp;If those alterations and deleted items were available to the&nbsp;system defenders, it would provide an advantage in both recovery and forensics. However, it is essential to let the attacker believe that the alterations and deletions are occurring so that countermeasures are not taken, or to ensure that the attacker does not terminate the attack before sufficient evidence is collected.<br /><br /><br />We constructed two prototype systems that collect the state of artifacts that an attacker might change or delete yet are not visible to the end user. &nbsp;One of these was part of a running OS, and the other was a modified virtual machine monitor. &nbsp;In each case, we explored making the capture&nbsp;of data undetectable to the user, yet of sufficient fidelity to allow reconstruction of the system before the attack, and capture of any uploads. &nbsp;We found that our final system, R2D2, worked well enough that it was also able to detect and counter ransomware attacks that would attempt to&nbsp;encrypt vast portions of the disk -- we were able to recover the entire disc contents after such an attack. We determined how to use a user-specified parameter to trade off the amount of extra storage used and the level of protection.&nbsp;<br /><br /><br />Our fourth effort was to explore the use of an extension to game theory using incomplete information -- hypergames -- to model the deployment and use of deception. &nbsp;Our goal was to explore if hypergames might be used to determine when deception was appropriate to use, and when it&nbsp;might not be effective. &nbsp;We constructed some simple models using single rounds of deception and found that using deception mechanisms were effective in cases where the attacker suspected deception was present. &nbsp; As of the end of this portion of the project, we have yet to explore more&nbsp;complex hypergames models of deception, such as, through multiple rounds of &ldquo;games&rdquo; between the attacker and the defender.&nbsp;<br /><br /><br />In addition to 15 publications on our research results in conferences and journals, we also produced several software prototypes that are available for further experimentation by others. &nbsp;Three students completed their Ph.D. degrees while working on this project, and several other graduate&nbsp;and undergraduate students obtained practical training in systems development and defense.<br /><br /><br />Both principal investigators on this project are planning on future research in the issues raised during the effort. &nbsp;They are also exploring technology transfer opportunities to employ some of the lessons learned in real-world products.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/06/2018<br>      Modified by: Eugene&nbsp;H&nbsp;Spafford</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project was devoted to the exploration of how deception could be used to add to the defenses of computer and network systems ("cyber").  Most current computing systems provide helpful error messages and feedback for purposes of debugging and enhanced user experience, but that same feedback may assist attackers in exploiting weaknesses.   Our project examined how providing false information and decoys could be used to slow, mislead, or expose attackers.  Our efforts involved four separate but related efforts, described below.   The first effort was to develop a formal taxonomy of deceptive practices, including masking, decoys, and providing misleading information.  This effort resulted in a published, comprehensive model that can be used to classify every known form of cyber deception.   The second effort was to explore the effectiveness of providing false information in patches for security problems.  Patching is widely used to fix flaws and functionality, but the patches may be reverse-engineering to find attack points.  We explored methods of obfuscating the patches and providing false patches ("ghost patches") to slow or confuse attackers.  An extensive analysis and experiments with prototypes showed this had some minor promise, but would not be highly effective against sophisticated attackers.    We concluded that providing new instances of the entire software artifact using existing methods of obfuscation and confusion would likely be more effective in slowing reverse engineering analysis and attack than would be releasing "ghost" patches.  We determined there might be more involved methods of building false and illusory patches, but we did not fully explore them; we determined that complicated false patching would make legitimate maintenance and debugging more difficult, and thus would be of questionable value.   Our third effort was to explore how to provide a misleading view of secondary memory (disk) to an attacker.  Attackers often delete system resources, alter logs, and remove malware traces to hide malicious activity.  If those alterations and deleted items were available to the system defenders, it would provide an advantage in both recovery and forensics. However, it is essential to let the attacker believe that the alterations and deletions are occurring so that countermeasures are not taken, or to ensure that the attacker does not terminate the attack before sufficient evidence is collected.   We constructed two prototype systems that collect the state of artifacts that an attacker might change or delete yet are not visible to the end user.  One of these was part of a running OS, and the other was a modified virtual machine monitor.  In each case, we explored making the capture of data undetectable to the user, yet of sufficient fidelity to allow reconstruction of the system before the attack, and capture of any uploads.  We found that our final system, R2D2, worked well enough that it was also able to detect and counter ransomware attacks that would attempt to encrypt vast portions of the disk -- we were able to recover the entire disc contents after such an attack. We determined how to use a user-specified parameter to trade off the amount of extra storage used and the level of protection.    Our fourth effort was to explore the use of an extension to game theory using incomplete information -- hypergames -- to model the deployment and use of deception.  Our goal was to explore if hypergames might be used to determine when deception was appropriate to use, and when it might not be effective.  We constructed some simple models using single rounds of deception and found that using deception mechanisms were effective in cases where the attacker suspected deception was present.   As of the end of this portion of the project, we have yet to explore more complex hypergames models of deception, such as, through multiple rounds of "games" between the attacker and the defender.    In addition to 15 publications on our research results in conferences and journals, we also produced several software prototypes that are available for further experimentation by others.  Three students completed their Ph.D. degrees while working on this project, and several other graduate and undergraduate students obtained practical training in systems development and defense.   Both principal investigators on this project are planning on future research in the issues raised during the effort.  They are also exploring technology transfer opportunities to employ some of the lessons learned in real-world products.          Last Modified: 07/06/2018       Submitted by: Eugene H Spafford]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
