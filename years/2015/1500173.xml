<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Rapid, Efficient Implementation of Irregular Applications on SIMD Many-Core Platforms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>249966.00</AwardTotalIntnAmount>
<AwardAmount>276866</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>General-purpose computation with efficient Single Instruction, Multiple Data (SIMD) oriented many-core devices, such as graphical processing units (GPUs), can deliver high performance in a variety of application domains. Data-parallel applications that perform well on SIMD many-cores typically exhibit regularity in patterns of computation and data movement, acting identically on each of an ensemble of many equal-sized inputs. However, many important applications exhibit irregular behavior making them difficult to implement efficiently on these platforms.  Thus, efficient SIMD implementation of applications with irregular behavior is an important ongoing research problem. &lt;br/&gt;&lt;br/&gt;This project's focus is the investigation and validation of novel interface designs, algorithmic techniques, and implementation strategies to address the problem of efficient SIMD implementation uniformly for applications from a variety of domains. The work includes generating alternate module designs to support efficient developer-driven searches over large design spaces to tune performance. Another key area of the research will validate these technologies on bio-sequence analysis applications resulting in innovative, efficient new GPU designs for computational tasks.  &lt;br/&gt;&lt;br/&gt;More broadly and with a particular focus on new high-performance application designs for data-intensive computations critical to bioinformatics, the project will enable faster development of more efficient, more maintainable GPU software, even for applications with SIMD-unfriendly irregular behaviors.</AbstractNarration>
<MinAmdLetterDate>07/28/2015</MinAmdLetterDate>
<MaxAmdLetterDate>05/24/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1500173</AwardID>
<Investigator>
<FirstName>Roger</FirstName>
<LastName>Chamberlain</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Roger D Chamberlain</PI_FULL_NAME>
<EmailAddress>roger@wustl.edu</EmailAddress>
<PI_PHON>3149355708</PI_PHON>
<NSF_ID>000362967</NSF_ID>
<StartDate>07/28/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeremy</FirstName>
<LastName>Buhler</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeremy D Buhler</PI_FULL_NAME>
<EmailAddress>jbuhler@wustl.edu</EmailAddress>
<PI_PHON>3149356180</PI_PHON>
<NSF_ID>000376117</NSF_ID>
<StartDate>07/28/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Washington University</Name>
<CityName>Saint Louis</CityName>
<ZipCode>631304862</ZipCode>
<PhoneNumber>3147474134</PhoneNumber>
<StreetAddress>CAMPUS BOX 1054</StreetAddress>
<StreetAddress2><![CDATA[1 Brookings Drive]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>068552207</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WASHINGTON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068552207</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Washington University]]></Name>
<CityName>St Louis</CityName>
<StateCode>MO</StateCode>
<ZipCode>631304899</ZipCode>
<StreetAddress><![CDATA[One Brookings Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~249966</FUND_OBLG>
<FUND_OBLG>2016~18350</FUND_OBLG>
<FUND_OBLG>2018~8550</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>High-performance computing today solves problems that involve massive amounts of data.&nbsp; Often, this data can be viewed as a long stream of inputs, each of which must be processed to complete a computation. Examples include streams of messages in a network, observations from a telescope or other scientific instrument, large collections of DNA and protein sequence, or individuals connected in a social network.&nbsp; If each input in the stream requires identical processing, we can finish a big&nbsp; computation faster by distributing inputs among many processors that execute the same work on different inputs in parallel.&nbsp; For<br />example, given a stream of numbers, if the goal is to double the value of each, every number could be doubled in parallel given enough processors. Streaming is particularly attractive for graphics processors (GPUs) and other special-purpose devices that can execute a single stream of instructions on hundreds or thousands of data items at once (so-called Single-Instruction, Multiple-Data or SIMD computation).<br /><br />Unfortunately, not all streaming computations are naturally well-suited to SIMD processing.&nbsp; Sometimes, a computation may involve a sequential pipeline of steps, each of which discards an unpredictable subset of the inputs.&nbsp; Decision cascades in machine learning (e.g., face recognition from images) and bioinformatics (e.g., detecting DNA sequences similar to a known example) are two examples of such pipelines.&nbsp; Alternatively, completing one input may require repeating some step a variable number of times, or some inputs may require different processing than others, in a way that cannot be predicted until the input is analyzed.&nbsp; For example, particle detection events in an orbiting space telescope may need different analyses depending on the energy of the event and the number of times the particle collided with the detector.&nbsp; We call such ill-behaved streaming computations "irregular."<br /><br />If we had hundreds or thousands of independent processors, it would be straightforward to perform the "right" computation for each input. But SIMD processors, which are found in modern supercomputers and increasingly in all types of computing devices, are restricted to doing the same computation on each input processed in parallel.&nbsp; The principal challenge addressed by this project is how to express irregular streaming computations in a way that allows them to be implemented rapidly and efficiently on SIMD processors.<br /><br />In this project, we have developed MERCATOR, a software system that supports irregular streaming computation on GPUs.&nbsp; A MERCATOR application is specified as a network of nodes, each of which contains a regular, SIMD-friendly computation, connected by links along which data flows between computations.&nbsp; The application's programmer supplies code for each node using the device's preferred language (e.g. CUDA for NVIDIA GPUs), while MERCATOR provides the "glue" that schedules the execution of nodes and moves data between them. Irregular application behavior is captured by the fact that each node can choose, for each input item, to send data to one or more of its output links, or to no link at all.&nbsp; MERCATOR uses queueing and<br />efficient parallel scanning operations to redistribute work among the threads of SIMD computation dynamically.&nbsp; This redistribution ensures that, at any given time, a GPU's processor is executing just one node's computation, as required by the SIMD paradigm, and that this node acts on as many simultaneous inputs as possible, so that the GPU's processing resources are not left idle.<br /><br />The main intellectual contributions of our project are in the design, implementation, and performance analysis of MERCATOR's supporting infrastructure.&nbsp; Key pieces of MERCATOR's design include dynamic, parallel remapping of inputs between queues and to GPU threads, deadlock-free scheduling of applications that include cyclic dataflow, and scheduling of nodes to maximize utilization fo SIMD processor cores. Our work includes extending the irregular streaming SIMD model of computation to perform aggregation, in which a group of consecutive inputs is summarized by a single result, and disaggregation, in which a single, composite input is "exploded" into a stream of elements that are processed independently and later collected back together.&nbsp; In addition to developing new and effective<br />ways to express and realize such computations, we have investigated how to apply the irregular streaming SIMD paradigm to important computations in gamma-ray astronomy, stereo vision, and bioinformatics.<br /><br />In addition to publishing about MERCATOR and related work, we have made MERCATOR's source code freely and publicly available.&nbsp; This project has trained two doctoral students and nine undergraduate students, including two women and two underrepresented minority students, in high-performance and parallel computing techniques.</p><br> <p>            Last Modified: 11/29/2018<br>      Modified by: Jeremy&nbsp;D&nbsp;Buhler</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1500173/1500173_10381024_1543526016346_mercator-topology--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1500173/1500173_10381024_1543526016346_mercator-topology--rgov-800width.jpg" title="Example Topology of MERCATOR Application"><img src="/por/images/Reports/POR/2018/1500173/1500173_10381024_1543526016346_mercator-topology--rgov-66x44.jpg" alt="Example Topology of MERCATOR Application"></a> <div class="imageCaptionContainer"> <div class="imageCaption">MERCATOR applications are described as dataflow graphs that can include branching and cyclic structures as shown in this example topology</div> <div class="imageCredit">Steve Cole</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jeremy&nbsp;D&nbsp;Buhler</div> <div class="imageTitle">Example Topology of MERCATOR Application</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1500173/1500173_10381024_1543526209648_mercator-parallelism--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1500173/1500173_10381024_1543526209648_mercator-parallelism--rgov-800width.jpg" title="How MERCATOR parallelizes streaming computation"><img src="/por/images/Reports/POR/2018/1500173/1500173_10381024_1543526209648_mercator-parallelism--rgov-66x44.jpg" alt="How MERCATOR parallelizes streaming computation"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Each node collects inputs from one or more queues, which are formed into a SIMD "ensemble" that is processed in parallel threads of computation. Some subset of inputs produce outputs, which are gathered and placed on a downstream queue for later processing.</div> <div class="imageCredit">Jeremy Buhler</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jeremy&nbsp;D&nbsp;Buhler</div> <div class="imageTitle">How MERCATOR parallelizes streaming computation</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ High-performance computing today solves problems that involve massive amounts of data.  Often, this data can be viewed as a long stream of inputs, each of which must be processed to complete a computation. Examples include streams of messages in a network, observations from a telescope or other scientific instrument, large collections of DNA and protein sequence, or individuals connected in a social network.  If each input in the stream requires identical processing, we can finish a big  computation faster by distributing inputs among many processors that execute the same work on different inputs in parallel.  For example, given a stream of numbers, if the goal is to double the value of each, every number could be doubled in parallel given enough processors. Streaming is particularly attractive for graphics processors (GPUs) and other special-purpose devices that can execute a single stream of instructions on hundreds or thousands of data items at once (so-called Single-Instruction, Multiple-Data or SIMD computation).  Unfortunately, not all streaming computations are naturally well-suited to SIMD processing.  Sometimes, a computation may involve a sequential pipeline of steps, each of which discards an unpredictable subset of the inputs.  Decision cascades in machine learning (e.g., face recognition from images) and bioinformatics (e.g., detecting DNA sequences similar to a known example) are two examples of such pipelines.  Alternatively, completing one input may require repeating some step a variable number of times, or some inputs may require different processing than others, in a way that cannot be predicted until the input is analyzed.  For example, particle detection events in an orbiting space telescope may need different analyses depending on the energy of the event and the number of times the particle collided with the detector.  We call such ill-behaved streaming computations "irregular."  If we had hundreds or thousands of independent processors, it would be straightforward to perform the "right" computation for each input. But SIMD processors, which are found in modern supercomputers and increasingly in all types of computing devices, are restricted to doing the same computation on each input processed in parallel.  The principal challenge addressed by this project is how to express irregular streaming computations in a way that allows them to be implemented rapidly and efficiently on SIMD processors.  In this project, we have developed MERCATOR, a software system that supports irregular streaming computation on GPUs.  A MERCATOR application is specified as a network of nodes, each of which contains a regular, SIMD-friendly computation, connected by links along which data flows between computations.  The application's programmer supplies code for each node using the device's preferred language (e.g. CUDA for NVIDIA GPUs), while MERCATOR provides the "glue" that schedules the execution of nodes and moves data between them. Irregular application behavior is captured by the fact that each node can choose, for each input item, to send data to one or more of its output links, or to no link at all.  MERCATOR uses queueing and efficient parallel scanning operations to redistribute work among the threads of SIMD computation dynamically.  This redistribution ensures that, at any given time, a GPU's processor is executing just one node's computation, as required by the SIMD paradigm, and that this node acts on as many simultaneous inputs as possible, so that the GPU's processing resources are not left idle.  The main intellectual contributions of our project are in the design, implementation, and performance analysis of MERCATOR's supporting infrastructure.  Key pieces of MERCATOR's design include dynamic, parallel remapping of inputs between queues and to GPU threads, deadlock-free scheduling of applications that include cyclic dataflow, and scheduling of nodes to maximize utilization fo SIMD processor cores. Our work includes extending the irregular streaming SIMD model of computation to perform aggregation, in which a group of consecutive inputs is summarized by a single result, and disaggregation, in which a single, composite input is "exploded" into a stream of elements that are processed independently and later collected back together.  In addition to developing new and effective ways to express and realize such computations, we have investigated how to apply the irregular streaming SIMD paradigm to important computations in gamma-ray astronomy, stereo vision, and bioinformatics.  In addition to publishing about MERCATOR and related work, we have made MERCATOR's source code freely and publicly available.  This project has trained two doctoral students and nine undergraduate students, including two women and two underrepresented minority students, in high-performance and parallel computing techniques.       Last Modified: 11/29/2018       Submitted by: Jeremy D Buhler]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
