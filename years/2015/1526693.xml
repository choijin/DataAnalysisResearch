<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Transforming the Architectural Design Review Process through Collaborative Embodiment in HMD-Based Immersive Virtual Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>499410.00</AwardTotalIntnAmount>
<AwardAmount>499410</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Immersive virtual reality (IVR) technology has the potential to fundamentally transform the architectural design and building industries, by enabling individuals and groups to achieve an accurate and intuitive experiential understanding of a designed environment before it is built.  To help realize this promise, the PI and her team will in this project pursue a multi-faceted research agenda that seeks to develop and deploy low-cost, multi-user, head-mounted-display (HMD) based IVR technology to more effectively support the decision-making process in architecture / engineering / construction design reviews.  The research will address two critical challenges: to enable individual stakeholders to achieve a more accurate understanding of the 3D spatial structure and affordances for action in a designed interior space and to reliably assess its aesthetic and functional suitability under realistic use conditions; and to facilitate effective collaborative design review by enabling groups of stakeholders to be jointly immersed in the virtual model during the review process.  Project outcomes promise to offer immediate benefits to architects, builders, and their clients, who will be able to more readily evaluate the suitability of designed spaces to meet their needs.  The work also has the potential to enhance the effectiveness with which IVR technology can be used for a wider variety of collaborative and experiential purposes, in areas from education and training to psychotherapy and rehabilitation.  In addition, the research has the potential to support significant advances in design education, by enabling the broader effective use of IVR technology in teaching fundamental concepts of visual imagination, and to foster closer interdisciplinary collaboration between faculty and students in computer science, architecture and design.&lt;br/&gt;&lt;br/&gt;The ambitious research plan consists of three key components. The PI and her team will develop robust methods for providing individual users with the ability to see a visually faithful, dynamically rendered 3D representation of their own body while they are physically moving about within an HMD-based IVR, along with a quantitative assessment of the impact of alternative embodiment methodologies on the accuracy of peoples' spatial perception judgments in the virtual environment.  The team will also develop robust methods for providing multiple users with the ability to see each other while being co-located in a wide-area, HMD-based IVR, along with a qualitative assessment of best-practice representational approaches for supporting effective interpersonal communication and simultaneous accurate spatial understanding when multiple users are immersed as a group in a shared virtual environment.  Finally, the team will create a system for populating a designed environment with realistically behaving and interactively responsive autonomous virtual agents, along with qualitative and quantitative testing of the impact on spatial perception and functional suitability judgments from experiencing dynamically populated, as opposed to static or unpopulated, immersive virtual environments, plus related efforts that will assess the subjective and objective realism of the agents' dynamic behavior.</AbstractNarration>
<MinAmdLetterDate>08/24/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526693</AwardID>
<Investigator>
<FirstName>Lee</FirstName>
<LastName>Anderson</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lee B Anderson</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>6126245201</PI_PHON>
<NSF_ID>000379719</NSF_ID>
<StartDate>08/24/2015</StartDate>
<EndDate>06/24/2019</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Victoria</FirstName>
<LastName>Interrante</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Victoria L Interrante</PI_FULL_NAME>
<EmailAddress>interran@cs.umn.edu</EmailAddress>
<PI_PHON>6126253543</PI_PHON>
<NSF_ID>000160817</NSF_ID>
<StartDate>08/24/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stephen</FirstName>
<LastName>Guy</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stephen J Guy</PI_FULL_NAME>
<EmailAddress>sjguy@cs.umn.edu</EmailAddress>
<PI_PHON>6126245599</PI_PHON>
<NSF_ID>000637127</NSF_ID>
<StartDate>08/24/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554550255</ZipCode>
<StreetAddress><![CDATA[117 Pleasant St. SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~499410</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In the USA, people spend a large part of every day indoors, in spaces designed by architects.&nbsp; In order to ensure that what a space feels like from the inside is given as much or more consideration, during all stages of the design process, as what a building will look like from the outside, architects and their clients need access to tools that support an accurate <em>experiential</em> appreciation of design alternatives. &nbsp;This project encompassed a wide range of research efforts aimed at supporting that goal through the use of immersive virtual environments (VR) technology.</p> <p>Our research began by investigating the extent to which, and conditions under which, people are able to make accurate judgments about sizes and distances when immersed in virtual building models, encompassing factors like: how the available level of detail affects spatial judgments in VR; how one's impression of an interior space in VR is affected by presence of other (virtual) people in that space; and how the subjective sense of spaciousness that an interior affords can be affected by different surface treatment options and/or by the exterior views that are available through its windows. &nbsp;Our experiments found that visual realism may be less important than experiential realism for enabling accurate spatial perception in VR, that egocentric spatial judgments do not seem to be affected by the presence or absence of other people in a virtual environment, that a windowless room will feel smaller and less spacious when its walls are decorated with a bolder wallpaper pattern than with a finer one, and that people's judgments about the metric features of an interior space do not seem to be affected by the type of exterior view afforded by a single window in that space.</p> <p>In addition, our research explored the development and use of multiple alternative technologies for enabling people to see themselves and others while immersed in VR, with the aims of improving the quality of the immersive VR experience and better supporting productive collaborative discussion and successful negotiation between multiple stakeholders in the context of mutual immersion within a shared virtual building model.&nbsp; In the case of self-embodiment, our research found equivalent fundamental potential in the use of dynamically tracked, custom-scanned 3D self-body models as in the ability to see a perspectively-correct stereo view of one's own body reconstructed from streaming color+depth camera images; in the context of interaction with others, we found a significant preference for the streaming 3D video modality, which was also associated with higher levels of inter-personal trust and co-presence.</p> <p>Finally, our research also led to the development of improved, data-driven computational models of how individual people move through interior spaces, for instance while shopping, and how groups of people move in relation to each other and as parts of a crowd while navigating through densely-occupied spaces, both of which can support the realistic, evidence-based introduction of virtual humans into virtual architectural models to facilitate the understanding of how these designed spaces will feel when they are built and occupied and how different design alternatives for hallways and other open spaces might influence the flow of pedestrian traffic through a building.</p><br> <p>            Last Modified: 06/10/2021<br>      Modified by: Victoria&nbsp;L&nbsp;Interrante</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623373978710_sahar--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623373978710_sahar--rgov-800width.jpg" title="Comparing collaborative interaction under three different VR embodiment type conditions"><img src="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623373978710_sahar--rgov-66x44.jpg" alt="Comparing collaborative interaction under three different VR embodiment type conditions"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our research compared multiple measures of communication effectiveness between three different embodiment conditions, applied to oneself and to one's conversational partner: a minimal representation (left), a dynamically-animated scanned 3D body model (middle), a real time 3D video stream (right).</div> <div class="imageCredit">Sahar Aseeri</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Victoria&nbsp;L&nbsp;Interrante</div> <div class="imageTitle">Comparing collaborative interaction under three different VR embodiment type conditions</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623372534020_koorosh--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623372534020_koorosh--rgov-800width.jpg" title="Investigating spatial perception accuracy under conditions of high and low visual realism"><img src="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623372534020_koorosh--rgov-66x44.jpg" alt="Investigating spatial perception accuracy under conditions of high and low visual realism"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image shows how we used a custom-built video-see-through visor in conjunction with a backpack worn computer to compare the accuracy with which people could judge distances to targets under reduced-cue viewing conditions. These pictures show an outdoor environment; interior spaces were also used</div> <div class="imageCredit">Koorosh Vaziri</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Victoria&nbsp;L&nbsp;Interrante</div> <div class="imageTitle">Investigating spatial perception accuracy under conditions of high and low visual realism</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623374088284_frobt-06-00044-g009--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623374088284_frobt-06-00044-g009--rgov-800width.jpg" title="Three differently-sized virtual humans in the same 3D virtual model of a hallway environment"><img src="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623374088284_frobt-06-00044-g009--rgov-66x44.jpg" alt="Three differently-sized virtual humans in the same 3D virtual model of a hallway environment"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This image illustrates some of our investigations into how the introduction of virtual human entourage elements might affect people�s perception of egocentric distances within interior spaces in an immersive virtual environment.</div> <div class="imageCredit">Sahar Aseeri</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Victoria&nbsp;L&nbsp;Interrante</div> <div class="imageTitle">Three differently-sized virtual humans in the same 3D virtual model of a hallway environment</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623374644249_wallpaper--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623374644249_wallpaper--rgov-800width.jpg" title="Four different scales of the same wallpaper pattern applied to same-sized rooms"><img src="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623374644249_wallpaper--rgov-66x44.jpg" alt="Four different scales of the same wallpaper pattern applied to same-sized rooms"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our research found that people perceived rooms to feel increasingly less spacious, and also to be objectively smaller, as a bolder wallpaper pattern was applied.  This image shows four differently-sized wallpaper patterns applied to the same-sized room in VR.</div> <div class="imageCredit">Governess Simpson, Ariadne Sinnis-Bourozikas and Megan Zhao</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Victoria&nbsp;L&nbsp;Interrante</div> <div class="imageTitle">Four different scales of the same wallpaper pattern applied to same-sized rooms</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623375685270_windows--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623375685270_windows--rgov-800width.jpg" title="Six different virtual exterior views from the same-sized window"><img src="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623375685270_windows--rgov-66x44.jpg" alt="Six different virtual exterior views from the same-sized window"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Current systems support building design in a void, yet research shows that window size, shape, and placement preferences are more strongly affected by the view that a window affords than by any other factor. Our research looked at how people�s sense of spaciousness in a room is affected by the view</div> <div class="imageCredit">Megan Zhao and Ariadne Sinnis-Bourozikas</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Victoria&nbsp;L&nbsp;Interrante</div> <div class="imageTitle">Six different virtual exterior views from the same-sized window</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623376736004_zhihang--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623376736004_zhihang--rgov-800width.jpg" title="Using a visual/haptic cue conflict paradigm to compare the inherent perceived naturalness of two different technical methods for self-embodiment in VR"><img src="/por/images/Reports/POR/2021/1526693/1526693_10390878_1623376736004_zhihang--rgov-66x44.jpg" alt="Using a visual/haptic cue conflict paradigm to compare the inherent perceived naturalness of two different technical methods for self-embodiment in VR"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our research explored two different methods for enabling people to see themselves in VR: (a) a dynamically-tracked 3D scanned model of their own body; (b) correctly re-projected, live-streamed 3D video. This image illustrates how we used a visual/haptic cue conflict paradigm to compare their impact</div> <div class="imageCredit">Zhihang Deng</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Victoria&nbsp;L&nbsp;Interrante</div> <div class="imageTitle">Using a visual/haptic cue conflict paradigm to compare the inherent perceived naturalness of two different technical methods for self-embodiment in VR</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In the USA, people spend a large part of every day indoors, in spaces designed by architects.  In order to ensure that what a space feels like from the inside is given as much or more consideration, during all stages of the design process, as what a building will look like from the outside, architects and their clients need access to tools that support an accurate experiential appreciation of design alternatives.  This project encompassed a wide range of research efforts aimed at supporting that goal through the use of immersive virtual environments (VR) technology.  Our research began by investigating the extent to which, and conditions under which, people are able to make accurate judgments about sizes and distances when immersed in virtual building models, encompassing factors like: how the available level of detail affects spatial judgments in VR; how one's impression of an interior space in VR is affected by presence of other (virtual) people in that space; and how the subjective sense of spaciousness that an interior affords can be affected by different surface treatment options and/or by the exterior views that are available through its windows.  Our experiments found that visual realism may be less important than experiential realism for enabling accurate spatial perception in VR, that egocentric spatial judgments do not seem to be affected by the presence or absence of other people in a virtual environment, that a windowless room will feel smaller and less spacious when its walls are decorated with a bolder wallpaper pattern than with a finer one, and that people's judgments about the metric features of an interior space do not seem to be affected by the type of exterior view afforded by a single window in that space.  In addition, our research explored the development and use of multiple alternative technologies for enabling people to see themselves and others while immersed in VR, with the aims of improving the quality of the immersive VR experience and better supporting productive collaborative discussion and successful negotiation between multiple stakeholders in the context of mutual immersion within a shared virtual building model.  In the case of self-embodiment, our research found equivalent fundamental potential in the use of dynamically tracked, custom-scanned 3D self-body models as in the ability to see a perspectively-correct stereo view of one's own body reconstructed from streaming color+depth camera images; in the context of interaction with others, we found a significant preference for the streaming 3D video modality, which was also associated with higher levels of inter-personal trust and co-presence.  Finally, our research also led to the development of improved, data-driven computational models of how individual people move through interior spaces, for instance while shopping, and how groups of people move in relation to each other and as parts of a crowd while navigating through densely-occupied spaces, both of which can support the realistic, evidence-based introduction of virtual humans into virtual architectural models to facilitate the understanding of how these designed spaces will feel when they are built and occupied and how different design alternatives for hallways and other open spaces might influence the flow of pedestrian traffic through a building.       Last Modified: 06/10/2021       Submitted by: Victoria L Interrante]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
