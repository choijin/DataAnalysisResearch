<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Supporting Crowdsourced Sensemaking in Big Data with Dynamic Context Slices</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2015</AwardEffectiveDate>
<AwardExpirationDate>12/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>532000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research will investigate how crowdsourcing and computational techniques can be combined to support the efforts of an individual analyst engaged in a complex sensemaking task, such as identifying a threat to national security or determining the names of people and places in a photograph. Currently, such complex tasks are beyond the capabilities of the most advanced machine learning techniques or crowdsourcing workflows, and even trained experts struggle to perform them.  Huge quantities of data are now available online, but making sense of them is challenging because human cognition, while remarkably powerful, is nevertheless a limited resource. Visual analytics tools seek to overcome this limitation by leveraging the complementary strengths of information visualization and data mining, but these tools generally assist with low-level tasks, requiring significant effort on the part of users. Crowdsourcing has emerged as a promising technique for applying human intelligence to problems computers cannot easily solve, but for crowds to assist individuals with complex sensemaking tasks, two significant challenges must be addressed. First, we must understand when crowds versus computation are more useful at each phase in the sensemaking loop. Second, we must overcome the limited time and expertise of most crowd workers to sustain deep, complex lines of inquiry.&lt;br/&gt;&lt;br/&gt;This research addresses both of these challenges through a series of four experiments. First, it will conduct a laboratory study where individuals perform complex sensemaking tasks to understand what types and amounts of context they use to make decisions, and how the sensemaking loop might be decomposed into subtasks. Second, it will conduct a series of experiments comparing crowdsourcing to automated techniques for each of the most promising sensemaking subtasks. Third, it will experiment with different crowd workflows to develop a revised sensemaking loop, optimized for the relative strengths of crowds and computation, and develop a software prototype based on this approach. At the core of the software design is the novel concept of "context slices," an innovative technique for addressing the transience of crowd workers by giving them only the information they need to complete their assigned task, allowing complex investigations to be pursued across multiple workers. The fourth experiment will evaluate this approach by comparing performance with the software to the baselines established in the first study.</AbstractNarration>
<MinAmdLetterDate>09/09/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/17/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1527453</AwardID>
<Investigator>
<FirstName>Christopher</FirstName>
<LastName>North</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christopher L North</PI_FULL_NAME>
<EmailAddress>north@cs.vt.edu</EmailAddress>
<PI_PHON>5402312458</PI_PHON>
<NSF_ID>000194960</NSF_ID>
<StartDate>09/09/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kurt</FirstName>
<LastName>Luther</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kurt Luther</PI_FULL_NAME>
<EmailAddress>kluther@vt.edu</EmailAddress>
<PI_PHON>5402315281</PI_PHON>
<NSF_ID>000689719</NSF_ID>
<StartDate>09/09/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Polytechnic Institute and State University</Name>
<CityName>BLACKSBURG</CityName>
<ZipCode>240610001</ZipCode>
<PhoneNumber>5402315281</PhoneNumber>
<StreetAddress>Sponsored Programs 0170</StreetAddress>
<StreetAddress2><![CDATA[300 Turner Street NW, Suite 4200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003137015</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VIRGINIA POLYTECHNIC INSTITUTE AND STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003137015</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Virginia Polytechnic Institute and State University]]></Name>
<CityName/>
<StateCode>VA</StateCode>
<ZipCode>240600916</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~165603</FUND_OBLG>
<FUND_OBLG>2016~163789</FUND_OBLG>
<FUND_OBLG>2017~170608</FUND_OBLG>
<FUND_OBLG>2018~16000</FUND_OBLG>
<FUND_OBLG>2019~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p dir="ltr"><span>Challenges:</span></p> <p dir="ltr"><span>The goal of this project is to investigate how crowdsourcing and computational techniques can be combined to support the efforts of an individual analyst engaged in a complex sensemaking task, such as identifying a threat to national security or determining the names of people and places in a photograph. Currently, such complex tasks are beyond the capabilities of the most advanced machine learning techniques or crowdsourcing workflows, and even trained experts struggle to perform them. Crowdsourcing has emerged as a promising technique for applying human intelligence to problems computers cannot easily solve, but for crowds to assist individuals with complex sensemaking tasks, two significant challenges must be addressed. First, we must understand when crowds versus computation are more useful at each phase in the sensemaking loop. Second, we must overcome the limited time and expertise of most crowd workers to sustain deep, complex lines of inquiry.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Solutions:</span></p> <p dir="ltr"><span>To overcome these challenges, we studied current practices for sensemaking tasks, developed new sensemaking software tools to combine crowds and computational techniques, and evaluated the resulting usage. Our novel approach is the concept of "context slices," an innovative technique for addressing the transience of crowd workers by giving them only the information they need to complete their assigned task, allowing complex investigations to be pursued across multiple workers.</span></p> <p dir="ltr"><span>We demonstrated the ?context slices? concept in two major software tools, each focusing on a different problem domain. The CrowdIA system used context slices to support an analyst solving a mystery, such as a homicide or terrorist plot, by piecing together evidence across dozens of evidence documents. The GroundTruth system used context slices to support an investigator in searching large areas of satellite imagery to identify the precise geographic location where a photo or video was created.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Intellectual merit:</span></p> <p dir="ltr"><span>In terms of intellectual merits, this project made the following novel contributions. First, we generated a rich description of emergent sensemaking behaviors and cognitive processes across multiple domains (e.g., solving mysteries in textual evidence, geolocating photos and videos), focused on how people use context to make decisions. Second, we developed the concept of context slices and a modularized pipeline that leverages context slices to allow novice crowd workers to perform microtasks that contribute to complex sensemaking. Third, we demonstrated the benefits of the context slices approach through the creation of two software systems, CrowdIA and GroundTruth, across the diverse domains of text-based mystery solving and image geolocation, respectively. Fourth, we conducted robust empirical evaluations of both systems with real users and realistic datasets, showing that the software enabled crowds to contribute substantively to complex sensemaking tasks. Fifth, we developed a typology of errors and bottlenecks in crowd sensemaking and identified a set of trade-offs in the amount of local context provided to crowd workers. The project produced 13 publications, one PhD dissertation, and one master?s thesis.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Broader impacts:</span></p> <p dir="ltr"><span>In terms of broader impacts, this project achieved several key objectives. The research findings were incorporated into best practices for designing crowdsourcing workflows taught in undergraduate and graduate courses at our institution. This research also contributed to the establishment of a new academic workshop on human computation for image and video analysis. Software developed for the project was demonstrated at public outreach events as well as training workshops for professional analysts. Finally, the project involved a diverse group of students in the research process, including six graduate students in STEM fields (four female) and 12 undergraduate students (five female).</span></p><br> <p>            Last Modified: 03/31/2020<br>      Modified by: Kurt&nbsp;Luther</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662358484_ScreenShot2020-03-31at9.44.48AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662358484_ScreenShot2020-03-31at9.44.48AM--rgov-800width.jpg" title="Modularized sensemaking pipeline (Overview)"><img src="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662358484_ScreenShot2020-03-31at9.44.48AM--rgov-66x44.jpg" alt="Modularized sensemaking pipeline (Overview)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Step 1 searches external data sources for relevant documents. Step 2 extracts important information pieces from the relevant documents. Step 3 organizes information pieces into profile schemas. Step 4 compares and merges schemas to develop hypotheses. Step 5 synthesizes the best hypotheses.</div> <div class="imageCredit">Tianyi Li</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kurt&nbsp;Luther</div> <div class="imageTitle">Modularized sensemaking pipeline (Overview)</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662411968_ScreenShot2020-03-31at9.46.05AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662411968_ScreenShot2020-03-31at9.46.05AM--rgov-800width.jpg" title="Step 1: Search and Filter"><img src="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662411968_ScreenShot2020-03-31at9.46.05AM--rgov-66x44.jpg" alt="Step 1: Search and Filter"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Crowds independently rate document relevance from 0 (completely irrelevant)to 100 (completely relevant). Using a predefined threshold, each relevance rating is converted to a binaryvote. Documents with the majority vote will be passed to Step 2.</div> <div class="imageCredit">Tianyi Li</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kurt&nbsp;Luther</div> <div class="imageTitle">Step 1: Search and Filter</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662552788_ScreenShot2020-03-31at9.46.58AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662552788_ScreenShot2020-03-31at9.46.58AM--rgov-800width.jpg" title="Step 2: Read and Extract"><img src="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662552788_ScreenShot2020-03-31at9.46.58AM--rgov-66x44.jpg" alt="Step 2: Read and Extract"></a> <div class="imageCaptionContainer"> <div class="imageCaption">CrowdIA groups documents with overlapping entities into context slices of size n = 2 (A). Crowd workers extract information pieces from context slices (B). Information pieces are then regrouped by their source documents into new context slices (C). Crowds review information pieces (D).</div> <div class="imageCredit">Tianyi Li</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kurt&nbsp;Luther</div> <div class="imageTitle">Step 2: Read and Extract</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662591178_ScreenShot2020-03-31at9.49.17AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662591178_ScreenShot2020-03-31at9.49.17AM--rgov-800width.jpg" title="Step 3: Schematize"><img src="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662591178_ScreenShot2020-03-31at9.49.17AM--rgov-66x44.jpg" alt="Step 3: Schematize"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Crowds identify potential target locations and tag the information pieces withknown elements. Information pieces are tagged with tags that earned the crowd�s majority vote and organizedinto profiles of the candidate targets.</div> <div class="imageCredit">Tianyi Li</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kurt&nbsp;Luther</div> <div class="imageTitle">Step 3: Schematize</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662630548_ScreenShot2020-03-31at9.50.01AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662630548_ScreenShot2020-03-31at9.50.01AM--rgov-800width.jpg" title="Step 4: Build Case"><img src="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662630548_ScreenShot2020-03-31at9.50.01AM--rgov-66x44.jpg" alt="Step 4: Build Case"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Crowds compare candidate profiles and merge aliases. As in a single-eliminationcompetition, workers in Step 4 rank candidates by their perceived likelihood of being the target location.</div> <div class="imageCredit">Tianyi Li</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kurt&nbsp;Luther</div> <div class="imageTitle">Step 4: Build Case</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662679467_ScreenShot2020-03-31at9.50.50AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662679467_ScreenShot2020-03-31at9.50.50AM--rgov-800width.jpg" title="Step 5: Tell Story"><img src="/por/images/Reports/POR/2020/1527453/1527453_10397003_1585662679467_ScreenShot2020-03-31at9.50.50AM--rgov-66x44.jpg" alt="Step 5: Tell Story"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Crowds put together the information in the winning profile and write a completenarrative. The presentation is ready when no new revisions are made.</div> <div class="imageCredit">Tianyi Li</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Kurt&nbsp;Luther</div> <div class="imageTitle">Step 5: Tell Story</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Challenges: The goal of this project is to investigate how crowdsourcing and computational techniques can be combined to support the efforts of an individual analyst engaged in a complex sensemaking task, such as identifying a threat to national security or determining the names of people and places in a photograph. Currently, such complex tasks are beyond the capabilities of the most advanced machine learning techniques or crowdsourcing workflows, and even trained experts struggle to perform them. Crowdsourcing has emerged as a promising technique for applying human intelligence to problems computers cannot easily solve, but for crowds to assist individuals with complex sensemaking tasks, two significant challenges must be addressed. First, we must understand when crowds versus computation are more useful at each phase in the sensemaking loop. Second, we must overcome the limited time and expertise of most crowd workers to sustain deep, complex lines of inquiry.     Solutions: To overcome these challenges, we studied current practices for sensemaking tasks, developed new sensemaking software tools to combine crowds and computational techniques, and evaluated the resulting usage. Our novel approach is the concept of "context slices," an innovative technique for addressing the transience of crowd workers by giving them only the information they need to complete their assigned task, allowing complex investigations to be pursued across multiple workers. We demonstrated the ?context slices? concept in two major software tools, each focusing on a different problem domain. The CrowdIA system used context slices to support an analyst solving a mystery, such as a homicide or terrorist plot, by piecing together evidence across dozens of evidence documents. The GroundTruth system used context slices to support an investigator in searching large areas of satellite imagery to identify the precise geographic location where a photo or video was created.     Intellectual merit: In terms of intellectual merits, this project made the following novel contributions. First, we generated a rich description of emergent sensemaking behaviors and cognitive processes across multiple domains (e.g., solving mysteries in textual evidence, geolocating photos and videos), focused on how people use context to make decisions. Second, we developed the concept of context slices and a modularized pipeline that leverages context slices to allow novice crowd workers to perform microtasks that contribute to complex sensemaking. Third, we demonstrated the benefits of the context slices approach through the creation of two software systems, CrowdIA and GroundTruth, across the diverse domains of text-based mystery solving and image geolocation, respectively. Fourth, we conducted robust empirical evaluations of both systems with real users and realistic datasets, showing that the software enabled crowds to contribute substantively to complex sensemaking tasks. Fifth, we developed a typology of errors and bottlenecks in crowd sensemaking and identified a set of trade-offs in the amount of local context provided to crowd workers. The project produced 13 publications, one PhD dissertation, and one master?s thesis.    Broader impacts: In terms of broader impacts, this project achieved several key objectives. The research findings were incorporated into best practices for designing crowdsourcing workflows taught in undergraduate and graduate courses at our institution. This research also contributed to the establishment of a new academic workshop on human computation for image and video analysis. Software developed for the project was demonstrated at public outreach events as well as training workshops for professional analysts. Finally, the project involved a diverse group of students in the research process, including six graduate students in STEM fields (four female) and 12 undergraduate students (five female).       Last Modified: 03/31/2020       Submitted by: Kurt Luther]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
