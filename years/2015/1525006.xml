<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Collaborative Research: Unified Feedback Control and Mechanical Design for Robotic, Prosthetic, and Exoskeleton Locomotion</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>300022.00</AwardTotalIntnAmount>
<AwardAmount>300022</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>There is a pressing need for wearable robots, e.g., prostheses and exoskeletons, which improve the quality of life for individuals with limited mobility - devices that work symbiotically with human users to achieve stable, safe and efficient locomotion.  At present, approximately 4.7 million people in the United States would benefit from an active lower-limb exoskeleton due to the effects of stroke, polio, multiple sclerosis, spinal cord injury, and cerebral palsy, and by 2050 an estimated 1.5 million people in the United States will be living with a major lower-limb amputation.  Yet current wearable robotic devices do not address this growing population's needs since they are bulky, heavy, noisy, and require large batteries for even short duration use, while implementing predominately hierarchical control algorithms.  Impeding innovation in this domain is the expensive and slow traditional design-build-test approach that ignores the tight coupling between hardware specifications and control algorithm performance.  The vision of this work is to provide a methodology---inspired by advancements in robotic locomotion---that allows lower-limb prostheses and exoskeletons to meet real-world requirements through the co-design of the electromechanical and feedback systems.  The transformative nature of this work, therefore, stems from its ability to realize wearable robots that synergize with humans to achieve increased mobility, providing a template for the growing robotic assistive device industry and potentially improving the quality of life of millions.  &lt;br/&gt;&lt;br/&gt;To realize the vision of this work, the overarching research goal is to create a new unified control and design framework that will allow for the efficient and stable locomotion of robots, prostheses, and exoskeletons.  A key aspect of this control methodology is the ability to continuously mediate between different objectives enforcing stability and safety in an efficient manner through force-based interactions among (wearable) robotic devices, their environment and the user. The resulting framework will be utilized via control-in-the-loop mechanical design of prostheses and exoskeletons with stringent design requirements, tested experimentally on a novel humanoid robot, and clinically evaluated through human subject trials.  This work is, therefore, guided by the following specific goals:  (1) develop a unified online optimization-based control framework for (wearable) robotic locomotion that efficiently mediates stability, safety and force constraints, (2) create a feedback loop between formal control synthesis and the mechanical design of wearable robots that satisfy stringent performance requirements,  (3) accelerate clinical testing by translating controllers formally and experimentally from bipedal humanoid robots to prostheses and exoskeletons.  As a result of these research goals, this work has the potential to create the next generation of robotic systems that enable stable, safe and efficient human mobility.</AbstractNarration>
<MinAmdLetterDate>08/31/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1525006</AwardID>
<Investigator>
<FirstName>Jessy</FirstName>
<LastName>Grizzle</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jessy W Grizzle</PI_FULL_NAME>
<EmailAddress>grizzle@umich.edu</EmailAddress>
<PI_PHON>7347633598</PI_PHON>
<NSF_ID>000396941</NSF_ID>
<StartDate>08/31/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481092122</ZipCode>
<StreetAddress><![CDATA[1301 Beal Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>092E</Code>
<Text>Control systems &amp; applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~300022</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In terms of Intellectual Merit, the major finding of the project was a unified approach to robotic systems and robotic assistive (wearable) devices.&nbsp; In particular, we enhanced the control system designs for humanoid robots (even under safety-critical constraints), and translated the resulting gait generation technology and control infrastructure to prostheses and exoskeletons.&nbsp; These results were at the theoretic front as reported in multiple publications and at the experimental level in which the concepts were implemented on a bipedal robots, a custom-built lower-limb prosthesis, and a full-body exoskeleton that allows a paraplegic person to walk without the use of crutches or any external device.&nbsp; This combination of theoretical and experimental results on platforms raging from walking robots, to prosthetic devices to exoskeletons is unprecedented and highlights the benefits of NSF funding projects that encourage the collaboration of PIs in multiple universities (in this case, Michigan, Caltech, and Berkeley) and&nbsp; with industry (in this case, the startup Wandercraft). There were many cross-university engagements for the graduate students and there were internship positions with the company involved.</p> <p>Publications from the project have been made open source via the PIs? personal websites and through placing papers on the arXiv. In addition, software developed for a Cassie bipedal robot has been released as open-source on GitHub. Video of the work have been curated and placed in the public domain on YouTube. Finally, the PIs has numerous media interventions where they explained the importance of the work being done:</p> <p><a href="https://www.wired.com/story/the-lab-making-robots-walk-through-fire-and-ride-segways/">https://www.wired.com/story/the-lab-making-robots-walk-through-fire-and-ride-segways/</a></p> <p><a href="https://phys.org/news/2017-10-michigan-expert-bird-like-robot-paces.html">https://phys.org/news/2017-10-michigan-expert-bird-like-robot-paces.html</a></p> <p><a href="https://news.engin.umich.edu/2017/09/getting-people-moving-walking-exoskeletons-could-mobilize-disabled-patients/">https://news.engin.umich.edu/2017/09/getting-people-moving-walking-exoskeletons-could-mobilize-disabled-patients/</a></p> <p><a href="https://www.biped.solutions/post/at-the-state-capitol-on-tuesday-government-officials-got-to-meet-cassie-blue">https://www.biped.solutions/post/at-the-state-capitol-on-tuesday-government-officials-got-to-meet-cassie-blue</a></p> <p><a href="https://www.wired.com/story/the-punishing-polar-vortex-is-ideal-for-cassie-the-robot/">https://www.wired.com/story/the-punishing-polar-vortex-is-ideal-for-cassie-the-robot/</a></p> <p>&nbsp;</p> <p>Broader Impacts</p> <p>By collaborating with a startup (with which the PIs have no financial interest), the PIs?&nbsp; graduate students had access to world-leading hardware for their dissertation work. This led to publications with the company that highlighted the value of fundamental research to products that help society.&nbsp; Indeed, by collaborating with the company, the NSF researchers sped up the transfer of fundamental work to society. Indeed, exoskeletons with control laws (in part) based on the work have already been placed in Rehabilitation Centers. To be clear, all of their results, including those shared with the company, have been published in the public domain and made available on open-source platforms. The company was not given any privileged information. In fact, the company shared vital information with the NSF researchers that allowed them to better target their research questions.&nbsp;</p><br> <p>            Last Modified: 09/30/2019<br>      Modified by: Jessy&nbsp;W&nbsp;Grizzle</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850109435_Picture2--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850109435_Picture2--rgov-800width.jpg" title="Cassie Blue walking on various terrains (sand)"><img src="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850109435_Picture2--rgov-66x44.jpg" alt="Cassie Blue walking on various terrains (sand)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The narrow feet sunk into the sand, with the ?heel? digging in  the most. Because the stance  foot  is  passive, the robot?s gait remained quite  stable. The  robot  walked  more  slowly than on grass (possibly due to foot slip) and it traversed the entire course, passing under the (volleyball) net</div> <div class="imageCredit">Jessy Grizzle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jessy&nbsp;W&nbsp;Grizzle</div> <div class="imageTitle">Cassie Blue walking on various terrains (sand)</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850170898_Picture1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850170898_Picture1--rgov-800width.jpg" title="The Lab making Robots Walk Through Fire and Ride Segways"><img src="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850170898_Picture1--rgov-66x44.jpg" alt="The Lab making Robots Walk Through Fire and Ride Segways"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Cassie Blue, one of Michigan?s Cassie-series robots designed by Agility Robotics. The robot is shown here participating in a controlled burn.It has 20 degrees of freedom, 10 actuators, joint encoders, and an IMU. The robot?s serial number is 001.</div> <div class="imageCredit">Jessy Grizzle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jessy&nbsp;W&nbsp;Grizzle</div> <div class="imageTitle">The Lab making Robots Walk Through Fire and Ride Segways</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850366750_Picture3--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850366750_Picture3--rgov-800width.jpg" title="Bipedal Robot Cassie Blue Hones Her Segway Riding Skills"><img src="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850366750_Picture3--rgov-66x44.jpg" alt="Bipedal Robot Cassie Blue Hones Her Segway Riding Skills"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Cassie Blue is controlling the motion of the Segway by body lean, just as a human rider would do. To turn, she leans into the middle bar of the Segway with her "shin".</div> <div class="imageCredit">Jessy Grizzle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jessy&nbsp;W&nbsp;Grizzle</div> <div class="imageTitle">Bipedal Robot Cassie Blue Hones Her Segway Riding Skills</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850588596_Picture4--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850588596_Picture4--rgov-800width.jpg" title="Prof. Jessy Grizzle's team developed algorithms for walking motions for Wandercraft's Version 3 exoskeleton, shown above. They were excited by the challenge and opportunity of working on the just-finished Version 4 exoskeleton when they arrived in Paris."><img src="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569850588596_Picture4--rgov-66x44.jpg" alt="Prof. Jessy Grizzle's team developed algorithms for walking motions for Wandercraft's Version 3 exoskeleton, shown above. They were excited by the challenge and opportunity of working on the just-finished Version 4 exoskeleton when they arrived in Paris."></a> <div class="imageCaptionContainer"> <div class="imageCaption">Prof. Jessy Grizzle has long said that his work in robotics could one day be used to help the disabled. Now he and his group, alongside French company Wandercraft, are working to make that claim a reality in the form of walking exoskeletons</div> <div class="imageCredit">Jessy Grizzle</div> <div class="imageSubmitted">Jessy&nbsp;W&nbsp;Grizzle</div> <div class="imageTitle">Prof. Jessy Grizzle's team developed algorithms for walking motions for Wandercraft's Version 3 exoskeleton, shown above. They were excited by the challenge and opportunity of working on the just-finished Version 4 exoskeleton when they arrived in Paris.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569851046775_Picture5--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569851046775_Picture5--rgov-800width.jpg" title="Prof. Jessy Grizzle, Ayonga Hereid, Margaret Eva Mungai wearing a V-3 exoskeleton, and Omar Harib"><img src="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569851046775_Picture5--rgov-66x44.jpg" alt="Prof. Jessy Grizzle, Ayonga Hereid, Margaret Eva Mungai wearing a V-3 exoskeleton, and Omar Harib"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Prof. Jessy Grizzle has long said that his work in robotics could one day be used to help the disabled. Now he and his group, alongside French company Wandercraft, are working to make that claim a reality in the form of walking exoskeletons.</div> <div class="imageCredit">Jessy Grizzle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jessy&nbsp;W&nbsp;Grizzle</div> <div class="imageTitle">Prof. Jessy Grizzle, Ayonga Hereid, Margaret Eva Mungai wearing a V-3 exoskeleton, and Omar Harib</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569851152430_Picture6--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569851152430_Picture6--rgov-800width.jpg" title="The punishing Polar Vortex is ideal for Cassie the Robot"><img src="/por/images/Reports/POR/2019/1525006/1525006_10393640_1569851152430_Picture6--rgov-66x44.jpg" alt="The punishing Polar Vortex is ideal for Cassie the Robot"></a> <div class="imageCaptionContainer"> <div class="imageCaption">While humans suffer, a trunkless pair of ostrich-like legs is braving the frozen grounds of the University of Michigan, for the good of science.</div> <div class="imageCredit">Jessy Grizzle</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jessy&nbsp;W&nbsp;Grizzle</div> <div class="imageTitle">The punishing Polar Vortex is ideal for Cassie the Robot</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In terms of Intellectual Merit, the major finding of the project was a unified approach to robotic systems and robotic assistive (wearable) devices.  In particular, we enhanced the control system designs for humanoid robots (even under safety-critical constraints), and translated the resulting gait generation technology and control infrastructure to prostheses and exoskeletons.  These results were at the theoretic front as reported in multiple publications and at the experimental level in which the concepts were implemented on a bipedal robots, a custom-built lower-limb prosthesis, and a full-body exoskeleton that allows a paraplegic person to walk without the use of crutches or any external device.  This combination of theoretical and experimental results on platforms raging from walking robots, to prosthetic devices to exoskeletons is unprecedented and highlights the benefits of NSF funding projects that encourage the collaboration of PIs in multiple universities (in this case, Michigan, Caltech, and Berkeley) and  with industry (in this case, the startup Wandercraft). There were many cross-university engagements for the graduate students and there were internship positions with the company involved.  Publications from the project have been made open source via the PIs? personal websites and through placing papers on the arXiv. In addition, software developed for a Cassie bipedal robot has been released as open-source on GitHub. Video of the work have been curated and placed in the public domain on YouTube. Finally, the PIs has numerous media interventions where they explained the importance of the work being done:  https://www.wired.com/story/the-lab-making-robots-walk-through-fire-and-ride-segways/  https://phys.org/news/2017-10-michigan-expert-bird-like-robot-paces.html  https://news.engin.umich.edu/2017/09/getting-people-moving-walking-exoskeletons-could-mobilize-disabled-patients/  https://www.biped.solutions/post/at-the-state-capitol-on-tuesday-government-officials-got-to-meet-cassie-blue  https://www.wired.com/story/the-punishing-polar-vortex-is-ideal-for-cassie-the-robot/     Broader Impacts  By collaborating with a startup (with which the PIs have no financial interest), the PIs?  graduate students had access to world-leading hardware for their dissertation work. This led to publications with the company that highlighted the value of fundamental research to products that help society.  Indeed, by collaborating with the company, the NSF researchers sped up the transfer of fundamental work to society. Indeed, exoskeletons with control laws (in part) based on the work have already been placed in Rehabilitation Centers. To be clear, all of their results, including those shared with the company, have been published in the public domain and made available on open-source platforms. The company was not given any privileged information. In fact, the company shared vital information with the NSF researchers that allowed them to better target their research questions.        Last Modified: 09/30/2019       Submitted by: Jessy W Grizzle]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
