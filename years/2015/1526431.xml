<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Adaptive Integration of Textual and Geospatial Information for Mining Massive Map Collections</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>297859.00</AwardTotalIntnAmount>
<AwardAmount>297859</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Libraries and archives are digitizing historical maps for widespread online access. Without technology for searching them, large map collections relevant to a given problem or question may remain obscure even in online archives. If all of the text in a map can be read automatically by computer, a wealth of information becomes quickly available -- location names, geographic features, and often statistics. This project will increase capacity for search and analysis of historical maps by automatically recognizing place names and other text in these digitized artifacts while simultaneously aligning them with modern geography. The improvements this project will make to current text recognition methods will facilitate more powerful uses of humanity's trove of old maps -- for example, by allowing scientists and policymakers to establish changes in land usage, waterways, or borders over time. By creating free, open-source tools for studying historical maps, this project will increase public engagement with science and technology and empower any Internet user to explore the intersection of technology and history. This research will train a diverse group of graduate and undergraduate students in constructing, learning, and making predictions with adaptive models featuring heterogeneous yet highly interdependent entities.&lt;br/&gt;&lt;br/&gt;Although many institutions are digitizing hundreds of thousands of historical maps, most digitized map images are poorly annotated, limiting their usefulness. Manual annotation and metadata association is highly laborious. This project's primary objectives are (1) to fully automate text and shape-based georeferencing (aligning map images to the known global geography) while (2) indexing words and place names (for search) by enhancing text detection and recognition methods in these complex artifacts. These innovations will address the shortcomings of manual georeferencing and current automated text recognition algorithms. The researchers will employ an iterative interpretation process for solving problems including text/graphics separation, text recognition, and georeferencing. For example, the fact that all members of a given class of text entities on a map (e.g., county names) are typically rendered in the same text style can be used to inform predictions about difficult members of the category with information derived from more easily-recognized members. The researchers will use a dataset of annotated maps containing over 12,000 words in 9,000 place names as benchmark data for testing the algorithms developed in the project. Software, data, and benchmarks will be broadly distributed on the project website (http://www.cs.grinnell.edu/~weinman/research/maps.shtml). Findings will be shared with the research community through journals and conferences in the computer vision, artificial intelligence, and GIS communities.</AbstractNarration>
<MinAmdLetterDate>08/18/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526431</AwardID>
<Investigator>
<FirstName>Erik</FirstName>
<LastName>Learned-Miller</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Erik Learned-Miller</PI_FULL_NAME>
<EmailAddress>elm@cs.umass.edu</EmailAddress>
<PI_PHON>4135452746</PI_PHON>
<NSF_ID>000342665</NSF_ID>
<StartDate>08/18/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039242</ZipCode>
<StreetAddress><![CDATA[70 Butterfield Terrace]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~297859</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p><span>The recognition of text in historical maps is a sub-area in document recognition that is receiving increased attention</span><span>, both because it has important practical applications and because it presents certain technical challenges that require new models and methods. In particular, traditional text recognition methods, including standard optical character recognition (OCR) systems, and more specialized systems such as scene-text recognition systems, simply do not work well in this domain. </span></p> <p><span>Text in maps is characterized by certain hallmarks that make it particu</span>larly challenging (see Figure "The challenges of text recognition in maps") including words at extreme orientations, often over an angle span of more than 180 degrees (yellow box); large and variable spacings between letters (green box); confusing distractors, such as a large numbers of lines and junctions that are easily confused with characters (blue box); overlapping strings and curved baselines (red boxes). While traditional text recognition systems may partially deal with some of these issues, the confluence of them can cause traditional methods to break down.</p> </div> </div> </div> <div class="page" title="Page 2"> <div class="layoutArea"> <div class="column"> <p><span>Computer-based word recognition systems usually have separate com- ponents for detecting where words are (before recognizing them), breaking the words into characters (known as segmentation), and recognition of characters. Many systems are built so that an error in one stage cannot be correctly in a later stage. </span></p> <p>Our work under this grant was about trying to get all of the elements of a map recognition system to "cooperate" to achieve the final goal. For example, it is much easier to recognize words correctly when you know what the reasonable possibilities are. What does this have to do with maps? Well, if you can recognize one word on a map, you may be able to figure out your approximate geographic location. If I see the word "Kentucky", then I can look in a geographic database to see what other words are likely to occur near Kentucky such as other state names (Ohio, Indiana, etc.) or parts of Kentucky (Louisville, Ohio River, etc.). Thus, by first determining the approximate location of a map, and using this to produce a lexicon of possible place names, we can dramatically improve the accuracy with which we read words on maps.&nbsp;</p> <p>Another idea is that if we know that "Indiana" is a possible word to find on a map, and our initial word recognizer finds "ndiana", it seems likely that we have missed the "I" at the beginning of the word. Using the feedback mechanisms we developed in this grant, we can go back to the image and lower our threshold of detection for the "I" to see if we can find it on a second pass, knowing that it is likely to be there.</p> <p>We describe these types of outcomes in the 2019 technical report associated with this grant. A diagram of our system is shown in the second figure. While more work is required to turn these ideas into commercially useful products, we made good headway in exploring these ideas in this work.</p> </div> </div> </div><br> <p>            Last Modified: 12/03/2019<br>      Modified by: Erik&nbsp;Learned-Miller</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1526431/1526431_10388948_1575391646684_difficulties--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526431/1526431_10388948_1575391646684_difficulties--rgov-800width.jpg" title="The challenges of text recognition in maps"><img src="/por/images/Reports/POR/2019/1526431/1526431_10388948_1575391646684_difficulties--rgov-66x44.jpg" alt="The challenges of text recognition in maps"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Text recognition in maps comes with extreme challenges such as wide letter spacing (green box), overlapping words (red boxes), unusual word orientations (yellow box) and dense distractors (blue box).</div> <div class="imageCredit">Archan Ray</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Erik&nbsp;Learned-Miller</div> <div class="imageTitle">The challenges of text recognition in maps</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526431/1526431_10388948_1575392598302_SystemDiagram--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526431/1526431_10388948_1575392598302_SystemDiagram--rgov-800width.jpg" title="System Diagram"><img src="/por/images/Reports/POR/2019/1526431/1526431_10388948_1575392598302_SystemDiagram--rgov-66x44.jpg" alt="System Diagram"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Flowchart of map word detection</div> <div class="imageCredit">Archan Ray</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Erik&nbsp;Learned-Miller</div> <div class="imageTitle">System Diagram</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    The recognition of text in historical maps is a sub-area in document recognition that is receiving increased attention, both because it has important practical applications and because it presents certain technical challenges that require new models and methods. In particular, traditional text recognition methods, including standard optical character recognition (OCR) systems, and more specialized systems such as scene-text recognition systems, simply do not work well in this domain.   Text in maps is characterized by certain hallmarks that make it particularly challenging (see Figure "The challenges of text recognition in maps") including words at extreme orientations, often over an angle span of more than 180 degrees (yellow box); large and variable spacings between letters (green box); confusing distractors, such as a large numbers of lines and junctions that are easily confused with characters (blue box); overlapping strings and curved baselines (red boxes). While traditional text recognition systems may partially deal with some of these issues, the confluence of them can cause traditional methods to break down.        Computer-based word recognition systems usually have separate com- ponents for detecting where words are (before recognizing them), breaking the words into characters (known as segmentation), and recognition of characters. Many systems are built so that an error in one stage cannot be correctly in a later stage.   Our work under this grant was about trying to get all of the elements of a map recognition system to "cooperate" to achieve the final goal. For example, it is much easier to recognize words correctly when you know what the reasonable possibilities are. What does this have to do with maps? Well, if you can recognize one word on a map, you may be able to figure out your approximate geographic location. If I see the word "Kentucky", then I can look in a geographic database to see what other words are likely to occur near Kentucky such as other state names (Ohio, Indiana, etc.) or parts of Kentucky (Louisville, Ohio River, etc.). Thus, by first determining the approximate location of a map, and using this to produce a lexicon of possible place names, we can dramatically improve the accuracy with which we read words on maps.   Another idea is that if we know that "Indiana" is a possible word to find on a map, and our initial word recognizer finds "ndiana", it seems likely that we have missed the "I" at the beginning of the word. Using the feedback mechanisms we developed in this grant, we can go back to the image and lower our threshold of detection for the "I" to see if we can find it on a second pass, knowing that it is likely to be there.  We describe these types of outcomes in the 2019 technical report associated with this grant. A diagram of our system is shown in the second figure. While more work is required to turn these ideas into commercially useful products, we made good headway in exploring these ideas in this work.          Last Modified: 12/03/2019       Submitted by: Erik Learned-Miller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
