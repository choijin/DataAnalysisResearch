<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Comp Cog:  Collaborative Research on the Development of Visual Object Recognition</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>405158.00</AwardTotalIntnAmount>
<AwardAmount>405158</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Chalandra Bryant</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Human visual object recognition is fast and robust.  People can recognize a large number of visual objects in complex scenes, from varied views, and in less than optimal circumstances.  This ability underlies many advanced human skills, including tool use, reading, and navigation.  Artificial intelligence devices do not yet approach the level of skill of everyday human object recognition. This project will address one gap in current knowledge, an understanding of the visual experiences that allow skilled object recognition to develop, by capturing and analyzing the visual experiences of 1- to 2-year-old toddlers.  This is a key period for understanding human visual object recognition because it is the time when toddlers learn a large number of object categories, when they learn the names for those objects, and when they instrumentally act on and use objects as tools.  Two-year-old children, unlike computer vision systems, rapidly learn to recognize many visual objects.  This project seeks to understand how the training experiences (everyday object viewing) of toddlers may be optimal for building robust visual object recognition. The project aims to (1) understand the visual and statistical regularities in 1- to 2-year-old children's experiences of common objects (e.g., cups, chairs, trucks, dogs) and (2) determine whether a training regimen like that experienced by human toddlers supports visual object recognition by state-of-the art machine vision. &lt;br/&gt;&lt;br/&gt;Considerable progress in understanding adult vision has been made by studying the visual statistics of "natural scenes." However, there is concern about possible artifacts in these scenes because they typically photographs taken by adults and thus potentially biased by the already developed mature visual system that holds the camera and frames the pictures. Also, photographed scenes differ systematically from the scenes sampled by people as they move about and act in the world.  Accordingly, there is increased interest in egocentric views collected from body-worn cameras, the method used in the present work.  Toddlers will wear lightweight head cameras as they go about their daily activities, allowing the investigators to capture the objects the toddlers see and the perspectives and contexts in which they see them.  The research will analyze the frequency, views, visual properties, and range of seen objects for the first 100 object names normatively learned by young children, providing a first description of the early learning environment for human visual object recognition.  These toddler-perspective scenes  will be used as inputs to machine learning models to better understand how the visual information in the scenes supports and constrains the development of visual object recognition. Machine-learning experiments will determine which properties and statistical regularities are most critical for learning to recognize common object categories in multiple scene contexts.  Data collected will be shared through Databrary, an open data library for developmental science.</AbstractNarration>
<MinAmdLetterDate>07/21/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/02/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1523982</AwardID>
<Investigator>
<FirstName>Linda</FirstName>
<LastName>Smith</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Linda B Smith</PI_FULL_NAME>
<EmailAddress>smith4@indiana.edu</EmailAddress>
<PI_PHON>8128558256</PI_PHON>
<NSF_ID>000085967</NSF_ID>
<StartDate>07/21/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Chen</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chen Yu</PI_FULL_NAME>
<EmailAddress>chenyu@indiana.edu</EmailAddress>
<PI_PHON>8128560838</PI_PHON>
<NSF_ID>000175165</NSF_ID>
<StartDate>07/21/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474057007</ZipCode>
<StreetAddress><![CDATA[1101 E 10th St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~169339</FUND_OBLG>
<FUND_OBLG>2016~235819</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The development of visual object recognition is not well understood although it is central to many other developmental achievements, including object name learning and tool use.&nbsp; All the evidence suggests that young children are highly skilled in</span><span> </span><span>the</span><span> </span><span>ability</span><span> </span><span>to</span><span> </span><span>learn</span><span> </span><span>and</span><span> </span><span>recognize</span><span> </span><span>instances</span><span> </span><span>of</span><span> </span><span>many</span><span> </span><span>categories,</span><span> </span><span>better</span><span> </span><span>than</span><span> </span><span>the</span><span> </span><span>most</span><span> </span><span>advanced</span><span> </span><span>machine</span><span> </span><span>learning approaches to visual object recognition. Here we studied the idea that the <strong>statistics of infant and toddlers&rsquo; everyday visual object experiences </strong>hold the key to this emerging prowess and the answer to the question of why visual category recognition seems easy&nbsp; for&nbsp; children&nbsp; hard&nbsp; for&nbsp; theorists&nbsp; to&nbsp; explain,&nbsp; and&nbsp; hard&nbsp; for&nbsp; machine&nbsp; vision&nbsp; to&nbsp; achieve&nbsp; in&nbsp; a&nbsp; human-like&nbsp; </span><span>way.&nbsp; The research had two components:&nbsp; (1) Collecting and analyzing the infant&nbsp; and toddler visual environments collected by infants and toddlers as they went about their daily lives.&nbsp; (2) Studying the implications of these regularities for machine learning algorithms.&nbsp; The research shows that the properties and statistical structure of infant visual experiences is different in multiple ways from those used in current image recognition learning, from those assumed to optimal for all learning, including extensive visual&nbsp; experience with relatively few objects instances of each category including many visual poor images (dark, blurry, partially occluded.&nbsp; Yet from these early experiences toddlers become one-shot learners of novel categories.&nbsp; The research also show that training images with these properties&nbsp; and drawn from infant visual experiences offer significant advantages over standard training in machine visions. In sum, the research </span><span>used vision science and computer vision algorithms (frequency, contrast, texture, etc.) to (1) quantify regularities in the images; (2) train state-of-the-art convolutional neural networks&nbsp; with child head-camera images to understand the how properties and regularities in infant visual experience interact with well-understood and current state-of-the art machine learning<strong>;</strong> and<strong> </strong>(3) identify novel approaches to to structuring training sets for rapid learning. exploit these regularities to deliver one-shot recognition. The<strong> Intellectual merit </strong>of the work lies in the collection and annotation of a large corpus of head-camera video of toddlers in the home, to specify the natural statistics of visual object experiences and the properties that support rapid learning of visual categories. The <strong>Broader impacts </strong>include the collaboration across human and machine learning .&nbsp; Further,<strong> </strong>multiple under-represented students were vertically integrated into the research. The data have been shared with 3 research groups interested in optic flow, natural statistics of face experiences, and the role of visual experiences in developing mental rotation.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 08/01/2018<br>      Modified by: Linda&nbsp;B&nbsp;Smith</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The development of visual object recognition is not well understood although it is central to many other developmental achievements, including object name learning and tool use.  All the evidence suggests that young children are highly skilled in the ability to learn and recognize instances of many categories, better than the most advanced machine learning approaches to visual object recognition. Here we studied the idea that the statistics of infant and toddlers? everyday visual object experiences hold the key to this emerging prowess and the answer to the question of why visual category recognition seems easy  for  children  hard  for  theorists  to  explain,  and  hard  for  machine  vision  to  achieve  in  a  human-like  way.  The research had two components:  (1) Collecting and analyzing the infant  and toddler visual environments collected by infants and toddlers as they went about their daily lives.  (2) Studying the implications of these regularities for machine learning algorithms.  The research shows that the properties and statistical structure of infant visual experiences is different in multiple ways from those used in current image recognition learning, from those assumed to optimal for all learning, including extensive visual  experience with relatively few objects instances of each category including many visual poor images (dark, blurry, partially occluded.  Yet from these early experiences toddlers become one-shot learners of novel categories.  The research also show that training images with these properties  and drawn from infant visual experiences offer significant advantages over standard training in machine visions. In sum, the research used vision science and computer vision algorithms (frequency, contrast, texture, etc.) to (1) quantify regularities in the images; (2) train state-of-the-art convolutional neural networks  with child head-camera images to understand the how properties and regularities in infant visual experience interact with well-understood and current state-of-the art machine learning; and (3) identify novel approaches to to structuring training sets for rapid learning. exploit these regularities to deliver one-shot recognition. The Intellectual merit of the work lies in the collection and annotation of a large corpus of head-camera video of toddlers in the home, to specify the natural statistics of visual object experiences and the properties that support rapid learning of visual categories. The Broader impacts include the collaboration across human and machine learning .  Further, multiple under-represented students were vertically integrated into the research. The data have been shared with 3 research groups interested in optic flow, natural statistics of face experiences, and the role of visual experiences in developing mental rotation.          Last Modified: 08/01/2018       Submitted by: Linda B Smith]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
