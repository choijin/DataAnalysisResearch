<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: A Novel P300 Brain-Computer Interface</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2015</AwardEffectiveDate>
<AwardExpirationDate>09/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>499556.00</AwardTotalIntnAmount>
<AwardAmount>504431</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Brain computer interfaces (BCIs) translate basic mental commands into computer-mediated actions, thereby allowing the user to bypass the peripheral motor system and interact with the world directly via brain activity.  These systems are being developed to aid users with motor deficits stemming from neurodegenerative disease, injury, or even environmental restrictions which make movement difficult or impossible.  One of the most successful classes of EEG-driven BCI systems is the P300, which works by detecting user responses to flashed stimuli.  In most P300 systems, a grid of letters and/or other symbols is presented and rows or columns of the symbols are flashed in random order; the user attends to the desired symbol (usually by silently counting when it flashes).  A major problem with these grid-based P300 systems is that the user must ideally look at the flashed target and minimally attend to the tiny letters, but late-stage ALS and other locked-in patients for whom these systems are most needed have trouble foveating targets and making controlled eye movements.  The PI's hypothesis is that a BCI that flashes segments of one large letter can retain the combinatorial efficiency that comes with querying several letters at once, while having the advantage of one central focus (no gaze shifts required).  This research aims to design and test this new segment speller idea.  Project outcomes have the potential to vastly improve the usability of P300 EEG-based BCI systems for those with visual, sensory and motor impairments.  All software written for EEG signal processing and analysis will be made available as add-ons to EEGLAB which is distributed by the Swartz Center for Computational Neuroscience (SCCN) at UCSD and part of the Temporal Dynamics of Learning Center.  Data will also be made available through the HeadIT data archive that is also run by the SCCN.&lt;br/&gt;&lt;br/&gt;This research task can be broken down into three main objectives: develop and test the response to flashed segments; improve the single-trial classification of the responses to flashed segments; and design a logic for selecting segments and interpreting their responses.  The developed system will provide another method for BCI speller control that does not depend on the ability to shift gaze.  The PI argues that this method will have a higher information transfer rate than other space invariant BCI spellers due to being able to probe multiple letters at once.  Besides being advantageous for those with impaired eye movements and/or impaired vision, the method should have other advantages over the standard P300 systems.  When errors are made, they will tend to be to visually similar symbols. Incorporating language priors and active segment selection is easily accommodated, and this may result in higher information transfer rates with slower flash rates.  In addition the work on improving recognition of single-trial temporal EEG signals and incorporating Bayesian language models into spellers could be useful for other types of brain-computer interfaces.</AbstractNarration>
<MinAmdLetterDate>08/27/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/23/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1528214</AwardID>
<Investigator>
<FirstName>Virginia</FirstName>
<LastName>de Sa</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Virginia de Sa</PI_FULL_NAME>
<EmailAddress>vdesa@cogsci.ucsd.edu</EmailAddress>
<PI_PHON>8588225095</PI_PHON>
<NSF_ID>000169194</NSF_ID>
<StartDate>08/27/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>920930515</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~168069</FUND_OBLG>
<FUND_OBLG>2016~172264</FUND_OBLG>
<FUND_OBLG>2017~159223</FUND_OBLG>
<FUND_OBLG>2021~4875</FUND_OBLG>
</Award>
</rootTag>
