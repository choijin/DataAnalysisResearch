<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Artificial Characterization of Objects Relating to Human Tactile Perception</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>11/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>711871.00</AwardTotalIntnAmount>
<AwardAmount>1113517</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this project is to provide a new standard of quantifying touch for industries currently relying on qualitative data from expert sensory panels (the tactile equivalent of professional wine tasters). Advancing the understanding of the role and function of tactile sensing in perception and manipulation is also essential if robots are to behave like humans. Studies have demonstrated that humans who cannot feel due to permanent disease or temporary anesthesia perform poorly in fine manipulation tasks (similar to even the best robotic systems without touch). The research proposed in this project is the next step to bring tactile sensing and sensory-motor intelligence to the next generation of robotics. The successful demonstration of a tactile sensor with perceptual similarity to the human fingertip would mark substantial progress in the field of telemanipulation, bringing the world one step closer to remote haptic perception. This Small Business Innovation Research (SBIR) Phase 2 project seeks to develop the world's first standard of human tactile perception. It has been proposed that tactile recognition presents a more difficult problem than vision and hearing, requiring not only intelligent sensory processing, but also intelligent algorithms to select and control movements, which have a tremendous influence on what is sensed. Artificial sensors that mimic the mechanical properties and sensitivity of the human fingertip have not existed until recently. The research proposed herein will test hypotheses that a biologically inspired robotic system can measure properties that correspond to subjective percepts, descriptors and associations that humans use to characterize objects by touch.</AbstractNarration>
<MinAmdLetterDate>09/11/2015</MinAmdLetterDate>
<MaxAmdLetterDate>11/10/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1534524</AwardID>
<Investigator>
<FirstName>Jeremy</FirstName>
<LastName>Fishel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeremy Fishel</PI_FULL_NAME>
<EmailAddress>jafishel@csuchico.edu</EmailAddress>
<PI_PHON>5308985320</PI_PHON>
<NSF_ID>000606414</NSF_ID>
<StartDate>09/11/2015</StartDate>
<EndDate>06/29/2018</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeremy</FirstName>
<LastName>Fishel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeremy Fishel</PI_FULL_NAME>
<EmailAddress>jafishel@csuchico.edu</EmailAddress>
<PI_PHON>5308985320</PI_PHON>
<NSF_ID>000606414</NSF_ID>
<StartDate>08/27/2018</StartDate>
<EndDate>09/09/2019</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rahman</FirstName>
<LastName>Davoodi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rahman Davoodi</PI_FULL_NAME>
<EmailAddress>Rahman.Davoodi@syntouchinc.com</EmailAddress>
<PI_PHON/>
<NSF_ID>000770251</NSF_ID>
<StartDate>06/29/2018</StartDate>
<EndDate>09/05/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Rahman</FirstName>
<LastName>Davoodi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rahman Davoodi</PI_FULL_NAME>
<EmailAddress>Rahman.Davoodi@syntouchinc.com</EmailAddress>
<PI_PHON/>
<NSF_ID>000770251</NSF_ID>
<StartDate>09/09/2019</StartDate>
<EndDate>09/09/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vijay</FirstName>
<LastName>Anandani</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vijay A Anandani</PI_FULL_NAME>
<EmailAddress>vijay.anandani@syntouchinc.com</EmailAddress>
<PI_PHON>2132626138</PI_PHON>
<NSF_ID>000806633</NSF_ID>
<StartDate>09/05/2019</StartDate>
<EndDate>09/09/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vijay</FirstName>
<LastName>Anandani</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vijay A Anandani</PI_FULL_NAME>
<EmailAddress>vijay.anandani@syntouchinc.com</EmailAddress>
<PI_PHON>2132626138</PI_PHON>
<NSF_ID>000806633</NSF_ID>
<StartDate>09/09/2019</StartDate>
<EndDate>11/10/2020</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Koffler</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard P Koffler</PI_FULL_NAME>
<EmailAddress>richard.koffler@syntouchinc.com</EmailAddress>
<PI_PHON>3108075786</PI_PHON>
<NSF_ID>000807626</NSF_ID>
<StartDate>11/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SynTouch LLC</Name>
<CityName>Montrose</CityName>
<ZipCode>910201516</ZipCode>
<PhoneNumber>3108075786</PhoneNumber>
<StreetAddress>3720 Clifton Place</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>28</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA28</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>827484929</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SYNTOUCH L.L.C.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117367572</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SynTouch LLC]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900076601</ZipCode>
<StreetAddress><![CDATA[2222 South Figueroa St Ph2]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>165E</Code>
<Text>SBIR Phase IIB</Text>
</ProgramReference>
<ProgramReference>
<Code>169E</Code>
<Text>SBIR Tech Enhan Partner (TECP)</Text>
</ProgramReference>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>8240</Code>
<Text>SBIR/STTR CAP</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~711871</FUND_OBLG>
<FUND_OBLG>2017~152171</FUND_OBLG>
<FUND_OBLG>2018~249475</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>The sense of touch is indispensable! Imagine life without skin sensation compared to not seeing, hearing, smelling, or tasting. </strong>Evolution made touch a powerful, persuasive non-verbal channel of communication. People often touch for the sake, pleasure, and fun of touching (e.g., to enjoy the texture of paper, silkiness of soft fabric, or luxuriousness of cashmere).</p> <p dir="ltr"><span><strong>The feel of a product powerfully influences consumers' decisions to sample or purchase. </strong>Touch triggers high emotional responses that significantly affect consumer's product perception, often subconsciously (e.g., perception of product value and amount willing to pay; a sense of product "ownership" and brand loyalty; and product attributes such as quality, warmth, safety, sustainability, and luxury).</span></p> <p dir="ltr"><span>A short list of product categories whose feel is important to consumers includes baby care, feminine hygiene, cosmetics, personal care, automotive interiors, plastics, glass, kitchenware, personal electronics, apparel, paper, furniture, paints, and coatings. These categories represent trillions of dollars in global annual revenue.</span></p> <p dir="ltr"><strong>Product manufacturers ask four essential touch-related questions: How should their products feel? How to design them to feel like that? How to manufacture them so they feel like that consistently? How to integrate product-feel information into marketing?</strong></p> <p dir="ltr"><span>Getting the right answers directly affects business issues like time and cost to market, competitiveness, and consumer acceptance.</span></p> <p dir="ltr">But getting answers is complex because they depend on many factors, not all related to touch. For example, tactile perception is influenced by more than the materials' properties (e.g., multi-sensory effects; individual differences like gender, age, culture, and "need to touch"; contact point on the body; and active vs passive touching.)</p> <p dir="ltr"><span>Manufacturers must also find the tradeoff between product feel and factors like product performance, cost, manufacturability, and sustainability. </span></p> <p dir="ltr"><span>Lastly, ensuring product feel requires alignment and a common "language of touch" across internal and external supply chains -- from product design and development to production, quality assurance, and marketing.</span></p> <p dir="ltr"><span><strong>This NSF SBIR grant funded SynTouch to develop novel hardware and software technologies to overcome the limited usefulness of current methods to assess product feel: tribology instruments and human fingers.</strong> </span></p> <p dir="ltr"><span>Tribology produces data that are too simplistic to describe the complexity of the sense of touch -- and therefore do not correlate to human perception and preference. Humans provide opinions about perception that are subjective, imprecise, and not easily replicable -- and therefore not very useful in objectively guiding product design and formulation. Just ask three people and get five imprecisely described opinions before they change their minds a day later. And human sensory panels are typically expensive and a big hassle, which makes them available only to large manufacturers with large budgets.</span></p> <p dir="ltr"><span><strong>The outcome of this grant is the SynTouch Toccare Haptics Measurement System, an instrument that scientifically, replicably, objectively, and accurately quantifies human tactile perception. </strong></span></p> <p dir="ltr"><span><strong>&nbsp;</strong>If a finger can feel it, the Toccare system can measure it. It is biomimetic in that it reproduces how human fingers sense, explore, and move. Its signal processing was inspired by human neural and cognitive systems.&nbsp;</span></p> <p dir="ltr"><span>The Toccare system produces the <strong>Toccare Haptics Profiles</strong>, which are 15-dimensional profiles that uniquely describe a material's haptics. The model was developed and validated with psychophysics research to ensure conformance with human tactile perception.&nbsp;</span></p> <p dir="ltr"><span>The endpoint of the grant is a unique, game-changing tool that provides a quick, inexpensive, reliable method to understand the feel of products and materials.&nbsp;</span></p> <p dir="ltr"><span>Since the launch of the Toccare system's first version in 2018, it has successfully helped over 100 companies across the world make objective decisions about the feel of their products.</span></p><br> <p>            Last Modified: 12/01/2020<br>      Modified by: Richard&nbsp;P&nbsp;Koffler</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848298697_Toccarepartialsystem-withsamples-3forNSFOutcomesreport--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848298697_Toccarepartialsystem-withsamples-3forNSFOutcomesreport--rgov-800width.jpg" title="SynTouch Toccare Haptics Measurement System"><img src="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848298697_Toccarepartialsystem-withsamples-3forNSFOutcomesreport--rgov-66x44.jpg" alt="SynTouch Toccare Haptics Measurement System"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Toccare Haptics Measurement System scientifically, replicably, objectively, and accurately quantifies human tactile perception. If a finger can feel it, the Toccare system can measure it.</div> <div class="imageCredit">SynTouch Inc.</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Richard&nbsp;P&nbsp;Koffler</div> <div class="imageTitle">SynTouch Toccare Haptics Measurement System</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848384848_Diagram-wipes3bubbles-diapersforNSFOutcomesreport--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848384848_Diagram-wipes3bubbles-diapersforNSFOutcomesreport--rgov-800width.jpg" title="Toccare Haptics Studies"><img src="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848384848_Diagram-wipes3bubbles-diapersforNSFOutcomesreport--rgov-66x44.jpg" alt="Toccare Haptics Studies"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Toccare Haptic Profiles scientifically guide decisions about product feel.</div> <div class="imageCredit">SynTouch Inc.</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Richard&nbsp;P&nbsp;Koffler</div> <div class="imageTitle">Toccare Haptics Studies</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848452286_spidercomparisonForNSFOutcomesreport--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848452286_spidercomparisonForNSFOutcomesreport--rgov-800width.jpg" title="Toccare Haptics Profiles"><img src="/por/images/Reports/POR/2020/1534524/1534524_10398350_1606848452286_spidercomparisonForNSFOutcomesreport--rgov-66x44.jpg" alt="Toccare Haptics Profiles"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Toccare Haptics Profiles are 15-dimensional profiles that uniquely describe a material's haptics. They were developed and validated with psychophysics research to ensure conformance with human tactile perception.</div> <div class="imageCredit">SynTouch Inc.</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Richard&nbsp;P&nbsp;Koffler</div> <div class="imageTitle">Toccare Haptics Profiles</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The sense of touch is indispensable! Imagine life without skin sensation compared to not seeing, hearing, smelling, or tasting. Evolution made touch a powerful, persuasive non-verbal channel of communication. People often touch for the sake, pleasure, and fun of touching (e.g., to enjoy the texture of paper, silkiness of soft fabric, or luxuriousness of cashmere). The feel of a product powerfully influences consumers' decisions to sample or purchase. Touch triggers high emotional responses that significantly affect consumer's product perception, often subconsciously (e.g., perception of product value and amount willing to pay; a sense of product "ownership" and brand loyalty; and product attributes such as quality, warmth, safety, sustainability, and luxury). A short list of product categories whose feel is important to consumers includes baby care, feminine hygiene, cosmetics, personal care, automotive interiors, plastics, glass, kitchenware, personal electronics, apparel, paper, furniture, paints, and coatings. These categories represent trillions of dollars in global annual revenue. Product manufacturers ask four essential touch-related questions: How should their products feel? How to design them to feel like that? How to manufacture them so they feel like that consistently? How to integrate product-feel information into marketing? Getting the right answers directly affects business issues like time and cost to market, competitiveness, and consumer acceptance. But getting answers is complex because they depend on many factors, not all related to touch. For example, tactile perception is influenced by more than the materials' properties (e.g., multi-sensory effects; individual differences like gender, age, culture, and "need to touch"; contact point on the body; and active vs passive touching.) Manufacturers must also find the tradeoff between product feel and factors like product performance, cost, manufacturability, and sustainability.  Lastly, ensuring product feel requires alignment and a common "language of touch" across internal and external supply chains -- from product design and development to production, quality assurance, and marketing. This NSF SBIR grant funded SynTouch to develop novel hardware and software technologies to overcome the limited usefulness of current methods to assess product feel: tribology instruments and human fingers.  Tribology produces data that are too simplistic to describe the complexity of the sense of touch -- and therefore do not correlate to human perception and preference. Humans provide opinions about perception that are subjective, imprecise, and not easily replicable -- and therefore not very useful in objectively guiding product design and formulation. Just ask three people and get five imprecisely described opinions before they change their minds a day later. And human sensory panels are typically expensive and a big hassle, which makes them available only to large manufacturers with large budgets. The outcome of this grant is the SynTouch Toccare Haptics Measurement System, an instrument that scientifically, replicably, objectively, and accurately quantifies human tactile perception.   If a finger can feel it, the Toccare system can measure it. It is biomimetic in that it reproduces how human fingers sense, explore, and move. Its signal processing was inspired by human neural and cognitive systems.  The Toccare system produces the Toccare Haptics Profiles, which are 15-dimensional profiles that uniquely describe a material's haptics. The model was developed and validated with psychophysics research to ensure conformance with human tactile perception.  The endpoint of the grant is a unique, game-changing tool that provides a quick, inexpensive, reliable method to understand the feel of products and materials.  Since the launch of the Toccare system's first version in 2018, it has successfully helped over 100 companies across the world make objective decisions about the feel of their products.       Last Modified: 12/01/2020       Submitted by: Richard P Koffler]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
