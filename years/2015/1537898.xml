<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Active Statistical Learning: Ensembles, Manifolds, and Optimal Experimental Design</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Georgia-Ann Klutke</SignBlockName>
<PO_EMAI>gaklutke@nsf.gov</PO_EMAI>
<PO_PHON>7032922443</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In numerous industries such as manufacturing, health care or energy production, current sensor technology can generate enormous quantities of measurements of an object at low cost. Each measurement consists of several instances of interrelated variables, and the goal is to use the data to build a computer model that permits one to predict the class of an object (such as the health condition of a patient or the quality of a manufactured part). Along with the sensor data, the class labels for some objects are needed to train the computer model. While the sensor variables can frequently be obtained rapidly and inexpensively (e.g., medical images or chemical analyses) the class label associated with each object might require human effort that is time-consuming and expensive. Therefore, care should be taken to select the objects to label that are most informative for building the predictive computer model. Often one selects objects iteratively, where the class labels from the previously selected batch guides the next batch of objects to label. This is the purpose of a so-called active learning strategy. The purpose of this research is to find new active learning methods that accelerate model building and provide better predictions in systems where large datasets of attribute measurements are available. This will result in more efficient and productive systems that will benefit the U.S. economy and society.&lt;br/&gt;&lt;br/&gt;Existing active learning methods are often based on strong assumptions for the joint input/output distribution or use a distance-based approach. These methods are susceptible to noise in the input space, assume numerical inputs only, and often work poorly in high dimensions. In applications, data sets are often large, noisy, contain missing values and mixed variable types. In this research, a non-parametric approach to the active learning problem is proposed to address these challenges. The algorithm is based on a batch diversification strategy applied to an ensemble of decision trees. A novel active learning strategy that considers the geometric structure of the manifold where the unlabeled data resides will also be considered. The geometric properties of the data space may result in more informative active learning solutions. This is a collaborative effort between Arizona State University, Pennsylvania State University, and Intel Corporation with complementary expertise in machine learning and optimal design. The participation of Intel will help ensure the successful dissemination and broad applicability of the results.</AbstractNarration>
<MinAmdLetterDate>08/07/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1537898</AwardID>
<Investigator>
<FirstName>George</FirstName>
<LastName>Runger</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>George C Runger</PI_FULL_NAME>
<EmailAddress>george.runger@asu.edu</EmailAddress>
<PI_PHON>4809653193</PI_PHON>
<NSF_ID>000202872</NSF_ID>
<StartDate>08/07/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Eugene</FirstName>
<LastName>Tuv</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>Eugene Tuv</PI_FULL_NAME>
<EmailAddress>eugene.tuv@intel.com</EmailAddress>
<PI_PHON>4805544069</PI_PHON>
<NSF_ID>000485163</NSF_ID>
<StartDate>08/07/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2><![CDATA[660 South Mill Avenue, Suite 310]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>Tempe</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852876011</ZipCode>
<StreetAddress><![CDATA[P O Box 876011]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>006Y</Code>
<Text>OE Operations Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>071E</Code>
<Text>MFG ENTERPRISE OPERATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>078E</Code>
<Text>ENTERPRISE DESIGN &amp; LOGISTICS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~175000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Data analytics can be used to learn empirical models from diverse data for better engineering decisions and scientific understandings. These data science tasks are based on collected data and although there can be a large repository of data, the outcomes related to these data might be more difficult or costly to obtain. For example, multiple images might be available, but it can be costly to associate labels of the content with each one. Active learning (AL) is a strategy to prioritize and select data instances to label in order to learn an empirical model efficiently and effectively. Most specifically, in many engineering and enterprise systems, automated sensing&nbsp;can generate an enormous number of measurements (such as manufacturing, health care, energy, environmental, etc.). A common objective is to predict a response variable y associated with multiple measurements, denoted as x. A collection of data pairs (x, y) is usually available to build a predictive relationship. Each pair is called an instance and y is called the label of the instance. Labeling may require effort that is time-consuming and expensive. An AL strategy sequentially selects instances to label so that a good model can be trained with a relatively small number of iterations.</p> <p>AL can be considered to be a newer approach that is related to the design and planning of experiments. The AL strategy is considered a robust approach, with few assumptions, that selects data instances from the collection available. Experimental design approaches provide more flexible choices for instances to label (instances to test), but are based on assumptions regarding the model to be learned. Both AL and experimental design are broadly applicable to numerous disciplines and applications in science and engineering. Both methods provide strong efficiencies to learn empirical models from data. This collaborative research project considered this important issue from both AL and experimental design perspectives. &nbsp;</p> <p>The Arizona State University researchers led the design of strategies&nbsp;to learn to classify instances (such as to assign an image to a specific class) for very large, noisy, heterogeneous data, to confront the challenges encountered in applications. This research team drew upon their earlier work that was the top performer at a previous AL Challenge. The research literature focused on measures to select instances based on the uncertainty of the instance in the current cycle of modeling. We provided a new uncertainty measure that used the full information in a machine learning model and showed its advantages in multiple experimental cases for complex data. This change also facilitated an extension from the binary (two class) to multi-class problems.</p> <p>Also, uncertainty methods tend to select instances for which the classifier?s assignment is less certain. However, this can lead to redundant instances in the selected pool. Consequently, we studied the effects of adding diversity and density measures to AL with uncertainty measures. Diversity measures limit the redundancy and density methods focus on instances where the instance distribution has high density (in order to discourage outlier selection). Our results were important because even with our improved measure for uncertainty, both diversity and density considerations were important additions for instance selection in AL. A robust measure of distance was the preferred choice and this fit well with the approach for complex data, and few assumptions. Robust clustering methods were used to group similar instances to study the breadth of instances while limiting redundancy of those selected. A number of research studies were conducted that compared a one-time clustering of instances to an improved algorithm that adjusted the clustering of unlabeled instance iteratively in each learning cycle of AL. This considered the distance of unlabeled instances at each iteration to avoid high density regions which were previously selected. Furthermore, we extended upon clustering and uncertainty methods and designed a new, generalized approach that, for each instance, computes a cluster margin (probability of cluster membership) and class margin (probability of label class). The advantage is that measures for uncertainty and density, which are important to AL, are integrated in a model with consistently. This provides a new direction for future AL researchers to leverage this type of construct that helps integrate measures coherently into a single strategy selection. Our experiments showed results better than our previous clustering and uncertainty methods.</p> <p>A number of PhD students at Arizona State University participated in this project (including two women). Their training included: (i) advanced machine learning methods for classification, (ii) advanced methods for active learning, (iii) knowledge of the relationship to experimental designs, (iv) scientific software development, (v) how to conduct research, and (vi) technical writing skills. All the students below have participated as coauthors in research papers and/or presentations associated with the project.</p><br> <p>            Last Modified: 01/29/2019<br>      Modified by: George&nbsp;C&nbsp;Runger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Data analytics can be used to learn empirical models from diverse data for better engineering decisions and scientific understandings. These data science tasks are based on collected data and although there can be a large repository of data, the outcomes related to these data might be more difficult or costly to obtain. For example, multiple images might be available, but it can be costly to associate labels of the content with each one. Active learning (AL) is a strategy to prioritize and select data instances to label in order to learn an empirical model efficiently and effectively. Most specifically, in many engineering and enterprise systems, automated sensing can generate an enormous number of measurements (such as manufacturing, health care, energy, environmental, etc.). A common objective is to predict a response variable y associated with multiple measurements, denoted as x. A collection of data pairs (x, y) is usually available to build a predictive relationship. Each pair is called an instance and y is called the label of the instance. Labeling may require effort that is time-consuming and expensive. An AL strategy sequentially selects instances to label so that a good model can be trained with a relatively small number of iterations.  AL can be considered to be a newer approach that is related to the design and planning of experiments. The AL strategy is considered a robust approach, with few assumptions, that selects data instances from the collection available. Experimental design approaches provide more flexible choices for instances to label (instances to test), but are based on assumptions regarding the model to be learned. Both AL and experimental design are broadly applicable to numerous disciplines and applications in science and engineering. Both methods provide strong efficiencies to learn empirical models from data. This collaborative research project considered this important issue from both AL and experimental design perspectives.    The Arizona State University researchers led the design of strategies to learn to classify instances (such as to assign an image to a specific class) for very large, noisy, heterogeneous data, to confront the challenges encountered in applications. This research team drew upon their earlier work that was the top performer at a previous AL Challenge. The research literature focused on measures to select instances based on the uncertainty of the instance in the current cycle of modeling. We provided a new uncertainty measure that used the full information in a machine learning model and showed its advantages in multiple experimental cases for complex data. This change also facilitated an extension from the binary (two class) to multi-class problems.  Also, uncertainty methods tend to select instances for which the classifier?s assignment is less certain. However, this can lead to redundant instances in the selected pool. Consequently, we studied the effects of adding diversity and density measures to AL with uncertainty measures. Diversity measures limit the redundancy and density methods focus on instances where the instance distribution has high density (in order to discourage outlier selection). Our results were important because even with our improved measure for uncertainty, both diversity and density considerations were important additions for instance selection in AL. A robust measure of distance was the preferred choice and this fit well with the approach for complex data, and few assumptions. Robust clustering methods were used to group similar instances to study the breadth of instances while limiting redundancy of those selected. A number of research studies were conducted that compared a one-time clustering of instances to an improved algorithm that adjusted the clustering of unlabeled instance iteratively in each learning cycle of AL. This considered the distance of unlabeled instances at each iteration to avoid high density regions which were previously selected. Furthermore, we extended upon clustering and uncertainty methods and designed a new, generalized approach that, for each instance, computes a cluster margin (probability of cluster membership) and class margin (probability of label class). The advantage is that measures for uncertainty and density, which are important to AL, are integrated in a model with consistently. This provides a new direction for future AL researchers to leverage this type of construct that helps integrate measures coherently into a single strategy selection. Our experiments showed results better than our previous clustering and uncertainty methods.  A number of PhD students at Arizona State University participated in this project (including two women). Their training included: (i) advanced machine learning methods for classification, (ii) advanced methods for active learning, (iii) knowledge of the relationship to experimental designs, (iv) scientific software development, (v) how to conduct research, and (vi) technical writing skills. All the students below have participated as coauthors in research papers and/or presentations associated with the project.       Last Modified: 01/29/2019       Submitted by: George C Runger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
