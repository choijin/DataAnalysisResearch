<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Solving the Problems of Scalability and Portability while Maximizing Performance of Multiprecision Scalar and Vector Arithmetic on Clusters of GPUs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project extends the PI's prior research into achieving high performance for multiprecision arithmetic utilizing commodity graphics processors (GPUs). Multiprecision (MP) arithmetic has important applications in science, engineering, and mathematics when computations require greater numerical precision than standard computer systems support. It is also an important part of cryptography used in secure internet communication. GPUs can accelerate MP arithmetic by more than two orders of magnitude. However, achieving this performance requires novel algorithms and software tools. The world-record performance for exponentiation achieved under the prior grant will be extended to include floating point vector arithmetic. A new code generation model will enable handling a wider range of precisions across newer generations of graphics processors. Support for clusters of GPUs to work together on larger problems, and practical demonstrations of the effectiveness of MP library such as showing how one GPU can offload decryption work from more than a hundred servers, with higher levels of security than are currently in common use, is being developed. &lt;br/&gt;&lt;br/&gt;Each generation of GPU architecture requires extensive experimentation and reworking of multiprecision code to obtain a new optimum. Yet the potential benefits of a portable and scalable package could be transformational in certain application areas. This effort extends PI's prior work to include floating point and vectors, and begin the transition to GPU clusters. The result will be a publicly available multi-precision arithmetic package and implementation toolset that enables the scientific community to easily take full advantage of GPU scaling to obtain at least an order of magnitude improvement in performance per dollar and performance per watt over CPUs at the same technology step. The approach relies on a novel set of models for GPU storage that provide a higher level of abstraction over which the code generation tools can search for optimal combinations of algorithm, register/memory layout, and kernel launch geometry for a given precision size and GPU architectural generation to achieve maximum resource utilization.</AbstractNarration>
<MinAmdLetterDate>07/01/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/01/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1525754</AwardID>
<Investigator>
<FirstName>Charles</FirstName>
<LastName>Weems</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Charles C Weems</PI_FULL_NAME>
<EmailAddress>weems@cs.umass.edu</EmailAddress>
<PI_PHON>4135453163</PI_PHON>
<NSF_ID>000434762</NSF_ID>
<StartDate>07/01/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039242</ZipCode>
<StreetAddress><![CDATA[70 Butterfield Terrace]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>When the work began, we had hand-optimized graphics processor (GPU) implementations of multiple-precision (MP) add, subtract, and multiply working efficiently on two generations of GPU. We subsequently developed a performance model of existing NVIDIA GPUs that enabled construction of an automatic optimization system for all existing GPU architectural generations, and used it for these operations as well as modular exponentiation.&nbsp;</span></p> <p><span>Developing that model enabled us to make a significant improvement to a key routine in an NVIDIA matrix processing library, which helped one student, Niall Emmart, get an internship at NVIDIA, working on their MP library project. Under nondisclosure, we gained further insight into optimizations for their GPUs which, combined with our expertise in MP arithmetic, enabled us to to show them how to obtain an additional factor of ten in performance over their original approach. Our work became a significant part of the core of their library, called MPX, which is now the standard GPU MP library. We also helped with implementation of a new, more flexible, version, MPX-2, which is in testing. MPX is publicly available, and achieved world-record performance levels on arithmetic from 256 to 4192 bits in length. The work received a best-in-conference paper award at the 2016 IEEE Symposium on Computer Arithmetic. Our work also resulted in improvements to the optimizations done by the NVIDIA compiler and influenced some modest changes to subsequent GPU architectures to better support MP arithmetic.&nbsp;</span></p> <p><span>The range of values supported by our optimizations and MPX was chosen because it is commonly employed in digital encryption systems. We showed that the performance on a single GPU (6.7M 256-bit modular exponentiations per second on a GTX-780Ti GPU) is sufficient to offload the cryptographic work corresponding to an entire rack of servers, which saves power. Combining many encryption operations into a parallel group also enhances security by hiding the timing of individual operations, which is a known means of enabling code cracking. Being able to accelerate encryption at larger key sizes also makes it more feasible for the internet to shift to higher levels of security without suffering a speed penalty.&nbsp;</span></p> <p><span>We also developed a new parallel algorithm for MP short division (division of an MP value by a constant) that we proved was theoretically optimal and established a new strict lower bound for the complexity of this operation. It is rare to do this for the well-trod ground of computer arithmetic. We also showed that the algorithm has practical applications on a wide range of parallel architectures.</span></p> <p><span>Working with Yang Chen at U. Macau, we developed an application to compute the least eigenvalues of a particular class of ill-formed Hankel matrices that have some use in theoretical physics. As the size of the matrices grows, the number of bits of precision needed to obtain a valid result can grow into the millions. Our work helped him to demonstrate a conjecture about the nature of the convergence of these eigenvalues.&nbsp;</span></p> <p><span>We developed a format for representing MP floating point numbers, and a library for the GPU that accelerates processing of arrays of these values. The library demonstrates a good performance improvement (5 to 20 times for the most common operators) over traditional multi-core processors, although there remains room for further optimization. We did not end up extending this to a cluster implementation as originally planned, in part because our relationship with NVIDA opened up opportunities for work with greater impact.&nbsp;</span></p> <p><span>Beyond the NVIDIA library, we developed optimized integer routines for addition, subtraction, and multiplication of MP values ranging from 384K bits to 16M bits, with a speed-up of 2X to 5X over multicore implementations.&nbsp;</span>&nbsp;</p> <p><span>Based on our reputation, we were contacted by Fangyu Zheng of the Chinese Academy of Sciences for help on a new MP implementation that uses the mantissa unit of the double-precision floating point unit (DPFP) of the GPU for acceleration. Recent NVIDIA architectures have moved to optimizing for shorter integers that are used in machine learning, so MP calculations based on their integer units have not kept pace with other speedups. However, they have also improved DPFP support significantly. The DPFP unit provides 52-bit operations in its mantissa unit. Prior work had used just 23 of those bits so that chains of multiplies in computing the modular exponent operation would not overflow. We developed an alternate representation that enabled the use of all 52 bits. Furthermore, the new approach operates in constant time (avoiding timing attacks), with high performance (50K 2048-bit RSA code operations per second) and has lower latency (19 ms).</span></p> <p><span>We also began exploring acceleration of post-quantum cryptographic systems using GPUs.&nbsp;</span></p> <p><span>The work resulted in three journal papers and six conference papers (one more in preparation). Besides Dr. Emmart's Ph.D., the effort helped train one female MS student, one female B.S. student, and one male B.S. student.&nbsp;</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 09/23/2019<br>      Modified by: Charles&nbsp;C&nbsp;Weems</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ When the work began, we had hand-optimized graphics processor (GPU) implementations of multiple-precision (MP) add, subtract, and multiply working efficiently on two generations of GPU. We subsequently developed a performance model of existing NVIDIA GPUs that enabled construction of an automatic optimization system for all existing GPU architectural generations, and used it for these operations as well as modular exponentiation.   Developing that model enabled us to make a significant improvement to a key routine in an NVIDIA matrix processing library, which helped one student, Niall Emmart, get an internship at NVIDIA, working on their MP library project. Under nondisclosure, we gained further insight into optimizations for their GPUs which, combined with our expertise in MP arithmetic, enabled us to to show them how to obtain an additional factor of ten in performance over their original approach. Our work became a significant part of the core of their library, called MPX, which is now the standard GPU MP library. We also helped with implementation of a new, more flexible, version, MPX-2, which is in testing. MPX is publicly available, and achieved world-record performance levels on arithmetic from 256 to 4192 bits in length. The work received a best-in-conference paper award at the 2016 IEEE Symposium on Computer Arithmetic. Our work also resulted in improvements to the optimizations done by the NVIDIA compiler and influenced some modest changes to subsequent GPU architectures to better support MP arithmetic.   The range of values supported by our optimizations and MPX was chosen because it is commonly employed in digital encryption systems. We showed that the performance on a single GPU (6.7M 256-bit modular exponentiations per second on a GTX-780Ti GPU) is sufficient to offload the cryptographic work corresponding to an entire rack of servers, which saves power. Combining many encryption operations into a parallel group also enhances security by hiding the timing of individual operations, which is a known means of enabling code cracking. Being able to accelerate encryption at larger key sizes also makes it more feasible for the internet to shift to higher levels of security without suffering a speed penalty.   We also developed a new parallel algorithm for MP short division (division of an MP value by a constant) that we proved was theoretically optimal and established a new strict lower bound for the complexity of this operation. It is rare to do this for the well-trod ground of computer arithmetic. We also showed that the algorithm has practical applications on a wide range of parallel architectures.  Working with Yang Chen at U. Macau, we developed an application to compute the least eigenvalues of a particular class of ill-formed Hankel matrices that have some use in theoretical physics. As the size of the matrices grows, the number of bits of precision needed to obtain a valid result can grow into the millions. Our work helped him to demonstrate a conjecture about the nature of the convergence of these eigenvalues.   We developed a format for representing MP floating point numbers, and a library for the GPU that accelerates processing of arrays of these values. The library demonstrates a good performance improvement (5 to 20 times for the most common operators) over traditional multi-core processors, although there remains room for further optimization. We did not end up extending this to a cluster implementation as originally planned, in part because our relationship with NVIDA opened up opportunities for work with greater impact.   Beyond the NVIDIA library, we developed optimized integer routines for addition, subtraction, and multiplication of MP values ranging from 384K bits to 16M bits, with a speed-up of 2X to 5X over multicore implementations.    Based on our reputation, we were contacted by Fangyu Zheng of the Chinese Academy of Sciences for help on a new MP implementation that uses the mantissa unit of the double-precision floating point unit (DPFP) of the GPU for acceleration. Recent NVIDIA architectures have moved to optimizing for shorter integers that are used in machine learning, so MP calculations based on their integer units have not kept pace with other speedups. However, they have also improved DPFP support significantly. The DPFP unit provides 52-bit operations in its mantissa unit. Prior work had used just 23 of those bits so that chains of multiplies in computing the modular exponent operation would not overflow. We developed an alternate representation that enabled the use of all 52 bits. Furthermore, the new approach operates in constant time (avoiding timing attacks), with high performance (50K 2048-bit RSA code operations per second) and has lower latency (19 ms).  We also began exploring acceleration of post-quantum cryptographic systems using GPUs.   The work resulted in three journal papers and six conference papers (one more in preparation). Besides Dr. Emmart's Ph.D., the effort helped train one female MS student, one female B.S. student, and one male B.S. student.           Last Modified: 09/23/2019       Submitted by: Charles C Weems]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
