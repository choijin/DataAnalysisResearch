<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Theory of threshold-linear networks and combinatorial neural codes.</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Junping Wang</SignBlockName>
<PO_EMAI>jwang@nsf.gov</PO_EMAI>
<PO_PHON>7032924488</PO_PHON>
</ProgramOfficer>
<AbstractNarration>How do connections between neurons store memories and shape the dynamics of neural activity in the brain?  How do firing patterns of neurons represent our sensory experiences?  The advent of technologies that facilitate simultaneous recordings of large populations of neurons present new opportunities to answer these classical questions of neuroscience.  There are mathematical models that are frequently used in network simulations and data analyses that can be employed, but whose mathematical properties are still poorly understood.  To guide these efforts, a better understanding of theoretical models of recurrent networks and population codes is essential.  This research will focus on two such examples: threshold-linear networks and combinatorial neural codes.  The goal is to produce major advances in the mathematical theory of these models, with an eye towards neuroscience applications.  Part of the research will involve the analyses of neural activity in the cortex and hippocampus, in collaboration with experimentalists.  Despite the focus on neuroscience, the mathematical results have the potential to be sufficiently general so as to be useful in a variety of broader contexts in the biological and social sciences.&lt;br/&gt;&lt;br/&gt;A threshold-linear network is a common firing rate model for a recurrent network, with a threshold nonlinearity. These networks generically exhibit multiple stable fixed points, and multistability makes them attractive as models for memory storage and retrieval.  Preliminary results have shown that the equilibria possess a rich combinatorial structure, and can be analyzed using ideas from classical distance geometry.  The first project will build on this understanding in order to develop a more complete picture of the structure of fixed points and higher-dimensional attractors of these networks.  A combinatorial neural code is a collection of binary patterns for a population of neurons.  The second project will develop an algebraic classification of combinatorial codes, using the recently developed framework of the neural ring.  The neural ring encodes information about a neural code in a manner that makes properties such as receptive field organization most transparent.  The resulting methods will be tested and refined using electrophysiological recordings of place cells in the hippocampus.  This research will also generate new and interesting problems at the interface of neuroscience with applied algebra, combinatorics, and geometry.</AbstractNarration>
<MinAmdLetterDate>08/07/2015</MinAmdLetterDate>
<MaxAmdLetterDate>01/04/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1516881</AwardID>
<Investigator>
<FirstName>Carina</FirstName>
<LastName>Curto</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Carina Curto</PI_FULL_NAME>
<EmailAddress>ccurto@psu.edu</EmailAddress>
<PI_PHON>8148639119</PI_PHON>
<NSF_ID>000522202</NSF_ID>
<StartDate>08/07/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1253</Code>
<Text>OFFICE OF MULTIDISCIPLINARY AC</Text>
</ProgramElement>
<ProgramElement>
<Code>7334</Code>
<Text>MATHEMATICAL BIOLOGY</Text>
</ProgramElement>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>There were two major outcomes of this award. First, we developed the mathematical theory of threshold-linear networks (TLNs). These recurrent networks have been used for decades in computational neuroscience to model various aspects of brain function. Our results focused on stable and unstable fixed points and the associated attractor dynamics. We discovered several ways in which the fixed point structure is determined by the architecture of the network, as reflected by a directed graph. In particular, we proved a variety of graph rules relating network structure to dynamics for a special class of TLNs, and characterized robust and flexible motifs in more general TLNs. The second development was a series of papers on the theory of combinatorial neural codes. Here we found new results on how to detect the organization of a neural code based on algebraic, topological, and combinatorial features. Collectively, these projects resulted in three book chapters and nine journal publications, including the selection below.</p> <div class="page" title="Page 2"><span style="font-size: 10.000000pt; font-family: 'Times';">C. Curto, K. Morrison. Pattern completion in symmetric threshold-linear networks. Neural Computation, Vol 28, pp. 28252852, 2016. </span></div> <div class="page" title="Page 2"><span style="font-size: 10.000000pt; font-family: 'Times';"><br /></span></div> <div class="page" title="Page 2"><span style="font-size: 10.000000pt; font-family: 'Times';"> <div class="page" title="Page 2"> <div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);"> <div class="layoutArea"> <div class="column"> <p><span style="font-size: 10.000000pt; font-family: 'Times';">C. Curto. What can topology tell us about the neural code? Bulletin of the AMS, vol. 54, no. 1, pp. 6378, 2017 </span></p> <div class="page" title="Page 2"> <div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);"> <div class="layoutArea"> <div class="column"> <p><span style="font-size: 10.000000pt; font-family: 'Times';">C. Curto, E. Gross, J. Jeffries, K. Morrison, M. Omar, Z. Rosen, A. Shiu, N. Youngs. What makes a neural code convex? SIAM J. Appl. Algebra and Geometry, vol. 1, pp. 222238, 2017. </span></p> <div class="page" title="Page 3"> <div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);"> <div class="layoutArea"> <div class="column"> <p><span style="font-size: 10.000000pt; font-family: 'Times';">K. Morrison, C. Curto. Predicting neural network dynamics via graphical analysis. Book chapter in Algebraic and Combinatorial Computational Biology. R. Robeva, M. Macaulay (Eds), 2018. </span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div class="column"> <div class="page" title="Page 2"> <div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);"> <div class="layoutArea"> <div class="column"> <p><span style="font-size: 10.000000pt; font-family: 'Times';">C. Curto, J. Geneson, K. Morrison. Fixed points of threshold-linear networks. Neural Computation, 2019. </span></p> <div class="page" title="Page 2"> <div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);"> <div class="layoutArea"> <div class="column"> <p><span style="font-size: 10.000000pt; font-family: 'Times';">C. Curto, E. Gross, J. Jeffries, K. Morrison, M. Omar, Z. Rosen, A. Shiu, N. Youngs. Algebraic signatures of convex and nonconvex codes. Journal of Pure and Applied Algebra, 2019. </span></p> <div class="page" title="Page 2"> <div class="section" style="background-color: rgb(100.000000%, 100.000000%, 100.000000%);"> <div class="layoutArea"> <div class="column"> <p><span style="font-size: 10.000000pt; font-family: 'Times';">C. Curto, K. Morrison. Relating network connectivity to dynamics: opportunities and challenges for theoretical neuroscience. Current Opinion in Neurobiology, 2019. </span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </span></div><br> <p>            Last Modified: 11/08/2019<br>      Modified by: Carina&nbsp;Curto</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ There were two major outcomes of this award. First, we developed the mathematical theory of threshold-linear networks (TLNs). These recurrent networks have been used for decades in computational neuroscience to model various aspects of brain function. Our results focused on stable and unstable fixed points and the associated attractor dynamics. We discovered several ways in which the fixed point structure is determined by the architecture of the network, as reflected by a directed graph. In particular, we proved a variety of graph rules relating network structure to dynamics for a special class of TLNs, and characterized robust and flexible motifs in more general TLNs. The second development was a series of papers on the theory of combinatorial neural codes. Here we found new results on how to detect the organization of a neural code based on algebraic, topological, and combinatorial features. Collectively, these projects resulted in three book chapters and nine journal publications, including the selection below. C. Curto, K. Morrison. Pattern completion in symmetric threshold-linear networks. Neural Computation, Vol 28, pp. 28252852, 2016.          C. Curto. What can topology tell us about the neural code? Bulletin of the AMS, vol. 54, no. 1, pp. 6378, 2017       C. Curto, E. Gross, J. Jeffries, K. Morrison, M. Omar, Z. Rosen, A. Shiu, N. Youngs. What makes a neural code convex? SIAM J. Appl. Algebra and Geometry, vol. 1, pp. 222238, 2017.       K. Morrison, C. Curto. Predicting neural network dynamics via graphical analysis. Book chapter in Algebraic and Combinatorial Computational Biology. R. Robeva, M. Macaulay (Eds), 2018.                 C. Curto, J. Geneson, K. Morrison. Fixed points of threshold-linear networks. Neural Computation, 2019.       C. Curto, E. Gross, J. Jeffries, K. Morrison, M. Omar, Z. Rosen, A. Shiu, N. Youngs. Algebraic signatures of convex and nonconvex codes. Journal of Pure and Applied Algebra, 2019.       C. Curto, K. Morrison. Relating network connectivity to dynamics: opportunities and challenges for theoretical neuroscience. Current Opinion in Neurobiology, 2019.                         Last Modified: 11/08/2019       Submitted by: Carina Curto]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
