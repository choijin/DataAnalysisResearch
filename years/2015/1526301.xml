<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Knowledge Representation and Reasoning under Uncertainty with Probabilistic Answer Set Programming</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>342795.00</AwardTotalIntnAmount>
<AwardAmount>342795</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
<PO_EMAI>jdonlon@nsf.gov</PO_EMAI>
<PO_PHON>7032928074</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Combining logic and probability is an important subject in Artificial Intelligence, and is recently being extensively studied in the area of statistical relational learning, where the main goal of representation is to express probabilistic models in a compact way that reflects the relational structure of the domain and ideally supports efficient learning and inference. However, in comparison with main knowledge representation languages, such languages do not allow natural, elaboration tolerant representation of commonsense knowledge. Currently, there is a big gap between the state of the art languages that are used in knowledge representation and the state of the art languages in which machine learning is done.  The success of this project will identify fundamental issues in bridging the gap between the two areas, will produce a uniform framework for both expressive representation and learning, and will contribute to the integration of knowledge representation and machine learning. The outcome of the research will be useful for many applications that require integration of knowledge representation and other areas, such as vision, robotics, and event recognition, where commonsense reasoning has to be applied on uncertain knowledge and data. The software systems developed under this project will be freely available as open source software. The research will involve both graduate and undergraduate students, contributing to a strengthened relationship between education and research. &lt;br/&gt;&lt;br/&gt;The goal of the project is to design and implement a knowledge representation language that allows elaboration tolerant representation of expressive commonsense knowledge involving logic and probability, which can be efficiently computed by the techniques developed in related areas.  The proposed research aims at shifting the current logic-based foundation of answer set programming to a novel foundation that combines logic and probability, and achieving its computation by intelligently adapting and combining the methods from probabilistic reasoning and machine learning. It will build upon the existing works on answer set programming, statistical relational learning, and probabilisitic logic programming.  The project will (i) enhance the mathematical foundation of answer set programming to the novel foundation that combines logic and probability. (ii) relate it to other existing approaches in statistical relational learning, Pearl's causal models, and P-Log; (iii) design inference and learning algorithms; (iv) design a high level action language that allows elaboration tolerant representation of probabilistic transition systems; (v) apply probabilistic answer set programming to event recognition; (vi) implement and evaluate involved software systems.</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526301</AwardID>
<Investigator>
<FirstName>Joohyung</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joohyung Lee</PI_FULL_NAME>
<EmailAddress>joolee@asu.edu</EmailAddress>
<PI_PHON>4809652784</PI_PHON>
<NSF_ID>000492036</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2><![CDATA[660 South Mill Avenue, Suite 310]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>Tempe</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852876011</ZipCode>
<StreetAddress><![CDATA[P.O. Box 876011]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~342795</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the project is to design and implement a knowledge representation language that allows for elaboration tolerant representation of expressive commonsense knowledge involving logic and probability, which can be efficiently computed by the techniques developed in knowledge representation and machine learning.&nbsp;&nbsp;</p> <p><br />Answer set programming is a widely used knowledge representation framework that facilitates an elegant and succinct representation of many problem domains that require complex reasoning. However, it is not suitable for problems involving probabilistic uncertainty. To account for the deficiency, we introduced the concept of weighted rules into answer set programs following the weighting scheme of Markov Logic. LPMLN is a proper extension of standard answer set programs to overcome the deterministic nature of the stable model semantics and provides ways to resolve inconsistencies in answer set programs, rank stable models, associate probabilities to stable models, and apply statistical inference to computing probabilistic stable models. We showed that several mathematical results known in answer set programming can be naturally extended to LPMLN.</p> <p><br />We showed reductions from LPMLN to answer set programs and Markov Logic under certain conditions. The reductions are not only interesting theoretically, but also important from a computational point of view because they provide ways to compute LPMLN using existing implementations of ASP and Markov Logic solvers. We designed and implemented two LPMLN solvers based on each reduction. The solvers can not only compute LPMLN but also can compute other probabilistic logic languages that we have previously shown to be embeddable into LPMLN.&nbsp;</p> <p>We designed and implemented parameter learning methods for LPMLN. Learning in LPMLN is under the stable model semantics, so it learns parameters for probabilistic extensions of knowledge-rich domains where ASP has shown to be useful but was limited to the deterministic case, such as reachability analysis and reasoning about actions in dynamic domains.&nbsp;</p> <p>Furthermore, we defined an action language called pBC+ as a high-level notation of LPMLN programs for describing probabilistic transitions. We show how probabilistic reasoning about transition systems, such as prediction, postdiction, and planning problems, as well as a probabilistic diagnosis for dynamic domains, can be modeled in pBC+ and computed using an implementation of LPMLN. We established a formal relationship between the pBC+ and Markov Decision Process (MDP) and implemented a prototype system that computes pBC+ action description using MDP solvers. The work provides a representation of MDP in a succinct and elaboration tolerant way as well as leveraging an MDP solver to compute a pBC+ action description. This result was further extended to relate pBC+ to Partially Observable Decision Process (POMDP).</p> <p>Overall, the project contributed to identifying fundamental issues in bridging the gap between the two areas, and based on the results, producing a uniform framework for both expressive representation and learning. In particular, the project aimed at extending the logical foundation of answer set programming to a novel foundation that incorporates probabilistic reasoning and learning, and achieving its computation by intelligently adapting and combining the methods from probabilistic reasoning and machine learning.&nbsp;<br /><br /></p><br> <p>            Last Modified: 11/29/2019<br>      Modified by: Joohyung&nbsp;Lee</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1526301/1526301_10383451_1575034262611_lpmln--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526301/1526301_10383451_1575034262611_lpmln--rgov-800width.jpg" title="LPMLN"><img src="/por/images/Reports/POR/2019/1526301/1526301_10383451_1575034262611_lpmln--rgov-66x44.jpg" alt="LPMLN"></a> <div class="imageCaptionContainer"> <div class="imageCaption">LPMLN</div> <div class="imageCredit">J. Lee</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Joohyung&nbsp;Lee</div> <div class="imageTitle">LPMLN</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526301/1526301_10383451_1575034381992_lpmln-learning--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526301/1526301_10383451_1575034381992_lpmln-learning--rgov-800width.jpg" title="LPMLN learning pipeline"><img src="/por/images/Reports/POR/2019/1526301/1526301_10383451_1575034381992_lpmln-learning--rgov-66x44.jpg" alt="LPMLN learning pipeline"></a> <div class="imageCaptionContainer"> <div class="imageCaption">LPMLN learning pipeline</div> <div class="imageCredit">J. Lee</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Joohyung&nbsp;Lee</div> <div class="imageTitle">LPMLN learning pipeline</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the project is to design and implement a knowledge representation language that allows for elaboration tolerant representation of expressive commonsense knowledge involving logic and probability, which can be efficiently computed by the techniques developed in knowledge representation and machine learning.     Answer set programming is a widely used knowledge representation framework that facilitates an elegant and succinct representation of many problem domains that require complex reasoning. However, it is not suitable for problems involving probabilistic uncertainty. To account for the deficiency, we introduced the concept of weighted rules into answer set programs following the weighting scheme of Markov Logic. LPMLN is a proper extension of standard answer set programs to overcome the deterministic nature of the stable model semantics and provides ways to resolve inconsistencies in answer set programs, rank stable models, associate probabilities to stable models, and apply statistical inference to computing probabilistic stable models. We showed that several mathematical results known in answer set programming can be naturally extended to LPMLN.   We showed reductions from LPMLN to answer set programs and Markov Logic under certain conditions. The reductions are not only interesting theoretically, but also important from a computational point of view because they provide ways to compute LPMLN using existing implementations of ASP and Markov Logic solvers. We designed and implemented two LPMLN solvers based on each reduction. The solvers can not only compute LPMLN but also can compute other probabilistic logic languages that we have previously shown to be embeddable into LPMLN.   We designed and implemented parameter learning methods for LPMLN. Learning in LPMLN is under the stable model semantics, so it learns parameters for probabilistic extensions of knowledge-rich domains where ASP has shown to be useful but was limited to the deterministic case, such as reachability analysis and reasoning about actions in dynamic domains.   Furthermore, we defined an action language called pBC+ as a high-level notation of LPMLN programs for describing probabilistic transitions. We show how probabilistic reasoning about transition systems, such as prediction, postdiction, and planning problems, as well as a probabilistic diagnosis for dynamic domains, can be modeled in pBC+ and computed using an implementation of LPMLN. We established a formal relationship between the pBC+ and Markov Decision Process (MDP) and implemented a prototype system that computes pBC+ action description using MDP solvers. The work provides a representation of MDP in a succinct and elaboration tolerant way as well as leveraging an MDP solver to compute a pBC+ action description. This result was further extended to relate pBC+ to Partially Observable Decision Process (POMDP).  Overall, the project contributed to identifying fundamental issues in bridging the gap between the two areas, and based on the results, producing a uniform framework for both expressive representation and learning. In particular, the project aimed at extending the logical foundation of answer set programming to a novel foundation that incorporates probabilistic reasoning and learning, and achieving its computation by intelligently adapting and combining the methods from probabilistic reasoning and machine learning.          Last Modified: 11/29/2019       Submitted by: Joohyung Lee]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
