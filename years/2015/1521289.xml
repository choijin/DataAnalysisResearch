<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps:  Automated Attendance Check by Using Smartphone Cameras</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/15/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>lydia mcclure</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Checking attendance in scenarios such as classrooms commonly needs an instructor to recognize each student one by one by reading the names on a roster or ask students to sign up the attendance sheet. However, this traditional method faces two problems: reading students' names may occupy minutes of lecture time when the number of students is large and letting students to sign up an attendance sheet is prone to be cheated since they can sign their own names and their classmates' names who are absent in the class; it is not a desirable task for instructors to calculate the total attendance of every student in a semester by going through every attendance sheet manually. This I-Corps team proposes an efficient and accurate way to accomplish this task. By taking videos of student faces in classrooms using Smartphone cameras, the team proposes a unified framework of visual face detection, tracking and recognition algorithms to recognize multi-faces in the video simultaneously.&lt;br/&gt;&lt;br/&gt;The proposed system has the following steps: instructors install the proposed App on their own Smartphones; in the first class, instructors use the Smartphone cameras to take a short-period video of student faces in the classroom. The application will automatically build a face dataset for the course and the instructor only needs to identify them for the first class; in the remaining classes, instructors take videos of each class and the application will do automated attendance check. The proposed Smartphone App will perform multi-object tracking to associate detected faces (including false positives) into face tracklets (each tracklet contains multiple instances of the same individual with variations in pose, illumination etc.) and then the face instances in each face tracklet are clustered into a small number of clusters, achieving sparse face representation with less redundancy.</AbstractNarration>
<MinAmdLetterDate>01/02/2015</MinAmdLetterDate>
<MaxAmdLetterDate>01/02/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1521289</AwardID>
<Investigator>
<FirstName>Zhaozheng</FirstName>
<LastName>Yin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhaozheng Yin</PI_FULL_NAME>
<EmailAddress>zhaozheng.yin@stonybrook.edu</EmailAddress>
<PI_PHON>6316322592</PI_PHON>
<NSF_ID>000605796</NSF_ID>
<StartDate>01/02/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Missouri University of Science and Technology</Name>
<CityName>Rolla</CityName>
<ZipCode>654096506</ZipCode>
<PhoneNumber>5733414134</PhoneNumber>
<StreetAddress>300 W 12th Street</StreetAddress>
<StreetAddress2><![CDATA[202 Centennial Hall]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804883767</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Missouri University of Science and Technology]]></Name>
<CityName>Rolla</CityName>
<StateCode>MO</StateCode>
<ZipCode>654096506</ZipCode>
<StreetAddress><![CDATA[300 W 12th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~50000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Face recognition has promising applications in the education field such as class attendance check, identity verification and exam proctor during the oneline education. We propose an efficient and accurate way to accomplish this task. By taking videos of student faces in classrooms using Smartphone (or web cameras during online education), we propose a unified framework of visual face detection, tracking and recognition algorithms to recognize multi-faces in the video simultaneously. The algorithm can further enable educators to monitor students&rsquo; attendance and learning behavior over time.</p> <p><span style="text-decoration: underline;">Intellectual Merits</span>: Our proposed system has the following steps: 1. Instructors install our App on their own Smartphones which will be lower cost than commercial face recognition systems used in security applications; 2. In the first class, instructors use the Smartphone cameras to take a short-period video of student faces in the classroom. The application will automatically build a face dataset for the course and the instructor only needs to identify them for the first class; 3. In the remaining classes, instructors take videos of each class and the application will do automated attendance check. During online education, the face videos will be provided by webcams. Our algorithm performs multi-object tracking to associate detected faces (including false positives) into face tracklets (each tracklet contains multiple instances of the same individual with variations in pose, illumination etc.) and then the face instances in each face tracklet are clustered into a small number of clusters, achieving sparse face representation with less redundancy. The algorithm solves a unified optimization problem to: (a) identify false positive face tracklets; (b) link face tracklets belonging to the same person due to long occlusion; and (c) recognize the group of faces simultaneously with spatial and temporal context constraints in the video.</p> <p><span style="text-decoration: underline;">Broader Impacts</span>. The proposed project will advance the scientific and technological understanding on scene-specific object detection, multi-object tracking under occlusion and multi-face recognition in videos. It will assist the educators to efficiently and accurately check the course attendance, verify identities and protocor exams. The video-based face recognition algorithm can also be extended into the application domains of identify and access management in financial system and medical institutions.</p><br> <p>            Last Modified: 07/05/2016<br>      Modified by: Zhaozheng&nbsp;Yin</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Face recognition has promising applications in the education field such as class attendance check, identity verification and exam proctor during the oneline education. We propose an efficient and accurate way to accomplish this task. By taking videos of student faces in classrooms using Smartphone (or web cameras during online education), we propose a unified framework of visual face detection, tracking and recognition algorithms to recognize multi-faces in the video simultaneously. The algorithm can further enable educators to monitor studentsÃ† attendance and learning behavior over time.  Intellectual Merits: Our proposed system has the following steps: 1. Instructors install our App on their own Smartphones which will be lower cost than commercial face recognition systems used in security applications; 2. In the first class, instructors use the Smartphone cameras to take a short-period video of student faces in the classroom. The application will automatically build a face dataset for the course and the instructor only needs to identify them for the first class; 3. In the remaining classes, instructors take videos of each class and the application will do automated attendance check. During online education, the face videos will be provided by webcams. Our algorithm performs multi-object tracking to associate detected faces (including false positives) into face tracklets (each tracklet contains multiple instances of the same individual with variations in pose, illumination etc.) and then the face instances in each face tracklet are clustered into a small number of clusters, achieving sparse face representation with less redundancy. The algorithm solves a unified optimization problem to: (a) identify false positive face tracklets; (b) link face tracklets belonging to the same person due to long occlusion; and (c) recognize the group of faces simultaneously with spatial and temporal context constraints in the video.  Broader Impacts. The proposed project will advance the scientific and technological understanding on scene-specific object detection, multi-object tracking under occlusion and multi-face recognition in videos. It will assist the educators to efficiently and accurately check the course attendance, verify identities and protocor exams. The video-based face recognition algorithm can also be extended into the application domains of identify and access management in financial system and medical institutions.       Last Modified: 07/05/2016       Submitted by: Zhaozheng Yin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
