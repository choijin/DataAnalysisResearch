<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF:  Small: Geometric, Variational Algorithms for Radiometric-Based Shape Reconstruction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The investigator will develop a new class of variational geometric inverse algorithms for reconstructing dense 3D shape of objects from measurements of a scene representing an arbitrary combination of vantage points and/or resolution by employing a common mathematical framework based on generative radiometric models. Reconstruction of shape from raw sensor data is a necessary step for graphical 3D rendering and analysis in scenarios where CAD models are unavailable or impossible. Two examples to be initially explored include unfocussed camera images from different viewpoints and/or focal lengths using thin-lens modelling, and radar signals reflected from nearby objects  with different antenna locations and/or wavelengths.&lt;br/&gt;&lt;br/&gt;The framework will be general enough to apply to several related sensor modalities beyond those initially investigated, ranging from infrared, acoustics, and SAR. Furthermore, having a unified model affords the freedom to generate flexible data capture and fusion schemes where not one, but multiple sets of measurements are captured under different viewpoint and sensor setting characteristics, and use the entire set of collected data to infer an estimate of reflectance and geometry that is of superior quality relative to what may be obtained in scenarios where "isolating a single cue" is not possible. For instance, with cameras, it may be impossible to fix the viewpoint while capturing images of different focus (isolating focus), or to capture perfectly sharp images because of the finite aperture of the lens (isolating viewpoint). Removing this constraint can enable applications to endoscopy, inspection of pipes and crevices, dental impressions, as well as environmental monitoring.</AbstractNarration>
<MinAmdLetterDate>07/27/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526848</AwardID>
<Investigator>
<FirstName>Anthony</FirstName>
<LastName>Yezzi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anthony Yezzi</PI_FULL_NAME>
<EmailAddress>ayezzi@ece.gatech.edu</EmailAddress>
<PI_PHON>4043851017</PI_PHON>
<NSF_ID>000382373</NSF_ID>
<StartDate>07/27/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName/>
<StateCode>GA</StateCode>
<ZipCode>303320250</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Intellectual Merit:</p> <p>Building upon our prior work in reconstructing the shape of objects from multiple fully focused camera images, we developed a new class of methods to carry out the same task using images that are potentially out of focus. In addition, we further adapted the framework to work using radar measurements as input for scenarios in which camera images may not be useful or practical. While the general intuition behind these new methods matched that of our previous work, new mathematical models had to be derived, new engineering challenges had to be overcome, and new numerical and compuational strategies had to be developed.</p> <p>Broader Impact:</p> <p>The new camera based shape reconstrution methods, by allowing the images to be unfocussed as well as be acquired from potentially different camera poses, opens up the possibility for surface reconstruction in scenarios that have been challening thus far for camera based vision. This would include medical endoscopy as well as robotic inspection of the interior of pipelines. While the new methodogies for radar based shape reconstruction, given that they simulteously estimate both shape and variable reflectivity, allow improvements in radar processing in niche areas were one of these (shape or reflectivity) had to be known first in order to estimate the other. For example, in radar based survelliance for irrigation, the moisture content of the ground (which affects its reflectivity) can be estimated with current radar technology by overhead drones if the terrain height fluctuations are known in advance. Thew new mehodology developed in this project would elimiate that constraint and thus make such technology more broadly applicable.</p><br> <p>            Last Modified: 10/30/2019<br>      Modified by: Anthony&nbsp;Yezzi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit:  Building upon our prior work in reconstructing the shape of objects from multiple fully focused camera images, we developed a new class of methods to carry out the same task using images that are potentially out of focus. In addition, we further adapted the framework to work using radar measurements as input for scenarios in which camera images may not be useful or practical. While the general intuition behind these new methods matched that of our previous work, new mathematical models had to be derived, new engineering challenges had to be overcome, and new numerical and compuational strategies had to be developed.  Broader Impact:  The new camera based shape reconstrution methods, by allowing the images to be unfocussed as well as be acquired from potentially different camera poses, opens up the possibility for surface reconstruction in scenarios that have been challening thus far for camera based vision. This would include medical endoscopy as well as robotic inspection of the interior of pipelines. While the new methodogies for radar based shape reconstruction, given that they simulteously estimate both shape and variable reflectivity, allow improvements in radar processing in niche areas were one of these (shape or reflectivity) had to be known first in order to estimate the other. For example, in radar based survelliance for irrigation, the moisture content of the ground (which affects its reflectivity) can be estimated with current radar technology by overhead drones if the terrain height fluctuations are known in advance. Thew new mehodology developed in this project would elimiate that constraint and thus make such technology more broadly applicable.       Last Modified: 10/30/2019       Submitted by: Anthony Yezzi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
