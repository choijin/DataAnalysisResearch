<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: EMBRACE: Evolvable Methods for Benchmarking Realism through Application and Community Engagement</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>125000.00</AwardTotalIntnAmount>
<AwardAmount>125000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Edward Walker</SignBlockName>
<PO_EMAI>edwalker@nsf.gov</PO_EMAI>
<PO_PHON>7032924863</PO_PHON>
</ProgramOfficer>
<AbstractNarration>High-performance computing opens new avenues in science, planning, health, and defense that are not economically achievable by pure experimentation. New progress areas require new evaluation methods, packaged in benchmarks, for selecting computational hardware and systems. EMBRACE will guide selection of computing technologies for different scientific areas with different needs. Current approaches assume that one kind of platform addresses all problems, but growing use in bioinformatics, urban planning, medicine, and more fields have demonstrated new, uncovered system requirements. EMBRACE opens the process through community competitions. These competitions will both build benchmarks useful for multiple scientific areas as well as build a community around benchmarking science. The evolving measurements will help scientists best match their applications with computing platforms.&lt;br/&gt;&lt;br/&gt;Despite the long-standing interest and important impacts of benchmarking, there is no resolution on the most rational way to design, develop, and evolve forward-looking benchmarks, and to correctly interpret their results. Over time, the community has broadened, the platforms have changed dramatically, and the applications have evolved, yet today's benchmarks have not necessarily evolved with them. The primary objective of this proposal is to sustainably advance the science of benchmarking based on current and future needs. A second objective is to create sustainable incentives that drive research and innovation. A third objective is to produce a select set of the most useful and evolving benchmarks, benchmarking methods, or benchmarking analyses that can be accepted by the community. The vision and objectives will be realized by establishing a new, sustainable, and community-driven competition, the Evolvable Methods for Benchmarking Realism through Application and Community Engagement (EMBRACE) Workshop, in which teams compete in categories directly relevant to performance measurement and benchmarking. Submissions to the contest will include code, technical papers and presentations. In consultation with leaders in various application domains and with vendor representatives, the EMBRACE team will be responsible for defining the contest categories, framing the rules, recruiting both the participants and the judges, and monitoring and managing the process as it takes place. It will be an open forum to advance the broader scientific community's understanding of fundamental questions in the area of benchmarking.</AbstractNarration>
<MinAmdLetterDate>08/14/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/14/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1535058</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Bader</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David A Bader</PI_FULL_NAME>
<EmailAddress>bader@njit.edu</EmailAddress>
<PI_PHON>9735962654</PI_PHON>
<NSF_ID>000206826</NSF_ID>
<StartDate>08/14/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Vuduc</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard W Vuduc</PI_FULL_NAME>
<EmailAddress>richie@cc.gatech.edu</EmailAddress>
<PI_PHON>5103017014</PI_PHON>
<NSF_ID>000080331</NSF_ID>
<StartDate>08/14/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Edward</FirstName>
<LastName>Riedy</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edward J Riedy</PI_FULL_NAME>
<EmailAddress>jason.riedy@cc.gatech.edu</EmailAddress>
<PI_PHON>4048944819</PI_PHON>
<NSF_ID>000596559</NSF_ID>
<StartDate>08/14/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7684</Code>
<Text>CESER-Cyberinfrastructure for</Text>
</ProgramElement>
<ProgramReference>
<Code>7684</Code>
<Text>STRATEGIC TECHNOLOGIES FOR CI</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~125000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>High-performance computing opens new avenues in science, planning, health, engineering, and defense that are not economically achievable by pure experimentation. New progress areas require new evaluation methods, packaged in benchmarks, for selecting computational hardware and systems. EMBRACE developed methods to guide selection of computing technologies for different scientific areas with different needs. Current approaches assume that one kind of platform addresses all problems, but growing use in bioinformatics, urban planning, medicine, and more fields have demonstrated new, uncovered system requirements. EMBRACE built a community for benchmarking HPC systems. The evolving measurements will help scientists best match their applications with computing platforms.<br /><br />Despite the long-standing interest and important impacts of benchmarking, there is no resolution on the most rational way to design, develop, and evolve forward-looking benchmarks, and to correctly interpret their results. Over time, the community has broadened, the platforms have changed dramatically, and the applications have evolved, yet today's benchmarks have not necessarily evolved with them. This award has established a new, sustainable, and community-driven event, the Evolvable Methods for Benchmarking Realism through Application and Community Engagement (EMBRACE) Workshop. This workshop is an open forum to advance the broader scientific community's understanding of fundamental questions in the area of benchmarking.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/22/2018<br>      Modified by: David&nbsp;A&nbsp;Bader</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ High-performance computing opens new avenues in science, planning, health, engineering, and defense that are not economically achievable by pure experimentation. New progress areas require new evaluation methods, packaged in benchmarks, for selecting computational hardware and systems. EMBRACE developed methods to guide selection of computing technologies for different scientific areas with different needs. Current approaches assume that one kind of platform addresses all problems, but growing use in bioinformatics, urban planning, medicine, and more fields have demonstrated new, uncovered system requirements. EMBRACE built a community for benchmarking HPC systems. The evolving measurements will help scientists best match their applications with computing platforms.  Despite the long-standing interest and important impacts of benchmarking, there is no resolution on the most rational way to design, develop, and evolve forward-looking benchmarks, and to correctly interpret their results. Over time, the community has broadened, the platforms have changed dramatically, and the applications have evolved, yet today's benchmarks have not necessarily evolved with them. This award has established a new, sustainable, and community-driven event, the Evolvable Methods for Benchmarking Realism through Application and Community Engagement (EMBRACE) Workshop. This workshop is an open forum to advance the broader scientific community's understanding of fundamental questions in the area of benchmarking.                      Last Modified: 03/22/2018       Submitted by: David A Bader]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
