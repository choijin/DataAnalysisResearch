<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Robust Optimization of Loss Functions with Application to Active Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to develop machine learning techniques that produce better predictions in a broad range of application domains where the usefulness of predictions is measured by application-specific performance measures. Existing machine learning methods are frequently forced to approximate these performance measures so that the search for a good predictor using the approximated measure will be efficient. This can produce inappropriate predictions for data in which the approximation to the performance measure is loose, even for the most fundamental performance measure: accuracy. The approach of this project instead approximates the training data and optimizes the exact performance measure to obtain a good predictor. Approximation takes the form of an "adversary" in a zero-sum game that chooses how the predicted variables are distributed for evaluation in a way that minimizes performance, but also matches properties of the dataset that are measured from training data. Many performance measures that are intractable to directly optimize become tractable when adversarially optimized.  Resulting predictors are designed for the worst case and must perform at least as well when the adversary is replaced by real data with high probability.&lt;br/&gt;&lt;br/&gt;The societal impact of better aligning machine learning methods to a significantly wider range of performance measures is substantial.  All classification and regression tasks that are currently solved using methods that approximate the desired performance measure, such as support vector machines or AdaBoost, could potentially be improved by the proposed approach.  The project specifically investigates cost-sensitive classification, in which different mistakes incur penalties that are based on the implications of the prediction on real-world applications, F-measure maximization, which is a preferred performance measure balancing precision and recall in information retrieval tasks, and active learning, where the approach produces predictions that are robust to sample selection bias.  Additional broader impacts of this project include developing new curriculum that will enable a wide range of data-driven practitioners to apply these improved methods to important application areas, including public policy, medical decision support, and epidemiology. Further, the PIs are committed to advising students from underrepresented groups at the University of Illinois at Chicago, which is an urban school with a diverse student population.</AbstractNarration>
<MinAmdLetterDate>08/07/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526379</AwardID>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Ziebart</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian Ziebart</PI_FULL_NAME>
<EmailAddress>bziebart@uic.edu</EmailAddress>
<PI_PHON>2178407256</PI_PHON>
<NSF_ID>000607805</NSF_ID>
<StartDate>08/07/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lev</FirstName>
<LastName>Reyzin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lev Reyzin</PI_FULL_NAME>
<EmailAddress>lreyzin@uic.edu</EmailAddress>
<PI_PHON>3129962862</PI_PHON>
<NSF_ID>000649506</NSF_ID>
<StartDate>08/07/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606124305</ZipCode>
<PhoneNumber>3129962862</PhoneNumber>
<StreetAddress>809 S. Marshfield Avenue</StreetAddress>
<StreetAddress2><![CDATA[MB 502, M/C 551]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>098987217</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Chicago]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>606077042</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed a general approach for supervised machine learning using a game-theoretic construction of the prediction task. This can be interpreted as <em>approximating the training data labels while using the exact performance measure, </em>while the standard existing approach (empirical risk minimization) typically employs the opposite approach: <em>approximating the loss function with a surrogate loss (that is easier to optimize) and optimizing over the exact training data</em>. The project demonstrated approach on:</p> <ul> <li>Classification tasks with additive losses (zero-one loss and ordinal regression);</li> <li>Classification tasks with non-additive losses (F-measure and discounted cummulative gain);</li> <li>Regression tasks with covariate shift; and</li> <li>Structured prediction tasks (learning graph cuts, bipartite matchings, and graphical models).</li> </ul> <p>A number of optimization techniques were developed to handle the variety of prediction tasks investigated. These include: explicit construction of a game matrix and using linear programming to solve for the equilibirum; analytical solutions of this game for special cases of the loss function; constraint generation methods for uncovering the columns and rows of the game matrix that have non-zero equilibrium probability; and marginal decompositions of the equilbirium distribution that allow polynomial-time solutions.</p> <p>For the classification using the 0-1 loss, this approach produces an equivalent surrogate loss that is the combination of two offset hinge losses for binary prediction tasks. When extended to multiclass classification settings, this provides an equivalent surrogate loss (see figure) that better aligns with the 0-1 loss to provide consistency guarantees that standard support vector machine methods lack in this setting.</p> <p>Additionally, the project prepared seven PhD research assistants (including three female students) for employment in postdoctoral and full-time positions in top academic institutions and technology companies.</p><br> <p>            Last Modified: 11/29/2018<br>      Modified by: Brian&nbsp;Ziebart</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1526379/1526379_10384786_1543551667234_0-1-surrogate--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1526379/1526379_10384786_1543551667234_0-1-surrogate--rgov-800width.jpg" title="Multiclass 0-1 Loss Surrogate"><img src="/por/images/Reports/POR/2018/1526379/1526379_10384786_1543551667234_0-1-surrogate--rgov-66x44.jpg" alt="Multiclass 0-1 Loss Surrogate"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The equivalent surrogate loss provided by our 0-1 adversarial formulation for classification with three classes.</div> <div class="imageCredit">Rizal Fathony</div> <div class="imageSubmitted">Brian&nbsp;Ziebart</div> <div class="imageTitle">Multiclass 0-1 Loss Surrogate</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed a general approach for supervised machine learning using a game-theoretic construction of the prediction task. This can be interpreted as approximating the training data labels while using the exact performance measure, while the standard existing approach (empirical risk minimization) typically employs the opposite approach: approximating the loss function with a surrogate loss (that is easier to optimize) and optimizing over the exact training data. The project demonstrated approach on:  Classification tasks with additive losses (zero-one loss and ordinal regression); Classification tasks with non-additive losses (F-measure and discounted cummulative gain); Regression tasks with covariate shift; and Structured prediction tasks (learning graph cuts, bipartite matchings, and graphical models).   A number of optimization techniques were developed to handle the variety of prediction tasks investigated. These include: explicit construction of a game matrix and using linear programming to solve for the equilibirum; analytical solutions of this game for special cases of the loss function; constraint generation methods for uncovering the columns and rows of the game matrix that have non-zero equilibrium probability; and marginal decompositions of the equilbirium distribution that allow polynomial-time solutions.  For the classification using the 0-1 loss, this approach produces an equivalent surrogate loss that is the combination of two offset hinge losses for binary prediction tasks. When extended to multiclass classification settings, this provides an equivalent surrogate loss (see figure) that better aligns with the 0-1 loss to provide consistency guarantees that standard support vector machine methods lack in this setting.  Additionally, the project prepared seven PhD research assistants (including three female students) for employment in postdoctoral and full-time positions in top academic institutions and technology companies.       Last Modified: 11/29/2018       Submitted by: Brian Ziebart]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
