<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Mathematical and Computational Methods for Non-Equilbrium Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>279654.00</AwardTotalIntnAmount>
<AwardAmount>279654</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Eun Heui Kim</SignBlockName>
<PO_EMAI>eukim@nsf.gov</PO_EMAI>
<PO_PHON>7032922091</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research project is concerned with the behavior in time of complex systems subject to random influences.  Complex systems with a large number of parameters and agents are ubiquitous -- think, for example, of the traffic on a network of highways or of bio-chemical systems, which involve many types of molecules and many chemical reactions.  For such systems, the issue of sensitivity analysis presents special challenges: sensitivity analysis consists in understanding the effects of parameters on the future behavior of the system -- for example, how the closure of one lane on a busy highway influences the traffic, possibly many miles away and several hours later.  Understanding these effects is at the heart of the field of predictive modeling and poses formidable challenges, which often exceed the capabilities of modern computers.  The Principal Investigators will develop tools, both conceptual and computational, to tackle such issues by using, in a complementary fashion, techniques from different fields of science.  This includes methods from information theory (which quantifies how information is lost in physical processes), from statistical mechanics (which allows one to understand the global behavior of very large systems), and from numerical analysis (which is the science that allows one to simulate and reproduce the behavior of complex systems on a computer).&lt;br/&gt;&lt;br/&gt;Understanding non-equilibrium systems driven by external forces, boundary effects, and multi-physics presents numerous mathematical and computational challenges, especially if the system is large and involves many parameters.  A paradigmatic example is a bio-chemical reaction network, which often involves multiple time scales, feedback loops, hundreds of species, and hundreds of parameters.  At the center of this project is the development of mathematical and numerical tools for the analysis and simulation of such non-equilibrium high-dimensional stochastic systems.  The research blends together concepts from information theory, statistical mechanics, numerical analysis, and probability theory in order to develop novel algorithms, as well as novel tools to assess existing algorithms for complex systems.  The issue of sensitivity analysis plays a central role in the work.  One of the novelties here is the systematic use and development of information-theoretic tools for the analysis and uncertainty quantification of stochastic systems, with a strong emphasis on the long-time behavior of the systems.  Concepts such as the relative entropy and the Fisher information matrix, especially applied to the time histories of the system, are particularly well suited.  Another important feature of the project concerns the fact that non-equilibrium systems do not respect invariance under time reversal.  Measuring quantitatively this symmetry breaking is one the main themes in modern non-equilibrium statistical mechanics, and the Principal Investigators will use concepts developed in this project to create efficient algorithms to do this for complex systems.  Finally, the research team will investigate the role of memory or delay effects, which are unavoidable in complex systems with multiple spatial or temporal scales.</AbstractNarration>
<MinAmdLetterDate>08/20/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1515712</AwardID>
<Investigator>
<FirstName>Markos</FirstName>
<LastName>Katsoulakis</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Markos A Katsoulakis</PI_FULL_NAME>
<EmailAddress>markos@math.umass.edu</EmailAddress>
<PI_PHON>4135451331</PI_PHON>
<NSF_ID>000109971</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Luc</FirstName>
<LastName>Rey-Bellet</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Luc Rey-Bellet</PI_FULL_NAME>
<EmailAddress>lr7q@math.umass.edu</EmailAddress>
<PI_PHON>4135456020</PI_PHON>
<NSF_ID>000196997</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039242</ZipCode>
<StreetAddress><![CDATA[710 North Pleasant Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1266</Code>
<Text>APPLIED MATHEMATICS</Text>
</ProgramElement>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~279654</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>The goal of the project is to provide performance guarantees for complex systems, especially for large systems which possibly depend on many parameters. For example bio-chemical reactions often involve hundreds (or even thousands) of species and depend on hundred of parameters. These models are themselves a reduced description of a more detailed physical model and are calibrated using (sometimes sparse) data. There are also (often uncontrolled) approximations used in the construction of the model.&nbsp; In view of all these approximations and uncertainties the resulting model should be then considered only as an imperfect realization of the the "true" model which remains partially unknown. To build truly predictive models it is necessary to assess the effects on uncertainties, (the known unknowns and the unknown unknowns), on the predictions made using the model.&nbsp;</p> <p>The intellectual merit of the proposal is to build an array of mathematical tools to quantify how the uncertainties in the nature of the model itself will influence the accuracy of the information extracted from the model. Typical examples of predictions are computing an average (over space or time) quantity,&nbsp; or maybe&nbsp; computing the probability that some rare (but potentially catstrophic) event would occur.&nbsp; Each type of predictions actually require its very own set of well-designed diagnostic tools.&nbsp; The PIs use and develop a number of information-theoretic divergences (a type of measure of the distance between systems) and variational representations to build an array of new information inequalites which quantifies the uncertainties in predictions. The work combines ideas and concepts from probability, statistical mechanics, and probability.&nbsp;</p> <p>As an example of the broader impact of the proposal the PIs have also applied these new ideas and tools to concrete models. For examples the PI Rey-Bellet and his collaborator provide performance guarantees for Monte-Carlo Markov chains samplers (e.g. the Hamiltonian Monte-Carlo and the bouncy particle sampler) which are of current interests in statistical and molecular dynamics applications. In another vein the PI Katsoulakis and his collaborator analyze a chemical reaction network with hundreds of species and reactions and uses a path-space information theoretic senstivity analysis to build efficiently a reduced model involving only the very few most relevant species.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 02/07/2020<br>      Modified by: Luc&nbsp;Rey-Bellet</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    The goal of the project is to provide performance guarantees for complex systems, especially for large systems which possibly depend on many parameters. For example bio-chemical reactions often involve hundreds (or even thousands) of species and depend on hundred of parameters. These models are themselves a reduced description of a more detailed physical model and are calibrated using (sometimes sparse) data. There are also (often uncontrolled) approximations used in the construction of the model.  In view of all these approximations and uncertainties the resulting model should be then considered only as an imperfect realization of the the "true" model which remains partially unknown. To build truly predictive models it is necessary to assess the effects on uncertainties, (the known unknowns and the unknown unknowns), on the predictions made using the model.   The intellectual merit of the proposal is to build an array of mathematical tools to quantify how the uncertainties in the nature of the model itself will influence the accuracy of the information extracted from the model. Typical examples of predictions are computing an average (over space or time) quantity,  or maybe  computing the probability that some rare (but potentially catstrophic) event would occur.  Each type of predictions actually require its very own set of well-designed diagnostic tools.  The PIs use and develop a number of information-theoretic divergences (a type of measure of the distance between systems) and variational representations to build an array of new information inequalites which quantifies the uncertainties in predictions. The work combines ideas and concepts from probability, statistical mechanics, and probability.   As an example of the broader impact of the proposal the PIs have also applied these new ideas and tools to concrete models. For examples the PI Rey-Bellet and his collaborator provide performance guarantees for Monte-Carlo Markov chains samplers (e.g. the Hamiltonian Monte-Carlo and the bouncy particle sampler) which are of current interests in statistical and molecular dynamics applications. In another vein the PI Katsoulakis and his collaborator analyze a chemical reaction network with hundreds of species and reactions and uses a path-space information theoretic senstivity analysis to build efficiently a reduced model involving only the very few most relevant species.                            Last Modified: 02/07/2020       Submitted by: Luc Rey-Bellet]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
