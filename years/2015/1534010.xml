<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>STTR Phase II:  An Assistive Tool to Locate People and Objects with a Multimodal Thermogram Interface</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>02/28/2019</AwardExpirationDate>
<AwardTotalIntnAmount>742386.00</AwardTotalIntnAmount>
<AwardAmount>890856</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this project is the assistive use by blind people of thermal imaging. The resulting product provides a person who is blind or visually impaired with the relevant information about the layout of an unfamiliar public space in order to assist blind users in everyday activities. Thermal imaging can differentiate people and objects from their background without the need for complex image analysis. The shape and the temperature of the human body allows the location of people to be easily determined. The societal impact will be assisting users in navigation of complex public spaces. A blind person can use a smartphone?s haptic touchscreen display to examine the thermal image to determine the location of people in front of them. Information about the layout of an unfamiliar public space can be learned from the heat and shape of materials. Examples would be locating vending machines like ATMs and train passes. The market sector for this technology will likely extend beyond assisting blind users, to include additional commercial opportunities as well.&lt;br/&gt;&lt;br/&gt;This Small Business Technology Transfer Research (STTR) Phase 2 project will leverage past National Science Foundation Funded research to develop a product that a blind/low vision user can use to receive practical navigation and interaction information about their environment from a multimodal thermogram (thermal image) interface on a smartphone. There are no practical assistive technologies for blind or low vision users that allow them to locate people, objects, and the layout information of their surroundings other than exploring with a cane. This development will address the objective of creating an interface that provides both practical utility and will be accepted by the target demographic of blind users. This project represents an excellent translational path from NSF-sponsored research programs to a product that is built from the ground up on solid theoretical underpinnings and empirical findings from multimodal human information processing. This development will use thermal radiation from people, machines, lighting and heat retention differences in building materials and convert this data into a user interface to facilitate blind navigation and environment interaction. The product resulting will be a multimodal (kinesthetic, vibro-tactile, and auditory) interface for blind users of a smartphone to interpret and gain useful value from thermal image information.</AbstractNarration>
<MinAmdLetterDate>09/14/2015</MinAmdLetterDate>
<MaxAmdLetterDate>11/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1534010</AwardID>
<Investigator>
<FirstName>Nicholas</FirstName>
<LastName>Giudice</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nicholas Giudice</PI_FULL_NAME>
<EmailAddress>nicholas.giudice@maine.edu</EmailAddress>
<PI_PHON>2075812187</PI_PHON>
<NSF_ID>000503809</NSF_ID>
<StartDate>09/14/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Hanzal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian Hanzal</PI_FULL_NAME>
<EmailAddress>brian_hanzal@yahoo.com</EmailAddress>
<PI_PHON>6124818723</PI_PHON>
<NSF_ID>000647355</NSF_ID>
<StartDate>09/14/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Moai Technologies L.L.C.</Name>
<CityName>Plymouth</CityName>
<ZipCode>554464595</ZipCode>
<PhoneNumber>6124818723</PhoneNumber>
<StreetAddress>18215 45th Ave N</StreetAddress>
<StreetAddress2><![CDATA[Suite B]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078662436</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MOAI TECHNOLOGIES LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maine]]></Name>
<CityName>Orono</CityName>
<StateCode>ME</StateCode>
<ZipCode>044695711</ZipCode>
<StreetAddress><![CDATA[348 Boardman Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maine</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>ME02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1591</Code>
<Text>STTR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>1591</Code>
<Text>STTR PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>169E</Code>
<Text>SBIR Tech Enhan Partner (TECP)</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~742386</FUND_OBLG>
<FUND_OBLG>2018~148470</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Among the assistive devices for use by blind or low-vision persons are various applications on smartphones. In addition, smartphones now make possible the fusion of multiple technologies, for example, camera imaging and vibration (haptics), which can be combined to allow a blind or low-vision person to locate people and objects, and to interpret the layout of their surroundings. Most importantly, there are now commercially-available smartphone-add-on (and likely eventually, built-in) thermal imaging cameras. This is a unique range of information-gathering capabilities to the disabled user in a single, portable handheld assistive device. Moai Technologies LLC, through this grant from the NSF, has created a small suite of innovative applications using a smartphone and the capabilities of both an add-on thermal camera and the native optical camera. Our research partner on this effort was the VEMI Laboratory at the University of Maine. The director of the laboratory, who also served as the project&rsquo;s co-PI, is a blind person, whose assistance in the direction of the app development was invaluable.</p> <p>&nbsp;</p> <p>The device operates in two complementary modes. In one, the camera and signal processing can locate a person or object in a scene by the thermal signature, and display it on the screen of the smartphone, and the blind or low-vision person can move a finger over the screen, and when it coincides with the image, the phone vibrates. In the second mode, the system can be used &lsquo;finger-free&rsquo; by vibrating when the image is in an (adjustable-sized) area in the center of the screen. For instance, by noting where the thermal image of a person is located, a blind or low-vision person can determine autonomously where an empty seat is, or where there is an opening in a line of people. This first-of-its-kind application opens the possibility for similar but diverse apps.</p> <p>&nbsp;</p> <p>As part of an NSF Technology Enhancement for Commercial Partnerships supplemental program, we developed a sub-app which assists a blind or low-vision person in locating the open doors of a train or light-rail car. This type of assistance was felt to be of prime importance by the co-PI.</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/29/2019<br>      Modified by: Brian&nbsp;Hanzal</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Among the assistive devices for use by blind or low-vision persons are various applications on smartphones. In addition, smartphones now make possible the fusion of multiple technologies, for example, camera imaging and vibration (haptics), which can be combined to allow a blind or low-vision person to locate people and objects, and to interpret the layout of their surroundings. Most importantly, there are now commercially-available smartphone-add-on (and likely eventually, built-in) thermal imaging cameras. This is a unique range of information-gathering capabilities to the disabled user in a single, portable handheld assistive device. Moai Technologies LLC, through this grant from the NSF, has created a small suite of innovative applications using a smartphone and the capabilities of both an add-on thermal camera and the native optical camera. Our research partner on this effort was the VEMI Laboratory at the University of Maine. The director of the laboratory, who also served as the project?s co-PI, is a blind person, whose assistance in the direction of the app development was invaluable.     The device operates in two complementary modes. In one, the camera and signal processing can locate a person or object in a scene by the thermal signature, and display it on the screen of the smartphone, and the blind or low-vision person can move a finger over the screen, and when it coincides with the image, the phone vibrates. In the second mode, the system can be used ?finger-free? by vibrating when the image is in an (adjustable-sized) area in the center of the screen. For instance, by noting where the thermal image of a person is located, a blind or low-vision person can determine autonomously where an empty seat is, or where there is an opening in a line of people. This first-of-its-kind application opens the possibility for similar but diverse apps.     As part of an NSF Technology Enhancement for Commercial Partnerships supplemental program, we developed a sub-app which assists a blind or low-vision person in locating the open doors of a train or light-rail car. This type of assistance was felt to be of prime importance by the co-PI.          Last Modified: 03/29/2019       Submitted by: Brian Hanzal]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
