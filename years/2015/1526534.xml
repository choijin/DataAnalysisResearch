<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Collaborative Research: Unified Feedback Control and Mechanical Design for Robotic, Prosthetic, and Exoskeleton Locomotion</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>302981.00</AwardTotalIntnAmount>
<AwardAmount>302981</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>There is a pressing need for wearable robots, e.g., prostheses and exoskeletons, which improve the quality of life for individuals with limited mobility - devices that work symbiotically with human users to achieve stable, safe and efficient locomotion.  At present, approximately 4.7 million people in the United States would benefit from an active lower-limb exoskeleton due to the effects of stroke, polio, multiple sclerosis, spinal cord injury, and cerebral palsy, and by 2050 an estimated 1.5 million people in the United States will be living with a major lower-limb amputation.  Yet current wearable robotic devices do not address this growing population's needs since they are bulky, heavy, noisy, and require large batteries for even short duration use, while implementing predominately hierarchical control algorithms.  Impeding innovation in this domain is the expensive and slow traditional design-build-test approach that ignores the tight coupling between hardware specifications and control algorithm performance.  The vision of this work is to provide a methodology---inspired by advancements in robotic locomotion---that allows lower-limb prostheses and exoskeletons to meet real-world requirements through the co-design of the electromechanical and feedback systems.  The transformative nature of this work, therefore, stems from its ability to realize wearable robots that synergize with humans to achieve increased mobility, providing a template for the growing robotic assistive device industry and potentially improving the quality of life of millions.  &lt;br/&gt;&lt;br/&gt;To realize the vision of this work, the overarching research goal is to create a new unified control and design framework that will allow for the efficient and stable locomotion of robots, prostheses, and exoskeletons.  A key aspect of this control methodology is the ability to continuously mediate between different objectives enforcing stability and safety in an efficient manner through force-based interactions among (wearable) robotic devices, their environment and the user. The resulting framework will be utilized via control-in-the-loop mechanical design of prostheses and exoskeletons with stringent design requirements, tested experimentally on a novel humanoid robot, and clinically evaluated through human subject trials.  This work is, therefore, guided by the following specific goals:  (1) develop a unified online optimization-based control framework for (wearable) robotic locomotion that efficiently mediates stability, safety and force constraints, (2) create a feedback loop between formal control synthesis and the mechanical design of wearable robots that satisfy stringent performance requirements,  (3) accelerate clinical testing by translating controllers formally and experimentally from bipedal humanoid robots to prostheses and exoskeletons.  As a result of these research goals, this work has the potential to create the next generation of robotic systems that enable stable, safe and efficient human mobility.</AbstractNarration>
<MinAmdLetterDate>08/31/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526534</AwardID>
<Investigator>
<FirstName>Levi</FirstName>
<LastName>Hargrove</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Levi Hargrove</PI_FULL_NAME>
<EmailAddress>lhargrove@sralab.org</EmailAddress>
<PI_PHON>3122384534</PI_PHON>
<NSF_ID>000611184</NSF_ID>
<StartDate>08/31/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rehabilitation Institute of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606113167</ZipCode>
<PhoneNumber>3122385195</PhoneNumber>
<StreetAddress>355 East Erie Street</StreetAddress>
<StreetAddress2><![CDATA[ATTN: Research Administration]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>068477546</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REHABILITATION INSTITUTE OF CHICAGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068477546</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rehabilitation Institute of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606112654</ZipCode>
<StreetAddress><![CDATA[345 E. Superior Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>092E</Code>
<Text>Control systems &amp; applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~302981</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we workded to create generic high-level control systems for robotic, prosthetic, and exoskeleton locomotion. We began by collecting a set of baseline data from non-impaired individuals as they ambulated through continuous locomotion circuits. These included sit/stand transitions, walking, ambultating up and down stairs and up and down ramps, and included seamless transitions between activities. From these data, which we published as an open dataset, we used machine learning to recognize activities from bilateral sensor sets that included EMG, inertial and kinematic sensor sets. Next, we used our develop algorihtms to control a robotic knee/anke prosthesis while a transfemoral amputee was ambulating. Next, we used deep neural networks to create generative models that allowed our control approach to work accross users, across days, and across devices. The impact of this particular portion of the work is that it alows for controllers to be trained with a much less training data. From a clinical perspective, this reduces the amount of time a user needs to work in a controlled clinical setting while data are recorded while they ambulate with the devices. We plan to continue this work by explore how the approach may be extended to include images, with the goal of having a generalized controller that makes use of whatever sensor set is available.&nbsp;</p><br> <p>            Last Modified: 12/17/2019<br>      Modified by: Levi&nbsp;Hargrove</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we workded to create generic high-level control systems for robotic, prosthetic, and exoskeleton locomotion. We began by collecting a set of baseline data from non-impaired individuals as they ambulated through continuous locomotion circuits. These included sit/stand transitions, walking, ambultating up and down stairs and up and down ramps, and included seamless transitions between activities. From these data, which we published as an open dataset, we used machine learning to recognize activities from bilateral sensor sets that included EMG, inertial and kinematic sensor sets. Next, we used our develop algorihtms to control a robotic knee/anke prosthesis while a transfemoral amputee was ambulating. Next, we used deep neural networks to create generative models that allowed our control approach to work accross users, across days, and across devices. The impact of this particular portion of the work is that it alows for controllers to be trained with a much less training data. From a clinical perspective, this reduces the amount of time a user needs to work in a controlled clinical setting while data are recorded while they ambulate with the devices. We plan to continue this work by explore how the approach may be extended to include images, with the goal of having a generalized controller that makes use of whatever sensor set is available.        Last Modified: 12/17/2019       Submitted by: Levi Hargrove]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
