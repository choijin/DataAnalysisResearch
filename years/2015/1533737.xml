<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS: FULL: CCA: Collaborative Research: Automatically Scalable Computation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>525000.00</AwardTotalIntnAmount>
<AwardAmount>525000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For over thirty years, each generation of computers has been faster than the one that preceded it. This exponential scaling transformed the way we communicate, navigate, purchase, and conduct science. More recently, this dramatic growth in single processor performance has stopped and has been replaced by new generations of computers with more processors on them; for example, even the cell phones we carry have multiple processors in them.  Writing software that effectively leverages multiple processing elements is difficult, and rewriting the decades of accumulated software is both difficult and costly. This research takes a different approach -- rather than converting sequential software into parallel software, this project develops ways to store and reuse computation. Imagine computing only when computer time and energy are cheap and plentiful, storing that computation, and then using it later, when computation might be limited or expensive.  The approach used involves making informed predictions about computation likely to happen in the future, proactively executing likely computations in parallel with the actual computation, and then "jumping forward in time" if the actual execution arrives at any of the predicted computations that have already been completed.  This research touches many areas within Computer Science, architecture, compilers, machine learning, systems, and theory.  Additionally, exploiting massively parallel computation will produce immediate returns in multiple scientific fields that rely on computation.&lt;br/&gt;&lt;br/&gt;The approach used in this research views computational execution as moving a system through the enormously high dimensional space represented by its registers and memory of a conventional single-threaded processor.  It uses machine learning algorithms to observe execution patterns and make predictions about likely future states of the computation.  Based on these predictions, the system launches potentially large numbers of speculative threads to execute from these likely computations, while the actual computation proceeds serially.  At strategically chosen points, the main computation queries the speculative executions to determine if any of the completed computation is useful; if it is, the main thread uses the speculative computation to immediately begin execution where the speculative computation left off, achieving a speed-up over the serial execution.  This approach has the potential to be extremely scalable: the more cores, memory, and communication bandwidth available, the greater the potential for performance improvement. The approach also scales across programs -- if the program running today happens upon a state encountered by a program running yesterday, the program can reuse yesterday's computation. This project has the potential to break new ground for research in many areas in Computer Science touched by it.</AbstractNarration>
<MinAmdLetterDate>07/27/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1533737</AwardID>
<Investigator>
<FirstName>Margo</FirstName>
<LastName>Seltzer</LastName>
<PI_MID_INIT>I</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Margo I Seltzer</PI_FULL_NAME>
<EmailAddress>margo@eecs.harvard.edu</EmailAddress>
<PI_PHON>6174965663</PI_PHON>
<NSF_ID>000146422</NSF_ID>
<StartDate>07/27/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Brooks</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David M Brooks</PI_FULL_NAME>
<EmailAddress>dbrooks@eecs.harvard.edu</EmailAddress>
<PI_PHON>6174953989</PI_PHON>
<NSF_ID>000091383</NSF_ID>
<StartDate>07/27/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ryan</FirstName>
<LastName>Adams</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ryan P Adams</PI_FULL_NAME>
<EmailAddress>rpa@princeton.edu</EmailAddress>
<PI_PHON>6092584651</PI_PHON>
<NSF_ID>000623159</NSF_ID>
<StartDate>07/27/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021384401</ZipCode>
<StreetAddress><![CDATA[33 Oxford Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8283</Code>
<Text>Exploiting Parallel&amp;Scalabilty</Text>
</ProgramElement>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~525000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The performance of computer programs is inherently limited by the difficulty of executing multiple portions of the application in parallel. Writing parallel programs is difficult, even for expert programmers, and hence many programs are still written in serial fashion. The goal of this project is to develop a practical approach to parallelism using coarse-grain speculative execution, learning, and prediction. The goal of this project is &ldquo;Automatically Scalable Computing&rdquo; (ASC) in which a machine learning system can assist with this problem. Effectively, the question we seek to answer if whether it is possible to we train a system to automatically find parallelism.</p> <p>&nbsp;</p> <p>The project has had several major foci of investigation:</p> <p>1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Identification of locations in the program that are amenable for prediction and development of prediction algorithms to accurately predict the future state of a program;</p> <p>2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Finding what applications this applications this approach might be useful for.</p> <p>3)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Understanding the hardware support necessary to take advantage of this information in order to make the program run faster.</p> <p>&nbsp;</p> <p>Work in the project demonstrated the overall merit of the ASC approach for speeding up applications. Further work was necessary to show how to build computers that could practically take advantage of this. One fundamental problem is that machine learning algorithms are themselves quite costly to implement. Hence, a major challenge in this project was to understand the hardware support necessary to enable the ASC vision. At the project outset very little research had been performed on hardware support for efficient machine learning. The cost of machine learning training and prediction on general-purpose computers was known to be quite high in energy and latency. However, over the past two years many machine learning accelerators have been deployed for both cloud and edge computing devices, and many more are under active research and development. While these accelerators have primarily been developed for existing applications leveraging deep neural networks for computer vision (CV) and natural language processing (NLP), they have the potential to impact many other applications, including techniques such as ASC. The project has undertaken the benchmarking and workload characterization of modern machine learning hardware platforms across a range of different applications. This will ultimately allow us to understand where modern hardware designed for ML can be applied to broader problems like the needs of ASC.</p> <p>&nbsp;</p> <p>Education has been an important focus throughout the duration of the project. The team included a postdocs and several graduate students and several undergraduates at Harvard University. This included two female PhD students, one of whom recently completed the PhD and is a researcher in US industry.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/29/2020<br>      Modified by: David&nbsp;M&nbsp;Brooks</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The performance of computer programs is inherently limited by the difficulty of executing multiple portions of the application in parallel. Writing parallel programs is difficult, even for expert programmers, and hence many programs are still written in serial fashion. The goal of this project is to develop a practical approach to parallelism using coarse-grain speculative execution, learning, and prediction. The goal of this project is "Automatically Scalable Computing" (ASC) in which a machine learning system can assist with this problem. Effectively, the question we seek to answer if whether it is possible to we train a system to automatically find parallelism.     The project has had several major foci of investigation:  1)         Identification of locations in the program that are amenable for prediction and development of prediction algorithms to accurately predict the future state of a program;  2)         Finding what applications this applications this approach might be useful for.  3)         Understanding the hardware support necessary to take advantage of this information in order to make the program run faster.     Work in the project demonstrated the overall merit of the ASC approach for speeding up applications. Further work was necessary to show how to build computers that could practically take advantage of this. One fundamental problem is that machine learning algorithms are themselves quite costly to implement. Hence, a major challenge in this project was to understand the hardware support necessary to enable the ASC vision. At the project outset very little research had been performed on hardware support for efficient machine learning. The cost of machine learning training and prediction on general-purpose computers was known to be quite high in energy and latency. However, over the past two years many machine learning accelerators have been deployed for both cloud and edge computing devices, and many more are under active research and development. While these accelerators have primarily been developed for existing applications leveraging deep neural networks for computer vision (CV) and natural language processing (NLP), they have the potential to impact many other applications, including techniques such as ASC. The project has undertaken the benchmarking and workload characterization of modern machine learning hardware platforms across a range of different applications. This will ultimately allow us to understand where modern hardware designed for ML can be applied to broader problems like the needs of ASC.     Education has been an important focus throughout the duration of the project. The team included a postdocs and several graduate students and several undergraduates at Harvard University. This included two female PhD students, one of whom recently completed the PhD and is a researcher in US industry.          Last Modified: 10/29/2020       Submitted by: David M Brooks]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
