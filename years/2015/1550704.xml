<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  Mining Seismic Wavefields</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2016</AwardEffectiveDate>
<AwardExpirationDate>04/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>198002.00</AwardTotalIntnAmount>
<AwardAmount>198002</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>06030000</Code>
<Directorate>
<Abbreviation>GEO</Abbreviation>
<LongName>Directorate For Geosciences</LongName>
</Directorate>
<Division>
<Abbreviation>EAR</Abbreviation>
<LongName>Division Of Earth Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Margaret Benoit</SignBlockName>
<PO_EMAI>mbenoit@nsf.gov</PO_EMAI>
<PO_PHON>7032927233</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A working group of the Southern California Earthquake Center (SCEC) will develop and deploy cyberinfrastructure for mining seismic wavefields through data intensive computing techniques in order to extend similarity search for earthquake detection to massive data sets. Similarity search has been used to understand the mechanics of tectonic tremor, transform our understanding of the depth dependence of faulting, illuminate diffusion within aftershock seismicity, and reveal new insights into induced earthquakes. These results were achieved with modest data volumes ? from ~ 10 seismic stations spanning ~ 10 km ? yet they increased the number of detected earthquakes by a factor of 10 to 100. This geoinformatics project will develop the cyberinfrastructure required to enable high-sensitivity studies of earthquake processes through the discovery of previously undetected seismic events within massive data volumes.&lt;br/&gt;&lt;br/&gt;This goal of this project is to develop a cyberinfrastructure to mine seismic waveform data. The effort will develop methods and hardware to use coherent signal processing on very large waveform databases to detect, locate and characterize events that cannot be detected by standard network operations (detection of single arrivals, association, location by optimization). &lt;br/&gt;&lt;br/&gt;The methodology involves the use of a network-based approach for earthquake detection, especially weak and unusual events that in the current method of treating signals individually go unreported. The PIs will work on the large T and the large N problem, where large T is using waveform similarity of multiple events over time to detect earthquakes over long periods of time; and the large N is using waveform similarity of single events over space as recorded on a dense seismic array with up to thousands of stations.&lt;br/&gt;&lt;br/&gt;The results will greatly increase knowledge of the number of seismic sources of various kinds and potentially identify patterns in earthquake occurrence that could inform hazard and near-term rupture forecasting. Seismicity induced by human activities is an emerging problem that adversely affects energy options for the 21st century, including shale gas development, enhanced geothermal energy, and carbon sequestration. A more complete view of seismicity related to these activities is essential to managing the risks they pose.</AbstractNarration>
<MinAmdLetterDate>05/03/2016</MinAmdLetterDate>
<MaxAmdLetterDate>05/03/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.050</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1550704</AwardID>
<Investigator>
<FirstName>Egill</FirstName>
<LastName>Hauksson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Egill Hauksson</PI_FULL_NAME>
<EmailAddress>hauksson@caltech.edu</EmailAddress>
<PI_PHON>6263956954</PI_PHON>
<NSF_ID>000172125</NSF_ID>
<StartDate>05/03/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>California Institute of Technology</Name>
<CityName>PASADENA</CityName>
<ZipCode>911250600</ZipCode>
<PhoneNumber>6263956219</PhoneNumber>
<StreetAddress>1200 E California Blvd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code 273-6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009584210</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CALIFORNIA INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009584210</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[California Institute of Technology]]></Name>
<CityName>Pasadena</CityName>
<StateCode>CA</StateCode>
<ZipCode>911250001</ZipCode>
<StreetAddress><![CDATA[1200 East California Blvd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7255</Code>
<Text>GEOINFORMATICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7726</Code>
<Text>Data Cyberinfrastructure</Text>
</ProgramElement>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~198002</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the last twenty years, earthquake detection rates in southern California have improved dramatically, resulting in the minimum magnitude of completeness decreasing from M~2.5 to M~1.5 today. It is believed, however, that these events still constitute less than 10% of all earthquake activity that is being recorded by the seismic network on a regular basis.&nbsp;Earthquakes follow a well-known power-law size relation, with smaller events occurring much more often than larger events. Earthquake catalogs are thus dominated by small earthquakes yet are still missing a much larger number of even smaller events because of signal fidelity issues.&nbsp;To address these shortcomings, we applied a matched filter (template matching) algorithm (QTMatch) to the entire continuous waveform archive of the Southern California Seismic Network using the seismograms of ~300,000 past events as templates. This GPU supercomputing effort resulted in a catalog of ~1.8 million earthquakes for the period 2008-2017, which is ~13 times as many events as the standard regional catalog, and a completeness magnitude of ~0.5.&nbsp;&nbsp;The rich detail resolved in this type of catalog will facilitate the next generation of analyses of earthquakes and faults.&nbsp;</p> <p>As seismologists detect increasingly smaller earthquakes, the average time between observed events continues to decrease, revealing more-complex dynamical behavior. These rich spatiotemporal patterns provide valuable constraints on the physics of earthquakes and faults, thus reflecting properties of the underlying fault structure and the various mechanisms and external loadings that can trigger earthquakes, and may also provide additional information on the rupture process of individual events.&nbsp;We have used the relocated seismicity to investigate connections between properties of fault zones and earthquake rupture processes. As an example, we were able to separate out signals from the after slip and fluid diffusion as it swept through a fault fracture mess following the Mw7.2 El Mayor-Cucapha earthquake. As we continue our synthesis, the unprecedented level of detail in this next-generation seismicity catalog is expected to facilitate important new analyses of earthquakes and faults in southern California.&nbsp;&nbsp;By extending the minimum magnitude of completeness down by more than a full magnitude unit over a decadal time period, the earthquake catalog produced in this study is the most comprehensive to date, and going forward, such catalogs will facilitate the next generation of analyses of earthquakes and faults.&nbsp;</p> <p>This research has created opportunities for students and early career scientists (both geoscience and computational science students and a postdoc at four institutions) to learn and apply techniques of data intensive computing to earthquake science problems.&nbsp;&nbsp;The complementary nature of the approaches we applied has allowed us to compare their output and assess their performance.&nbsp;&nbsp;Data-intensive computing approaches have had limited impact in seismology.&nbsp;&nbsp;As other studies follow, this research will have the potential for exceptionally broad impact because earthquake detection is foundational to seismology at all scales.&nbsp;Moreover, seismicity induced by human activities is an emerging problem that adversely affects energy options for the 21st century, including: shale gas development, enhanced geothermal energy, and carbon sequestration. A more complete view of seismicity related to these activities is essential to managing the risks they pose. Low cost, capable sensor technology is poised to increase data rates dramatically, and earthquake seismology is under-prepared for this. The long-term potential impact in the field of seismology is also improved understanding of the relationship between small and big earthquakes as well as tectonic structures.&nbsp;&nbsp;Also, this type of data processing could potentially be brought into the real-time arena, and used to provide real-time information for rapid earthquake and volcano hazards estimates. &nbsp;</p><br> <p>            Last Modified: 05/07/2020<br>      Modified by: Egill&nbsp;Hauksson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the last twenty years, earthquake detection rates in southern California have improved dramatically, resulting in the minimum magnitude of completeness decreasing from M~2.5 to M~1.5 today. It is believed, however, that these events still constitute less than 10% of all earthquake activity that is being recorded by the seismic network on a regular basis. Earthquakes follow a well-known power-law size relation, with smaller events occurring much more often than larger events. Earthquake catalogs are thus dominated by small earthquakes yet are still missing a much larger number of even smaller events because of signal fidelity issues. To address these shortcomings, we applied a matched filter (template matching) algorithm (QTMatch) to the entire continuous waveform archive of the Southern California Seismic Network using the seismograms of ~300,000 past events as templates. This GPU supercomputing effort resulted in a catalog of ~1.8 million earthquakes for the period 2008-2017, which is ~13 times as many events as the standard regional catalog, and a completeness magnitude of ~0.5.  The rich detail resolved in this type of catalog will facilitate the next generation of analyses of earthquakes and faults.   As seismologists detect increasingly smaller earthquakes, the average time between observed events continues to decrease, revealing more-complex dynamical behavior. These rich spatiotemporal patterns provide valuable constraints on the physics of earthquakes and faults, thus reflecting properties of the underlying fault structure and the various mechanisms and external loadings that can trigger earthquakes, and may also provide additional information on the rupture process of individual events. We have used the relocated seismicity to investigate connections between properties of fault zones and earthquake rupture processes. As an example, we were able to separate out signals from the after slip and fluid diffusion as it swept through a fault fracture mess following the Mw7.2 El Mayor-Cucapha earthquake. As we continue our synthesis, the unprecedented level of detail in this next-generation seismicity catalog is expected to facilitate important new analyses of earthquakes and faults in southern California.  By extending the minimum magnitude of completeness down by more than a full magnitude unit over a decadal time period, the earthquake catalog produced in this study is the most comprehensive to date, and going forward, such catalogs will facilitate the next generation of analyses of earthquakes and faults.   This research has created opportunities for students and early career scientists (both geoscience and computational science students and a postdoc at four institutions) to learn and apply techniques of data intensive computing to earthquake science problems.  The complementary nature of the approaches we applied has allowed us to compare their output and assess their performance.  Data-intensive computing approaches have had limited impact in seismology.  As other studies follow, this research will have the potential for exceptionally broad impact because earthquake detection is foundational to seismology at all scales. Moreover, seismicity induced by human activities is an emerging problem that adversely affects energy options for the 21st century, including: shale gas development, enhanced geothermal energy, and carbon sequestration. A more complete view of seismicity related to these activities is essential to managing the risks they pose. Low cost, capable sensor technology is poised to increase data rates dramatically, and earthquake seismology is under-prepared for this. The long-term potential impact in the field of seismology is also improved understanding of the relationship between small and big earthquakes as well as tectonic structures.  Also, this type of data processing could potentially be brought into the real-time arena, and used to provide real-time information for rapid earthquake and volcano hazards estimates.         Last Modified: 05/07/2020       Submitted by: Egill Hauksson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
