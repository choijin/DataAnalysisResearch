<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: A Distributed Approximate Dynamic Programming Approach for Robust Adaptive Control of Multiscale Dynamical Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>182032.00</AwardTotalIntnAmount>
<AwardAmount>182032</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Usha Varshney</SignBlockName>
<PO_EMAI>uvarshne@nsf.gov</PO_EMAI>
<PO_PHON>7032925385</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will develop a new type of general multiagent system for management and control of complex systems, in which the agents work together in a fully cooperative way to maximize global performance over time, in the face of nonlinearity and complexity. As a testbed to prove the value of the new approach, they will simulate the challenges of: (1) earthquake response, representing a class of disasters with very rapid occurrence, short lead times and restricted geographic extent; and (2) drought-induced famine relief, representing the class of disasters with longer forecast and lead times, and larger geographic extent. The results will be widely disseminated and will feed into programs for education and outreach, including a Research Experience for Undergraduates (REU) site at Duke and the NSF-funded IGERT on Wireless Intelligent Sensor Networks, feeding into summer schools and international partnerships.&lt;br/&gt;&lt;br/&gt;The key challenge here is to develop a new version of adaptive, approximate dynamic programming (ADP) which is fully distributed,&lt;br/&gt;to address the case of multiscale dynamical systems. The work builds on recent work of the lead PI on Distributed Optimal Control (DOC), and includes development of optimal restriction operators for dimensionality reduction in parts of the system, and exploitation of methods from the field of partial differential equations (PDE) and stochastic differential equations (SDE).</AbstractNarration>
<MinAmdLetterDate>09/21/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/21/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1556900</AwardID>
<Investigator>
<FirstName>Silvia</FirstName>
<LastName>Ferrari</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Silvia Ferrari</PI_FULL_NAME>
<EmailAddress>ferrari@cornell.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000484512</NSF_ID>
<StartDate>09/21/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~182032</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Traditionally, approximate dynamic programming (ADP) methods for feedback control have dealt with a single dynamical system, such as a vehicle or chemical process, modeled by a small set of ordinary differential equations. However, in many complex systems of current interest, ranging from robotics to chemical processes, the goal is to optimally control numerous interacting dynamical systems or agents. For many of these systems, descriptions are known at the microscopic level, but the closures required to translate them to a high-level macroscopic description, which typically amounts to a partial differential equation (PDE), are not available. In this project, optimal control and ADP were used to control to a new class of dynamical systems by considering a set of coupled differential equations, and by formulating their cooperative performance as an integral cost function of the combined state and control vectors. The computational complexity associated with solving recurrence relationships or optimality conditions for large-scale dynamical system can become prohibitive when the number of agents is very large. This project was able to develop new theory and algorithms that extend the applicability of ADP to multiscale dynamical systems, and demonstrate the novel approaches through simulated humanitarian response systems and applications. In particular, the method was simulated on a problem of gas dispersion in a large environment patrolled by autonomous collaborative agents that measure and map the gas concentration over time.</p><br> <p>            Last Modified: 01/27/2020<br>      Modified by: Silvia&nbsp;Ferrari</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Traditionally, approximate dynamic programming (ADP) methods for feedback control have dealt with a single dynamical system, such as a vehicle or chemical process, modeled by a small set of ordinary differential equations. However, in many complex systems of current interest, ranging from robotics to chemical processes, the goal is to optimally control numerous interacting dynamical systems or agents. For many of these systems, descriptions are known at the microscopic level, but the closures required to translate them to a high-level macroscopic description, which typically amounts to a partial differential equation (PDE), are not available. In this project, optimal control and ADP were used to control to a new class of dynamical systems by considering a set of coupled differential equations, and by formulating their cooperative performance as an integral cost function of the combined state and control vectors. The computational complexity associated with solving recurrence relationships or optimality conditions for large-scale dynamical system can become prohibitive when the number of agents is very large. This project was able to develop new theory and algorithms that extend the applicability of ADP to multiscale dynamical systems, and demonstrate the novel approaches through simulated humanitarian response systems and applications. In particular, the method was simulated on a problem of gas dispersion in a large environment patrolled by autonomous collaborative agents that measure and map the gas concentration over time.       Last Modified: 01/27/2020       Submitted by: Silvia Ferrari]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
