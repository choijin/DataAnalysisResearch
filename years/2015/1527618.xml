<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Learning Mixed Membership Models with a Separable Latent Structure: theory, provably efficient algorithms, and applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In a wide spectrum of problems in science and engineering that includes hyperspectral imaging, gene expression analysis, and metabolic networks, the observed data is high-dimensional and arises from an unknown random mixture of a small set of unknown shared latent (hidden) causes. Being able to successfully and efficiently identify the latent causes from the observed data is important not only for scientific understanding, but also for efficient data representation and decision making. Popular algorithms for such problems make use of approximations and heuristics for computational tractability.  As a consequence, consistency or efficiency guarantees for such algorithms are either very weak or nonexistent. This research involves the development of algorithms for learning latent-cause models from high-dimensional data with provable statistical and computational efficiency guarantees.&lt;br/&gt;&lt;br/&gt;The linchpin of this research is a natural separability property of the shared latent factors ? the presence of a signature component for each latent factor ? that is approximately satisfied by the estimates produced by popular approaches. This research aims to establish that approximate separability is not only a natural and convenient structural property of mixed-membership latent-factor models, but is, in fact, an inevitable consequence of high-dimensionality. This research also involves the development of a suite of provably consistent and statistically and computationally efficient algorithms for a diverse set of mixed-membership latent-factor problems by suitably leveraging the geometry induced by the signature components. The key insight is to identify the signature parts of each latent factor as extreme points in a suitable space. This can be done efficiently through appropriately defined random projections. The random-projections-based algorithm is naturally amenable to a low-communication-cost distributed implementation that is attractive for web-scale distributed data-mining applications.</AbstractNarration>
<MinAmdLetterDate>07/09/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/09/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1527618</AwardID>
<Investigator>
<FirstName>Venkatesh</FirstName>
<LastName>Saligrama</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Venkatesh Saligrama</PI_FULL_NAME>
<EmailAddress>srv@bu.edu</EmailAddress>
<PI_PHON>6173531040</PI_PHON>
<NSF_ID>000308822</NSF_ID>
<StartDate>07/09/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Prakash</FirstName>
<LastName>Ishwar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Prakash Ishwar</PI_FULL_NAME>
<EmailAddress>pi@bu.edu</EmailAddress>
<PI_PHON>6173583499</PI_PHON>
<NSF_ID>000310021</NSF_ID>
<StartDate>07/09/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName/>
<StateCode>MA</StateCode>
<ZipCode>022151300</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Today there is an abundance of complex data in almost every field of human activity ranging from e-commerce and social media to neuroscience and genetics. The data is typically high-dimensional, i.e., it is composed of building blocks drawn from a large repository, e.g., the inventory of all items in an online store, the vocabulary of all words used in news articles or social messaging platforms, the pixels in a high-resolution image or video, genes regulating protein production, neurons in the brain, etc.&nbsp; Despite the vast size of the repository, only a few "hidden patterns" of the building blocks are actually responsible for the observed data. This project developed computationally efficient algorithms for learning hidden patterns in high-dimensional datasets, analyzed their properties using mathematical tools, established theoretical conditions under which they will succeed in learning the hidden patterns or fail, and comprehensively validated their performance against competing methods on both simulated and real-world datasets. Such fundamental theoretical results and new methods for discovering hidden structure in high-dimensional datasets improve our ability to uncover new phenomena, advance our understanding of existing phenomena, make reliable predictions possible, and enable the design of optimal systems in a number of disciplines from biology to social science.</p> <p><strong>Intellectual Merit:</strong> The project investigated four hidden pattern discovery problems: 1) Discovering latent topics within collections of text documents 2) Discovering latent preference-patterns underlying item-choices made by a population of users 3) Discovering latent communities of interacting entities within a network and 4) Discovering subtle changes in the interaction-pattern between entities within a network.</p> <p>For latent topic discovery, the project mathematically proved that if the size of the vocabulary is sufficiently larger than the number of topics, then under some additional technical conditions, every topic will have one or more "signature words", i.e., words that occur predominantly in one topic but in none of the others. Conditions were identified that are both necessary and sufficient to ensure that such topics can be successfully learned from a sufficiently large corpus of documents. These theoretical insights were leveraged to design a computationally efficient algorithm to successfully learn the latent topics and their performance was validated in simulated and real-world text corpora.</p> <p>For latent preference discovery, the project first made an intriguing connection between topic discovery in text documents and preference discovery in user choices. The key insight was to re-express the ratings or rankings of items given by users in terms of binary choices between pairs of items and then to identify these pairs as "words" and the latent preferences as topics. Thereafter, the techniques that were developed for discovering topics were successfully transplanted to solve the corresponding problem of discovering latent preferences. &nbsp;&nbsp;</p> <p>For community discovery in networks, the project first made an ingenious connection between sentences of words in a text document and random walks of nodes in a network. Communities in a network then become the counterparts of word-clusters. In the field of Natural Language Processing (NLP), a powerful framework to solve a variety of problems, such as finding word analogies or recognizing named entities, is to represent them geometrically as vectors. A number of well-established methods have been developed to learn such representations. The project leveraged these methods to learn geometric representations of nodes in a network and then discover communities by clustering them.&nbsp; A number of theoretical properties of the new method for community discovery were established and the performance of the new approach was validated through a comprehensive set of experiments on both simulated and real-world data. Empirical results demonstrate that the new method performs consistently better than benchmark methods across a wide range of community connectivity levels.</p> <p>The problem of testing changes in community structures naturally arises in applications such as identifying differences in brain networks between healthy and diseased individuals or deciding whether there are changes in functional modules in protein-protein networks. This project investigated and established the limits to which it is feasible to test differences in the underlying community structure of a network. Results reveal that it is possible to reliably discover <em>changes</em> in community structure in a broad class of networks even when it may not be possible to reliably identify the communities themselves.</p> <p><strong>Broader Impact:</strong> Topic discovery methods were used to analyze social media text through a cross-disciplinary collaborative effort with a colleague in emerging media and communication at Boston University. This project has contributed to bridge the areas of NLP and Network Science by leveraging word embedding ideas from NLP to develop novel counterparts for nodes in graphs and use them to solve community discovery problems in networks. The random-walk-based method for community detection was applied to networks that arise in emerging media studies to discover the latent framing perspectives of news articles (economic, political, cultural, health, etc.).</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/27/2020<br>      Modified by: Venkatesh&nbsp;Saligrama</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Today there is an abundance of complex data in almost every field of human activity ranging from e-commerce and social media to neuroscience and genetics. The data is typically high-dimensional, i.e., it is composed of building blocks drawn from a large repository, e.g., the inventory of all items in an online store, the vocabulary of all words used in news articles or social messaging platforms, the pixels in a high-resolution image or video, genes regulating protein production, neurons in the brain, etc.  Despite the vast size of the repository, only a few "hidden patterns" of the building blocks are actually responsible for the observed data. This project developed computationally efficient algorithms for learning hidden patterns in high-dimensional datasets, analyzed their properties using mathematical tools, established theoretical conditions under which they will succeed in learning the hidden patterns or fail, and comprehensively validated their performance against competing methods on both simulated and real-world datasets. Such fundamental theoretical results and new methods for discovering hidden structure in high-dimensional datasets improve our ability to uncover new phenomena, advance our understanding of existing phenomena, make reliable predictions possible, and enable the design of optimal systems in a number of disciplines from biology to social science.  Intellectual Merit: The project investigated four hidden pattern discovery problems: 1) Discovering latent topics within collections of text documents 2) Discovering latent preference-patterns underlying item-choices made by a population of users 3) Discovering latent communities of interacting entities within a network and 4) Discovering subtle changes in the interaction-pattern between entities within a network.  For latent topic discovery, the project mathematically proved that if the size of the vocabulary is sufficiently larger than the number of topics, then under some additional technical conditions, every topic will have one or more "signature words", i.e., words that occur predominantly in one topic but in none of the others. Conditions were identified that are both necessary and sufficient to ensure that such topics can be successfully learned from a sufficiently large corpus of documents. These theoretical insights were leveraged to design a computationally efficient algorithm to successfully learn the latent topics and their performance was validated in simulated and real-world text corpora.  For latent preference discovery, the project first made an intriguing connection between topic discovery in text documents and preference discovery in user choices. The key insight was to re-express the ratings or rankings of items given by users in terms of binary choices between pairs of items and then to identify these pairs as "words" and the latent preferences as topics. Thereafter, the techniques that were developed for discovering topics were successfully transplanted to solve the corresponding problem of discovering latent preferences.     For community discovery in networks, the project first made an ingenious connection between sentences of words in a text document and random walks of nodes in a network. Communities in a network then become the counterparts of word-clusters. In the field of Natural Language Processing (NLP), a powerful framework to solve a variety of problems, such as finding word analogies or recognizing named entities, is to represent them geometrically as vectors. A number of well-established methods have been developed to learn such representations. The project leveraged these methods to learn geometric representations of nodes in a network and then discover communities by clustering them.  A number of theoretical properties of the new method for community discovery were established and the performance of the new approach was validated through a comprehensive set of experiments on both simulated and real-world data. Empirical results demonstrate that the new method performs consistently better than benchmark methods across a wide range of community connectivity levels.  The problem of testing changes in community structures naturally arises in applications such as identifying differences in brain networks between healthy and diseased individuals or deciding whether there are changes in functional modules in protein-protein networks. This project investigated and established the limits to which it is feasible to test differences in the underlying community structure of a network. Results reveal that it is possible to reliably discover changes in community structure in a broad class of networks even when it may not be possible to reliably identify the communities themselves.  Broader Impact: Topic discovery methods were used to analyze social media text through a cross-disciplinary collaborative effort with a colleague in emerging media and communication at Boston University. This project has contributed to bridge the areas of NLP and Network Science by leveraging word embedding ideas from NLP to develop novel counterparts for nodes in graphs and use them to solve community discovery problems in networks. The random-walk-based method for community detection was applied to networks that arise in emerging media studies to discover the latent framing perspectives of news articles (economic, political, cultural, health, etc.).          Last Modified: 12/27/2020       Submitted by: Venkatesh Saligrama]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
