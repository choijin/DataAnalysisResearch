<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Novel Statistical Framework for Big Data Prediction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent advances in genome-wide association studies (GWAS) have led to both an increase in the size of genetic data available and identification of important genetic variants responsible for a variety of diseases.  Prediction for these genetic diseases has also become of paramount importance.  However, prediction for big data such as GWAS is not trivial.  A key obstacle in big data prediction is identifying (perhaps a small number of) variable sets that lead to good prediction when variable dimensionality can be extremely large.   The project explores why a common approach towards prediction can often fail to deliver strong prediction rates.   A novel, interaction-based and prediction-oriented approach to extracting hidden information contained in big data will be investigated.  To improve prediction, a new criterion to guide the selection of variable sets will be developed.&lt;br/&gt;&lt;br/&gt;Prioritizing predictivity, not significance, requires using the correct estimates of prediction rates and developing predictivity-based criteria to evaluate variable sets.   The project offers a novel theoretical framework by characterizing what makes for highly predictive variable sets, and providing fundamental work towards a new criterion to identify these sets.   In the framework of this research project, variable sets have theoretical (true) levels of predictivity, which can be estimated with appropriately designed sample-based measures.  This framework is the first that seeks to develop estimators specific to a criterion of predictivity.   Additionally, methods that encompass both marginal and joint effects will be investigated, and a candidate measure of predictivity will be studied.  Four real data examples are analyzed to illustrate how final predictors found via the new approach compare to other approaches in the current literature.</AbstractNarration>
<MinAmdLetterDate>08/31/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1513408</AwardID>
<Investigator>
<FirstName>Shaw-Hwa</FirstName>
<LastName>Lo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shaw-Hwa Lo</PI_FULL_NAME>
<EmailAddress>slo@stat.columbia.edu</EmailAddress>
<PI_PHON>2128512133</PI_PHON>
<NSF_ID>000471911</NSF_ID>
<StartDate>08/31/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tian</FirstName>
<LastName>Zheng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tian Zheng</PI_FULL_NAME>
<EmailAddress>tzheng@stat.columbia.edu</EmailAddress>
<PI_PHON>2128512134</PI_PHON>
<NSF_ID>000149965</NSF_ID>
<StartDate>08/31/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>100277922</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7275</Code>
<Text>Cross-BIO Activities</Text>
</ProgramElement>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<ProgramElement>
<Code>7658</Code>
<Text>Physiolgcl Mechnsms&amp;Biomechnsm</Text>
</ProgramElement>
<ProgramElement>
<Code>8011</Code>
<Text>Systems and Synthetic Biology</Text>
</ProgramElement>
<ProgramReference>
<Code>7465</Code>
<Text>NANOSCALE BIO CORE</Text>
</ProgramReference>
<ProgramReference>
<Code>8007</Code>
<Text>BioMaPS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><!--?xml version="1.0" encoding="UTF-8"?--></p> <div><span>Recent advances in technologies has led to both an increase in the size of data available as well as important data-driven findings. &nbsp;It has been long expected that such findings would lead to better prediction of important outcomes. For example, prediction for the risks of heritable diseases using genetic information (e.g., observations taken at millions of genetic variants across one?s genome) is of paramount importance. Such a task turns out to be non-trivial given the size of available data. A key obstacle in such big data prediction is identifying (perhaps, a small number of) variable sets that lead to good prediction when the variable dimensionality can be enormous.&nbsp;</span></div> <div><span><br /></span></div> <div><span>In this project, w</span><span>e illustrated that why a common significance-oriented approach towards predicting can fail to deliver strong prediction rates. We proposed and studied instead a novel, interaction-based and prediction-oriented approach to extract hidden information contained in big data. To improve prediction, we&nbsp;developed&nbsp;a new criteria to guide the selection of variable sets.&nbsp;</span><span>In particular, we showed that prioritizing predictivity, not significance, requires using the correct estimates of prediction rates and developing predictivity-based criteria to evaluate variable sets.&nbsp;</span><span>We introduced the Influence score, or "I-score," as a statistic correlated with how much variables inherently can predict, or "predictivity," which can consequently be used to identify highly predictive variables.&nbsp;</span><span>We provided a theoretical framework from which to design good measures of prediction in general. Importantly, we introduced a variable set's predictivity as a new parameter of interest to estimate, and provide the I-score as a candidate statistic to estimate variable set predictivity.&nbsp;</span><span>We demonstrated that the I-score can be used to compute a measure that asymptotically approaches predictivity. The I-score can effectively differentiate between noisy and predictive variables.&nbsp;</span></div> <div><span><br /></span></div> <div><span>We offered simulations and an application of the I-score on real data to demonstrate the statistic's predictive performance on sample data. These show that the I-score can capture highly predictive variable sets, estimates a lower bound for the theoretical correct prediction rate, and correlates well with the out of sample correct rate.&nbsp;</span></div><br> <p>            Last Modified: 11/25/2019<br>      Modified by: Tian&nbsp;Zheng</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1513408/1513408_10393883_1573585255835_F3.large--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1513408/1513408_10393883_1573585255835_F3.large--rgov-800width.jpg" title="Proposed new statistics track well with a variable set's potential predictivity"><img src="/por/images/Reports/POR/2019/1513408/1513408_10393883_1573585255835_F3.large--rgov-66x44.jpg" alt="Proposed new statistics track well with a variable set's potential predictivity"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Using simulation studies, we demonstrated that the proposed I-score reveal the potential finite-sample predictivity of a variable set.</div> <div class="imageCredit">Tian Zheng</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tian&nbsp;Zheng</div> <div class="imageTitle">Proposed new statistics track well with a variable set's potential predictivity</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1513408/1513408_10393883_1573585540283_figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1513408/1513408_10393883_1573585540283_figure1--rgov-800width.jpg" title="Statistically significant variable sets are not automatically predictive"><img src="/por/images/Reports/POR/2019/1513408/1513408_10393883_1573585540283_figure1--rgov-66x44.jpg" alt="Statistically significant variable sets are not automatically predictive"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Statistics used in test of significance are not necessarily good measure of predictivity. Variable sets identified using such test statistics may not overlap much with those that are highly predictive. As sample size increases, this overlap grows.</div> <div class="imageCredit">Tian Zheng</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tian&nbsp;Zheng</div> <div class="imageTitle">Statistically significant variable sets are not automatically predictive</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Recent advances in technologies has led to both an increase in the size of data available as well as important data-driven findings.  It has been long expected that such findings would lead to better prediction of important outcomes. For example, prediction for the risks of heritable diseases using genetic information (e.g., observations taken at millions of genetic variants across one?s genome) is of paramount importance. Such a task turns out to be non-trivial given the size of available data. A key obstacle in such big data prediction is identifying (perhaps, a small number of) variable sets that lead to good prediction when the variable dimensionality can be enormous.    In this project, we illustrated that why a common significance-oriented approach towards predicting can fail to deliver strong prediction rates. We proposed and studied instead a novel, interaction-based and prediction-oriented approach to extract hidden information contained in big data. To improve prediction, we developed a new criteria to guide the selection of variable sets. In particular, we showed that prioritizing predictivity, not significance, requires using the correct estimates of prediction rates and developing predictivity-based criteria to evaluate variable sets. We introduced the Influence score, or "I-score," as a statistic correlated with how much variables inherently can predict, or "predictivity," which can consequently be used to identify highly predictive variables. We provided a theoretical framework from which to design good measures of prediction in general. Importantly, we introduced a variable set's predictivity as a new parameter of interest to estimate, and provide the I-score as a candidate statistic to estimate variable set predictivity. We demonstrated that the I-score can be used to compute a measure that asymptotically approaches predictivity. The I-score can effectively differentiate between noisy and predictive variables.    We offered simulations and an application of the I-score on real data to demonstrate the statistic's predictive performance on sample data. These show that the I-score can capture highly predictive variable sets, estimates a lower bound for the theoretical correct prediction rate, and correlates well with the out of sample correct rate.        Last Modified: 11/25/2019       Submitted by: Tian Zheng]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
