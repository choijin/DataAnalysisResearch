<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Nonlinear Dimension Reduction Methods</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In the era of Big Data, technological advances have brought significant changes in the amount and the complexity of data generated in almost every discipline from astronomy to genomics to medicine. It has become an essential component of the intellectual endeavor to find meaningful patterns and extract relevant information from large scale, high-dimensional data in a reliable and efficient fashion. Understanding and capturing the regular structures underlying the data is crucial for subsequent modeling and prediction. Low-dimensional projections of data are often primary tools for uncovering the structure and coping with high-dimensionality along with other techniques for sparsity or structural simplicity. Methods for dimension reduction will help the process of gathering information from data significantly. This project concerns nonlinear dimension reduction methods which can be viewed as an extension of standard principal component analysis (PCA) - a widely used tool for low-rank approximation of data. The research aims to expand the scope of PCA to various types of data from binary to ordinal responses to counts, and unravel the data embeddings given by nonlinear extensions of PCA. Enhanced understanding of the existing tools and the development of new tools in this research will improve statistical practice in many ways.&lt;br/&gt;&lt;br/&gt;This project is primarily focused on investigation of two nonlinear extensions of PCA: kernel PCA and generalized PCA, for various data types including the exponential family data. This research has two specific aims: (i) to understand the geometry of the nonlinear data embeddings given by the kernel PCA through the spectral analysis of the kernel operator, and the effect of a kernel and centering kernels on those nonlinear principal components for clustering  in relation to the data distribution, and (ii) to develop statistically principled extensions of the PCA methodology for analysis and modeling of data matrices from the exponential family distributions using generalized linear model framework. On the methodological aspect, the research parallels the coherent extension of linear model to generalized linear model framework for the best low-rank approximation of data. Computational tools will be developed for a wide range of applications of the studied methods.</AbstractNarration>
<MinAmdLetterDate>07/13/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/30/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1513566</AwardID>
<Investigator>
<FirstName>Yoonkyung</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yoonkyung Lee</PI_FULL_NAME>
<EmailAddress>yklee@stat.osu.edu</EmailAddress>
<PI_PHON>6142929495</PI_PHON>
<NSF_ID>000334037</NSF_ID>
<StartDate>07/13/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101247</ZipCode>
<StreetAddress><![CDATA[1958 Neil Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Salient features of multivariate observational data tend to be low dimensional due to correlation or other forms of dependency typically present among a large number of attributes. &nbsp;As a most common form of dimension reduction, principal components capture primary modes of variation in the data and help us uncover such a low dimensional latent structure underlying the data. This project developed new methods for coherent extension of standard principal component analysis to various types of data from the exponential family distributions. &nbsp;These new dimension reduction methods are useful for analyzing non-Gaussian multivariate data, a series of binary responses (e.g., yes/no responses in a questionnaire) and counts (e.g., word frequencies in a text) being primary examples. Such data types frequently arise in scientific investigations as well as in practical applications. For example, comorbidities can be studied from electronic health records with a set of binary indicators of medical conditions among patients. For the new methods, easy-to-use software was developed and made publicly available for use by the scientific community. &nbsp;</p> <p>In addition, this project examined nonlinear generalization of classical principal component analysis and linear discriminant analysis using kernels. In particular, it investigated the geometric relation between the data distribution and low dimensional embeddings corresponding to the kernel choice. The spectral analyses of data-dependent kernel covariance operators in the project illuminate how the data distribution and the kernel interact in determination of the resulting nonlinear embeddings to be used for data visualization, clustering, and classification. The insights from this research will be useful for applications of kernel methods in general.</p> <p>Moreover, this project led to many new research directions that are currently being pursued and provided opportunities for training graduate students. Several students earned their PhDs under the PI's direct supervision in conjunction with this project, and additional students are currently working with the PI on the related research projects. This project helped the students gain valuable research experience and further contributed to the development of workforce in data science.&nbsp;&nbsp;</p><br> <p>            Last Modified: 12/27/2020<br>      Modified by: Yoonkyung&nbsp;Lee</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Salient features of multivariate observational data tend to be low dimensional due to correlation or other forms of dependency typically present among a large number of attributes.  As a most common form of dimension reduction, principal components capture primary modes of variation in the data and help us uncover such a low dimensional latent structure underlying the data. This project developed new methods for coherent extension of standard principal component analysis to various types of data from the exponential family distributions.  These new dimension reduction methods are useful for analyzing non-Gaussian multivariate data, a series of binary responses (e.g., yes/no responses in a questionnaire) and counts (e.g., word frequencies in a text) being primary examples. Such data types frequently arise in scientific investigations as well as in practical applications. For example, comorbidities can be studied from electronic health records with a set of binary indicators of medical conditions among patients. For the new methods, easy-to-use software was developed and made publicly available for use by the scientific community.    In addition, this project examined nonlinear generalization of classical principal component analysis and linear discriminant analysis using kernels. In particular, it investigated the geometric relation between the data distribution and low dimensional embeddings corresponding to the kernel choice. The spectral analyses of data-dependent kernel covariance operators in the project illuminate how the data distribution and the kernel interact in determination of the resulting nonlinear embeddings to be used for data visualization, clustering, and classification. The insights from this research will be useful for applications of kernel methods in general.  Moreover, this project led to many new research directions that are currently being pursued and provided opportunities for training graduate students. Several students earned their PhDs under the PI's direct supervision in conjunction with this project, and additional students are currently working with the PI on the related research projects. This project helped the students gain valuable research experience and further contributed to the development of workforce in data science.         Last Modified: 12/27/2020       Submitted by: Yoonkyung Lee]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
