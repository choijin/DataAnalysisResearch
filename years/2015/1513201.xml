<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Medium: Energy Efficient Computing on GPU-based Heterogeneous Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2015</AwardEffectiveDate>
<AwardExpirationDate>05/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>750000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The current trend in designing future multiprocessors is to integrate hundreds of cores and hardware accelerators (HAs), such as GPUs, on a single platform. However, as the system size scales, the power and energy consumption of these heterogeneous multiprocessors vastly exceed the budget. The primary focus of the project is to develop energy efficient techniques that can be implemented in the GPU with proper coordination with the CPUs. Energy reduction in GPU-based heterogeneous multiprocessors can be achieved by extending current CPU techniques to GPU.  The project develops new runtime techniques for GPU core scaling and Dynamic Voltage and Frequency scaling (DVFS), and combines them with basic changes in algorithms and data structures to improve energy efficiency. &lt;br/&gt;&lt;br/&gt;Existing models for performance and energy consumption assume 100% utilization of the processing cores and perfect overlap with memory access during execution. This project develops a more accurate model for energy efficiency taking into account the algorithm, data structure, caching and memory coalescing for different applications. A runtime system is being developed that monitors the GPU core and memory utilizations together with the energy consumption while executing an application. The runtime adjusts the number of cores and/or frequency level dynamically through prediction, but continues to make corrections as the execution proceeds. The runtime is extended to heterogeneous systems consisting of both CPU and GPU.&lt;br/&gt;The current DVFS techniques for scientific computing applications cannot fully eliminate slacks, therefore, are not energy optimal. By leveraging the algorithmic characteristics, a frequency scheduling technique is developed for linear algebra applications to achieve better energy efficiency.&lt;br/&gt;The project optimizes the energy efficiency while partitioning and designing tasks of an application. Without loss of generality, Cholesky factorization is used as an example and an energy efficient scheduler is developed. &lt;br/&gt;&lt;br/&gt;The project develops software products that can be readily applied to existing large scale heterogeneous computers executing scientific applications that are suitable for defense, energy and critical infrastructure projects. Also applications like weather forecasting and structural dynamics are developed that have a great impact on society. The research content is integrated to graduate courses to provide training to students for designing and programming heterogeneous systems. The project aims to produce very high quality Ph.D. graduates including female students. The University of California, Riverside is known for its large proportion of Hispanic students, and UCR is a minority-serving institution. The project supports recruiting underrepresented minority and female students.</AbstractNarration>
<MinAmdLetterDate>06/15/2015</MinAmdLetterDate>
<MaxAmdLetterDate>06/30/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1513201</AwardID>
<Investigator>
<FirstName>Laxmi</FirstName>
<LastName>Bhuyan</LastName>
<PI_MID_INIT>N</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Laxmi N Bhuyan</PI_FULL_NAME>
<EmailAddress>bhuyan@cs.ucr.edu</EmailAddress>
<PI_PHON>9518272281</PI_PHON>
<NSF_ID>000318919</NSF_ID>
<StartDate>06/15/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zizhong</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zizhong Chen</PI_FULL_NAME>
<EmailAddress>chen@cs.ucr.edu</EmailAddress>
<PI_PHON>9518275639</PI_PHON>
<NSF_ID>000347508</NSF_ID>
<StartDate>06/15/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Riverside</Name>
<CityName>RIVERSIDE</CityName>
<ZipCode>925210217</ZipCode>
<PhoneNumber>9518275535</PhoneNumber>
<StreetAddress>Research &amp; Economic Development</StreetAddress>
<StreetAddress2><![CDATA[245 University Office Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>44</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA44</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>627797426</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Riverside]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>925210001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>41</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA41</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~250047</FUND_OBLG>
<FUND_OBLG>2016~499953</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The current trend in designing future multiprocessors is to integrate hundreds of cores and hardware accelerators (HAs), such as GPUs, on a single platform. However, as the system size scales, the power and energy consumption of these heterogeneous multiprocessors vastly exceed the budget. The primary focus of the project is to develop energy efficient techniques that can be implemented in the GPU with proper coordination with the CPUs. We develop new techniques to reduce GPU execution time and thus total energy consumption for both regular and irregular applications. We also design algorithms for scientific applications to save energy through dynamic voltage and frequency scaling (DVFS) and undervolting by combining them with changes in algorithms and data structures to improve energy efficiency.</p> <p>Intellectual Merit: The existence of data dependences across thread blocks may significantly impact the speedup by requiring global synchronization across multiprocessors (SMs) inside the GPU. Wavefront parallelism is a well-known technique to enable concurrent processing through barriers and is widely being used on GPUs. The project develops PeerWave, an alternative GPU&nbsp;wavefront parallelization technique that improves inter-SM&nbsp;load balance by using peer-wise synchronization between SMs&nbsp;and eliminating global synchronization.&nbsp;A hardware thread block (TB) scheduler is also designed that can schedule the TBs on the streaming multiprocessors (SMs) according to the data dependency between the TBs. Finally, a task-based execution scheme for GPU workloads with data dependences, called Juggler is proposed that takes applications embedding OpenMP 4.5 tasks as input and executes them on the GPU via an efficient in-device runtime, hence eliminating the need for kernel-wide global synchronization.</p> <p>The project also proposes schemes to reduce execution times of processing irregular graph processing applications.&nbsp;However, the inherent irregularity and large sizes of real-world&nbsp;power law graphs makes effective use of GPUs a&nbsp;major challenge. The project presents Warp&nbsp;Segmentation, a novel method that greatly enhances GPU&nbsp;device utilization by dynamically assigning appropriate number&nbsp;of SIMD threads to process a vertex with irregular-sized&nbsp;neighbors. We&nbsp;also present a software (compiler) technique named Collaborative Context Collection (CCC) that increases the&nbsp;warp execution effiuciency when faced with thread divergence incurred either by different intra-warp task assignment or by intra-warp load imbalance. Finally, we introduce a novel software technique named Collaborative Task Engagement (CTE) for efficient expression and execution of GPU kernels containing nested patterns.</p> <p>Improving the energy efficiency of commonly used libraries is an effective approach to energy efficient scientific computing. While many linear algebra libraries have been developed to optimize performance, no linear algebra library considers their energy efficiency at the library design time. In this project, we present GreenLA - an energy efficient linear algebra software package that leverages linear algebra algorithmic characteristics to maximize energy savings with negligible overhead. We analyze highly optimized dense matrix factorization algorithms including Cholesky, LU and QR factorizations. GreenLA exploits algorithmic knowledge of linear algebra operations to predict slack on CPU and GPU, and use application-level DVFS strategies to reclaim the&nbsp;slack for energy savings.</p> <p>Energy efficiency and resilience are two crucial challenges for High Performance Computing (HPC) systems to reach exascale. Decreasing the supply voltage associated with a given operating frequency for processors and other CMOS-based components can significantly reduce power consumption. However, this often raises system failure rates and consequently increases application execution time. In this project, we present GreenMM framework for matrix multiplication, which reduces energy consumption in GPUs through undervolting without sacrificing the performance. The idea is to undervolt the GPU beyond the minimum operating voltage (Vmin) to save maximum energy while keeping the frequency constant. Since such undervolting may give rise to faults, we design an Algorithm Based Fault Tolerance (ABFT) algorithm and checkpoint recovery technique to detect and correct those errors.</p> <p>Broader Impact: The project has given rise to many high-quality publications in top conferences like SC, HPDC and ICS. The project has supported several PhD students at University of California, Riverside. Two of them have graduated and joined Argonne National Lab. One of them later shifted to Colorado School of Mines and Technology as an Assistant Professor. One of the PhD students who was supported and is currently continuing is a female.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/24/2020<br>      Modified by: Laxmi&nbsp;N&nbsp;Bhuyan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The current trend in designing future multiprocessors is to integrate hundreds of cores and hardware accelerators (HAs), such as GPUs, on a single platform. However, as the system size scales, the power and energy consumption of these heterogeneous multiprocessors vastly exceed the budget. The primary focus of the project is to develop energy efficient techniques that can be implemented in the GPU with proper coordination with the CPUs. We develop new techniques to reduce GPU execution time and thus total energy consumption for both regular and irregular applications. We also design algorithms for scientific applications to save energy through dynamic voltage and frequency scaling (DVFS) and undervolting by combining them with changes in algorithms and data structures to improve energy efficiency.  Intellectual Merit: The existence of data dependences across thread blocks may significantly impact the speedup by requiring global synchronization across multiprocessors (SMs) inside the GPU. Wavefront parallelism is a well-known technique to enable concurrent processing through barriers and is widely being used on GPUs. The project develops PeerWave, an alternative GPU wavefront parallelization technique that improves inter-SM load balance by using peer-wise synchronization between SMs and eliminating global synchronization. A hardware thread block (TB) scheduler is also designed that can schedule the TBs on the streaming multiprocessors (SMs) according to the data dependency between the TBs. Finally, a task-based execution scheme for GPU workloads with data dependences, called Juggler is proposed that takes applications embedding OpenMP 4.5 tasks as input and executes them on the GPU via an efficient in-device runtime, hence eliminating the need for kernel-wide global synchronization.  The project also proposes schemes to reduce execution times of processing irregular graph processing applications. However, the inherent irregularity and large sizes of real-world power law graphs makes effective use of GPUs a major challenge. The project presents Warp Segmentation, a novel method that greatly enhances GPU device utilization by dynamically assigning appropriate number of SIMD threads to process a vertex with irregular-sized neighbors. We also present a software (compiler) technique named Collaborative Context Collection (CCC) that increases the warp execution effiuciency when faced with thread divergence incurred either by different intra-warp task assignment or by intra-warp load imbalance. Finally, we introduce a novel software technique named Collaborative Task Engagement (CTE) for efficient expression and execution of GPU kernels containing nested patterns.  Improving the energy efficiency of commonly used libraries is an effective approach to energy efficient scientific computing. While many linear algebra libraries have been developed to optimize performance, no linear algebra library considers their energy efficiency at the library design time. In this project, we present GreenLA - an energy efficient linear algebra software package that leverages linear algebra algorithmic characteristics to maximize energy savings with negligible overhead. We analyze highly optimized dense matrix factorization algorithms including Cholesky, LU and QR factorizations. GreenLA exploits algorithmic knowledge of linear algebra operations to predict slack on CPU and GPU, and use application-level DVFS strategies to reclaim the slack for energy savings.  Energy efficiency and resilience are two crucial challenges for High Performance Computing (HPC) systems to reach exascale. Decreasing the supply voltage associated with a given operating frequency for processors and other CMOS-based components can significantly reduce power consumption. However, this often raises system failure rates and consequently increases application execution time. In this project, we present GreenMM framework for matrix multiplication, which reduces energy consumption in GPUs through undervolting without sacrificing the performance. The idea is to undervolt the GPU beyond the minimum operating voltage (Vmin) to save maximum energy while keeping the frequency constant. Since such undervolting may give rise to faults, we design an Algorithm Based Fault Tolerance (ABFT) algorithm and checkpoint recovery technique to detect and correct those errors.  Broader Impact: The project has given rise to many high-quality publications in top conferences like SC, HPDC and ICS. The project has supported several PhD students at University of California, Riverside. Two of them have graduated and joined Argonne National Lab. One of them later shifted to Colorado School of Mines and Technology as an Assistant Professor. One of the PhD students who was supported and is currently continuing is a female.          Last Modified: 07/24/2020       Submitted by: Laxmi N Bhuyan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
