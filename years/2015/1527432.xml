<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Robust Stochastic Control for Agile Aerial Manipulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>496093.00</AwardTotalIntnAmount>
<AwardAmount>496093</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Miller</SignBlockName>
<PO_EMAI>damiller@nsf.gov</PO_EMAI>
<PO_PHON>7032924914</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A new class of flying robots are beginning to, not only navigate and observe, their surroundings, but also reach and manipulate objects in places that are difficult for humans to go. Such systems will assist people through manipulation in unsafe or remote locations, and will automate manual labor-intensive tasks such as package delivery, agricultural inspection, and infrastructure repair. Current aerial manipulator prototypes lack the control fidelity to ensure reliability and efficiency that is expected from such operations. To overcome these limitations, the proposed project develops novel control techniques that exploit the capabilities of the aerial vehicle. If successful, this research project will enable agile and safe aerial manipulation in extreme environments that is presently impossible or infeasible using standard methods. &lt;br/&gt;&lt;br/&gt;The goal of this research is the realization of planning and control methods with built-in robustness for robots that can interact with and manipulate the environment in autonomous and human-assisted modes. This is accomplished by posing the coupled perception-control problem as a statistical learning problem and adaptively computing decision policies to optimize future performance and minimize probability of safety violation. At the core of the approach lies a provably-stable adaptive control methodology equipped with probabilistic robustness guarantees in terms of maximum expected cost and probability of collision. These bounds correspond to concentration-of-measure inequalities derived through Bayesian probably-approximately-correct analysis. Two experimental platforms provide proof-of-concept for: 1) an autonomous "Air-gripper" for repetitive tasks such as load delivery, crop sampling, and remote cleaning; 2) co-robotic "hands in the sky" in direct assistance to a human operator enabling access to dangerous or difficult-to-access places, e.g. for inspection and repair in extreme environments, during rescue or security-sensitive missions. The implemented techniques are generally applicable and will be released as open-source ROS-compatible software.</AbstractNarration>
<MinAmdLetterDate>08/05/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1527432</AwardID>
<Investigator>
<FirstName>Marin</FirstName>
<LastName>Kobilarov</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marin Kobilarov</PI_FULL_NAME>
<EmailAddress>marin@jhu.edu</EmailAddress>
<PI_PHON>4105168668</PI_PHON>
<NSF_ID>000629795</NSF_ID>
<StartDate>08/05/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212181111</ZipCode>
<StreetAddress><![CDATA[3400 N Charles Str]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~496093</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project is to realize aerial robots equipped with manipulators that can pefrom useful tasks, such as package pick-up and delivery in factories and warehouses, sensor placement and inspection of structures such as buildings or bridges, and agricultural inspection and management.<br />The key outcomes can be summarized as follows:</p> <ul> <li>development and demonstration of a reliable system for package pick-up and delivery in indoor settings</li> <li>demonstration of reliable contact interaction with objects and also with vertical walls while performing sensor placement tasks</li> <li>adaptive dynamics modeling and robust model-based control capable of adjusting to uknown object mass or contact forces</li> <li>computational theory and algorithms for provably robust policy search using both physics-based and learning-based dynamical models</li> </ul> <p>Several aerial vehicles were developed that operate in an indoor warehouse-like setting and detect packages on shelves, navigate to them using visual guidance, pick up and deliver them to a designated area. The system achieved 90% delivery success rate averaging 12 seconds per package, based on 100 trials. An extension of this capability for navigating to a vertical wall and placing a sensor package containing a wireless camera was demonstrated, with the ability to estimate and handle contact forces reliably. To achieve such capabilities, both traditional physics-based models were employed but also high-fidelity learned models (i.e. models that combine known second-order physics models with neural networks) were developed to capture complex dynamics (i.e. articulated rigid body dynamics during pick-up for aerial systems, and high-fidelity side-slip model for a small ground vehicle on rough terrain). These high-fidelity models are stochastic and allow the propagation and use of state uncertainty. Throughout the project several methods for robust control based on stochatsic models were developed based on propagating ellipsoids which enclose the uncertainty with high-confidence and then ensuring low-probability of colllision and constraint violation with those ellipsoids. The stochastic models were employed for robust policy optimization, i.e. computing control laws with built-in performance guarantees of the form "with 99% chance the system will complete its mission successfully". This was achieved through domain randomization and probably-approximately-correct policy search (PROPS) in simulation using many randomized environments. The trained policies were then successfully transfered to a real vehicle with similar performance, shown emprically. Finally, an advanced actor-critic probably-appproximately-correct policy search (ACPROPS) framework was developed for more sample-efficient policy computation.</p><br> <p>            Last Modified: 02/09/2020<br>      Modified by: Marin&nbsp;Kobilarov</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1527432/1527432_10383778_1581306646363_airm_examples--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1527432/1527432_10383778_1581306646363_airm_examples--rgov-800width.jpg" title="Aerial Manipulation Examples"><img src="/por/images/Reports/POR/2020/1527432/1527432_10383778_1581306646363_airm_examples--rgov-66x44.jpg" alt="Aerial Manipulation Examples"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Aerial Manipulation Examples</div> <div class="imageCredit">Marin Kobilarov</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Marin&nbsp;Kobilarov</div> <div class="imageTitle">Aerial Manipulation Examples</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project is to realize aerial robots equipped with manipulators that can pefrom useful tasks, such as package pick-up and delivery in factories and warehouses, sensor placement and inspection of structures such as buildings or bridges, and agricultural inspection and management. The key outcomes can be summarized as follows:  development and demonstration of a reliable system for package pick-up and delivery in indoor settings demonstration of reliable contact interaction with objects and also with vertical walls while performing sensor placement tasks adaptive dynamics modeling and robust model-based control capable of adjusting to uknown object mass or contact forces computational theory and algorithms for provably robust policy search using both physics-based and learning-based dynamical models   Several aerial vehicles were developed that operate in an indoor warehouse-like setting and detect packages on shelves, navigate to them using visual guidance, pick up and deliver them to a designated area. The system achieved 90% delivery success rate averaging 12 seconds per package, based on 100 trials. An extension of this capability for navigating to a vertical wall and placing a sensor package containing a wireless camera was demonstrated, with the ability to estimate and handle contact forces reliably. To achieve such capabilities, both traditional physics-based models were employed but also high-fidelity learned models (i.e. models that combine known second-order physics models with neural networks) were developed to capture complex dynamics (i.e. articulated rigid body dynamics during pick-up for aerial systems, and high-fidelity side-slip model for a small ground vehicle on rough terrain). These high-fidelity models are stochastic and allow the propagation and use of state uncertainty. Throughout the project several methods for robust control based on stochatsic models were developed based on propagating ellipsoids which enclose the uncertainty with high-confidence and then ensuring low-probability of colllision and constraint violation with those ellipsoids. The stochastic models were employed for robust policy optimization, i.e. computing control laws with built-in performance guarantees of the form "with 99% chance the system will complete its mission successfully". This was achieved through domain randomization and probably-approximately-correct policy search (PROPS) in simulation using many randomized environments. The trained policies were then successfully transfered to a real vehicle with similar performance, shown emprically. Finally, an advanced actor-critic probably-appproximately-correct policy search (ACPROPS) framework was developed for more sample-efficient policy computation.       Last Modified: 02/09/2020       Submitted by: Marin Kobilarov]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
