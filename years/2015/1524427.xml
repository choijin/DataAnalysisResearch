<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Theory and Algorithms for Learning Perturbation Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>407091.00</AwardTotalIntnAmount>
<AwardAmount>407091</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Machine learning concerns designing and understanding computer programs that learn from experience. Modern complex settings (for example natural language) require the use of flexible probability models that permit one to entertain large numbers of possible hypotheses (semantics) underlying the observations (sentences). In such models likely structures (parse trees) are guided by functions that assess the suitability of structures by breaking them into smaller pieces. Richer models require larger subsets making it challenging to efficiently explore large sets of possible hypotheses. &lt;br/&gt;&lt;br/&gt;This project takes a fresh look at structured modeling by developing a new paradigm for modeling by combining randomization of parameters and combinatorial optimization. The combination provides a mechanism for inducing complex distributions over structures yet explicitly maintaining easy generation of likely structures. We pursue a comprehensive plan to understand, extend, and design these perturbation models towards the end goal of solving significant cross-cutting applied problems in natural language processing such as parsing or structured recommender tasks such as paraphrasing. Beyond modeling, the proposed work has the potential to merge tools and techniques across areas from theoretical computer science (stability, tractability), combinatorial optimization (relaxations, certificates), to probability (sampling from convex bodies). The tools developed will be broadly useful across prominent areas, from computer vision, natural language processing, to medical informatics and computational biology. The proposed work by its very nature compels strong collaborative relationships across disciplinary boundaries, from theory to applications. The PI will actively pursue these opportunities. All the software produced in this project will be open-sourced, and made available for download. The PI will also engage in outreach activities that enable high school students to participate.</AbstractNarration>
<MinAmdLetterDate>08/05/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1524427</AwardID>
<Investigator>
<FirstName>Tommi</FirstName>
<LastName>Jaakkola</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tommi S Jaakkola</PI_FULL_NAME>
<EmailAddress>tommi@csail.mit.edu</EmailAddress>
<PI_PHON>6172530440</PI_PHON>
<NSF_ID>000096103</NSF_ID>
<StartDate>08/05/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName/>
<StateCode>MA</StateCode>
<ZipCode>021394307</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~407091</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The prevalence of machine learning methods in applications such as recommender systems derives from their ability to learn to predict based only on examples illustrating the task. In other words, it suffices to provide examples of what you want, leaving the harder task of finding a solution to the learning algorithm. Current machine learning tools are increasingly automating more and more realistic prediction tasks. These include natural language translation or communication; understanding or generating images or visualizations; as well as automating the design of new molecules such as drugs that have more favorable properties. From the point of view of algorithms, common to all these tasks is the technical problem of designing methods that are able to efficiently use, modify, and generate complex objects such as sentences, images, or graphs. This project has focused on solving some of the key technical challenges underlying such prediction tasks.&nbsp;</p> <p>Our work has developed a class of methods called perturbation models or implicit distributions that turn simple random variation into diverse sets of complex objects such as sentences. Some of the technical parts to understand about such models include how they ought to be structured, how they can be used to complete partially known objects (conditioning), or finding efficient algorithms for learning them from data. Outcomes from this work include characterizations of the properties of perturbation models as well as new algorithms for predicting complex objects such as graphs. The methods studied as part of this project are broadly useful across disciplines, from natural language processing, recommender systems to medicine and chemistry.&nbsp;</p> <p>The project primarily supported the dissertation research of a female graduate student who is continuing her career in related technical areas.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/07/2018<br>      Modified by: Tommi&nbsp;S&nbsp;Jaakkola</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The prevalence of machine learning methods in applications such as recommender systems derives from their ability to learn to predict based only on examples illustrating the task. In other words, it suffices to provide examples of what you want, leaving the harder task of finding a solution to the learning algorithm. Current machine learning tools are increasingly automating more and more realistic prediction tasks. These include natural language translation or communication; understanding or generating images or visualizations; as well as automating the design of new molecules such as drugs that have more favorable properties. From the point of view of algorithms, common to all these tasks is the technical problem of designing methods that are able to efficiently use, modify, and generate complex objects such as sentences, images, or graphs. This project has focused on solving some of the key technical challenges underlying such prediction tasks.   Our work has developed a class of methods called perturbation models or implicit distributions that turn simple random variation into diverse sets of complex objects such as sentences. Some of the technical parts to understand about such models include how they ought to be structured, how they can be used to complete partially known objects (conditioning), or finding efficient algorithms for learning them from data. Outcomes from this work include characterizations of the properties of perturbation models as well as new algorithms for predicting complex objects such as graphs. The methods studied as part of this project are broadly useful across disciplines, from natural language processing, recommender systems to medicine and chemistry.   The project primarily supported the dissertation research of a female graduate student who is continuing her career in related technical areas.           Last Modified: 11/07/2018       Submitted by: Tommi S Jaakkola]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
