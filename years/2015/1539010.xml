<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RIDIR:  Collaborative Research: Enabling Access to and Analysis of Shared Daylong Child and Family Audio Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>02/28/2019</AwardExpirationDate>
<AwardTotalIntnAmount>256256.00</AwardTotalIntnAmount>
<AwardAmount>256256</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04010000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SMA</Abbreviation>
<LongName>SBE Off Of Multidisciplinary Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A child's language development in the first few years of life predicts long-term cognitive development, academic achievement, and expected income as an adult. Early language development in turn depends on linguistic interactions with adults. Increasingly, researchers are using daylong audio recordings to study child language development and child-caregiver interactions. Compared to short language samples, daylong recordings capture the full range of experiences a child has over the course of a day. Daylong audio recordings are also being used in applied settings. For example, studies show that by the time they enter First Grade, children from higher socioeconomic backgrounds hear tens of millions more words than children from lower socioeconomic backgrounds, perpetuating social inequalities. Multiple large-scale intervention projects targeting low socioeconomic households, including the Thirty Million Words Initiative in Chicago and the Providence Talks program, are using daylong audio recordings to provide automated, personalized feedback to parents on when and how often their child hears adult words and experiences conversational turns. The features of daylong recordings that are advantageous for researchers and practitioners also pose unique challenges. For one, their long durations are ideal for studying the temporal dynamics of child-adult interaction, but taking advantage of the long durations requires the enlistment of automated speech recognition technology. Current automatic speech recognition systems have difficulties with child speech and are challenged by the noisy and varied acoustic environments represented in the recordings. Another challenge is that the recordings capture private moments that require long hours of human listening to remove. This makes it difficult for researchers to share the recordings publicly, so that the potential value of the recordings collected by individual research labs is not fully realized.&lt;br/&gt;&lt;br/&gt;This project will create a new resource, called HomeBank, that will have three key components: (1) a public dataset containing daylong audio recordings that have had private information removed by human listeners, (2) a larger dataset containing about ten to one hundred times as many hours of recording that have not had private information removed and will be free but restricted to those who have demonstrated training in human research ethics, and (3) an open-source repository of computer programs to automatically analyze the daylong audio recordings. HomeBank will take advantage of an existing cyberinfrastructure for sharing linguistic data called TalkBank. The daylong audio recordings included in the datasets will represent both typically developing and clinical groups, a range of ages from newborn infants to school age children, and a range of language and socioeconomic backgrounds. We expect the primary users to be basic and applied child development researchers as well as engineers developing automatic speech recognition technologies. The free-to-access database and the open source computer programs will ultimately improve both the data on which early interventions are based and the tools available for providing parents with feedback on the linguistic input they provide their children.</AbstractNarration>
<MinAmdLetterDate>08/24/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1539010</AwardID>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>MacWhinney</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian J MacWhinney</PI_FULL_NAME>
<EmailAddress>macw@cmu.edu</EmailAddress>
<PI_PHON>4122683793</PI_PHON>
<NSF_ID>000470840</NSF_ID>
<StartDate>08/24/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7231</Code>
<Text>CYBERINFRASTRUCTURE</Text>
</ProgramElement>
<ProgramElement>
<Code>8294</Code>
<Text>Data Infrastructure</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8004</Code>
<Text>Software Institutes</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~256256</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>HomeBank (<a href="https://homebank.talkbank.org/">https://homebank.talkbank.org/</a>) is a web accessible collection of daylong audio recordings made in the homes of families with young children.&nbsp; The database includes raw audio recordings, metadata about the families and context of the recordings, and tools such as software and manuals developed to process the data in the database. The recordings come from a diverse populations, including typically-developing children, children with hearing loss, children in preindustrial societies, and children of teenage mothers.&nbsp;</p> <p>Using automatic speech recognition technology, the transcripts from these recordings provide annotations that tell us who is speaking when during the day. They identify each sound segment as coming from adult males, adult females, children, crying, machine noise, and other types of vocalizations and environmental audio. Each segment in the transcript is marked with beginning and ending time values for computation of time values for the different sound sources and which can be used to provide direct playback of segments in a web browser. To further develop this resource, the HomeBank project is collaborating with speech technology groups to improve the range and accuracy of the annotations of these corpora.</p> <p>When the HomeBank project began in 2015, none of these daylong recordings were being publicly shared. Since then, researchers have added continually to the database. HomeBank now contains over 12,000 hours of daylong recordings. To access the full dataset, users must agree to keep the data private and must have obtained training in the ethical issues involving work with human subjects. A smaller set of recordings that have been carefully checked to remove any problematic material is available without password. &nbsp;Information on these data protection issues, database versioning, membership, specific corpora, publications, and other topics are available from the home page, as indicated in the screenshot below.</p> <p>These data have been used to address a wide variety of research questions regarding the quantity and types of interactions across the day in these various communities and family types. Researchers in psychology, computer science, engineering, health and medical sciences, communication, speech and language disorders, acoustics, automatic speech recognition, and others are active users of the database. Potential topics include the role of autism, hearing loss, language disorders, cognitive disorders, socioeconomic status, bilingualism, child age, maternal age, noise in the home, time of day, activity type, and parental time outside the home on children's language environments and language development.&nbsp;</p> <p>HomeBank is one of the 14 components of the larger TalkBank system of online databases for spoken language. Other segments of TalkBank deal with language from bilinguals, older children, people with aphasia, classroom discourse, and language in many other settings and groups. The TalkBank system is a member of the European CLARIN Federation of language databases and it has received the Core Trust Seal for its implementation of practices and standards for data curation and preservation.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/10/2019<br>      Modified by: Brian&nbsp;J&nbsp;Macwhinney</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1539010/1539010_10390901_1552265575449_homepage--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1539010/1539010_10390901_1552265575449_homepage--rgov-800width.jpg" title="HomeBank Home Page"><img src="/por/images/Reports/POR/2019/1539010/1539010_10390901_1552265575449_homepage--rgov-66x44.jpg" alt="HomeBank Home Page"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Information on corpora and membership.</div> <div class="imageCredit">Brian MacWhinney</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Brian&nbsp;J&nbsp;Macwhinney</div> <div class="imageTitle">HomeBank Home Page</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ HomeBank (https://homebank.talkbank.org/) is a web accessible collection of daylong audio recordings made in the homes of families with young children.  The database includes raw audio recordings, metadata about the families and context of the recordings, and tools such as software and manuals developed to process the data in the database. The recordings come from a diverse populations, including typically-developing children, children with hearing loss, children in preindustrial societies, and children of teenage mothers.   Using automatic speech recognition technology, the transcripts from these recordings provide annotations that tell us who is speaking when during the day. They identify each sound segment as coming from adult males, adult females, children, crying, machine noise, and other types of vocalizations and environmental audio. Each segment in the transcript is marked with beginning and ending time values for computation of time values for the different sound sources and which can be used to provide direct playback of segments in a web browser. To further develop this resource, the HomeBank project is collaborating with speech technology groups to improve the range and accuracy of the annotations of these corpora.  When the HomeBank project began in 2015, none of these daylong recordings were being publicly shared. Since then, researchers have added continually to the database. HomeBank now contains over 12,000 hours of daylong recordings. To access the full dataset, users must agree to keep the data private and must have obtained training in the ethical issues involving work with human subjects. A smaller set of recordings that have been carefully checked to remove any problematic material is available without password.  Information on these data protection issues, database versioning, membership, specific corpora, publications, and other topics are available from the home page, as indicated in the screenshot below.  These data have been used to address a wide variety of research questions regarding the quantity and types of interactions across the day in these various communities and family types. Researchers in psychology, computer science, engineering, health and medical sciences, communication, speech and language disorders, acoustics, automatic speech recognition, and others are active users of the database. Potential topics include the role of autism, hearing loss, language disorders, cognitive disorders, socioeconomic status, bilingualism, child age, maternal age, noise in the home, time of day, activity type, and parental time outside the home on children's language environments and language development.   HomeBank is one of the 14 components of the larger TalkBank system of online databases for spoken language. Other segments of TalkBank deal with language from bilinguals, older children, people with aphasia, classroom discourse, and language in many other settings and groups. The TalkBank system is a member of the European CLARIN Federation of language databases and it has received the Core Trust Seal for its implementation of practices and standards for data curation and preservation.             Last Modified: 03/10/2019       Submitted by: Brian J Macwhinney]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
