<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Strengthening the Quality, Design and Usability of Simulations as Assessments of Teaching Practice</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>449906.00</AwardTotalIntnAmount>
<AwardAmount>449906</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Ford</SignBlockName>
<PO_EMAI>miford@nsf.gov</PO_EMAI>
<PO_PHON>7032925153</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Ensuring that beginning teachers are "classroom-ready" requires assessments that efficiently and validly evaluate proficiency in teaching. This project explores assessments involving simulated students as a way to assess teaching practice, which could provide an important complement, or alternative, to directly assessing teaching practice in classrooms. This form of assessment has the potential to provide a way to avoid onerous expense, logistics, and other difficulties of assessments happening in classrooms. The project will address questions about the development of performance expectations for elementary mathematics teachers, the extent to which the performance of the "student" role can be standardized across different performance contexts, and different approaches for generating teaching scenarios. The assessments will focus on the teaching practices of eliciting and interpreting students' mathematical thinking. The project will support: (1) establishing the validity of the assessment as a means to assess readiness to teach elementary mathematics and (2) providing the necessary foundation for scaling research and the use of simulation assessments. &lt;br/&gt;&lt;br/&gt;The goal of this project is generating, calibrating, and studying standardized simulations of clinical performance of mathematics teaching. The strategy is to investigate three components of the simulation assessment that will enable its broader use in the field. One component will focus on approaches that use different foundations (wisdom of practice, interactions with children, and learning trajectories research) for the design of simulations that are authentic and provide robust information about teaching. Data on the ways in which each approach supplies resources needed for assessment development will be compared. Another component will focus on the degree to which the role of the student can be standardized given the dynamics of teaching. Data on the responses of standardized students, who have similar initial training, to different situational categories will be analyzed. A final component will be establishing a basis for calibrating performance expectations for simulations linked to key points in a teacher's career trajectory (early career teachers, experienced teachers, "accomplished" teachers). Data on the performance of teachers at different points in their careers on the same assessment simulations will be compared. This study of components impacting assessment design will result in a more robust foundation for further development of, and further research on, teaching simulation assessments. The Discovery Research K-12 program (DRK-12) seeks to significantly enhance the learning and teaching of science, technology, engineering and mathematics (STEM) by preK-12 students and teachers, through research and development of innovative resources, models and tools (RMTs). Projects in the DRK-12 program build on fundamental research in STEM education and prior research and development efforts that provide theoretical and empirical justification for proposed projects.</AbstractNarration>
<MinAmdLetterDate>07/17/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/17/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1502711</AwardID>
<Investigator>
<FirstName>Deborah</FirstName>
<LastName>Ball</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Deborah L Ball</PI_FULL_NAME>
<EmailAddress>dball@umich.edu</EmailAddress>
<PI_PHON>3136473713</PI_PHON>
<NSF_ID>000091275</NSF_ID>
<StartDate>07/17/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tim</FirstName>
<LastName>Boerst</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tim Boerst</PI_FULL_NAME>
<EmailAddress>tboerst@umich.edu</EmailAddress>
<PI_PHON>7346159048</PI_PHON>
<NSF_ID>000540122</NSF_ID>
<StartDate>07/17/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meghan</FirstName>
<LastName>Shaughnessy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meghan Shaughnessy</PI_FULL_NAME>
<EmailAddress>mshaugh@bu.edu</EmailAddress>
<PI_PHON>5102958824</PI_PHON>
<NSF_ID>000635758</NSF_ID>
<StartDate>07/17/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091271</ZipCode>
<StreetAddress><![CDATA[3003 S. State St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7645</Code>
<Text>Discovery Research K-12</Text>
</ProgramElement>
<Appropriation>
<Code>0415</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~449906</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Increased attention to preparing beginning teachers who are classroom-readycreates the need for assessments that efficiently and validly evaluate proficiency in teaching mathematics. The expense, logistics, contextual variability, as well as issues of equity, associated with assessing preservice teachers in the field has led us to explore alternatives. Assessments that simulate teaching practice, such as simulations that are used in the preparation of professionals in other fields, hold promise for assessment in initial teacher preparation. However, simulation assessments for evaluating practice are difficult and time-consuming to design and implement well. Needed are careful studies to understand the responses to simulation assessments by teachers at different points in their development, the quality of the standardization in such assessments, and the generation of scenarios where student thinking corresponds with the research literature and also rings true to participants in the assessment.&nbsp;&nbsp;</p> <p>We developed and investigated simulation assessments focused on the knowledge and skill preservice teachers demonstrate as they engage in teaching practices. In the simulation, preservice teachers interact with a person following a mathematical learner profile specifying a student?s process, understanding, and way of engaging with respect to a specific mathematical problem. Each simulation focused specifically on one important area of mathematics and the teaching practices of eliciting children?s thinking and interpreting children?s mathematical thinking. Each simulation was designed by specifying three important characteristics of a student?s mathematical thinking: the mathematical strategy (standard, alternative, or invented); the nature of mathematical understanding (conceptual, procedural, or mixed); and the outcome of the student?s mathematical work (correct answer or incorrect answer). Each simulation went through a development process involving iterative cycles of use with preservice teachers at different points in their teacher education program, careful study of the preservice teacher performances that were elicited, and revision of the simulation to address shortcomings of content, enactment, and interpretation. Once a simulation was in its final form, training materials were developed to support the use of the assessment.</p> <p>Through this exploratory project, we have developed and studied three different approaches (using mathematics curriculum materials, mathematics education research, and cases of students working on math problems) to design the mathematical learner profile of the student in the assessment. The findings suggest that each have limitations that may be addressed by other resources and that the wisdom of practice brought by mathematics teacher educators is crucial to the design of the learner profile. In a second strand of work, we found that, when teacher educators were trained, they were able to consistently carry out the role of the student. In other words, the role of the student was standardized in important ways. Finally, in a third strand, we established a set of performances expectations to assess preservice teachers? instructional capabilities. These expectations were based on review of preservice and practicing teachers? performances on the assessments and were reviewed by an outside set of teacher educators,</p> <p>This exploratory project contributed substantially to the field in several respects. First, the findings support the validity of the assessment as a means to assess readiness to teach elementary mathematics. Further, the findings provide the necessary foundation for scaling research and the use of simulation assessments. By studying a key set of design challenges in assessing one high-leverage teaching practice across multiple mathematics strands, both the assessments themselves and research generated by this project will be of use to many involved in preparing STEM teachers. Further, this research provides the foundation for investigating assessments of high-leverage teaching practices in a range of other teaching simulations.<strong><em> </em></strong></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/12/2018<br>      Modified by: Meghan&nbsp;Shaughnessy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Increased attention to preparing beginning teachers who are classroom-readycreates the need for assessments that efficiently and validly evaluate proficiency in teaching mathematics. The expense, logistics, contextual variability, as well as issues of equity, associated with assessing preservice teachers in the field has led us to explore alternatives. Assessments that simulate teaching practice, such as simulations that are used in the preparation of professionals in other fields, hold promise for assessment in initial teacher preparation. However, simulation assessments for evaluating practice are difficult and time-consuming to design and implement well. Needed are careful studies to understand the responses to simulation assessments by teachers at different points in their development, the quality of the standardization in such assessments, and the generation of scenarios where student thinking corresponds with the research literature and also rings true to participants in the assessment.    We developed and investigated simulation assessments focused on the knowledge and skill preservice teachers demonstrate as they engage in teaching practices. In the simulation, preservice teachers interact with a person following a mathematical learner profile specifying a student?s process, understanding, and way of engaging with respect to a specific mathematical problem. Each simulation focused specifically on one important area of mathematics and the teaching practices of eliciting children?s thinking and interpreting children?s mathematical thinking. Each simulation was designed by specifying three important characteristics of a student?s mathematical thinking: the mathematical strategy (standard, alternative, or invented); the nature of mathematical understanding (conceptual, procedural, or mixed); and the outcome of the student?s mathematical work (correct answer or incorrect answer). Each simulation went through a development process involving iterative cycles of use with preservice teachers at different points in their teacher education program, careful study of the preservice teacher performances that were elicited, and revision of the simulation to address shortcomings of content, enactment, and interpretation. Once a simulation was in its final form, training materials were developed to support the use of the assessment.  Through this exploratory project, we have developed and studied three different approaches (using mathematics curriculum materials, mathematics education research, and cases of students working on math problems) to design the mathematical learner profile of the student in the assessment. The findings suggest that each have limitations that may be addressed by other resources and that the wisdom of practice brought by mathematics teacher educators is crucial to the design of the learner profile. In a second strand of work, we found that, when teacher educators were trained, they were able to consistently carry out the role of the student. In other words, the role of the student was standardized in important ways. Finally, in a third strand, we established a set of performances expectations to assess preservice teachers? instructional capabilities. These expectations were based on review of preservice and practicing teachers? performances on the assessments and were reviewed by an outside set of teacher educators,  This exploratory project contributed substantially to the field in several respects. First, the findings support the validity of the assessment as a means to assess readiness to teach elementary mathematics. Further, the findings provide the necessary foundation for scaling research and the use of simulation assessments. By studying a key set of design challenges in assessing one high-leverage teaching practice across multiple mathematics strands, both the assessments themselves and research generated by this project will be of use to many involved in preparing STEM teachers. Further, this research provides the foundation for investigating assessments of high-leverage teaching practices in a range of other teaching simulations.           Last Modified: 11/12/2018       Submitted by: Meghan Shaughnessy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
