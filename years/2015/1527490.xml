<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Inference with Incomplete Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>473159.00</AwardTotalIntnAmount>
<AwardAmount>473159</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Missing data is a problem that plagues every branch of empirical science. Sensors do not always work reliably, respondents do not fill out every question in the questionnaire, and medical patients are often unable to recall episodes, treatments or outcomes. This project attempts to recover information of interest from partially observed data by reasoning about the process that could have caused some data to be missing and others to be observed. Recent advances in graphical models and causal inference permit us to describe such processes formally and identify conditions under which recovery from missing data would be feasible and, if so, how. This project will focus on conditions in which recovery is deemed infeasible by available techniques. By learning to manage such conditions this research will benefit empirical research in a variety of fields, including machine learning, big data, epidemiology, statistics, economics, social science and medicine.&lt;br/&gt;&lt;br/&gt;The aim of the proposed research is to develop computer systems capable of learning from incomplete data by encoding assumptions in a graphical causal model. Using such models we will identify conditions that facilitate (or prohibit) inference and learning. In particular, this research will develop effective procedures for determining whether unbiased estimates of statistical and causal relationships can be computed given incomplete data and whether assumptions that facilitate such estimability have testable implications. Additionally, it will generate bounds for those relationships that are proved to be inestimable. These will in turn lead to a theoretical understanding of what is possible and impossible under missing data conditions. Given the ubiquity of the missing data problem we believe this research will create new and important tools for all data-intensive sciences.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/04/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1527490</AwardID>
<Investigator>
<FirstName>Judea</FirstName>
<LastName>Pearl</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Judea Pearl</PI_FULL_NAME>
<EmailAddress>judea@cs.ucla.edu</EmailAddress>
<PI_PHON>3108253243</PI_PHON>
<NSF_ID>000179905</NSF_ID>
<StartDate>08/04/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Los Angeles]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951596</ZipCode>
<StreetAddress><![CDATA[420 Westwood Plaza, 4532 BH]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~473159</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p dir="ltr"><span>Missing data i.e. data in which one or more variables have missing or unobserved values, are widespread in all branches of empirical sciences. We use graphical models to encode assumptions about the missingness process and develop general algorithms to consistently estimate probabilistic and causal queries. We summarize the details of accomplishments below based on the technical reports and publications generated during the reporting period:</span></p> <p dir="ltr"><strong>Estimation with Incomplete Data: The Linear Case</strong></p> <p dir="ltr"><span>Traditional methods for handling incomplete data, including Multiple Imputation and Maximum Likelihood, require that the data be Missing At Random (MAR). In most cases, however, missingness in a variable depends on the underlying value of that variable. In this work, we devise model? based methods to consistently estimate mean, variance and covariance given data that are Missing Not At Random (MNAR). While previous work on MNAR data require variables to be discrete, we extend the analysis to continuous variables drawn from Gaussian distributions. We demonstrate the merits of our techniques by comparing them empirically to state of the art software packages.</span></p> <p><strong>On the utility of causal diagrams in modeling attrition: a practical example</strong></p> <p dir="ltr">In a recent communication, Breskin, Cole and Hudgens (2018) aimed to demonstrate ``how single?world intervention graphs can supplement traditional causal diagrams''. The example used in their demonstration involved selection bias due to attrition, namely, subjects dropping out from a randomized trial before the outcome is observed. Here we use the same example to demonstrate the opposite conclusion; the derivation presented by (Breskin et al., 2018) is in fact longer and more complicated than the standard, Three? step derivation facilitated by traditional causal diagrams. We further show that more natural solutions to attrition problems are obtained when viewed as missing? data problems encoded in causal diagrams.</p> <p dir="ltr"><strong>Graphical Models for Processing Missing Data</strong></p> <p dir="ltr"><span>This paper reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: transparency, estimability and testability. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are Missing Not At Random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally we derive testable implications for missing data models in both MAR (Missing At Random) and MNAR categories.</span></p> <p><strong>The Seven Tools of Causal Inference with Reflections on Machine Learning</strong></p> <p dir="ltr"><span>Systems that operate in purely statistical mode of inference entail theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human?level intelligence, learning machines need the guidance of a model of external reality, similar to the ones used in causal inference tasks. To demonstrate the&nbsp;</span>essential role of such models, this paper presents a summary of seven tasks which are beyond reach of associational learning systems and which have been accomplished using the tools of causal modeling.</p> <p dir="ltr"><strong>Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution</strong></p> <p dir="ltr"><span>Current machine learning systems operate, almost exclusively, in a statistical, or model ?free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human&nbsp;</span>level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling.</p> <p dir="ltr"><strong>General Algorithms for handling data that are Missing Not At Random</strong></p> <p dir="ltr"><span>This paper presents a unified approach for recovering causal and probabilistic queries using graphical models given missing (or incomplete) data. To this end, we develop a general algorithm that can recover conditional probability distributions and conditional causal effects in models with latent variables.</span></p> <p dir="ltr"><strong>On learning the structure of missingness graphs from data</strong></p> <p dir="ltr"><span>In this paper, we develop a causal discovery method for recovering the underlying causal structure from data sets with missing values, including data that are Missing Not At Random (MNAR). We first apply PC algorithm on a fully connected undirected graph and then use a corrective procedure to remove potentially erroneous edges. The algorithm developed is theoretically sound and empirically efficient. Experimental results on both synthetic data and real healthcare applications illustrate that the proposed algorithm is able to find correct causal relations given MAR and MNAR data.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/29/2018<br>      Modified by: Judea&nbsp;Pearl</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Missing data i.e. data in which one or more variables have missing or unobserved values, are widespread in all branches of empirical sciences. We use graphical models to encode assumptions about the missingness process and develop general algorithms to consistently estimate probabilistic and causal queries. We summarize the details of accomplishments below based on the technical reports and publications generated during the reporting period: Estimation with Incomplete Data: The Linear Case Traditional methods for handling incomplete data, including Multiple Imputation and Maximum Likelihood, require that the data be Missing At Random (MAR). In most cases, however, missingness in a variable depends on the underlying value of that variable. In this work, we devise model? based methods to consistently estimate mean, variance and covariance given data that are Missing Not At Random (MNAR). While previous work on MNAR data require variables to be discrete, we extend the analysis to continuous variables drawn from Gaussian distributions. We demonstrate the merits of our techniques by comparing them empirically to state of the art software packages.  On the utility of causal diagrams in modeling attrition: a practical example In a recent communication, Breskin, Cole and Hudgens (2018) aimed to demonstrate ``how single?world intervention graphs can supplement traditional causal diagrams''. The example used in their demonstration involved selection bias due to attrition, namely, subjects dropping out from a randomized trial before the outcome is observed. Here we use the same example to demonstrate the opposite conclusion; the derivation presented by (Breskin et al., 2018) is in fact longer and more complicated than the standard, Three? step derivation facilitated by traditional causal diagrams. We further show that more natural solutions to attrition problems are obtained when viewed as missing? data problems encoded in causal diagrams. Graphical Models for Processing Missing Data This paper reviews recent advances in missing data research using graphical models to represent multivariate dependencies. We first examine the limitations of traditional frameworks from three different perspectives: transparency, estimability and testability. We then show how procedures based on graphical models can overcome these limitations and provide meaningful performance guarantees even when data are Missing Not At Random (MNAR). In particular, we identify conditions that guarantee consistent estimation in broad categories of missing data problems, and derive procedures for implementing this estimation. Finally we derive testable implications for missing data models in both MAR (Missing At Random) and MNAR categories.  The Seven Tools of Causal Inference with Reflections on Machine Learning Systems that operate in purely statistical mode of inference entail theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human?level intelligence, learning machines need the guidance of a model of external reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, this paper presents a summary of seven tasks which are beyond reach of associational learning systems and which have been accomplished using the tools of causal modeling. Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution Current machine learning systems operate, almost exclusively, in a statistical, or model ?free mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference tasks. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal modeling. General Algorithms for handling data that are Missing Not At Random This paper presents a unified approach for recovering causal and probabilistic queries using graphical models given missing (or incomplete) data. To this end, we develop a general algorithm that can recover conditional probability distributions and conditional causal effects in models with latent variables. On learning the structure of missingness graphs from data In this paper, we develop a causal discovery method for recovering the underlying causal structure from data sets with missing values, including data that are Missing Not At Random (MNAR). We first apply PC algorithm on a fully connected undirected graph and then use a corrective procedure to remove potentially erroneous edges. The algorithm developed is theoretically sound and empirically efficient. Experimental results on both synthetic data and real healthcare applications illustrate that the proposed algorithm is able to find correct causal relations given MAR and MNAR data.          Last Modified: 11/29/2018       Submitted by: Judea Pearl]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
