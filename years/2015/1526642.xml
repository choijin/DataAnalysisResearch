<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Theory of Robust Learning Based on the Structure and Function of the Cortical Column</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>167554.00</AwardTotalIntnAmount>
<AwardAmount>182629</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>How the brain learns, and in the process modifies its synaptic connectivity, remains one of the greatest mysteries of modern science. The objective of this project is to uncover the effects of robust associative learning and long-term memory storage on synaptic connectivity, thus creating the basis for quantitative analyses of these fundamental brain functions. The investigator proposes to develop a biologically realistic model of robust associative learning by cortical circuits. The model will be derived from a single hypothesis, according to which synaptic connectivity in a given circuit of adult cortex is functioning in a steady-state. In such a state the associative memory storage capacity of the circuit is maximal, and learning new associations is accompanied with forgetting some of the old ones. &lt;br/&gt;&lt;br/&gt;The model will integrate current knowledge of excitatory and inhibitory neuron classes, with structural connectivity constraints imposed by the morphologies of axonal and dendritic arbors of cortical neurons, with homeostatic constraints on numbers and strengths of synaptic connections. It is proposed to simulate steady-state learning based on one of the best studied networks in the mammalian neocortex - the barrel-centered column of rodent somatosensory cortex. The simulations will be imbedded in the structural connectivity of the column, built from the morphologies of neurons reconstructed in three-dimensions from various cortical depths. Salient features of steady-state circuits will be validated against a large dataset of experimental studies reporting probabilities of connections between neurons, probabilities of specific higher-order connectivity motifs, distributions of unitary postsynaptic potentials, as well as relative strengths of laminar and inter-laminar projections in rodent barrel cortex. The dataset will be created as part of the project and will encompass connectivity of major excitatory and inhibitory cell classes present in all cortical layers. The proposed research is rooted in the basic principles of statistical learning and will advance the state of the art in theoretical and computational modeling of cognitive functions with basic neuroscience and computational intelligence applications.</AbstractNarration>
<MinAmdLetterDate>09/03/2015</MinAmdLetterDate>
<MaxAmdLetterDate>05/15/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526642</AwardID>
<Investigator>
<FirstName>Armen</FirstName>
<LastName>Stepanyants</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Armen Stepanyants</PI_FULL_NAME>
<EmailAddress>a.stepanyants@neu.edu</EmailAddress>
<PI_PHON>6173732902</PI_PHON>
<NSF_ID>000111045</NSF_ID>
<StartDate>09/03/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~167554</FUND_OBLG>
<FUND_OBLG>2018~15075</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>A model of associative learning and memory storage was developed based on the knowledge of connectivity in the cerebral cortex. The model includes inhibitory and excitatory neuron classes and incorporates biologically-inspired homeostatic and sign-constraints on connection weights. The model neural networks can learn temporal sequences and entire basins of network states, which is believed to be the foundation of many cognitive functions. One of the advantages of the model is that the memory storage capacity of the network and the properties of its connectivity can be determined analytically, making it possible to explore the effects of model parameters and constraints on network functions.</p> <p>When model networks are robustly loaded with associative memories to capacity, they develop features like those observed in many cortical systems. A dataset of connectivity features in local cortical circuits was created to validate this finding. The dataset includes detailed information about the probabilities of connection and connection weights of various cortical projections described in the literature.&nbsp;</p> <p>Additionally, biological sources of errors and noise were incorporated into the model without jeopardizing its theoretical tractability. The results revealed that errors and noise should not be viewed as a nuisance, but that they are essential components of the reliable learning mechanism implemented by the brain. There is a tradeoff between the capacity and reliability of stored memories, and for the optimal retrieval of stored information, the level of noise during learning must exceed that during memory retrieval.</p> <p>The model was also embedded into a structurally constrained network of the cortical column. To that end, 55 morphological types from the Blue Brain Project were used to construct an instance of a structurally connected column. Associative memory sequences were loaded into the column to obtain its connectivity. The results demonstrate that associative learning alone is sufficient to explain the bulk of experimental knowledge about connectivity between different neuron classes and network dynamics in the column.</p> <p>This project resulted in several publications and conference presentations. One Ph.D. student and one REU student were involved in the research. The students were trained in all aspects of the work, and the research results make up the main part of the graduate student?s thesis. This research lies at the interface between multiple disciplines and the results are expected to have implications for neuroscience, machine learning, and neuromorphic computing.</p><br> <p>            Last Modified: 01/14/2020<br>      Modified by: Armen&nbsp;Stepanyants</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1526642/1526642_10395383_1579019310054_Figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1526642/1526642_10395383_1579019310054_Figure1--rgov-800width.jpg" title="Associative memory storage in recurrent networks of excitatory and inhibitory neurons"><img src="/por/images/Reports/POR/2020/1526642/1526642_10395383_1579019310054_Figure1--rgov-66x44.jpg" alt="Associative memory storage in recurrent networks of excitatory and inhibitory neurons"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Left: A recurrent network of excitatory and inhibitory neurons. Right: An associative memory in the model is a connected graph of successive network states. Each neuron must learn a set of input-output associations derived from the memory by modifying the strengths of its input connections.</div> <div class="imageCredit">Armen Stepanyants</div> <div class="imageSubmitted">Armen&nbsp;Stepanyants</div> <div class="imageTitle">Associative memory storage in recurrent networks of excitatory and inhibitory neurons</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1526642/1526642_10395383_1579020032436_Figure2--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1526642/1526642_10395383_1579020032436_Figure2--rgov-800width.jpg" title="Functional connectivity results from biologically-constrained associative learning in a morphologically constrained neural network"><img src="/por/images/Reports/POR/2020/1526642/1526642_10395383_1579020032436_Figure2--rgov-66x44.jpg" alt="Functional connectivity results from biologically-constrained associative learning in a morphologically constrained neural network"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Left: A cortical column consisting of 28,156 excitatory and inhibitory neurons belonging to 55 classes identified by the Blue Brain Project. Middle: The structural column was loaded with associative sequences of network states to capacity to produce its functional connectivity (right).</div> <div class="imageCredit">Armen Stepanyants</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Armen&nbsp;Stepanyants</div> <div class="imageTitle">Functional connectivity results from biologically-constrained associative learning in a morphologically constrained neural network</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ A model of associative learning and memory storage was developed based on the knowledge of connectivity in the cerebral cortex. The model includes inhibitory and excitatory neuron classes and incorporates biologically-inspired homeostatic and sign-constraints on connection weights. The model neural networks can learn temporal sequences and entire basins of network states, which is believed to be the foundation of many cognitive functions. One of the advantages of the model is that the memory storage capacity of the network and the properties of its connectivity can be determined analytically, making it possible to explore the effects of model parameters and constraints on network functions.  When model networks are robustly loaded with associative memories to capacity, they develop features like those observed in many cortical systems. A dataset of connectivity features in local cortical circuits was created to validate this finding. The dataset includes detailed information about the probabilities of connection and connection weights of various cortical projections described in the literature.   Additionally, biological sources of errors and noise were incorporated into the model without jeopardizing its theoretical tractability. The results revealed that errors and noise should not be viewed as a nuisance, but that they are essential components of the reliable learning mechanism implemented by the brain. There is a tradeoff between the capacity and reliability of stored memories, and for the optimal retrieval of stored information, the level of noise during learning must exceed that during memory retrieval.  The model was also embedded into a structurally constrained network of the cortical column. To that end, 55 morphological types from the Blue Brain Project were used to construct an instance of a structurally connected column. Associative memory sequences were loaded into the column to obtain its connectivity. The results demonstrate that associative learning alone is sufficient to explain the bulk of experimental knowledge about connectivity between different neuron classes and network dynamics in the column.  This project resulted in several publications and conference presentations. One Ph.D. student and one REU student were involved in the research. The students were trained in all aspects of the work, and the research results make up the main part of the graduate student?s thesis. This research lies at the interface between multiple disciplines and the results are expected to have implications for neuroscience, machine learning, and neuromorphic computing.       Last Modified: 01/14/2020       Submitted by: Armen Stepanyants]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
