<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Optimizing Computational Range and Velocity Imaging</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2016</AwardEffectiveDate>
<AwardExpirationDate>01/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project focuses on developing optimized hardware and software implementations for emerging computational range and velocity imaging. Today, the primary technologies for capturing range and velocity are radar and lidar. These offer a very high precision, but available systems are expensive, bulky, and slow, because they sequentially scan scenes in a point-by-point manner. Time-of-flight (ToF) cameras have emerged as inexpensive and fast alternatives. ToF cameras use active, temporally-modulated illumination and coded, in-pixel sensing to estimate the distance between the camera and each scene point in three dimensions (3D). Recently, simultaneous range and velocity imaging techniques were demonstrated for the first time with ToF cameras. A major roadblock for unlocking the full, transformative potential of range and velocity imaging has been the limited access to low-level sensor and illumination functionalities of commercially-available ToF cameras. Range (or depth) and velocity imaging enables computers to sense and understand the world and 3D scene dynamics. A wide range of applications in medical imaging, defense, human-computer interaction, and robotics rely on depth and velocity information to perform domain-specific tasks, such as object detection, tracking, localization, mapping, and motion analysis.&lt;br/&gt;&lt;br/&gt;This research makes computational range and velocity imaging practical by optimizing the speed, resolution, precision of depth and velocity estimation, 3D imaging capabilities, and photon sensitivity of emerging computational imaging systems in direct and non-line-of-sight scenarios. By analyzing the fundamental limitations and benefits of time-resolved imaging systems, optimized hardware implementations and reconstruction algorithms are devised that facilitate novel range and velocity sensing capabilities and make them practical (i.e. robust, inexpensive, and reproducible). The anticipated insights and contributions advance knowledge and gain an understanding of the limits of time-resolved computational imaging and how to practically achieve them. The developed computational imaging systems and mathematical models are expected to provide fundamentally new building blocks for a diversity of applications in computer and machine vision, medical imaging, microscopy, scientific imaging, remote sensing, defense, and robotics.</AbstractNarration>
<MinAmdLetterDate>01/11/2016</MinAmdLetterDate>
<MaxAmdLetterDate>02/13/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1553333</AwardID>
<Investigator>
<FirstName>Gordon</FirstName>
<LastName>Wetzstein</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gordon Wetzstein</PI_FULL_NAME>
<EmailAddress>gordon.wetzstein@stanford.edu</EmailAddress>
<PI_PHON>6504977953</PI_PHON>
<NSF_ID>000690865</NSF_ID>
<StartDate>01/11/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943054020</ZipCode>
<StreetAddress><![CDATA[350 Serra Mall, Rm 236]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~83050</FUND_OBLG>
<FUND_OBLG>2017~77460</FUND_OBLG>
<FUND_OBLG>2018~79597</FUND_OBLG>
<FUND_OBLG>2019~78784</FUND_OBLG>
<FUND_OBLG>2020~81109</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to develop new types of computational optical imaging systems that optimize 2D and 3D perception capabilities crucial to the success of applications such as autonomous driving, medical imaging, remote sensing, robotics, defense, and other application areas. In one research thrust of this project, the PI and his team developed a number of novel computational 3D imaging systems that combine the unique capabilities of emerging single-photon-sensitive light detectors with pulsed laser light sources and advanced algorithms. These computational single-photon imaging systems have enabled unprecedented imaging capabilities, among which the PI has demonstrated&nbsp; optimized&nbsp; depth resolution, accuracy, range, and robustness of direct 3D imaging, which is also known as light detection and ranging (LiDAR). This is an enabling technology for robotics and autonomous driving. Moreover, the PI also developed novel imaging modalities that allow a camera to see around corners or through a thick slab of a scattering medium, such as a wall. These unprecedented non-line-of-sight modalities could be cruial for future automotive and defense systems. In another research thrust, the PI and his team inveted and explored a new approach to designing computational cameras by jointly optimizing their optics, sensor electronics, and processing algorithms using modern artificial intelligence (AI) techniques. These AI-driven computational optical imaging systems were shown to enhance the resolution, contrast, depth imaging capabilities, or other characteristics compared with conventional cameras. Such end-to-end-optimized imaging systems optimize the capabilities of existing cameras and enable the design of emerging all-optical or hybrid optical-electronic computing systems with ultra-low-power consumption, small device form factors, and ultra-low latency. Finally, the PI and his team used a similar methodology of jointly designing optics and electronics to enhance wearable display systems that optimize user experiences and visual comfort of emerging virtual and augmented reality systems.<br /><br />In total, 38 papers were published as part of this project. These include several works published in the most prestigious journals of general science (2x Nature, Nature Communications, Science Advances) and many publications in the most prestigious journals and conferences across computer vision, optics, and computer graphics. This project supported 4 PhD students, who successfully defended their dissertations and completed their PhD programs, as well as one postdoctoral researcher. The program also funded 4 high-school students from underrespresented minority or low-income families in summer research internships in the PI's lab at Stanford. Some of these students are now pursuing undergraduate degrees in STEM at top-tier US universities. The research conducted in this program has been directly integrated into the teaching curriculum of several undergraduate and graduate-level courses at Stanford and the project has also supported continued education of industry professionals through seminar series and workshops organized as part of Stanford's Center for Image Systems Engineering, of which the PI is a faculty co-director.&nbsp;</p><br> <p>            Last Modified: 02/03/2021<br>      Modified by: Gordon&nbsp;Wetzstein</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to develop new types of computational optical imaging systems that optimize 2D and 3D perception capabilities crucial to the success of applications such as autonomous driving, medical imaging, remote sensing, robotics, defense, and other application areas. In one research thrust of this project, the PI and his team developed a number of novel computational 3D imaging systems that combine the unique capabilities of emerging single-photon-sensitive light detectors with pulsed laser light sources and advanced algorithms. These computational single-photon imaging systems have enabled unprecedented imaging capabilities, among which the PI has demonstrated  optimized  depth resolution, accuracy, range, and robustness of direct 3D imaging, which is also known as light detection and ranging (LiDAR). This is an enabling technology for robotics and autonomous driving. Moreover, the PI also developed novel imaging modalities that allow a camera to see around corners or through a thick slab of a scattering medium, such as a wall. These unprecedented non-line-of-sight modalities could be cruial for future automotive and defense systems. In another research thrust, the PI and his team inveted and explored a new approach to designing computational cameras by jointly optimizing their optics, sensor electronics, and processing algorithms using modern artificial intelligence (AI) techniques. These AI-driven computational optical imaging systems were shown to enhance the resolution, contrast, depth imaging capabilities, or other characteristics compared with conventional cameras. Such end-to-end-optimized imaging systems optimize the capabilities of existing cameras and enable the design of emerging all-optical or hybrid optical-electronic computing systems with ultra-low-power consumption, small device form factors, and ultra-low latency. Finally, the PI and his team used a similar methodology of jointly designing optics and electronics to enhance wearable display systems that optimize user experiences and visual comfort of emerging virtual and augmented reality systems.  In total, 38 papers were published as part of this project. These include several works published in the most prestigious journals of general science (2x Nature, Nature Communications, Science Advances) and many publications in the most prestigious journals and conferences across computer vision, optics, and computer graphics. This project supported 4 PhD students, who successfully defended their dissertations and completed their PhD programs, as well as one postdoctoral researcher. The program also funded 4 high-school students from underrespresented minority or low-income families in summer research internships in the PI's lab at Stanford. Some of these students are now pursuing undergraduate degrees in STEM at top-tier US universities. The research conducted in this program has been directly integrated into the teaching curriculum of several undergraduate and graduate-level courses at Stanford and the project has also supported continued education of industry professionals through seminar series and workshops organized as part of Stanford's Center for Image Systems Engineering, of which the PI is a faculty co-director.        Last Modified: 02/03/2021       Submitted by: Gordon Wetzstein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
