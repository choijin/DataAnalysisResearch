<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Inferring Mechanical Explanations from Manipulation Demonstrations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Robots are fast, accurate, reliable, and tireless, which make them great assets for factories. However, robots lack intuition - at which humans excel. Current robots have a hard time when tasked with imagining ways to manufacture new products. In an effective human-robot collaboration, humans conceive new products and feasible ways to manufacture them, and robots follow human guidelines with excellent precision and reliability. The scenario of interest is where a human operator demonstrates an execution of a task, such as mating two parts, and a robot understands how to replicate it. This proposal is concerned with improving the current robot understanding of those demonstrations. In particular, it is concerned with recovering information that is not directly observable with cameras, such as contacts between parts, and the forcefulness of the motions, both important for the ability of the robot to replicate the demonstration.&lt;br/&gt;&lt;br/&gt;This proposal aims to automate the inference of contact events and contact forces from noisy kinematic observations of the interaction between two known parts. The central idea is to use trajectory optimization and complementarity based models of contact to project noisy kinematic trajectories into dynamically-sound and environment-compatible motions, contacts, and forces. The problem is naturally under-constrained. There are many possible explanations for a given demonstration, and this proposal will investigate different ways to provide the optimizer with prior information to converge to a "reasonable" explanation. The first phase will conduct experiments instrumented with motion capture and force sensing to capture ground truth, and evaluate the ability of the algorithms to explain it, and overcome degradations such as noise and occlusions. A second phase will focus on un-instrumented scenarios and free-from demonstrations. The technical merit of the proposal will be demonstrated in the context of two high impact applications: automated assembly and shelf-picking/shelf-restocking in a warehouse scenario.</AbstractNarration>
<MinAmdLetterDate>08/12/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/12/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1551535</AwardID>
<Investigator>
<FirstName>Alberto</FirstName>
<LastName>Rodriguez Garcia</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alberto Rodriguez Garcia</PI_FULL_NAME>
<EmailAddress>albertor@mit.edu</EmailAddress>
<PI_PHON>4123209638</PI_PHON>
<NSF_ID>000655900</NSF_ID>
<StartDate>08/12/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Inst. of Technology]]></Name>
<CityName/>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project takes inspiration from humans&rsquo; unconscious but effective ability to make sense of contact to understand their environment. It only takes us a small push to a cup of coffee to estimate how full it is, and a quick glance to a bouncing ball to gauge its stiffness. Similarly, we aim at giving robots the ability to observe physical interaction in the form of motions and/or forces and gain a better understanding of the objects involved. Automating this process requires a clear understanding of the mathematical relationships between motions, forces, and inertias at contact.<br />In particular we have studied when and how it is possible to estimate object properties such as their mass and moment of inertia, and the forces involved in planar frictional contact and impact, when we observe with accuracy the motion of the interacting objects. The first step is to establish mathematical relationships between those dynamic parameters, forces and motions. A common way to do this in robotics is to use a formulation known as linear complementary problem (LCP). These models have been used in the past to simulate, plan, and control motion through contact, but less so for the task of contact &ldquo;introspection&rdquo;.<br />The study concludes that without the application of known external forces we can only estimate how object parameters and forces are related to each other. The analysis also shows that when known external forces are applied, we can fully estimate the object properties. In cases when the type of contact mode is known, these relationships lead to a system of mathematical equations that can be solved as a least squares problem to robustly estimate parameters in the presence of noise.<br />A second point of focus of this project has been to evaluate the accuracy of the mathematical models commonly used in robotic simulation of contact. The work started by automating and instrumenting the data collection process so that a robot (Fig 1) could automatically pick an object, throw it, and record the impact trajectories (Fig 2). The data was recorded with a high speed tracking system, and with force sensors on the ground.<br />The study has concluded that these models are often very inaccurate (Fig 3), and that the process of fitting their parameters usually leads to values with little physical meaning. Most models used in robotics make simplifying assumptions of instantaneous point impulses to resolve impacts, and use a small number of parameters (coefficient of friction and of restitution) to relate them. In practice, these pose underlying limitation that set an upper limit on how well the models perform. To overcome these limitations, we proposed ways to use experimental data to improve those same contact models, and compared their ability to accurately predict the resolution of contact and impact as a function of the amount of available data.</p><br> <p>            Last Modified: 08/31/2017<br>      Modified by: Alberto&nbsp;Rodriguez Garcia</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project takes inspiration from humans? unconscious but effective ability to make sense of contact to understand their environment. It only takes us a small push to a cup of coffee to estimate how full it is, and a quick glance to a bouncing ball to gauge its stiffness. Similarly, we aim at giving robots the ability to observe physical interaction in the form of motions and/or forces and gain a better understanding of the objects involved. Automating this process requires a clear understanding of the mathematical relationships between motions, forces, and inertias at contact. In particular we have studied when and how it is possible to estimate object properties such as their mass and moment of inertia, and the forces involved in planar frictional contact and impact, when we observe with accuracy the motion of the interacting objects. The first step is to establish mathematical relationships between those dynamic parameters, forces and motions. A common way to do this in robotics is to use a formulation known as linear complementary problem (LCP). These models have been used in the past to simulate, plan, and control motion through contact, but less so for the task of contact "introspection". The study concludes that without the application of known external forces we can only estimate how object parameters and forces are related to each other. The analysis also shows that when known external forces are applied, we can fully estimate the object properties. In cases when the type of contact mode is known, these relationships lead to a system of mathematical equations that can be solved as a least squares problem to robustly estimate parameters in the presence of noise. A second point of focus of this project has been to evaluate the accuracy of the mathematical models commonly used in robotic simulation of contact. The work started by automating and instrumenting the data collection process so that a robot (Fig 1) could automatically pick an object, throw it, and record the impact trajectories (Fig 2). The data was recorded with a high speed tracking system, and with force sensors on the ground. The study has concluded that these models are often very inaccurate (Fig 3), and that the process of fitting their parameters usually leads to values with little physical meaning. Most models used in robotics make simplifying assumptions of instantaneous point impulses to resolve impacts, and use a small number of parameters (coefficient of friction and of restitution) to relate them. In practice, these pose underlying limitation that set an upper limit on how well the models perform. To overcome these limitations, we proposed ways to use experimental data to improve those same contact models, and compared their ability to accurately predict the resolution of contact and impact as a function of the amount of available data.       Last Modified: 08/31/2017       Submitted by: Alberto Rodriguez Garcia]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
