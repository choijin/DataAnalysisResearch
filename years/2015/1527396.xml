<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Task-Cognizant Sparse Sensing for Inference</AwardTitle>
<AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Armand Makowski</SignBlockName>
</ProgramOfficer>
<AbstractNarration>As big data applications continue to grow in size and number, it is of crucial importance to deal only with measurements that are informative for a specific inference task in order to limit the required sensing cost, as well as the related costs of storing or communicating the data. To this end, this project develops a new paradigm of compressive sensing for random processes, where the signal compression and reconstruction strategies are designed to be task-cognizant, hinging on useful signal statistics rather than the original random signals. This research leads to major sensing energy savings, and can benefit a plethora of energy-efficient sensing applications such as location-aware services, weather monitoring, spectrum monitoring, and radio astronomy.&lt;br/&gt;&lt;br/&gt;The main goal of this project is to significantly reduce the cost of sensing as well as the related storage and communication requirements by offering innovative sensing approaches tailored to the inference task of interest. Different from existing compressive sampling, the proposed research leverages the inherent structures of signal statistical information in order to enable reliable inference from sparsely sampled data, rather than solely relying on signal sparsity to enable compression. As such, a new approach to sparse sensing is introduced for random processes, which reveals the fundamental limits of compression in relation to the degrees of freedom inherent to the underlying statistical structure, even in the absence of signal sparsity. Efficient inference techniques and deterministic compressive sampler designs are put forth to affect major savings in the sensing costs while achieving the desired inference quality. These basic results open up opportunities for efficient handling of data-intensive sensing applications in which inference from random processes is of foremost importance.</AbstractNarration>
<MinAmdLetterDate>07/21/2016</MinAmdLetterDate>
<MaxAmdLetterDate>07/12/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1527396</AwardID>
<Investigator>
<FirstName>Zhi</FirstName>
<LastName>Tian</LastName>
<EmailAddress>ztian1@gmu.edu</EmailAddress>
<StartDate>07/21/2016</StartDate>
<EndDate>07/12/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiang</FirstName>
<LastName>Chen</LastName>
<EmailAddress>xchen26@gmu.edu</EmailAddress>
<StartDate>07/12/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>George Mason University</Name>
<CityName>FAIRFAX</CityName>
<ZipCode>220304422</ZipCode>
<PhoneNumber>7039932295</PhoneNumber>
<StreetAddress>4400 UNIVERSITY DR</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
</Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7797</Code>
<Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
</Award>
</rootTag>
