<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: XooMR: Cross-Layer and Cross-Phase Cooperation for Fair and Efficient MapReduce</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/16/2015</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>378071.00</AwardTotalIntnAmount>
<AwardAmount>378692</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>MapReduce has been widely leveraged as a new programming model to tap the power of parallel data processing for Big Data. More and more systems are being deployed to serve data-intensive analytics applications written in MapReduce. Many jobs can show up at the same time on a system with conflicting resource requirements.  This project investigates cross-layer cooperation techniques to achieve system efficiency, cross-phase techniques to enhance job fairness and system throughput, and cross-job task co-scheduling techniques to exploit the temporal relationship among jobs for better throughput and services to analytic queries composed of multiple MapReduce jobs.&lt;br/&gt;&lt;br/&gt;This project has profound impacts in several aspects. These include (1) strengthening computer science courses at Auburn University, and enhancing instruction effectiveness with student research projects on MapReduce; (2) recruiting and cultivating students of diverse backgrounds, particularly under-represented minority and female student groups for careers in computing; (3) disseminating research results as publications, presentations, conference tutorials and demonstrations, releasing open-source software codes, and eventually pushing them for integration into the official Hadoop code base; and (4) collaborating with industry, strengthening research partnerships, and cultivating opportunities for technology transfer to industry.</AbstractNarration>
<MinAmdLetterDate>09/22/2015</MinAmdLetterDate>
<MaxAmdLetterDate>10/17/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1564647</AwardID>
<Investigator>
<FirstName>Weikuan</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Weikuan Yu</PI_FULL_NAME>
<EmailAddress>yuw@cs.fsu.edu</EmailAddress>
<PI_PHON>8506445442</PI_PHON>
<NSF_ID>000492930</NSF_ID>
<StartDate>09/22/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida State University</Name>
<CityName>TALLAHASSEE</CityName>
<ZipCode>323064166</ZipCode>
<PhoneNumber>8506445260</PhoneNumber>
<StreetAddress>874 Traditions Way, 3rd Floor</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790877419</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida State University]]></Name>
<CityName>Tallahassee</CityName>
<StateCode>FL</StateCode>
<ZipCode>323064166</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~346691</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>MapReduce has emerged as a powerful data processing engine that supports large-scale complex analytics applications. However, it adopts a job-level scheduling policy to strive for a balanced distribution of tasks and effective utilization of resources. Such simplistic policy is unable to reconcile the dynamics of different jobs in complex analytic queries, resulting in unfair treatment of different queries, low utilization of system resources, prolonged execution time, and low query throughput. In addition, newer data analytics platforms such as Spark have gained significant interested in industry and academic. Our research has evolved its focus into the Spark framework since 2017. Our main research activities have resulted in three major accomplishments.</p> <p>First, we have introduced a cross-layer two-level scheduling framework to address the lack of coordination among different phases and tasks systematically. Next, we have designed a flat hybridization scheme to leverage non-volatile memory to cache Spark RDD blocks, along with several architectural optimizations such as dynamic memory allocation for block unrolling, asynchronous migration with preemption, and opportunistic eviction. Finally, we have developed a robust tuning framework called ROBOTune that can tackle the issue of high dimensionality and suboptimal configuration, &nbsp;and tune cluster-based data analytics applications quickly for efficient data analytics. It features a Bayesian Optimization engine that overcomes the complex configuration-performance relationship and incrementally searches for an optimal configuration based on the observations of prior configuration samples.</p> <p>&nbsp;</p> <p><strong>Broader impacts on student training and broad participation:</strong></p> <p>&nbsp;</p> <p>12 graduate students (Huansong Fu, Lizhen Shi, Ahana Roy Choudhury, Aditya Bhattacharya, Ahad Alam, Tonmoy Dey, Xingang Fang, Bing Jiao, Muhib Khan, Amit Nath, Rupak Roy, Ismail Ataie) participated in research activities of this project. Two were female. One returned his home country due to a medical condition. Huansong Fu graduated in December 2018 and joined Argonne National Lab as a postdoc. Five students are progressing further to pursue their PhD degree. &nbsp;</p> <p>A total of 9 REU students, including one female African American and 3 Hispanic Americans, participated in this project. Four of them (Joshua Garlitos, Noah Nethery, William Wagner, Alexander De Sabatino) had significant efforts and completed research reports and presentations. At graduation, Joshua Garlitos, Noah Nethery and William Wagner joined Disney, Johnson &amp; Johnson, and Bloomberg, respectively. Alexander De Sabatino joined Georgia Tech to pursue a master's degree.</p> <p>&nbsp;</p> <p><strong>Research products:</strong></p> <p>&nbsp;</p> <p>The project has resulted a total of 15 technical publications. These publications are also listed on the project website <a href="http://castl.cs.fsu.edu/doku.php?id=xoomr">http://castl.cs.fsu.edu/doku.php?id=xoomr</a>). One technical paper is under review by a top conference and another one is being prepared for submission to a top conference. Selected publications are listed below.</p> <p class="level1">1.&nbsp;&nbsp;&nbsp;&nbsp; M. Khan*, Ahad Alam*, A. Nath*, W. Yu. Exploration of Memory Hybridization for RDD Caching in Spark. The 2019 International Symposium on Memory Management. June 2019. Phoenix, AZ.</p> <p class="level1">2.&nbsp;&nbsp;&nbsp;&nbsp; Z. Liu*, A. Nath*, X. Ding, H. Fu*, M. Khan, W. Yu. Multivariate Modeling and Two-Level Scheduling of Analytic Queries Journal of Parallel Computing. February 2019.</p> <p class="level1">3.&nbsp;&nbsp;&nbsp;&nbsp; F. Chowdhury*, Y. Zhu*, T. Heer, S. Paredes*, A. Moody, R. Goldstone, K. Mohror, W. Yu. I/O Characterization and Performance Evaluation of BeeGFS for Deep Learning. The 2019 International Conference on Parallel Processing. August 2019. Kyoto, Japan.</p> <p class="level1">4.&nbsp;&nbsp;&nbsp;&nbsp; W. Yu, Z. Liu, and X. Ding. Semantics-Aware Prediction for Analytic Queries in MapReduce Environment. 11th International Workshop on Parallel Programming Models and Systems Software for High-End Computing. Eugene, OR. August 2018.</p> <p class="level1">5.&nbsp;&nbsp;&nbsp;&nbsp; Zhuo Liu*, Bin Wang*, and W. Yu. HALO: a fast and durable disk write cache using phase change memory. Journal of Cluster Computing. 2017.</p> <p class="level1">6.&nbsp;&nbsp;&nbsp;&nbsp; H. Fu*, M. Gorentla Venkata, Shaeke Salman*, N. Imam, and W. Yu. SHMEMGraph: Efficient and Balanced Graph Processing Using One-sided Communication. 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing. Washington, DC. May 2018.</p> <p class="level1">7.&nbsp;&nbsp;&nbsp;&nbsp; H. Fu*, M. Gorentla Venkata, A. Roy Choudhury*, N. Imam, and W. Yu. High-Performance Key-Value Store On OpenSHMEM. 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing. Madrid, Spain. May 2017.</p> <p class="level1">8.&nbsp;&nbsp;&nbsp;&nbsp; Huansong Fu, Haiquan Chen, Yue Zhu and Weikuan Yu. FARMS: Efficient MapReduce Speculation for Failure Recovery in Short Jobs. Journal of Parallel Computing.</p> <p class="level1">9.&nbsp;&nbsp;&nbsp;&nbsp; B. Wang*, Y. Zhu*, W. Yu. OAWS: Memory Occlusion Aware Warp Scheduling. International Conference on Parallel Architecture and Compilation Techniques. September 2016. Haifa, Israel.</p> <p class="level1">10.&nbsp; C. Xu*, R. Goldstone, Z. Liu*, H. Chen*, B. Neitzel, W. Yu. Exploiting Analytics Shipping with Virtualized MapReduce on HPC Backend Storage Servers. IEEE Transactions on Parallel and Distributed Systems.</p> <p class="level1">11.&nbsp; Huansong Fu, Yue Zhu and Weikuan Yu. A Case Study of MapReduce Speculation Mechanism for Failure Recovery. International Workshop on Data-Intensive Scalable Computing Systems in conjunction with the ACM/IEEE Supercomputing Conference. Austin, TX. Nov 2015.</p> <p class="level1">12.&nbsp; L. Shi, Z. Wang, W. Yu, X. Meng. Performance Evaluation and Tuning of BioPig for Genomic Analysis. The 2015 International Workshop on Data-Intensive Scalable Computing Systems.</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/11/2021<br>      Modified by: Weikuan&nbsp;Yu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ MapReduce has emerged as a powerful data processing engine that supports large-scale complex analytics applications. However, it adopts a job-level scheduling policy to strive for a balanced distribution of tasks and effective utilization of resources. Such simplistic policy is unable to reconcile the dynamics of different jobs in complex analytic queries, resulting in unfair treatment of different queries, low utilization of system resources, prolonged execution time, and low query throughput. In addition, newer data analytics platforms such as Spark have gained significant interested in industry and academic. Our research has evolved its focus into the Spark framework since 2017. Our main research activities have resulted in three major accomplishments.  First, we have introduced a cross-layer two-level scheduling framework to address the lack of coordination among different phases and tasks systematically. Next, we have designed a flat hybridization scheme to leverage non-volatile memory to cache Spark RDD blocks, along with several architectural optimizations such as dynamic memory allocation for block unrolling, asynchronous migration with preemption, and opportunistic eviction. Finally, we have developed a robust tuning framework called ROBOTune that can tackle the issue of high dimensionality and suboptimal configuration,  and tune cluster-based data analytics applications quickly for efficient data analytics. It features a Bayesian Optimization engine that overcomes the complex configuration-performance relationship and incrementally searches for an optimal configuration based on the observations of prior configuration samples.     Broader impacts on student training and broad participation:     12 graduate students (Huansong Fu, Lizhen Shi, Ahana Roy Choudhury, Aditya Bhattacharya, Ahad Alam, Tonmoy Dey, Xingang Fang, Bing Jiao, Muhib Khan, Amit Nath, Rupak Roy, Ismail Ataie) participated in research activities of this project. Two were female. One returned his home country due to a medical condition. Huansong Fu graduated in December 2018 and joined Argonne National Lab as a postdoc. Five students are progressing further to pursue their PhD degree.    A total of 9 REU students, including one female African American and 3 Hispanic Americans, participated in this project. Four of them (Joshua Garlitos, Noah Nethery, William Wagner, Alexander De Sabatino) had significant efforts and completed research reports and presentations. At graduation, Joshua Garlitos, Noah Nethery and William Wagner joined Disney, Johnson &amp; Johnson, and Bloomberg, respectively. Alexander De Sabatino joined Georgia Tech to pursue a master's degree.     Research products:     The project has resulted a total of 15 technical publications. These publications are also listed on the project website http://castl.cs.fsu.edu/doku.php?id=xoomr). One technical paper is under review by a top conference and another one is being prepared for submission to a top conference. Selected publications are listed below. 1.     M. Khan*, Ahad Alam*, A. Nath*, W. Yu. Exploration of Memory Hybridization for RDD Caching in Spark. The 2019 International Symposium on Memory Management. June 2019. Phoenix, AZ. 2.     Z. Liu*, A. Nath*, X. Ding, H. Fu*, M. Khan, W. Yu. Multivariate Modeling and Two-Level Scheduling of Analytic Queries Journal of Parallel Computing. February 2019. 3.     F. Chowdhury*, Y. Zhu*, T. Heer, S. Paredes*, A. Moody, R. Goldstone, K. Mohror, W. Yu. I/O Characterization and Performance Evaluation of BeeGFS for Deep Learning. The 2019 International Conference on Parallel Processing. August 2019. Kyoto, Japan. 4.     W. Yu, Z. Liu, and X. Ding. Semantics-Aware Prediction for Analytic Queries in MapReduce Environment. 11th International Workshop on Parallel Programming Models and Systems Software for High-End Computing. Eugene, OR. August 2018. 5.     Zhuo Liu*, Bin Wang*, and W. Yu. HALO: a fast and durable disk write cache using phase change memory. Journal of Cluster Computing. 2017. 6.     H. Fu*, M. Gorentla Venkata, Shaeke Salman*, N. Imam, and W. Yu. SHMEMGraph: Efficient and Balanced Graph Processing Using One-sided Communication. 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing. Washington, DC. May 2018. 7.     H. Fu*, M. Gorentla Venkata, A. Roy Choudhury*, N. Imam, and W. Yu. High-Performance Key-Value Store On OpenSHMEM. 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing. Madrid, Spain. May 2017. 8.     Huansong Fu, Haiquan Chen, Yue Zhu and Weikuan Yu. FARMS: Efficient MapReduce Speculation for Failure Recovery in Short Jobs. Journal of Parallel Computing. 9.     B. Wang*, Y. Zhu*, W. Yu. OAWS: Memory Occlusion Aware Warp Scheduling. International Conference on Parallel Architecture and Compilation Techniques. September 2016. Haifa, Israel. 10.  C. Xu*, R. Goldstone, Z. Liu*, H. Chen*, B. Neitzel, W. Yu. Exploiting Analytics Shipping with Virtualized MapReduce on HPC Backend Storage Servers. IEEE Transactions on Parallel and Distributed Systems. 11.  Huansong Fu, Yue Zhu and Weikuan Yu. A Case Study of MapReduce Speculation Mechanism for Failure Recovery. International Workshop on Data-Intensive Scalable Computing Systems in conjunction with the ACM/IEEE Supercomputing Conference. Austin, TX. Nov 2015. 12.  L. Shi, Z. Wang, W. Yu, X. Meng. Performance Evaluation and Tuning of BioPig for Genomic Analysis. The 2015 International Workshop on Data-Intensive Scalable Computing Systems.          Last Modified: 01/11/2021       Submitted by: Weikuan Yu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
