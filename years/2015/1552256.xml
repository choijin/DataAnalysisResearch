<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Collaborative Research: Exploring Models for Conveying Imminent Robot Failures to Allow for Human Intervention</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>109521.00</AwardTotalIntnAmount>
<AwardAmount>117521</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In this exploratory research, the PIs will seek to advance the state of the science on how best to convey a robot's imminent failure to a human (whether an operator, supervisor, or bystander), in a manner that could allow the human to intervene as effectively as possible to prevent the failure. This project has the potential to dramatically increase the safety of humans in and around autonomous robots and vehicles.  Specific goals are to discover design principles for robot systems with respect to conveying failure, and to identify methods for expressing failure so that humans react appropriately.  The research will focus on three use cases: remote operation, co-located operation, and bystander interaction.  To these ends, the team will utilize a variety of robots in order to support different applications and movement scales.  Robots available to the team include small and mid-size unmanned ground vehicles, human-scale torso robots, a robot wheelchair, a telepresence robot, and an autonomous Jeep.  Project outcomes will impact the field of human-robot interaction and the future use of robots in many application domains, particularly those of mobile and manipulation robots, including autonomous vehicles, factory robots, and assistive technology, by enhancing productivity and task performance, increasing personal safety for those who work in hazardous occupations, and improving the lives of persons with disabilities.&lt;br/&gt;&lt;br/&gt;The PIs' core research questions are informed by their substantial prior work with task-oriented robots.  Based on that experience and other studies, they argue that the following three main factors strongly influence user actions during robot failure: perceived risk (e.g., a robot that crashes frequently is generally perceived as a high risk robot), perceived severity (e.g., the failure of a small robot made of soft materials is generally perceived as less severe than that of a full body humanoid robot), and role (e.g., is the user an operators or a bystander).  Unexplored research questions about the manner in which these factors impact failure include.  How do these factors, both independently and in combination, influence HRI during robot failures?  How do humans utilize these factors during robot failure, and does this utilization have high variability or are humans very consistent?  These factors will be used as independent variables during studies which will advance knowledge in three core areas: formulation and validation of generalizable quantitative and qualitative metrics for measuring a person's response to an imminent failure in a robot system; discovery of appropriate ways to communicate failure states to humans; and initial development of common design guidelines for handling failures.  The primary goal is to make it easier for humans to rapidly understand failure events and to act or assist appropriately in a timely manner.  The PIs are specifically focused on the human-robot interaction aspect of robot failures.  As such, they will track literature and research on diagnosing failures, but will not develop new systems or concepts for this step.  Instead, the team will seek appropriate and effective ways to convey failures to humans, appropriate human responses during failures, and appropriate failure states when human action is not possible or is insufficient.</AbstractNarration>
<MinAmdLetterDate>08/25/2015</MinAmdLetterDate>
<MaxAmdLetterDate>05/18/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1552256</AwardID>
<Investigator>
<FirstName>Aaron</FirstName>
<LastName>Steinfeld</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Aaron Steinfeld</PI_FULL_NAME>
<EmailAddress>steinfeld@cmu.edu</EmailAddress>
<PI_PHON>4122686346</PI_PHON>
<NSF_ID>000158622</NSF_ID>
<StartDate>08/25/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~109521</FUND_OBLG>
<FUND_OBLG>2016~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project, in collaboration with Holly Yanco's lab at the University of Massachusetts Lowell (IIS-1552228), explored ways to advance the state of the science on how best to convey a robot's imminent failure to a human (whether an operator, supervisor, or bystander), in a manner that could allow the human to intervene as effectively as possible to prevent the failure. The team was also interested in how humans interact with failing robots and how this is influenced by robot behaviors.</p> <p><br />Work by the team revealed a variety of important findings. Most of the team's work utilized a human-height, semi-humanoid robot. The initial study, which focused on a materials handling task, suggested that perceived personal risk outweighs perceived cost of damage. While this may seem logical, there are many instances in factory settings where people will place themselves in danger in order to lower costs. This was explored in more depth during the second study. Participants observed a robot while it performed a grocery packing task and were given opportunities to react to and assist the robot in multiple failure cases. The team explored several interaction approaches (e.g., robot feedback on current state, etc.). The most significant finding was that approximately 60% of the participants who were exposed to personal and property risk then physically entered the robot's workspace to help during a subsequent assistance trial. The study revealed important factors that influence trust, perception of safety, and whether participants will assist a robot after witnessing failure.&nbsp;</p> <p><br />The team also collaborated with another project on interactions between autonomous vehicles (AV) and pedestrians. This revealed a variety of expectations about AV competence and a need for increased transparency regarding AV behaviors. Another collaboration revealed that bystanders are likely to help robots when their failure is due to the actions of other humans. However, this help was almost always given only after the failure. The most effective robot action for obtaining assistance from the bystander appears to register the problem and then pretend to shut down.</p> <p><br />Key outputs for this project included new methodologies for examining human interaction with failing robots, development and validation of new measures and interactions, and improvement of existing research software. The team published a Masters thesis, 2 peer-reviewed papers, one peer-reviewed video submission, and has one more paper in preparation.</p> <p><br />The team also had significant impact on professional capacity through integration of research results into numerous classes and participation by students. At CMU, the research involved one completed Masters student and 3 undergraduate students (2 as REUs). The MS student has since joined a robotics company, one of the undergrads entered a technical Masters program, and another has applied for PhD programs. All four students were women and/or underrepresented minorities.</p> <p><br />Finally, the team has extensively disseminated results to classes, industry, K-12 students, and through numerous professional organizations and conferences. The two PIs were also active in the organization and program committees of several iterations of the ACM/IEEE International Conference on Human-Robot Interaction.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/14/2018<br>      Modified by: Aaron&nbsp;Steinfeld</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project, in collaboration with Holly Yanco's lab at the University of Massachusetts Lowell (IIS-1552228), explored ways to advance the state of the science on how best to convey a robot's imminent failure to a human (whether an operator, supervisor, or bystander), in a manner that could allow the human to intervene as effectively as possible to prevent the failure. The team was also interested in how humans interact with failing robots and how this is influenced by robot behaviors.   Work by the team revealed a variety of important findings. Most of the team's work utilized a human-height, semi-humanoid robot. The initial study, which focused on a materials handling task, suggested that perceived personal risk outweighs perceived cost of damage. While this may seem logical, there are many instances in factory settings where people will place themselves in danger in order to lower costs. This was explored in more depth during the second study. Participants observed a robot while it performed a grocery packing task and were given opportunities to react to and assist the robot in multiple failure cases. The team explored several interaction approaches (e.g., robot feedback on current state, etc.). The most significant finding was that approximately 60% of the participants who were exposed to personal and property risk then physically entered the robot's workspace to help during a subsequent assistance trial. The study revealed important factors that influence trust, perception of safety, and whether participants will assist a robot after witnessing failure.    The team also collaborated with another project on interactions between autonomous vehicles (AV) and pedestrians. This revealed a variety of expectations about AV competence and a need for increased transparency regarding AV behaviors. Another collaboration revealed that bystanders are likely to help robots when their failure is due to the actions of other humans. However, this help was almost always given only after the failure. The most effective robot action for obtaining assistance from the bystander appears to register the problem and then pretend to shut down.   Key outputs for this project included new methodologies for examining human interaction with failing robots, development and validation of new measures and interactions, and improvement of existing research software. The team published a Masters thesis, 2 peer-reviewed papers, one peer-reviewed video submission, and has one more paper in preparation.   The team also had significant impact on professional capacity through integration of research results into numerous classes and participation by students. At CMU, the research involved one completed Masters student and 3 undergraduate students (2 as REUs). The MS student has since joined a robotics company, one of the undergrads entered a technical Masters program, and another has applied for PhD programs. All four students were women and/or underrepresented minorities.   Finally, the team has extensively disseminated results to classes, industry, K-12 students, and through numerous professional organizations and conferences. The two PIs were also active in the organization and program committees of several iterations of the ACM/IEEE International Conference on Human-Robot Interaction.                Last Modified: 12/14/2018       Submitted by: Aaron Steinfeld]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
