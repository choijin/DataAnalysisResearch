<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Correspondence Mechanisms in Visual Cognition</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>286782.00</AwardTotalIntnAmount>
<AwardAmount>286782</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Hout</SignBlockName>
<PO_EMAI>mhout@nsf.gov</PO_EMAI>
<PO_PHON>7032922163</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Visual information is initially received by the eyes; however, the experience of vision itself is the result of complex computations carried out deep within the brain. Though many aspects of human vision are well-understood, the mechanisms by which the visual system maps recent memory (what happened a moment ago) onto incoming visual signals (what is happening now) remain a critical question for cognitive science. As events unfold in real time, there needs to be a mechanism for continually linking the current visual information with what just happened. For example, tracking a moving object requires mapping very recent visual memory signals onto the visual signals currently entering from the retina and tying this information together. The same holds true when trying to detect changes in a scene, or when trying to remember the positions of groups of objects, or even when trying to link landmarks on a map to landmarks in real space. This research project aims to characterize the correspondence mechanisms that enable this mapping between the recent and the current. Understanding how the human visual system accomplishes correspondence mappings is critical for understanding complex visual activities and the development of specialized visual skills such those involved in driving, radar control, video analysis, satallite imagery analysis, and baggage screening. Understanding correspondence mechanisms could also inform the design of artificial vision systems. &lt;br/&gt;&lt;br/&gt;The research achieves its goals by combining eye tracking methodology and probabilistic models derived from computer vision algorithms, along with behavioral tasks that engage motion tracking, spatial working memory, and visual working memory. Eye tracking is a crucial component of the project because, in humans, the quality of received visual signals depends heavily on a source's distance from an observer's fixation (eccentricity). The research project therefore begins with experiments that compare observers' performance as a function of their fixations as well as simulations by computational models that adopt those empirically obtained fixations. Subsequent experiments then investigate methods for facilitating and training fixation to improve observer performance. A major implication of the research is that fixation selection places tremendous constraints on the accuracy of probabilistic correspondence algorithms, and as a result, on the ability to effectively obtain, store, and retrieve visual information.</AbstractNarration>
<MinAmdLetterDate>07/21/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1534568</AwardID>
<Investigator>
<FirstName>Jonathan</FirstName>
<LastName>Flombaum</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonathan Flombaum</PI_FULL_NAME>
<EmailAddress>flombaum@jhu.edu</EmailAddress>
<PI_PHON>4105168111</PI_PHON>
<NSF_ID>000597236</NSF_ID>
<StartDate>07/21/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName/>
<StateCode>MD</StateCode>
<ZipCode>212182686</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~286782</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="white-space: pre;"> </span>This funded project sought to investigate how the human visual system addresses the computational problems of data assignment and object correspondence. By &lsquo;data assignment&rsquo;, we mean mechanisms that determine when simultaneous or nearly simultaneous signals have arrived from the same source, for example, whenever color and form signals are &lsquo;bound&rsquo; (implying that they share the same object as a source). And by &lsquo;correspondence&rsquo; we mean mechanisms that assign sources to signals over time, for example, whenever a moving object is perceived as a persisting individual (implying that a set of spatially and temporally separate signals share that object as their source).</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; All this may seem rather specific. But assignment and correspondence are actually instances of a general problem, <em>one of attributing signals to sources</em>. Such problems arise whenever signals can be received from sources that are unknown to the receiver in advance. Visual perception routinely operates under these conditions. Assignment and correspondence accordingly are not independent or isolated problems. We investigated them in this project with the goal of understanding how they constrain visual processing in general.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In particular, our research on assignment and correspondence has implications with respect to the causes of human cognitive limits: questions such as &lsquo;why do we forget what we saw?&rsquo; and &lsquo;why can&rsquo;t we track moving objects perfectly?&rsquo; Our research suggests that performance limits are caused by limited mental and neural resources to a far lesser extent than is usually thought; instead, assignment and correspondence appear to be inherently limiting computational factors. In other words, some of what limits human performance is not a limited number of neurons, or energy, or anything like that; it&rsquo;s that we face problems that are genuinely difficult in a concrete computational sense.</p> <p><span style="white-space: pre;"> </span>Commensurate with the topical scope of our work, we adopt a wide range of methods including psychophysics, computational modelling, and eye tracking. The funding provided allowed us to use all these methods in the service of research that we published in about a half of a dozen peer-reviewed papers in places such as <em>The Journal of Vision, Cognition, </em>and <em>The Journal of Experimental Psychology. </em>We also made presentations at major international meetings, particularly the annual meeting of the Vision Sciences Society.</p> <p><span style="white-space: pre;"> </span>Four graduate students were supported during some or all of their PhD studies over the course of the award, all of whom have gone on to research positions at other universities or in related industries. The funding also supported more than a dozen undergraduates who worked as research assistants in the lab, testing participants, analyzing data, and learning about the conduct of research on human vision. &nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/29/2020<br>      Modified by: Jonathan&nbsp;Flombaum</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This funded project sought to investigate how the human visual system addresses the computational problems of data assignment and object correspondence. By ‘data assignment’, we mean mechanisms that determine when simultaneous or nearly simultaneous signals have arrived from the same source, for example, whenever color and form signals are ‘bound’ (implying that they share the same object as a source). And by ‘correspondence’ we mean mechanisms that assign sources to signals over time, for example, whenever a moving object is perceived as a persisting individual (implying that a set of spatially and temporally separate signals share that object as their source).              All this may seem rather specific. But assignment and correspondence are actually instances of a general problem, one of attributing signals to sources. Such problems arise whenever signals can be received from sources that are unknown to the receiver in advance. Visual perception routinely operates under these conditions. Assignment and correspondence accordingly are not independent or isolated problems. We investigated them in this project with the goal of understanding how they constrain visual processing in general.              In particular, our research on assignment and correspondence has implications with respect to the causes of human cognitive limits: questions such as ‘why do we forget what we saw?’ and ‘why can’t we track moving objects perfectly?’ Our research suggests that performance limits are caused by limited mental and neural resources to a far lesser extent than is usually thought; instead, assignment and correspondence appear to be inherently limiting computational factors. In other words, some of what limits human performance is not a limited number of neurons, or energy, or anything like that; it’s that we face problems that are genuinely difficult in a concrete computational sense.   Commensurate with the topical scope of our work, we adopt a wide range of methods including psychophysics, computational modelling, and eye tracking. The funding provided allowed us to use all these methods in the service of research that we published in about a half of a dozen peer-reviewed papers in places such as The Journal of Vision, Cognition, and The Journal of Experimental Psychology. We also made presentations at major international meetings, particularly the annual meeting of the Vision Sciences Society.   Four graduate students were supported during some or all of their PhD studies over the course of the award, all of whom have gone on to research positions at other universities or in related industries. The funding also supported more than a dozen undergraduates who worked as research assistants in the lab, testing participants, analyzing data, and learning about the conduct of research on human vision.            Last Modified: 10/29/2020       Submitted by: Jonathan Flombaum]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
