<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Assistive Digital Vision for the Blind</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>730331.00</AwardTotalIntnAmount>
<AwardAmount>730331</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this project is to address the unmet needs of blind and visually impaired population in order to increased their mobility independence with the aid of an intelligent wearable electronic device, compatible with the white cane, in a simple and cost-effective manner. The outcome of this project will contribute to scientific and technological understanding of environmental sensing and process automation by developing an integrated system comprised of sensors and underlying algorithms capable of gathering, processing, and interpreting environmental data and communicating relevant information to the user. The envisioned product can potentially meet the needs of 2.1% of the U.S. population who are considered legally blind, as well as make further contribution to the field of robotics, artificial intelligence, and other assistive technologies wherein a better understanding of the environment is desired.          &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase 2 project seeks to create a state of the art wearable device for the visually impaired that will enhance their situational awareness through the use of multiple sensors and intelligent algorithms. The main research objective is to develop an intelligent  wearable device that will provide ability to detect above ground obstacles and recognize various categories of objects. In spite of significant technological breakthroughs, leading to many product innovations, there is very little technological progress for the visually impaired despite increased population longevity and significant demand for products that promote independent living. The proposed project will address the needs of the visually impaired in an intuitive and automated manner.</AbstractNarration>
<MinAmdLetterDate>09/14/2015</MinAmdLetterDate>
<MaxAmdLetterDate>09/14/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1534190</AwardID>
<Investigator>
<FirstName>Arman</FirstName>
<LastName>Ghodousi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arman Ghodousi</PI_FULL_NAME>
<EmailAddress>arman@g-technologygroup.com</EmailAddress>
<PI_PHON>4805443192</PI_PHON>
<NSF_ID>000660677</NSF_ID>
<StartDate>09/14/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ghodousi LLC</Name>
<CityName>Alexandria</CityName>
<ZipCode>223120000</ZipCode>
<PhoneNumber>4805443192</PhoneNumber>
<StreetAddress>5702 General Washington DR.</StreetAddress>
<StreetAddress2><![CDATA[Suite G]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079168015</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GHODOUSI, LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ghodousi, LLC]]></Name>
<CityName>Alexandria</CityName>
<StateCode>VA</StateCode>
<ZipCode>223144687</ZipCode>
<StreetAddress><![CDATA[2331 Mill Rd Suite 100]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~730331</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This NSF Phase II research effort has resulted in the preparation and successful demonstration of a fully integrated prototype system containing a miniaturized computer, camera, and sonar, that can detect obstacles and acquire and analyze an image to recognize objects.&nbsp; The project included concurrent development and integration of hardware and software platforms that serve as a versatile platform for inclusion into a number of marketable applications.&nbsp;</p> <p>Software efforts focused on the development of an object recognition algorithm that required a complete understanding of parameters of image size and classification precision and their effect on analysis times.&nbsp; Development and training of this DNN network resulted in an object recognition response time of approximately 3.5 seconds, which is an order of magnitude improvement over the Phase I object recognition times of 40 seconds.&nbsp; In addition, the objective parameter of less than 3 seconds is believed attainable with further algorithm training using a larger data set.&nbsp; Hardware development efforts focused on a simple, miniature housing for all device components that could be further adapted for specific product applications.&nbsp; Object recognition results met threshold objective targets, as common household objects (doors, chairs, microwaves, and refrigerators) were detected at or above the 90% recognition accuracy target when viewed within a 10-foot distance.&nbsp;</p> <p>These results demonstrate the utility of the work product in marketable applications, particularly for the blind and low vision population.&nbsp; One such products is wearable glasses to assist a user in locating objects of interest, particularly doors, windows, and street signs. &nbsp;A second mobility assistive device using the new capability is a sonar guide that can be attached to a walker or rollator to alert the user to elevation changes and approaching objects, in addition to the location of specific objects.&nbsp; On a broader scale, the research has wider implications in allowing &ldquo;digital vision&rdquo; to be incorporated into affordable products requiring portability.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/10/2017<br>      Modified by: Arman&nbsp;Ghodousi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This NSF Phase II research effort has resulted in the preparation and successful demonstration of a fully integrated prototype system containing a miniaturized computer, camera, and sonar, that can detect obstacles and acquire and analyze an image to recognize objects.  The project included concurrent development and integration of hardware and software platforms that serve as a versatile platform for inclusion into a number of marketable applications.   Software efforts focused on the development of an object recognition algorithm that required a complete understanding of parameters of image size and classification precision and their effect on analysis times.  Development and training of this DNN network resulted in an object recognition response time of approximately 3.5 seconds, which is an order of magnitude improvement over the Phase I object recognition times of 40 seconds.  In addition, the objective parameter of less than 3 seconds is believed attainable with further algorithm training using a larger data set.  Hardware development efforts focused on a simple, miniature housing for all device components that could be further adapted for specific product applications.  Object recognition results met threshold objective targets, as common household objects (doors, chairs, microwaves, and refrigerators) were detected at or above the 90% recognition accuracy target when viewed within a 10-foot distance.   These results demonstrate the utility of the work product in marketable applications, particularly for the blind and low vision population.  One such products is wearable glasses to assist a user in locating objects of interest, particularly doors, windows, and street signs.  A second mobility assistive device using the new capability is a sonar guide that can be attached to a walker or rollator to alert the user to elevation changes and approaching objects, in addition to the location of specific objects.  On a broader scale, the research has wider implications in allowing "digital vision" to be incorporated into affordable products requiring portability.          Last Modified: 11/10/2017       Submitted by: Arman Ghodousi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
