<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Collaborative Research: Dynamic Robot Guides for Emergency Evacuations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>282112.00</AwardTotalIntnAmount>
<AwardAmount>282112</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Irina Dolinskaya</SignBlockName>
<PO_EMAI>idolinsk@nsf.gov</PO_EMAI>
<PO_PHON>7032927078</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Crowd stampede is one of the most harmful collective human behaviors. In incidents throughout history, panic due, for example, to the outbreak of fire or the unexpected discharge of firearms has been a greater hazard than the original triggering events. This project supports fundamental research on the influence of human-robot interaction on crowd dynamics, towards the design of dynamic robot control algorithms to assist humans and prevent panic in emergency situations. The ultimate goal of this research will be reconfigurable robot guides that can respond to a variety of needs. These include different types of emergency evacuation, as well as non-emergency situations involving mass movement of crowds, such as at parades, concerts, or other large public events. The project integrates research with educational activities through robot-centric education and short course development. To engage the younger generation with science and technology, the project will partner with a university educational center and a community college for various outreach activities.&lt;br/&gt;&lt;br/&gt;The objective of the project is to investigate human-robot interaction in crowd dynamics, develop optimal feedback control to regulate human flow distribution, and design robot-assisted emergency evacuation algorithms. The research will advance the state-of-the-art in human-robot interaction, and fill a gap in robotics research by experimentally validating and measuring the interaction forces governing human-robot interaction in crowd dynamics. The proposed robot motion primitive design leads to new approaches for learning-based robot motion planning to efficiently engage humans. The project validates the use of dynamic robot guides in real human-robot interaction experiments in indoor environments. Simulation validation in benchmark environments such as shopping-malls and campus buildings will also be performed, and the efficiency of alternative robot-assisted evacuation strategies will be evaluated. While primarily for intelligent robots, the research results are anticipated to be cross-cutting and applicable to other areas such as transportation, communication, and control.</AbstractNarration>
<MinAmdLetterDate>08/03/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/03/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1526835</AwardID>
<Investigator>
<FirstName>Haibo</FirstName>
<LastName>He</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Haibo He</PI_FULL_NAME>
<EmailAddress>haibohe@uri.edu</EmailAddress>
<PI_PHON>4018745844</PI_PHON>
<NSF_ID>000557807</NSF_ID>
<StartDate>08/03/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rhode Island</Name>
<CityName>KINGSTON</CityName>
<ZipCode>028811967</ZipCode>
<PhoneNumber>4018742635</PhoneNumber>
<StreetAddress>RESEARCH OFFICE</StreetAddress>
<StreetAddress2><![CDATA[70 LOWER COLLEGE ROAD]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>144017188</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF RHODE ISLAND</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>075705780</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rhode Island]]></Name>
<CityName>Kingston</CityName>
<StateCode>RI</StateCode>
<ZipCode>028812019</ZipCode>
<StreetAddress><![CDATA[Kelley A223, 4 East Alumni Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>030E</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8024</Code>
<Text>Complex Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~282112</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Developing innovative human-robot interaction (HRI) approaches for robot-assisted evacuation is of critical importance to prevent crowd stampede, which has been considered as one of the most harmful collective human behaviors. Understanding such collective human behaviors is crucial to avoid such pedestrian crowd incidents. This project characterized the governing rules and validated the interaction forces between humans and robots in crowd dynamics, developed adaptive control and learning methods to regulate pedestrian flow, and designed robot-assisted emergency evacuation algorithms. Unlike many of the existing efforts that purely focuses on the evacuation planning and optimal design of facilities to improve pedestrian flows, this project introduced mobile robots to influence the collective motion of pedestrian crowd through human-robot interaction and machine learning approaches.&nbsp;</p> <p>The team has <span>developed</span>&nbsp;mathematical models that interprets the self-driving force and interactive forces with others in human mobility. Based on such models, the team has designed learning-based algorithms to have intelligent co-robot systems to assist pedestrian flow, which can be widely used in environments like shopping malls, museums, campus buildings, to name a few. Intensive modeling and simulation have been carried out to verify and validate the effectiveness of the developed approaches.&nbsp;</p> <p>The outcomes of this project are significant, ranging from new knowledge and methods to advance the robot-assisted&nbsp;emergency evacuation research, to education and outreach programs across different disciplines. Over the project period, the team published a series of high impact peer-reviewed papers in flagship conferences and journals, including IEEE Transactions on Cybernetics, IEEE Transactions on Human Machine Systems, IEEE Transactions on Industrial Electronics, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), American Control Conference (ACC), International Joint Conference on Neural Networks (IJCNN), among others. This project provided unique opportunities for students to work on cutting-edge research problems in robotics, machine learning, and human-robot interaction, leading to productive research results as well as intensive student training. One notable outcome is that two Ph.D. students graduated during this project period and they both joined academia as tenure-track assistant professor.&nbsp;&nbsp;</p> <p>The results generated in this project bridge different disciplines in control, machine learning, robotics and&nbsp;behavior science, and can be generalized to other areas such as intelligent transportation systems and social science research. This project also provided tremendous opportunities for educational and outreach activities, including the outreach to the International Engineering Program (IEP) at the University of Rhode Island (URI), and mentoring of summer internship undergraduate students. All of these have developed unique platforms and opportunities&nbsp;in educating and training students in research in an integrative way.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/05/2019<br>      Modified by: Haibo&nbsp;He</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573007748454_Picture1--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573007748454_Picture1--rgov-800width.jpg" title="Robot-assisted pedestrian flow optimization with adaptive dynamic programming (ADP)"><img src="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573007748454_Picture1--rgov-66x44.jpg" alt="Robot-assisted pedestrian flow optimization with adaptive dynamic programming (ADP)"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Adaptive dynamic programming (ADP) based approach for robot-assisted pedestrian flow optimization. The ADP control block uses the measured camera data as inputs, observes reward accordingly, and output optimal robot motion frequency in real time.</div> <div class="imageCredit">Haibo He</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Haibo&nbsp;He</div> <div class="imageTitle">Robot-assisted pedestrian flow optimization with adaptive dynamic programming (ADP)</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573007811199_Picture2--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573007811199_Picture2--rgov-800width.jpg" title="Crowd pressure reduced with robot-assisted pedestrian regulation"><img src="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573007811199_Picture2--rgov-66x44.jpg" alt="Crowd pressure reduced with robot-assisted pedestrian regulation"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Robot-assisted pedestrian regulation to reduce the crowd pressure and alleviate the risk of crowd accidents. The color bar indicates the scale of crowd pressure.</div> <div class="imageCredit">Haibo He</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Haibo&nbsp;He</div> <div class="imageTitle">Crowd pressure reduced with robot-assisted pedestrian regulation</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008207914_Picture3--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008207914_Picture3--rgov-800width.jpg" title="Robot-assisted pedestrian regulation simulator"><img src="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008207914_Picture3--rgov-66x44.jpg" alt="Robot-assisted pedestrian regulation simulator"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The team designed a robot-assisted pedestrian regulation simulator with PedSim in Robot Operating System (ROS).</div> <div class="imageCredit">Haibo He</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Haibo&nbsp;He</div> <div class="imageTitle">Robot-assisted pedestrian regulation simulator</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008258533_Picture4--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008258533_Picture4--rgov-800width.jpg" title="Human-robot interaction characteristics"><img src="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008258533_Picture4--rgov-66x44.jpg" alt="Human-robot interaction characteristics"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The team revealed the human-robot interaction characteristics and identified the optimal region for robot-assisted pedestrian regulation. (a) top view, (b) 3-D view.</div> <div class="imageCredit">Haibo He</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Haibo&nbsp;He</div> <div class="imageTitle">Human-robot interaction characteristics</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008313940_Picture5--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008313940_Picture5--rgov-800width.jpg" title="Robot-assisted pedestrian regulation with deep reinforcement learning"><img src="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008313940_Picture5--rgov-66x44.jpg" alt="Robot-assisted pedestrian regulation with deep reinforcement learning"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The team developed a robot motion planner for pedestrian regulation with deep reinforcement learning. The trajectory of the robot converges to the optimal region, and instantaneous outflow with the proposed regulation is higher than that without robot regulation.</div> <div class="imageCredit">Haibo He</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Haibo&nbsp;He</div> <div class="imageTitle">Robot-assisted pedestrian regulation with deep reinforcement learning</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008390587_Picture6--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008390587_Picture6--rgov-800width.jpg" title="The feature representations extracted by deep neural network"><img src="/por/images/Reports/POR/2019/1526835/1526835_10382904_1573008390587_Picture6--rgov-66x44.jpg" alt="The feature representations extracted by deep neural network"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The team investigated and visualized the representations extracted by the deep neural network and revealed how these representations contribute to the successful performance on this pedestrian flow regulation problem.</div> <div class="imageCredit">Haibo He</div> <div class="imageSubmitted">Haibo&nbsp;He</div> <div class="imageTitle">The feature representations extracted by deep neural network</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Developing innovative human-robot interaction (HRI) approaches for robot-assisted evacuation is of critical importance to prevent crowd stampede, which has been considered as one of the most harmful collective human behaviors. Understanding such collective human behaviors is crucial to avoid such pedestrian crowd incidents. This project characterized the governing rules and validated the interaction forces between humans and robots in crowd dynamics, developed adaptive control and learning methods to regulate pedestrian flow, and designed robot-assisted emergency evacuation algorithms. Unlike many of the existing efforts that purely focuses on the evacuation planning and optimal design of facilities to improve pedestrian flows, this project introduced mobile robots to influence the collective motion of pedestrian crowd through human-robot interaction and machine learning approaches.   The team has developed mathematical models that interprets the self-driving force and interactive forces with others in human mobility. Based on such models, the team has designed learning-based algorithms to have intelligent co-robot systems to assist pedestrian flow, which can be widely used in environments like shopping malls, museums, campus buildings, to name a few. Intensive modeling and simulation have been carried out to verify and validate the effectiveness of the developed approaches.   The outcomes of this project are significant, ranging from new knowledge and methods to advance the robot-assisted emergency evacuation research, to education and outreach programs across different disciplines. Over the project period, the team published a series of high impact peer-reviewed papers in flagship conferences and journals, including IEEE Transactions on Cybernetics, IEEE Transactions on Human Machine Systems, IEEE Transactions on Industrial Electronics, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), American Control Conference (ACC), International Joint Conference on Neural Networks (IJCNN), among others. This project provided unique opportunities for students to work on cutting-edge research problems in robotics, machine learning, and human-robot interaction, leading to productive research results as well as intensive student training. One notable outcome is that two Ph.D. students graduated during this project period and they both joined academia as tenure-track assistant professor.    The results generated in this project bridge different disciplines in control, machine learning, robotics and behavior science, and can be generalized to other areas such as intelligent transportation systems and social science research. This project also provided tremendous opportunities for educational and outreach activities, including the outreach to the International Engineering Program (IEP) at the University of Rhode Island (URI), and mentoring of summer internship undergraduate students. All of these have developed unique platforms and opportunities in educating and training students in research in an integrative way.           Last Modified: 11/05/2019       Submitted by: Haibo He]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
