<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SL-CN: Cortical Architectures for Robust Adaptive Perception and Action</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>749779.00</AwardTotalIntnAmount>
<AwardAmount>797779</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04010000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SMA</Abbreviation>
<LongName>SBE Off Of Multidisciplinary Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Soo-Siang Lim</SignBlockName>
<PO_EMAI>slim@nsf.gov</PO_EMAI>
<PO_PHON>7032927878</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The motivation for this biologically-inspired approach is to design systems that perceive and act in cluttered and noisy scenes that they have never experienced. This stands in contrast with the state of the art in computational engineering systems that need to be re-trained each time they confront an unanticipated environment. The main reason is that current approaches to perception address specific problems in isolation and do not consider that the primary role of perception is to support systems with bodies in action. As a result, they are constrained to the situations for which they were trained and cannot react to changing tasks and scenes. By focusing on cognition primitives rather than specific applications, the work is expected to greatly advance the state of the art of machine perception and lead to the development of systems that can robustly and on-line adapt to new environments, react to novel situations and learn new contexts. To do so, novel theoretical formulations of perception and action and high-speed, low-power, hardware implementations with on-line learning capabilities will be studied while assimilating new insights from the neurosciences. Consequently, this work will network neuroscience, cognitive science, applied mathematics, computer science and engineering so as to lower one of the few remaining barriers that keeps interactive robots in the realm of science fiction. Beyond the scholarly contribution, the work is expected to provide know-how for the design of systems with adaptive perception in a modular fashion with reusable components. Such systems have applications in computational vision and auditory perception problems and can advance the industry of cognitive biologically-inspired robotics and assistive devices.&lt;br/&gt;&lt;br/&gt;This proposal sets forward novel ideas in the design of intelligent perceptual systems and the development of synthetic intelligence. Just about any task which an intelligent system solves involves the interplay of four basic processes that are devoted to: (a) context, (b) attention, (c) segmentation and (d) categorization. The members of the proposed network will study these canonical cognitive primitives by combining neural modeling with neural and behavioral experiments, theoretical and computational modeling and implementation in robotics.  The findings of theoretical insights will then be adapted to satisfy the demands of realistic behavior, and to develop technological solutions for applications of robust and invariant perception and action. The proposed collaborative network will consist of a small science and engineering research team to directly address the questions in robust adaptive perception and action. It will then direct personnel, and inject results and pedagogical content to a Summer Workshop that aims to include a global network of researchers.</AbstractNarration>
<MinAmdLetterDate>08/20/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1540916</AwardID>
<Investigator>
<FirstName>Shihab</FirstName>
<LastName>Shamma</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shihab A Shamma</PI_FULL_NAME>
<EmailAddress>sas@isr.umd.edu</EmailAddress>
<PI_PHON>3014056842</PI_PHON>
<NSF_ID>000461861</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andreas</FirstName>
<LastName>Andreou</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andreas G Andreou</PI_FULL_NAME>
<EmailAddress>andreou@jhu.edu</EmailAddress>
<PI_PHON>4105164276</PI_PHON>
<NSF_ID>000421506</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Cornelia</FirstName>
<LastName>Fermuller</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Cornelia M Fermuller</PI_FULL_NAME>
<EmailAddress>fer@cfar.umd.edu</EmailAddress>
<PI_PHON>3014054526</PI_PHON>
<NSF_ID>000235233</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>Horiuchi</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy K Horiuchi</PI_FULL_NAME>
<EmailAddress>timmer@isr.umd.edu</EmailAddress>
<PI_PHON>3014057412</PI_PHON>
<NSF_ID>000441772</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ralph</FirstName>
<LastName>Etienne-Cummings</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ralph Etienne-Cummings</PI_FULL_NAME>
<EmailAddress>retienne@jhu.edu</EmailAddress>
<PI_PHON>4105163494</PI_PHON>
<NSF_ID>000360105</NSF_ID>
<StartDate>08/20/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>004Y</Code>
<Text>Science of Learning</Text>
</ProgramElement>
<ProgramElement>
<Code>7278</Code>
<Text>SCIENCE OF LEARN CTRS- CENTERS</Text>
</ProgramElement>
<ProgramReference>
<Code>059Z</Code>
<Text>Science of Learning</Text>
</ProgramReference>
<ProgramReference>
<Code>110E</Code>
<Text>EDUCATION RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>1340</Code>
<Text>ENGINEERING EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
<ProgramReference>
<Code>7956</Code>
<Text>SBE Interdisciplinary Research</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~749779</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<FUND_OBLG>2017~16000</FUND_OBLG>
<FUND_OBLG>2018~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Default">The Science of Learning Collaborative Network (SL-CN) on Cortical Architectures for Robust Adaptive Perception and Action has been devoted to the design and development of intelligent systems with cognition by studying fundamental principles of biological perception and their implementation in algorithms on both classical and neuromorphic real-time hardware. The network brought together scientists from multiple disciplines, who studied these principles through neural modeling and behavioral experiments, theoretical and computational modeling, and implementation in robotics in the domains of navigation, action understanding, and speech/music perception. Over its three-year duration, the project supported several working groups and an annual three-week long summer workshop that engaged the larger research community that has formed and coalesced around the goal of building cognitive neuromorphic systems.</p> <p>A major success of Neuromorphic Cognitive Engineering research has been the development of the Dynamic Vision Sensor (DVS), an imaging device, which inspired by the motion pathway of mammalian vision, records asynchronous temporal scene changes in form of a stream of events. This sensor has recently been adapted, beyond the neuromorphic community, by researchers of Robotics and Computer Vision, which is evidenced by the publication of more than three hundred and fifty papers in major conferences and journals in these fields. New algorithms were developed that exploit the principles of motion-based event coding and take advantage of the accurate time stamps and high temporal resolution of the data. Furthermore, industrial partners have developed neuromorphic chips, which model how the brain?s neurons communicate and learn using spikes and synapses that can be modulated based on the timing of events, most notably Intel?s Loihi and IBM?s True North. By using the events recorded at the dynamic imaging sensors as input to algorithms running on these neuromorphic chips, extremely low-power implementations of computing and learning principles were achieved.</p> <p>Principles of perception for navigation were studied by developing a minimalist framework for flight control based on active perception processes. While the current approach seeks to create a 3-D reconstruction of the scene, which then is used in planning and control &nbsp;to achieve autonomous behavior, in &nbsp;the minimalist framework, individual tasks are solved &nbsp;with only essential information and computations from perception, such as estimation of&nbsp; 3D motion, segmentation, and tracking of attended objects. Tasks included flying through unknown gaps, obstacle avoidance, dodging, and pursuit using only onboard sensing.</p> <p>Principles of perception for action-understanding were demonstrated through the development of a robotic system that interprets human actions. By integrating vision with reasoning and motor control, the group demonstrated a robot that can learn from a purely visual demonstration, rather than explicitly programming the task. This way, the robot learns to execute specific actions by observing the human expert. &nbsp;</p> <p>Finally, principles of auditory perception were studied in tasks involving speech and music understanding through neuroscience experiments, computational modeling, and the development of software for decoding sound-induced signals in the brain (EEG, MEG, and ECoG). Many insights and concrete outcomes have resulted from this work, including for example an EEG software decoding toolbox with classical and neural network-based algorithms that is now widely used around the world for analysis of speech-evoked brain activity. Another outcome is the formulation of a dynamic estimation and inference paradigm for extracting functional neuronal network dynamics.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/28/2019<br>      Modified by: Cornelia&nbsp;M&nbsp;Fermuller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The Science of Learning Collaborative Network (SL-CN) on Cortical Architectures for Robust Adaptive Perception and Action has been devoted to the design and development of intelligent systems with cognition by studying fundamental principles of biological perception and their implementation in algorithms on both classical and neuromorphic real-time hardware. The network brought together scientists from multiple disciplines, who studied these principles through neural modeling and behavioral experiments, theoretical and computational modeling, and implementation in robotics in the domains of navigation, action understanding, and speech/music perception. Over its three-year duration, the project supported several working groups and an annual three-week long summer workshop that engaged the larger research community that has formed and coalesced around the goal of building cognitive neuromorphic systems.  A major success of Neuromorphic Cognitive Engineering research has been the development of the Dynamic Vision Sensor (DVS), an imaging device, which inspired by the motion pathway of mammalian vision, records asynchronous temporal scene changes in form of a stream of events. This sensor has recently been adapted, beyond the neuromorphic community, by researchers of Robotics and Computer Vision, which is evidenced by the publication of more than three hundred and fifty papers in major conferences and journals in these fields. New algorithms were developed that exploit the principles of motion-based event coding and take advantage of the accurate time stamps and high temporal resolution of the data. Furthermore, industrial partners have developed neuromorphic chips, which model how the brain?s neurons communicate and learn using spikes and synapses that can be modulated based on the timing of events, most notably Intel?s Loihi and IBM?s True North. By using the events recorded at the dynamic imaging sensors as input to algorithms running on these neuromorphic chips, extremely low-power implementations of computing and learning principles were achieved.  Principles of perception for navigation were studied by developing a minimalist framework for flight control based on active perception processes. While the current approach seeks to create a 3-D reconstruction of the scene, which then is used in planning and control  to achieve autonomous behavior, in  the minimalist framework, individual tasks are solved  with only essential information and computations from perception, such as estimation of  3D motion, segmentation, and tracking of attended objects. Tasks included flying through unknown gaps, obstacle avoidance, dodging, and pursuit using only onboard sensing.  Principles of perception for action-understanding were demonstrated through the development of a robotic system that interprets human actions. By integrating vision with reasoning and motor control, the group demonstrated a robot that can learn from a purely visual demonstration, rather than explicitly programming the task. This way, the robot learns to execute specific actions by observing the human expert.    Finally, principles of auditory perception were studied in tasks involving speech and music understanding through neuroscience experiments, computational modeling, and the development of software for decoding sound-induced signals in the brain (EEG, MEG, and ECoG). Many insights and concrete outcomes have resulted from this work, including for example an EEG software decoding toolbox with classical and neural network-based algorithms that is now widely used around the world for analysis of speech-evoked brain activity. Another outcome is the formulation of a dynamic estimation and inference paradigm for extracting functional neuronal network dynamics.          Last Modified: 12/28/2019       Submitted by: Cornelia M Fermuller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
