<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: The Confluence of Music, Art and Science at Long Term Ecological Research Sites</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>76780.00</AwardTotalIntnAmount>
<AwardAmount>76780</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08010209</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DEB</Abbreviation>
<LongName>Division Of Environmental Biology</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Colette St. Mary</SignBlockName>
<PO_EMAI>cstmary@nsf.gov</PO_EMAI>
<PO_PHON>7032924332</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Practitioners of the arts, humanities, and sciences all seek solutions to complex problems, suggesting that collaborations across these disciplines could yield new insights into societal challenges and needs. Deep cultural and practical divides limit these collaborations. This project will bring together ecologists, artists, musicians, neuroscientists, computer scientists, educators, and science communicators to design research using new visualization and sonification tools. Project goals are to stimulate creative thinking, to allow for advanced forms of pattern recognition, and to facilitate a diverse and cross-disciplinary approach to environmental research needs, questions, and results. The project has the potential to expand significantly the participation of diverse cultural, ethnic, and economic groups in scientific research by allowing these groups to co-develop research questions at the outset. Inclusion of educators and science communicators will provide opportunities for students and the public to interact with high frequency environmental data in novel ways, allowing them new ways to comprehend complex data and processes. These new ways of experiencing complex natural phenomena may be particularly beneficial for individuals who have special learning needs, who learn better visually or acoustically, or who are disaffected by traditional numerical presentations of data and results.  The project is risky, but promises very high rewards.&lt;br/&gt; &lt;br/&gt;The major goal of this project is to encode high-volume and high-frequency ecological data in new ways in order to discover underlying patterns and processes. Online digital visualization and sonification tools will be developed to display multi-dimensional real-time ecological data generated from environmental sensor arrays at two Long Term Ecological Research sites. A novel partnership with neuroscientists will explore how stimulation of different neural circuitry in the human brain allows large datasets to be understood, perhaps in new ways. A current visualization tool, Waterviz, will be re-designed in collaboration with artists, neuroscientists, and computer scientists. Hydrologic data captured with sensors will drive a computer model that calculates all components of a water cycle in real time. These data in turn will drive artistic and musical simulations of the water cycle. The models will be used to test hypotheses that multi-sensory experiences simultaneously engage reasoning, visual, and acoustical brain centers such that large-scale patterns and processes are easier to apprehend; that neurological tools can provide a mechanistic understanding of improved comprehension; and that the engagement of artists directly in the research will stimulate new ideas and insights into complex problems. External evaluation of the project will determine whether artists and scientists are equitably engaged, whether new relationships result, and whether this process stimulates new ideas and insights.</AbstractNarration>
<MinAmdLetterDate>08/03/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/03/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1548177</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Casey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Casey</PI_FULL_NAME>
<EmailAddress>Michael.A.Casey@dartmouth.edu</EmailAddress>
<PI_PHON>6036463007</PI_PHON>
<NSF_ID>000694891</NSF_ID>
<StartDate>08/03/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Dartmouth College</Name>
<CityName>HANOVER</CityName>
<ZipCode>037551421</ZipCode>
<PhoneNumber>6036463007</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROJECTS</StreetAddress>
<StreetAddress2><![CDATA[11 ROPE FERRY RD #6210]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<StateCode>NH</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NH02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041027822</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF DARTMOUTH COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041027822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Dartmouth College]]></Name>
<CityName/>
<StateCode>NH</StateCode>
<ZipCode>037553599</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Hampshire</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NH02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1195</Code>
<Text>LONG TERM ECOLOGICAL RESEARCH</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9169</Code>
<Text>BIODIVERSITY AND ECOSYSTEM DYNAMICS</Text>
</ProgramReference>
<ProgramReference>
<Code>EGCH</Code>
<Text>ENVIRONMENT AND GLOBAL CHANGE</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~76780</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!--   @page { margin: 0.79in }   p { margin-bottom: 0.1in; direction: ltr; line-height: 120%; text-align: left; orphans: 0; widows: 0 }   p.western { font-family: "Times New Roman", serif; font-size: 10pt }   p.cjk { font-family: "Times New Roman"; font-size: 10pt }   p.ctl { font-family: "Times New Roman"; font-size: 10pt }   a:link { color: #0563c1 }   --> <p><span id="docs-internal-guid-78518f49-7fff-8cd6-716a-44314d30f9bc"> </span></p> <p dir="ltr"><span>This collaborative research project, funded by NSF's Early-Concept Grants for Exploratory Research (EAGER) program, investigated exploratory approaches for understanding high volume and frequency ecological data, using insights from multiple disciplines, including ecosystem science, music, art, and neuroscience. The project was framed by two main goals: (1) to develop digital visualization and sonification tools to better discover underlying pattern and process in ecological datasets; (2) and to use neurobiological research to explore how data visualizations and sonifications work in the brain.</span></p> <p>To address the first goal, a team of ecologists, computer scientists, data scientists, technicians, artists, and science educators worked to build new online digital visualization and sonification tools to display multi-dimensional real-time ecological data generated from environmental sensor arrays deployed at two Long Term Ecological Research sites: the Hubbard Brook Experimental Forest in New Hampshire and the H.J. Andrews Experimental Forest in Oregon. The final products can be viewed online at<a href="http://www.waterviz.org/"> www.waterviz.org</a>. The new data visualization and sonification products have been featured in several art gallery shows around the country, bringing awareness of long term ecological research, ecological processes, and ecological "big data" to new public audiences. The new data visualization and sonification products have also been shared with K-12 teachers and used in middle and high school classrooms to support STEM learning. A set of lesson plans and classroom-support materials is available to facilitate the use of these tools and associated long-term ecological datasets in formal education.</p> <p>A project evaluation focused on assessing the extent and outcomes of the project's exploratory, collaborative process to engage artists and scientists in a mutual endeavor. The evaluation found evidence for the establishment of new connections and relationships among participants from different disciplines, particularly among ecosystem scientists and artists, among ecosystem scientists and educators, and among ecosystem scientists and neuroscientists. One idea behind this project was that new connections across disciplines, including both the arts and sciences, might produce new ways of thinking and insights about ecological systems and emerging "big data" in ecology. The evaluation found evidence for early new discoveries in ecological datasets as a result of these cross-discipline relationships and interactions, and the potential for new discoveries both in ecological and neurobiological research.</p> <p><span>To address the second goal, a team of neuroscientists, computer scientists, and engineers worked to develop new ways to evaluate what happens in the brain when humans view and interact with data visualizations. The team analyzed the long term ecological data powering the visualizations and sonifications described above and created a neurobiological experimental design based on the complexity of those data. This work involved the development and engineering of a low-cost electroencephalography (EEG) platform with custom firmware, hardware, and software. Experiments using the new platform and experimental design resulted in a neurobiological </span><span>learning-state estimator</span><span>, which measures via EEG a user's degree of understanding of a task requiring visual data interaction. The learning-state estimation system is being used to adapt visualizations and sonifications, based on a user's personal rate and style of learning, for greater engagement with, and understanding of scientific data.</span></p><br> <p>            Last Modified: 11/06/2018<br>      Modified by: Michael&nbsp;Casey</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1548177/1548177_10383011_1541515906288_6-ExperimentwithUser--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1548177/1548177_10383011_1541515906288_6-ExperimentwithUser--rgov-800width.jpg" title="Data Visualization EEG Experiment"><img src="/por/images/Reports/POR/2018/1548177/1548177_10383011_1541515906288_6-ExperimentwithUser--rgov-66x44.jpg" alt="Data Visualization EEG Experiment"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Experiment setup featuring the new EEG platform and experimental design. This system was used to develop a neurobiological learning-state estimator, which measures via EEG a user?s degree of understanding of a task requiring visual data interaction.</div> <div class="imageCredit">Sol Diamond, Dartmouth College</div> <div class="imageSubmitted">Michael&nbsp;Casey</div> <div class="imageTitle">Data Visualization EEG Experiment</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1548177/1548177_10383011_1541516399975_4-ExperimentSetup--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1548177/1548177_10383011_1541516399975_4-ExperimentSetup--rgov-800width.jpg" title="EEG and User-Interaction Hardware"><img src="/por/images/Reports/POR/2018/1548177/1548177_10383011_1541516399975_4-ExperimentSetup--rgov-66x44.jpg" alt="EEG and User-Interaction Hardware"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Development and engineering of a low-cost electroencephalography (EEG) platform with custom firmware, hardware, and software to measure user engagement and learning with long-term ecological data visualizations.</div> <div class="imageCredit">Sol Diamond, Dartmouth College</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Michael&nbsp;Casey</div> <div class="imageTitle">EEG and User-Interaction Hardware</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    This collaborative research project, funded by NSF's Early-Concept Grants for Exploratory Research (EAGER) program, investigated exploratory approaches for understanding high volume and frequency ecological data, using insights from multiple disciplines, including ecosystem science, music, art, and neuroscience. The project was framed by two main goals: (1) to develop digital visualization and sonification tools to better discover underlying pattern and process in ecological datasets; (2) and to use neurobiological research to explore how data visualizations and sonifications work in the brain.  To address the first goal, a team of ecologists, computer scientists, data scientists, technicians, artists, and science educators worked to build new online digital visualization and sonification tools to display multi-dimensional real-time ecological data generated from environmental sensor arrays deployed at two Long Term Ecological Research sites: the Hubbard Brook Experimental Forest in New Hampshire and the H.J. Andrews Experimental Forest in Oregon. The final products can be viewed online at www.waterviz.org. The new data visualization and sonification products have been featured in several art gallery shows around the country, bringing awareness of long term ecological research, ecological processes, and ecological "big data" to new public audiences. The new data visualization and sonification products have also been shared with K-12 teachers and used in middle and high school classrooms to support STEM learning. A set of lesson plans and classroom-support materials is available to facilitate the use of these tools and associated long-term ecological datasets in formal education.  A project evaluation focused on assessing the extent and outcomes of the project's exploratory, collaborative process to engage artists and scientists in a mutual endeavor. The evaluation found evidence for the establishment of new connections and relationships among participants from different disciplines, particularly among ecosystem scientists and artists, among ecosystem scientists and educators, and among ecosystem scientists and neuroscientists. One idea behind this project was that new connections across disciplines, including both the arts and sciences, might produce new ways of thinking and insights about ecological systems and emerging "big data" in ecology. The evaluation found evidence for early new discoveries in ecological datasets as a result of these cross-discipline relationships and interactions, and the potential for new discoveries both in ecological and neurobiological research.  To address the second goal, a team of neuroscientists, computer scientists, and engineers worked to develop new ways to evaluate what happens in the brain when humans view and interact with data visualizations. The team analyzed the long term ecological data powering the visualizations and sonifications described above and created a neurobiological experimental design based on the complexity of those data. This work involved the development and engineering of a low-cost electroencephalography (EEG) platform with custom firmware, hardware, and software. Experiments using the new platform and experimental design resulted in a neurobiological learning-state estimator, which measures via EEG a user's degree of understanding of a task requiring visual data interaction. The learning-state estimation system is being used to adapt visualizations and sonifications, based on a user's personal rate and style of learning, for greater engagement with, and understanding of scientific data.       Last Modified: 11/06/2018       Submitted by: Michael Casey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
