<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SCH: INT: Collaborative Research: Replicating Clinic Physical Therapy at Home: Touch, Depth, and Epidermal Electronics in an Interactive Avatar System</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>1775020.00</AwardTotalIntnAmount>
<AwardAmount>1775020</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Physical therapy is often hampered by lack of access to therapists, and lack of adherence to home therapy regimens.  This research develops a physical therapy assistance system for home use, with emphasis on stroke rehabilitation.  As a person exercises, inexpensive cameras observe color and depth, and unobtrusive tattoo sensors monitor detailed muscle activity.  The 3D movement trajectory is derived and compared against the exercise done with an expert therapist.  The patient watches a screen avatar where arrows and color coding guide the patient to move correctly.  In addition to advancing fields such as movement tracking, skin sensors, and assistive systems, the project has the potential for broad impact by attracting women and under-represented minorities to engineering through health-related engineering coursework and projects, and because home physical therapy assistance can especially help rural and under-served populations. &lt;br/&gt;&lt;br/&gt;This project uses bio-electronics, computer vision, computer gaming, high-dimensional machine learning, and human factors to develop a home physical therapy assistance system.  During home exercises, patient kinematics and physiology are monitored with a Kinect color/depth camera and wireless epidermal electronics transferable to the skin with a temporary tattoo. The project involves optimization of electrode design and wireless signaling for epidermal electronics to monitor spatiotemporal aspects of muscle recruitment, hand and body pose estimation and tracking algorithms that are robust to rapid motion and occlusions, and development of machine learning and avatar rendering algorithms for multi-modal sensor fusion and expert-trained optimal control guidance logic, for both cloud and local usage.  The system aims to provide real-time feedback to make home sessions as effective as office visits with an expert therapist, reducing the time and money required for full recovery.</AbstractNarration>
<MinAmdLetterDate>08/19/2015</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1522125</AwardID>
<Investigator>
<FirstName>Truong</FirstName>
<LastName>Nguyen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Truong Nguyen</PI_FULL_NAME>
<EmailAddress>nguyent@ece.ucsd.edu</EmailAddress>
<PI_PHON>8588225554</PI_PHON>
<NSF_ID>000481463</NSF_ID>
<StartDate>08/19/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Pamela</FirstName>
<LastName>Cosman</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pamela C Cosman</PI_FULL_NAME>
<EmailAddress>pcosman@ucsd.edu</EmailAddress>
<PI_PHON>8588220157</PI_PHON>
<NSF_ID>000456426</NSF_ID>
<StartDate>08/19/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sujit</FirstName>
<LastName>Dey</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sujit Dey</PI_FULL_NAME>
<EmailAddress>dey@ece.ucsd.edu</EmailAddress>
<PI_PHON>8585340750</PI_PHON>
<NSF_ID>000295328</NSF_ID>
<StartDate>08/19/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Todd</FirstName>
<LastName>Coleman</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Todd P Coleman</PI_FULL_NAME>
<EmailAddress>tpcoleman@ucsd.edu</EmailAddress>
<PI_PHON>8585348207</PI_PHON>
<NSF_ID>000334763</NSF_ID>
<StartDate>08/19/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8062</Code>
<Text>SCH Type II: INT</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~1775020</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we developed a physical therapy monitoring and guidance system. To use the system, one first records the movement of a physical therapist who demonstrates a motion.&nbsp; The physical therapist can then be shown as an avatar or model on a screen, performing the exercise.&nbsp; At home, a patient can be trained or guided by this motion model using a tablet or laptop through a wireless network.&nbsp; A camera watches the patient&rsquo;s motion at home and compares it against the motion model.</p> <p>The motion sequences of the physical therapist avatar and the patient might be misaligned due to human reaction delay or network delays, so we applied a Dynamic Time Warping (DTW) algorithm on the sequences to find their optimal alignment. To enable real-time evaluation and guidance, we developed a gesture-based DTW algorithm that separates out different gestures in the user&rsquo;s motion in real time. &nbsp;Experimental results show that the algorithm outperforms other alignment methods and enables real-time evaluation with low computational complexity.</p> <p>After consultations with physical therapist colleagues, we developed a system that provides guidance after each gesture depending on the user performance. We found that combined visual and text guidance is the most effective to help the user improve performance accuracy.</p> <p>Real-time tracking of hand articulations is important for accurate recording and guidance of physical therapy in real-time. We proposed an efficient hand tracking system which uses an adaptive hand model and depth maps. In our system, we track hand articulations by minimizing the discrepancy between the depth map from a sensor and a computer-generated hand model. We also re-initialize the hand pose at each frame using finger detection and classification. &nbsp;Our system achieves both automatic hand model adjustment and real-time tracking with low complexity.&nbsp;</p> <p>&nbsp;In a related problem, we considered sign language recognition.&nbsp; We trained a convolutional neural network from depth maps for the classification of 31 alphabet letters and numbers using a subset of collected depth data from multiple subjects. We achieved 99.99% accuracy for signers who were in our set to be observed, and 84% accuracy for new signers. Accuracy improves as we include more data from different subjects during training. &nbsp;With a processing time of 3 ms for the prediction of a single image, the proposed system achieves high accuracy and speed.&nbsp;&nbsp;</p> <p>We also proposed an automated system for balance evaluation using multiple sensors to enable on-demand balance evaluation at home. The system provides a quantified balance level consistent with a physical therapist&rsquo;s assessments in traditional balance evaluation tests. We collected real patient clinic data to train our model. Experimental results show the high accuracy of the proposed systems. By using inexpensive sensors and artificial intelligence, the proposed virtual physical therapist and balance evaluation system has the potential of enabling on-demand virtual care and significantly reducing cost for both patients and care providers.</p> <p>In addition to successfully developing the core physical therapy system and algorithms of this project, the project also made a number of fundamental advances in video processing and electronics.&nbsp; To improve the accuracy of image pixel classification by utilizing depth information, we developed a depth-adaptive deep neural network which is able to adapt the receptive field not only for each layer but also for each neuron at the spatial location. To adjust the receptive field, we proposed the depth-adaptive multiscale convolution layer.&nbsp; On a publicly available RGB-D dataset for multi-class per-pixel classification and a novel hand segmentation dataset for hand-object interaction, the proposed method outperformed state-of-the-art methods.</p> <p>In terms of electronics for health monitoring, we developed fully functional systems containing sensors and integrated circuits for monitoring strain, fabricated on a flexible substrate embedded in an adhesive.&nbsp; We also fabricated a flexible antenna, embedded within 3M Tegaderm adhesive. Methods for microfabrication of solderable and stretchable sensing systems (S4s) were demonstrated.&nbsp; S4s are versatile and modular, and can be produced with an integrated adhesive, allowing them to be attached to the skin like a temporary tattoo.&nbsp; S4s&rsquo; excellent solderability is achieved by the sputter-deposited nickel-vanadium and gold pad metal layers and copper interconnection. The feasibility for S4-based health monitoring was demonstrated by developing an S4 integrated with a strain gauge and an onboard optical indication circuit. S4 respiration sensors were tested for robustness for cyclic deformation, maximum stretchability, durability, and biocompatibility for multiday wear time. The test results and demonstration of the respiration sensing indicate that the adhesive-integrated S4s can provide users a way to unobtrusively monitor health.&nbsp;</p> <p>Beyond the many healthcare applications, the broader impact of this work includes the development of several public databases, and the investigators on this project have been active in K-12 outreach to stimulate interest in engineering, including the Splash high school program, campus lab tours, Girl Scout events, school science nights, summer camps, and a book on gender in STEM for high school girls.&nbsp;</p><br> <p>            Last Modified: 11/09/2020<br>      Modified by: Pamela&nbsp;C&nbsp;Cosman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we developed a physical therapy monitoring and guidance system. To use the system, one first records the movement of a physical therapist who demonstrates a motion.  The physical therapist can then be shown as an avatar or model on a screen, performing the exercise.  At home, a patient can be trained or guided by this motion model using a tablet or laptop through a wireless network.  A camera watches the patient’s motion at home and compares it against the motion model.  The motion sequences of the physical therapist avatar and the patient might be misaligned due to human reaction delay or network delays, so we applied a Dynamic Time Warping (DTW) algorithm on the sequences to find their optimal alignment. To enable real-time evaluation and guidance, we developed a gesture-based DTW algorithm that separates out different gestures in the user’s motion in real time.  Experimental results show that the algorithm outperforms other alignment methods and enables real-time evaluation with low computational complexity.  After consultations with physical therapist colleagues, we developed a system that provides guidance after each gesture depending on the user performance. We found that combined visual and text guidance is the most effective to help the user improve performance accuracy.  Real-time tracking of hand articulations is important for accurate recording and guidance of physical therapy in real-time. We proposed an efficient hand tracking system which uses an adaptive hand model and depth maps. In our system, we track hand articulations by minimizing the discrepancy between the depth map from a sensor and a computer-generated hand model. We also re-initialize the hand pose at each frame using finger detection and classification.  Our system achieves both automatic hand model adjustment and real-time tracking with low complexity.    In a related problem, we considered sign language recognition.  We trained a convolutional neural network from depth maps for the classification of 31 alphabet letters and numbers using a subset of collected depth data from multiple subjects. We achieved 99.99% accuracy for signers who were in our set to be observed, and 84% accuracy for new signers. Accuracy improves as we include more data from different subjects during training.  With a processing time of 3 ms for the prediction of a single image, the proposed system achieves high accuracy and speed.    We also proposed an automated system for balance evaluation using multiple sensors to enable on-demand balance evaluation at home. The system provides a quantified balance level consistent with a physical therapist’s assessments in traditional balance evaluation tests. We collected real patient clinic data to train our model. Experimental results show the high accuracy of the proposed systems. By using inexpensive sensors and artificial intelligence, the proposed virtual physical therapist and balance evaluation system has the potential of enabling on-demand virtual care and significantly reducing cost for both patients and care providers.  In addition to successfully developing the core physical therapy system and algorithms of this project, the project also made a number of fundamental advances in video processing and electronics.  To improve the accuracy of image pixel classification by utilizing depth information, we developed a depth-adaptive deep neural network which is able to adapt the receptive field not only for each layer but also for each neuron at the spatial location. To adjust the receptive field, we proposed the depth-adaptive multiscale convolution layer.  On a publicly available RGB-D dataset for multi-class per-pixel classification and a novel hand segmentation dataset for hand-object interaction, the proposed method outperformed state-of-the-art methods.  In terms of electronics for health monitoring, we developed fully functional systems containing sensors and integrated circuits for monitoring strain, fabricated on a flexible substrate embedded in an adhesive.  We also fabricated a flexible antenna, embedded within 3M Tegaderm adhesive. Methods for microfabrication of solderable and stretchable sensing systems (S4s) were demonstrated.  S4s are versatile and modular, and can be produced with an integrated adhesive, allowing them to be attached to the skin like a temporary tattoo.  S4s’ excellent solderability is achieved by the sputter-deposited nickel-vanadium and gold pad metal layers and copper interconnection. The feasibility for S4-based health monitoring was demonstrated by developing an S4 integrated with a strain gauge and an onboard optical indication circuit. S4 respiration sensors were tested for robustness for cyclic deformation, maximum stretchability, durability, and biocompatibility for multiday wear time. The test results and demonstration of the respiration sensing indicate that the adhesive-integrated S4s can provide users a way to unobtrusively monitor health.   Beyond the many healthcare applications, the broader impact of this work includes the development of several public databases, and the investigators on this project have been active in K-12 outreach to stimulate interest in engineering, including the Splash high school program, campus lab tours, Girl Scout events, school science nights, summer camps, and a book on gender in STEM for high school girls.        Last Modified: 11/09/2020       Submitted by: Pamela C Cosman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
