<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SaTC-EDU: EAGER: Enhancing Cybersecurity Education through Peer Review</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>229280.00</AwardTotalIntnAmount>
<AwardAmount>229280</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11010001</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DGE</Abbreviation>
<LongName>Division Of Graduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Victor Piotrowski</SignBlockName>
<PO_EMAI>vpiotrow@nsf.gov</PO_EMAI>
<PO_PHON>7032925141</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Peer-review is a well-known process by which peers evaluate one another's work.  In educational settings, peer review involves students evaluating the work of classmates.  Peer evaluations can serve many educational purposes: they foster comprehension skills (as students read the work of others), encourage self-assessment and meta-reflection (as students contrast their solutions to others'), demand synthesis of comments from multiple perspectives (as students combine feedback from multiple reviews), and develop professional skills around giving and receiving critique from colleagues.&lt;br/&gt;&lt;br/&gt;The skills that educational peer review attempts to foster are critical in cybersecurity: code review is part of modern industrial software practice (and has identified high-profile security bugs), security problems are multi-faceted and require developers who can synthesize needs of many stakeholders, and developers must prioritize among vulnerabilities identified through different sources and processes.  Peer review, with its emphasis on developing students' reflective skills, thus promises to be a valuable mechanism in training security professionals.   There are, however, many configurations of peer review, each of which could engage students in different ways.  Educational research focused on linking peer review configurations to learning outcomes in cybersecurity is thus critical to using this mechanism effectively.&lt;br/&gt;&lt;br/&gt;This project will experiment with peer-review configurations in a variety of cybersecurity courses.  The courses span several areas of cybersecurity (software, system, and policy), as well as both undergraduate and graduate students.  The project will explore how various cybersecurity-specific learning objectives manifest through peer review. It will also yield software infrastructure for using and assessing peer review across a variety of courses and configurations.  Expected deliverables from the project include observations about students' reviewing practices, refined research questions about how to use peer-review successfully in security education, and software tools that others can use for similar projects (which will be made publicly available).</AbstractNarration>
<MinAmdLetterDate>07/15/2015</MinAmdLetterDate>
<MaxAmdLetterDate>07/15/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1500039</AwardID>
<Investigator>
<FirstName>Kathryn</FirstName>
<LastName>Fisler</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kathryn Fisler</PI_FULL_NAME>
<EmailAddress>kathryn_fisler@brown.edu</EmailAddress>
<PI_PHON>4018637600</PI_PHON>
<NSF_ID>000131380</NSF_ID>
<StartDate>07/15/2015</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Joshua</FirstName>
<LastName>Guttman</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joshua D Guttman</PI_FULL_NAME>
<EmailAddress>guttman@wpi.edu</EmailAddress>
<PI_PHON>5088315000</PI_PHON>
<NSF_ID>000537868</NSF_ID>
<StartDate>07/15/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Craig</FirstName>
<LastName>Shue</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Craig Shue</PI_FULL_NAME>
<EmailAddress>cshue@wpi.edu</EmailAddress>
<PI_PHON>5088314933</PI_PHON>
<NSF_ID>000603400</NSF_ID>
<StartDate>07/15/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Krishna Kumar</FirstName>
<LastName>Venkatasubramanian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Krishna Kumar Venkatasubramanian</PI_FULL_NAME>
<EmailAddress>krish@uri.edu</EmailAddress>
<PI_PHON>4018742701</PI_PHON>
<NSF_ID>000630856</NSF_ID>
<StartDate>07/15/2015</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Worcester Polytechnic Institute</Name>
<CityName>WORCESTER</CityName>
<ZipCode>016092247</ZipCode>
<PhoneNumber>5088315000</PhoneNumber>
<StreetAddress>100 INSTITUTE RD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041508581</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WORCESTER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041508581</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Worcester Polytechnic Institute]]></Name>
<CityName>Worcester</CityName>
<StateCode>MA</StateCode>
<ZipCode>016092247</ZipCode>
<StreetAddress><![CDATA[100 Institute Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0415</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~229280</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Menlo; background-color: #fffef9} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Menlo; background-color: #fffef9; min-height: 16.0px} span.s1 {font-variant-ligatures: no-common-ligatures} --> <p class="p1"><span class="s1">Peer-review is a well-known process by which peers evaluate one&nbsp;</span>another's work.&nbsp; In educational settings, peer review involves&nbsp;<span class="s1">students evaluating the work of classmates.</span><span class="s1">&nbsp; Peer&nbsp;</span><span class="s1">evaluations can serve many educational purposes: they foster&nbsp;</span><span class="s1">comprehension skills (as students read the work of others), encourage&nbsp;</span><span class="s1">self-assessment and meta-reflection (as students contrast their&nbsp;</span><span class="s1">solutions to others'), demand synthesis of comments from multiple&nbsp;</span><span class="s1">perspectives (as students combine feedback from multiple reviews), and&nbsp;</span><span class="s1">develop professional skills around giving and receiving critique from&nbsp;</span>colleagues. &nbsp;</p> <p class="p1"><span class="s1">The skills that educational peer review attempts to foster are&nbsp;</span>critical in cybersecurity: code review is part of modern industrial software practice (and has identified high-profile security bugs), security problems are multi-faceted and require developers who can synthesize needs of many stakeholders, and developers must prioritize among vulnerabilities identified through different sources and processes.&nbsp; Peer review, with its emphasis on developing students' reflective skills, thus promises to be a valuable mechanism in training security professionals. &nbsp;There are, however, many configurations of peer review, each of which could engage students in different ways.&nbsp; Educational research focused on linking peer review configurations to learning outcomes in cybersecurity is thus critical to using this mechanism effectively.</p> <p class="p2">This project set out to explore various peer-review configurations across multiple cybersecurity courses at WPI. &nbsp;During the funding period, we gathered data from two undergraduate courses (one focused on software security and one on system and network security). &nbsp;</p> <p class="p2">The network security course asked students to write and review documents describing two designs of a particular network-related security technology. &nbsp;Reviews were conducted after the final reports were submitted; students could not revise their work based on the reviews. &nbsp;The review questions were open-ended, asking about strengths, weaknesses, and areas of improvement for each document.</p> <p class="p2">The software security course asked students to write and review documents describing vulnerabilities and ways to exploit them in two versions of a software system. &nbsp;The reviews were conducted before the final due date; students could revise their work based on what they learned from reviewing (termed "in-flow" peer review). &nbsp;The review form asked whether the exploits were accurate for each vulnerability, whether different exploits had been identified, and whether the approach to finding exploits had been systematic.</p> <p class="p2">The research team gathered the submitted work, peer-reviews, and instructor feedback from each course. &nbsp;We analyzed the reviews to assess the nature of their content and whether reviewers provided vague or concrete suggestions. &nbsp;In the network security course, we also conducted a survey about students' experiences with peer review.</p> <p class="p2">Most comments in the software security reviews focused on security-related issues, whereas a majority of comments in the network security course focused on structural comments (about the documents) or technical issues that weren't security related. &nbsp;The questions in the review forms likely influenced these results: the network security questions were open-ended by design. Yet we were still surprised that students in a security course wouldn't have commented more on security-related details.</p> <p class="p2">Survey responses from the network security course suggested that students felt that the review process improved over time: students reported feeling better able to write good reviews and finding the reviews they received were more useful. &nbsp;</p> <p class="p2">In both courses, review comments were fairly evenly split between being concrete (about specific problems in the artifact being reviewed) or being abstract (a general comment without being specifically tied to the artifact). &nbsp;Both of these confirm findings from others' peer-review studies about the need to explicitly train students in effective engagement in peer review.</p> <p class="p2">Unexpected staffing and course-scheduling changes meant we did not have a chance to revise the peer-review procedures for either course and gather data about the impacts. &nbsp;We would have liked to add more security-specific prompts to the network security form, and to gather data from students in both courses as to which information they would choose to act on from each review. Our goal would have been to assess the impact of review timing (relative to due dates) on how seriously students took reviewing, while also determining whether this was a factor in how much time students spent digging into the security concerns with the work they were reviewing.</p> <p class="p2">The project also resulted in significant improvements to an online peer-review software system called CaptainTeach. &nbsp;While a prototype of CaptainTeach existed prior to this project, the system had several security weaknesses and user-facing limitations. &nbsp;The prototype had provided flexibility in configuring peer review (to occur within or after assignments were due, with different options for assigning reviewers to each others' work). &nbsp;Project funds improved the security and robustness of CaptainTeach. &nbsp;A high school teacher in NYC subsequently used CaptainTeach to integrate peer review in his AP Computer Science course. &nbsp;The teacher reported a positive experience with getting his students to engage with peer review. &nbsp;The tool thus is having impact beyond the security-related focus of the overall grant.</p><br> <p>            Last Modified: 08/06/2017<br>      Modified by: Kathryn&nbsp;Fisler</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Peer-review is a well-known process by which peers evaluate one another's work.  In educational settings, peer review involves students evaluating the work of classmates.  Peer evaluations can serve many educational purposes: they foster comprehension skills (as students read the work of others), encourage self-assessment and meta-reflection (as students contrast their solutions to others'), demand synthesis of comments from multiple perspectives (as students combine feedback from multiple reviews), and develop professional skills around giving and receiving critique from colleagues.   The skills that educational peer review attempts to foster are critical in cybersecurity: code review is part of modern industrial software practice (and has identified high-profile security bugs), security problems are multi-faceted and require developers who can synthesize needs of many stakeholders, and developers must prioritize among vulnerabilities identified through different sources and processes.  Peer review, with its emphasis on developing students' reflective skills, thus promises to be a valuable mechanism in training security professionals.  There are, however, many configurations of peer review, each of which could engage students in different ways.  Educational research focused on linking peer review configurations to learning outcomes in cybersecurity is thus critical to using this mechanism effectively. This project set out to explore various peer-review configurations across multiple cybersecurity courses at WPI.  During the funding period, we gathered data from two undergraduate courses (one focused on software security and one on system and network security).   The network security course asked students to write and review documents describing two designs of a particular network-related security technology.  Reviews were conducted after the final reports were submitted; students could not revise their work based on the reviews.  The review questions were open-ended, asking about strengths, weaknesses, and areas of improvement for each document. The software security course asked students to write and review documents describing vulnerabilities and ways to exploit them in two versions of a software system.  The reviews were conducted before the final due date; students could revise their work based on what they learned from reviewing (termed "in-flow" peer review).  The review form asked whether the exploits were accurate for each vulnerability, whether different exploits had been identified, and whether the approach to finding exploits had been systematic. The research team gathered the submitted work, peer-reviews, and instructor feedback from each course.  We analyzed the reviews to assess the nature of their content and whether reviewers provided vague or concrete suggestions.  In the network security course, we also conducted a survey about students' experiences with peer review. Most comments in the software security reviews focused on security-related issues, whereas a majority of comments in the network security course focused on structural comments (about the documents) or technical issues that weren't security related.  The questions in the review forms likely influenced these results: the network security questions were open-ended by design. Yet we were still surprised that students in a security course wouldn't have commented more on security-related details. Survey responses from the network security course suggested that students felt that the review process improved over time: students reported feeling better able to write good reviews and finding the reviews they received were more useful.   In both courses, review comments were fairly evenly split between being concrete (about specific problems in the artifact being reviewed) or being abstract (a general comment without being specifically tied to the artifact).  Both of these confirm findings from others' peer-review studies about the need to explicitly train students in effective engagement in peer review. Unexpected staffing and course-scheduling changes meant we did not have a chance to revise the peer-review procedures for either course and gather data about the impacts.  We would have liked to add more security-specific prompts to the network security form, and to gather data from students in both courses as to which information they would choose to act on from each review. Our goal would have been to assess the impact of review timing (relative to due dates) on how seriously students took reviewing, while also determining whether this was a factor in how much time students spent digging into the security concerns with the work they were reviewing. The project also resulted in significant improvements to an online peer-review software system called CaptainTeach.  While a prototype of CaptainTeach existed prior to this project, the system had several security weaknesses and user-facing limitations.  The prototype had provided flexibility in configuring peer review (to occur within or after assignments were due, with different options for assigning reviewers to each others' work).  Project funds improved the security and robustness of CaptainTeach.  A high school teacher in NYC subsequently used CaptainTeach to integrate peer review in his AP Computer Science course.  The teacher reported a positive experience with getting his students to engage with peer review.  The tool thus is having impact beyond the security-related focus of the overall grant.       Last Modified: 08/06/2017       Submitted by: Kathryn Fisler]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
