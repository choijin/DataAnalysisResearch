<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Cooperative Coevolution of Neural Networks in Sequential Decision Tasks</AwardTitle>
<AwardEffectiveDate>09/15/2000</AwardEffectiveDate>
<AwardExpirationDate>08/31/2004</AwardExpirationDate>
<AwardTotalIntnAmount>419113.00</AwardTotalIntnAmount>
<AwardAmount>419113</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Edwina L. Rissland</SignBlockName>
</ProgramOfficer>
<AbstractNarration>In sequential decision tasks such as resource optimization, robot control, and game playing, several decisions must be made before the outcome can be evaluated. Such reinforcement feedback depends on the entire sequence of decisions, and it is difficult to determine which of the decisions were responsible for the outcome.  This project aims at developing better techniques for learning in domains with such sparse feedback, based on evolving neural networks with genetic algorithms. The goal is both to be able to solve existing problems faster, and to be able to solve problems that have not been feasible as sequential decision tasks before.   Our previous work showed that neuroevolution is most powerful when individual neurons are evolved to cooperate and form good networks.  In this project, such cooperative coevolution methods are studied in depth. The research aims at answering three main questions:   Where does the power of cooperative coevolution come from and what are the best ways of making use of it?    How do the evolutionary reinforcement learning methods differ from the traditional value function methods in learning sequential decision tasks?    Does evolutionary reinforcement learning have the accuracy and flexibility required in real-world applications?    If successful, the project will result in cooperative coevolution algorithms that will solve existing sequential decision tasks faster, and will allow solving more difficult tasks than before.   We will know how to decide between evolutionary and value function methods for a given reinforcement learning task, and also how to use each method most effectively.    Finally, the project will demonstrate how learning in general, and cooperative coevolution of neural networks in particular, can be used to save resources and achieve complex behavior in challenging real-world tasks.</AbstractNarration>
<MinAmdLetterDate>09/11/2000</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2002</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0083776</AwardID>
<Investigator>
<FirstName>Risto</FirstName>
<LastName>Miikkulainen</LastName>
<EmailAddress>risto@cs.utexas.edu</EmailAddress>
<StartDate>09/11/2000</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramElement>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
