<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Empirical Investigations of Large-Scale Regression Testing</AwardTitle>
<AwardEffectiveDate>09/01/2001</AwardEffectiveDate>
<AwardExpirationDate>08/31/2005</AwardExpirationDate>
<AwardTotalIntnAmount>274991.00</AwardTotalIntnAmount>
<AwardAmount>274991</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010500</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Regression testing is an important, but expensive part of modern&lt;br/&gt;software development practices. Central hypotheses of the project are that several key issues have not been adequately considered in current research and that these issues can be exploited, singly and in&lt;br/&gt;combination, to control the regression testing process. If true, then&lt;br/&gt;successful research will lead to cheaper, faster, more predictable and&lt;br/&gt;more effective regression testing processes, thereby saving a great&lt;br/&gt;deal of time and money throughout the industry.  Consequently, the project conducts the following experiments:&lt;br/&gt;   1. Compare different RTS techniques and to explain how features of their inputs affect their performance.&lt;br/&gt;   2. Measure how different application policies (rules that trigger regression testing) affect RTS performance.&lt;br/&gt;   3. Develop and evaluate, using the information from experiments 1 and 2, data-driven (based on each test case's prior performance)&lt;br/&gt;techniques for prioritizing test case execution, for determining the&lt;br/&gt;order in which changes are integrated, and for pruning and optimizing&lt;br/&gt;the original test suites.&lt;br/&gt;   4. Explore whether and how these techniques can be combined and what effect that has, and&lt;br/&gt;   5. Validate these models, techniques, and heuristics in an on-line, long-term study of a large software system.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>05/14/2001</MinAmdLetterDate>
<MaxAmdLetterDate>06/16/2003</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0098158</AwardID>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Porter</LastName>
<EmailAddress>aporter@cs.umd.edu</EmailAddress>
<StartDate>05/14/2001</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
</Institution>
<ProgramElement>
<Code>2880</Code>
<Text>SOFTWARE ENGINEERING AND LANGU</Text>
</ProgramElement>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0101</Code>
</Appropriation>
<Appropriation>
<Code>0102</Code>
</Appropriation>
<Appropriation>
<Code>0103</Code>
</Appropriation>
</Award>
</rootTag>
