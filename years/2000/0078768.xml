<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Learning Complex Auditory Categories</AwardTitle>
<AwardEffectiveDate>09/01/2000</AwardEffectiveDate>
<AwardExpirationDate>09/30/2003</AwardExpirationDate>
<AwardTotalIntnAmount>295655.00</AwardTotalIntnAmount>
<AwardAmount>295655</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Guy Van Orden</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Categorization is a fundamental characteristic of human cognition. Recent research has suggested that at least part of language acquisition and adult speech perception depends upon formation of phonetic categories corresponding to the speech sounds of the native language. Unfortunately, much of what is known about perceptual categorization has been learned from examination of categories that are fundamentally different from phonetic categories (e.g., visual categories).&lt;br/&gt;&lt;br/&gt;Unfortunately, probing the means by which speech is categorized is not so easy as applying methods and results from visual categorization to the domain of speech perception. Speech categories are very difficult to examine because it is extraordinarily difficult to determine the history of speech experience that a listener encounters before entering the laboratory. There simply is little experimental control. Fortunately, there is a means to address this important question. Pilot work by the PIs has suggested that complex non-speech sounds that model the structure of speech categories have value in learning about how listeners form categories similar to phonetic categories. Using the set of novel methods developed in this pilot work, the PIs will investigate the role of experience in forming complex auditory categories.&lt;br/&gt;&lt;br/&gt;The ultimate goal of this project is to determine the role that general perceptual categorization processes play in first and second language acquisition. A program of research will employ complex nonspeech sounds to provide a detailed account of how human listeners form complex auditory categories. These results then will be examined to determine whether some of the notable characteristics of speech perception can be explained in part by appealing to general processes of perceptual categorization. The results of these experiments will allow the PIs to develop efficient methods of exposure and training to teach non-native contrasts to second-language learners. Exposing the mechanisms of complex category learning will illuminate potential aids for training individuals to discriminate nonnative speech categories. These aids could extend easily to other complex learning tasks such as musical training, acoustic warning systems or auditory data displays.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/21/2000</MinAmdLetterDate>
<MaxAmdLetterDate>06/04/2001</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0078768</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Lotto</LastName>
<EmailAddress>alotto@email.arizona.edu</EmailAddress>
<StartDate>08/21/2000</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lori</FirstName>
<LastName>Holt</LastName>
<EmailAddress>lholt@andrew.cmu.edu</EmailAddress>
<StartDate>08/21/2000</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1180</Code>
<Text>HUMAN COGNITION &amp; PERCEPTION</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
