<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Developing Contextual Cues for Just-in-Time Information Retrieval on Wearable Computers</AwardTitle>
<AwardEffectiveDate>03/15/2001</AwardEffectiveDate>
<AwardExpirationDate>02/28/2007</AwardExpirationDate>
<AwardTotalIntnAmount>549739.00</AwardTotalIntnAmount>
<AwardAmount>619389</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The hypothesis underlying this project is that, with increasing interactivity and personalization of computing systems, just-in-time information retrieval agents (JITIRs) which proactively retrieve and present information based on a person's local context in an accessible yet non-intrusive manner, and which are implemented on wearable computers, will become a feature of the next stage of computing.  To recover the user's context, the physical proximity of wearable computers to the user will be leveraged in designing perceptual systems that "see" and "hear" from the user's perspective.    To these ends, the PI will create a Wearable Computer Workshop for rapid prototyping of new wearable sensors and systems.   Although the mobile environment is extremely harsh for perceptual systems and algorithms that have been developed in the laboratory, systems that use standard video and audio for input will be preferred because they afford advantages such as automatic creation of new media databases for search, ease of annotation, availability of sensors, and applicability of results to other fields.  The PI expects to adapt and exploit promising results from prior research in other domains, including face recognition algorithms, recognition of sign language gestures, hand movements involved in interacting with objects or performing tasks, gestures made in discourse, and user location systems.   To support the desired model-based recognition systems, a new form of annotation derived from prior work in analyzing narration will be developed for the data collected during a user's everyday life.    Ultimately, the PI will create a community of everyday users of his systems and perform studies to determine how access to JITIRs affects the wearer's use of knowledge.   The PI expects this work to have broad impacts, including the development of radically new customizable wearable platforms with the ready ability to interface to new sensor technology, a sensor package directed at capturing a user's everyday life, prototype wearable face recognition and gesture recognition systems, and the expansion of traditional information retrieval algorithms to loosely defined multimedia query searches.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/05/2001</MinAmdLetterDate>
<MaxAmdLetterDate>02/11/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0093291</AwardID>
<Investigator>
<FirstName>Thad</FirstName>
<LastName>Starner</LastName>
<EmailAddress>thadstarner@gmail.com</EmailAddress>
<StartDate>03/05/2001</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>6845</Code>
<Text>HUMAN COMPUTER INTER PROGRAM</Text>
</ProgramElement>
<ProgramElement>
<Code>6846</Code>
<Text>UNIVERSAL ACCESS</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
