<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Average Reward Reinforcement Learning:   Scaling up</AwardTitle>
<AwardEffectiveDate>05/01/2001</AwardEffectiveDate>
<AwardExpirationDate>04/30/2005</AwardExpirationDate>
<AwardTotalIntnAmount>368658.00</AwardTotalIntnAmount>
<AwardAmount>368658</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Edwina L. Rissland</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This is the first year funding of a three year continuing award.  Imagine a factory of the future that teems with intelligent autonomous robots and machines engaged in production.   Machines that can not only sense and act, but can also optimize their own behavior without being explicitly programmed.  And robots that can learn to coordinate their actions with other robots in order to satisfy an overall optimization criterion.  The ability to build such machines and robots radically reorganizes the factories, so that people's role is reduced to specifying an optimization criterion and giving feedback to the machines, leaving the low level control and optimization issues to the machines themselves.  This project seeks to design and study  the algorithmic and computational tools necessary to build such machines and robots.  The long-term scientific goal  is to gain a better understanding of the tradeoffs involved in the design of adaptive autonomous multi-agent systems;   in particular, the tradeoffs between the optimality of the behavior, computational and communication efficiencies, generality, and speed of learning.  Optimizing the performance of programs via rewards and punishments, or reinforcement learning, appears to be the most promising approach to building such adaptive multi-agent systems for complex real-world domains.  Many real-world problems in manufacturing, such as production scheduling and inventory control, are best seen as "average-reward reinforcement learning" (ARL) problems, where the optimization criterion is to maximize the average reward received per unit of time.  The goal of this project is to develop scaleable algorithms, programs and techniques for solving large ARL problems, with manufacturing as the primary application domain.  The PI will push the frontiers of this technology to the point where it can be applied to factories with hundreds of machines and job types, with realistic assumptions such as partial observability and scalability to multiple agents.  Successful completion of this project will lead to new scaleable algorithms and programs for solving large ARL problems, which could well have significant economic impact.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>05/02/2001</MinAmdLetterDate>
<MaxAmdLetterDate>05/18/2004</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0098050</AwardID>
<Investigator>
<FirstName>Prasad</FirstName>
<LastName>Tadepalli</LastName>
<EmailAddress>tadepall@eecs.orst.edu</EmailAddress>
<StartDate>05/02/2001</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Oregon State University</Name>
<CityName>Corvallis</CityName>
<ZipCode>973318507</ZipCode>
<PhoneNumber>5417374933</PhoneNumber>
<StreetAddress>OREGON STATE UNIVERSITY</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramElement>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
