<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase II: Auto-Tracking Using Trailing Templates and Skeletal Guides</AwardTitle>
    <AwardEffectiveDate>05/01/2001</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2004</AwardExpirationDate>
    <AwardAmount>750000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Sara B. Nerlove</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Small Business Innovation Research (SBIR) Phase II project continues research and development aimed at demonstrating the feasibility for automatic video tracking of the motion of animals and humans in unconstrained environments. The Phase I study succeeded by designing low-level intelligence into predictive search algorithms that were able to confine their search for the correct position in a succeeding image to specific, small regions predicted by the system. The objective is to create a software system, easily operable by an unsophisticated user that can quickly and accurately track multiple points or regions of a moving animal or human through a sequence of video images. This tracking can be done despite background clutter and intermittent occlusion, and without attaching any distinguishing markers to the subject. In Phase I, a user interface was designed that allowed the user to choose a 'skeletal template' to be tracked with a pointing device (a mouse) by selecting vertices of closed polygons and connected rotation points. By sensing the direction and speed of motion of the system, the model-based tracking algorithm told the search mechanism where it should look in the next image to match a 'trailing template' derived from previous locations and orientations of the template. In Phase II, more sophisticated modeling and prediction algorithms, including supervised learning of constructed models, and a pyramided coarse-to-fine scale-space, constructed at video load time, will be brought to bear that will increase speed and efficiency of the tracking algorithm and improve the robustness of the model-based approach. At the same time, the user interface will be redefined to improve the 'look and feel' and give it a more intuitive structure. &lt;br/&gt;&lt;br/&gt;Applications for this software have a ready market demand. Present commercial tracking technology of biological motion requires the placement of intrusive control targets at critical positions on the subject. The commercial need for tracking and characterizing general biological motion will be exploited, including tools for animal behavior analysis, and predicting and improving motion efficiency in athletes. In addition, this technology has applications in diagnostics and medicine/health applications, surveillance, and other uses ranging from NASA's space research, to ergonomic design, to the fingering of musical instruments.</AbstractNarration>
    <MinAmdLetterDate>05/14/2001</MinAmdLetterDate>
    <MaxAmdLetterDate>07/13/2004</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0091510</AwardID>
    <Investigator>
      <FirstName>Paul</FirstName>
      <LastName>Mostert</LastName>
      <EmailAddress>pmostert@alltel.net</EmailAddress>
      <StartDate>05/14/2001</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Mostert Group</Name>
      <CityName>Lexington</CityName>
      <ZipCode>405033432</ZipCode>
      <PhoneNumber>6062231490</PhoneNumber>
      <StreetAddress>3298 Roxburg Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Kentucky</StateName>
      <StateCode>KY</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
  </Award>
</rootTag>
