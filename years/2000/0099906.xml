<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Model Complexity Control for Predictive Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2001</AwardEffectiveDate>
<AwardExpirationDate>08/31/2004</AwardExpirationDate>
<AwardTotalIntnAmount>150236.00</AwardTotalIntnAmount>
<AwardAmount>150236</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Werbos</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>0099906&lt;br/&gt;Cherkassky&lt;br/&gt;&lt;br/&gt;This proposal will attempt to develop new approaches to the statistical foundations of learning, which are fundamental to the performance and capability of all learning systems, including intelligent control.&lt;br/&gt;&lt;br/&gt;Many learning algorithms are based on the idea of 'empirical risk minimization', which amounts to choosing the model that minimizes the number of errors on the training data. However, the goal of learning is often to obtain a model providing minimal prediction risk, i.e. error for (unknown) future data. It is well-known that for a given training sample there exist a model of optimal complexity corresponding to the smallest prediction (generalization) error for future data. Hence, any method for learning from samples need to have some provisions for complexity control. Existing implementations of complexity control include penalization (or regularization), weight decay (in neural networks), and various greedy procedures (i.e. stepwise regression).&lt;br/&gt;&lt;br/&gt;There are three (generic) problems common to all methodologies for complexity control. First, one needs to define a meaningful complexity index for a set of (parameterized) functions (admissible models). Second, one needs to estimate the prediction risk from the (known) empirical risk; such estimates are known as model selection criteria in statistics. Third, there is a problem of finding a global minimum of the empirical risk (or penalized empirical risk).  This project will attempt to extent Vapnik-Chervonenkis (VC) theory in order to provide a principled solution to these problems.&lt;br/&gt;&lt;br/&gt;This research is intended to improve theoretical understanding of signal estimation and to develop new practical methods for signal denoising.  The PI shall develop new methods for estimation/denoising of 1D and 2D signals (images) and compare them with existing wavelet denoising methods.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/21/2001</MinAmdLetterDate>
<MaxAmdLetterDate>09/21/2001</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0099906</AwardID>
<Investigator>
<FirstName>Vladimir</FirstName>
<LastName>Cherkassky</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vladimir S Cherkassky</PI_FULL_NAME>
<EmailAddress>cherk001@umn.edu</EmailAddress>
<PI_PHON>6126259597</PI_PHON>
<NSF_ID>000372327</NSF_ID>
<StartDate>09/21/2001</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<CountyName>HENNEPIN</CountyName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<CountyName>HENNEPIN</CountyName>
<StateCode>MN</StateCode>
<ZipCode>554552070</ZipCode>
<StreetAddress><![CDATA[200 OAK ST SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0510403</Code>
<Name>Engineering &amp; Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>1518</Code>
<Text>CONTROL, NETWORKS, &amp; COMP INTE</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0101</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2001~150236</FUND_OBLG>
</Award>
</rootTag>
