<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Instrumentation:  Free-Viewing Eyetracker for Studies of Visuo-Spatial Cognition and Psycholinguistics</AwardTitle>
<AwardEffectiveDate>08/15/2000</AwardEffectiveDate>
<AwardExpirationDate>07/31/2003</AwardExpirationDate>
<AwardTotalIntnAmount>51314.00</AwardTotalIntnAmount>
<AwardAmount>51314</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Yellen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Ferreira&lt;br/&gt;0083570&lt;br/&gt;&lt;br/&gt;The grant provides funds to allow the investigators to obtain significant instrumentation for cognitive / behavioral research. The requested-funds wo6/ld be used to purchase a free-viewing, mobile eye movement monitoring system, along with a computer workstation and a monitor for displaying some stimuli (in other cases, stimuli will be real, three-dimensional objects and scenes). The mobile eyetracker allows the viewer to examine real-world scenes or visual displays of scenes while making normal, natural head and body movements. Indeed, the system allows researchers to obtain precise information about where a person is looking as he or she moves through or manipulates objects in a natural environment. The instrumentation would be used for a variety of studies in cognitive and behavioral sciences. These include: (1) Research to examine how comprehenders quickly obtain interpretations for spoken sentences. No other existing methodology allows researchers to measure moment-by-moment processing for aurally presented sentences. (2) Research to study how real-world scenes are represented, and how representations of objects and scenes are generated dynamically over time in the context of meaningful actions. (3) Investigations of how humans are able to navigate novel and familiar environments, focusing particularly on eye movement patterns (e.g., what objects are used as guideposts and landmarks). (4) Studies of human-computer interaction, including the representation of objects and navigation through "virtual reality" environments. The free-viewing eyetracker would complement the Principal Investigators' existing laboratory facilities and greatly enhance the ability to train undergraduate and graduate students in sophisticated methodologies for studying complex behavior in intelligent systems.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/27/2000</MinAmdLetterDate>
<MaxAmdLetterDate>11/12/2002</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0083570</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Henderson</LastName>
<EmailAddress>johnhenderson@ucdavis.edu</EmailAddress>
<StartDate>07/27/2000</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fernanda</FirstName>
<LastName>Ferreira</LastName>
<EmailAddress>fferreira@ucdavis.edu</EmailAddress>
<StartDate>07/27/2000</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>1327</Code>
<Text>SBE INSTRUMENTATION</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
