<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Faster Eigenvalue Computations</AwardTitle>
<AwardEffectiveDate>08/15/2000</AwardEffectiveDate>
<AwardExpirationDate>07/31/2004</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040100</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Junping Wang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>FASTER EIGENVALUE COMPUTATIONS&lt;br/&gt;&lt;br/&gt;Roy Mathias&lt;br/&gt;College of William and Mary&lt;br/&gt;&lt;br/&gt;ABSTRACT&lt;br/&gt;&lt;br/&gt;I will  develop new, much faster, algorithms to solve eigenproblems.  My approach is to actively force deflations, rather than passively waiting for them to occur.  This idea, called aggressive deflation, was developed by Braman, Byers and Mathias.  A very simple untuned implementation of the idea resulted in computational savings of up to a factor of 3. My project consists of two parts.  The first part is to perfect the details of the implementation of aggressive deflation, to extend it to other eigenvalue problems, and to write software implementing these ideas, so that others can use them easily -- like a black box.  This will provide a simple way to greatly increase the speed of eigenvalue computations.  In light of the results mentioned above I have little doubt about the utility and success of this first part of the project.  The second part is much more ambitious and more speculative. It is to repeatedly use the aggressive deflation idea, with carefully chosen parameters, so that one is able to force so many deflations that, in the case of the Hessenberg eigenvalue problem, the complexity is less than the now standard n-cubed, and is perhaps as low as  n-squared-log(n) for many families of problems.  I hope to make similar improvements in algorithms for other eigenvalue problems.&lt;br/&gt;&lt;br/&gt;Many physical systems are modeled using matrices.  The eigenvalues of these matrices provide insight on how these systems behave.  Here are two well known examples of the utility of eigenvalues.  Firstly, the collapse of the Tacoma narrows bridge  could have been predicted by analyzing the eigenvalues of the associated matrix.  Secondly, each chemical element emits light of characteristic frequencies, which are the eigenvalues of an associated matrix.  One can deduce the make up of stars just by observing the frequencies of light they emit.  The larger the matrix used to model the system the more accurate the model.  Unfortunately, the number of arithmetic operations that the standard approach to computing the eigenvalues of a n-by-n matrix is proportional to n-cubed.  I plan to develop algorithms which &lt;br/&gt;&lt;br/&gt;1. have operation count proportional to n-squared (approximately), and since n can be in the thousands or millions this apparently minor improvement should prove very useful, and &lt;br/&gt;&lt;br/&gt;2. can exploit the capabilities of modern super computers, which perhaps ironically, take longer to recall numbers from memory than to multiply or add them.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/29/2000</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2000</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0075112</AwardID>
<Investigator>
<FirstName>Roy</FirstName>
<LastName>Mathias</LastName>
<EmailAddress>mathias@for.mat.bham.ac.uk</EmailAddress>
<StartDate>08/29/2000</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>College of William and Mary</Name>
<CityName>Williamsburg</CityName>
<ZipCode>231878795</ZipCode>
<PhoneNumber>7572213966</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
