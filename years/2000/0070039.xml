<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Global Stability and Robustness Properties of Neural Control Systems</AwardTitle>
<AwardEffectiveDate>06/15/2000</AwardEffectiveDate>
<AwardExpirationDate>12/31/2003</AwardExpirationDate>
<AwardTotalIntnAmount>222787.00</AwardTotalIntnAmount>
<AwardAmount>222787</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Werbos</SignBlockName>
</ProgramOfficer>
<AbstractNarration>0070039&lt;br/&gt;Annaswamy&lt;br/&gt;&lt;br/&gt;The use of neural networks in identification and control of engineering systems has been intensely debated over the past decade.  Despite the fact that several stability results have been derived in the literature concerning neural networks in identification and control, most of them are local in nature and/or include fairly restrictive conditions under which the stability is valid.  In contrast to these analytical results, the actual demonstration in applications and numerical simulations reports just the contrary: Neural networks indeed serve as powerful numerical computational units that are capable of very good approximations of nonlinear maps and provide complex functionalities of estimation, control, and optimization over a large region of operation. The goal of this project is to address this gap and develop global stability tools that are capable of explaining the true scope of operation of a neural network when used for nonlinear control.  The main idea here is to directly address and exploit the distinguishing feature of nonlinear regression in neural networks and derive the underlying convergence and stability properties. Preliminary results in [I] show that it is possible to derive conditions under which global convergence takes place in identification problems using neural networks.  The P.I. plans to derive training algorithms as well as conditions under which global system identification using neural networks as well as global stability using neural controllers can be derived.  Various neural network structures including multi-layered perceptrons and radial basis functions will be examined.  The applicability as well as limitations of gradient-like algorithms in these problems &lt;br/&gt;will be studied.  All theoretical derivations will be complemented by simulation studies.  The results from the proposed research will lead to fundamental advances in the analysis and design of complex dynamic systems in various engineering problems.&lt;br/&gt;***&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/13/2000</MinAmdLetterDate>
<MaxAmdLetterDate>07/15/2002</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0070039</AwardID>
<Investigator>
<FirstName>Anuradha</FirstName>
<LastName>Annaswamy</LastName>
<EmailAddress>aanna@mit.edu</EmailAddress>
<StartDate>06/13/2000</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<FoaInformation>
<Code>0206000</Code>
<Name>Telecommunications</Name>
</FoaInformation>
<ProgramElement>
<Code>1518</Code>
<Text>CONTROL, NETWORKS, &amp; COMP INTE</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
