<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SGER: Real-time Depth-Image Meshing and Warping</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2001</AwardEffectiveDate>
<AwardExpirationDate>08/31/2002</AwardExpirationDate>
<AwardTotalIntnAmount>68123.00</AwardTotalIntnAmount>
<AwardAmount>68123</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010200</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Randolph Franklin</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>0119053&lt;br/&gt;Pajarola, Renato&lt;br/&gt;U of Cal Irvine&lt;br/&gt;&lt;br/&gt;In recent years a new rendering paradigm based on the reuse of two-dimensional imagery to generate 3D renderings has evolved, called Image Based Rendering (IBR). Based on a set of input images, so called reference views, IBR methods can generate new images from arbitrary view points. One of the main advantages of IBR techniques is that the rendering cost is independent of the scene complexity and bound by the image resolution. The use of IBR techniques thus allows in certain situations to achieve real-time display performance for other-wise non-interactive rendering of complex geometric scenes. The main target applications are interactive rendering of highly complex scenes (virtual reality systems), and rendering on time-budgets (simulations and computer-game like environments).&lt;br/&gt;&lt;br/&gt;This grant will improve and explore new techniques for interactive rendering applications on the basis of the depth-image warping approach. Our goal is not to restrict computation of reference views to a preprocessing step, but to explore and develop algorithms and data structures that allow the generation and reuse of depth-image reference views dynamically in an interactive visualization environment. Depth-image warping is a powerful approach, and using multiple reference views to limit visibility artifacts it is possible to create new renderings for a wide range of views. However, the user's movements in a virtual environment are unpredictable, and thus reference views have to be generated dynamically to optimize their use. Therefore, from acquiring image based representations for the reference views to rendering from image data everything has to be done dynamically in an interactive visualization framework.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/28/2001</MinAmdLetterDate>
<MaxAmdLetterDate>08/28/2001</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0119053</AwardID>
<Investigator>
<FirstName>Renato</FirstName>
<LastName>Pajarola</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Renato B Pajarola</PI_FULL_NAME>
<EmailAddress>pajarola@ics.uci.edu</EmailAddress>
<PI_PHON>9498246357</PI_PHON>
<NSF_ID>000494202</NSF_ID>
<StartDate>08/28/2001</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<CountyName/>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<CountyName/>
<StateCode>CA</StateCode>
<ZipCode>926977600</ZipCode>
<StreetAddress><![CDATA[160 Aldrich Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2865</Code>
<Text>NUMERIC, SYMBOLIC &amp; GEO COMPUT</Text>
</ProgramElement>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0101</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2001~68123</FUND_OBLG>
</Award>
</rootTag>
