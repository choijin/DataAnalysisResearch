<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Intelligent Autonomous Video Quality Agents</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>499944.00</AwardTotalIntnAmount>
<AwardAmount>499944</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Determining the perceptual quality of video transmitted through complex networks and viewed on heterogeneous platforms, from cell phones to Internet-based television, is a key problem for the YouTube generation. It is also central to a variety of vision applications including face detection, face recognition and surveillance. Video is subject to numerous distortions: blur, noise, compression, packet/frame drops, etc. Quality assessment is non-trivial when an undistorted video is not available, and unsolved for multiple distortion types and in distributed, non-stationary viewing environments.&lt;br/&gt;&lt;br/&gt;This project designs and creates intelligent video "quality agents" that learn how to determine perceptual video quality in heterogeneous networks, and assesses its impact on decision tasks such as face detection and recognition, all without the benefit of reference videos. It uses statistical properties of natural scenes, perceptual principles, machine learning, and intelligent adaptive agent collectives to handle videos simultaneously impaired by multiple distortion types. A primary application is novel face-salient quality assessment agents and quality-aware face detection algorithms. Multiple, co-operative video and face quality agents are trained using active learning based feedback mechanisms on mobile devices. This project yields adaptive, robust video Quality of Service assessment in real-life networks and provides new insights into human visual quality perception and visual distortion detection. The research team also creates two large, unique video quality databases: (a) A Mobile Video Quality Database of raw and distorted mobile videos and (b) A Distorted Face Database of undistorted and distorted face images, as gold standards for research and development in this area.</AbstractNarration>
<MinAmdLetterDate>08/29/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116656</AwardID>
<Investigator>
<FirstName>Alan</FirstName>
<LastName>Bovik</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alan C Bovik</PI_FULL_NAME>
<EmailAddress>bovik@ece.utexas.edu</EmailAddress>
<PI_PHON>5124715370</PI_PHON>
<NSF_ID>000305764</NSF_ID>
<StartDate>08/29/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Joydeep</FirstName>
<LastName>Ghosh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joydeep Ghosh</PI_FULL_NAME>
<EmailAddress>jghosh@utexas.edu</EmailAddress>
<PI_PHON>5124718980</PI_PHON>
<NSF_ID>000446751</NSF_ID>
<StartDate>08/29/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787595316</ZipCode>
<StreetAddress><![CDATA[3925 W Braker Lane, Ste 3.340]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~499944</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Outcome 1: We created the world&rsquo;s first high-performance no-reference (blind) image and video quality models called DIIVINE, BLIINDS, and BRISQUE which can predict what a human will judge the quality of an image, video, or 3D image is, without knowing anything about the image or video in advance. It is created using machine learning methods trained on large databases of distorted images and videos and human judgements of them. W</span>e created the world&rsquo;s first &lsquo;completely blind&rsquo; image and video quality models, called NIQE and VIIDEO, respectively, that do not require training on human subject scores of distorted videos, do not require training or exposure of any kind to distorted signals, and indeed to not rely on training at all, instead depending only on the quality-aware statistical models of natural images, videos, and 3D images.</p> <p><span>Outcome 2: We created a number of high-profile databases that are freely available at no charge to any persons around the world to conduct imae/video/3D quality research:</span></p> <p><span>LIVE Mobile Video Quality Assessment Database</span></p> <p><span>LIVE Multiply Distorted Image Quality Database</span></p> <p>LIVE <span>QoE Database for HTTP-based Video Streaming</span></p> <p><span>LIVE 3D Image Quality Database<span><span>&nbsp;</span></span></span></p> <p>LIVE <span>Distorted Face Database<span><span>&nbsp;</span></span></span></p> <p><span>&nbsp;</span></p> <p><span>Outcome3: We showed how the Quality of Experience of video users can be improved by perceptually optimizing the way that videos are coded and compressed in computer and wireless networks that change over time or with conditions. We created algorithms that can analyze the current video quality and adjust the rate of video communication. This can directly impact OTT video like Netflix and Hulu.</span></p> <p><span><br /></span></p> <p><span>Outcome 4: We defined anew concept of blind image repair as a process of correcting one or more different and unknown types of distortions afflicting an image. These distortions could introduce linear or non-linear degradations, compression artifacts, noise, etc., or combinations of these. Thus the concept encompasses denoising, deblurring, deblocking, deringing, and other post-acquisition image improvement processes that address distortions. The problem we tackle is also distortion-blind when the natures of the distortion processes are unknown prior to analyzing the image. Towards solving this problem, we created a new way of repairing an image that has undergone an unknown set of distortions, based on identifying the distortion(s) present in the image (if any) and applying possibly multiple distortion-specific image repair algorithms.</span></p> <p>&nbsp;</p> <p><span>Outcome 5: Motivated by the proliferation of low-cost digital cameras in mobile devices being deployed in automated surveillance networks, we studied the interaction between perceptual image quality and a classic computer vision task of face detection. We quantified the degradation in performance of a popular and effective face detector when human-perceived image quality was degraded by distortions commonly occurring&nbsp;</span>in capture, storage, and transmission of facial images, including noise, blur, and compression. It was observed that, within a certain range of perceived image quality, a modest increase in image quality can drastically improve face detection performance.</p> <p><span>These results can be used to guide resource or bandwidth allocation in acquisition or communication/delivery systems that are associated with face detection tasks. A new&nbsp;</span>algorithm, called QualHOG, was devised using perceptual quality-aware spatial Natural Scene Statistics (NSS) features. Face detectors trained on these new features provide statistically significant improvement in tolerance to image distortions. Distort...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Outcome 1: We created the worldÆs first high-performance no-reference (blind) image and video quality models called DIIVINE, BLIINDS, and BRISQUE which can predict what a human will judge the quality of an image, video, or 3D image is, without knowing anything about the image or video in advance. It is created using machine learning methods trained on large databases of distorted images and videos and human judgements of them. We created the worldÆs first æcompletely blindÆ image and video quality models, called NIQE and VIIDEO, respectively, that do not require training on human subject scores of distorted videos, do not require training or exposure of any kind to distorted signals, and indeed to not rely on training at all, instead depending only on the quality-aware statistical models of natural images, videos, and 3D images.  Outcome 2: We created a number of high-profile databases that are freely available at no charge to any persons around the world to conduct imae/video/3D quality research:  LIVE Mobile Video Quality Assessment Database  LIVE Multiply Distorted Image Quality Database  LIVE QoE Database for HTTP-based Video Streaming  LIVE 3D Image Quality Database   LIVE Distorted Face Database      Outcome3: We showed how the Quality of Experience of video users can be improved by perceptually optimizing the way that videos are coded and compressed in computer and wireless networks that change over time or with conditions. We created algorithms that can analyze the current video quality and adjust the rate of video communication. This can directly impact OTT video like Netflix and Hulu.     Outcome 4: We defined anew concept of blind image repair as a process of correcting one or more different and unknown types of distortions afflicting an image. These distortions could introduce linear or non-linear degradations, compression artifacts, noise, etc., or combinations of these. Thus the concept encompasses denoising, deblurring, deblocking, deringing, and other post-acquisition image improvement processes that address distortions. The problem we tackle is also distortion-blind when the natures of the distortion processes are unknown prior to analyzing the image. Towards solving this problem, we created a new way of repairing an image that has undergone an unknown set of distortions, based on identifying the distortion(s) present in the image (if any) and applying possibly multiple distortion-specific image repair algorithms.     Outcome 5: Motivated by the proliferation of low-cost digital cameras in mobile devices being deployed in automated surveillance networks, we studied the interaction between perceptual image quality and a classic computer vision task of face detection. We quantified the degradation in performance of a popular and effective face detector when human-perceived image quality was degraded by distortions commonly occurring in capture, storage, and transmission of facial images, including noise, blur, and compression. It was observed that, within a certain range of perceived image quality, a modest increase in image quality can drastically improve face detection performance.  These results can be used to guide resource or bandwidth allocation in acquisition or communication/delivery systems that are associated with face detection tasks. A new algorithm, called QualHOG, was devised using perceptual quality-aware spatial Natural Scene Statistics (NSS) features. Face detectors trained on these new features provide statistically significant improvement in tolerance to image distortions. Distortion dependent and distortion-unaware variants of the face detectors were developed and evaluated on a large database of face images representing a wide range of distortions.     Outcome 6: Estimating an accurate and naturalistic dense depth map from a single monocular photographic image is a very difficult problem. Nevertheless, 2D images of the real-world environment contain significant statistical information regar...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
