<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: New Directions for Metric Learning</AwardTitle>
<AwardEffectiveDate>03/01/2012</AwardEffectiveDate>
<AwardExpirationDate>10/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>432280.00</AwardTotalIntnAmount>
<AwardAmount>478280</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Quantifying similarity is a fundamental challenge in artificial intelligence and machine learning which - if performed perfectly - would reduce many tasks to a trivial nearest neighbor search. For example, determining whether an email were spam would be as simple as searching a labeled database of emails and assigning it the same label (spam or not) as the email considered most similar to it. But how can one measure the similarity of two email messages? Does the same measurement still apply when comparing medical images? How does our understanding of similarity depend on the problem specification? Metric learning optimizes distance functions specifically for a given task, taking into account both the learning problem and the data. Initial successes with linear metrics show great improvements on many "k-nearest neighbors"-based learning tasks. &lt;br/&gt;&lt;br/&gt;This project pursues four research directions that strengthen the theoretical understanding of metric learning within the research community, broaden its impact and significantly improve the current state-of-the-art: &lt;br/&gt;&lt;br/&gt;1. Are there non-linear transformations that lead to equally elegant and efficient optimization problems as existing linear metrics? As data sets grow and become increasingly complex, linear metrics are no longer sufficient to capture similarity relations. By exploring the use of non-linear metrics, this research can substantially improve the impact of metric learning and the accuracy of similarity relations. &lt;br/&gt;&lt;br/&gt;2. Can the impact of metric learning be extended to machine learning frameworks beyond nearest neighbors? Designing new metric learning algorithms that explicitly optimize distances for a broad variety of machine learning algorithms will significantly increase the number of applications and learning methods that can directly benefit from metric learning. &lt;br/&gt;&lt;br/&gt;3. Can metrics be learned from weak supervision? Removing the dependency on labeled data will reduce the cost of metric learning and increase its applicability. &lt;br/&gt;&lt;br/&gt;4. Can one develop a solid theoretical framework to explain preliminary empirical successes and to direct future research? This will strengthen the theoretical understanding of metric learning within the research community. &lt;br/&gt;&lt;br/&gt;Successful resolution of the proposed problems will lead to novel learning methods which will be immediately applicable to ongoing high-impact medical research collaborations of the principal investigator. In conjunction with these research directions, the principal investigator will also pursue educational goals, including the co-development of a K-12 curriculum module estimated to impact 2,500 high-school students. Many topics in the proposed research plan have components ideal for introducing the research process to undergraduate and graduate students, and the principal investigator plans to use his research as a vehicle to instruct and inspire future computer scientists and next-generation researchers.</AbstractNarration>
<MinAmdLetterDate>01/19/2012</MinAmdLetterDate>
<MaxAmdLetterDate>03/02/2015</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1149882</AwardID>
<Investigator>
<FirstName>Kilian</FirstName>
<LastName>Weinberger</LastName>
<EmailAddress>kilianweinberger@cornell.edu</EmailAddress>
<StartDate>01/19/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Washington University</Name>
<CityName>Saint Louis</CityName>
<ZipCode>631304862</ZipCode>
<PhoneNumber>3147474134</PhoneNumber>
<StreetAddress>CAMPUS BOX 1054</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
</Award>
</rootTag>
