<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Programming with Crowds: Models and Tools for General Purpose Crowdsourcing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>369067.00</AwardTotalIntnAmount>
<AwardAmount>369067</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Frederick Kronz</SignBlockName>
<PO_EMAI>fkronz@nsf.gov</PO_EMAI>
<PO_PHON>7032927283</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Crowdsourcing is a powerful way to marshal small contributions from large numbers of people to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk). This project moves towards a vision of crowdsourcing that extends it to support complex, creative, and interdependent tasks, and embeds it into computing systems as part of our everyday lives. The project will focus on two application areas for complex crowdsourcing: science journalism and software development.&lt;br/&gt;&lt;br/&gt;The intellectual merits of the project include the uncovering of new scientific knowledge about how to model online crowd behavior, and the development of new methods and tools for using crowds as part of computer system designs, particularly for complex, interdependent, real time work. The project will also show that these methods can be used for real-world problems. &lt;br/&gt;&lt;br/&gt;The potential broader impacts include those specifically having to do with the two application areas, which could have significant impacts on society. Crowdsourcing science journalism will directly involve citizens in the process of science dissemination, making scientific information more accessible to the general public, and promoting greater awareness of science and the scientific process. Crowdsourcing software development can transform the way that software is created, lowering barriers and broadening participation in open source software development, and helping larger masses of people use and improve their programming skills. Other impacts will flow from the researchers' plans to publically share the infrastructure that they develop to facilitate complex crowdsourcing in many other areas. They also plan to integrate their research results into undergraduate courses.</AbstractNarration>
<MinAmdLetterDate>09/19/2011</MinAmdLetterDate>
<MaxAmdLetterDate>09/19/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1111044</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Miller</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert C Miller</PI_FULL_NAME>
<EmailAddress>rcm@mit.edu</EmailAddress>
<PI_PHON>6173246028</PI_PHON>
<NSF_ID>000222423</NSF_ID>
<StartDate>09/19/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7953</Code>
<Text>SOCIAL-COMPUTATIONAL SYSTEMS</Text>
</ProgramElement>
<ProgramReference>
<Code>7953</Code>
<Text>SOCIAL-COMPUTATIONAL SYSTEMS</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~369067</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Crowdsourcing is a powerful way to collect small contributions from large numbers of people on the web to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk).</p> <p>This project has extended the frontiers of crowdsourcing in several directions, including (1) realtime crowdsourcing, (2) communitysourcing for solving problems with complex constraints, and (3) learnersourcing for education.</p> <p><strong>Realtime crowdsourcing</strong> means that the crowd&rsquo;s help is needed within seconds, rather than hours or days, in order to support an interactive application. &nbsp;Examples of interactive applications we have built that depend on realtime crowds include VizWiz, a smartphone app that allows a blind user to take a picture, ask a question about it, and get answers from a crowd in less than a minute; and Adrenaline, a camera app with a &ldquo;crowd-controlled shutter&rdquo;, which captures a short video and sends it to a crowd to choose the best frame to keep, getting the answer back in seconds.</p> <p><strong>Communitysourcing</strong> combines small contributions from members of a community to solve a complex problem. &nbsp;In collaboration with Carnegie Mellon University, Northwestern University, and University of Washington, our Cobi project has developed ways to use communitysourcing to create a schedule for a large multi-track research conference. &nbsp;Scheduling a conference is a daunting task, requiring consideration of the preferences and constraints of organizers, authors, and attendees. Traditionally, a few dedicated organizers manage the size and complexity of the schedule with limited information and coverage. Cobi consists of a collection of crowdsourcing applications that collect preferences and constraints from the community, and a visual scheduling interface that enables organizers and other community members to take informed actions based on collected information.</p> <p><strong>Learnersourcing</strong> draws on crowds of learners, who might be students enrolled in a MOOC or people learning informally from online resources like YouTube how-to videos, to contribute small bits of work that improve the learning experience of the system. We have been studying two kinds of learnersourcing: passive learnersourcing, which uses behavior traces from learners as they interact with learning materials to improve them, and active learnersourcing, which directly asks learners to do a small amount of work. &nbsp;The kinds of work that our systems collect have ranged from small bits of programming, to video outlines, to hints about solving assignments.</p> <p>The project has contributed support to 5 PhD students and 4 masters students at MIT, and work associated with the project has produced at least 19 research papers and 7 theses, and at least 8 software systems that are available as open source.</p><br> <p>            Last Modified: 11/30/2015<br>      Modified by: Robert&nbsp;C&nbsp;Miller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Crowdsourcing is a powerful way to collect small contributions from large numbers of people on the web to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk).  This project has extended the frontiers of crowdsourcing in several directions, including (1) realtime crowdsourcing, (2) communitysourcing for solving problems with complex constraints, and (3) learnersourcing for education.  Realtime crowdsourcing means that the crowdÃ†s help is needed within seconds, rather than hours or days, in order to support an interactive application.  Examples of interactive applications we have built that depend on realtime crowds include VizWiz, a smartphone app that allows a blind user to take a picture, ask a question about it, and get answers from a crowd in less than a minute; and Adrenaline, a camera app with a "crowd-controlled shutter", which captures a short video and sends it to a crowd to choose the best frame to keep, getting the answer back in seconds.  Communitysourcing combines small contributions from members of a community to solve a complex problem.  In collaboration with Carnegie Mellon University, Northwestern University, and University of Washington, our Cobi project has developed ways to use communitysourcing to create a schedule for a large multi-track research conference.  Scheduling a conference is a daunting task, requiring consideration of the preferences and constraints of organizers, authors, and attendees. Traditionally, a few dedicated organizers manage the size and complexity of the schedule with limited information and coverage. Cobi consists of a collection of crowdsourcing applications that collect preferences and constraints from the community, and a visual scheduling interface that enables organizers and other community members to take informed actions based on collected information.  Learnersourcing draws on crowds of learners, who might be students enrolled in a MOOC or people learning informally from online resources like YouTube how-to videos, to contribute small bits of work that improve the learning experience of the system. We have been studying two kinds of learnersourcing: passive learnersourcing, which uses behavior traces from learners as they interact with learning materials to improve them, and active learnersourcing, which directly asks learners to do a small amount of work.  The kinds of work that our systems collect have ranged from small bits of programming, to video outlines, to hints about solving assignments.  The project has contributed support to 5 PhD students and 4 masters students at MIT, and work associated with the project has produced at least 19 research papers and 7 theses, and at least 8 software systems that are available as open source.       Last Modified: 11/30/2015       Submitted by: Robert C Miller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
