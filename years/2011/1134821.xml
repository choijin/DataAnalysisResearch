<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Center: I/UCRC in Center for Energy-Smart Electronic Systems (ES2)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
<AwardExpirationDate>11/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>275000.00</AwardTotalIntnAmount>
<AwardAmount>293000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Andre Marshall</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Full Proposal for an I/UCRC for Energy Efficient Electronic Systems &lt;br/&gt;&lt;br/&gt;1134867 SUNY at Binghamton; Baghat Sammakia &lt;br/&gt;1134810 Villanova University; Alfonso Ortega &lt;br/&gt;1134821 University of Texas-Arlington; Dereje Agonafer &lt;br/&gt;&lt;br/&gt;The Center for Energy Efficient Electronic Systems will focus on optimizing energy utilization in electronic systems. SUNY at Binghamton, Villanova University and the University of Texas at Arlington are collaborating to establish the proposed center, with SUNY at Binghamton as the lead institution &lt;br/&gt;&lt;br/&gt;The proposed center will focus on the development of systematic methodologies for operating electronic systems, including data centers, as dynamic self sensing and regulating systems that are predictive and verified in real time. Algorithms will be developed to control cooling resources and to assist expert system schedulers to schedule and/or migrate workload to achieve optimal energy consumption. Thermal management resources will also be allocated dynamically in response to system needs. Problem-oriented research related to Thermal Management Protocols, Software Systems, Control Systems, and Implementation and Assessment, will be addressed during the Center's first five year program. &lt;br/&gt;&lt;br/&gt;The proposed center will enable a significant reduction in energy consumption in electronic systems, including data centers, thereby potentially reducing electrical power consumption across the nation. This will, in turn, reduce the nations consumption of carbon-based fuels and related emissions. The center will attract a diverse group of students at the undergraduate and graduate levels, by providing industrially-relevant training required by graduates entering the workforce. The proposed center is committed to attracting talented and motivated students from all groups, and will integrate a variety of mechanisms across the partners, including enhancement of existing minority pipeline programs to exceed participation by women and under-represented students. The center also intends to leverage existing programming on its campuses to engage K-12 students in conversation on energy conservation.</AbstractNarration>
<MinAmdLetterDate>08/09/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/26/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1134821</AwardID>
<Investigator>
<FirstName>Dereje</FirstName>
<LastName>Agonafer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dereje Agonafer</PI_FULL_NAME>
<EmailAddress>agonafer@uta.edu</EmailAddress>
<PI_PHON>8172727377</PI_PHON>
<NSF_ID>000417235</NSF_ID>
<StartDate>08/09/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Arlington</Name>
<CityName>Arlington</CityName>
<ZipCode>760190145</ZipCode>
<PhoneNumber>8172722105</PhoneNumber>
<StreetAddress>701 S Nedderman Dr, Box 19145</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>064234610</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT ARLINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Arlington]]></Name>
<CityName/>
<StateCode>TX</StateCode>
<ZipCode>760190145</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5761</Code>
<Text>IUCRC-Indust-Univ Coop Res Ctr</Text>
</ProgramElement>
<ProgramReference>
<Code>116E</Code>
<Text>RESEARCH EXP FOR UNDERGRADS</Text>
</ProgramReference>
<ProgramReference>
<Code>5761</Code>
<Text>INDUSTRY/UNIV COOP RES CENTERS</Text>
</ProgramReference>
<ProgramReference>
<Code>8040</Code>
<Text>Energy and Environment</Text>
</ProgramReference>
<ProgramReference>
<Code>8808</Code>
<Text>Veterans Research Supplements</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~55000</FUND_OBLG>
<FUND_OBLG>2012~55000</FUND_OBLG>
<FUND_OBLG>2013~65000</FUND_OBLG>
<FUND_OBLG>2014~55000</FUND_OBLG>
<FUND_OBLG>2015~55000</FUND_OBLG>
<FUND_OBLG>2016~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Direct and Indirect Evaporative Cooling of IT Pods: </strong>Evaporative cooling is an alternative data center cooling solution that presents significant energy cost savings in acquisition and operation when compared to conventional air conditioning and mechanical refrigeration systems. The goal of this project is to develop a comprehensive guide to assess and contrast different approaches of evaporative cooling being used in data center cooling and provide guidance in improving water and energy efficiency. University of Texas at Arlington established a research modular data center with a direct/indirect evaporative cooling module at the facility of industrial partner, Mestex, in Dallas, TX. The research facility is operated and monitored all year round in the hot and humid Dallas climate using only evaporative cooling or outside air free cooling. The year-around monitoring, development of Computational Fluid Dynamics (CFD) models of IT (Information Technology) Pod and Cooling module, development of Artificial Neural Network models for proactive cooling has enabled assessment of Direct and Indirect Evaporative Cooling in modular data centers. The outcome of research studies in this project serves to develop deeper understanding in implementing, operating and maintaining evaporative cooling systems integrated with air-side economization to realize the energy and water savings potential in data center cooling.</p> <p>As an extension of this project,&nbsp;condensation phenomenon has been studied experimentally and computationally. This study allows for determination of acclimation period of new IT equipment, transported in extreme climate conditions, to in situ data center conditions.</p> <p>&nbsp;</p> <p><strong>Computational and Experimental Models in Design of Dynamic, Energy Efficient Cooling Solutions for High-Power Data Center and Telecommunication Facilities: </strong>Dynamic cold plates are designed to have sections isolated from each other to cool multichip scale modules. To reduce pumping power for liquid cooling, dynamic cold plates can distribute flow between various sections within the cold plate based on cooling requirement in each section of the module. Each section of the cold plate has a dedicated flow control device, that can sense temperature and regulate flow rate accordingly. The major goals of the project are to design reliable dynamic cold plate with flow control devices and experimentally validate for its performance.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As a part of the project a control scheme was introduced using LabVIEW and static vs. dynamic cold plate designs were tested. The experimental results were compared for both the cases in terms of pumping power and temperature gradient savings. The proof of concept has been completely established for cooling individual sections of cold plate and address the non-uniform temperature distribution in high power electronics. A total of 28.3% savings in pumping power (across the cold plate set up) and 52.36% of temperature gradient savings across the MCM TTV has been observed. Now we are working on the smart Flow control device that can regulates the flow with respect to temperature. Miniaturization of Flow control device with dynamic cold plate gives the smart cold plate that saves the pumping power and&nbsp;provides&nbsp;energy efficient cooling.</p> <p>&nbsp;</p> <p><strong>Impacts of Particulate and Gaseous Contamination on IT equipment Where Air-Side Economizers Are Implemented: </strong>Air side economization is commonly used in the data centers by using outside air could be used to cool IT equipment directly without any air conditioning. Depending on the geography and the climate, the particulate and gaseous contaminants would be present in the air that enters the data center. The goal of this project is to determine the negative impacts of particulate and gaseous contamination on IT equipment where air-side economizers are implemented. Airflow patterns and flow path of contaminants in a high-density data center is analyzed to find the most vulnerable locations. In this study, methods to mitigate corrosion problem and to make IT equipment more robust were studied and their limitations were estimated.</p> <p><strong>&nbsp;</strong></p> <p><strong>An In-Depth Understanding of Oil Immersion Cooling Strategies for Data Centers: </strong>Complete immersion of servers in electrically nonconductive oil has recently become a promising technique for minimizing cooling energy consumption in data centers. However, a lack of sufficient published data and long-term reliability documentation on oil cooling makes most data center operators hesitant to apply these approaches to their mission critical facilities. The study and understanding goals of this proposal can be broken into two primary areas:</p> <ol> <li>The cooling efficiency of oil immersed ITE: This allows for study of the dynamic heating and cooling patterns of the bulk fluid, thermal runaway times, and implications on the efficiency of an entire facility.</li> <li>The operational efficiency (overall life cycle of oil, reliability of components, and serviceability) of an oil cooled data center: A life cycle analysis of the oil including its evaporation rates, contamination issues, dielectric breakdown, and impact on system components (pumps, PCBs, ICs, system mechanical components, etc.) will help establish the operational issues that must be addressed to successfully run and manage an oil cooled data center. </li> </ol> <p>&nbsp;</p><br> <p>            Last Modified: 03/11/2018<br>      Modified by: Dereje&nbsp;Agonafer</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Direct and Indirect Evaporative Cooling of IT Pods: Evaporative cooling is an alternative data center cooling solution that presents significant energy cost savings in acquisition and operation when compared to conventional air conditioning and mechanical refrigeration systems. The goal of this project is to develop a comprehensive guide to assess and contrast different approaches of evaporative cooling being used in data center cooling and provide guidance in improving water and energy efficiency. University of Texas at Arlington established a research modular data center with a direct/indirect evaporative cooling module at the facility of industrial partner, Mestex, in Dallas, TX. The research facility is operated and monitored all year round in the hot and humid Dallas climate using only evaporative cooling or outside air free cooling. The year-around monitoring, development of Computational Fluid Dynamics (CFD) models of IT (Information Technology) Pod and Cooling module, development of Artificial Neural Network models for proactive cooling has enabled assessment of Direct and Indirect Evaporative Cooling in modular data centers. The outcome of research studies in this project serves to develop deeper understanding in implementing, operating and maintaining evaporative cooling systems integrated with air-side economization to realize the energy and water savings potential in data center cooling.  As an extension of this project, condensation phenomenon has been studied experimentally and computationally. This study allows for determination of acclimation period of new IT equipment, transported in extreme climate conditions, to in situ data center conditions.     Computational and Experimental Models in Design of Dynamic, Energy Efficient Cooling Solutions for High-Power Data Center and Telecommunication Facilities: Dynamic cold plates are designed to have sections isolated from each other to cool multichip scale modules. To reduce pumping power for liquid cooling, dynamic cold plates can distribute flow between various sections within the cold plate based on cooling requirement in each section of the module. Each section of the cold plate has a dedicated flow control device, that can sense temperature and regulate flow rate accordingly. The major goals of the project are to design reliable dynamic cold plate with flow control devices and experimentally validate for its performance.            As a part of the project a control scheme was introduced using LabVIEW and static vs. dynamic cold plate designs were tested. The experimental results were compared for both the cases in terms of pumping power and temperature gradient savings. The proof of concept has been completely established for cooling individual sections of cold plate and address the non-uniform temperature distribution in high power electronics. A total of 28.3% savings in pumping power (across the cold plate set up) and 52.36% of temperature gradient savings across the MCM TTV has been observed. Now we are working on the smart Flow control device that can regulates the flow with respect to temperature. Miniaturization of Flow control device with dynamic cold plate gives the smart cold plate that saves the pumping power and provides energy efficient cooling.     Impacts of Particulate and Gaseous Contamination on IT equipment Where Air-Side Economizers Are Implemented: Air side economization is commonly used in the data centers by using outside air could be used to cool IT equipment directly without any air conditioning. Depending on the geography and the climate, the particulate and gaseous contaminants would be present in the air that enters the data center. The goal of this project is to determine the negative impacts of particulate and gaseous contamination on IT equipment where air-side economizers are implemented. Airflow patterns and flow path of contaminants in a high-density data center is analyzed to find the most vulnerable locations. In this study, methods to mitigate corrosion problem and to make IT equipment more robust were studied and their limitations were estimated.     An In-Depth Understanding of Oil Immersion Cooling Strategies for Data Centers: Complete immersion of servers in electrically nonconductive oil has recently become a promising technique for minimizing cooling energy consumption in data centers. However, a lack of sufficient published data and long-term reliability documentation on oil cooling makes most data center operators hesitant to apply these approaches to their mission critical facilities. The study and understanding goals of this proposal can be broken into two primary areas:  The cooling efficiency of oil immersed ITE: This allows for study of the dynamic heating and cooling patterns of the bulk fluid, thermal runaway times, and implications on the efficiency of an entire facility. The operational efficiency (overall life cycle of oil, reliability of components, and serviceability) of an oil cooled data center: A life cycle analysis of the oil including its evaporation rates, contamination issues, dielectric breakdown, and impact on system components (pumps, PCBs, ICs, system mechanical components, etc.) will help establish the operational issues that must be addressed to successfully run and manage an oil cooled data center.            Last Modified: 03/11/2018       Submitted by: Dereje Agonafer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
