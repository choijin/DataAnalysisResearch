<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: A General Ethical Dilemma Analyzer</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>66061.00</AwardTotalIntnAmount>
<AwardAmount>76243</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Systems that are capable of producing change in the environment require particular attention to the ethical ramifications of their behavior.  The determination and mitigation of the ethical concerns of such systems has to date been charged to their designers and has largely been accomplished by simply preventing systems from engaging in ethically unacceptable behavior in a predetermined, ad hoc manner, which can unnecessarily constrain the set of possible behaviors.  Although this may have been considered "best practice" in the past, the coupling of computational intelligence to such systems is likely to provide better options.  This is especially true of autonomous systems, which not only produce change in the environment but are capable of monitoring this environment to determine the effect of their actions as well as what the next action should be.  Ethical questions concerning the behavior of such complex and dynamic systems are likely to exceed the grasp of their designers and elude simple static solutions.  Autonomous systems will therefore need tools and methodologies to help codify ethical principles pertinent to their behavior, principles which form the basis for the autonomous selection and justification of ethically preferable actions.&lt;br/&gt;&lt;br/&gt;In this research, the PI and his team will develop and implement a general methodology for the discovery of ethical principles, abstracted from their previous work, which incrementally constructs representations that characterize ethical dilemmas and discovers decision principles necessary to resolve them.  They will use this system to codify representation schemes and principles of ethical decision-making in domains that are of particular significance to autonomous systems in their interaction with human beings.  And they will evaluate the discovered representations and principles through independent consultation.  The PI expects project outcomes will provide evidence that ethical principles and decision-making can be computed and function effectively in domains where machines are likely to interact with human beings.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  This research will lay the foundations for providing autonomous systems across multiple domains with the principles required to choose the most ethically correct actions and justify these choices.   Thus, the work should alleviate concerns with autonomous systems and bolster society's support for their development in a wide range of domains.  An important by-product of the research is that breakthroughs in ethical theory are likely to result as representations and principles for resolving ethical dilemmas are discovered.</AbstractNarration>
<MinAmdLetterDate>08/20/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/12/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1151305</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Anderson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael Anderson</PI_FULL_NAME>
<EmailAddress>anderson@hartford.edu</EmailAddress>
<PI_PHON>8607684917</PI_PHON>
<NSF_ID>000111559</NSF_ID>
<StartDate>08/20/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Hartford</Name>
<CityName>West Hartford</CityName>
<ZipCode>061171545</ZipCode>
<PhoneNumber>8607685938</PhoneNumber>
<StreetAddress>200 Bloomfield Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>069264398</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF HARTFORD, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>069264398</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Hartford]]></Name>
<CityName/>
<StateCode>CT</StateCode>
<ZipCode>061171599</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~66061</FUND_OBLG>
<FUND_OBLG>2013~10182</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Systems that interact with human beings require particular attention to the ethical ramifications of their behavior.&nbsp; A profusion of such systems is on the verge of being widely deployed in a variety of domains (e.g. personal assistance, healthcare, driverless cars, search and rescue, etc.).&nbsp; That these interactions will be charged with ethical significance should be self-evident and, clearly, these systems will be expected to navigate this ethically charged landscape responsibly. As correct ethical behavior not only involves <em>not doing</em> certain things, but also <em>doing</em> certain things to bring about ideal states of affairs, ethical issues concerning the behavior of such complex and dynamic systems are likely to exceed the grasp of their designers and elude simple, static solutions. To date, the determination and mitigation of the ethical concerns of such systems has largely been accomplished by simply preventing systems from engaging in ethically unacceptable behavior in a predetermined, ad hoc manner, often unnecessarily constraining the system's set of possible behaviors and domains of deployment.&nbsp; We assert that the behavior of such systems should be guided by explicitly represented ethical principles determined through a consensus of ethicists.&nbsp; Principles are comprehensive and comprehensible declarative abstractions that succinctly represent this consensus in a centralized, extensible, and auditable way.&nbsp; Systems guided by such principles are likely to behave in a more acceptably ethical manner, permitting a richer set of behaviors in a wider range of domains than systems not so guided.</p> <p>&nbsp;&nbsp; We contend that even some of the most basic system actions have an ethical dimension.&nbsp; For instance, simply choosing a fully awake state over a sleep state consumes more energy and shortens the lifespan of a system. Given this, to help ensure ethical behavior, a system&rsquo;s set of possible ethically significant actions should be weighed against each other to determine which is the most ethically preferable at any given moment. It is likely that ethical action preference of a large set of actions will be difficult or impossible to define as an exhaustive list of instances and instead will need to be defined in the form of rules. This more concise definition is possible since action preference is only dependent upon a likely smaller set of ethically relevant features that actions involve. Given this, action preference can be more succinctly stated in terms of satisfaction or violation of duties to either minimize or maximize (as appropriate) each ethically relevant feature. We refer to an action preference rule as a principle.&nbsp; Principles have the further benefit of helping justify a system&rsquo;s actions as they can provide pointed, logical explanations as to why one action was chosen over another.</p> <p>&nbsp;&nbsp; Although it may be fruitful to develop ethical principles for the guidance of autonomous machine behavior, it is a complex process that involves determining what the ethical dilemmas are in terms of ethically relevant features, which duties need to be considered, and how to weigh them when they pull in different directions. To help contend with this complexity, we have developed GenEth, a general ethical dilemma analyzer that, through a dialog with ethicists, helps codify ethical principles from specific cases of ethical dilemmas in any given domain.&nbsp; GenEth uses machine learning to infer a principle of ethical action preference from these cases that is complete and consistent in relation to them.&nbsp; As the principles discovered are <em>most general specializations</em>, they cover more cases than those used in their specialization and, therefore, are able to be used to make and justify provisional determinations about untested cases. These cases also provide a further means of justifi...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Systems that interact with human beings require particular attention to the ethical ramifications of their behavior.  A profusion of such systems is on the verge of being widely deployed in a variety of domains (e.g. personal assistance, healthcare, driverless cars, search and rescue, etc.).  That these interactions will be charged with ethical significance should be self-evident and, clearly, these systems will be expected to navigate this ethically charged landscape responsibly. As correct ethical behavior not only involves not doing certain things, but also doing certain things to bring about ideal states of affairs, ethical issues concerning the behavior of such complex and dynamic systems are likely to exceed the grasp of their designers and elude simple, static solutions. To date, the determination and mitigation of the ethical concerns of such systems has largely been accomplished by simply preventing systems from engaging in ethically unacceptable behavior in a predetermined, ad hoc manner, often unnecessarily constraining the system's set of possible behaviors and domains of deployment.  We assert that the behavior of such systems should be guided by explicitly represented ethical principles determined through a consensus of ethicists.  Principles are comprehensive and comprehensible declarative abstractions that succinctly represent this consensus in a centralized, extensible, and auditable way.  Systems guided by such principles are likely to behave in a more acceptably ethical manner, permitting a richer set of behaviors in a wider range of domains than systems not so guided.     We contend that even some of the most basic system actions have an ethical dimension.  For instance, simply choosing a fully awake state over a sleep state consumes more energy and shortens the lifespan of a system. Given this, to help ensure ethical behavior, a systemÆs set of possible ethically significant actions should be weighed against each other to determine which is the most ethically preferable at any given moment. It is likely that ethical action preference of a large set of actions will be difficult or impossible to define as an exhaustive list of instances and instead will need to be defined in the form of rules. This more concise definition is possible since action preference is only dependent upon a likely smaller set of ethically relevant features that actions involve. Given this, action preference can be more succinctly stated in terms of satisfaction or violation of duties to either minimize or maximize (as appropriate) each ethically relevant feature. We refer to an action preference rule as a principle.  Principles have the further benefit of helping justify a systemÆs actions as they can provide pointed, logical explanations as to why one action was chosen over another.     Although it may be fruitful to develop ethical principles for the guidance of autonomous machine behavior, it is a complex process that involves determining what the ethical dilemmas are in terms of ethically relevant features, which duties need to be considered, and how to weigh them when they pull in different directions. To help contend with this complexity, we have developed GenEth, a general ethical dilemma analyzer that, through a dialog with ethicists, helps codify ethical principles from specific cases of ethical dilemmas in any given domain.  GenEth uses machine learning to infer a principle of ethical action preference from these cases that is complete and consistent in relation to them.  As the principles discovered are most general specializations, they cover more cases than those used in their specialization and, therefore, are able to be used to make and justify provisional determinations about untested cases. These cases also provide a further means of justification for a systemÆs actions through analogy.  We have used GenEth to discover principles using cases of ethical dilemmas that might be faced by autonomous machines interacting ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
