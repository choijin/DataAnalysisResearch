<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CGV: Small: Collaborative Research: AdaCID: Adaptive Coded Imaging and Displays</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This is a collaborative project leveraging expertise of Ashok Veeraraghavan, William Marsh Rice University (IIS-1116718) and Ramesh Raskar, Massachusetts Institute of Technology (IIS-1116452).  Imaging and display devices are all around us and are used in a variety of applications. The spatial resolution, depth range, depth resolution, temporal resolution, frame-rate and bandwidth of these devices are usually fixed a priori. When the resolution and other properties of the content being imaged or displayed does not exactly mimic those that were assumed a priori, this leads to inefficiencies (in utilizing available resources) and undesirable artifacts (aliasing, blurring and noise). Since both imaging and display devices are fast becoming multi-purpose, there is a need to develop imaging and display architectures (and algorithms) that are capable of adapting their resolution and bandwidth characteristics to match those of the content.&lt;br/&gt;&lt;br/&gt;The goal of this project is to develop imaging and display devices that adapt to scene, motion, geometry, viewer, or illumination conditions. Such adaptive devices lead to performance improvements and novel capabilities hitherto unexplored. This research agenda is organized into four intellectual thrusts: (1) the establishment a theoretical framework for Adaptive Coded Imaging and Displays (AdaCID) that enables efficient exploration of the space of designs (2) the design of adaptive coded imaging systems that adapt to scene geometry, motion, and illumination (3) the design of adaptive and interactive coded 2D/3D displays that adapt in real-time to content, viewer position, and the human visual system enhancing visual appearance and allowing intuitive 3D interaction and (4) the demonstration of coded feedback projector-camera systems enabling rapid acquisition of range and material characteristics.&lt;br/&gt;&lt;br/&gt;It is expected that AdaCID will have far-reaching impact to diverse applications spanning consumer imaging and displays, machine vision and automation, scientific/medical imaging and displays and surveillance. Since AdaCID and the broader field of computational imaging and displays is increasingly important, they will be integrated into various courses offered at Rice University and MIT. Broad dissemination of the educational material will be achieved through participation in the free, open-licensed Connexions program and OpenCourseWare and in public-domain museum initiatives (at the MIT Museum). This project also offers collaborative research opportunities for students at the two institutions. Project Website (http://cameraculture.media.mit.edu/AdaCID/) provides additional information.</AbstractNarration>
<MinAmdLetterDate>08/06/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116718</AwardID>
<Investigator>
<FirstName>Ashok</FirstName>
<LastName>Veeraraghavan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ashok Veeraraghavan</PI_FULL_NAME>
<EmailAddress>Ashok.Veeraraghavan@gmail.com</EmailAddress>
<PI_PHON>7133484820</PI_PHON>
<NSF_ID>000583333</NSF_ID>
<StartDate>08/06/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>William Marsh Rice University</Name>
<CityName>Houston</CityName>
<ZipCode>770051827</ZipCode>
<PhoneNumber>7133484820</PhoneNumber>
<StreetAddress>6100 MAIN ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>050299031</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WILLIAM MARSH RICE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>050299031</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[William Marsh Rice University]]></Name>
<CityName>Houston</CityName>
<StateCode>TX</StateCode>
<ZipCode>770051827</ZipCode>
<StreetAddress><![CDATA[6100 MAIN ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Adaptive methods influenced by control theory and information theory can dramatically improve and enlarge today&rsquo;s imaging and display platforms achieving capabilities that cannot be achieved with today&rsquo;s passive approaches. The transition from film to digital has so far been about convenience and programmability but the remarkable optical, computational flexibility available today means that real-time adaptation is now within reach. Imaging and display devices that rapidly adapt to scene, motion, geometry, viewer, or illumination conditions will result both in performance improvements and in new and novel capabilities hitherto unexplored. In this project, we focused on the development of new theory that: (1) unifies existing, non-adaptive coded imaging and displays (CID), (2) characterizes the benefits of such adaptation, and (3) derives fundamental limits of coded imaging and displays (AdaCID).</p> <p>We developed a unified theory and practical designs for Computational Imaging and Displays that was based on the framework of Gaussian Mixture Models. Gaussian Mixture Models are powerful tools for deriving these bounds since they simultaneously allow for universal approximability and analytical tractability. We established a theoretical framework for AdaCID using signal and device representations that enable analysis and design. We demonstrated several examples of coded imaging systems (compressive sensing cameras, high speed cameras, short-wave infra-red cameras, and light-field cameras) that adapt to scene geometry, motion, and illumination to maximize information throughput. We designed and demonstrated several examples of display devices (3D displays, light-field displays, interactive displays, adaptive displays etc) to enhance visual appearance and allow intuitive 3D interaction. Finally, we also demonstrated coded feedback projector-camera systems for rapid acquisition of range and material characteristics. We believe that our results lay some of the foundations to understand and characterize coded imaging and display systems and these systems will lead to orders of magnitude performance improvements and new abilities in imaging and displays.</p> <p><strong>Broader Impact: </strong>This project has far-reaching impact to diverse applications spanning consumer imaging and displays, machine vision and automation, scientific/medical imaging and displays, robotic surgery, and surveillance and remote sensing. We have several ongoing collaborations in these areas and have utilized these collaborations to increase the immediate impact of the research outcomes to these areas. This project has directly or indirectly led to the PIS filing several invention disclosures and preliminary patent filings. We have integrated the research outcomes of this project into various vision and imaging courses offered at Rice University and MIT. We have involved more than 6 undergraduate students as summer researchers in various efforts related to this project. We have also conducted several workshops, short courses and tutorials in premier conferences such as CVPR, ICCV and SIGGRAPH and disseminated the research results broadly through these workshops and tutorials.</p><br> <p>            Last Modified: 10/22/2015<br>      Modified by: Ashok&nbsp;Veeraraghavan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Adaptive methods influenced by control theory and information theory can dramatically improve and enlarge todayÆs imaging and display platforms achieving capabilities that cannot be achieved with todayÆs passive approaches. The transition from film to digital has so far been about convenience and programmability but the remarkable optical, computational flexibility available today means that real-time adaptation is now within reach. Imaging and display devices that rapidly adapt to scene, motion, geometry, viewer, or illumination conditions will result both in performance improvements and in new and novel capabilities hitherto unexplored. In this project, we focused on the development of new theory that: (1) unifies existing, non-adaptive coded imaging and displays (CID), (2) characterizes the benefits of such adaptation, and (3) derives fundamental limits of coded imaging and displays (AdaCID).  We developed a unified theory and practical designs for Computational Imaging and Displays that was based on the framework of Gaussian Mixture Models. Gaussian Mixture Models are powerful tools for deriving these bounds since they simultaneously allow for universal approximability and analytical tractability. We established a theoretical framework for AdaCID using signal and device representations that enable analysis and design. We demonstrated several examples of coded imaging systems (compressive sensing cameras, high speed cameras, short-wave infra-red cameras, and light-field cameras) that adapt to scene geometry, motion, and illumination to maximize information throughput. We designed and demonstrated several examples of display devices (3D displays, light-field displays, interactive displays, adaptive displays etc) to enhance visual appearance and allow intuitive 3D interaction. Finally, we also demonstrated coded feedback projector-camera systems for rapid acquisition of range and material characteristics. We believe that our results lay some of the foundations to understand and characterize coded imaging and display systems and these systems will lead to orders of magnitude performance improvements and new abilities in imaging and displays.  Broader Impact: This project has far-reaching impact to diverse applications spanning consumer imaging and displays, machine vision and automation, scientific/medical imaging and displays, robotic surgery, and surveillance and remote sensing. We have several ongoing collaborations in these areas and have utilized these collaborations to increase the immediate impact of the research outcomes to these areas. This project has directly or indirectly led to the PIS filing several invention disclosures and preliminary patent filings. We have integrated the research outcomes of this project into various vision and imaging courses offered at Rice University and MIT. We have involved more than 6 undergraduate students as summer researchers in various efforts related to this project. We have also conducted several workshops, short courses and tutorials in premier conferences such as CVPR, ICCV and SIGGRAPH and disseminated the research results broadly through these workshops and tutorials.       Last Modified: 10/22/2015       Submitted by: Ashok Veeraraghavan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
