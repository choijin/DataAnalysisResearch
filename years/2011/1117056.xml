<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Collaborative Research: Entropy Rate for Source Separation and Model Selection: Applications in fMRI and EEG Analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>334180.00</AwardTotalIntnAmount>
<AwardAmount>334180</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Blind source separation (BSS) has found wide use in many disciplines including signal processing as it starts from a simple generative model minimizing assumptions on the data generation mechanism and achieves useful decompositions of the observed data. In particular, independent component analysis (ICA) has been the most commonly used approach to achieve BSS since statistical independence of the underlying components is plausible in many applications. Besides independence, sample correlation is another inherent property of many signals of interest. Traditionally, these two properties are addressed separately when developing methods for source separation. Entropy rate, on the other hand, is a natural cost that allows one to account for independence and sample correlation jointly, and hence promises to result in a new class of powerful solutions with wide applicability. In addition, it enables one to easily incorporate model selection---another key problem complementing the power of BSS---into the problem through the use of information theoretic criteria.&lt;br/&gt;&lt;br/&gt;The focus of this research is the development of a class of powerful methods for source separation and model selection using entropy rate so that one can take both the higher-order-statistical information and sample correlation into account to achieve significant performance gains in more challenging problems. The main application domain is one that can truly take advantage of this fully combined approach: the analysis of functional magnetic resonance (fMRI) data and the rejection of gradient and pulse artifacts in electroencephalography (EEG) in concurrent EEG-fMRI data. Both are applications that have proven challenging for the traditional model-based approach due to the unique nature of the noise and artifacts in these problems. Hence, they provide a unique testbed for the performance evaluation of the new class of methods developed under this study. Since independence and sample correlation are intrinsic properties of many other types of data, the new set of methods will be attractive solutions for many other problems as well.</AbstractNarration>
<MinAmdLetterDate>07/19/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1117056</AwardID>
<Investigator>
<FirstName>Tulay</FirstName>
<LastName>Adali</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tulay Adali</PI_FULL_NAME>
<EmailAddress>adali@umbc.edu</EmailAddress>
<PI_PHON>4104553521</PI_PHON>
<NSF_ID>000251838</NSF_ID>
<StartDate>07/19/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland Baltimore County</Name>
<CityName>Baltimore</CityName>
<ZipCode>212500002</ZipCode>
<PhoneNumber>4104553140</PhoneNumber>
<StreetAddress>1000 Hilltop Circle</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>061364808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND BALTIMORE COUNTY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland Baltimore County]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212500002</ZipCode>
<StreetAddress><![CDATA[1000 Hilltop Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~334180</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Independent component analysis (ICA), the most popular method to achieve source separation, has found wide use in many disciplines including signal processing. This is due to the fact that ICA starts from a simple generative model minimizing assumptions on the data and achieves useful decompositions of the observed data that can be used for various purposes including classification, artifact rejection, data fusion, object detection among many others. In order to achieve the decomposition of the data, ICA algorithms make use of a given statistical property (diversity), and the most commonly used type of diversity has been the non-Gaussianity of the signal, i.e., higher-order-statistics (HOS).</p> <p>&nbsp;</p> <p>However, most often a given set of observations/data possesses multiple statistical properties that can be jointly exploited. These include, for example, sample-to-sample correlation and nonstationarity besides the HOS. This is the case for medical imaging data such as functional magnetic resonance (fMRI) and electroencephalography (EEG) data, two key medical imaging modalities, which also define the main applications considered in the study.</p> <p>&nbsp;</p> <p>We developed a number of effective solutions for performing ICA by <em>jointly</em> accounting for multiple types of statistical property typically present in the data. An efficient entropy estimator is at the heart of these methods. We established the theory for the general linear unmixing problem that clearly shows how with the addition of each new type of diversity, performance of the algorithms improves and identification of the model becomes easier, i.e., a broader class of signals can be identified. The performance of the new algorithms are compared against the performance bounds that are established. In particular, the important trade-off in terms of model complexity&mdash;accounting for multiple types of diversity increases the complexity of the algorithm&mdash;and the performance is quantified depending on the properties of the signals. It is shown that available domain information can be effectively taken into account to establish the best balance in terms of accuracy, robustness, and complexity.</p> <p>&nbsp;</p> <p>With a number of practical examples in medical imaging, both for the analysis of fMRI data and for artifact rejection in EEG, it is shown that indeed important performance gains are possible by using these algorithms that jointly account for multiple statistical properties of the data.</p> <p>&nbsp;</p> <p>These results have been reported in 39 journal and 17 conference publications in major venues in our area, and led to one book and three PhD dissertations. Four of the journal publications are major overview papers in top venues in electrical engineering. Two of the overview papers appeared in the Proceedings of the IEEE (impact factor: 4.934 and top journal in Electrical Engineering in terms of Article Influence Score*), and two in the IEEE Signal Processing Magazine (impact factor: 4.481*) where the main results and complete overviews in source separation and data fusion are given along with future research discussions in the area.</p> <p>&nbsp;</p> <p>The results of the project have been also disseminated through a series of invited talks given by Dr. Adali&mdash;total of 68 invited talks delivered from January 2012 till August 2015 including Dr. Adali&rsquo;s term as an IEEE Signal Processing Society Distinguished Lecturer 2012&ndash;2013. Nine of these invited talks were major conference keynotes or tutorials. Dr. Adali received the 2012&ndash;2013 University System of Maryland Regents&rsquo; Award for Excellence in Research and was named a Distinguished University Professor in 2015. The work performed as part of this project has played an important role in these recognitions.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>The Fusion ICA Toolbox (FIT) and the Group ICA of fMRI Too...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Independent component analysis (ICA), the most popular method to achieve source separation, has found wide use in many disciplines including signal processing. This is due to the fact that ICA starts from a simple generative model minimizing assumptions on the data and achieves useful decompositions of the observed data that can be used for various purposes including classification, artifact rejection, data fusion, object detection among many others. In order to achieve the decomposition of the data, ICA algorithms make use of a given statistical property (diversity), and the most commonly used type of diversity has been the non-Gaussianity of the signal, i.e., higher-order-statistics (HOS).     However, most often a given set of observations/data possesses multiple statistical properties that can be jointly exploited. These include, for example, sample-to-sample correlation and nonstationarity besides the HOS. This is the case for medical imaging data such as functional magnetic resonance (fMRI) and electroencephalography (EEG) data, two key medical imaging modalities, which also define the main applications considered in the study.     We developed a number of effective solutions for performing ICA by jointly accounting for multiple types of statistical property typically present in the data. An efficient entropy estimator is at the heart of these methods. We established the theory for the general linear unmixing problem that clearly shows how with the addition of each new type of diversity, performance of the algorithms improves and identification of the model becomes easier, i.e., a broader class of signals can be identified. The performance of the new algorithms are compared against the performance bounds that are established. In particular, the important trade-off in terms of model complexity&mdash;accounting for multiple types of diversity increases the complexity of the algorithm&mdash;and the performance is quantified depending on the properties of the signals. It is shown that available domain information can be effectively taken into account to establish the best balance in terms of accuracy, robustness, and complexity.     With a number of practical examples in medical imaging, both for the analysis of fMRI data and for artifact rejection in EEG, it is shown that indeed important performance gains are possible by using these algorithms that jointly account for multiple statistical properties of the data.     These results have been reported in 39 journal and 17 conference publications in major venues in our area, and led to one book and three PhD dissertations. Four of the journal publications are major overview papers in top venues in electrical engineering. Two of the overview papers appeared in the Proceedings of the IEEE (impact factor: 4.934 and top journal in Electrical Engineering in terms of Article Influence Score*), and two in the IEEE Signal Processing Magazine (impact factor: 4.481*) where the main results and complete overviews in source separation and data fusion are given along with future research discussions in the area.     The results of the project have been also disseminated through a series of invited talks given by Dr. Adali&mdash;total of 68 invited talks delivered from January 2012 till August 2015 including Dr. AdaliÆs term as an IEEE Signal Processing Society Distinguished Lecturer 2012&ndash;2013. Nine of these invited talks were major conference keynotes or tutorials. Dr. Adali received the 2012&ndash;2013 University System of Maryland RegentsÆ Award for Excellence in Research and was named a Distinguished University Professor in 2015. The work performed as part of this project has played an important role in these recognitions.        The Fusion ICA Toolbox (FIT) and the Group ICA of fMRI Toolbox (GIFT) are two major efforts that enable the use of the methods we develop by the practitioners. These toolboxes disseminate the results of our project to a wider audience, in particular to t...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
