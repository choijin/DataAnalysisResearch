<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Communicative Efficiency and Adaptiveness in the Ideal Speaker</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2012</AwardEffectiveDate>
<AwardExpirationDate>12/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>519843.00</AwardTotalIntnAmount>
<AwardAmount>567843</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>D.  Langendoen</SignBlockName>
<PO_EMAI>dlangend@nsf.gov</PO_EMAI>
<PO_PHON>7032925088</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Human communication is typically robust even at high speeds. This suggests that both speakers and listeners efficiently deal with the uncertainty and noise inherent to perception, production, and the environment. This CAREER award investigates how the human brain accomplishes this. A mathematical model of efficient communication based on probability and information theory (the Ideal Speaker model) is tested against data from conversational speech. Specifically, the project investigates how the pronunciation of words in spontaneous speech depends on words' expected confusability in context, the cognitive load the speaker is under and the situational incentive for robust communication. The Ideal Speaker model also predicts that efficient communication with a particular interlocutor requires adaptation to that interlocutor, a prediction that the project tests in behavioral paradigms against task-oriented speech production. &lt;br/&gt;&lt;br/&gt;The project contributes to our understanding of how humans produce language, why language has the properties it has, and to what extent the neural systems underlying language production can adjust to different communicative task demands. These insights can contribute to the development of better automatic speech recognition systems (this project is limited to the evaluation of such systems). In addition, novel paradigms to gather large amounts of language data are developed that will dramatically cut research costs. Finally, training in the emerging field of computational psycholinguistics is provided to a broad international audience via summer schools and workshops. This will contribute to a new generation of multidisciplinary scientists working across traditional boundaries between computer science, linguistics, and cognitive psychology.</AbstractNarration>
<MinAmdLetterDate>12/22/2011</MinAmdLetterDate>
<MaxAmdLetterDate>12/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1150028</AwardID>
<Investigator>
<FirstName>T. Florian</FirstName>
<LastName>Jaeger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>T. Florian Jaeger</PI_FULL_NAME>
<EmailAddress>fjaeger@bcs.rochester.edu</EmailAddress>
<PI_PHON>5852763611</PI_PHON>
<NSF_ID>000497304</NSF_ID>
<StartDate>12/22/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146270268</ZipCode>
<StreetAddress><![CDATA[BCS, Meliora Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~111170</FUND_OBLG>
<FUND_OBLG>2013~111827</FUND_OBLG>
<FUND_OBLG>2014~111197</FUND_OBLG>
<FUND_OBLG>2015~113802</FUND_OBLG>
<FUND_OBLG>2016~111847</FUND_OBLG>
<FUND_OBLG>2017~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.0px Helvetica} --> <p class="p1">Conversational speech often proceeds at speeds of muiltiple words per second. On the speaker's side, this requires the translation of thought into dozens of complex coordination of articulatory movements (lips, tongue, etc.) every second. On the listeners side, it requires inferring the intended meaning from an acoustic signal that is perturbed by noise.&nbsp;&nbsp;</p> <p class="p1">This CAREER award investigated the computational principles that allow the human brain to achieve efficient communication. Phase 1 of the project found that human language is organized so that the amount of information (bits) transmitted at each moment seems to be balanced against the amount and quality of the signal. This was documented for multiple levels of linguistic representations. Phase 2 identified two sources for this trade-off. First, the mechanisms underlying language production seem to be adaptive: even articulatory movements that are organized and executed within fractions of a second seem to be adjusted based on whether the speaker was understood or not. Second, a bias towards more efficient communicative systems is evident during language learning: when adult learners of a new language had to acquire a new language with inefficiencies in the lab, they tend to subtly change the language towards a more efficient system. All results were shared with other scientists and the public through conferences and journal publications. Additionally, most of the data gathered and methods developed as part of the project--including several novel web-based crowdsourcing paradigms for the collection of speech data--were made freely available.</p> <p class="p1">Throughout all phases of this project, training in advanced computational and statistical techniques was provided to undergraduate and graduate students. Similar training was also provided to the broader scientific community through tutorials, workshops, email lists, and a blog.&nbsp;</p><br> <p>            Last Modified: 01/07/2018<br>      Modified by: T. Florian&nbsp;Jaeger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Conversational speech often proceeds at speeds of muiltiple words per second. On the speaker's side, this requires the translation of thought into dozens of complex coordination of articulatory movements (lips, tongue, etc.) every second. On the listeners side, it requires inferring the intended meaning from an acoustic signal that is perturbed by noise.   This CAREER award investigated the computational principles that allow the human brain to achieve efficient communication. Phase 1 of the project found that human language is organized so that the amount of information (bits) transmitted at each moment seems to be balanced against the amount and quality of the signal. This was documented for multiple levels of linguistic representations. Phase 2 identified two sources for this trade-off. First, the mechanisms underlying language production seem to be adaptive: even articulatory movements that are organized and executed within fractions of a second seem to be adjusted based on whether the speaker was understood or not. Second, a bias towards more efficient communicative systems is evident during language learning: when adult learners of a new language had to acquire a new language with inefficiencies in the lab, they tend to subtly change the language towards a more efficient system. All results were shared with other scientists and the public through conferences and journal publications. Additionally, most of the data gathered and methods developed as part of the project--including several novel web-based crowdsourcing paradigms for the collection of speech data--were made freely available. Throughout all phases of this project, training in advanced computational and statistical techniques was provided to undergraduate and graduate students. Similar training was also provided to the broader scientific community through tutorials, workshops, email lists, and a blog.        Last Modified: 01/07/2018       Submitted by: T. Florian Jaeger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
