<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DIP: Collaborative Research: Mixed-Reality Labs: Integrating Sensors and Simulations to Improve Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2011</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>958439.00</AwardTotalIntnAmount>
<AwardAmount>958439</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kevin Lee</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This collaborative project is investigating the characteristics of a mixed-reality learning environment that combines the rich context and multi-sensory experiences of a physical lab with the interactive simulations of a virtual lab. The hybrid environment integrates sensors and simulations to bring out the advantages of each setting in a complementary way. The research team is developing four such mixed-reality laboratory experiences for secondary school level chemistry and physics courses and studying student learning in these contexts. Two of the activities use an integration strategy in which data acquired in real time from a physical experiment are used to control a virtual experiment. The advantage of this coupling is that abstract concepts or invisible processes can be visualized on the computer screen while the physical experiment is underway. Whenever the learner's hands-on interaction with the physical experiments changes the sensor measurement, the visualization in the virtual experiment responds accordingly, creating an intimate link between the two worlds. The other integration strategy uses physical and virtual experiments in parallel, challenging the student to match the results measured by the sensors and the results computed by the simulations. The learning potential in this configuration stems from the ability to go back and forth between both worlds, adjusting the virtual experiment to match the physical experiment and then adjusting the physical experiment to test the fidelity of the virtual experiment. Implementations of the four activities in eight classrooms are being compared to classes covering similar content. The intellectual merit of this project lies in its investigation of the potential of cyberlearning technologies to transform inquiry in the lab. In addition, the project brings to bear the expertise of a recognized team of researchers. The project is exercising its broader impacts through its identification of a new instructional approach to STEM education. The combination of physical and virtual labs carries the potential for broad utility, with the insights and examples developed by this project potentially applicable throughout STEM education. In fact, because all of the project software is open source and the materials made available freely from the project's website, the only expenses to schools are for the sensors. A key design criterion is that all project software is compatible with sensors from multiple vendors so that schools are not limited in their choices.</AbstractNarration>
<MinAmdLetterDate>09/01/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/10/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1124281</AwardID>
<Investigator>
<FirstName>Charles</FirstName>
<LastName>Xie</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Charles Xie</PI_FULL_NAME>
<EmailAddress>charles@intofuture.org</EmailAddress>
<PI_PHON>5083977021</PI_PHON>
<NSF_ID>000075350</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Edmund</FirstName>
<LastName>Hazzard</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edmund Hazzard</PI_FULL_NAME>
<EmailAddress>ehazzard@concord.org</EmailAddress>
<PI_PHON>9784053205</PI_PHON>
<NSF_ID>000587014</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate>06/10/2014</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Concord Consortium</Name>
<CityName>Concord</CityName>
<ZipCode>017422345</ZipCode>
<PhoneNumber>9784053205</PhoneNumber>
<StreetAddress>25 Love Lane</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>876728429</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CONCORD CONSORTIUM INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Concord Consortium]]></Name>
<CityName>Concord</CityName>
<StateCode>MA</StateCode>
<ZipCode>017422345</ZipCode>
<StreetAddress><![CDATA[25 Love Lane]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8842</Code>
<Text>Design and Implementation Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~958439</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Laboratory experiences are indisputably a fundamental part of science education. In order to understand the concepts at work in an experiment, students must place the data they collect into a conceptual framework. However, there is often a wide gap between the raw data and the abstract concepts under investigation. For example, to understand heat transfer measured by a thermometer, students must imagine the invisible flow of thermal energy; to understand air pressure measured by a barometer, they must imagine the collisions of gas molecules. In these cases, &ldquo;heat&rdquo; and &ldquo;molecules&rdquo; are the conceptual frameworks. A lab would have limited educational value if it could not bridge experimental data and the underlying concepts.</p> <p>The Mixed-Reality Labs Project set out to develop and research cyberlearning technologies and activities that narrow the gap between data and concepts. The project created technologies that seamlessly combine the visualization power of simulations and the investigation power of sensors to enhance the learner&rsquo;s perception of reality. Simultaneously supporting inquiries in both the virtual and physical worlds, this integrated approach transcends the limitations of real labs while retaining their tangibility to make learning physically relevant to students.</p> <p>The project invented the unique Frame technology based on the fact that the frame of a computer screen is the natural boundary between the virtual world and the physical world and is, therefore, an intuitive user interface for certain human-computer interactions. Compared with other interfaces, the Frame allows users to interact with the computer from the edges of the screen. By running a simulation in full screen mode, the data from sensors attached to the edge of the screen looks as though it's &ldquo;transmitted&rdquo; into the simulated scene in real time. For example, moving a hot object close to the Frame where there are temperature sensors creates an input to an ongoing heat transfer simulation, which then produces a visual effect as if heat could flow into the screen from the hot object. The Frame technology follows the typical way we conduct real experiments, namely, by allowing students to change variables in a system and observe how it responds to those changes. Unlike a real experiment, however, the inputs are applied to change a virtual system. Unlikea virtual experiment, the inputs come from the real world. Bridging the two worlds, the Frame takes advantage of learning opportunities in both worlds.</p> <p>The project also developed learning activities based on augmented-reality thermal imaging using the Multi Spectral Dynamic Imaging (MSX) technology developed by industry partner FLIR Systems. The technology blends visible light images from a conventional digital camera and invisible infrared light images from a thermal camera to create an augmented-reality view of the real world, allowing students to explore thermodynamics and heat transfer around them as if they acquired a sixth sense of thermal vision.</p><br> <p>            Last Modified: 01/04/2017<br>      Modified by: Charles&nbsp;Xie</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Laboratory experiences are indisputably a fundamental part of science education. In order to understand the concepts at work in an experiment, students must place the data they collect into a conceptual framework. However, there is often a wide gap between the raw data and the abstract concepts under investigation. For example, to understand heat transfer measured by a thermometer, students must imagine the invisible flow of thermal energy; to understand air pressure measured by a barometer, they must imagine the collisions of gas molecules. In these cases, "heat" and "molecules" are the conceptual frameworks. A lab would have limited educational value if it could not bridge experimental data and the underlying concepts.  The Mixed-Reality Labs Project set out to develop and research cyberlearning technologies and activities that narrow the gap between data and concepts. The project created technologies that seamlessly combine the visualization power of simulations and the investigation power of sensors to enhance the learner?s perception of reality. Simultaneously supporting inquiries in both the virtual and physical worlds, this integrated approach transcends the limitations of real labs while retaining their tangibility to make learning physically relevant to students.  The project invented the unique Frame technology based on the fact that the frame of a computer screen is the natural boundary between the virtual world and the physical world and is, therefore, an intuitive user interface for certain human-computer interactions. Compared with other interfaces, the Frame allows users to interact with the computer from the edges of the screen. By running a simulation in full screen mode, the data from sensors attached to the edge of the screen looks as though it's "transmitted" into the simulated scene in real time. For example, moving a hot object close to the Frame where there are temperature sensors creates an input to an ongoing heat transfer simulation, which then produces a visual effect as if heat could flow into the screen from the hot object. The Frame technology follows the typical way we conduct real experiments, namely, by allowing students to change variables in a system and observe how it responds to those changes. Unlike a real experiment, however, the inputs are applied to change a virtual system. Unlikea virtual experiment, the inputs come from the real world. Bridging the two worlds, the Frame takes advantage of learning opportunities in both worlds.  The project also developed learning activities based on augmented-reality thermal imaging using the Multi Spectral Dynamic Imaging (MSX) technology developed by industry partner FLIR Systems. The technology blends visible light images from a conventional digital camera and invisible infrared light images from a thermal camera to create an augmented-reality view of the real world, allowing students to explore thermodynamics and heat transfer around them as if they acquired a sixth sense of thermal vision.       Last Modified: 01/04/2017       Submitted by: Charles Xie]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
