<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Language Preservation 2.0: Crowdsourcing Oral Language Documentation using Mobile Devices</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>12/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>101501.00</AwardTotalIntnAmount>
<AwardAmount>101501</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Shobhana Chelliah</SignBlockName>
<PO_EMAI>schellia@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Language Preservation 2.0&lt;br/&gt;&lt;br/&gt;The purpose of this pilot project is to demonstrate the feasibility of a new approach to documenting endangered languages.&lt;br/&gt;&lt;br/&gt;To allow wide-ranging investigation of a language even after it is no longer spoken,  we need the equivalent of the million words of extant biblical Hebrew texts, or the five million words of extant classical Latin.  But for endangered languages without a significant culture of literacy, diverse text collections on this scale seem out of reach. &lt;br/&gt;&lt;br/&gt;Given typical speaking rates of about 10,000 word-equivalents per hour, a hundred hours of recorded speech -- conversations, narratives, or oral histories -- would give us the equivalent of a million words of text.  With community involvement, hundreds of hours of such recordings are easily within reach.&lt;br/&gt;&lt;br/&gt;However, transcribing such large audio collections is a daunting task, given the small number of literate native speakers and the time-consuming nature of such transcription, which can take 200 hours of work for every hour of audio. We propose to solve this problem by substituting re-speaking and verbal translation: one or more native speakers repeats each phrase of a recording, speaking slowly and carefully, and then translates it into a better-documented language.&lt;br/&gt;&lt;br/&gt;The utility of translated passages as a way to analyze otherwise-unknown languages has been demonstrated many times, starting with the Rosetta Stone.  This aspect of our task is easier, since at least a grammatical sketch will in general be available.  &lt;br/&gt;&lt;br/&gt;Our goal in this project is to demonstrate the utility of re-speaking. We believe that  linguists, starting out with relatively little knowledge of a language, can produce phonetic transcriptions that will be good enough to support subsequent analysis resulting in coherent texts, in a process analogous to (but easier than) the process that allowed previous generations of scholars to learn to read ancient Egyptian or Sumerian.</AbstractNarration>
<MinAmdLetterDate>06/18/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/18/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1160639</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Liberman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark Liberman</PI_FULL_NAME>
<EmailAddress>myl@unagi.cis.upenn.edu</EmailAddress>
<PI_PHON>2155735490</PI_PHON>
<NSF_ID>000118365</NSF_ID>
<StartDate>06/18/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Bird</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven G Bird</PI_FULL_NAME>
<EmailAddress>steven@icsi.berkeley.edu</EmailAddress>
<PI_PHON>5106662900</PI_PHON>
<NSF_ID>000210677</NSF_ID>
<StartDate>06/18/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<StreetAddress2><![CDATA[3451 Walnut St, 5th Flr Franklin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042250712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042250712</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Linguistic Data Consortium]]></Name>
<CityName>PHILADELPHIA</CityName>
<StateCode>PA</StateCode>
<ZipCode>191042653</ZipCode>
<StreetAddress><![CDATA[3600 MARKET ST STE 810]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7719</Code>
<Text>DEL</Text>
</ProgramElement>
<ProgramReference>
<Code>7719</Code>
<Text>DEL</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~101501</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Thousands of the world's languages are not adequately documented, and the languages are falling out of use more rapidly than linguists can record and transcribe them. This project investigated the problem of scaling up the language documentation effort through crowdsourcing, engaging the members of speech communities to record, respeak, and orally translate their linguistic heritage.</p> <p>The software, Aikuma, is available from aikuma.org, and won the Open Source Software World Challenge Grand Prize 2013. Field tests were conducted in Papua New Guinea, Brazil, and Nepal. Laboratory experiments demonstrated that the audio collected by the phones is of sufficient quality to support later scientific study.</p> <p>The project established an effective new way to avoid the usual transcription bottleneck which prevents linguists from transcribing more than a few hours of recordings for any language studied. Instead, the method relies on a protocol known as "careful respeaking", in which someone listens to a previously made recording and carefully repeats what was said, phrase by phrase. Aikuma permits the user to start respeaking at any stage during playback and records what was said, aligning it with the original source. Oral translation works in the same way. Accordingly, each source is associated with additional recordings that can be used by future linguists to perform their transcription and translation work, even once no speakers of the language remain.</p> <p>The app is being used in a variety of ongoing language documentation work, more effectively leveraging the human resources of local speech communities, and contributing significantly to the preservation of endangered languages.</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/19/2015<br>      Modified by: Steven&nbsp;G&nbsp;Bird</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390192840821_DSC_0488--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390192840821_DSC_0488--rgov-800width.jpg" title="Tembe Recording"><img src="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390192840821_DSC_0488--rgov-66x44.jpg" alt="Tembe Recording"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Recording Augustine Tembe recounting a story</div> <div class="imageCredit">Steven Bird</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Steven&nbsp;G&nbsp;Bird</div> <div class="imageTitle">Tembe Recording</div> </div> </li> <li> <a href="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390193089713_IMAG0250--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390193089713_IMAG0250--rgov-800width.jpg" title="Nhengatu transcription"><img src="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390193089713_IMAG0250--rgov-66x44.jpg" alt="Nhengatu transcription"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Transcribing Nhengatu narratives</div> <div class="imageCredit">Steven Bird</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Steven&nbsp;G&nbsp;Bird</div> <div class="imageTitle">Nhengatu transcription</div> </div> </li> <li> <a href="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390193337220_DSC_0139--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/1160639/1160639_10182220_1390193337220_DSC_0139--rgov-800width....]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Thousands of the world's languages are not adequately documented, and the languages are falling out of use more rapidly than linguists can record and transcribe them. This project investigated the problem of scaling up the language documentation effort through crowdsourcing, engaging the members of speech communities to record, respeak, and orally translate their linguistic heritage.  The software, Aikuma, is available from aikuma.org, and won the Open Source Software World Challenge Grand Prize 2013. Field tests were conducted in Papua New Guinea, Brazil, and Nepal. Laboratory experiments demonstrated that the audio collected by the phones is of sufficient quality to support later scientific study.  The project established an effective new way to avoid the usual transcription bottleneck which prevents linguists from transcribing more than a few hours of recordings for any language studied. Instead, the method relies on a protocol known as "careful respeaking", in which someone listens to a previously made recording and carefully repeats what was said, phrase by phrase. Aikuma permits the user to start respeaking at any stage during playback and records what was said, aligning it with the original source. Oral translation works in the same way. Accordingly, each source is associated with additional recordings that can be used by future linguists to perform their transcription and translation work, even once no speakers of the language remain.  The app is being used in a variety of ongoing language documentation work, more effectively leveraging the human resources of local speech communities, and contributing significantly to the preservation of endangered languages.          Last Modified: 05/19/2015       Submitted by: Steven G Bird]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
