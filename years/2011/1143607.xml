<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Coordinated Power and Thermal Management for Virtualized Data Centers: Algorithms, Framework, and Middleware</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
<AwardExpirationDate>01/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>395219.00</AwardTotalIntnAmount>
<AwardAmount>395219</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In recent years, power and thermal control has become one of the most serious concerns for large-scale data centers that are rapidly expanding the number of hosted servers. In addition to reducing operating costs, precisely controlling power consumption and heat dissipation is an essential way to avoid system failures caused by power capacity overload or overheating due to increasingly high server density (e.g., blade servers). Power and thermal control becomes even more challenging as many data centers start to adopt the virtualization technology for resource sharing, leading to increased utilization and power consumption. &lt;br/&gt;&lt;br/&gt;This CAREER project addresses the following research topics. 1) We plan to design and evaluate advanced power and thermal control algorithms, based on feedback control theory, to achieve analytic assurance of control accuracy and system stability. First, we propose novel control algorithms at multiple layers to control power and application performance for virtualized server environments. Second, we propose highly scalable hierarchical algorithms to control the power consumption of an entire large-scale data center. Third, we will design cascaded control algorithms to control heat dissipation and handle thermal emergencies by coordinating with power control loops. 2) We propose power and thermal control middleware. Our middleware will find the optimal coordination strategy for multiple control loops to work together at different layers, and then configure them to achieve the desired control functions. In addition, our middleware can automate the procedure of controller design and analysis for a universal control solution. 3) We will also investigate other components such as hard drives and network switches, as well as the controllability and feasibility problems, in order to provide a complete power and thermal control framework for today's large-scale data centers.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/17/2011</MinAmdLetterDate>
<MaxAmdLetterDate>04/11/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1143607</AwardID>
<Investigator>
<FirstName>Xiaorui</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaorui Wang</PI_FULL_NAME>
<EmailAddress>xwang@ece.osu.edu</EmailAddress>
<PI_PHON>6142471977</PI_PHON>
<NSF_ID>000344273</NSF_ID>
<StartDate>08/17/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>4090</Code>
<Text>ADVANCED NET INFRA &amp; RSCH</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~51349</FUND_OBLG>
<FUND_OBLG>2010~79819</FUND_OBLG>
<FUND_OBLG>2011~83744</FUND_OBLG>
<FUND_OBLG>2012~87925</FUND_OBLG>
<FUND_OBLG>2013~92382</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>On the technical side, the main outcome of this project is the design and development of a coordinated control framework for power, performance, thermal, and cost management in virtualized data centers. Specifically, the framework includes four major components: 1) power control and capping at different levels, 2) performance optimization, 3) thermal monitoring and management, and 4) reduction of the capital and operating expenses.</p> <p>&nbsp;</p> <p>We now introduce our technical outcomes in detail. First, for power control and capping, we have designed several power control algorithms at three different levels of a data center: server, server rack, and the entire data center. All those algorithms were systematically designed based on optimal control theory for theoretically guaranteed control accuracy and system stability. Those algorithms have been published in prestigious research conferences, such as PACT 2009, HPCA 2008, ICS 2011, and ICAC 2011. Their extended journal versions were published in IEEE Transactions on Parallel and Distributed Systems (TPDS) from 2010 to 2012. In the second component, we have systematically designed several performance optimization algorithms based on the recent advances of control theory. Those algorithms were published in several major conferences including RTSS 2008, IWQoS 2009, and IWQoS 2010. Their extended journal versions were published in IEEE TPDS from 2010 to 2012. Third, for thermal monitoring and management, we have designed two intelligent and near-optimal temperature sensor placement algorithms for improved hot server or server component detection based on a systematic Computational Fluid Dynamics (CFD) analysis of the thermal conditions in the data center. These algorithms have been published in ICDCS 2011, IGCC 2012, IEEE TPDS in 2013, and Elsevier Journal of Sustainable Computing: Informatics and Systems (SUSCOM) in 2013. For thermal management, we have designed two power optimization schemes that effectively coordinate liquid cooling, free air cooling, server placement, and dynamically manages workload allocation for jointly optimized cooling and server power. Those studies were published in ICAC 2014 and IGCC 2014. Finally, for the reduction of the capital and operating expenses, we have designed six novel algorithms that can significantly cut the capital expenses (CapEx) and operating expenses (OpEx) of data centers. Those algorithms leverage different equipment such as renewable energy supplies, thermal energy storage devices, PHEVs, and portable containerized modules and were published in Middleware 2011, ICPP 2012, CNSM 2012, IGCC 2013, HPCA 2014, and Performance 2014. Also, the extended journal versions were published in SUSCOM in 2015 and accepted to the IEEE Transactions on Computers (TC).</p> <p>&nbsp;</p> <p>A key difference between our framework and the related work is that our power, performance, and thermal control and management solutions feature a rigorous system design methodology based on recent advances in feedback control theory for analytical assurance of control accuracy and system stability. In addition, our thermal monitoring algorithms are designed based on a systematic Computational Fluid Dynamics (CFD) analysis of the thermal conditions in the data center. This theoretical foundation is in sharp contrast to the current practice that was designed based on oversimplified heuristics.</p> <p>&nbsp;</p> <p>The broader impacts of this project are as follows. First, our power control framework has significantly improved the data center performance while ensuring its power consumption stays safely below the desired power budget. For example, our work published in ICAC 2011 shows that our solution has achieved 38% better server performance, on average, than the state-of-the-art solutions. Likewise, the extensive evaluation results in our ICS 2011 paper show a 23% performance improvement. Those...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ On the technical side, the main outcome of this project is the design and development of a coordinated control framework for power, performance, thermal, and cost management in virtualized data centers. Specifically, the framework includes four major components: 1) power control and capping at different levels, 2) performance optimization, 3) thermal monitoring and management, and 4) reduction of the capital and operating expenses.     We now introduce our technical outcomes in detail. First, for power control and capping, we have designed several power control algorithms at three different levels of a data center: server, server rack, and the entire data center. All those algorithms were systematically designed based on optimal control theory for theoretically guaranteed control accuracy and system stability. Those algorithms have been published in prestigious research conferences, such as PACT 2009, HPCA 2008, ICS 2011, and ICAC 2011. Their extended journal versions were published in IEEE Transactions on Parallel and Distributed Systems (TPDS) from 2010 to 2012. In the second component, we have systematically designed several performance optimization algorithms based on the recent advances of control theory. Those algorithms were published in several major conferences including RTSS 2008, IWQoS 2009, and IWQoS 2010. Their extended journal versions were published in IEEE TPDS from 2010 to 2012. Third, for thermal monitoring and management, we have designed two intelligent and near-optimal temperature sensor placement algorithms for improved hot server or server component detection based on a systematic Computational Fluid Dynamics (CFD) analysis of the thermal conditions in the data center. These algorithms have been published in ICDCS 2011, IGCC 2012, IEEE TPDS in 2013, and Elsevier Journal of Sustainable Computing: Informatics and Systems (SUSCOM) in 2013. For thermal management, we have designed two power optimization schemes that effectively coordinate liquid cooling, free air cooling, server placement, and dynamically manages workload allocation for jointly optimized cooling and server power. Those studies were published in ICAC 2014 and IGCC 2014. Finally, for the reduction of the capital and operating expenses, we have designed six novel algorithms that can significantly cut the capital expenses (CapEx) and operating expenses (OpEx) of data centers. Those algorithms leverage different equipment such as renewable energy supplies, thermal energy storage devices, PHEVs, and portable containerized modules and were published in Middleware 2011, ICPP 2012, CNSM 2012, IGCC 2013, HPCA 2014, and Performance 2014. Also, the extended journal versions were published in SUSCOM in 2015 and accepted to the IEEE Transactions on Computers (TC).     A key difference between our framework and the related work is that our power, performance, and thermal control and management solutions feature a rigorous system design methodology based on recent advances in feedback control theory for analytical assurance of control accuracy and system stability. In addition, our thermal monitoring algorithms are designed based on a systematic Computational Fluid Dynamics (CFD) analysis of the thermal conditions in the data center. This theoretical foundation is in sharp contrast to the current practice that was designed based on oversimplified heuristics.     The broader impacts of this project are as follows. First, our power control framework has significantly improved the data center performance while ensuring its power consumption stays safely below the desired power budget. For example, our work published in ICAC 2011 shows that our solution has achieved 38% better server performance, on average, than the state-of-the-art solutions. Likewise, the extensive evaluation results in our ICS 2011 paper show a 23% performance improvement. Those timely designs can significantly help the data center operators to achieve better data center performance with l...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
