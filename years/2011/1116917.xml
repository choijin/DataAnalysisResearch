<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Planning Algorithms for Large Decentralized Multiagent Settings</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>449906.00</AwardTotalIntnAmount>
<AwardAmount>474906</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is aimed at developing effective decision-theoretic planning algorithms for multi-agent systems that involve dozens or hundreds of agents.  Current approaches to agent coordination that provide rigorous performance guarantees can only handle a few agents.  The project addresses this barrier with the following objectives: (1) develop new problem representations that allow planning algorithms to leverage the interaction structure and independence relationships within a domain; (2) develop approximation methods that operate with limited memory and time, and exhibit anytime characteristics; (3) perform rigorous convergence analysis and establish tight error bounds on solution quality; (4) develop techniques that make it easy to exploit parallelization offered by multi-core processors; and (5) create a new set of challenging test problems and perform a rigorous evaluation. The project produces two fundamentally new approaches to planning in multi-agent settings. The first approach offers efficient message-passing planning algorithms based on computational paradigms such as expectation-maximization (EM) and the concave-convex procedure (CCCP). The second approach offers rollout sampling methods for domains that are too large to be explicitly represented. These new methods improve the scalability of existing techniques by several orders of magnitude. The results transform the ability of researchers and practitioners to apply rigorous decision-theoretic planning to multi-agent domains such as sensor networks and mobile robot coordination. The broader impact stems from the wide applicability of the resulting technology, undergraduate and graduate educational activities at UMass, dissemination efforts that make the experimental domain and algorithms publically available, and the development of international collaborations.</AbstractNarration>
<MinAmdLetterDate>07/29/2011</MinAmdLetterDate>
<MaxAmdLetterDate>05/25/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116917</AwardID>
<Investigator>
<FirstName>Shlomo</FirstName>
<LastName>Zilberstein</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shlomo Zilberstein</PI_FULL_NAME>
<EmailAddress>shlomo@cs.umass.edu</EmailAddress>
<PI_PHON>4135454189</PI_PHON>
<NSF_ID>000460242</NSF_ID>
<StartDate>07/29/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Hadley</CityName>
<StateCode>MA</StateCode>
<ZipCode>010359450</ZipCode>
<StreetAddress><![CDATA[Research Administration Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7298</Code>
<Text>International Research Collab</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>5936</Code>
<Text>GERMANY (F.R.G.)</Text>
</ProgramReference>
<ProgramReference>
<Code>5979</Code>
<Text>Europe and Eurasia</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~139156</FUND_OBLG>
<FUND_OBLG>2012~335750</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <div>This project has addressed a fundamental question in artificial intelligence: how to achieve intelligent coordination of a group of decision makers in spite of stochasticity and limited information?&nbsp;The problem arises frequently in such areas as autonomous exploration, target detection and tracking, and coordination of mobile robots. What makes automated planning in these settings particularly&nbsp;challenging is the fact that each decision maker or agent must operate based on different partial information about the overall situation.</div> <div>The project utilized a recently develop mathematical formulation of this problem called Dec-POMDP. &nbsp;The key outcomes of this project is rich new algorithms that&nbsp;extend decision-theoretic planning to complex multiagent settings that involve many agents, while providing more than an order-of-magniture acceleration in the execution time of these algorithms. Previously, the prevailing approaches to&nbsp;agent coordination either relied on ad-hoc approximations that lack performance guarantees, or provided performance guarantees but could only handle a few agents. This project&nbsp;produced new planning algorithms that stand on a rigorous formal foundation and, at the same time, are more widely applicable and more scalable.<br /><br /></div> <div>The main results of the project include: (1)&nbsp;new problem representations that allow the algorithms to leverage the interaction structure and independence relationships within a domain; (2) approximation solution methods that operate with limited memory and time; (3) rigorous convergence analysis and error bounds on solution quality; (4) techniques that make it easy to exploit parallelization offered by multi-core processors; and (5) new set of challenging test problems. Thanks to these outcomes, the Dec-POMDP model has become the de-facto standard for decision-theoretic analysis of multi-agent coordination. The algorithms developed in this project are highly cited and had been&nbsp;covered in several international tutorials. The problem domains and benchmark problems created by the PI and his students are commonly used by the research community to&nbsp;compare results and facilitate progress in this area.</div> <p>&nbsp;</p><br> <p>            Last Modified: 11/27/2015<br>      Modified by: Shlomo&nbsp;Zilberstein</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   This project has addressed a fundamental question in artificial intelligence: how to achieve intelligent coordination of a group of decision makers in spite of stochasticity and limited information? The problem arises frequently in such areas as autonomous exploration, target detection and tracking, and coordination of mobile robots. What makes automated planning in these settings particularly challenging is the fact that each decision maker or agent must operate based on different partial information about the overall situation. The project utilized a recently develop mathematical formulation of this problem called Dec-POMDP.  The key outcomes of this project is rich new algorithms that extend decision-theoretic planning to complex multiagent settings that involve many agents, while providing more than an order-of-magniture acceleration in the execution time of these algorithms. Previously, the prevailing approaches to agent coordination either relied on ad-hoc approximations that lack performance guarantees, or provided performance guarantees but could only handle a few agents. This project produced new planning algorithms that stand on a rigorous formal foundation and, at the same time, are more widely applicable and more scalable.   The main results of the project include: (1) new problem representations that allow the algorithms to leverage the interaction structure and independence relationships within a domain; (2) approximation solution methods that operate with limited memory and time; (3) rigorous convergence analysis and error bounds on solution quality; (4) techniques that make it easy to exploit parallelization offered by multi-core processors; and (5) new set of challenging test problems. Thanks to these outcomes, the Dec-POMDP model has become the de-facto standard for decision-theoretic analysis of multi-agent coordination. The algorithms developed in this project are highly cited and had been covered in several international tutorials. The problem domains and benchmark problems created by the PI and his students are commonly used by the research community to compare results and facilitate progress in this area.          Last Modified: 11/27/2015       Submitted by: Shlomo Zilberstein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
