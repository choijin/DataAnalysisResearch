<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Large: Collaborative Research: Algebraic Graph Algorithms: The Laplacian and Beyond</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>724700.00</AwardTotalIntnAmount>
<AwardAmount>724700</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will exploit algebraic properties of operators associated with graphs in an integrated set of research and educational activities designed to develop new mathematical and algorithmic techniques; apply these to the solution of real-world problems and longstanding theoretical questions in mathematics, computer science, biology, and physics; and make these techniques broadly known and accessible to students, researchers, and practitioners in many fields. &lt;br/&gt;&lt;br/&gt;This research has its origins in spectral graph theory, which studies how the eigenvalues and eigenvectors of the graph Laplacian (and other related matrices) interact with the combinatorial structure of the graph. Spectral graph theory has been one of the great success stories in both the theory and practice of algorithm design. It has led to fundamental advances in graph partitioning, web search (notably including Google's PageRank algorithm), the understanding of random processes and the algorithms derived from them, the construction of error correcting codes, derandomization, convex optimization, machine learning, and many others. &lt;br/&gt;&lt;br/&gt;While the eigenvalues and eigenvectors of the Laplacian capture a striking amount of the structure of the graph, they certainly do not capture all of it. Recent work by the principal investigators and other researchers suggests that theoretical computer scientists have only scratched the surface of what can be done if they are willing to broaden their investigation, extending it to study more general algebraic properties of the Laplacian than just its eigenvalue structure, and more general operators than just the Laplacian. &lt;br/&gt;&lt;br/&gt;Under this award, the principal investigators will build a research program across the three universities involved in this proposal to develop such a theory and its applications. This initiative has the potential to provide transformative advances in a range of theoretical and applied areas of computer science, including: &lt;br/&gt;&lt;br/&gt;* Faster algorithms for fundamental graph problems, such as Maximum Flow, Minimum Cut, Minimum Cost Flow, Multicommodity Flow, approximating Sparsest Cut, generating random spanning trees, and constructing low-stretch spaning trees. &lt;br/&gt;&lt;br/&gt;* Better algorithms for the analysis of data, with potential applications to the Unique Games Conjecture. &lt;br/&gt;&lt;br/&gt;* Faster algorithms for solving broad classes of important linear systems, both sequentially and in parallel. &lt;br/&gt;&lt;br/&gt;* Faster distributed algorithms for information dissemination in networks. &lt;br/&gt;&lt;br/&gt;* A spectral and algebraic graph theory for directed graphs, based on ideas from differential geometry. &lt;br/&gt;&lt;br/&gt;* Novel quantum algorithms for a large class of problems that appear to be hard for classical computers. &lt;br/&gt;&lt;br/&gt;* New techniques for problems in Quantum Physics based on ideas developed in Computer Science and Combinatorics. &lt;br/&gt;&lt;br/&gt;The principal investigators will also work to disseminate these techniques by developing courses, training undergraduate and graduate students, and introducing these ideas to scientists in other fields.</AbstractNarration>
<MinAmdLetterDate>06/24/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1111270</AwardID>
<Investigator>
<FirstName>Shanghua</FirstName>
<LastName>Teng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shanghua Teng</PI_FULL_NAME>
<EmailAddress>shanghua@usc.edu</EmailAddress>
<PI_PHON>2137407762</PI_PHON>
<NSF_ID>000538833</NSF_ID>
<StartDate>06/24/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900890001</ZipCode>
<StreetAddress><![CDATA[University Park]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7928</Code>
<Text>QUANTUM COMPUTING</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~724700</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This has been an exciting project centered at spectral graph theory, network analysis, and machine learning that has interdisciplinary interactions with social choice theory, game theory, numerical analysis, and mathematical economics. Built on recent breakthroughs in nearly linear-time Laplacian solvers, this proposed research aims to address the fundamental conceptual and algorithmic challenges in the age of Big Data and network sciences. We studied a wide-range of graph-theoretical problems with algebraic connections aiming to connect spectral graph theory with fundamental problems in network analysis, machine learning, and data mining. We developed algorithms representing significant improvements for several fundamental problems including sublinear-time PageRank approximations, parallel sampling from Gaussian graphical models, graph isomorphism testing of strongly regular graphs, and social influence analysis. We also made conceptual contributions in network analysis for centrality formulation and community identification.</p> <p>I<strong>ntellectual Meri</strong>t:</p> <p><strong><em>Spectral Graph Theory in Machine Learning:</em></strong></p> <p><em>Background:</em> One of our goals is to strengthen the connection between machine learning and spectral graph theory, two of the active fields in understanding large data and networks. We focus on a basic problem in machine learning. Recall that a Markov random field, a graphical model of distributions, is a set of random variables whose dependencies are represented by an undirected graph. Sampling from a multivariate probability distribution is one of the most fundamental problems in statistical machine learning and statistical inference. The classical Markov Chain Monte Carlo (MCMC) algorithms (Gibbs sampling) tends to be highly sequential.&nbsp; Despite efforts by various research groups, the following &ldquo;holy grail&rdquo; question in parallel sampling for graphical models remains open:<strong><em>&nbsp;</em></strong></p> <p><em>Is it possible to obtain a characterization of the family of Markov random fields from which one can draw a sample in polylogarithmic depth with nearly-linear total work?</em></p> <p><em>Results: Our study of this problem yields a </em>major algorithmic contribution of this project. Our paper, &ldquo;Efficient Sampling for Gaussian Graphical Models via Spectral Sparsification&rdquo;, (COLT 2015,&nbsp; with my ML colleague Yan Liu and our Ph.D. students Yu Cheng and Dehua Cheng, and with Richard Peng of Georgia Tech) has three major contributions:</p> <p><strong><em>Scalable Sampling for Gaussian Graphical Models with SDD Precision Matrices</em></strong></p> <p>We gave the first nearly-optimal parallel algorithm for this basic sampling problem. Our algorithm runs in nearly-linear time, polylogarithmic depth, and uses only O(n) random scalars to generate a random sample from the Markov random fields with n variables.&nbsp;It crucially uses graph sparsification.&nbsp;</p> <p><strong><em>Sparse Newton&rsquo;s Method</em></strong></p> <p>Mathematically, we solved a more general matrix root problem:&nbsp; <em>Given an n by n Laplacian matrix M&nbsp; and a constant &minus;1 &le; p &le; 1 , compute an n by n&nbsp; linear operator C&nbsp; such that M<sup>p</sup> = CC<sup>T</sup></em>.</p> <p>Prior to our work, no algorithm could provide such a factorization in nearly-linear time. We present an approach using spectral sparsification to ensure all intermediate matrices are sparse while preserving the effectiveness of Newton&rsquo;s method. Our result provides the first example of a scalable implementation of Newton&rsquo;s method for matrix computation.</p> <p><strong><em>Sparsification of Random-Walk Matrix Polyniomials:</em></strong></p> <ul> </ul> <p>The need to sparsify intermediate matrices in Newton&rsquo;s method leads to a fundamental problem that is of interest on its own: <em>Whether a random-walk polynomial can be efficiently sparsified in nearly linear time.&nbsp;</em>We solved this problem using several intrinsic graph inequalities and advanced path sampling of effective resistance.&nbsp;</p> <p><strong>Broader Impacts:</strong></p> <p>Aiming to make fundamental contributions to network sciences and develop theory of scalable algorithms for Big Data, we have successful multi-disciplinary collaborations in several emerging areas.&nbsp;</p> <p><strong>Conceptual Contribution to Network Science</strong></p> <p>Inspired by Social-Choice Theory, Borgs, Chayes, Marple, and I developed an axiomatic framework for community identification in networks. Inspired by cooperative game theory and mathematical economics, &shy;Chen and I developed first axiomatic characterization of influence-based network centrality.&nbsp;</p> <p><strong><em>Theory of Scalable Algorithms</em></strong>:</p> <p>During this project, encouraged by Madhu Sudan, I completed a 272-page manuscript, &ldquo;Scalable Algorithms for Data and Network Analysis&rdquo;&nbsp; which provides formal discussions of algorithmic scalability, scalable algorithms, and scalable reductions. It presents a family of fundamental algorithmic techniques for designing provably-good scalable algorithms. The writing led us to discover several significant new algorithms including sub-linear time PageRank approximation algorithm and scalable algorithms for social-influence analysis.</p> <p><strong>Ph.D. Mentoring:</strong></p> <p><strong>&nbsp;</strong>Yu Cheng, &ldquo;Computational Aspects of Optimal Information Revelation.&rdquo; (USC)</p> <p>Konstantin Voevodski, &ldquo;Clustering and Network Analysis with Biological Applications.&rdquo;&nbsp; (BU)&nbsp;</p> <p>Contributed to three Ph.D. theses:</p> <p style="padding-left: 30px;">Rumi Ghosh, &ldquo;Disentangling the network: Understanding the interplay topology and dynamics in network analysis&rdquo; (advisor: Kristina Lerman, USC)</p> <p style="padding-left: 30px;">Dehua Cheng, &ldquo;Improving machine learning algorithms with efficient data relevance discovery&rdquo; (advisor:&nbsp; Yan Liu, USC),</p> <p style="padding-left: 30px;">Xiaorui Sun, &ldquo;On the isomorphism testing of graphs.&rdquo; (advisor:&nbsp; Xi Chen, Columbia University)</p> <p>Alana Shine, Han Li, Ho Yee Cheung, Qiu Ye and Jiaowen Yang have made progresses towards their Ph.D.</p> <p><strong>Award:</strong>&nbsp;G&ouml;del Prize (2015, with Dan Spielman), Simons Investigator Award (2014)</p> <p><strong>First-Time Parenting:<em> </em></strong>Sonia Rosario Teng (born on 10/15/2012) who inspired me to work on a book on bilingual learing.&nbsp;</p> <p><strong><br /></strong></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/29/2017<br>      Modified by: Shanghua&nbsp;Teng</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This has been an exciting project centered at spectral graph theory, network analysis, and machine learning that has interdisciplinary interactions with social choice theory, game theory, numerical analysis, and mathematical economics. Built on recent breakthroughs in nearly linear-time Laplacian solvers, this proposed research aims to address the fundamental conceptual and algorithmic challenges in the age of Big Data and network sciences. We studied a wide-range of graph-theoretical problems with algebraic connections aiming to connect spectral graph theory with fundamental problems in network analysis, machine learning, and data mining. We developed algorithms representing significant improvements for several fundamental problems including sublinear-time PageRank approximations, parallel sampling from Gaussian graphical models, graph isomorphism testing of strongly regular graphs, and social influence analysis. We also made conceptual contributions in network analysis for centrality formulation and community identification.  Intellectual Merit:  Spectral Graph Theory in Machine Learning:  Background: One of our goals is to strengthen the connection between machine learning and spectral graph theory, two of the active fields in understanding large data and networks. We focus on a basic problem in machine learning. Recall that a Markov random field, a graphical model of distributions, is a set of random variables whose dependencies are represented by an undirected graph. Sampling from a multivariate probability distribution is one of the most fundamental problems in statistical machine learning and statistical inference. The classical Markov Chain Monte Carlo (MCMC) algorithms (Gibbs sampling) tends to be highly sequential.  Despite efforts by various research groups, the following "holy grail" question in parallel sampling for graphical models remains open:   Is it possible to obtain a characterization of the family of Markov random fields from which one can draw a sample in polylogarithmic depth with nearly-linear total work?  Results: Our study of this problem yields a major algorithmic contribution of this project. Our paper, "Efficient Sampling for Gaussian Graphical Models via Spectral Sparsification", (COLT 2015,  with my ML colleague Yan Liu and our Ph.D. students Yu Cheng and Dehua Cheng, and with Richard Peng of Georgia Tech) has three major contributions:  Scalable Sampling for Gaussian Graphical Models with SDD Precision Matrices  We gave the first nearly-optimal parallel algorithm for this basic sampling problem. Our algorithm runs in nearly-linear time, polylogarithmic depth, and uses only O(n) random scalars to generate a random sample from the Markov random fields with n variables. It crucially uses graph sparsification.   Sparse Newton?s Method  Mathematically, we solved a more general matrix root problem:  Given an n by n Laplacian matrix M  and a constant &minus;1 &le; p &le; 1 , compute an n by n  linear operator C  such that Mp = CCT.  Prior to our work, no algorithm could provide such a factorization in nearly-linear time. We present an approach using spectral sparsification to ensure all intermediate matrices are sparse while preserving the effectiveness of Newton?s method. Our result provides the first example of a scalable implementation of Newton?s method for matrix computation.  Sparsification of Random-Walk Matrix Polyniomials:    The need to sparsify intermediate matrices in Newton?s method leads to a fundamental problem that is of interest on its own: Whether a random-walk polynomial can be efficiently sparsified in nearly linear time. We solved this problem using several intrinsic graph inequalities and advanced path sampling of effective resistance.   Broader Impacts:  Aiming to make fundamental contributions to network sciences and develop theory of scalable algorithms for Big Data, we have successful multi-disciplinary collaborations in several emerging areas.   Conceptual Contribution to Network Science  Inspired by Social-Choice Theory, Borgs, Chayes, Marple, and I developed an axiomatic framework for community identification in networks. Inspired by cooperative game theory and mathematical economics, &shy;Chen and I developed first axiomatic characterization of influence-based network centrality.   Theory of Scalable Algorithms:  During this project, encouraged by Madhu Sudan, I completed a 272-page manuscript, "Scalable Algorithms for Data and Network Analysis"  which provides formal discussions of algorithmic scalability, scalable algorithms, and scalable reductions. It presents a family of fundamental algorithmic techniques for designing provably-good scalable algorithms. The writing led us to discover several significant new algorithms including sub-linear time PageRank approximation algorithm and scalable algorithms for social-influence analysis.  Ph.D. Mentoring:   Yu Cheng, "Computational Aspects of Optimal Information Revelation." (USC)  Konstantin Voevodski, "Clustering and Network Analysis with Biological Applications."  (BU)   Contributed to three Ph.D. theses: Rumi Ghosh, "Disentangling the network: Understanding the interplay topology and dynamics in network analysis" (advisor: Kristina Lerman, USC) Dehua Cheng, "Improving machine learning algorithms with efficient data relevance discovery" (advisor:  Yan Liu, USC), Xiaorui Sun, "On the isomorphism testing of graphs." (advisor:  Xi Chen, Columbia University)  Alana Shine, Han Li, Ho Yee Cheung, Qiu Ye and Jiaowen Yang have made progresses towards their Ph.D.  Award: G&ouml;del Prize (2015, with Dan Spielman), Simons Investigator Award (2014)  First-Time Parenting: Sonia Rosario Teng (born on 10/15/2012) who inspired me to work on a book on bilingual learing.              Last Modified: 11/29/2017       Submitted by: Shanghua Teng]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
