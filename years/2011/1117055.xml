<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Small: Fast and Memory-Efficient Dimensionality Reduction for Massive Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>360000.00</AwardTotalIntnAmount>
<AwardAmount>360000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jack S. Snoeyink</SignBlockName>
<PO_EMAI>jsnoeyin@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many systems take the form of massive networks, i.e., a set of nodes joined together in pairs by links. Examples include social, communication and biological networks. Research on such complex networks has attracted broad scientific disciplines. While many sophisticated mathematical tools for network analysis have been developed, many such tools are not directly applicable due to the sheer size of modern-day networks.  In addition, these networks may be dynamically evolving and may have extra node information and/or auxiliary links between the same group of nodes obtained from heterogeneous data sources. Our proposed research aims to develop mathematical ideas novel to the analysis of massive networks. In particular, we plan to develop a novel dimensionality reduction method that proceeds by conducting a very fast clustering of the graph, extracting local latent subspaces of the graph, and then "gluing" together these subspaces to get a dimensionality reduction scheme for the entire network. Building on our new method, we plan to develop methods for handling time-evolving networks, multiple sources of information, supervised dimensionality reduction of networks and hierarchical schemes for dimensionality reduction as well as prediction. Our methods are eminently suitable for parallel computation, and we propose to further address the scalability problem by developing parallel versions of our methods on modern multi-core architectures.&lt;br/&gt;&lt;br/&gt;The proposed research will enable important inference tasks, such as link prediction, collaborative filtering and semi-supervised classification to be efficiently carried out on massive networks. We expect the resulting algorithms to have the following properties: (1) computationally faster than current state-of-the-art methods for dimensionality reduction; (2) much more memory-efficient than the globally and rank-wise optimal SVD method; (3) scalable to extremely large data sets, such as online social networks, e.g., MySpace and Facebook, communication networks and virtual networks; (4) flexible enough to integrate auxiliary information of various types and different levels of uncertainty; and (5) effective enough to discover the task-oriented low-dimensional structure of the network. The proposed project will have broad impact on research in a variety of disciplines, including applied mathematics, computer science and social sciences. We plan to share the software developed under the project with the scientific community via a public web site, as well as the data and results that arise from our studies. The project will make a conscious effort to involve students in inter-disciplinary research.</AbstractNarration>
<MinAmdLetterDate>06/02/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/02/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1117055</AwardID>
<Investigator>
<FirstName>Inderjit</FirstName>
<LastName>Dhillon</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Inderjit S Dhillon</PI_FULL_NAME>
<EmailAddress>inderjit@cs.utexas.edu</EmailAddress>
<PI_PHON>5124719725</PI_PHON>
<NSF_ID>000200521</NSF_ID>
<StartDate>06/02/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787595316</ZipCode>
<StreetAddress><![CDATA[3925 W Braker Lane, Ste 3.340]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7933</Code>
<Text>NUM, SYMBOL, &amp; ALGEBRA COMPUT</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~360000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Many systems take the form of massive networks, i.e., a set of nodes joined together in pairs by links. Examples include social, communication and biological networks. Research on such complex networks has attracted broad scientific disciplines. While many sophisticated mathematical tools for network analysis have been developed, many such tools are not directly applicable due to the sheer size of modern-day networks. In addition, these networks may be dynamically evolving and may have extra node information and/or auxiliary links between the same group of nodes obtained from heterogeneous data sources. Through this award, we have developed fast and memory-efficient dimensionality reduction techniques. Our new dimensionality reduction schemes offer a fundamentally different viewpoint to compressing graph information. This allows so-called matrix functions to be approximated on massive networks, thus offering an alternative to the ubiquitous singular value decomposition. The end applications are numerous, such as semi-supervised classification and recommender systems. Building on our new methods, we have also developed methods for handling time-evolving networks, multiple sources of information, supervised dimensionality reduction of networks and hierarchical schemes for dimensionality reduction as well as prediction. Our methods are eminently suitable for parallel computation, and we have addressed the scalability problem by developing parallel versions of our methods on modern multi-core and distributed memory computers.</p> <p>The newly developed techniques have the following properties: (1) computationally faster than current state-of-the-art methods for dimensionality reduction; (2) much more memory-efficient than the globally and rank-wise optimal SVD method; (3) scalable to extremely large data sets, such as online social networks, communication networks and virtual networks; (4) flexible enough to integrate auxiliary information of various types; and (5) effective enough to discover the task-oriented low-dimensional structure of the network. As a result, our techniques enable important inference tasks, such as link prediction, collaborative filtering and semi-supervised classification to be efficiently carried out on massive networks. Also, we addressed various real-world applications in social network analysis, signed network analysis, recommender systems and biological network analysis using our new methodologies. The results have been disseminated through publications in various venues, such as KDD, NIPS, CIKM, ICDM, ICML, VLDB, and JMLR which are leading conferences in data mining and machine learning. In addition, we have shared the software developed under the project with the scientific community via a public web site, in addition to the data and results that arise from our studies. This project has had broad impact on research in a variety of disciplines, including applied mathematics, computer science and social sciences. The project made a conscious effort to involve female students in inter-disciplinary research.</p><br> <p>            Last Modified: 10/13/2015<br>      Modified by: Inderjit&nbsp;S&nbsp;Dhillon</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Many systems take the form of massive networks, i.e., a set of nodes joined together in pairs by links. Examples include social, communication and biological networks. Research on such complex networks has attracted broad scientific disciplines. While many sophisticated mathematical tools for network analysis have been developed, many such tools are not directly applicable due to the sheer size of modern-day networks. In addition, these networks may be dynamically evolving and may have extra node information and/or auxiliary links between the same group of nodes obtained from heterogeneous data sources. Through this award, we have developed fast and memory-efficient dimensionality reduction techniques. Our new dimensionality reduction schemes offer a fundamentally different viewpoint to compressing graph information. This allows so-called matrix functions to be approximated on massive networks, thus offering an alternative to the ubiquitous singular value decomposition. The end applications are numerous, such as semi-supervised classification and recommender systems. Building on our new methods, we have also developed methods for handling time-evolving networks, multiple sources of information, supervised dimensionality reduction of networks and hierarchical schemes for dimensionality reduction as well as prediction. Our methods are eminently suitable for parallel computation, and we have addressed the scalability problem by developing parallel versions of our methods on modern multi-core and distributed memory computers.  The newly developed techniques have the following properties: (1) computationally faster than current state-of-the-art methods for dimensionality reduction; (2) much more memory-efficient than the globally and rank-wise optimal SVD method; (3) scalable to extremely large data sets, such as online social networks, communication networks and virtual networks; (4) flexible enough to integrate auxiliary information of various types; and (5) effective enough to discover the task-oriented low-dimensional structure of the network. As a result, our techniques enable important inference tasks, such as link prediction, collaborative filtering and semi-supervised classification to be efficiently carried out on massive networks. Also, we addressed various real-world applications in social network analysis, signed network analysis, recommender systems and biological network analysis using our new methodologies. The results have been disseminated through publications in various venues, such as KDD, NIPS, CIKM, ICDM, ICML, VLDB, and JMLR which are leading conferences in data mining and machine learning. In addition, we have shared the software developed under the project with the scientific community via a public web site, in addition to the data and results that arise from our studies. This project has had broad impact on research in a variety of disciplines, including applied mathematics, computer science and social sciences. The project made a conscious effort to involve female students in inter-disciplinary research.       Last Modified: 10/13/2015       Submitted by: Inderjit S Dhillon]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
