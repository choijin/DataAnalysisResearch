<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DIP:  Collaborative Research:  Social Robots as Mechanisms for Language Instruction, Interaction, and Evaluation in Pre-School Children</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>623993.00</AwardTotalIntnAmount>
<AwardAmount>623993</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is leveraging emerging technologies in social robotics with recent findings from social, developmental, and cognitive psychology to design, implement, and evaluate a new generation of robots that is capable of interacting with and instructing young learners (ages 3 through 6) in a truly social way. The robot incorporates signals that the mind implicitly uses to ascertain another's intentions, motivations, and affiliations (e.g., motor mimicry and synchrony, affective cues, gaze direction), making it capable of serving as a true embodiment of a human instructor. The robotic platform can be controlled remotely, through a direct and proximate connection or a remote, Internet-based operator interface. As such, the system can be placed in several different environments, ranging from a child's home to medical areas where issues of mobility or immunosuppression make it difficult for direct interaction with instructors. Research is aimed at better understanding children's concepts of robot mind and of robots as agents, uncovering mental operations behind learning new words, and adding to what is known about the added value (if any) of non-verbal utterances to understanding, communication, and collaboration.&lt;br/&gt;&lt;br/&gt;Emerging research has identified the acquisition of early language and vocabulary skills primary predictors of later academic success. Impoverished vocabulary upon entering kindergarten strongly predicts poor subsequent academic performance. Accordingly, the use of technologies designed to build vocabulary during the preschool years is key to facilitating many types of learning. Interactions with a robotic language partner are expected to have particularly important ramifications for children with compromised opportunities to interact regularly with attentive, nurturing caregivers willing and able to foster their vital socio-intellectual developmental needs. In addition, the rationales, artifacts, and cyber platforms and infrastructure created for this project could lend themselves to a broad range of design extensions, such as providing opportunities for children who are learning English as a second language to participate in English-language-based social activities, outreach to rural areas where children have infrequent access to social activities, supporting children of deaf parents, and assessing/assisting children with pragmatic language impairments.</AbstractNarration>
<MinAmdLetterDate>09/07/2011</MinAmdLetterDate>
<MaxAmdLetterDate>09/07/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1122886</AwardID>
<Investigator>
<FirstName>Cynthia</FirstName>
<LastName>Breazeal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Cynthia Breazeal</PI_FULL_NAME>
<EmailAddress>cynthiab@media.mit.edu</EmailAddress>
<PI_PHON>6174525601</PI_PHON>
<NSF_ID>000481013</NSF_ID>
<StartDate>09/07/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7444</Code>
<Text>NATIONAL SMETE DIGITAL LIBRARY</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>7444</Code>
<Text>NATIONAL SMETE DIGITAL LIBRARY</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8842</Code>
<Text>Design and Implementation Projects</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~623993</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>A society&rsquo;s ability to flourish necessarily depends on the development of an active and intellectually-engaged citizenry. Given that one principle factor underlying intellectual development is the acquisition of appropriate language and vocabulary skills early in life, we sought to examine how the use of technologies designed to build vocabulary during the preschool years might be improved to facilitate relevant learning. More specifically, this grant allowed us to leverage emerging technologies in social robotics and recent findings from social, developmental, and cognitive psychology in an effort to design and evaluate a new generation of robots that would be capable of interacting with and instructing young learners in a truly social way.</p> <p>Given the growing recognition that the social aspects of a child&rsquo;s environment are central to her ability to learn rapidly and efficiently, we developed robots that, through incorporating signals that the mind implicitly uses to ascertain the intentions and motivations of others, is capable of serving as true embodiments of a human instructor. We investigated the extent to which different social cues (e.g., social-emotional contingency, gaze, and vocal expressivity) affected children's engagement and learning. Broadly speaking, the experiments conducted as part of this project confirmed the view that designing robots to express more human-like social and emotional cues produced greater engagement and superior outcomes with respect to vocabulary learning environments.</p> <p>&nbsp;</p> <p>In experiments in which we varied the extent to which robots behaved in an emotionally-contingent manner (i.e., expressed emotional cues in ways that were responsive to the children), we found that children preferentially sought information from the robots that behaved in more &ldquo;human-like&rdquo; emotionally appropriate ways. In other experiments where we presented multiple objects that could be referents for new vocabulary words, we found that children would make use of a robot&rsquo;s gaze, much as they would with a human interlocutor, to efficiently determine which object the newly presented vocabulary word named. In a final experiment in which we varied the emotional expressiveness of robots who were telling a story, we found that while short-term learning of information contained in the story was not affected by a given robot&rsquo;s expressivity, children who heard the story from an emotionally expressive robot showed stronger emotional engagement in the story as it was being narrated as well as greater inclusion of the newly learned vocabulary into their own subsequent retelling of the story. Moreover, during a period of delayed recall of a few weeks, children who had interacted with a more emotionally expressive robot evidenced greater fidelity to the original story during their own second retelling of it.</p> <p>Of import, the robotic platform we developed is one that can be controlled remotely, allowing the system to be placed in different environments, such as the child's home or school, or even medical areas where issues of mobility or immunosuppression make it difficult for direct interaction with instructors. We believe that the ability for an instructor to be co-present with a child learner in the form of a robotic avatar (as opposed to screen-based telecommunication solely) could offer substantial benefits in learning by increasing the truly social aspects of the environment in several ways. Indeed, our work demonstrates how the human mind implicitly makes use of and responds to social cues emitted by a robot in the same was as it does to similar cues emitted by a human.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/19/2016<br>      Modified by: Cynthia&nbsp;Breazeal</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1122886/1122886_10131572_1479588723535_cyber4-expressivity-2--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1122886/1122886_10131572_1479588723535_cyber4-expressivity-2--rgov-800width.jpg" title="social robot learning companion"><img src="/por/images/Reports/POR/2016/1122886/1122886_10131572_1479588723535_cyber4-expressivity-2--rgov-66x44.jpg" alt="social robot learning companion"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The robot and puppet used for the final expressivity study involving storytell/retell.</div> <div class="imageCredit">MIT Media Lab</div> <div class="imageSubmitted">Cynthia&nbsp;Breazeal</div> <div class="imageTitle">social robot learning companion</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ A society?s ability to flourish necessarily depends on the development of an active and intellectually-engaged citizenry. Given that one principle factor underlying intellectual development is the acquisition of appropriate language and vocabulary skills early in life, we sought to examine how the use of technologies designed to build vocabulary during the preschool years might be improved to facilitate relevant learning. More specifically, this grant allowed us to leverage emerging technologies in social robotics and recent findings from social, developmental, and cognitive psychology in an effort to design and evaluate a new generation of robots that would be capable of interacting with and instructing young learners in a truly social way.  Given the growing recognition that the social aspects of a child?s environment are central to her ability to learn rapidly and efficiently, we developed robots that, through incorporating signals that the mind implicitly uses to ascertain the intentions and motivations of others, is capable of serving as true embodiments of a human instructor. We investigated the extent to which different social cues (e.g., social-emotional contingency, gaze, and vocal expressivity) affected children's engagement and learning. Broadly speaking, the experiments conducted as part of this project confirmed the view that designing robots to express more human-like social and emotional cues produced greater engagement and superior outcomes with respect to vocabulary learning environments.     In experiments in which we varied the extent to which robots behaved in an emotionally-contingent manner (i.e., expressed emotional cues in ways that were responsive to the children), we found that children preferentially sought information from the robots that behaved in more "human-like" emotionally appropriate ways. In other experiments where we presented multiple objects that could be referents for new vocabulary words, we found that children would make use of a robot?s gaze, much as they would with a human interlocutor, to efficiently determine which object the newly presented vocabulary word named. In a final experiment in which we varied the emotional expressiveness of robots who were telling a story, we found that while short-term learning of information contained in the story was not affected by a given robot?s expressivity, children who heard the story from an emotionally expressive robot showed stronger emotional engagement in the story as it was being narrated as well as greater inclusion of the newly learned vocabulary into their own subsequent retelling of the story. Moreover, during a period of delayed recall of a few weeks, children who had interacted with a more emotionally expressive robot evidenced greater fidelity to the original story during their own second retelling of it.  Of import, the robotic platform we developed is one that can be controlled remotely, allowing the system to be placed in different environments, such as the child's home or school, or even medical areas where issues of mobility or immunosuppression make it difficult for direct interaction with instructors. We believe that the ability for an instructor to be co-present with a child learner in the form of a robotic avatar (as opposed to screen-based telecommunication solely) could offer substantial benefits in learning by increasing the truly social aspects of the environment in several ways. Indeed, our work demonstrates how the human mind implicitly makes use of and responds to social cues emitted by a robot in the same was as it does to similar cues emitted by a human.          Last Modified: 11/19/2016       Submitted by: Cynthia Breazeal]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
