<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDI Type II: Bridging the Computational Semantic Gap: A Demand-Driven Framework for Portal-Based Chemistry, Astronomy and Neurobiology</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2011</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>2100000.00</AwardTotalIntnAmount>
<AwardAmount>2100000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>01060000</Code>
<Directorate>
<Abbreviation>O/D</Abbreviation>
<LongName>Office Of The Director</LongName>
</Directorate>
<Division>
<Abbreviation>OIA</Abbreviation>
<LongName>Office of Integrative Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Stephen Meacham</SignBlockName>
<PO_EMAI>smeacham@nsf.gov</PO_EMAI>
<PO_PHON>7032927599</PO_PHON>
</ProgramOfficer>
<AbstractNarration>We propose a new framework to enhance the quality of scientific computational research in the fields of chemistry, astronomy, and neurobiology.  We make an analogy with demand-driven, portal-based online knowledge systems, such as Google Search, Wolfram|Alpha, Expedia and Orbitz.  For example, travelers in the recent past relied heavily on travel agents who manipulated complicated flight databases and booking protocols.  Nowadays customers can perform searches and make reservations on their own via the web using a simple online interface without any specialized knowledge such as hotel logistics or airport codes.  One of the greatest advantages is the freedom to explore the information space autonomously, potentially finding many more travel options, increasing overall competition and quality of results.&lt;br/&gt;&lt;br/&gt;In our analogy, the application scientist is the traveler and the computer expert is the travel agent.  Scientific computation is an accepted third pillar of scientific discovery, alongside traditional experiment and pen-and-paper theory.  However, it is very often restricted to a cadre of specialists who have mastered the knowledge of utilizing complicated software tools and hardware, despite massive investment in world-class high-performance computing (HPC) facilities.  Successful scientists who lack these computer skills face a semantic gap impeding their potential.  Our ultimate vision is to democratize the exploitation of these valuable HPC resources to a broader range of application scientists, inspired by the success of portal-based online services which abstract-away the technical details of a computer platform without sacrificing functionality.  Our system will provide access to simulation and data-processing packages on HPC hardware, and facilitate the imaging and visualization of complex data sets.  Moreover, a natural-language interface and expert system, based around the Wolfram|Alpha approach, will help to guide productive inquiry and interpretation of results.  The selected drivers are: (1) quantum chemistry simulation of thousands of molecules, including the search for advanced materials; (2) imaging massive cosmological datasets from radio telescopes; (3) analysis of high-resolution electron microscope brain images in computational neurobiology.&lt;br/&gt;&lt;br/&gt;We envisage a broad impact of the work not only in many areas of fundamental research, but also in education.  The program will be integrated into courses offered at Harvard and its Extension School, and outreach to minorities and the underprivileged will be accomplished through established mechanisms at the University.  The portal format, coupled with an online database of historical results, naturally enables dissemination of research products and offers an ideal platform for training events and workshops.</AbstractNarration>
<MinAmdLetterDate>09/19/2011</MinAmdLetterDate>
<MaxAmdLetterDate>09/19/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.083</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1125087</AwardID>
<Investigator>
<FirstName>Lincoln</FirstName>
<LastName>Greenhill</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lincoln J Greenhill</PI_FULL_NAME>
<EmailAddress>greenhill@cfa.harvard.edu</EmailAddress>
<PI_PHON>6174957194</PI_PHON>
<NSF_ID>000175585</NSF_ID>
<StartDate>09/19/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hanspeter</FirstName>
<LastName>Pfister</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hanspeter Pfister</PI_FULL_NAME>
<EmailAddress>pfister@seas.harvard.edu</EmailAddress>
<PI_PHON>6174968269</PI_PHON>
<NSF_ID>000185558</NSF_ID>
<StartDate>09/19/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alan</FirstName>
<LastName>Aspuru-Guzik</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alan Aspuru-Guzik</PI_FULL_NAME>
<EmailAddress>aspuru@chemistry.harvard.edu</EmailAddress>
<PI_PHON>6173848188</PI_PHON>
<NSF_ID>000076971</NSF_ID>
<StartDate>09/19/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021382902</ZipCode>
<StreetAddress><![CDATA[12 Oxford Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7751</Code>
<Text>CDI TYPE II</Text>
</ProgramElement>
<ProgramReference>
<Code>7721</Code>
<Text>FROM DATA TO KNOWLEDGE</Text>
</ProgramReference>
<ProgramReference>
<Code>7722</Code>
<Text>COMPLEXITY</Text>
</ProgramReference>
<ProgramReference>
<Code>7725</Code>
<Text>CDI-VIRTUAL ORGANIZATIONS</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~2100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The enormous amounts of data produced by experimental observations and high-performance computational procedures create new challenges for researchers who need to store, process, analyze, and make sense of them. The CDI2: Bridging the Computational Gap project tackled these challenges in three computation-heavy areas&mdash;quantum chemistry, radio cosmology, and neurobiology&mdash; through new algorithms, standards, and software.</p> <p>The Computational Quantum Chemistry team focused on creating stable, scalable, and user-friendly approaches for exploring chemical space, predicting reaction energetics from first principles, constructing chemical reaction networks, and analyzing their properties.</p> <p>The Radio Cosmology group's domain science is characterization of the universe during and after the cosmological dark age (the time before stars). The LEDA telescope, built by the group, includes a streaming data acquisition system capable of generating over 1 TB/hour in real-time. The project goal is to lower barriers for development of high-performance computational pipelines such as are used in LEDA, with ultimate application in and out of astronomy.</p> <p>The Computational Neurobiology team has developed a multi-user tool that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. Therefore, the developed tool provides crucial support for the management, provenance, accountability, and auditing of large-scale segmentations.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/31/2016<br>      Modified by: Alan&nbsp;Aspuru-Guzik</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The enormous amounts of data produced by experimental observations and high-performance computational procedures create new challenges for researchers who need to store, process, analyze, and make sense of them. The CDI2: Bridging the Computational Gap project tackled these challenges in three computation-heavy areas&mdash;quantum chemistry, radio cosmology, and neurobiology&mdash; through new algorithms, standards, and software.  The Computational Quantum Chemistry team focused on creating stable, scalable, and user-friendly approaches for exploring chemical space, predicting reaction energetics from first principles, constructing chemical reaction networks, and analyzing their properties.  The Radio Cosmology group's domain science is characterization of the universe during and after the cosmological dark age (the time before stars). The LEDA telescope, built by the group, includes a streaming data acquisition system capable of generating over 1 TB/hour in real-time. The project goal is to lower barriers for development of high-performance computational pipelines such as are used in LEDA, with ultimate application in and out of astronomy.  The Computational Neurobiology team has developed a multi-user tool that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. Therefore, the developed tool provides crucial support for the management, provenance, accountability, and auditing of large-scale segmentations.          Last Modified: 10/31/2016       Submitted by: Alan Aspuru-Guzik]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
