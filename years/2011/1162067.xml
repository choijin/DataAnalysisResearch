<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CGV: Medium: Collaborative Research: Visualizing Comparisons</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>300445.00</AwardTotalIntnAmount>
<AwardAmount>300445</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Comparison is an essential part of data analysis and, therefore, of many visualization tasks.  While the published literature provides a wealth of visualization tools for looking at individual objects (graphs, volumes, time series, gene sequences, molecular motions, etc.), there has to date been less consideration of support for comparison.  The PIs argue that comparison tasks are best supported by tools explicitly designed for that purpose.  The problem is that visual comparison becomes more challenging as the number of objects, their size, and the complexity of the objects and/or of the relationships among them increases.  The difficulty is further compounded by our rapidly growing ability to collect and generate data.  In prior work the PIs have developed some encouraging initial examples of comparison tools, but these are specialized successes that offer little guidance for future endeavors.  Addressing a wider range of comparison problems at greater scale with our present limited understanding thus largely remains an art that requires considerable effort.  The PIs' goal in this project is to move towards a science of visual comparison.  By studying visual comparison as a general problem, they will establish a domain-independent foundation for the field that facilitates the design of future tools which allow the creation of more effective and scalable comparisons.  To these ends the team will pursue three interconnected research threads.  They will define theories that are grounded upon principles of visual cognition.  They will explore case studies (derived from real problems suggested by domain collaborators) that challenge and extend these theories, provide examples for empirical study, and suggest or use general concepts.  And they will identify common tasks, designs, and strategies that enable development of generalized techniques, guidelines, and software components.  This approach uniquely combines empirical studies, design explorations, and software development to take the field of visual comparisons to a new level that is both rooted in theory yet viable in practice. &lt;br/&gt;&lt;br/&gt;Broader Impacts:   Because visual comparison plays a key role in diverse domains (including essentially all of the sciences, engineering, and medicine), the potential benefits from an improved science of visual comparison tools are far reaching.  To ensure maximum applicability for project outcomes, the PIs are directly collaborating with physical, biological, social, educational, and medical scientists, as well as with engineers and scholars in the humanities.  The project will generate visualization tools, software components, and resources for visualization development by others.  Visual comparison will serve as a mechanism to expose students at all levels to issues in data understanding.  This project will also provide training for visualization specialists, engage non-technical students in visualization, and explore the role of visualization in public outreach efforts.</AbstractNarration>
<MinAmdLetterDate>05/16/2012</MinAmdLetterDate>
<MaxAmdLetterDate>07/16/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1162067</AwardID>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Franconeri</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven L Franconeri</PI_FULL_NAME>
<EmailAddress>franconeri@northwestern.edu</EmailAddress>
<PI_PHON>2246161430</PI_PHON>
<NSF_ID>000201156</NSF_ID>
<StartDate>05/16/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602081110</ZipCode>
<StreetAddress><![CDATA[633 Clark St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~110954</FUND_OBLG>
<FUND_OBLG>2013~113979</FUND_OBLG>
<FUND_OBLG>2014~37343</FUND_OBLG>
<FUND_OBLG>2015~38169</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br />Human activity, including science, engineering, education, and business, produces an incredible amount of data. As this trend increases, so does the demand for techniques that help us use it. Data visualization is a critical tool for discovery, reasoning, and communication of the trends and insights hidden in complex data. The goal of the project was to explore a critical visual step in interpreting data visualizations: visual comparison. While many aspects of interpreting data visualizations are relatively quick and easy (e.g., Is one value different from others? What's the highest or lowest value?), comparisons can be extremely slow and difficult (Where does this pattern repeat? Where is it different, and how is it different?).&nbsp;</p> <p><br />As a sample of our findings and contributions, we produced a review of what types of visual processing are slow, vs. fast, intended to summarize this knowledge to the data visualization research community, as well as to inspire the perception research community to study questions with maximal real-world impact. We explored how the visual system is able to extract information about correlation, a comparison between two sets of data values, across several known ways of depicting those data, and produced guidelines stating that two displays were most effective. We explored the effectiveness of display animation in highlighting comparisons, and found that they are surprisingly ineffective, despite their wide use in data journalism and education. We studied the techniques of data journalists (e.g., at the New York Times Upshot) to see how they engage readers with clear depictions of data, and how these techniques might be extended to teachers, scientists, and visualization designers.&nbsp;</p> <p><br />The intellectual merit of this project was to combine knowledge and research methods from the data visualization research field and the perceptual psychology research field, to explore which comparisons are tough, and which are not. The broader impacts of this work were to produce guidelines for how to best leverage the human visual system's powers to make comparisons more efficient, build stronger bridges across the disciplines of perceptual psychology, education, and data visualization, and to teach and train the next generation of researchers.&nbsp;</p><br> <p>            Last Modified: 12/01/2017<br>      Modified by: Steven&nbsp;L&nbsp;Franconeri</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Human activity, including science, engineering, education, and business, produces an incredible amount of data. As this trend increases, so does the demand for techniques that help us use it. Data visualization is a critical tool for discovery, reasoning, and communication of the trends and insights hidden in complex data. The goal of the project was to explore a critical visual step in interpreting data visualizations: visual comparison. While many aspects of interpreting data visualizations are relatively quick and easy (e.g., Is one value different from others? What's the highest or lowest value?), comparisons can be extremely slow and difficult (Where does this pattern repeat? Where is it different, and how is it different?).    As a sample of our findings and contributions, we produced a review of what types of visual processing are slow, vs. fast, intended to summarize this knowledge to the data visualization research community, as well as to inspire the perception research community to study questions with maximal real-world impact. We explored how the visual system is able to extract information about correlation, a comparison between two sets of data values, across several known ways of depicting those data, and produced guidelines stating that two displays were most effective. We explored the effectiveness of display animation in highlighting comparisons, and found that they are surprisingly ineffective, despite their wide use in data journalism and education. We studied the techniques of data journalists (e.g., at the New York Times Upshot) to see how they engage readers with clear depictions of data, and how these techniques might be extended to teachers, scientists, and visualization designers.    The intellectual merit of this project was to combine knowledge and research methods from the data visualization research field and the perceptual psychology research field, to explore which comparisons are tough, and which are not. The broader impacts of this work were to produce guidelines for how to best leverage the human visual system's powers to make comparisons more efficient, build stronger bridges across the disciplines of perceptual psychology, education, and data visualization, and to teach and train the next generation of researchers.        Last Modified: 12/01/2017       Submitted by: Steven L Franconeri]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
