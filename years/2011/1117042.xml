<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Developing and Applying Reuse Distance Analysis Techniques for Large-Scale Multicore Processors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>499998.00</AwardTotalIntnAmount>
<AwardAmount>499998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Today, simulation is the de facto method for studying multicore cache hierarchies.  But simulation is costly due to the combinatorial design spaces involved, especially as multicore processors scale to 100s of cores and 100+ MB of on-chip cache.  Reuse distance (RD) analysis can help architects evaluate multicore memory performance more efficiently.  Unfortunately, locality in multicore processors depends on how per-thread memory reference streams interleave.  Reliance on memory interleaving makes multicore locality profiles architecture dependent, limiting their ability to analyze different configurations. For loop-based parallel programs, however, threads are typically symmetric and exhibit similar locality characteristics.  Such thread symmetry makes multicore RD analysis tractable: locality profiles remain stable with respect to cache capacity scaling, and change systematically with core count and problem size scaling.&lt;br/&gt;&lt;br/&gt;This project is exploring several research directions related to multicore RD analysis for loop-based parallel programs.  First, it is characterizing how Concurrent RD and per-thread RD profiles for symmetric threads vary with processor and problem scaling.  Second, it is developing techniques to predict these profile variations.  Simple prediction techniques such as reference groups, as well as more sophisticated parametric and non-parametric learning approaches, are being studied.  Finally, it is applying the new RD analysis to explore large-scale multicore design spaces, identifying good cache hierarchy organizations.  It is also using the RD analyses to improve existing memory performance enhancement techniques such as multithreading and locality optimization.</AbstractNarration>
<MinAmdLetterDate>07/11/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/11/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1117042</AwardID>
<Investigator>
<FirstName>Donald</FirstName>
<LastName>Yeung</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Donald Yeung</PI_FULL_NAME>
<EmailAddress>yeung@umd.edu</EmailAddress>
<PI_PHON>3014053649</PI_PHON>
<NSF_ID>000460886</NSF_ID>
<StartDate>07/11/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ankur</FirstName>
<LastName>Srivastava</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ankur Srivastava</PI_FULL_NAME>
<EmailAddress>ankurs@eng.umd.edu</EmailAddress>
<PI_PHON>3014056269</PI_PHON>
<NSF_ID>000313791</NSF_ID>
<StartDate>07/11/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7329</Code>
<Text>COMPILERS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~499998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Hardware caches play a crucial role in optimizing the performance and<br />power consumption of microprocessors, so understanding their behavior<br />is extremely important.&nbsp; Traditionally, cache behavior has been<br />studied via simulation.&nbsp; Unfortunately, simulators are slow, so they<br />are often unable to fully explore large cache hierarchy design spaces.<br />Worse yet, speed limitations also prevent simulators from studying<br />realistic configurations--for example, a program running a<br />realistically large problem size on a large number of cores.<br /><br />A powerful alternative for studying cache behavior is reuse distance<br />(RD) analysis.&nbsp; RD analysis measures a program's memory reuse distance<br />histogram, or RD profile, using least recently used (LRU) stacks that<br />capture the application-level locality responsible for cache<br />performance.&nbsp; Once acquired, an RD profile can be used to predict the<br />cache performance of a large number of different cache configurations<br />(e.g., across all possible cache sizes).&nbsp; This not only accelerates<br />design space exploration, it also provides deep insights into how<br />programs utilize cache hierarchies.<br /><br />Historically, RD analysis has been relevant for analyzing<br />uniprocessors only.&nbsp; Techniques for multicore processors have been<br />elusive because parallel program locality is complex: it not only<br />depends on per-thread locality, but it also depends on how threads'<br />memory references interfere within the cache hierarchy.&nbsp; While no<br />solution exists yet for general threads, solutions do exist for<br />homogeneous threads such as those extant in programs exploiting<br />loop-level parallelism.&nbsp; Recently, researchers have provided RD<br />profiling techniques for homogeneous multithreaded programs.<br />Specifically, concurrent reuse distance (CRD) profiling yields<br />locality profiles for analyzing shared caches, while private-stack<br />reuse distance (PRD) profiling yields locality profiles for analyzing<br />private caches.&nbsp; (See Figure 1).<br /><br />Our research project builds on top of this recent work, advancing the<br />state-of-the-art for multicore RD analysis in two major ways.&nbsp; One<br />contribution is that we identified several fundamental parallel<br />locality behaviors that fall out of CRD/PRD analysis.&nbsp; First, both CRD<br />and PRD profiles are shifted versions of uniprocessor RD profiles,<br />where the shift reflects the locality degradation due to thread<br />interference.&nbsp; In fact, as core count scales up, the profiles simply<br />shift to larger cache capacities.&nbsp; Second, shifting in CRD profiles<br />only occurs up to a certain capacity, which we call "Ccore."&nbsp; Because<br />thread interference can only happen within the scope of program<br />parallelization, locality degradation is limited.&nbsp; Ccore quantifies<br />the maximum scope of locality degradation--i.e., a program's "parallel<br />working set size."&nbsp; Third, the shift in CRD and PRD profiles is<br />systematic, and hence, predictable.&nbsp; We developed several techniques<br />to predict this shift.&nbsp; Our techniques enable construction of locality<br />profiles for large-scale CPUs from profiles acquired on small-scale<br />CPUs.&nbsp; Finally, data sharing is capacity dependent.&nbsp; It tends to be<br />non-existent at small cache sizes.&nbsp; In the absence of sharing, shared<br />and private caches behave similarly, so CRD and PRD profiles are<br />coincident in this small-capacity region.&nbsp; However, as cache size<br />increases, data sharing starts to occur within the cache hierarchy<br />which causes CRD and PRD profiles to diverge.&nbsp; This CRD-PRD gap<br />quantifies the miss rate advantage of a shared cache over a private<br />cache.&nbsp; We call the capacity at which sharing starts to ma...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Hardware caches play a crucial role in optimizing the performance and power consumption of microprocessors, so understanding their behavior is extremely important.  Traditionally, cache behavior has been studied via simulation.  Unfortunately, simulators are slow, so they are often unable to fully explore large cache hierarchy design spaces. Worse yet, speed limitations also prevent simulators from studying realistic configurations--for example, a program running a realistically large problem size on a large number of cores.  A powerful alternative for studying cache behavior is reuse distance (RD) analysis.  RD analysis measures a program's memory reuse distance histogram, or RD profile, using least recently used (LRU) stacks that capture the application-level locality responsible for cache performance.  Once acquired, an RD profile can be used to predict the cache performance of a large number of different cache configurations (e.g., across all possible cache sizes).  This not only accelerates design space exploration, it also provides deep insights into how programs utilize cache hierarchies.  Historically, RD analysis has been relevant for analyzing uniprocessors only.  Techniques for multicore processors have been elusive because parallel program locality is complex: it not only depends on per-thread locality, but it also depends on how threads' memory references interfere within the cache hierarchy.  While no solution exists yet for general threads, solutions do exist for homogeneous threads such as those extant in programs exploiting loop-level parallelism.  Recently, researchers have provided RD profiling techniques for homogeneous multithreaded programs. Specifically, concurrent reuse distance (CRD) profiling yields locality profiles for analyzing shared caches, while private-stack reuse distance (PRD) profiling yields locality profiles for analyzing private caches.  (See Figure 1).  Our research project builds on top of this recent work, advancing the state-of-the-art for multicore RD analysis in two major ways.  One contribution is that we identified several fundamental parallel locality behaviors that fall out of CRD/PRD analysis.  First, both CRD and PRD profiles are shifted versions of uniprocessor RD profiles, where the shift reflects the locality degradation due to thread interference.  In fact, as core count scales up, the profiles simply shift to larger cache capacities.  Second, shifting in CRD profiles only occurs up to a certain capacity, which we call "Ccore."  Because thread interference can only happen within the scope of program parallelization, locality degradation is limited.  Ccore quantifies the maximum scope of locality degradation--i.e., a program's "parallel working set size."  Third, the shift in CRD and PRD profiles is systematic, and hence, predictable.  We developed several techniques to predict this shift.  Our techniques enable construction of locality profiles for large-scale CPUs from profiles acquired on small-scale CPUs.  Finally, data sharing is capacity dependent.  It tends to be non-existent at small cache sizes.  In the absence of sharing, shared and private caches behave similarly, so CRD and PRD profiles are coincident in this small-capacity region.  However, as cache size increases, data sharing starts to occur within the cache hierarchy which causes CRD and PRD profiles to diverge.  This CRD-PRD gap quantifies the miss rate advantage of a shared cache over a private cache.  We call the capacity at which sharing starts to manifest itself "Cshare."  (See Figure 2 for an illustration of all of these parallel locality phenomena).  While the shape of the CRD and PRD profiles and the values for Ccore and Cshare differ across parallel programs, we find *all* homogeneous multithreaded programs exhibit these phenomena.  (See Figure 3).  Thus, they are quite useful in helping computer architects reason about parallel cache behavior.  Our second contribution is that we applied multicore ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
