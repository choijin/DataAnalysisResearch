<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Visual Saliency with Discriminancy, Sparsity and Connectivity</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2012</AwardEffectiveDate>
<AwardExpirationDate>12/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>135742.00</AwardTotalIntnAmount>
<AwardAmount>135742</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project explores new directions to solving top-down modulated visual saliency maps with three basic principles: discriminancy, sparsity and connectivity. The research identifies key factors for advancing the state-of-the-art and presents a novel latent variable model, which extends the classical conditional random field with an embedded layer of latent variables to exploit the sparsity nature of features for saliency maps. This sparse latent variable conditional random filed model can be considered as a joint optimization of group sparse coding and conditional random field, which can be solved with an efficient stochastic gradient descent algorithm.  Unlike bottom-up saliency, this model facilities high-level visual recognition tasks by learning sparse image structures from objects of interest. The key intellectual contributions of this project are a novel formulation that considers all three important properties for visual saliency in a unified framework, and an efficient learning algorithm to estimate the model parameters. &lt;br/&gt;&lt;br/&gt;With the developed techniques, the search regions of these vision tasks can be constrained and thereby reduce the computational complexity and enhancing robustness. Effective top-down modulated visual saliency algorithms have broad applications including object detection, object recognition, visual tracking, scene analysis, image compression, surveillance, and robotics. It also provides a crucial tool for studying and analyzing fixations of eye movements in cognitive science. The research results including code and data are made public on the project web site.</AbstractNarration>
<MinAmdLetterDate>08/26/2011</MinAmdLetterDate>
<MaxAmdLetterDate>02/09/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1152576</AwardID>
<Investigator>
<FirstName>Ming-Hsuan</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ming-Hsuan Yang</PI_FULL_NAME>
<EmailAddress>mhyang@ucmerced.edu</EmailAddress>
<PI_PHON>2092284318</PI_PHON>
<NSF_ID>000508933</NSF_ID>
<StartDate>08/26/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California - Merced</Name>
<CityName>Merced</CityName>
<ZipCode>953435001</ZipCode>
<PhoneNumber>2092012039</PhoneNumber>
<StreetAddress>5200 North Lake Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA16</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>113645084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, MERCED</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California - Merced]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>953435001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>16</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA16</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~135742</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">One of the most important problems in computational or biological perception is visual information overload. Without filtering out extraneous signals, it would be computationally expensive to process all the incoming information. Perceptual saliency is of great importance with survival relevance for animals to make decisions on regions for further visual processing. In computer vision, one of the long standing questions is to develop algorithms in order to focus on salient regions for efficient and effective image understanding. In a visual scene, is a particular object present or not? If yes, where is this object likely to appear? If it is moving, how can we predict its location in the next frame? When the scenes are relatively simple and the object appearance does not vary significantly, the state-of-the-art computer vision systems are able to handle these questions reasonably well. However, the real-world scenes are usually highly cluttered and the object appearance constantly changes as a result of variation in poses and illumination. Not surprisingly, those questions are answered by the human vision system. How does the human vision system handle the interference of cluttered background and accomplish the above-mentioned visual tasks effortlessly? Research work in neuroscience brings forth some answers to these questions with models for saliency map and visual attention mechanism</p> <p>In this project, we have developed effective methods to analyze salient objects using top-down contextual information. With the developed methods, we are able to detect objects of interest in scenes even when they are heavily occluded. Such algorithms are useful for further analysis (e.g., object category) with numerous applications (e.g., surveillance and autonomous driving). In addition, we have also carried out extensive experiments to evaluate the state-of-the-art saliency detection methods. The developed algorithms and source codes are available on the PI's web.&nbsp;</p><br> <p>            Last Modified: 02/04/2016<br>      Modified by: Ming-Hsuan&nbsp;Yang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[One of the most important problems in computational or biological perception is visual information overload. Without filtering out extraneous signals, it would be computationally expensive to process all the incoming information. Perceptual saliency is of great importance with survival relevance for animals to make decisions on regions for further visual processing. In computer vision, one of the long standing questions is to develop algorithms in order to focus on salient regions for efficient and effective image understanding. In a visual scene, is a particular object present or not? If yes, where is this object likely to appear? If it is moving, how can we predict its location in the next frame? When the scenes are relatively simple and the object appearance does not vary significantly, the state-of-the-art computer vision systems are able to handle these questions reasonably well. However, the real-world scenes are usually highly cluttered and the object appearance constantly changes as a result of variation in poses and illumination. Not surprisingly, those questions are answered by the human vision system. How does the human vision system handle the interference of cluttered background and accomplish the above-mentioned visual tasks effortlessly? Research work in neuroscience brings forth some answers to these questions with models for saliency map and visual attention mechanism  In this project, we have developed effective methods to analyze salient objects using top-down contextual information. With the developed methods, we are able to detect objects of interest in scenes even when they are heavily occluded. Such algorithms are useful for further analysis (e.g., object category) with numerous applications (e.g., surveillance and autonomous driving). In addition, we have also carried out extensive experiments to evaluate the state-of-the-art saliency detection methods. The developed algorithms and source codes are available on the PI's web.        Last Modified: 02/04/2016       Submitted by: Ming-Hsuan Yang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
