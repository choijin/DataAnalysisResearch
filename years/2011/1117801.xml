<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Small: Manipulating Perceptions of Robot Agency</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Robots are increasingly becoming a part of daily human interactions: They vacuum floors, deliver medicine in hospitals, and provide company for elderly and disabled individuals. This project examines one aspect of people's interactions with these robots: how intentional and self-reflective the robot seems to be. Because the perceived agency of a robot affects many dimensions of people's interactions with that robot, it is important to understand how features of robot design, such as its behavior and cognitive abilities, affect perceptions of agency.  This question is addressed through a series of laboratory experiments that manipulate behavior and cognitive abilities and measure the degree of agency attributed to socially interactive robots.&lt;br/&gt;&lt;br/&gt;Intellectual merit: The project will lead to new measures of perceived robot agency and new knowledge about how people collaborate with robots. The results will inform how engineers construct robots, how artificial intelligence researchers conceptualize behavioral architectures, and how designers craft interactions to produce robots that engage people in simple ways.&lt;br/&gt;&lt;br/&gt;Broader impacts: The project will provide a new quantitative measurement of agency that can be used in human-robot interaction and related disciplines and new information that can inform how agency is modeled in the design of human-robot interactions, especially in situations where recognition of agency is a primary factor.  The outcomes will be used to improve socially assistive robotics for children with social deficits. The project will also enhance interdisciplinary research offerings for graduate and undergraduate students at the investigators' institution.</AbstractNarration>
<MinAmdLetterDate>08/05/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1117801</AwardID>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Scassellati</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian M Scassellati</PI_FULL_NAME>
<EmailAddress>brian.scassellati@yale.edu</EmailAddress>
<PI_PHON>2034321246</PI_PHON>
<NSF_ID>000197372</NSF_ID>
<StartDate>08/05/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>New Haven</CityName>
<ZipCode>065208327</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>Office of Sponsored Projects</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 208327]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>043207562</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>YALE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>043207562</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Yale University]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065208327</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Projects]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our perceptual systems divide the world into social agents (things which can have goals, desires, and beliefs) and inanimate objects (which do not).&nbsp; Robots occupy a unique middle-ground; at times, robots can be perceived as social agents while at other times, they appear to be nothing more than inanimate machines.</p> <p>&nbsp;</p> <p>One of the primary design considerations that must be taken in building technology is whether to encourage interpretation of the robot as a social agent or as an inanimate object.&nbsp; There are times when we desire robots to be social; social agents simplify interactions, are more engaging than non-social objects, and result in greater opportunities for collaboration. There are other times though when we want our robots to be simply inanimate tools; we don't want to feel bad that we put them into storage, and we don't want to feel awkward having a robot in the room while we change our clothes.</p> <p>&nbsp;</p> <p>Animators and artists have known for centuries how effective motion can be in generating this perception of social agency.&nbsp; This low-level perceptual cue is simple and effective, but is often ephemeral; the perception fades rapidly as soon as the object comes to rest.&nbsp; In our previous work (Short et al., 2011), we demonstrated that a high-level cognitive cue could generate a similar perception of animacy but with long-lasting impact.&nbsp; In this study, a robot and a person played a simple game.&nbsp; After many games, the robot would spontaneously cheat to win this game.&nbsp; At that moment, the robot would become a social agent and this perception would persist even when evidence to the contrary was presented.</p> <p>&nbsp;</p> <p>Under this funding, we attempted to further understand both how this attribution of agency could be generated by cognitive cues and to understand how these effects differ from more traditional motion-based attributions of agency.&nbsp; Our work uncovered three principle results:</p> <p>&nbsp;</p> <p>1)&nbsp;&nbsp;&nbsp;&nbsp; Our evidence suggests that robots trigger a specialized detector in humans that responds selectively to cheating, as opposed to motions that change the outcome of an event.&nbsp; To show this, we demonstrated that a robot that &ldquo;throws&rdquo; a match by changing from a winning position to a losing position does not trigger an attribution of agency.</p> <p>2)&nbsp;&nbsp;&nbsp;&nbsp; Attributions of agency and animacy can be triggered purely from motion characteristics, without reference to, or even in spite of, human-like appearance.</p> <p>3)&nbsp;&nbsp;&nbsp;&nbsp; Contrary to cheating actions made by humans, cheating actions in robots enhance our assessment of the intelligence and capability of robots.</p> <p>&nbsp;</p> <p>Our efforts with this award have enhanced the ability of robot designers to construct engaging, animate robots, a capability that is fundamental to larger efforts to build educational and therapeutic robot systems.</p><br> <p>            Last Modified: 02/25/2015<br>      Modified by: Brian&nbsp;M&nbsp;Scassellati</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our perceptual systems divide the world into social agents (things which can have goals, desires, and beliefs) and inanimate objects (which do not).  Robots occupy a unique middle-ground; at times, robots can be perceived as social agents while at other times, they appear to be nothing more than inanimate machines.     One of the primary design considerations that must be taken in building technology is whether to encourage interpretation of the robot as a social agent or as an inanimate object.  There are times when we desire robots to be social; social agents simplify interactions, are more engaging than non-social objects, and result in greater opportunities for collaboration. There are other times though when we want our robots to be simply inanimate tools; we don't want to feel bad that we put them into storage, and we don't want to feel awkward having a robot in the room while we change our clothes.     Animators and artists have known for centuries how effective motion can be in generating this perception of social agency.  This low-level perceptual cue is simple and effective, but is often ephemeral; the perception fades rapidly as soon as the object comes to rest.  In our previous work (Short et al., 2011), we demonstrated that a high-level cognitive cue could generate a similar perception of animacy but with long-lasting impact.  In this study, a robot and a person played a simple game.  After many games, the robot would spontaneously cheat to win this game.  At that moment, the robot would become a social agent and this perception would persist even when evidence to the contrary was presented.     Under this funding, we attempted to further understand both how this attribution of agency could be generated by cognitive cues and to understand how these effects differ from more traditional motion-based attributions of agency.  Our work uncovered three principle results:     1)     Our evidence suggests that robots trigger a specialized detector in humans that responds selectively to cheating, as opposed to motions that change the outcome of an event.  To show this, we demonstrated that a robot that "throws" a match by changing from a winning position to a losing position does not trigger an attribution of agency.  2)     Attributions of agency and animacy can be triggered purely from motion characteristics, without reference to, or even in spite of, human-like appearance.  3)     Contrary to cheating actions made by humans, cheating actions in robots enhance our assessment of the intelligence and capability of robots.     Our efforts with this award have enhanced the ability of robot designers to construct engaging, animate robots, a capability that is fundamental to larger efforts to build educational and therapeutic robot systems.       Last Modified: 02/25/2015       Submitted by: Brian M Scassellati]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
