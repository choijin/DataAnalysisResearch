<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CGV: Small: Collaborative Research: AdaCID: Adaptive Coded Imaging and Displays</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This is a collaborative project leveraging expertise of Ashok Veeraraghavan, William Marsh Rice University (IIS-1116718) and Ramesh Raskar, Massachusetts Institute of Technology (IIS-1116452).  Imaging and display devices are all around us and are used in a variety of applications. The spatial resolution, depth range, depth resolution, temporal resolution, frame-rate and bandwidth of these devices are usually fixed a priori. When the resolution and other properties of the content being imaged or displayed does not exactly mimic those that were assumed a priori, this leads to inefficiencies (in utilizing available resources) and undesirable artifacts (aliasing, blurring and noise). Since both imaging and display devices are fast becoming multi-purpose, there is a need to develop imaging and display architectures (and algorithms) that are capable of adapting their resolution and bandwidth characteristics to match those of the content.&lt;br/&gt;&lt;br/&gt;The goal of this project is to develop imaging and display devices that adapt to scene, motion, geometry, viewer, or illumination conditions. Such adaptive devices lead to performance improvements and novel capabilities hitherto unexplored. This research agenda is organized into four intellectual thrusts: (1) the establishment a theoretical framework for Adaptive Coded Imaging and Displays (AdaCID) that enables efficient exploration of the space of designs (2) the design of adaptive coded imaging systems that adapt to scene geometry, motion, and illumination (3) the design of adaptive and interactive coded 2D/3D displays that adapt in real-time to content, viewer position, and the human visual system enhancing visual appearance and allowing intuitive 3D interaction and (4) the demonstration of coded feedback projector-camera systems enabling rapid acquisition of range and material characteristics.&lt;br/&gt;&lt;br/&gt;It is expected that AdaCID will have far-reaching impact to diverse applications spanning consumer imaging and displays, machine vision and automation, scientific/medical imaging and displays and surveillance. Since AdaCID and the broader field of computational imaging and displays is increasingly important, they will be integrated into various courses offered at Rice University and MIT. Broad dissemination of the educational material will be achieved through participation in the free, open-licensed Connexions program and OpenCourseWare and in public-domain museum initiatives (at the MIT Museum). This project also offers collaborative research opportunities for students at the two institutions. Project Website (http://cameraculture.media.mit.edu/AdaCID/) provides additional information.</AbstractNarration>
<MinAmdLetterDate>08/06/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116452</AwardID>
<Investigator>
<FirstName>Ramesh</FirstName>
<LastName>Raskar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ramesh Raskar</PI_FULL_NAME>
<EmailAddress>raskar@media.mit.edu</EmailAddress>
<PI_PHON>6172530329</PI_PHON>
<NSF_ID>000502041</NSF_ID>
<StartDate>08/06/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 MASSACHUSETTS AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>Optical display and capture techniques continue to play an increasing role in the way people in technical societies interact with general-purpose computation. Within this project we developed imaging and display devices that adapt to scene, motion, geometry, viewer or illumination conditions. Specifically, we developed a switchable light field camera architecture based on a novel CMOS architecture known as angle sensitive pixels has shown the possibility of achieving high resolution single shot images without compromising 2D image quality. We created a compressive light field projection system that completes a highly recognized series of papers detailing the application of the tensor display framework to high resolution light field display across displays, theoretically ranging in physical size from smart phones to theaters. Additionally, we have shown that it is possible to create vision correcting 2D displays that maintain high contrast and high-resolution using methods inspired by the tensor display framework.&nbsp;We published the technical framework and research results in top tier journals and conferences, and received a best paper award at ICCP 2014.</p> <p>The fundamentals developed, e.g. improved light field sensors and displays, could impact diverse fields such as biology (microscopy), manufacturing (e.g. improved quality control), entertainment (virtual reality, augmented reality, telepresence), health (diagnostics) and many others.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/20/2015<br>      Modified by: Ramesh&nbsp;Raskar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    Optical display and capture techniques continue to play an increasing role in the way people in technical societies interact with general-purpose computation. Within this project we developed imaging and display devices that adapt to scene, motion, geometry, viewer or illumination conditions. Specifically, we developed a switchable light field camera architecture based on a novel CMOS architecture known as angle sensitive pixels has shown the possibility of achieving high resolution single shot images without compromising 2D image quality. We created a compressive light field projection system that completes a highly recognized series of papers detailing the application of the tensor display framework to high resolution light field display across displays, theoretically ranging in physical size from smart phones to theaters. Additionally, we have shown that it is possible to create vision correcting 2D displays that maintain high contrast and high-resolution using methods inspired by the tensor display framework. We published the technical framework and research results in top tier journals and conferences, and received a best paper award at ICCP 2014.  The fundamentals developed, e.g. improved light field sensors and displays, could impact diverse fields such as biology (microscopy), manufacturing (e.g. improved quality control), entertainment (virtual reality, augmented reality, telepresence), health (diagnostics) and many others.             Last Modified: 10/20/2015       Submitted by: Ramesh Raskar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
