<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Software Cache Memory Managements with Reconfigurable Hardware Emulators</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>360345.00</AwardTotalIntnAmount>
<AwardAmount>360345</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As multi-core systems become the major computing platform, efficient cache management is even more crucial to system performance and power efficiency than before.  An effective approach is to use software cache management (SCM) with hardware supports to manage shared last-level cache, because sophisticated SCM may adapt to the complex scenarios of cache usage on multi-core processors.&lt;br/&gt;&lt;br/&gt;A critical and unsolved issue in SCM is the lack of rich and relevant information for software to reason about cache performance under different configurations. The project investigates the use of lightweight and Reconfigurable hardware Cache Emulators (RCEs) to extend the capability of SCM. With this new hardware support, sophisticated SCM algorithms that constantly monitor cache usage through RCEs are developed. Those SCM algorithms aim to improve cache power efficiency by turning off unused cache portion, optimize cache partitioning for multi-core processors, and improve software-controlled cache mapping to improve cache utilization.&lt;br/&gt;&lt;br/&gt;The research will improve system performance, power efficiency, and performance predictability for laptop, desktop and server computers using multi-core processors of large shared caches. It may make an impact on industry processor design to include lightweight RCEs as well as enrich SCM algorithms. It will also introduce new educational materials for students to study multicore cache management through hand-on experiments.</AbstractNarration>
<MinAmdLetterDate>07/06/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1117604</AwardID>
<Investigator>
<FirstName>Zhao</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhao Zhang</PI_FULL_NAME>
<EmailAddress>zhangz@uic.edu</EmailAddress>
<PI_PHON>3129963420</PI_PHON>
<NSF_ID>000243180</NSF_ID>
<StartDate>07/06/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Iowa State University</Name>
<CityName>AMES</CityName>
<ZipCode>500112207</ZipCode>
<PhoneNumber>5152945225</PhoneNumber>
<StreetAddress>1138 Pearson</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<StateCode>IA</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IA04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005309844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005309844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Iowa State University]]></Name>
<CityName>AMES</CityName>
<StateCode>IA</StateCode>
<ZipCode>500112207</ZipCode>
<StreetAddress><![CDATA[1138 Pearson]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IA04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~360345</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we have explored a combination of lightweight hardware support and new software management methods to improve the performance and energy efficiency of computer cache and memory. This approach only requires simple hardware extension in processors and memory controllers but enables efficient software management of cache and memory. We have demonstrated that this approach is as effective as hardware-only approach, which usually leads to complex hardware implementation and lacks the flexibility that software management can provide.</p> <p>A core idea of this research is to use a hardware profiling unit to estimate the cache miss rates of multiple cache configurations for the current phase of computing, but without immediate changes to cache configuration. Then, a prediction model is used to predict the system performance and/or power efficiency under each configuration. If the best configuration of those is measurably better than the current and actual cache configuration, this cache configuration will become the actual cache configuration for the next phase of computing. The prediction model is implemented in a system software module, and we have also proposed lightweight hardware design for dynamic cache re-configuration.</p> <p>In a preliminary study, we have used this approach to improve the cache performance of multi-core processor. We have shown that, on a simulated multi-core computer, it may improve performance significantly over conventional cache design in commercially available processors. We further use this approach to improve the energy efficiency of cache by turning off part of the cache to save energy. Using sophisticated models, we have shown that we can achieve the best balance between performance and energy efficiency for different optimization targets and various workloads. As extensions of this project, we have also studied new cache and memory reliability schemes and compressed memory design, which may also improve performance and/or energy efficiency.</p> <p>With the support of this project, we have published over ten research papers in renowned forums, including International Conference on Computer Design, International Conference on VLSI Design, International Symposium on Computer Architecture, ACM Transactions on Architecture and Code, and Journal of Circuits, Systems, and Computers.</p> <p>&nbsp;</p><br> <p>            Last Modified: 02/01/2017<br>      Modified by: Zhao&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we have explored a combination of lightweight hardware support and new software management methods to improve the performance and energy efficiency of computer cache and memory. This approach only requires simple hardware extension in processors and memory controllers but enables efficient software management of cache and memory. We have demonstrated that this approach is as effective as hardware-only approach, which usually leads to complex hardware implementation and lacks the flexibility that software management can provide.  A core idea of this research is to use a hardware profiling unit to estimate the cache miss rates of multiple cache configurations for the current phase of computing, but without immediate changes to cache configuration. Then, a prediction model is used to predict the system performance and/or power efficiency under each configuration. If the best configuration of those is measurably better than the current and actual cache configuration, this cache configuration will become the actual cache configuration for the next phase of computing. The prediction model is implemented in a system software module, and we have also proposed lightweight hardware design for dynamic cache re-configuration.  In a preliminary study, we have used this approach to improve the cache performance of multi-core processor. We have shown that, on a simulated multi-core computer, it may improve performance significantly over conventional cache design in commercially available processors. We further use this approach to improve the energy efficiency of cache by turning off part of the cache to save energy. Using sophisticated models, we have shown that we can achieve the best balance between performance and energy efficiency for different optimization targets and various workloads. As extensions of this project, we have also studied new cache and memory reliability schemes and compressed memory design, which may also improve performance and/or energy efficiency.  With the support of this project, we have published over ten research papers in renowned forums, including International Conference on Computer Design, International Conference on VLSI Design, International Symposium on Computer Architecture, ACM Transactions on Architecture and Code, and Journal of Circuits, Systems, and Computers.          Last Modified: 02/01/2017       Submitted by: Zhao Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
