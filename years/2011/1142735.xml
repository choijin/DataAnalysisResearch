<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Online High Fidelity 3D Modeling of Produce Using Low Cost Sensors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2012</AwardExpirationDate>
<AwardTotalIntnAmount>145485.00</AwardTotalIntnAmount>
<AwardAmount>145485</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project investigates the feasibility of employing high?resolution, colorized, 3D models of food produce captured with structured light technology to identify (ID) and sort produce by quality. The feasibility of accomplishing this within the real-time constraints of in-field harvesting will be determined. The PROBLEM being addressed is that high fidelity modeling currently requires controlled calibration and acquisition processes, expensive sensor hardware and time consuming global optimization algorithms taking minutes, or hours, to complete. The proposed APPROACH is to research novel processing algorithms to extend 2D super-resolution principles and exploit new probabilistic motion and sensor error models to achieve precise multi-frame registration and fast global optimization. This research will exploit new methods which operate on smaller clusters of ?similar? pixels and leverage 3D probabilistic occupancy mappings, taking advantage of imaging and geometry features simultaneously to reduce computation time and noise. If achievable, the BENEFITS include development of a cost-effective and feature-rich advanced data modeling technology that can be integrated into produce collection machinery and used to cost-effectively segment individual food items based on cosmetic imperfections. This is expected to provide both reduced costs and increased revenues to small and medium farm enterprises.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project addresses two areas: 1) a critical gap within domestic produce farming which prevents small farmers from competing with large, corporate enterprise farms in terms of efficiency, quality control and product pricing and 2) a very real advance in the broader area of sensor systems and technology. Although a distributed, low cost modeling and sorting application for fruits and vegetables is targeted in Phase I, the technology should provide similar benefits to the broader consumer foods market by improving the distribution and sorting of meats, seafood, cheeses or even baked goods, and the like, while also advancing many other areas that can benefit from good ID and sorting technology. At the very least, this cost effective, automated, sorting capability is expected to increase small farm revenues by at least 25% and provide the offeror with a burgeoning, worldwide business through its strategic partners. In addition, such an affordable, and fast, 3D data modeling and inspection technology for accurately categorizing geometric defects can be expected to have a much broader impact within the field of data modeling and inspection.</AbstractNarration>
<MinAmdLetterDate>11/28/2011</MinAmdLetterDate>
<MaxAmdLetterDate>11/28/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1142735</AwardID>
<Investigator>
<FirstName>Parag</FirstName>
<LastName>Batavia</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Parag Batavia</PI_FULL_NAME>
<EmailAddress>paragb@neyasystems.com</EmailAddress>
<PI_PHON>7247998078</PI_PHON>
<NSF_ID>000591854</NSF_ID>
<StartDate>11/28/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Neya Systems, LLC</Name>
<CityName>Wexford</CityName>
<ZipCode>150908319</ZipCode>
<PhoneNumber>7247998078</PhoneNumber>
<StreetAddress>12330 Perry Hwy</StreetAddress>
<StreetAddress2><![CDATA[Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>831883868</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEYA SYSTEMS, LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097967608</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Neya Systems, LLC]]></Name>
<CityName>Wexford</CityName>
<StateCode>PA</StateCode>
<ZipCode>150908319</ZipCode>
<StreetAddress><![CDATA[12330 Perry Hwy, Suite 220]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~145485</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br /><br /></p> <p>The majority of produce quality-grading systems today use<br />color and other multi-spectral 2D image features as criteria by which to sort<br />food items. They set experimentally defined thresholds on features such as<br />color, color-based textures and intensities, to classify per-pixel segments of<br />the produce as good or bad. While this technique has shown success when<br />tailored to a specific type of produce, classification accuracy suffers when<br />the system is presented with a wider variety of fruits and vegetables that vary<br />in size, shape, roughness and topology (stem, pulp, skin, calyx). However,<br />trained harvesters typically use shape as an important consideration when<br />evaluating produce to detect cosmetic abnormalities which can be unappealing to<br />consumer markets and can indicate disease. In some cases, processing facilities<br />can require produce to meet specific geometric criteria to efficiently be<br />processed by their machinery. Understanding the shape of the produce will<br />assist farmers in identifying the appropriate market into which the food item<br />should be sold. Understanding and leveraging 3D shape and geometry of produce<br />will allow sorting algorithms to better detect and classify these cosmetic<br />abnormalities.</p> <p><br /><br /></p> <p>To address this challenge, Neya Systems, LLC has developed a<br />software process that extends 2D super-resolution principles and generates<br />accurate high-resolution 3D color models of produce using inexpensive<br />commercial off-the-shelf (COTS) structured light sensing hardware. The feature-rich<br />data models resulting from this process can be integrated into turnkey portable<br />solutions, commoditizing inspection processes and improving quality control for<br />small local farms and collectives.</p> <p><br /><br /></p> <p>Based on this Phase I research and analysis, we have shown<br />that individual high resolution splices of the models generated using this<br />software can be created and classified within real-time constraints of standard<br />sorting processes, averaging 10-15 frames per second for our smallest food item<br />on a standard Intel core i7 processor. This includes the ability to accurately<br />track motion precisely over a half meter scanning trajectory. The resulting<br />models are not only much higher resolution (with an average of 0.5 mm spacing<br />between pixels) but also show a 1.9x improvement in the average geometric<br />accuracy of the model when compared to a micron-precision baseline model. Based<br />on our preliminary analysis of using the high resolution model splices for<br />quality classification, we found that shape features not only add to the<br />overall accuracy of classification, but for this specific set of features<br />actually outperforms the color-based classification in every case. While the<br />training data sets are too small to provide conclusive results at this stage,<br />this certainly motivates the case for continued research with additional<br />features (both shape and color) as well as more sophisticated classification<br />techniques as applied to high resolution color 3D data models.</p><br> <p>            Last Modified: 07/11/2012<br>      Modified by: Parag&nbsp;Batavia</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2012/1142735/1142735_10143790_1342037991854_summaryImage--rgov-214x142.jpg" original="/por/images/Reports/POR/2012/114273...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[     The majority of produce quality-grading systems today use color and other multi-spectral 2D image features as criteria by which to sort food items. They set experimentally defined thresholds on features such as color, color-based textures and intensities, to classify per-pixel segments of the produce as good or bad. While this technique has shown success when tailored to a specific type of produce, classification accuracy suffers when the system is presented with a wider variety of fruits and vegetables that vary in size, shape, roughness and topology (stem, pulp, skin, calyx). However, trained harvesters typically use shape as an important consideration when evaluating produce to detect cosmetic abnormalities which can be unappealing to consumer markets and can indicate disease. In some cases, processing facilities can require produce to meet specific geometric criteria to efficiently be processed by their machinery. Understanding the shape of the produce will assist farmers in identifying the appropriate market into which the food item should be sold. Understanding and leveraging 3D shape and geometry of produce will allow sorting algorithms to better detect and classify these cosmetic abnormalities.      To address this challenge, Neya Systems, LLC has developed a software process that extends 2D super-resolution principles and generates accurate high-resolution 3D color models of produce using inexpensive commercial off-the-shelf (COTS) structured light sensing hardware. The feature-rich data models resulting from this process can be integrated into turnkey portable solutions, commoditizing inspection processes and improving quality control for small local farms and collectives.      Based on this Phase I research and analysis, we have shown that individual high resolution splices of the models generated using this software can be created and classified within real-time constraints of standard sorting processes, averaging 10-15 frames per second for our smallest food item on a standard Intel core i7 processor. This includes the ability to accurately track motion precisely over a half meter scanning trajectory. The resulting models are not only much higher resolution (with an average of 0.5 mm spacing between pixels) but also show a 1.9x improvement in the average geometric accuracy of the model when compared to a micron-precision baseline model. Based on our preliminary analysis of using the high resolution model splices for quality classification, we found that shape features not only add to the overall accuracy of classification, but for this specific set of features actually outperforms the color-based classification in every case. While the training data sets are too small to provide conclusive results at this stage, this certainly motivates the case for continued research with additional features (both shape and color) as well as more sophisticated classification techniques as applied to high resolution color 3D data models.       Last Modified: 07/11/2012       Submitted by: Parag Batavia]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
