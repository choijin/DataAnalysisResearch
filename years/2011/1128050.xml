<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Adaptive Dynamic Programming for Real-Time Cooperative Multi-Player Games and Graphical Games</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>272730.00</AwardTotalIntnAmount>
<AwardAmount>272730</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The Objective of this research is to design new algorithms for decision and control in multi-player games for complex human-engineered systems interacting on communication graph topologies.  Standard differential game solutions are for systems with a single dynamics and multiple action inputs.  However, realistic systems are composed of agents having their own individual dynamics and only interacting with their immediate neighbors in a social graph topology.  The Approach is to bring together discoveries in neurobiological learning, sociobiological systems having local interactions between agents, and multi-player differential games to develop novel feedback control structures for nonlinear dynamical systems.  &lt;br/&gt;&lt;br/&gt;Intellectual Merit.  Standard differential game theory solutions are generally offline design methods that rely on solving nonlinear design equations requiring knowledge of full system dynamics. Approximate Dynamic Programming techniques based on reinforcement learning will be used to develop novel adaptive control structures that learn game theory solutions online in real time using data measured along the system trajectories and without knowing full system dynamics.  Solutions for different definitions of game equilibria will be sought including Nash, Pareto, Nash bargaining, and cooperative games.&lt;br/&gt;&lt;br/&gt;Broader Impacts.  The research will help bridge the gap between the Computational Intelligence and the Control Systems communities by bringing together reinforcement learning, game theory, and differential dynamical systems.  Applications will be made to cooperative control of distributed electric power microgrids for renewable energy such as wind and solar generation.  Existing programs at UTA will be expanded in women in engineering, research for US students, high school engineering technology, and K-12 outreach.</AbstractNarration>
<MinAmdLetterDate>07/22/2011</MinAmdLetterDate>
<MaxAmdLetterDate>12/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1128050</AwardID>
<Investigator>
<FirstName>Frank</FirstName>
<LastName>Lewis</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Frank L Lewis</PI_FULL_NAME>
<EmailAddress>lewis@uta.edu</EmailAddress>
<PI_PHON>8172725972</PI_PHON>
<NSF_ID>000257326</NSF_ID>
<StartDate>07/22/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ali</FirstName>
<LastName>Davoudi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ali Davoudi</PI_FULL_NAME>
<EmailAddress>davoudi@uta.edu</EmailAddress>
<PI_PHON>8172722105</PI_PHON>
<NSF_ID>000565785</NSF_ID>
<StartDate>12/20/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Arlington</Name>
<CityName>Arlington</CityName>
<ZipCode>760190145</ZipCode>
<PhoneNumber>8172722105</PhoneNumber>
<StreetAddress>701 S Nedderman Dr, Box 19145</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>064234610</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT ARLINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UTA Automation & Robotics Research Inst.]]></Name>
<CityName>Ft Worth</CityName>
<StateCode>TX</StateCode>
<ZipCode>761187115</ZipCode>
<StreetAddress><![CDATA[7300 Jack Newell Blvd S]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>155E</Code>
<Text>Electric power networks</Text>
</ProgramReference>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~272730</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This NSF grant entitled &ldquo;Adaptive Dynamic Programming for Real-Time Cooperative Multi-Player Games and Graphical Games&rdquo; was funded for the years 2011-2015.&nbsp; Researchers at The University of Texas at Arlington, led by F. Lewis and A. Davoudi, put together a multidisciplinary team of students and collaborated with international colleagues from Europe, China, Hong Kong, and Singapore to develop new structures of Automatic Feedback Control Systems.&nbsp; The goals of this grant are to use new mechanisms for decision-making observed in the human brain to build better automatic feedback controllers that can be used for aircraft autopilots, vehicle emission control, freeway traffic platooning, satellite mapping and imagery control, and elsewhere.&nbsp; Feedback Control is a principle that has been developed and refined throughout human history, culminating in the Industrial Revolution in the 1780s and the Aerospace/Computer/Robotics revolution since the 1970s, to better control our machines and deliver smoother more efficient performance with less use of resources.&nbsp; This grant particularly developed a new class of Feedback Control Systems that delivers guaranteed Optimal performance in the sense of completing objectives using less fuel, less time, less energy, or other quantifiable performance metrics.&nbsp; These systems are characterized by a two-loop feedback structure wherein an inner action loop learns a control policy and an outer critic loop computes the optimality value of that control.&nbsp; The action and critic networks learn simultaneously to best adjust the control applied to the system so as to minimize an optimality index depending on the system performance that is prescribed by the user.&nbsp; These methods extended a technique known as Reinforcement Learning that is based on the way in which natural biological species and organisms adapt to their environments.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One aspect of the research developed new methods for many dynamical agents to coordinate their actions so as to achieve an overall global team goal.&nbsp; The theory of multi-player games was extended to take into account the communications channels available to the agents in the design of their individual feedback control systems.&nbsp; The result is guaranteed optimal performance of the overall team based on the coordinated individual actions of each agent.&nbsp; Applications are to multi-vehicle formation control, industrial manufacturing control with multiple processes, and so on.</p> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The NSF research results developed under this grant were applied to develop new improved controllers for renewable energy microgrids that allow more robust and faster responses to power load changes and wind and solar energy fluctuations.&nbsp; A US patent was issued in 2015- &ldquo;Control methodology for online adaptation to optimal feedback controller using Integral Reinforcement Learning,&rdquo; developed with Draguna Vrabie at United Technologies Research Center and K. Vamvoudakis at UC Santa Barbara. Our Integral Reinforcement Learning (IRL) research results were transitioned to industry for faster improved control of industrial processes with colleagues in Singapore and China.&nbsp; Our results about multi-player learning interactions were transitioned to US Army TARDEC for better, safer decision and control in mixed teams of humans and autonomous machines.&nbsp; Numerous USA, female, and minority students were trained in Science, Technology, Engineering, and Math (STEM) disciplines to contribute productively to USA Society, academia, and industry.&nbsp; Three books and numerous scientific articles were published to disseminate the new scientific knowledge discovered over the course of this grant.&nbsp; Numerous invited keynote talks were delive...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This NSF grant entitled "Adaptive Dynamic Programming for Real-Time Cooperative Multi-Player Games and Graphical Games" was funded for the years 2011-2015.  Researchers at The University of Texas at Arlington, led by F. Lewis and A. Davoudi, put together a multidisciplinary team of students and collaborated with international colleagues from Europe, China, Hong Kong, and Singapore to develop new structures of Automatic Feedback Control Systems.  The goals of this grant are to use new mechanisms for decision-making observed in the human brain to build better automatic feedback controllers that can be used for aircraft autopilots, vehicle emission control, freeway traffic platooning, satellite mapping and imagery control, and elsewhere.  Feedback Control is a principle that has been developed and refined throughout human history, culminating in the Industrial Revolution in the 1780s and the Aerospace/Computer/Robotics revolution since the 1970s, to better control our machines and deliver smoother more efficient performance with less use of resources.  This grant particularly developed a new class of Feedback Control Systems that delivers guaranteed Optimal performance in the sense of completing objectives using less fuel, less time, less energy, or other quantifiable performance metrics.  These systems are characterized by a two-loop feedback structure wherein an inner action loop learns a control policy and an outer critic loop computes the optimality value of that control.  The action and critic networks learn simultaneously to best adjust the control applied to the system so as to minimize an optimality index depending on the system performance that is prescribed by the user.  These methods extended a technique known as Reinforcement Learning that is based on the way in which natural biological species and organisms adapt to their environments.              One aspect of the research developed new methods for many dynamical agents to coordinate their actions so as to achieve an overall global team goal.  The theory of multi-player games was extended to take into account the communications channels available to the agents in the design of their individual feedback control systems.  The result is guaranteed optimal performance of the overall team based on the coordinated individual actions of each agent.  Applications are to multi-vehicle formation control, industrial manufacturing control with multiple processes, and so on.              The NSF research results developed under this grant were applied to develop new improved controllers for renewable energy microgrids that allow more robust and faster responses to power load changes and wind and solar energy fluctuations.  A US patent was issued in 2015- "Control methodology for online adaptation to optimal feedback controller using Integral Reinforcement Learning," developed with Draguna Vrabie at United Technologies Research Center and K. Vamvoudakis at UC Santa Barbara. Our Integral Reinforcement Learning (IRL) research results were transitioned to industry for faster improved control of industrial processes with colleagues in Singapore and China.  Our results about multi-player learning interactions were transitioned to US Army TARDEC for better, safer decision and control in mixed teams of humans and autonomous machines.  Numerous USA, female, and minority students were trained in Science, Technology, Engineering, and Math (STEM) disciplines to contribute productively to USA Society, academia, and industry.  Three books and numerous scientific articles were published to disseminate the new scientific knowledge discovered over the course of this grant.  Numerous invited keynote talks were delivered by the Principal Investigators on an international venue.        Last Modified: 10/05/2015       Submitted by: Frank L Lewis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
