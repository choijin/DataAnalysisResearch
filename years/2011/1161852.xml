<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Temporal Stimulus Segmentation with Spiking Neurons</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>316236.00</AwardTotalIntnAmount>
<AwardAmount>316236</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Human beings have an unmatched ability to learn to abstract information from the environment, use this information to predict the consequences of their actions, and develop appropriate behavioral strategies. State-of-the-art artificial devices are far from exhibiting such autonomous learning abilities. This project focuses on a subset of the skills required for autonomous learning, specifically, the ability to identify the relevant cues and stimuli from the environment and establish how to act in their presence. In many situations, such as speech processing, this problem amounts to extracting temporally extended segments embedded in a continuous sensory stream of irrelevant stimuli and noise, a problem of temporal stimulus segmentation. Traditional algorithms for stimulus segmentation that learn based just on the unsegmented input stream are unlikely to succeed in this task, especially if the relevant segments do not exhibit features that are detectable by some standard pre-processing strategy. As a consequence, existing models typically endow a learning agent with prior knowledge of what is relevant (the so-called "states" of the agent) and focus on the problem of relating each state with the outcome they predict. Such models, of widespread use in computational neuroscience and machine learning, are unable to form or modify their own relevant states, preventing the development of truly autonomous learning and decision-making devices.&lt;br/&gt;&lt;br/&gt;This project aims to develop a biologically relevant solution to the problem of temporal stimulus segmentation, with a focus on foundational theory and principles. In this theory, the states are represented by spatio-temporal patterns of spike trains and are processed by a network of spiking neurons capable of online, spike-based learning. The network learns to segment the input stream by taking appropriate actions at the right time, using a spike-based synaptic plasticity rule that approximates gradient ascent on the average reward, and makes use of locally available information about the network's decision. Importantly, the relevant segments are constructed so as to be behaviorally meaningful but not statistically different from irrelevant stimuli and noise, and therefore their boundaries are not detectable by standard pre-processing techniques.&lt;br/&gt;&lt;br/&gt;Segmentation performance will be quantified as a function of the network's properties (such as number of neurons, connectivity and architecture) in the framework of different neurobiologically-inspired stimulus-coding schemes, and contrasted to more traditional approaches such as artificial neural networks and hidden Markov models. The research will be further enhanced by developing a hard challenge application related to natural stimuli, with the long-term goal of demonstrating the power and usefulness of the new approach compared to more traditional ones. This will also demonstrate that the network can be applied widely, across modalities (e.g., vision as well as speech), and in real-life scenarios.</AbstractNarration>
<MinAmdLetterDate>09/06/2012</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1161852</AwardID>
<Investigator>
<FirstName>Giancarlo</FirstName>
<LastName>La Camera</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Giancarlo La Camera</PI_FULL_NAME>
<EmailAddress>giancarlo.lacamera@stonybrook.edu</EmailAddress>
<PI_PHON>6316329109</PI_PHON>
<NSF_ID>000594097</NSF_ID>
<StartDate>09/06/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName>Stony Brook</CityName>
<StateCode>NY</StateCode>
<ZipCode>117945230</ZipCode>
<StreetAddress><![CDATA[Life Sciences Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~316236</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 5"> <div class="layoutArea"> <div class="column"> <p>Humans have an unmatched ability to extract information from the environment, use this information to predict the consequences of their actions, and develop appropriate behavioral strategies. Integral to this skill is the ability to identify relevant cues and stimuli in the environment. At the biophysical level, this requires neurons to analyze a continuous sensory stream, parse it to separate the irrelevant segments of the stream from the action-relevant ones, and trigger appropriate actions. Whereas a lot of effort has been devoted to understanding how responses to relevant events are generated, very little attention has been paid to the temporal segmentation of the input stream necessary to identify the occurrence of relevant events.</p> <p>The goal of this project was to develop a realistic neural network model able to solve this problem. In our proposed solution, populations of neurons receive and process an uninterrupted stream of neural activity in the form of spike trains &mdash; the sequences of action potentials through which neurons communicate. The network then learns to extract action-relevant stimuli and produce a desired (but initially unknown) response to them, while ignoring stimuli that are not behaviorally relevant. This is accomplished through a biologically plausible learning rule, which maximizes the long-term reward obtained for taking correct decisions at the right time, a form of reinforcement learning. The learning rule uses the activity locally present at synapses (the specialized structures connecting neurons) together with more global information on the reward and the agent&rsquo;s own decisions, a biologically realistic scenario. Learning is flexible with respect to specific input representations, is faster in larger networks (despite an increased difficulty in finding out which neurons deserve the credit for a correct decision), and capable of successfully segmenting real spike trains.&nbsp;</p> <p>Overall, in this project we have demonstrated how relevant stimuli embedded in a continuous stream of spike trains can be extracted by reinforcement learning. We have further discovered a novel form of learning, enabling agents to make decisions on stimuli not yet identified as relevant, and whose occurrence times are unknown. These findings further our understanding of learning and decision making, and could inspire the adoption of new machine learning methods based on spiking neurons (as opposed to artificial neural networks). We suggest that a shift towards spiking models might reduce the gap between the machine learning and neuroscience fields, possibly resulting in learning machines capable of more human-like intelligence.</p> <p>Throughout its development, this project has offered a spectrum of training possibilities for undergraduate and graduate students at Stony Brook University. These include a series of lectures and workshops on the application of mathematical methods to neuroscience, and an undergraduate course in theoretical neuroscience for students of biology, physics, applied math and related disciplines that has provided interdisciplinary training across separate colleges. Through this project, students have been recruited to neuroscience with the opportunity of training in both theoretical and experimental methods of neurobiology. Concepts at the interface of biology and math have been disseminated to communities not previously aware of these research activities, such as high school students attending 'math camp' at Stony Brook, college students at Nassau Community College, and part of the Physics community at Stony Brook University.</p> <p>&nbsp;</p> <br /> <p>&nbsp;</p> </div> </div> </div> </div> </div> </div><br> <p>            Last Modified: 12/06/2016<br>      Modified by: Giancarlo&nbsp;La Camera</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[       Humans have an unmatched ability to extract information from the environment, use this information to predict the consequences of their actions, and develop appropriate behavioral strategies. Integral to this skill is the ability to identify relevant cues and stimuli in the environment. At the biophysical level, this requires neurons to analyze a continuous sensory stream, parse it to separate the irrelevant segments of the stream from the action-relevant ones, and trigger appropriate actions. Whereas a lot of effort has been devoted to understanding how responses to relevant events are generated, very little attention has been paid to the temporal segmentation of the input stream necessary to identify the occurrence of relevant events.  The goal of this project was to develop a realistic neural network model able to solve this problem. In our proposed solution, populations of neurons receive and process an uninterrupted stream of neural activity in the form of spike trains &mdash; the sequences of action potentials through which neurons communicate. The network then learns to extract action-relevant stimuli and produce a desired (but initially unknown) response to them, while ignoring stimuli that are not behaviorally relevant. This is accomplished through a biologically plausible learning rule, which maximizes the long-term reward obtained for taking correct decisions at the right time, a form of reinforcement learning. The learning rule uses the activity locally present at synapses (the specialized structures connecting neurons) together with more global information on the reward and the agent?s own decisions, a biologically realistic scenario. Learning is flexible with respect to specific input representations, is faster in larger networks (despite an increased difficulty in finding out which neurons deserve the credit for a correct decision), and capable of successfully segmenting real spike trains.   Overall, in this project we have demonstrated how relevant stimuli embedded in a continuous stream of spike trains can be extracted by reinforcement learning. We have further discovered a novel form of learning, enabling agents to make decisions on stimuli not yet identified as relevant, and whose occurrence times are unknown. These findings further our understanding of learning and decision making, and could inspire the adoption of new machine learning methods based on spiking neurons (as opposed to artificial neural networks). We suggest that a shift towards spiking models might reduce the gap between the machine learning and neuroscience fields, possibly resulting in learning machines capable of more human-like intelligence.  Throughout its development, this project has offered a spectrum of training possibilities for undergraduate and graduate students at Stony Brook University. These include a series of lectures and workshops on the application of mathematical methods to neuroscience, and an undergraduate course in theoretical neuroscience for students of biology, physics, applied math and related disciplines that has provided interdisciplinary training across separate colleges. Through this project, students have been recruited to neuroscience with the opportunity of training in both theoretical and experimental methods of neurobiology. Concepts at the interface of biology and math have been disseminated to communities not previously aware of these research activities, such as high school students attending 'math camp' at Stony Brook, college students at Nassau Community College, and part of the Physics community at Stony Brook University.                     Last Modified: 12/06/2016       Submitted by: Giancarlo La Camera]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
