<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EFRI-M3C: Development of New Algorithmic Models and Tools to Enhance Neural Adaptation in Brain Computer Interface Systems.</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>1992456.00</AwardTotalIntnAmount>
<AwardAmount>1992456</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07040000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>EFMA</Abbreviation>
<LongName>Emerging Frontiers &amp; Multidisciplinary Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Human interaction with machines has always relied on some form of muscle movement to translate the brain's desired action to the machine (e.g. turning a knob). The objective of our project is to eliminate the need for muscle transformations in the man-machine interface. Using a new brain-computer  interface (BCI) technology (electrocorticography or ECoG) pioneered by the research team, we will  develop novel decoding algorithms to control the force/torque inputs to an external device directly.  Likewise, by designing machine learning algorithms to identify and incorporate neural plasticity in the  decoding schemes will allow the BCI to evolve over time. Finally, by combining brain signals from multiple areas to identify various brain states, we can identify and change the effectors to be controlled. &lt;br/&gt;&lt;br/&gt; Intellectual Merit: All previous BCI studies decoded only kinematic signals to control computer cursors as well as robotic limbs. While kinematic control is a natural extension for disabled individuals trying to regain function lost by paralysis or amputation, a direct interface between the brain and the machine allows for much more elegant interaction. Thus, rather than controlling a robotic arm through the  use of imagined self limb movements (a proxy of intention), one rather controls the device as if it was a  part of their own body. For instance, mapping brain activity to kinetic parameters such as a robot?s torque motor allows the individual to directly control the forceful interactions within the system.&lt;br/&gt;&lt;br/&gt; Broader Impact: One advantage of ECoG is that while it is an invasive recording technology,  the electrodes can be placed epidurally which significantly reduces the risk profile for implantation. In the long term, this should allow ECoG-based BCIs to be accepted as a viable implant in able-bodied humans. Developing a safe and effective BCI modality for the general public will fundamentally change how humans interact with machines. No longer will humans require muscle activity as an intermediary to interact with machines. A whole new field of man-machine interfacing will be initiated where the brain builds complex internal models of the machine's dynamics (instead of musculoskeletal dynamics) for accurate and direct control of the machine's effectors.</AbstractNarration>
<MinAmdLetterDate>09/01/2011</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1137211</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Moran</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel W Moran</PI_FULL_NAME>
<EmailAddress>dmoran@wustl.edu</EmailAddress>
<PI_PHON>3149358836</PI_PHON>
<NSF_ID>000340902</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kilian</FirstName>
<LastName>Weinberger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kilian Weinberger</PI_FULL_NAME>
<EmailAddress>kilianweinberger@cornell.edu</EmailAddress>
<PI_PHON>6072550983</PI_PHON>
<NSF_ID>000576980</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Eric</FirstName>
<LastName>Leuthardt</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eric Leuthardt</PI_FULL_NAME>
<EmailAddress>leuthardte@wustl.edu</EmailAddress>
<PI_PHON>3143628012</PI_PHON>
<NSF_ID>000580066</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Washington University</Name>
<CityName>Saint Louis</CityName>
<ZipCode>631304862</ZipCode>
<PhoneNumber>3147474134</PhoneNumber>
<StreetAddress>CAMPUS BOX 1054</StreetAddress>
<StreetAddress2><![CDATA[1 Brookings Drive]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>068552207</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WASHINGTON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068552207</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Washington University]]></Name>
<CityName>St. Louis</CityName>
<StateCode>MO</StateCode>
<ZipCode>631304899</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7633</Code>
<Text>EFRI Research Projects</Text>
</ProgramElement>
<ProgramReference>
<Code>7633</Code>
<Text>EFRI RESEARCH PROJECTS</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~1992456</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this project, we used a co-adaptive brain computer interface (where both the brain adapts via biofeedback and the decoding algorithm adapts to improve performance) to train subjects to control kinetic or "force-based" variables in virtual arm simulator. &nbsp;Current brain-machine or brain-computer interface (BCI) technology relies primarily on kinematic parameter (i.e. position or velocity) based control signals. &nbsp;Kinematic-based signals are sufficient for control of virtual objects such as those found in computer environments. However, this type of control signal is not ideal for controlling real-world objects with mass that are subject to external and unexpected forces. &nbsp;A prime example of this is seen with functional neuromuscular stimulation (FNS), a technique that attempts to control a paralyzed limb with electrical stimulation of muscles to restore motor function. &nbsp;In this case, a physical model of the affected limb is unknown or incomplete. &nbsp;Using an inverse dynamics model to calculate muscle stimulations from the patient&rsquo;s velocity control signal could result in very large errors and unproductive movements. It would be much more effective to map brain activity to muscle stimulation directly and allow the brain to develop its own transfer function between muscle stimulation and limb movement.</p> <p>With this in mind, we designed and developed a novel force-based BCI that allowed subjects to control virtual muscles in computer simulation directly from brain activity in order to move a simulated arm throughout a workspace. &nbsp;We tested various brain regions and found that both motor and sensory areas of the brain can be trained to control a virtual arm.&nbsp; This has interesting applications going forward as more areas of the brain are examined for their ability to interact directly with machines.&nbsp; For instance, auditory areas of the brain could be engaged in a closed-loop manner to control an adaptive hearing device for the either the impaired (deaf) or as an enhancement to normal function. &nbsp;Our results clearly show that BCI technology could be used to control muscle stimulators in paralyzed individuals directly for functional restoration of movement.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/11/2017<br>      Modified by: Daniel&nbsp;W&nbsp;Moran</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this project, we used a co-adaptive brain computer interface (where both the brain adapts via biofeedback and the decoding algorithm adapts to improve performance) to train subjects to control kinetic or "force-based" variables in virtual arm simulator.  Current brain-machine or brain-computer interface (BCI) technology relies primarily on kinematic parameter (i.e. position or velocity) based control signals.  Kinematic-based signals are sufficient for control of virtual objects such as those found in computer environments. However, this type of control signal is not ideal for controlling real-world objects with mass that are subject to external and unexpected forces.  A prime example of this is seen with functional neuromuscular stimulation (FNS), a technique that attempts to control a paralyzed limb with electrical stimulation of muscles to restore motor function.  In this case, a physical model of the affected limb is unknown or incomplete.  Using an inverse dynamics model to calculate muscle stimulations from the patient?s velocity control signal could result in very large errors and unproductive movements. It would be much more effective to map brain activity to muscle stimulation directly and allow the brain to develop its own transfer function between muscle stimulation and limb movement.  With this in mind, we designed and developed a novel force-based BCI that allowed subjects to control virtual muscles in computer simulation directly from brain activity in order to move a simulated arm throughout a workspace.  We tested various brain regions and found that both motor and sensory areas of the brain can be trained to control a virtual arm.  This has interesting applications going forward as more areas of the brain are examined for their ability to interact directly with machines.  For instance, auditory areas of the brain could be engaged in a closed-loop manner to control an adaptive hearing device for the either the impaired (deaf) or as an enhancement to normal function.  Our results clearly show that BCI technology could be used to control muscle stimulators in paralyzed individuals directly for functional restoration of movement.             Last Modified: 05/11/2017       Submitted by: Daniel W Moran]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
