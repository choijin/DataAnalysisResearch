<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Recovery of Multi-Channel Visual Signals from Limited Color Information Using Rank Minimization and Sparsity Maximization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>408536.00</AwardTotalIntnAmount>
<AwardAmount>408536</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The recovery of visual colors from captured images and video signals is among the most prevalent and fundamental problems in digital imaging. This problem affects billions of consumers, and it impacts the quality of the visual signal that these consumers capture, communicate, and display. Millions of image and video cameras, mobile and smart phones, and many other types of visual devices and applications are impacted in a significant way. For example, virtually all consumer cameras are based on an architecture that utilizes a Color Filter Array (CFA), which captures single-color-per-pixel images to reduce cost, size, and power consumption. Hence, one needs to recover the original three color images (Red-Green-Blue) from the captured single-color-per-pixel CFA image. Despite numerous contributions and noticeable progress that has been made in this area, this problem is still largely unsolved.&lt;br/&gt;&lt;br/&gt;This project addresses the general problem of the recovery of multiple color channels (RMCC) from limited color information. The project develops a joint rank-minimization sparsity-maximization (RMSM) framework for the recovery of multiple color channels. Rank minimization of matrices, which is a more general framework than compressed sensing (CS) of vectors, provides many powerful tools. The project targets both approaches jointly in novel ways. An important question is how to strike an optimal balance between rank-minimization and sparsity-maximization under a joint framework. Furthermore, this effort designs optimization frameworks for a sparsifying "color"-dictionary paradigm. The notion of utilizing overcomplete, sparsifying "color" dictionaries represents a major departure from prior work. The project is also extending the applications of this research to video demosaicing and visual coding systems.</AbstractNarration>
<MinAmdLetterDate>06/30/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/30/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1117709</AwardID>
<Investigator>
<FirstName>Hayder</FirstName>
<LastName>Radha</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hayder Radha</PI_FULL_NAME>
<EmailAddress>radha@egr.msu.edu</EmailAddress>
<PI_PHON>5174329958</PI_PHON>
<NSF_ID>000322047</NSF_ID>
<StartDate>06/30/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName>East Lansing</CityName>
<StateCode>MI</StateCode>
<ZipCode>488242600</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Programs]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~408536</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Imaging data provides crucial information that impacts many critical applications and services ranging from medicine to entertainment. The "missing" imaging data problem usually occurs due to limitations in the capturing device and/or due to an imposed set of requirements to reduce cost or acquisition time when capturing the data.&nbsp;The ability to recover missing imaging data that are captured by a variety of devices can have a profound impact on the aforementioned applications and services. Furthermore, recovery of missing imaging data, in general, and missing color channels, in particular, are among the most critical and fundamental problems in imaging and video. Consequently, the main focus of this project has been the development of novel approaches for the recovery of missing imaging data. The primary outcomes of this effort can be summarized by the following:</p> <p>(1) Recovery of the "true" colors of an image (that is captured using only partial color information) can be achieved by emerging methods that are based on "sparse signal" models. The approaches that we have developed under this project provided significant improvements over state-of-the-art in this area. Figure 1(a) shows an example of an image captured using a single color per pixel. The reconstructed image using one of the approaches developed under this NSF project is shown in Figure 1(b). As can be seen, virtually perfect reconstruction can be achieved based on the developed framework.</p> <p>(2) When capturing an image using limited color information (e.g., single color per pixel), the color pattern used for the captured image can have an impact on the quality of the reconstructed image. For example, we have found that the so-called "second generation" color pattern might provide better results than the popular Bayer pattern used in virtually all consumer cameras. Also, having a "periodic" color pattern (i.e., a color pattern that repeats over the image) can provide better results than a purely random color mosaic.</p> <p>(3) The general framework of "sparse signal representation" of visual information can be successfully applied to the modeling of video as well. In particular, under this project, we succeeded in developing the foundations of a video framework (based on sparse representation) that can be used for a broad range of applications, including tracking of arbitrary objects (e.g., face and people tracking), removing of objects, and video scene detection. An example for object removal from a video sequence is shown in Figure 2. As can be seen from the figure, a highly accurate performance can be achieved based on the developed approach.</p> <p>(4) The area of "sparse representation" can be a powerful tool for other important classes of missing data recovery methods. In particular, we employed what is known as "sparse space clustering" to develop a novel framework for image super-resolution. The area of image super-resolution has received a great deal of attention due to its impact on a variety of applications including medical imaging and the emerging ultra-high definition video displays. We were able to successfully recover super-resolution images from much lower-resolution images (e.g., magnification by a factor of 3x3) by employing the developed techniques under this project. An example is shown in Figure 3 where the quality of the higher-resolution&nbsp;image can clearly be seen when compared to the low-resolution image that has significantly lower visual quality than the reconstructed super-resolution image.</p> <p>Finally, we believe that there is still a great deal of work that can be pursued in the general area of missing image data recovery. We have shown in some of our presentations at leading venues that there are still some limitations in the most advanced methods that have been developed so far, even under the frameworks developed under this project. After developing ...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Imaging data provides crucial information that impacts many critical applications and services ranging from medicine to entertainment. The "missing" imaging data problem usually occurs due to limitations in the capturing device and/or due to an imposed set of requirements to reduce cost or acquisition time when capturing the data. The ability to recover missing imaging data that are captured by a variety of devices can have a profound impact on the aforementioned applications and services. Furthermore, recovery of missing imaging data, in general, and missing color channels, in particular, are among the most critical and fundamental problems in imaging and video. Consequently, the main focus of this project has been the development of novel approaches for the recovery of missing imaging data. The primary outcomes of this effort can be summarized by the following:  (1) Recovery of the "true" colors of an image (that is captured using only partial color information) can be achieved by emerging methods that are based on "sparse signal" models. The approaches that we have developed under this project provided significant improvements over state-of-the-art in this area. Figure 1(a) shows an example of an image captured using a single color per pixel. The reconstructed image using one of the approaches developed under this NSF project is shown in Figure 1(b). As can be seen, virtually perfect reconstruction can be achieved based on the developed framework.  (2) When capturing an image using limited color information (e.g., single color per pixel), the color pattern used for the captured image can have an impact on the quality of the reconstructed image. For example, we have found that the so-called "second generation" color pattern might provide better results than the popular Bayer pattern used in virtually all consumer cameras. Also, having a "periodic" color pattern (i.e., a color pattern that repeats over the image) can provide better results than a purely random color mosaic.  (3) The general framework of "sparse signal representation" of visual information can be successfully applied to the modeling of video as well. In particular, under this project, we succeeded in developing the foundations of a video framework (based on sparse representation) that can be used for a broad range of applications, including tracking of arbitrary objects (e.g., face and people tracking), removing of objects, and video scene detection. An example for object removal from a video sequence is shown in Figure 2. As can be seen from the figure, a highly accurate performance can be achieved based on the developed approach.  (4) The area of "sparse representation" can be a powerful tool for other important classes of missing data recovery methods. In particular, we employed what is known as "sparse space clustering" to develop a novel framework for image super-resolution. The area of image super-resolution has received a great deal of attention due to its impact on a variety of applications including medical imaging and the emerging ultra-high definition video displays. We were able to successfully recover super-resolution images from much lower-resolution images (e.g., magnification by a factor of 3x3) by employing the developed techniques under this project. An example is shown in Figure 3 where the quality of the higher-resolution image can clearly be seen when compared to the low-resolution image that has significantly lower visual quality than the reconstructed super-resolution image.  Finally, we believe that there is still a great deal of work that can be pursued in the general area of missing image data recovery. We have shown in some of our presentations at leading venues that there are still some limitations in the most advanced methods that have been developed so far, even under the frameworks developed under this project. After developing critical pieces of the foundation of novel methods for the recovery of missing visual data under this ...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
