<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Large: Collaborative Research: Human-Robot Dialog for Collaborative Navigation Tasks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>693265.00</AwardTotalIntnAmount>
<AwardAmount>693265</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research involves collaboration among investigators at three institutions.  The PIs anticipate a future in which humans and intelligent robots will collaborate on shared tasks.  To achieve this vision, a robot must have sufficiently rich knowledge of the task domain and that knowledge must be usable in ways that support effective communication between a human and the robot.  Navigational space is one of the few task domains where the structure of the knowledge is sufficiently well understood for a physically-embodied robot agent to be a useful collaborator, meeting genuine human needs.  In this project, the PIs will develop and evaluate an intelligent robot capable of being genuinely useful to a human, and capable of natural dialog with a human about their shared task.&lt;br/&gt;&lt;br/&gt;The Hybrid Spatial Semantic Hierarchy (HSSH) is a human-inspired multi-ontology representation for knowledge of navigational space.  The spatial representations in the HSSH provide for efficient incremental learning, graceful degradation under resource limitations, and natural interfaces for different kinds of human-robot interactions.  Speech is a natural though demanding way to use natural language to communicate with a robot.  To maintain real-time performance, natural language understanding must be organized to minimize the amount of backtracking from early conclusions in light of later information.  This project will answer three scientific questions.&lt;br/&gt;&lt;br/&gt;(1) Can the HSSH framework, extended with real-time computer vision, express the kinds of knowledge of natural human environments that are relevant to navigation tasks? &lt;br/&gt;(2) Can the HSSH representation support effective natural language communication in the spatial navigation domain? &lt;br/&gt;3) Can we develop effective human-robot interaction that meets the needs of a person and improves the performance of the system?&lt;br/&gt;&lt;br/&gt;To these ends, the PIs will perform this research with two different kinds of navigational robots, each learning from its travel experiences and building an increasingly sophisticated cognitive map: an intelligent robotic wheelchair which carries its human driver to desired destinations, and a telepresence robot that transmits its perceptions to a remote human driver as it navigates within an environment so the driver can achieve virtual presence and communicate with others remotely.  To inform the design process, the PIs will conduct focus groups with potential users.  They will also evaluate their implemented systems throughout the process, creating an iterative design-test cycle.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  To be successful, an intelligent robot must not only be able to perceive the world, represent what it learns, make useful inferences and plans, and act effectively.  It must also be able to communicate effectively with other agents, and particularly with people.  This confluence among grounded knowledge representation, situated natural language understanding, and human-robot interaction is intellectually fundamental, and is the focus of this research.  Since the domain of spatial knowledge is foundational for virtually all aspects of human knowledge, project outcomes will have broad applicability.  This work will create technologies for mobility assistance for people with disabilities in perception (blindness or low vision), cognition (developmental delay or dementia), or general frailty (old age).  It will also support telepresence applications such as telecommuting, telemedicine and search and rescue.  The project includes outreach to K-12 and community college students, K-12 teachers, and the public in a number of venues.</AbstractNarration>
<MinAmdLetterDate>08/11/2011</MinAmdLetterDate>
<MaxAmdLetterDate>03/16/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1111494</AwardID>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Kuipers</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin J Kuipers</PI_FULL_NAME>
<EmailAddress>kuipers@umich.edu</EmailAddress>
<PI_PHON>7346476887</PI_PHON>
<NSF_ID>000324244</NSF_ID>
<StartDate>08/11/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Regents of the University of Michigan - Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091274</ZipCode>
<StreetAddress><![CDATA[3003 South State St. Room 1062]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~693265</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The task of an intelligent robotic wheelchair is to understand the spatial structure of its environment, and to interact effectively with its human driver.&nbsp; The wheelchair must be able to navigate safely toward a destination with whatever degree of autonomy is delegated by its human driver.&nbsp; It must also be able to learn a cognitive map from its experience traveling through the environment, without necessarily having the opportunity to explore according to its own preferences. &nbsp;</p> <p>An intelligent robotic wheelchair like this could be transformative for potentially millions of people with disabilities, including elders, who would benefit from independent assisted mobility, but who are unable to use a traditional powered wheelchair.&nbsp; By allowing people to move according to their own needs and desires within an apartment, a building, or a campus (university, industry, retirement center, or medical center), such a robot encourages social and personal involvement, which is known to be important for health.</p> <p>In order to communicate effectively with a human, even as it is in the midst of learning about the environment, the robot needs a knowledge representation that is compatible with the ways that humans conceptualize the environment.&nbsp; This is the inspiration behind our Hybrid Spatial Semantic Hierarchy (HSSH) representation for spatial knowledge of large-scale and small-scale space (the &ldquo;cognitive map&rdquo;).&nbsp; An essential feature of the HSSH is the ability to express states of partial knowledge that arise during exploration and learning.</p> <p>A major theme of our research has been extending the HSSH to handle the scale and complexity of human environments.&nbsp; Metrical representations for space, constructed by SLAM (Simultaneous Localization And Mapping) algorithms, have become powerful and standard.&nbsp; However, graph-like topological representations offer conceptual simplicity, correspondence with natural language concepts, and scalability to much larger environments.&nbsp; The HSSH is a hybrid between metrical and topological representations for space.&nbsp; We have accomplished a number of significant advances within this theme.</p> <p>Our robot wheelchair senses its environment using both vision and laser range-finders.&nbsp; For both of these sensors, glass walls, doors, and windows are almost always invisible.&nbsp; We have developed new methods that exploit the special properties of glass and other specular surfaces, so that the robot can accurately perceive and map them.</p> <p>Computer vision provides more information than lasers, but is computationally very expensive.&nbsp; We developed a new method for visual mapping of indoor environments, which are often dominated by planar surfaces, especially walls and floor.&nbsp; It generates a relatively small number of planar surface hypotheses, and then uses Bayesian probabilistic methods to combine many subtle pieces of evidence obtained by tracking visual features during motion, to converge rapidly on the best hypotheses.&nbsp; This work resulted in a PhD thesis in Electrical Engineering: Systems at the University of Michigan.</p> <p>Topological maps provide concise skeleton descriptions for large environments, supporting efficient and scalable route planning.&nbsp; However, they depend on creating a useful abstraction from local areas in the environment to discrete descriptions as destinations, decision points, and path segments. &nbsp;Major contributions from this project include an efficient probabilistic method for generating and testing these abstractions, an efficient probabilistic method for managing hypotheses about the global topological structure of the environment, and a method for creating hierarchical maps by abstracting large-scale topological maps to individual places in higher-level maps.&nbsp; This work is expected to result in a PhD in Computer Science and Engineering at the University of Michigan in mid-2017.</p> <p>Safe and comfortable (even &ldquo;graceful&rdquo;) motion while traveling through an environment, even in the presence of pedestrians, is the <em>raison d&rsquo;etre</em> for the robotic wheelchair&rsquo;s cognitive map.&nbsp; Our project produced a novel and robust motion planning method based on model-predictive control.&nbsp; It observes and tracks pedestrians around it, predicting their motion, proposing comfortable collision-free trajectories, and selecting the one that best combines safety, comfort, and progress toward the destination.&nbsp; Then, five times each second, it revises its predictions based on new observations and selects a new best trajectory.&nbsp; This strategy results in startlingly natural and considerate navigation behavior.&nbsp; It can move very quickly when no obstacles are present, slowing down and even stopping when pedestrians are in its way, and it even waits for pedestrians to clear a narrow passage before attempting to travel through.&nbsp; This work resulted in a PhD thesis in Mechanical Engineering at the University of Michigan.</p> <p>We recently produced two videos to demonstrate our work, particularly on robust motion planning:&nbsp; &ldquo;Vulcan:&nbsp; The Intelligent Wheelchair&rdquo; (<a href="https://www.youtube.com/watch?v=nZySQijSQWY">https://www.youtube.com/watch?v=nZySQijSQWY</a>), and &ldquo;Vulcan Robotic Wheelchair: Speed and Performance&rdquo; (<a href="https://www.youtube.com/watch?v=6AxE7nf3JTM">https://www.youtube.com/watch?v=6AxE7nf3JTM</a>).</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/22/2016<br>      Modified by: Benjamin&nbsp;J&nbsp;Kuipers</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The task of an intelligent robotic wheelchair is to understand the spatial structure of its environment, and to interact effectively with its human driver.  The wheelchair must be able to navigate safely toward a destination with whatever degree of autonomy is delegated by its human driver.  It must also be able to learn a cognitive map from its experience traveling through the environment, without necessarily having the opportunity to explore according to its own preferences.    An intelligent robotic wheelchair like this could be transformative for potentially millions of people with disabilities, including elders, who would benefit from independent assisted mobility, but who are unable to use a traditional powered wheelchair.  By allowing people to move according to their own needs and desires within an apartment, a building, or a campus (university, industry, retirement center, or medical center), such a robot encourages social and personal involvement, which is known to be important for health.  In order to communicate effectively with a human, even as it is in the midst of learning about the environment, the robot needs a knowledge representation that is compatible with the ways that humans conceptualize the environment.  This is the inspiration behind our Hybrid Spatial Semantic Hierarchy (HSSH) representation for spatial knowledge of large-scale and small-scale space (the "cognitive map").  An essential feature of the HSSH is the ability to express states of partial knowledge that arise during exploration and learning.  A major theme of our research has been extending the HSSH to handle the scale and complexity of human environments.  Metrical representations for space, constructed by SLAM (Simultaneous Localization And Mapping) algorithms, have become powerful and standard.  However, graph-like topological representations offer conceptual simplicity, correspondence with natural language concepts, and scalability to much larger environments.  The HSSH is a hybrid between metrical and topological representations for space.  We have accomplished a number of significant advances within this theme.  Our robot wheelchair senses its environment using both vision and laser range-finders.  For both of these sensors, glass walls, doors, and windows are almost always invisible.  We have developed new methods that exploit the special properties of glass and other specular surfaces, so that the robot can accurately perceive and map them.  Computer vision provides more information than lasers, but is computationally very expensive.  We developed a new method for visual mapping of indoor environments, which are often dominated by planar surfaces, especially walls and floor.  It generates a relatively small number of planar surface hypotheses, and then uses Bayesian probabilistic methods to combine many subtle pieces of evidence obtained by tracking visual features during motion, to converge rapidly on the best hypotheses.  This work resulted in a PhD thesis in Electrical Engineering: Systems at the University of Michigan.  Topological maps provide concise skeleton descriptions for large environments, supporting efficient and scalable route planning.  However, they depend on creating a useful abstraction from local areas in the environment to discrete descriptions as destinations, decision points, and path segments.  Major contributions from this project include an efficient probabilistic method for generating and testing these abstractions, an efficient probabilistic method for managing hypotheses about the global topological structure of the environment, and a method for creating hierarchical maps by abstracting large-scale topological maps to individual places in higher-level maps.  This work is expected to result in a PhD in Computer Science and Engineering at the University of Michigan in mid-2017.  Safe and comfortable (even "graceful") motion while traveling through an environment, even in the presence of pedestrians, is the raison d?etre for the robotic wheelchair?s cognitive map.  Our project produced a novel and robust motion planning method based on model-predictive control.  It observes and tracks pedestrians around it, predicting their motion, proposing comfortable collision-free trajectories, and selecting the one that best combines safety, comfort, and progress toward the destination.  Then, five times each second, it revises its predictions based on new observations and selects a new best trajectory.  This strategy results in startlingly natural and considerate navigation behavior.  It can move very quickly when no obstacles are present, slowing down and even stopping when pedestrians are in its way, and it even waits for pedestrians to clear a narrow passage before attempting to travel through.  This work resulted in a PhD thesis in Mechanical Engineering at the University of Michigan.  We recently produced two videos to demonstrate our work, particularly on robust motion planning:  "Vulcan:  The Intelligent Wheelchair" (https://www.youtube.com/watch?v=nZySQijSQWY), and "Vulcan Robotic Wheelchair: Speed and Performance" (https://www.youtube.com/watch?v=6AxE7nf3JTM).          Last Modified: 12/22/2016       Submitted by: Benjamin J Kuipers]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
