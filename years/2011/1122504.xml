<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DIP: Teaching Writing and Argumentation with AI-Supported Diagramming and Peer Review</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>1349985.00</AwardTotalIntnAmount>
<AwardAmount>1390735</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The PIs are investigating the design of intelligent tutoring systems (ITSs) that are aimed at learning in unstructured domains. Such systems are not able to do as much automatically as ITSs working in traditionally narrow and well-structured domains, but rather they need to share responsibilities for scaffolding learning with a teacher and/or peers. In the work proposed, the three PIs, who share expertise in automated natural language understanding, intelligent tutoring systems, machine learning, argumentation (especially in law), complex problem solving, and engineering education, are integrating intelligent tutoring, data mining, machine learning, and language processing to design a socio-technical system (people and machines working together) that helps undergraduates and law students write better argumentative essays. The work of helping learners derive an argument is shared by the computer and peers, as is the work of helping peer reviewers review the writing of others and the work of learners to turn their argument diagrams into well-written documents. Research questions address the roles computers might take on in promoting writing and the technology that enables that, how to distribute scaffolding between an intelligent machine and human agents, how to promote better writing (especially the relationship between diagramming and writing), and how to promote learning through peer review of the writing of others. &lt;br/&gt;&lt;br/&gt;This project is bringing together outstanding researchers from a variety of different disciplines -- artificial intelligence, law education, engineering and science education, and cognitive psychology -- to address an education issue of national concern -- writing, especially writing that makes and substantiates a point -- and to explore ways of extending intelligent tutoring systems beyond fact-based domains. It fulfills all aims of the Cyberlearning program -- to imagine, design, and learn how to best design and use the next generation of learning technologies, to address learning issues of national importance, and to contribute to understanding of how people learn.</AbstractNarration>
<MinAmdLetterDate>09/01/2011</MinAmdLetterDate>
<MaxAmdLetterDate>04/09/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1122504</AwardID>
<Investigator>
<FirstName>Diane</FirstName>
<LastName>Litman</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Diane J Litman</PI_FULL_NAME>
<EmailAddress>litman@cs.pitt.edu</EmailAddress>
<PI_PHON>4126241261</PI_PHON>
<NSF_ID>000233759</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Ashley</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin D Ashley</PI_FULL_NAME>
<EmailAddress>ashley@pitt.edu</EmailAddress>
<PI_PHON>4126247496</PI_PHON>
<NSF_ID>000193474</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Christian</FirstName>
<LastName>Schunn</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christian D Schunn</PI_FULL_NAME>
<EmailAddress>schunn@pitt.edu</EmailAddress>
<PI_PHON>4126248807</PI_PHON>
<NSF_ID>000207377</NSF_ID>
<StartDate>09/01/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133203</ZipCode>
<StreetAddress><![CDATA[300 Murdoch Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7444</Code>
<Text>NATIONAL SMETE DIGITAL LIBRARY</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>7444</Code>
<Text>NATIONAL SMETE DIGITAL LIBRARY</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8842</Code>
<Text>Design and Implementation Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~1349985</FUND_OBLG>
<FUND_OBLG>2012~40750</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><h3>Argument Mining in Student Essays</h3> <p>We applied data-driven  learned models using natural language processing and machine learning  techniques for topic-independent argument element identification and  argumentative relation classification in student essays.</p> <p>We proposed novel topic-independent prediction features to improve  argument mining in student essays. In particular we improved the  argument element identification model using novel features derived from  argument indicators and essay topics. For argument indicator features,  we post-processed topic modeling output to extract argument and domain  words which are used for new features and constraints. We also used  comparative adverbs, and discourse relations. To abstract argument  topics of student essays, we counted common words of argument elements  in preceding sentences and within essays. Our experiments showed that  our proposed features significantly improved prediction performance in  random folding cross validation as well as cross-topic validation for  both corpora, academic writings and persuasive essays. Furthermore, all  of our novel features were selected in the top features of the  prediction model.</p> <p>We also proposed a novel approach to classifying argumentative  relation of pairs of argument elements that considered each argument  element in relation to adjacent sentences. Adjacent sentences in the  same paragraph with the argument element are called context-sentences.  In addition to baseline features including sentence position, pair of  first words, and word counts, we extracted features from discourse  relations between argument elements and their context sentences. Also,  we exploited argument and domain word lexicons to extract novel lexical  features including pairs of argument words, and domain word counts. Our  proposed argumentative relation model significantly outperformed  state-of-the-art model (Stab &amp; Gurevych 2014).</p> <h3>Argument Diagramming for Scientific Writing</h3> <p>Students  given diagramming support wrote more about the relevance (in terms of  population, context, and comparison of situations) and validity (in  terms of sample size, experimental design, confounds) of cited studies.</p> <p>In the first set of student papers, relative to students given no  diagramming support, students given diagramming support included  significantly more writing about: any risk, uncertainty, and a  combination of uncertainty and opposition. There was no significant difference in writing about opposition.  Similar to the published articles, uncertainty was the most commonly  addressed form of risk. This pattern of results was consistent for both  the between-instructor lab section pair and the within-instructor lab  section pair. In addition, those students given diagramming support  wrote more about the relevance (in terms of population, context, and  comparison of situations) and validity (in terms of sample size,  experimental design, confounds) of cited studies. Regression analyses  suggested that the effects of condition on discussion of validity were  mediated through the effects on discussion of relevance, but were  independent of the effects of discussion of risk. In the second set of student papers, students who were  given diagramming support for the first paper included more writing  about: any risk, uncertainty, opposition, and combinations of risk  types, but only the difference in opposition and combinations trended  towards statistical significance &ndash; the other two were non-significant.  Effect sizes were quite large for both sets of papers, but because the  second set of papers were only collected from one pair of lab sections  and written in dyads, insufficient power may have been an obstacle to  detecting significant differences.</p><br> <p>            Last Modified: 09/10/2017<br>      Modified by: Kevin&nbsp;D&nbsp;Ashley</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Argument Mining in Student Essays  We applied data-driven  learned models using natural language processing and machine learning  techniques for topic-independent argument element identification and  argumentative relation classification in student essays.  We proposed novel topic-independent prediction features to improve  argument mining in student essays. In particular we improved the  argument element identification model using novel features derived from  argument indicators and essay topics. For argument indicator features,  we post-processed topic modeling output to extract argument and domain  words which are used for new features and constraints. We also used  comparative adverbs, and discourse relations. To abstract argument  topics of student essays, we counted common words of argument elements  in preceding sentences and within essays. Our experiments showed that  our proposed features significantly improved prediction performance in  random folding cross validation as well as cross-topic validation for  both corpora, academic writings and persuasive essays. Furthermore, all  of our novel features were selected in the top features of the  prediction model.  We also proposed a novel approach to classifying argumentative  relation of pairs of argument elements that considered each argument  element in relation to adjacent sentences. Adjacent sentences in the  same paragraph with the argument element are called context-sentences.  In addition to baseline features including sentence position, pair of  first words, and word counts, we extracted features from discourse  relations between argument elements and their context sentences. Also,  we exploited argument and domain word lexicons to extract novel lexical  features including pairs of argument words, and domain word counts. Our  proposed argumentative relation model significantly outperformed  state-of-the-art model (Stab &amp; Gurevych 2014). Argument Diagramming for Scientific Writing  Students  given diagramming support wrote more about the relevance (in terms of  population, context, and comparison of situations) and validity (in  terms of sample size, experimental design, confounds) of cited studies.  In the first set of student papers, relative to students given no  diagramming support, students given diagramming support included  significantly more writing about: any risk, uncertainty, and a  combination of uncertainty and opposition. There was no significant difference in writing about opposition.  Similar to the published articles, uncertainty was the most commonly  addressed form of risk. This pattern of results was consistent for both  the between-instructor lab section pair and the within-instructor lab  section pair. In addition, those students given diagramming support  wrote more about the relevance (in terms of population, context, and  comparison of situations) and validity (in terms of sample size,  experimental design, confounds) of cited studies. Regression analyses  suggested that the effects of condition on discussion of validity were  mediated through the effects on discussion of relevance, but were  independent of the effects of discussion of risk. In the second set of student papers, students who were  given diagramming support for the first paper included more writing  about: any risk, uncertainty, opposition, and combinations of risk  types, but only the difference in opposition and combinations trended  towards statistical significance &ndash; the other two were non-significant.  Effect sizes were quite large for both sets of papers, but because the  second set of papers were only collected from one pair of lab sections  and written in dyads, insufficient power may have been an obstacle to  detecting significant differences.       Last Modified: 09/10/2017       Submitted by: Kevin D Ashley]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
