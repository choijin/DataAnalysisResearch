<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SoCS: Studying the Computability of Emotions by Harnessing Massive Online Social Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>12/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>720821.00</AwardTotalIntnAmount>
<AwardAmount>784821</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The emergence of massive human-rated and commented visual data has opened avenues for exploring fundamental questions in artificial intelligence beyond the horizon.  This project tackles the challenge of automatically inferring visual aesthetics and emotions and inventing new systems that assist creative and decision-making activities of the general public.  An interdisciplinary team, with expertise in visual modeling, data mining, psychology, and computational sciences will build tools to distill information from a combination of visual, textual, and numerical data.  Visual features, selected based on published literature and consultation with domain experts, will be extracted for discriminating types of emotions.  The resulting systems can select and rank visual information based on aesthetics and emotions.&lt;br/&gt;&lt;br/&gt;Intellectual Merits: This project will allow computer scientists to gain understanding of next-generation computerized visual aesthetics and emotion assessment systems.  The complex inter-relationship among content, context, and subjectivity in aesthetics and emotion assessment makes the corresponding learning problems especially challenging, which is likely to trigger innovation in machine learning and statistical modeling. Such capabilities will fundamentally change the way visual information is analyzed, processed, and managed.  The project will advance our understanding of the computability of emotions, and lead to new applications that can be used in a variety of settings.&lt;br/&gt;&lt;br/&gt;Broader Impacts: The research will have a transformative impact in the fields of information retrieval, human-computer interaction, information processing, consumer electronics, and design. The technology can also be used to refine multimedia content that serves as education resources.  The project will disseminate research findings, generate new software implementations and collected datasets, and provide online services that can be used by researchers, educators, and industry. Education efforts include developing an interdisciplinary curriculum, training cross-disciplinary scientists, and involving underrepresented groups in research.</AbstractNarration>
<MinAmdLetterDate>07/26/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/13/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1110970</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT>Z</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James Z Wang</PI_FULL_NAME>
<EmailAddress>jwang@ist.psu.edu</EmailAddress>
<PI_PHON>8148657889</PI_PHON>
<NSF_ID>000382648</NSF_ID>
<StartDate>09/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jia</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>Jia Li</PI_FULL_NAME>
<EmailAddress>jiali@psu.edu</EmailAddress>
<PI_PHON>8148633074</PI_PHON>
<NSF_ID>000486811</NSF_ID>
<StartDate>06/13/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jia</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>Jia Li</PI_FULL_NAME>
<EmailAddress>jiali@psu.edu</EmailAddress>
<PI_PHON>8148633074</PI_PHON>
<NSF_ID>000486811</NSF_ID>
<StartDate>07/26/2011</StartDate>
<EndDate>09/09/2013</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Reginald</FirstName>
<LastName>Adams</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Reginald B Adams</PI_FULL_NAME>
<EmailAddress>radams@psu.edu</EmailAddress>
<PI_PHON>8148656219</PI_PHON>
<NSF_ID>000242743</NSF_ID>
<StartDate>07/26/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michelle</FirstName>
<LastName>Newman</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michelle G Newman</PI_FULL_NAME>
<EmailAddress>mgn1@psu.edu</EmailAddress>
<PI_PHON>8148631148</PI_PHON>
<NSF_ID>000576574</NSF_ID>
<StartDate>06/13/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michelle</FirstName>
<LastName>Newman</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michelle G Newman</PI_FULL_NAME>
<EmailAddress>mgn1@psu.edu</EmailAddress>
<PI_PHON>8148631148</PI_PHON>
<NSF_ID>000576574</NSF_ID>
<StartDate>03/15/2012</StartDate>
<EndDate>09/11/2012</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>7953</Code>
<Text>SOCIAL-COMPUTATIONAL SYSTEMS</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7953</Code>
<Text>SOCIAL-COMPUTATIONAL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~221178</FUND_OBLG>
<FUND_OBLG>2012~515643</FUND_OBLG>
<FUND_OBLG>2013~16000</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The project contributed to computational modeling of evoked emotions by developing and disseminating novel approaches based on computational image analysis and computer vision, psychology, and statistical learning techniques&nbsp;applied to large volume of carefully collected data about how visual content evoke emotions. Academic researchers at Penn State, from information sciences and technology, social psychology, clinical psychology, and statistics, collaborated on both research and advising of graduate students. A large number of undergraduate research students have also been involved in this research, either funded through REU supplements or volunteered. The team have collaborated with both industrial and international researchers with complementary research expertise. The resulting research publications have shown to the research and development community that aspects of evoked emotion are computable. Specific modeling methods have been developed and published. The team have created and made available carefully collected datasets on evoked emotions. The data will likely have positive impact to further development of such technologies and capabilities.</p> <p><span>The work is the first-known computational attempt to systematically investigate how perceptual shapes contributes to emotions aroused from images. There have been numerous psychological theories suggesting a link between our affective responses and the low-level features in images apart from the semantic content. However, there is a wide gap between what humans can perceive and feel and what can be explained using the current computable image features. &nbsp;</span><span>The team proposed a framework to statistically analyze line segments and curves extracted from images to model perceptual shapes and understand the relationship between shapes and emotions. The proposed shape descriptors include characteristics of lines, curves, and angles between lines extracted from contours. They further show that it is possible to estimate the roundness, the angularity, and the complexity of a visual scene, and use them alone to model the evoked emotion from the scene.</span></p> <p><span><span>The team have also proposed a way to improve the quality of the crowdsourced affective data. Specifically, they developed&nbsp;a probabilistic approach to joint modeling of participants' reliability and humans' regularity in crowdsourced affective studies. Reliability measures how likely a subject will respond to a question seriously; and regularity measures how often a human will agree with other seriously-entered responses coming from a targeted population. Crowdsourcing-based studies or experiments, which rely on human self-reported affect, pose additional challenges as compared with typical crowdsourcing studies that attempt to acquire concrete non-affective labels of objects. It has been often observed that different individuals exhibit different feelings on the same test question, which does not have a sole correct response in the first place. High reliability of responses from one individual thus cannot conclusively result in high consensus across individuals. Instead, globally testing consensus of a population is of great interest to the affective computing community. Built upon the agreement multigraph among tasks and workers, our probabilistic model differentiates subject regularity from population reliability. The team demonstrated the method's effectiveness for in-depth robust analysis of large-scale crowdsourced affective data, including emotion and aesthetic assessments collected by presenting visual stimuli to human subjects.</span><br /></span></p> <p>The project has impact on related disciplines. Dating back decades in psychological research (Aronoff et al, 1988), featural aspects of photographic images, including angularity and roundness, have been proposed to be fundamental to evoking emotional responses in human observers. What has been lacking in this research is the technology necessary to compute more nuanced visual properties to examine such psychological effects (e.g., emotion evocation) from natural images. As we advance this technology, scientists will be able to utilize it to better understand how the human visual system extracts emotional meaning from pictorial scenes. Once we have identified the emotions that certain pictorial properties elicit, these properties could be used to generate research and therapeutic stimuli. For example, stimuli that can evoke emotions can be used to engage clients in emotional processing (a fundamental therapeutic goal) within psychotherapy.&nbsp;</p> <p>Through active industrial and international collaboration, the project also contributed to related research questions including modeling of visual aesthetics, microexpression analysis, and smart cities.</p> <p>Funded graduate and undergraduate students in computer and information sciences and psychology engaged in active joint research with faculty and research scientists in both psychology and statistics. The multidisciplinary research training is expected to have positive impact on their research career for many years to come.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/05/2018<br>      Modified by: James&nbsp;Z&nbsp;Wang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project contributed to computational modeling of evoked emotions by developing and disseminating novel approaches based on computational image analysis and computer vision, psychology, and statistical learning techniques applied to large volume of carefully collected data about how visual content evoke emotions. Academic researchers at Penn State, from information sciences and technology, social psychology, clinical psychology, and statistics, collaborated on both research and advising of graduate students. A large number of undergraduate research students have also been involved in this research, either funded through REU supplements or volunteered. The team have collaborated with both industrial and international researchers with complementary research expertise. The resulting research publications have shown to the research and development community that aspects of evoked emotion are computable. Specific modeling methods have been developed and published. The team have created and made available carefully collected datasets on evoked emotions. The data will likely have positive impact to further development of such technologies and capabilities.  The work is the first-known computational attempt to systematically investigate how perceptual shapes contributes to emotions aroused from images. There have been numerous psychological theories suggesting a link between our affective responses and the low-level features in images apart from the semantic content. However, there is a wide gap between what humans can perceive and feel and what can be explained using the current computable image features.  The team proposed a framework to statistically analyze line segments and curves extracted from images to model perceptual shapes and understand the relationship between shapes and emotions. The proposed shape descriptors include characteristics of lines, curves, and angles between lines extracted from contours. They further show that it is possible to estimate the roundness, the angularity, and the complexity of a visual scene, and use them alone to model the evoked emotion from the scene.  The team have also proposed a way to improve the quality of the crowdsourced affective data. Specifically, they developed a probabilistic approach to joint modeling of participants' reliability and humans' regularity in crowdsourced affective studies. Reliability measures how likely a subject will respond to a question seriously; and regularity measures how often a human will agree with other seriously-entered responses coming from a targeted population. Crowdsourcing-based studies or experiments, which rely on human self-reported affect, pose additional challenges as compared with typical crowdsourcing studies that attempt to acquire concrete non-affective labels of objects. It has been often observed that different individuals exhibit different feelings on the same test question, which does not have a sole correct response in the first place. High reliability of responses from one individual thus cannot conclusively result in high consensus across individuals. Instead, globally testing consensus of a population is of great interest to the affective computing community. Built upon the agreement multigraph among tasks and workers, our probabilistic model differentiates subject regularity from population reliability. The team demonstrated the method's effectiveness for in-depth robust analysis of large-scale crowdsourced affective data, including emotion and aesthetic assessments collected by presenting visual stimuli to human subjects.   The project has impact on related disciplines. Dating back decades in psychological research (Aronoff et al, 1988), featural aspects of photographic images, including angularity and roundness, have been proposed to be fundamental to evoking emotional responses in human observers. What has been lacking in this research is the technology necessary to compute more nuanced visual properties to examine such psychological effects (e.g., emotion evocation) from natural images. As we advance this technology, scientists will be able to utilize it to better understand how the human visual system extracts emotional meaning from pictorial scenes. Once we have identified the emotions that certain pictorial properties elicit, these properties could be used to generate research and therapeutic stimuli. For example, stimuli that can evoke emotions can be used to engage clients in emotional processing (a fundamental therapeutic goal) within psychotherapy.   Through active industrial and international collaboration, the project also contributed to related research questions including modeling of visual aesthetics, microexpression analysis, and smart cities.  Funded graduate and undergraduate students in computer and information sciences and psychology engaged in active joint research with faculty and research scientists in both psychology and statistics. The multidisciplinary research training is expected to have positive impact on their research career for many years to come.           Last Modified: 01/05/2018       Submitted by: James Z Wang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
