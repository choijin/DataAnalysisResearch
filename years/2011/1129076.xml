<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>PIRE: Training and Workshops in Data Intensive Computing Using The Open Science Data Cloud</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>12/03/2010</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>3489523.00</AwardTotalIntnAmount>
<AwardAmount>4891876</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>01090000</Code>
<Directorate>
<Abbreviation>O/D</Abbreviation>
<LongName>Office Of The Director</LongName>
</Directorate>
<Division>
<Abbreviation>OISE</Abbreviation>
<LongName>Office Of Internatl Science &amp;Engineering</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cassandra Dudka</SignBlockName>
<PO_EMAI>cdudka@nsf.gov</PO_EMAI>
<PO_PHON>7032927250</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many scientists today face the unprecedented challenge of managing and analyzing a rapidly growing set of complex data. This international PIRE project aims to narrow the growing gap between the capability of modern scientific instruments to produce data and the ability of researchers to manage, analyze, and share those data in a reliable and timely manner. The emerging technology of cloud computing is a step forward from the current cyberinfrastructure.  Cloud computing involves clusters (the "clouds") of distributed computers that provide potentially less expensive, more flexible, and more powerful on-demand resources and services over a network, usually the Internet, while providing the scale and the reliability of a data center.  This PIRE team intends to help develop large-scale distributed computing capabilities - the Open Science Data Cloud (OSDC) - to provide long term persistent storage for scientific data and state-of-the-art services for integrating, analyzing, sharing and archiving scientific data.  The group proposes to study and strengthen storage systems that integrate specialized network protocols and support data transport over wide-area, high-performance networks. As data grows in size, the only practical means to analyze it is to use parallel programming, but until recently it has been time consuming for a domain scientist to take advantage of parallel programming.  Another research focus will be to develop new classes of cloud-based parallel programming frameworks and to integrate them into the cloud infrastructure so that this technology is more broadly available to scientists.  In addition to the research dimensions of this project, another key aspect is the involvement, in workshops and in subsequent use of the cloud cyberinfrastructure, of many domain scientists and their students. These groups will be trained in the basics of cloud computing and then will work to ensure that the cloud computing research advances maximize the manageability and analytical power of the complex datasets unique to their disciplines. &lt;br/&gt;&lt;br/&gt;This PIRE project embraces cloud computing as a global issue and so taps the cloud computing, high performance networking, domain science, e-Science, education and outreach expertise of its many collaborators in Europe, Asia and South America.  Foreign partners also provide a natural mechanism to engage international scientific datasets and distributed networks, and accommodate different international standards to guarantee interoperability. The international collaborators can provide an entry into international collaborations for U.S. graduate students and early career scientists and can also serve as global ambassadors for this new cyberinfrastructure, helping to garner widespread support that will be critical to its future adoption.&lt;br/&gt;&lt;br/&gt;The project will build a strong cadre of students with a global perspective on scientific data management in many research areas vital to U.S. and international scientific collaborations. The project will provide U.S. graduate students and early career scientists with international research and education experiences with leading scientists via research and training at foreign institutions and participation in annual workshops. As a group, the PIRE students will share an interest in data intensive computing but will be drawn from fields as diverse as computer science, physics, astronomy, geosciences, chemistry, engineering, and biology, lending an interdisciplinary vigor to their training. The PIRE team members will also develop 1-2 day and 1-2 week courses on data intensive computing, with hands-on exercises developed by U.S. and international faculty in computer science and the domain sciences.&lt;br/&gt;&lt;br/&gt;This PIRE project is likely to have numerous impacts above the level of the individual collaborators. For the U.S. PIRE institutions, it will strengthen current linkages and collaborations in the global Cloud Computing community and engage more U.S. students in international interdisciplinary research teams for the service, support and analysis of large scientific datasets. The project will enhance internationalizing efforts both at the University of Illinois at Chicago and at Florida International University by providing opportunities for short term research abroad and other academic experiences to a diverse group of students. This project will increase the virtual international engagement of the U.S. institutions via distributed research collaborations, courses with transcontinental participation, global web discussions, and focused social networking forums.  Increasing the number of scientists with expertise in managing and analyzing very large datasets is also vital to the future of our nation.  Finally, since this transformative technology is broadly applicable to any scientific project struggling to manage and analyze the volume of data produced, the OSDC and its facilitative impacts are likely to persist long after the PIRE project has ended. &lt;br/&gt;&lt;br/&gt;Participating U.S. institutions include the National Center for Data Mining (NCDM) at the University of Illinois at Chicago and Florida International University.  OSDC U.S. partner institutions include the University of Chicago and Johns Hopkins University.  Partnering foreign institutions include the University of Edinburgh (UK); Universidade Federal Fluminense (Brazil); University of Amsterdam (The Netherlands); National Institute of Advanced Industrial Science and Technology (AIST) (Japan);  Korea Institute of Science and Technology Information (KISTI) Supercomputing Center; Beijing Institute of Genomics (BIG) - Chinese Academy of Sciences, and the State University of Sao Paulo (Brazil). &lt;br/&gt;&lt;br/&gt;This project is cofunded by the NSF's Office of International Science and Engineering, the Office of Cyberinfrastructure, the Division of Computer and Communication Foundations, the Division of Astronomical Sciences, and the Division of Physics.</AbstractNarration>
<MinAmdLetterDate>03/07/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/25/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.079</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1129076</AwardID>
<Investigator>
<FirstName>Heidi L.</FirstName>
<LastName>Morgan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Heidi L. Morgan</PI_FULL_NAME>
<EmailAddress>hlmorgan@isi.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000161923</NSF_ID>
<StartDate>12/12/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Philip</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Philip S Yu</PI_FULL_NAME>
<EmailAddress>psyu@cs.uic.edu</EmailAddress>
<PI_PHON>3129960498</PI_PHON>
<NSF_ID>000079589</NSF_ID>
<StartDate>12/12/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Grossman</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert L Grossman</PI_FULL_NAME>
<EmailAddress>robert.grossman@uchicago.edu</EmailAddress>
<PI_PHON>7738344669</PI_PHON>
<NSF_ID>000278293</NSF_ID>
<StartDate>03/07/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606375418</ZipCode>
<StreetAddress><![CDATA[900 E 57th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1217</Code>
<Text>EXTRAGALACTIC ASTRON &amp; COSMOLO</Text>
</ProgramElement>
<ProgramElement>
<Code>1221</Code>
<Text>HEP-High Energy Physics</Text>
</ProgramElement>
<ProgramElement>
<Code>7742</Code>
<Text>PIRE- Prtnrshps Inter Res &amp; Ed</Text>
</ProgramElement>
<ProgramElement>
<Code>7793</Code>
<Text>DATA-INTENSIVE COMPUTING</Text>
</ProgramElement>
<ProgramElement>
<Code>8004</Code>
<Text>Software Institutes</Text>
</ProgramElement>
<ProgramElement>
<Code>L567</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>7566</Code>
<Text>PIRE</Text>
</ProgramReference>
<ProgramReference>
<Code>7569</Code>
<Text>CYBERINFRASTRUCTURE/SCIENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~882011</FUND_OBLG>
<FUND_OBLG>2011~634126</FUND_OBLG>
<FUND_OBLG>2012~2049116</FUND_OBLG>
<FUND_OBLG>2013~659068</FUND_OBLG>
<FUND_OBLG>2014~667552</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Scientific datasets are growing ever larger in volume and researchers are finding that the bottleneck to discovery is no longer a lack of data but an inability to manage, analyze, and share their large datasets. The goals of the Open Science Data Cloud (OSDC) were to: 1) design and implement scalable architectures for petabyte-scale platforms for data intensive science; 2) work with our OSDC international partners to populate these platforms with interesting datasets and to operate them for the research community; and 3) work with our OSDC international partners to train and educate students and early career scientists to be able to use the infrastructure, algorithms, applications, and tools required to make discoveries using large datasets.</p> <p>The first version of the OSDC was designed and developed during the period 2010&ndash;2012 and was populated with over 900 TB of research data from a variety of scientific disciplines, including environmental sciences, biological sciences, astronomy and the digital humanities.</p> <p>During the period 2012-2015, we developed a second version of the OSDC and used the underlying open source software stack to develop and operate some of the first data commons. &nbsp;By a commons we mean cyberinfrastructure that co-locates data, storage and computing infrastructure with commonly used services and tools for analyzing and sharing data to create an interoperable resource for the research community.</p> <p>We currently operate several commons with the OSDC developed technology, including the OCC NASA Project Matsu, the OCC NOAA Environmental Commons, and the Bionimbus Protected Data Cloud.&nbsp; See Figure 1.</p> <p>During the period 2010&ndash;2016, we worked with collaborators in Amsterdam, Edinburgh, San Paulo, Tsukuba and Namibia on 35 research projects that used the Open Science Data Cloud. Seventy students and early career scientists worked with our foreign partners from 30 to 60 days on these projects as part of their training. For example, one of the projects that we supported was processing satellite images from NASA&rsquo;s EO-1 satellite to detect floods in Namibia. See Figure 2 for an image of the dashboard that we developed for this project.</p> <p>In addition, we ran tutorials that provided hands on training for over 500 students using the Open Science Data Cloud.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/04/2016<br>      Modified by: Robert&nbsp;L&nbsp;Grossman</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1129076/1129076_10019587_1478305347985_osdc--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1129076/1129076_10019587_1478305347985_osdc--rgov-800width.jpg" title="The Open Science Data Cloud"><img src="/por/images/Reports/POR/2016/1129076/1129076_10019587_1478305347985_osdc--rgov-66x44.jpg" alt="The Open Science Data Cloud"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This is a screen shot of the Open Science Data Cloud (www.opensciencedatacloud.org).</div> <div class="imageCredit">screen shot of public website</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Robert&nbsp;L&nbsp;Grossman</div> <div class="imageTitle">The Open Science Data Cloud</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1129076/1129076_10019587_1478305466088_flood-dashboard--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1129076/1129076_10019587_1478305466088_flood-dashboard--rgov-800width.jpg" title="The Namibia Flood Dashboard"><img src="/por/images/Reports/POR/2016/1129076/1129076_10019587_1478305466088_flood-dashboard--rgov-66x44.jpg" alt="The Namibia Flood Dashboard"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This is a screenshot of the Namibia Flood Dashboard (http://matsu-namibiaflood.opensciencedatacloud.org).</div> <div class="imageCredit">screen shot of public website</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Robert&nbsp;L&nbsp;Grossman</div> <div class="imageTitle">The Namibia Flood Dashboard</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Scientific datasets are growing ever larger in volume and researchers are finding that the bottleneck to discovery is no longer a lack of data but an inability to manage, analyze, and share their large datasets. The goals of the Open Science Data Cloud (OSDC) were to: 1) design and implement scalable architectures for petabyte-scale platforms for data intensive science; 2) work with our OSDC international partners to populate these platforms with interesting datasets and to operate them for the research community; and 3) work with our OSDC international partners to train and educate students and early career scientists to be able to use the infrastructure, algorithms, applications, and tools required to make discoveries using large datasets.  The first version of the OSDC was designed and developed during the period 2010&ndash;2012 and was populated with over 900 TB of research data from a variety of scientific disciplines, including environmental sciences, biological sciences, astronomy and the digital humanities.  During the period 2012-2015, we developed a second version of the OSDC and used the underlying open source software stack to develop and operate some of the first data commons.  By a commons we mean cyberinfrastructure that co-locates data, storage and computing infrastructure with commonly used services and tools for analyzing and sharing data to create an interoperable resource for the research community.  We currently operate several commons with the OSDC developed technology, including the OCC NASA Project Matsu, the OCC NOAA Environmental Commons, and the Bionimbus Protected Data Cloud.  See Figure 1.  During the period 2010&ndash;2016, we worked with collaborators in Amsterdam, Edinburgh, San Paulo, Tsukuba and Namibia on 35 research projects that used the Open Science Data Cloud. Seventy students and early career scientists worked with our foreign partners from 30 to 60 days on these projects as part of their training. For example, one of the projects that we supported was processing satellite images from NASA?s EO-1 satellite to detect floods in Namibia. See Figure 2 for an image of the dashboard that we developed for this project.  In addition, we ran tutorials that provided hands on training for over 500 students using the Open Science Data Cloud.          Last Modified: 11/04/2016       Submitted by: Robert L Grossman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
