<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Problems in Bayesian Model Selection and Development and Analysis of Markov Chain Sampling Algorithms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>239998.00</AwardTotalIntnAmount>
<AwardAmount>239998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Bayesian methods are now routinely used in very complex models, with posterior distributions estimated by Markov chain Monte Carlo (MCMC) methods.  There are two consequences to this.  First, complex Bayesian models are virtually always governed by some hyperparameters, which have a large impact on subsequent inference.  Therefore, there is now a strong need for methods that enable selection of these hyperparameters.  Second, the Markov chains used to estimate the posterior distributions now run in non-standard spaces, for example large function spaces, and there is a need for the development of MCMC methods that will work well in non-standard spaces.  The investigators develop methods for efficiently estimating marginal likelihoods for large number of hyperparameter values.  This will enable implementation of the empirical Bayes method, and also enables users to determine classes of hyperparameter values which constitute reasonable choices.  The exploration of intractable posterior distributions resulting from complex Bayesian models often requires MCMC.  Unfortunately, in contrast with classical Monte Carlo, establishing central limit theorems (CLTs) for MCMC estimators is not straightforward.  This is a serious practical problem because the ability to choose an appropriate MCMC sample size hinges upon the existence of a CLT.  The investigators use spectral methods to develop checkable sufficient conditions for CLTs as well as methods for comparing the asymptotic efficiency of MCMC algorithms with the same target distribution.  They apply the theoretical results to very concrete problems of model selection and assessment.&lt;br/&gt;&lt;br/&gt;Model selection in complex situations is an important and pervasive problem in scientific and medical research.  It includes in particular variable selection in regression, where a few important variables are to be selected from many candidates and used for understanding, prediction and decision making.  Different models can lead to different conclusions, with potential impact on public policy.  The investigators develop efficient computational methods for determining optimal models in complex settings.  The project has an educational component in that graduate students are involved in the research under the supervision of the investigators.</AbstractNarration>
<MinAmdLetterDate>08/13/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1106395</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Hobert</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James P Hobert</PI_FULL_NAME>
<EmailAddress>jhobert@stat.ufl.edu</EmailAddress>
<PI_PHON>3523921941</PI_PHON>
<NSF_ID>000170306</NSF_ID>
<StartDate>08/13/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hani</FirstName>
<LastName>Doss</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hani J Doss</PI_FULL_NAME>
<EmailAddress>doss@stat.ufl.edu</EmailAddress>
<PI_PHON>3522732991</PI_PHON>
<NSF_ID>000183601</NSF_ID>
<StartDate>08/13/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Florida</Name>
<CityName>GAINESVILLE</CityName>
<ZipCode>326112002</ZipCode>
<PhoneNumber>3523923516</PhoneNumber>
<StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>969663814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Florida]]></Name>
<CityName>GAINESVILLE</CityName>
<StateCode>FL</StateCode>
<ZipCode>326112002</ZipCode>
<StreetAddress><![CDATA[1 UNIVERSITY OF FLORIDA]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~239998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Monte Carlo simulation is a methodology that uses random sampling to<br />arrive at numerical approximations to quantities that cannot be<br />computed exactly.&nbsp; The methodology allows researchers to use<br />extremely complex statistical models: if a potentially useful model<br />is so complicated that the solutions it provides cannot be computed,<br />the model can still be considered if one is willing to use<br />approximate solutions provided by Monte Carlo simulation.&nbsp; Generally<br />speaking, the longer the simulation, the more accurate are the<br />approximations.&nbsp; Recent advances in computing power have made Monte<br />Carlo simulation increasingly feasible, especially for problems<br />involving very large data sets.&nbsp; However, a key unsolved problem is<br />to determine the accuracy of the approximations that Monte Carlo<br />provides.<br /><br />Our research has produced two kinds of results.&nbsp; One of them is a<br />class of techniques for accurately quantifying the average<br />discrepancy between the approximation provided by Monte Carlo<br />simulation and the exact solution.&nbsp; The relevance of these results<br />is as follows.&nbsp; First, given a specific Monte Carlo procedure, the<br />ability to quantify the average error rate enables us to determine<br />how long we need to run the simulation to give acceptable results.<br />Second, given several competing Monte Carlo procedures, because we<br />can calculate the average error rate for each procedure, we can<br />select the optimal procedure, namely the one with the smallest<br />average error.&nbsp; Third, we can use our knowledge regarding error<br />rates to guide our development of new Monte Carlo procedures.<br /><br />The second class of results we have obtained pertain to variable<br />selection in regression.&nbsp; We consider the situation where we want to<br />relate a response variable to a set of p predictor variables.&nbsp; For<br />instance, in a medical situation the response might be a variable<br />indicating whether or not a patient benefited from a new treatment,<br />and the p predictor variables may be the activity levels for p genes<br />believed to be potentially related to the medical condition under<br />study.&nbsp; The goal is to select the predictor variables that are<br />actually do influence the response.&nbsp; Failing to include one or more<br />important predictors obviously gives rise to an inferior model,<br />while including irrelevant predictors gives rise to models that are<br />difficult to understand and are less useful.&nbsp; The standard<br />literature on variable selection has many procedures for choosing<br />the predictor variables.&nbsp; Each procedure gives rise to a single set<br />of variables to include.&nbsp; We have developed a method that does not<br />produce a single "best" model, but rather a list of possible best<br />models, together with uncertainty estimates: our methodology gives a<br />ranked list of models, where each model is presented together with<br />the probability that this is the best model.&nbsp; The benefits of this<br />is that someone analyzing the results of an experiment can interpret<br />the data from several different points of view, thus obtaining<br />insight that might be missed if one were to use only a single model.</p><br> <p>            Last Modified: 11/11/2015<br>      Modified by: Hani&nbsp;J&nbsp;Doss</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Monte Carlo simulation is a methodology that uses random sampling to arrive at numerical approximations to quantities that cannot be computed exactly.  The methodology allows researchers to use extremely complex statistical models: if a potentially useful model is so complicated that the solutions it provides cannot be computed, the model can still be considered if one is willing to use approximate solutions provided by Monte Carlo simulation.  Generally speaking, the longer the simulation, the more accurate are the approximations.  Recent advances in computing power have made Monte Carlo simulation increasingly feasible, especially for problems involving very large data sets.  However, a key unsolved problem is to determine the accuracy of the approximations that Monte Carlo provides.  Our research has produced two kinds of results.  One of them is a class of techniques for accurately quantifying the average discrepancy between the approximation provided by Monte Carlo simulation and the exact solution.  The relevance of these results is as follows.  First, given a specific Monte Carlo procedure, the ability to quantify the average error rate enables us to determine how long we need to run the simulation to give acceptable results. Second, given several competing Monte Carlo procedures, because we can calculate the average error rate for each procedure, we can select the optimal procedure, namely the one with the smallest average error.  Third, we can use our knowledge regarding error rates to guide our development of new Monte Carlo procedures.  The second class of results we have obtained pertain to variable selection in regression.  We consider the situation where we want to relate a response variable to a set of p predictor variables.  For instance, in a medical situation the response might be a variable indicating whether or not a patient benefited from a new treatment, and the p predictor variables may be the activity levels for p genes believed to be potentially related to the medical condition under study.  The goal is to select the predictor variables that are actually do influence the response.  Failing to include one or more important predictors obviously gives rise to an inferior model, while including irrelevant predictors gives rise to models that are difficult to understand and are less useful.  The standard literature on variable selection has many procedures for choosing the predictor variables.  Each procedure gives rise to a single set of variables to include.  We have developed a method that does not produce a single "best" model, but rather a list of possible best models, together with uncertainty estimates: our methodology gives a ranked list of models, where each model is presented together with the probability that this is the best model.  The benefits of this is that someone analyzing the results of an experiment can interpret the data from several different points of view, thus obtaining insight that might be missed if one were to use only a single model.       Last Modified: 11/11/2015       Submitted by: Hani J Doss]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
