<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Evaluation Communities for Learning, Inquiry, and Practice about Systems (ECLIPS)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>249932.00</AwardTotalIntnAmount>
<AwardAmount>249932</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cherniavsky</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This exploratory study will investigate what is needed to increase the capacity of STEM education evaluators to use a systems-oriented approach to evaluation. The work will be guided by two research questions:  1) Are core system evaluations more effective than evaluations without an intentional system orientation? and 2) How does ECLIPS effectively build the capacity of evaluators to conduct core system evaluations? Evaluators of ITEST and ATE projects will be guided in revising their evaluations to employ a more systems-oriented approach to evaluation. Results from the project on systems-oriented evaluation and what is needed for evaluators to learn how to use this approach will be informative to evaluators of the full range of STEM projects. Researchers will be from InSites, a support network for educational change, located in Fort Collins, Colorado. &lt;br/&gt;&lt;br/&gt;Six to eight STEM education evaluators of ITEST and ATE projects will be identified to participate in the study. These evaluators will work with guides and others who are knowledgeable about systems-oriented evaluation to revise existing evaluation plans. Much of the interactions will be through monthly webinars, annual meetings, and individual interaction with guides. Sessions will be recorded and interactions among participants and leaders will serve as a major source of data. In addition, a pre and post questionnaire will be administered to the STEM education evaluators. Other STEM evaluators and interested parties will be used to validate inferences made.  &lt;br/&gt;&lt;br/&gt;Outcomes from the project will include six to eight STEM education evaluators who are more knowledgeable about systems-oriented evaluations, a written guide on how others can be educated in using such an approach, and published articles on the process. The findings will be particularly relevant to STEM project evaluators and evaluators in general.</AbstractNarration>
<MinAmdLetterDate>08/19/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1118819</AwardID>
<Investigator>
<FirstName>Beverly</FirstName>
<LastName>Parsons</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Beverly A Parsons</PI_FULL_NAME>
<EmailAddress>bparsons@insites.org</EmailAddress>
<PI_PHON>6613435052</PI_PHON>
<NSF_ID>000334262</NSF_ID>
<StartDate>08/19/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Pat</FirstName>
<LastName>Jessup</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pat Jessup</PI_FULL_NAME>
<EmailAddress>pjessup@insites.org</EmailAddress>
<PI_PHON>9702261003</PI_PHON>
<NSF_ID>000585711</NSF_ID>
<StartDate>08/19/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marah</FirstName>
<LastName>Moore</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marah Moore</PI_FULL_NAME>
<EmailAddress>marah@i2i-Institute.com</EmailAddress>
<PI_PHON>9702261003</PI_PHON>
<NSF_ID>000585712</NSF_ID>
<StartDate>08/19/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>InSites, 'A Support Network for Educational Change'</Name>
<CityName>Fort Collins</CityName>
<ZipCode>805264247</ZipCode>
<PhoneNumber>9702261003</PhoneNumber>
<StreetAddress>1307 Sanford Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>105309921</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>INSITES, A SUPPORT NETWORK FOR EDUCATIONAL CHANGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>105309921</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[InSites, 'A Support Network for Educational Change']]></Name>
<CityName>Fort Collins</CityName>
<StateCode>CO</StateCode>
<ZipCode>805264247</ZipCode>
<StreetAddress><![CDATA[1307 Sanford Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7261</Code>
<Text>Project &amp; Program Evaluation</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~249932</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="Text">The goal of <em>Evaluation Communities for Learning, Inquiry, and Practice about Systems (ECLIPS)</em> was to explore the effectiveness of an 18-month process to increase the capacity of evaluators to conduct systems-oriented evaluations of STEM (science, technology, engineering, and science) education projects. We investigated a) whether systems-oriented evaluations helped to increase the effectiveness and value of the evaluations of the STEM projects and b) if the process we used in ECLIPS was effective in increasing the ability of evaluators to conduct systems-oriented evaluations. The ECLIPS participants were in four roles: ECLIPS Guides; STEM Education Evaluators (SEESs); Resource Center Leaders; and External Review Panelists. The ECLIPS Principal Investigator (PI) and co-PIs serves as the ECLIPS Guides.</p> <p class="Text">In the first two years we focused on building the ECLIPS community of practice and testing its value for participants. Through monthly webinars and annual one-day in-person meetings, we presented systems concepts including systems definitions; the relationships, perspectives, boundaries, and patterns occurring within systems; and the dynamics or movement that occurs within systems. These concepts were tied to the process of conducting evaluations. The webinars and in-person meetings included presentations by the ECLIPS Guides as well as other ECLIPS members.</p> <p class="Text">Between events, the ECLIPS Guides provided the SEEs with tools and assignments and held phone conversations with them to assist in applying system concepts to their individual evaluations. For example, project assignments and tools helped the SEEs use a framework for identifying and describing systems concepts in their evaluations; create&nbsp; systems diagrams of the projects they were evaluating; and look for levers for systemic change in the projects. Phone call topics included: changes in SEEs thinking related to systems; subsystems and system dynamics in the projects they were evaluating; patterns they were seeing through their evaluation of the projects; and changes they were considering in their evaluation plans and their dissemination plans.</p> <p class="Text">In year three, we (the ECLIPS Guides) emphasized relationship-building, knowledge-integration, and dissemination activities. We continued various connections with ECLIPS members. For example, we hosted a follow-up webinar several months after the conclusion of the 18-month ECLIPS process so members could share ways in which they had applied systems concepts to their evaluations and were sustaining their attention to a systems orientation. Based on the knowledge gained from the ECLIPS and other work, we and the other ECLIPS members continue to deepen our thinking and application of systems concepts to our evaluation work.</p> <p class="Text">The highest profile example of this integration is the 2014 American Evaluation Association (AEA) conference theme that was developed by Beverly Parsons (ECLIPS PI and 2014 AEA president) with feedback from ECLIPS members. Matt Keene, one of the ECLIPS external review panel members, served as the conference program co-chair and helped to develop this theme for the October 2014 conference. The conference theme &ndash; <em>Visionary Evaluation for a Sustainable, Equitable Future</em> &ndash; focused on integrating systems thinking into evaluation, building relationships, and understanding sustainable, equitable living.</p> <p>Over the course of the project, ECLIPS members gave over 15 conference presentations, (primarily at the American Evaluation Association annual conferences) related to systems concepts and evaluation. Two articles have been submitted and are currently under review by the American Journal of Evaluation. One of these focuses on the ECLIPS process and its value in building evaluation capacity related to systems and the other focuses on t...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The goal of Evaluation Communities for Learning, Inquiry, and Practice about Systems (ECLIPS) was to explore the effectiveness of an 18-month process to increase the capacity of evaluators to conduct systems-oriented evaluations of STEM (science, technology, engineering, and science) education projects. We investigated a) whether systems-oriented evaluations helped to increase the effectiveness and value of the evaluations of the STEM projects and b) if the process we used in ECLIPS was effective in increasing the ability of evaluators to conduct systems-oriented evaluations. The ECLIPS participants were in four roles: ECLIPS Guides; STEM Education Evaluators (SEESs); Resource Center Leaders; and External Review Panelists. The ECLIPS Principal Investigator (PI) and co-PIs serves as the ECLIPS Guides. In the first two years we focused on building the ECLIPS community of practice and testing its value for participants. Through monthly webinars and annual one-day in-person meetings, we presented systems concepts including systems definitions; the relationships, perspectives, boundaries, and patterns occurring within systems; and the dynamics or movement that occurs within systems. These concepts were tied to the process of conducting evaluations. The webinars and in-person meetings included presentations by the ECLIPS Guides as well as other ECLIPS members. Between events, the ECLIPS Guides provided the SEEs with tools and assignments and held phone conversations with them to assist in applying system concepts to their individual evaluations. For example, project assignments and tools helped the SEEs use a framework for identifying and describing systems concepts in their evaluations; create  systems diagrams of the projects they were evaluating; and look for levers for systemic change in the projects. Phone call topics included: changes in SEEs thinking related to systems; subsystems and system dynamics in the projects they were evaluating; patterns they were seeing through their evaluation of the projects; and changes they were considering in their evaluation plans and their dissemination plans. In year three, we (the ECLIPS Guides) emphasized relationship-building, knowledge-integration, and dissemination activities. We continued various connections with ECLIPS members. For example, we hosted a follow-up webinar several months after the conclusion of the 18-month ECLIPS process so members could share ways in which they had applied systems concepts to their evaluations and were sustaining their attention to a systems orientation. Based on the knowledge gained from the ECLIPS and other work, we and the other ECLIPS members continue to deepen our thinking and application of systems concepts to our evaluation work. The highest profile example of this integration is the 2014 American Evaluation Association (AEA) conference theme that was developed by Beverly Parsons (ECLIPS PI and 2014 AEA president) with feedback from ECLIPS members. Matt Keene, one of the ECLIPS external review panel members, served as the conference program co-chair and helped to develop this theme for the October 2014 conference. The conference theme &ndash; Visionary Evaluation for a Sustainable, Equitable Future &ndash; focused on integrating systems thinking into evaluation, building relationships, and understanding sustainable, equitable living.  Over the course of the project, ECLIPS members gave over 15 conference presentations, (primarily at the American Evaluation Association annual conferences) related to systems concepts and evaluation. Two articles have been submitted and are currently under review by the American Journal of Evaluation. One of these focuses on the ECLIPS process and its value in building evaluation capacity related to systems and the other focuses on the relationship between culturally responsive evaluation and systems-oriented evaluation. The ECLIPS exploratory project was effective in deepening STEM evaluatorsÆ understanding of sys...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
