<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Sufficient dimension reduction of high-dimensional data through regularized covariance estimation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2011</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>195311.00</AwardTotalIntnAmount>
<AwardAmount>195311</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many statistical methods for dimensionality reduction, classification, and prediction, require an estimate of a covariance or precision matrix.  In high-dimensional settings, (where the number of variables is larger than the sample size), it is known that classical covariance estimation with the sample covariance performs poorly.  This has lead to a wealth of alternative regularized high-dimension covariance estimators, many of which have been proposed in the last decade. These estimators have been analyzed primarily in terms of how they perform when estimating the population covariance or precision matrix directly, rather than how they affect the performance of the statistical methods that require a regularized covariance estimate.  A particular class of statistical methods of interest is those that perform sufficient dimension reduction (SDR), a powerful approach to reduce the dimensionality of the predictor in regression problems. Most of the SDR methodology and theory requires the number of variables to be less than the sample size, preventing its application to high-dimensional data.  The PI, Co-PI, and their colleagues adapt sufficient dimension reduction methodology to high-dimensional settings via regularized covariance estimation.  Specifically, they develop alternative SDR methodology, high-dimensional asymptotic analysis (as both the number of variables and the sample size grow), efficient computational algorithms, and applications to data.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Genetics, spectroscopy, climate studies, and remote sensing are a few examples of the many research fields that produce high-dimensional data; these are data with many more measured characteristics than subjects or cases.  Many standard statistical methods for prediction, classification, and data reduction are either inapplicable or perform poorly in this setting.  In response, statistical methods to extract a subset of the measured characteristics for use in predictive models have been developed; however, these methods operate under the assumption that a relatively small number of measured characteristics are relevant for prediction.  The investigators address this deficiency by developing new methods for the reduction of high-dimensional data for use in predictive modeling, which unlike many existing methods, are able to extract relevant predictive information from all of the measured characteristics.  In addition, the investigators develop publicly available computer software to implement these new methods, enabling their application by researchers and practitioners in many fields.</AbstractNarration>
<MinAmdLetterDate>04/29/2011</MinAmdLetterDate>
<MaxAmdLetterDate>04/08/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1105650</AwardID>
<Investigator>
<FirstName>Ralph</FirstName>
<LastName>Cook</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ralph D Cook</PI_FULL_NAME>
<EmailAddress>dennis@stat.umn.edu</EmailAddress>
<PI_PHON>6126257732</PI_PHON>
<NSF_ID>000410997</NSF_ID>
<StartDate>04/29/2011</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Rothman</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam J Rothman</PI_FULL_NAME>
<EmailAddress>arothman@umn.edu</EmailAddress>
<PI_PHON>6126260356</PI_PHON>
<NSF_ID>000547003</NSF_ID>
<StartDate>04/29/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554552070</ZipCode>
<StreetAddress><![CDATA[200 OAK ST SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~34546</FUND_OBLG>
<FUND_OBLG>2012~35183</FUND_OBLG>
<FUND_OBLG>2013~125582</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-df993c52-234c-7e58-3b2e-e5d105f615a3"> </span></p> <p dir="ltr"><span>Some statistical applications require the modeling of data with more measured characteristics than subjects, e.g. data from gene microarray experiments, functional MRI, recommender systems, and spectroscopy. &nbsp;Traditional methods for predictive modeling with these data perform inadequatly. &nbsp;The projects of this grant addressed this deficiency by developing new methods for predictive modeling that apply to datasets with more measured characteristics than subjects. &nbsp;We call these data high-dimensional.</span></p> <p dir="ltr">&nbsp;</p> <p dir="ltr">We extended the Principal Fitted Components model for sufficient dimension reduction in regression to high-dimensional settings by incorporating shrinkage estimation of the inverse covariance matrix. &nbsp;We also proposed a new method for prediction in normal linear regression where most of the explanatory variables contribute information about the response variable.</p> <p dir="ltr">&nbsp;</p> <p dir="ltr">Fitting statistical models for prediction often requires the estimation of covariance matrices. We developed a new sparse and positive definite covariance estimator through convex optimization and we illustrated its use in fitting the quadratic discriminant analysis model for classification. &nbsp;We also proposed a new penalized likelihood method to fit this quadratic discriminant analysis model. &nbsp;In addition, we established some theoretical properties of the optimization problems used to define a popular shrinkage estimator of the inverse covariance matrix.</p> <p dir="ltr">&nbsp;</p> <p dir="ltr"><span>These research projects were published in peer reviewed academic journals. &nbsp;The PI also gave invited talks on these projects at academic conferences and at statistics departments. &nbsp;</span>The PI coadvised and partially supported a PhD student at the University of Minnesota with this grant. &nbsp;This student completed his PhD degree and is currently working in academia. In addition, two R software packages "PDSCE" and "abundant" were created and are available to the public at the CRAN repository.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/12/2015<br>      Modified by: Adam&nbsp;J&nbsp;Rothman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Some statistical applications require the modeling of data with more measured characteristics than subjects, e.g. data from gene microarray experiments, functional MRI, recommender systems, and spectroscopy.  Traditional methods for predictive modeling with these data perform inadequatly.  The projects of this grant addressed this deficiency by developing new methods for predictive modeling that apply to datasets with more measured characteristics than subjects.  We call these data high-dimensional.   We extended the Principal Fitted Components model for sufficient dimension reduction in regression to high-dimensional settings by incorporating shrinkage estimation of the inverse covariance matrix.  We also proposed a new method for prediction in normal linear regression where most of the explanatory variables contribute information about the response variable.   Fitting statistical models for prediction often requires the estimation of covariance matrices. We developed a new sparse and positive definite covariance estimator through convex optimization and we illustrated its use in fitting the quadratic discriminant analysis model for classification.  We also proposed a new penalized likelihood method to fit this quadratic discriminant analysis model.  In addition, we established some theoretical properties of the optimization problems used to define a popular shrinkage estimator of the inverse covariance matrix.   These research projects were published in peer reviewed academic journals.  The PI also gave invited talks on these projects at academic conferences and at statistics departments.  The PI coadvised and partially supported a PhD student at the University of Minnesota with this grant.  This student completed his PhD degree and is currently working in academia. In addition, two R software packages "PDSCE" and "abundant" were created and are available to the public at the CRAN repository.          Last Modified: 08/12/2015       Submitted by: Adam J Rothman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
