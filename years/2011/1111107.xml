<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SOCS: Socially Intelligent Computing for Coding of Qualitative Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>747831.00</AwardTotalIntnAmount>
<AwardAmount>779831</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will develop and evaluate an innovative research tool, based on Natural Language Processing (NLP) and Machine Learning (ML), to support qualitative social science research, specifically content analysis. Content analysis is a qualitative research technique for finding evidence of concepts of theoretical interest using text rather than numbers as its raw data.  The process of identifying and labeling significant features in text is referred to as "coding," and the result of such an analysis is a text annotated with codes for the concepts exhibited. This technique has become increasingly popular and more applicable as the volume of available "born-digital" text has exploded.  However, the reliance on manual analysis of the text limits the scale and scope of content analysis research.&lt;br/&gt;&lt;br/&gt;In this project, the problem of coding qualitative data is conceptualized as an information extraction problem amenable to automation using NLP. However, rather than seeking to automate the process, the technologies will be used in a supporting role, creating a human-computer partnership. ML will be used to induce NLP rules from examples of coded text, avoiding the need to develop rules manually. To reduce the amount of training data needed from the human participants, an active learning process will be employed, in which a few hand-coded examples are used to create an initial model that can be further evolved through interaction with the user. These approaches will be combined in a prototype tool to support qualitative content analysis. As a demonstration and test of the tool, it will be applied to current and novel studies of cyber-infrastructure-supported distributed groups, specifically free/libre open source software development teams, and then to a broad range of social science research problems. This broad usage will also provide a test of the generalizability of a socio-computational approach to this problem.&lt;br/&gt;&lt;br/&gt;The intellectual merit of the research is four-fold.  First, the proposal seeks to develop a novel socio-computational system that supports a human-computer partnership through the integration of information extraction and active learning. Second, a validation study will apply the tool to a diverse set of codes, providing evidence of the generality and limits of a socio-computational approach.  Third, the demonstration studies using the tool will contribute to research on distributed groups.  Finally, the project addresses a fundamental methodological problem in the broad domain of qualitative research, namely dealing with large quantities of unstructured qualitative data, by applying innovative computer-support.  By avoiding the need for hand-written rules and reducing the required amount of hand-annotated training data, this partnership will make practical the use of a system for coding large quantities of qualitative data in various domains.&lt;br/&gt;&lt;br/&gt;The project has numerous broader impacts. It will benefit society by providing useful infrastructure for research in the form of a content analysis tool for scientific research and in for the form of corpora of annotated data for use in future Natural Language Processing research. The demonstration studies will provide generalizable knowledge to improve the effectiveness of distributed groups, an increasingly important mode of organization. Finally, the project contributes to the education and training, of women and minority group members in particular.</AbstractNarration>
<MinAmdLetterDate>08/30/2011</MinAmdLetterDate>
<MaxAmdLetterDate>05/15/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1111107</AwardID>
<Investigator>
<FirstName>Nancy</FirstName>
<LastName>McCracken</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nancy J McCracken</PI_FULL_NAME>
<EmailAddress>njm@ecs.syr.edu</EmailAddress>
<PI_PHON>3154435484</PI_PHON>
<NSF_ID>000292278</NSF_ID>
<StartDate>05/15/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Nancy</FirstName>
<LastName>McCracken</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nancy J McCracken</PI_FULL_NAME>
<EmailAddress>njm@ecs.syr.edu</EmailAddress>
<PI_PHON>3154435484</PI_PHON>
<NSF_ID>000292278</NSF_ID>
<StartDate>08/30/2011</StartDate>
<EndDate>08/30/2012</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Crowston</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin Crowston</PI_FULL_NAME>
<EmailAddress>crowston@syr.edu</EmailAddress>
<PI_PHON>3154431676</PI_PHON>
<NSF_ID>000106314</NSF_ID>
<StartDate>08/30/2011</StartDate>
<EndDate>08/30/2012</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Syracuse University</Name>
<CityName>SYRACUSE</CityName>
<ZipCode>132441200</ZipCode>
<PhoneNumber>3154432807</PhoneNumber>
<StreetAddress>OFFICE OF SPONSORED PROGRAMS</StreetAddress>
<StreetAddress2><![CDATA[211 Lyman Hall]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY24</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002257350</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SYRACUSE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002257350</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Syracuse University]]></Name>
<CityName>SYRACUSE</CityName>
<StateCode>NY</StateCode>
<ZipCode>132441200</ZipCode>
<StreetAddress><![CDATA[OFFICE OF SPONSORED PROGRAMS]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY24</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>7642</Code>
<Text>VIRTUAL ORGANIZATIONS</Text>
</ProgramElement>
<ProgramElement>
<Code>7953</Code>
<Text>SOCIAL-COMPUTATIONAL SYSTEMS</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7642</Code>
<Text>VIRTUAL ORGANIZATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>7953</Code>
<Text>SOCIAL-COMPUTATIONAL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~325196</FUND_OBLG>
<FUND_OBLG>2012~422635</FUND_OBLG>
<FUND_OBLG>2013~16000</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="NoSpacingTimes">The research of many scientists may need to examine text for evidence of particular concepts and use them to analyze differences between their objects of study. For example, a researcher might study organizational behavior by looking at how often different types of people in the organization express concepts like &ldquo;appreciation&rdquo; or &ldquo;inclusion&rdquo; in their group emails.&nbsp; A common research method is &ldquo;content analysis&rdquo; in which the researchers develop rules to reliably and consistently label evidence of such concepts in order to attach appropriate labels to pieces of text.&nbsp; However, in the era of big data with millions of text documents, this human annotation method is not feasible to handle such large amounts of data.</p> <p class="NoSpacingTimes">This project implemented a software tool that enables scientists to use these research methods on large quantities of text in a semi-automated fashion.&nbsp; The tool starts with machine learning that uses human-annotated text to learn a model to predict labels in text. &nbsp;Typically, the initial model will not be sufficiently accurate so the tool uses active learning to semi-automatically analyze the text. It works in partnership with the scientist by predicting the occurrences of concepts in small text examples and by getting feedback from the scientist to correct its predictions.&nbsp; The examples are chosen to be corrected as the ones that the model is most uncertain about so that the machine learning can get the most informative examples and learn a more accurate model with a minimum of human annotation time.&nbsp; The goal is for the software to produce ever more accurate predictive models until the scientist can use the machine learning to reliably discover the concepts in large amounts of data.</p> <p class="NoSpacingTimes">The tool was implemented and used with two different projects, one in leadership behavior and one in training citizen scientists.&nbsp; The results are that the system could successfully build automatic prediction of concepts for some concepts, but not for others.&nbsp; The concepts that were most difficult were either extremely sparse in the data, or they were concepts that were more difficult concepts for both humans and the automatic learner, due to the complexity and diversity of language used in the text.&nbsp; In the future, we hope to apply new &ldquo;deep learning&rdquo; techniques for the semantic understanding of language in order to improve the tool to be successful on more of the concepts of interest to researchers.</p> <p class="NoSpacingTimes">The potential impact of this tool is that it will enable discovery from textual &ldquo;big data&rdquo;.&nbsp; It can enable researcher to address research questions using vast quantities of email, social media or other types of communications where it is impossible to do so using current techniques.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/30/2015<br>      Modified by: Nancy&nbsp;J&nbsp;Mccracken</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The research of many scientists may need to examine text for evidence of particular concepts and use them to analyze differences between their objects of study. For example, a researcher might study organizational behavior by looking at how often different types of people in the organization express concepts like "appreciation" or "inclusion" in their group emails.  A common research method is "content analysis" in which the researchers develop rules to reliably and consistently label evidence of such concepts in order to attach appropriate labels to pieces of text.  However, in the era of big data with millions of text documents, this human annotation method is not feasible to handle such large amounts of data. This project implemented a software tool that enables scientists to use these research methods on large quantities of text in a semi-automated fashion.  The tool starts with machine learning that uses human-annotated text to learn a model to predict labels in text.  Typically, the initial model will not be sufficiently accurate so the tool uses active learning to semi-automatically analyze the text. It works in partnership with the scientist by predicting the occurrences of concepts in small text examples and by getting feedback from the scientist to correct its predictions.  The examples are chosen to be corrected as the ones that the model is most uncertain about so that the machine learning can get the most informative examples and learn a more accurate model with a minimum of human annotation time.  The goal is for the software to produce ever more accurate predictive models until the scientist can use the machine learning to reliably discover the concepts in large amounts of data. The tool was implemented and used with two different projects, one in leadership behavior and one in training citizen scientists.  The results are that the system could successfully build automatic prediction of concepts for some concepts, but not for others.  The concepts that were most difficult were either extremely sparse in the data, or they were concepts that were more difficult concepts for both humans and the automatic learner, due to the complexity and diversity of language used in the text.  In the future, we hope to apply new "deep learning" techniques for the semantic understanding of language in order to improve the tool to be successful on more of the concepts of interest to researchers. The potential impact of this tool is that it will enable discovery from textual "big data".  It can enable researcher to address research questions using vast quantities of email, social media or other types of communications where it is impossible to do so using current techniques.          Last Modified: 11/30/2015       Submitted by: Nancy J Mccracken]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
