<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Ordering-Based Semantics for Emerging Models of Parallel Computing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>497530.00</AwardTotalIntnAmount>
<AwardAmount>497530</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>With the proliferation of multicore processors has come resurgence&lt;br/&gt;of interest in parallel programming languages and models,&lt;br/&gt;particularly those intended to make it easier for non-expert&lt;br/&gt;programmers to correctly implement important classes of parallel&lt;br/&gt;applications.  Unfortunately, most such languages and models are &lt;br/&gt;informally -- and thus imprecisely -- defined.  The aim of the &lt;br/&gt;sponsored research is to develop more formal definitions, which will&lt;br/&gt;be needed in order to truly understand and reason about programs,&lt;br/&gt;guide language implementations, and verify implementation&lt;br/&gt;correctness.  Within computer science and allied fields, formal&lt;br/&gt;definitions will facilitate the transition to ubiquitous parallel&lt;br/&gt;computing.  For society at large, this transition will be essential&lt;br/&gt;to maintain the momentum of the IT revolution, across government,&lt;br/&gt;industry, science, the arts, and entertainment.&lt;br/&gt;&lt;br/&gt;The technical core of the sponsored research is the use of&lt;br/&gt;history-based executions to capture both the behavior of individual&lt;br/&gt;threads of control and the interactions among those threads.  In a&lt;br/&gt;departure from previous work, the interactions are always expressed&lt;br/&gt;in terms of atomic blocks, which can capture arbitrary&lt;br/&gt;language-level synchronization mechanisms.  Specific topics being&lt;br/&gt;addressed include transactional memory (including the concepts of&lt;br/&gt;publication and privatization), explicit speculation, and &lt;br/&gt;determinism.  The notion of determinism, in particular, is central&lt;br/&gt;to several emerging languages and models specifically intended for &lt;br/&gt;non-expert programmers.  A formal framework for the definition of&lt;br/&gt;determinism will allow alternative definitions to be compared,&lt;br/&gt;contrasted, and correctly implemented.</AbstractNarration>
<MinAmdLetterDate>07/19/2011</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116055</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Scott</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael L Scott</PI_FULL_NAME>
<EmailAddress>scott@cs.rochester.edu</EmailAddress>
<PI_PHON>5852757745</PI_PHON>
<NSF_ID>000343030</NSF_ID>
<StartDate>07/19/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146270140</ZipCode>
<StreetAddress><![CDATA[518 HYLAN, RC BOX 270140]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~497530</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Much of the complexity of parallel computing stems from the need to reason about the many possible orderings of operations performed in different threads of control. &nbsp;This complexity impacts both language designers, who must formally specify the semantics (meaning) of their notation, and application programmers, who must write programs that run correctly.</p> <p>Work supported by this grant has advanced our understanding of ordering for two of today's most important programming models&mdash;namely, transactional and deterministic parallelism. &nbsp;For both of these models, we distinguish sharply between the orderings visible at the level of the application program and the orderings visible in the underlying language implementation. &nbsp;The former are simpler, but more abstract. &nbsp;The latter enable optimizations that are hidden from the typical programmer.</p> <p>With transactional parallelism, the application programmer writes code blocks that appear to execute atomically&mdash;as indivisible operations. &nbsp;The language implementation achieves atomicity by aborting and restarting a code block whenever two or more values read by that block could not (because of an intervening write by some other block) have been valid at the same time. &nbsp;Past models of transactional ordering have required inconsistent reads to cause <em>immediate</em>&nbsp;aborts, but implementations can often be faster if "zombie" blocks&mdash;those that are doomed to abort eventually&mdash;can continue to run for a while. &nbsp;We developed the first transactional semantics that permit such implementations, and allow them to be proven correct. &nbsp;These semantics pave the way for entirely new classes of high-performance transactional parallelism.</p> <p>With deterministic parallelism, program behavior is supposed to depend only on the code of the program and its inputs. &nbsp;This stands in sharp contrast to most models of parallelism (including transactional ones), in which program behavior often depends on how the underlying system schedules (interleaves) the operations of different threads. &nbsp;The exact meaning of "determinism," however, has proven surprisingly difficult to formalize. &nbsp;We have addressed the problem by noting that every execution of a program at the implementation level corresponds to (i.e., implements) some abstract execution at the application level. &nbsp;We define a language implementation to be correct if any two observable executions at the implementation level correspond to abstract (application-level) executions that are considered to be <em>equivalent</em>. &nbsp;The definition of determinism then amounts to defining a notion of equivalence for abstract executions. &nbsp;We identified definitions corresponding to a wide variety of informal notions of determinism found in prior studies. &nbsp;Building on a favorite definition, we also designed and implemented a deterministic parallel scripting language language&mdash;Deterministic Parallel Ruby (DPR). &nbsp;Unlike previous notations, DPR introduces performance-enhancing parallelism without sacrificing the simplicity of programming that is the principal strength of scripting.</p> <p>In other work, we developed a general technique for software implementations of transactional parallelism that improves performance while preserving application-level semantics by allowing code blocks at the implementation level to read old values of recently overwritten locations (after which they may be able to "commit in the past"). &nbsp;We also developed techniques that allow the programmer to provide a transactional system with hints about the likely sources of conflicts. &nbsp;Implementation-level software can then use these hints to significantly reduce the abort rates of hardware-supported transactions such as those found on recent processors from Intel and IBM.</p><br> <p>            Last Modified: 10/30/...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Much of the complexity of parallel computing stems from the need to reason about the many possible orderings of operations performed in different threads of control.  This complexity impacts both language designers, who must formally specify the semantics (meaning) of their notation, and application programmers, who must write programs that run correctly.  Work supported by this grant has advanced our understanding of ordering for two of today's most important programming models&mdash;namely, transactional and deterministic parallelism.  For both of these models, we distinguish sharply between the orderings visible at the level of the application program and the orderings visible in the underlying language implementation.  The former are simpler, but more abstract.  The latter enable optimizations that are hidden from the typical programmer.  With transactional parallelism, the application programmer writes code blocks that appear to execute atomically&mdash;as indivisible operations.  The language implementation achieves atomicity by aborting and restarting a code block whenever two or more values read by that block could not (because of an intervening write by some other block) have been valid at the same time.  Past models of transactional ordering have required inconsistent reads to cause immediate aborts, but implementations can often be faster if "zombie" blocks&mdash;those that are doomed to abort eventually&mdash;can continue to run for a while.  We developed the first transactional semantics that permit such implementations, and allow them to be proven correct.  These semantics pave the way for entirely new classes of high-performance transactional parallelism.  With deterministic parallelism, program behavior is supposed to depend only on the code of the program and its inputs.  This stands in sharp contrast to most models of parallelism (including transactional ones), in which program behavior often depends on how the underlying system schedules (interleaves) the operations of different threads.  The exact meaning of "determinism," however, has proven surprisingly difficult to formalize.  We have addressed the problem by noting that every execution of a program at the implementation level corresponds to (i.e., implements) some abstract execution at the application level.  We define a language implementation to be correct if any two observable executions at the implementation level correspond to abstract (application-level) executions that are considered to be equivalent.  The definition of determinism then amounts to defining a notion of equivalence for abstract executions.  We identified definitions corresponding to a wide variety of informal notions of determinism found in prior studies.  Building on a favorite definition, we also designed and implemented a deterministic parallel scripting language language&mdash;Deterministic Parallel Ruby (DPR).  Unlike previous notations, DPR introduces performance-enhancing parallelism without sacrificing the simplicity of programming that is the principal strength of scripting.  In other work, we developed a general technique for software implementations of transactional parallelism that improves performance while preserving application-level semantics by allowing code blocks at the implementation level to read old values of recently overwritten locations (after which they may be able to "commit in the past").  We also developed techniques that allow the programmer to provide a transactional system with hints about the likely sources of conflicts.  Implementation-level software can then use these hints to significantly reduce the abort rates of hardware-supported transactions such as those found on recent processors from Intel and IBM.       Last Modified: 10/30/2015       Submitted by: Michael L Scott]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
