<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Medium: Plug and Train: Mixed Reality Humans for Team Training</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>1087380.00</AwardTotalIntnAmount>
<AwardAmount>1087380</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>There are an estimated 45 million inpatient surgical procedures per year in the U.S., where critical incidents account for 832,500 deaths and between 1,350,000 and 7,650,000 cases of significant harm to the patient. Of these errors, teamwork failures (e.g. misunderstanding procedural instructions and not acknowledging and repeating back drug dosage levels) are a significant factor - up to 70% for medical operations such as surgery. Reducing teamwork failures requires team training using effective protocols; however, few team training opportunities on these protocols exist. &lt;br/&gt;&lt;br/&gt;Intellectual merit:  To address this deficiency in training, the project will substitute unavailable human team members with mixed reality humans (MRH). MRHs will plug into roles of unavailable human team members to facilitate training in multi-party scenarios. The research team will first develop systems capable of having MRH inhabit training environments alongside human trainees.  Then, they will develop novel conversational modeling techniques to support a training experience to be conducted with any combination of human trainees and virtual human teammates.  Finally, the  team will conduct a set of user studies with the system to explore the effect of mixed reality humans, the impact of mixed reality humans on team dynamics, and the efficacy of team training with mixed reality humans. The result of this work will be effective self-contained, portable MRH systems that integrate into clinical training environments.&lt;br/&gt;&lt;br/&gt;Broader impacts: The project will result in important educational tools for team training that will ultimately lower the high social and financial costs of team errors in medicine.  Better trained teams make fewer and less serious mistakes, thereby improving patient outcomes.  The tools and findings will be integrated into the curriculum of continuing medical education and new hire orientation at the University of Florida. While initially applied and evaluated in a clinical setting, the investigators anticipate that mixed reality human team training will be applicable to other multiparty scenarios in aviation, the military, education, and crisis response.</AbstractNarration>
<MinAmdLetterDate>06/19/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/04/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1161491</AwardID>
<Investigator>
<FirstName>Benjamin</FirstName>
<LastName>Lok</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Benjamin C Lok</PI_FULL_NAME>
<EmailAddress>lok@cise.ufl.edu</EmailAddress>
<PI_PHON>3522149829</PI_PHON>
<NSF_ID>000364797</NSF_ID>
<StartDate>06/19/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Samsun</FirstName>
<LastName>Lampotang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Samsun Lampotang</PI_FULL_NAME>
<EmailAddress>SLampotang@anest.ufl.edu</EmailAddress>
<PI_PHON>3528460923</PI_PHON>
<NSF_ID>000484088</NSF_ID>
<StartDate>06/19/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Casey</FirstName>
<LastName>White</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Casey White</PI_FULL_NAME>
<EmailAddress>cwhite@anest.ufl.edu</EmailAddress>
<PI_PHON>3523923516</PI_PHON>
<NSF_ID>000601241</NSF_ID>
<StartDate>06/19/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Wendling</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam Wendling</PI_FULL_NAME>
<EmailAddress>awendling@anest.ufl.edu</EmailAddress>
<PI_PHON>3523923516</PI_PHON>
<NSF_ID>000601249</NSF_ID>
<StartDate>06/19/2012</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Florida</Name>
<CityName>GAINESVILLE</CityName>
<ZipCode>326112002</ZipCode>
<PhoneNumber>3523923516</PhoneNumber>
<StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>969663814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Florida]]></Name>
<CityName>Gainesville</CityName>
<StateCode>FL</StateCode>
<ZipCode>326112002</ZipCode>
<StreetAddress><![CDATA[1 University of Florida]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~270514</FUND_OBLG>
<FUND_OBLG>2013~268186</FUND_OBLG>
<FUND_OBLG>2014~269195</FUND_OBLG>
<FUND_OBLG>2015~279485</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Project Outcomes</p> <p>Findings</p> <div class="page" title="Page 1"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>A team of computer science, medical education, and simulation researchers from the University of Florida and University of Virginia have collaborated to address the problem of how to reduce errors in the operating room. Our team has focused on errors due to team communication problems, which some estimate results in over 560,000 deaths annually.</span></p> <p><span>To address communication problems, we worked to empower every team member in the operating room team to learn how to administer drugs accurately and speak up on patient safety issues. Although best practices, such as closed-loop communication (repeating back what one hears) and patient safety assertive statements (saying certain words when one is concerned), implementing them in the practice is difficult because teams are not able to practice. Teams are not able to practice because of the logistics of having all team members together.</span></p> <p><span>To address this issue, our team developed&nbsp;</span>mixed reality humans. Mixed reality humans are a combination of virtual and physical elements. The Mixed reality humans play the role of operating room teammates to practice communication skills. We used the mixed reality humans to plug into roles of unavailable human team members, as to facilitate team training.</p> <p>During the past seven years, the the team established some important fundamental advances in how to build mixed reality humans and how to train operating room personnel. We have run a series of studies that resulted in training operating room personnel at the University of Florida Health Hospitals. These simulations showed that mixed reality humans helped train the user on best communication practices including repeating back drug orders and speaking up when they felt the patient's health was at risk. Hundreds of operating room staff (nurses, surgical technicians, anesthesiology residents) have been trained with feedback being extremely positive.</p> <p>The work has also been disseminated. First, other groups within the UF Health Hospital system at both Gainesville and Jacksonville have taken the mixed reality humans and built scenarios to train nurses on new procedures. Second, the intellectual property generated from this work has been licensed by Shadow Health, Inc. Shadow Health has commercialized other simulation technologies and is currently in over 1500 nursing college and university programs internationally with over a hundred thousand users a year. Thus, the work and findings of this award will have a real world impact on nursing education and patient outcomes.</p> <p>This work has also resulted in publications that demonstrated that mixed reality humans can train and implement best practices. We have also studied the how people treat mixed reality humans compared to real humans, what aspects of the mixed reality human impacts virtual reality concepts such as social presence (how much people feel they interact with a virtual person like a real person). The team has published 7 journal and 5 conference publications. Further, 3 Ph.D. students have been supported and graduated from this award. The graduates include an assistant professor at Clemson University, and developers at Amazon.com and VR startup Strivr Labs.</p> <p>&nbsp;</p> </div> </div> </div> </div><br> <p>            Last Modified: 07/06/2018<br>      Modified by: Benjamin&nbsp;C&nbsp;Lok</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1161491/1161491_10182703_1530903564120_ScreenShot2018-07-06at2.56.44PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1161491/1161491_10182703_1530903564120_ScreenShot2018-07-06at2.56.44PM--rgov-800width.jpg" title="Team training with mixed reality humans"><img src="/por/images/Reports/POR/2018/1161491/1161491_10182703_1530903564120_ScreenShot2018-07-06at2.56.44PM--rgov-66x44.jpg" alt="Team training with mixed reality humans"></a> <div class="imageCaptionContainer"> <div class="imageCaption">a surgical technician trains with a team of mixed reality humans to practice drug administration best practices to reduce errors</div> <div class="imageCredit">Benjamin C Lok</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Benjamin&nbsp;C&nbsp;Lok</div> <div class="imageTitle">Team training with mixed reality humans</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1161491/1161491_10182703_1530903636025_ScreenShot2018-07-06at2.56.30PM--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1161491/1161491_10182703_1530903636025_ScreenShot2018-07-06at2.56.30PM--rgov-800width.jpg" title="nurse practices patient safety scenarios"><img src="/por/images/Reports/POR/2018/1161491/1161491_10182703_1530903636025_ScreenShot2018-07-06at2.56.30PM--rgov-66x44.jpg" alt="nurse practices patient safety scenarios"></a> <div class="imageCaptionContainer"> <div class="imageCaption">a nurse works with a team of mixed reality humans to work on patient safety best practices</div> <div class="imageCredit">Benjamin C Lok</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Benjamin&nbsp;C&nbsp;Lok</div> <div class="imageTitle">nurse practices patient safety scenarios</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Project Outcomes  Findings      A team of computer science, medical education, and simulation researchers from the University of Florida and University of Virginia have collaborated to address the problem of how to reduce errors in the operating room. Our team has focused on errors due to team communication problems, which some estimate results in over 560,000 deaths annually.  To address communication problems, we worked to empower every team member in the operating room team to learn how to administer drugs accurately and speak up on patient safety issues. Although best practices, such as closed-loop communication (repeating back what one hears) and patient safety assertive statements (saying certain words when one is concerned), implementing them in the practice is difficult because teams are not able to practice. Teams are not able to practice because of the logistics of having all team members together.  To address this issue, our team developed mixed reality humans. Mixed reality humans are a combination of virtual and physical elements. The Mixed reality humans play the role of operating room teammates to practice communication skills. We used the mixed reality humans to plug into roles of unavailable human team members, as to facilitate team training.  During the past seven years, the the team established some important fundamental advances in how to build mixed reality humans and how to train operating room personnel. We have run a series of studies that resulted in training operating room personnel at the University of Florida Health Hospitals. These simulations showed that mixed reality humans helped train the user on best communication practices including repeating back drug orders and speaking up when they felt the patient's health was at risk. Hundreds of operating room staff (nurses, surgical technicians, anesthesiology residents) have been trained with feedback being extremely positive.  The work has also been disseminated. First, other groups within the UF Health Hospital system at both Gainesville and Jacksonville have taken the mixed reality humans and built scenarios to train nurses on new procedures. Second, the intellectual property generated from this work has been licensed by Shadow Health, Inc. Shadow Health has commercialized other simulation technologies and is currently in over 1500 nursing college and university programs internationally with over a hundred thousand users a year. Thus, the work and findings of this award will have a real world impact on nursing education and patient outcomes.  This work has also resulted in publications that demonstrated that mixed reality humans can train and implement best practices. We have also studied the how people treat mixed reality humans compared to real humans, what aspects of the mixed reality human impacts virtual reality concepts such as social presence (how much people feel they interact with a virtual person like a real person). The team has published 7 journal and 5 conference publications. Further, 3 Ph.D. students have been supported and graduated from this award. The graduates include an assistant professor at Clemson University, and developers at Amazon.com and VR startup Strivr Labs.              Last Modified: 07/06/2018       Submitted by: Benjamin C Lok]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
