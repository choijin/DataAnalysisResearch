<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Collaborative Research: ShapeShifting and PubSub for Tailoring Memory Access and Communication in Heterogeneous Multiprocessors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>270000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>tao li</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Over the past decade or more, microprocessors have faced increasing challenges in achieving high-performance for current and emerging software applications while abiding by severe power and thermal limits. In response, industry has turned to approaches that use specialized graphics and computational hardware and complex memory organizations.  The end result is that computer systems have become more heterogeneous and complex, in ways that make it difficult for programmers to write efficient and high-performance software.  Software tuned to run on one implementation will often not run at all or will perform poorly or unpredictably when ported to even a different implementation in the same chip family. The objective of this research effort is to design and evaluate system and hardware support that tailors memory and data access/movements to improve performance and power efficiency, while also easing the issues of programmability and of tuning software for individual chip characteristics.&lt;br/&gt;The two key themes of this work are ShapeShifting and PubSub data abstractions.  ShapeShifting refers to optimizations and hardware support structures that allow data to be transformed in layout, in order to support faster access, more efficient use of memory, and other attributes that improve power and performance.  In some preliminary experiments, even a software-only implementation of ShapeShifting improves performance by 15%-2.8X. PubSub data abstractions offer methods for individual processors to indicate interest (or disinterest) in updates regarding other program variables.  These abstractions form the underpinning for memory optimizations that are tailored to the application?s memory usage patterns. By mitigating false sharing, encouraging coarse-grained fetches, and reducing coherence broadcasts to uninterested cores, PubSub has the potential to improve the power and performance efficiency of multi-core implementations by a factor of 2X or more.&lt;br/&gt;The research program is targeting several types of broad impact.  First, the simulators and tools developed by this project will be released as free, open-source software. Second, the results can enhance performance and energy efficiency of future parallel hardware.  Energy-efficiency is of particular concern from a national economic and strategic standpoint, given the growing electricity consumption of computer systems and the important role of the memory hierarchy in influencing computer power consumption.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/21/2011</MinAmdLetterDate>
<MaxAmdLetterDate>09/10/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116673</AwardID>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Skadron</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin Skadron</PI_FULL_NAME>
<EmailAddress>skadron@cs.virginia.edu</EmailAddress>
<PI_PHON>4349822042</PI_PHON>
<NSF_ID>000393383</NSF_ID>
<StartDate>06/21/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>065391526</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RECTOR &amp; VISITORS OF THE UNIVERSITY OF VIRGINIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>065391526</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Virginia Main Campus]]></Name>
<CityName>CHARLOTTESVILLE</CityName>
<StateCode>VA</StateCode>
<ZipCode>229044195</ZipCode>
<StreetAddress><![CDATA[P.O.  BOX 400195]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7354</Code>
<Text>COMPUTER SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~225000</FUND_OBLG>
<FUND_OBLG>2013~45000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the past ten years, the computing industry has seen a trend toward new microprocessor architectures that differ dramatically from the classic CPU. Most prominent among these has been the graphics processor (GPU), which evolved from 3D graphics processing into a general-purpose architecture for high-performance computing for applications with high parallelism.&nbsp; Another major platform has been the field-programmable gate array (FPGA), which provides a matrix of processing elements that can be interconnected in customized ways to create specialized processing engines.&nbsp; Various other accelerators have been introduced, including the AP, an accelerator for automata processing, a class of applications relying on inexact, symbolic pattern matching.&nbsp;</p> <p>All of these processing architectures have different execution models and memory organizations. The goal of this project was to develop methods that abstract away these differences, allowing the programmer to write a single program that is portable across these diverse platforms and that achieves high performance across these platforms. This project developed a set of novel methods to achieve these goals, and released a variety of open-source software tools to make these methods broadly accessible. This project also developed a range of benchmark applications to drive the research, evaluate the benefits of these methods, serve as benchmarks for other research, and also serve as case studies and examples for researchers and programmers. These applications were released in the form of two open-source benchmark suites. In all cases, the open-source license was chosen to enable broad commercial and non-commercial use.</p> <p>For the GPU, this project developed two programming languages to allow the user to define <em>what</em> they wanted to achieve without needing to express the details of how the program should execute. This provides both the information and the flexibility for the compiler and language runtime to map the program in the most efficient way.&nbsp; Trellis asks the programmer to provide hints about the relationship among tasks, so that maximum parallelism can be extracted. Dymaxion++ asks the programmer to specify a general access pattern (such as row-major vs. column-major, diagonal, etc.) to allow the compiler and runtime to obtain the most efficient memory-access pattern.&nbsp; In the process of developing, these approaches, new compiler analysis techniques were developed.</p> <p>A variety of applications with diverse memory and parallelism characteristics were developed for diverse computing platforms as a way to drive the research, and facilitate other research and development, by exposing challenging use cases. These applications were added to the existing Rodinia benchmark suite, which is now up to version 3.1, with version 4.0 forthcoming soon.&nbsp;</p> <p>In the course of developing a range of applications to drive the research, this project observed the importance of automata processing. Finite automata are a computing paradigm for inexact, symbolic pattern matching, which is prominent in a range of application domains such as network processing, data mining, and bioinformatics. This project found that various application domains that had never previously been formulated using automata-based algorithms could in fact be executed with high performance by developing new algorithms for automata-based processing. This achieves unprecedented performance on several computing platforms, and even on the CPU, it was shown that some of these new application domains achieve higher performance than the previous state-of-the-art algorithms. This project developed and released a separate benchmark suite for these automata applications. &nbsp;</p> <p>In this study of automata processing, this project extended its work to include FPGAs and the recently-announced Automata Processor (AP), as well as GPU and CPU.&nbsp; A variety of applications were evaluated across these platforms, and new methods were developed to achieve faster automata processing on the GPU and FPGA.&nbsp; Benchmarking showed the high potential of &ldquo;spatial architectures&rdquo; such as the AP and FPGA, which map the application in space across a pool of resources and achieve very high parallelism as a result.</p> <p>To support efficient and <em>convenient </em>automata processing across a range of current and future heterogeneous platforms, this project developed an end-to-end suite of open-source tools to allow convenient programming of applications involving symbolic pattern-matching tasks and efficient, portable execution across the CPU, GPU, FPGA, and AP.&nbsp; These tools include VASim, an automata optimization engine; RAPID, a highly portable programming language; MNRL, a new specification language for automata and finite-state machines; iNFAnt2, a new automata execution engine for GPUs; REAPR, a new automata execution engine for FPGAs; and more tools growing out of this research are being prepared for release.</p> <p>Overall, the intellectual contributions are in new methods for portable, high-performance execution across diverse, heterogeneous computing resources.&nbsp; The broader impacts are in the release of a set of tools and benchmarks to enable further research as well as enabling everyday programmers to more easily use the capabilities of these heterogeneous platforms.&nbsp; Further broader impacts were realized in training of students in research methods and robust, portable software development, and a variety of outreach activities.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/20/2017<br>      Modified by: Kevin&nbsp;Skadron</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the past ten years, the computing industry has seen a trend toward new microprocessor architectures that differ dramatically from the classic CPU. Most prominent among these has been the graphics processor (GPU), which evolved from 3D graphics processing into a general-purpose architecture for high-performance computing for applications with high parallelism.  Another major platform has been the field-programmable gate array (FPGA), which provides a matrix of processing elements that can be interconnected in customized ways to create specialized processing engines.  Various other accelerators have been introduced, including the AP, an accelerator for automata processing, a class of applications relying on inexact, symbolic pattern matching.   All of these processing architectures have different execution models and memory organizations. The goal of this project was to develop methods that abstract away these differences, allowing the programmer to write a single program that is portable across these diverse platforms and that achieves high performance across these platforms. This project developed a set of novel methods to achieve these goals, and released a variety of open-source software tools to make these methods broadly accessible. This project also developed a range of benchmark applications to drive the research, evaluate the benefits of these methods, serve as benchmarks for other research, and also serve as case studies and examples for researchers and programmers. These applications were released in the form of two open-source benchmark suites. In all cases, the open-source license was chosen to enable broad commercial and non-commercial use.  For the GPU, this project developed two programming languages to allow the user to define what they wanted to achieve without needing to express the details of how the program should execute. This provides both the information and the flexibility for the compiler and language runtime to map the program in the most efficient way.  Trellis asks the programmer to provide hints about the relationship among tasks, so that maximum parallelism can be extracted. Dymaxion++ asks the programmer to specify a general access pattern (such as row-major vs. column-major, diagonal, etc.) to allow the compiler and runtime to obtain the most efficient memory-access pattern.  In the process of developing, these approaches, new compiler analysis techniques were developed.  A variety of applications with diverse memory and parallelism characteristics were developed for diverse computing platforms as a way to drive the research, and facilitate other research and development, by exposing challenging use cases. These applications were added to the existing Rodinia benchmark suite, which is now up to version 3.1, with version 4.0 forthcoming soon.   In the course of developing a range of applications to drive the research, this project observed the importance of automata processing. Finite automata are a computing paradigm for inexact, symbolic pattern matching, which is prominent in a range of application domains such as network processing, data mining, and bioinformatics. This project found that various application domains that had never previously been formulated using automata-based algorithms could in fact be executed with high performance by developing new algorithms for automata-based processing. This achieves unprecedented performance on several computing platforms, and even on the CPU, it was shown that some of these new application domains achieve higher performance than the previous state-of-the-art algorithms. This project developed and released a separate benchmark suite for these automata applications.    In this study of automata processing, this project extended its work to include FPGAs and the recently-announced Automata Processor (AP), as well as GPU and CPU.  A variety of applications were evaluated across these platforms, and new methods were developed to achieve faster automata processing on the GPU and FPGA.  Benchmarking showed the high potential of "spatial architectures" such as the AP and FPGA, which map the application in space across a pool of resources and achieve very high parallelism as a result.  To support efficient and convenient automata processing across a range of current and future heterogeneous platforms, this project developed an end-to-end suite of open-source tools to allow convenient programming of applications involving symbolic pattern-matching tasks and efficient, portable execution across the CPU, GPU, FPGA, and AP.  These tools include VASim, an automata optimization engine; RAPID, a highly portable programming language; MNRL, a new specification language for automata and finite-state machines; iNFAnt2, a new automata execution engine for GPUs; REAPR, a new automata execution engine for FPGAs; and more tools growing out of this research are being prepared for release.  Overall, the intellectual contributions are in new methods for portable, high-performance execution across diverse, heterogeneous computing resources.  The broader impacts are in the release of a set of tools and benchmarks to enable further research as well as enabling everyday programmers to more easily use the capabilities of these heterogeneous platforms.  Further broader impacts were realized in training of students in research methods and robust, portable software development, and a variety of outreach activities.             Last Modified: 05/20/2017       Submitted by: Kevin Skadron]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
