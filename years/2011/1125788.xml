<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Electrophysiological and Computational studies on action monitoring</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>643675.00</AwardTotalIntnAmount>
<AwardAmount>643675</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alumit Ishai</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>How humans regulate their behaviors is a fundamental question. With funding from the National Science Foundation, Dr. Michael Frank of Brown University is investigating interactions between different brain regions involved in how people monitor, learn, and control their actions. This research project focuses on how humans accomplish restrained control over behavior when confronted with difficult decisions. Theoretical models and empirical results suggest that the prefrontal cortex and the basal ganglia interact during these motivated behaviors, and that the neurochemical dopamine plays a central role in both the prefrontal cortex and basal ganglia brain regions. Using electroencephalography (EEG), the investigators are measuring participants' brain waves associated with prefrontal cortex activity, while they perform computerized cognitive tasks that assess learning and decision making in difficult circumstances.  The brain wave activity is expected to predict participants' cognitive performance on these tasks. Critically, this brain-behavior relationship is predicted to differ as a function of genetic variants in dopamine function in both the prefrontal cortex and basal ganglia. In another experiment, researchers are directly manipulating dopamine pharmacologically in order to determine how these brain and behavior relationships are causally altered by dopamine levels. In all of their studies, the investigators use detailed mathematical models guided by contemporary theory to isolate specific brain-behavior relationships. It is theorized that both genetic variants and pharmacological manipulations affect the way that the brain monitors, learns, and controls actions.  The brain wave measures are allowing the research team to define how neurochemicals modulate the processes of large neural systems.&lt;br/&gt;&lt;br/&gt;This research has the goal to substantially advance our understanding of how humans are able to regulate their behaviors as a function of motivation and cognitive control. Scientists widely appreciate that there are large individual differences in these types of motivated behaviors, but only recently have they begun to understand some of the factors governing these differences. By combining multiple research approaches, this project is posed to reveal the ways in which genetic and neurochemical factors alter activity in brain areas that are critically involved in such behaviors. The project also has the potential to identify mechanisms that disrupt brain circuitry and lead to disorders in motivated behavior and cognitive control,  including addiction and obsessive compulsive disorder among others.</AbstractNarration>
<MinAmdLetterDate>08/31/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/31/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1125788</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Frank</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael J Frank</PI_FULL_NAME>
<EmailAddress>michael_frank@brown.edu</EmailAddress>
<PI_PHON>4018636872</PI_PHON>
<NSF_ID>000176925</NSF_ID>
<StartDate>08/31/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129002</ZipCode>
<StreetAddress><![CDATA[BOX 1929]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~643675</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="FirstlineindentCxSpFirst">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Cavanagh, Masters, Bath, and Frank (<em>Nature Communications</em><span>, 2014) studied conflict during reinforcement learning (RL) and found that it functions as a cost: It makes rewarding actions less rewarding and punishing actions more punishing. Cavanagh et al. (2014) used electroencephalography (EEG), computational modeling, genetics, and pharmacology to demonstrate that this effect of conflict on RL is related to an interaction between frontal cortex and dopamine in the striatum. Both pharmacological manipulations of striatal dopamine and individual differences in the gene DARPP-32, which affects striatal dopamine, modulated the effect of conflict on RL.</span></p> <p class="FirstlineindentCxSpMiddle"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Even though making a choice can be costly, as in Cavanagh et al. (2014),</span> people highly value the freedom to make a choice. Cockburn, Collins, and Frank (<em>Neuron</em>, 2014) proposed a striatal dopamine mechanism for this &ldquo;choice bias&rdquo; phenomenon. Using modeling predictions and behavioral data, they showed that when people receive an unexpected reward from a freely made choice, they are more likely to repeat that choice and they value the reward more highly. As in Cavanagh et al. (2014), individual differences in DARPP-32 modulated this effect.</p> <p class="FirstlineindentCxSpMiddle">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Collins and Frank (<em>Psychological Review</em>, 2014) modeled the effects of striatal dopamine on choice incentive and RL. Collins and Frank (2014) proposed an Opponent Actor Learning (OpAL) model that replaces the &ldquo;actor&rdquo; in a standard actor-critic model with two opponent actors. One of the actors learns from positive outcomes, corresponding to the direct &ldquo;Go&rdquo; pathway through the basal ganglia, while the other learns from negative outcomes, corresponding to the indirect &ldquo;NoGo&rdquo; pathway. Collins and Frank (2014) applied the OpAL model to a variety of data. It successfully modeled the effects&mdash;and the interaction between them&mdash;of striatal dopamine on RL and choice incentive.</p> <p class="FirstlineindentCxSpMiddle">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Collins and Frank (<em>European Journal of Neuroscience</em>, 2012) investigated how much of people&rsquo;s RL should instead be attributed to working memory, addressing a gap in the RL literature. Collins and Frank (2012) designed a learning task that teased apart the influences of the striatal RL system and the prefrontal working memory system. They showed that their novel model, which incorporated both RL and capacity-limited working memory, predicted people&rsquo;s performance better than models that only included RL. Collins and Frank (2012) also found that individual differences in the COMT and GPR6 genes predicted working memory capacity and RL rate, respectively.</p> <p class="FirstlineindentCxSpMiddle">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Collins and Frank (<em>Psychological Review</em>, 2013) modeled yet another aspect of learning: how people learn which actions to make given a set of rules, or &ldquo;task-set,&rdquo; and how people learn which task-set should govern their actions given a specific context. Collins and Frank (2013) developed a hierarchical extension of their previous neural network model. The extended model facilitates computation over multiple cortico-basal ganglia loops and links its emergent computations to those of higher-level, non-parametric Bayesian models. Collins and Frank (2013)&rsquo;s extended model quantitatively matched how people performed in a task-set learning task.</p> <p class="FirstlineindentCxSpMiddle">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[            Cavanagh, Masters, Bath, and Frank (Nature Communications, 2014) studied conflict during reinforcement learning (RL) and found that it functions as a cost: It makes rewarding actions less rewarding and punishing actions more punishing. Cavanagh et al. (2014) used electroencephalography (EEG), computational modeling, genetics, and pharmacology to demonstrate that this effect of conflict on RL is related to an interaction between frontal cortex and dopamine in the striatum. Both pharmacological manipulations of striatal dopamine and individual differences in the gene DARPP-32, which affects striatal dopamine, modulated the effect of conflict on RL.             Even though making a choice can be costly, as in Cavanagh et al. (2014), people highly value the freedom to make a choice. Cockburn, Collins, and Frank (Neuron, 2014) proposed a striatal dopamine mechanism for this "choice bias" phenomenon. Using modeling predictions and behavioral data, they showed that when people receive an unexpected reward from a freely made choice, they are more likely to repeat that choice and they value the reward more highly. As in Cavanagh et al. (2014), individual differences in DARPP-32 modulated this effect.             Collins and Frank (Psychological Review, 2014) modeled the effects of striatal dopamine on choice incentive and RL. Collins and Frank (2014) proposed an Opponent Actor Learning (OpAL) model that replaces the "actor" in a standard actor-critic model with two opponent actors. One of the actors learns from positive outcomes, corresponding to the direct "Go" pathway through the basal ganglia, while the other learns from negative outcomes, corresponding to the indirect "NoGo" pathway. Collins and Frank (2014) applied the OpAL model to a variety of data. It successfully modeled the effects&mdash;and the interaction between them&mdash;of striatal dopamine on RL and choice incentive.             Collins and Frank (European Journal of Neuroscience, 2012) investigated how much of peopleÆs RL should instead be attributed to working memory, addressing a gap in the RL literature. Collins and Frank (2012) designed a learning task that teased apart the influences of the striatal RL system and the prefrontal working memory system. They showed that their novel model, which incorporated both RL and capacity-limited working memory, predicted peopleÆs performance better than models that only included RL. Collins and Frank (2012) also found that individual differences in the COMT and GPR6 genes predicted working memory capacity and RL rate, respectively.             Collins and Frank (Psychological Review, 2013) modeled yet another aspect of learning: how people learn which actions to make given a set of rules, or "task-set," and how people learn which task-set should govern their actions given a specific context. Collins and Frank (2013) developed a hierarchical extension of their previous neural network model. The extended model facilitates computation over multiple cortico-basal ganglia loops and links its emergent computations to those of higher-level, non-parametric Bayesian models. Collins and Frank (2013)Æs extended model quantitatively matched how people performed in a task-set learning task.             Wiecki, Sofer, and Frank used a different type of hierarchical model in their 2013 Frontiers in Neuroinformatics paper, in which they announced the release of Hierarchical Drift Diffusion Modeling (HDDM), a novel Python toolbox. HDDM improves upon the drift diffusion model, often applied to decision making, by providing an efficient way to hierarchically estimate model parameters. Wiecki et al. (2013) applied HDDM to data collected previously by the Laboratory for Neural Computation and Cognition (Cavanagh et al., Nature Neuroscience, 2011). HDDM was more successful at modeling decision making processes than less sophisticated, non-hierarchical approaches.             Collins, Cavanagh, and Frank returned to task-set learning in...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
