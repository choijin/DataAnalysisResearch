<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TC: Small: Provably Private Microdata Publishing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>439227.00</AwardTotalIntnAmount>
<AwardAmount>439227</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Data is a key resource in this information age.  The availability of data, however, often causes privacy concerns.  Many data sharing scenarios require data be anonymized for privacy protection.  Most existing data anonymization techniques, however, satisfy only weak privacy notions that rely on particular assumptions about the adversaries, and provide inadequate protection.  In recent years, the elegant notion of differential privacy has gradually been accepted as the privacy notion of choice for answering statistical queries.  Most research on differential privacy, however, focuses on answering interactive queries, and there are several negative results on publishing microdata while satisfying differential privacy.  Regardless, many data sharing scenarios require sharing of microdata, and research is needed to bridge this gap.&lt;br/&gt;&lt;br/&gt;This project aims at bridging the gap between the elegant notion of differential privacy, and the practical difficulty of publishing microdata while preserving utility.  Building on the preliminary results of the PI on using random sampling together with "safe" k-anonymization to satisfy differential privacy, this project aims at advancing the state of the art of both scientific understanding and specific techniques for privacy-preserving microdata publishing.  Research activities include developing (1) Practical anonymization methods that can be proven to satisfy differential privacy, while capable of handling high-dimensional data; (2) Relaxations of differential privacy that are more suitable for microdata publishing; (3) Privacy theory and techniques that are easily applied to a family of data sanitization algorithms called localized algorithms, enabling the usage of input perturbation techniques for provably-private microdata publishing; (4) Privacy notions and techniques for publishing social network data and network trace data.&lt;br/&gt;&lt;br/&gt;Advances in data anonymization techniques will benefit the society by providing a better balance between the need to release data to serve public interest and the need to protect individuals' privacy. This project also involves developing a graduate seminar course on data privacy, and supports two graduate students.</AbstractNarration>
<MinAmdLetterDate>08/18/2011</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1116991</AwardID>
<Investigator>
<FirstName>Ninghui</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ninghui Li</PI_FULL_NAME>
<EmailAddress>ninghui@cs.purdue.edu</EmailAddress>
<PI_PHON>7654966756</PI_PHON>
<NSF_ID>000166436</NSF_ID>
<StartDate>08/18/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072114</ZipCode>
<StreetAddress><![CDATA[Young Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~439227</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project has&nbsp;<span>developed new data privacy notions as well as better&nbsp;</span>techniques for privacy-preserving data publishing and analysis. &nbsp;This project demonstrated the relationship between two major privacy notions: k-anonnymity and differential privacy. &nbsp;This project also resulted in the development of the membership privacy framework, which defines privacy as preventing any adversary from learning that an individual's data is included in the input dataset. &nbsp;The membership privacy framework generalizes differential privacy, makes the undelying assumptions of differential privacy explicit, and points out ways to relax the notion of differential privacy in a principled way so that more useful information can be learned from the data.&nbsp;</p> <p>This project also resulted in several state of the art techniques for performing data analysis tasks while satisfying differential privacy. &nbsp;While providing the same level of privacy guarantees, some algorithms can perform analysis tasks more accurately than others. &nbsp;This project has resulted in algorithms for publishing histograms of low-dimensional datasets, frequent itemset mining and publishing item counts for transactional datasets, k-means clustering, classification using decesion trees, logistic regression, and Support Vector Machines, answering marginal queries, and publishing graph node degree distribution. &nbsp;Algorithms introduced in the beginning of the project (published in 2013) were still found to be the best-performing ones by a study in 2016 conducted by other researchers who compared a large number of competing algorithms, even though this area has been under intensive study in recent years. &nbsp;</p> <p>This also project also supported the study of two PhD students. &nbsp;One just defended his PhD dissertation and joined IBM T.J.Watson Research Center. &nbsp;Another plans to defend in December 2016, and will join Google Inc.</p><br> <p>            Last Modified: 10/21/2016<br>      Modified by: Ninghui&nbsp;Li</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project has developed new data privacy notions as well as better techniques for privacy-preserving data publishing and analysis.  This project demonstrated the relationship between two major privacy notions: k-anonnymity and differential privacy.  This project also resulted in the development of the membership privacy framework, which defines privacy as preventing any adversary from learning that an individual's data is included in the input dataset.  The membership privacy framework generalizes differential privacy, makes the undelying assumptions of differential privacy explicit, and points out ways to relax the notion of differential privacy in a principled way so that more useful information can be learned from the data.   This project also resulted in several state of the art techniques for performing data analysis tasks while satisfying differential privacy.  While providing the same level of privacy guarantees, some algorithms can perform analysis tasks more accurately than others.  This project has resulted in algorithms for publishing histograms of low-dimensional datasets, frequent itemset mining and publishing item counts for transactional datasets, k-means clustering, classification using decesion trees, logistic regression, and Support Vector Machines, answering marginal queries, and publishing graph node degree distribution.  Algorithms introduced in the beginning of the project (published in 2013) were still found to be the best-performing ones by a study in 2016 conducted by other researchers who compared a large number of competing algorithms, even though this area has been under intensive study in recent years.    This also project also supported the study of two PhD students.  One just defended his PhD dissertation and joined IBM T.J.Watson Research Center.  Another plans to defend in December 2016, and will join Google Inc.       Last Modified: 10/21/2016       Submitted by: Ninghui Li]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
