<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Combining Knowledge with Data for Generalizable and Robust Visual Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2011</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>202421.00</AwardTotalIntnAmount>
<AwardAmount>226421</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer vision has made tremendous progress in the past decades, partially enabled   by the advanced machine learning techniques.  But compared with human perception, computer vision remains primitive.  One contributing factor for this is the data-driven nature of the current learning algorithms and their inability to incorporate any related knowledge.  The data-driven methods tend to be database-specific and cannot generalize well to unseen data. This project addresses this issue through the introduction of a knowledge-augmented statistical learning framework.   Within this framework, knowledge and data can be systematically exploited, captured, and are principally integrated to jointly train a vision algorithm.  Developing such a framework, however, is challenging since the domain knowledge often exists in different and diverse formats, typically inaccessible to the data-driven statistical machine learning methods.  To overcome this challenge, the research team systematically converts domain knowledge into either the constraints on the model or into pseudo-data, whereby they can be incorporated into the statistical learning methods.  The project includes systematic identification of knowledge from different sources and concrete mechanisms to capture the knowledge and to convert them into formats easily accessible to the automatic machine learning methods.  The project also involves demonstrating the effectiveness of the proposed framework for certain computer vision problems.&lt;br/&gt;&lt;br/&gt;The project provides the training for graduate and undergraduate students, and the research results are disseminated through publications and organization of the related workshops.</AbstractNarration>
<MinAmdLetterDate>07/20/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1145152</AwardID>
<Investigator>
<FirstName>Qiang</FirstName>
<LastName>Ji</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qiang Ji</PI_FULL_NAME>
<EmailAddress>qji@ecse.rpi.edu</EmailAddress>
<PI_PHON>5182766440</PI_PHON>
<NSF_ID>000350734</NSF_ID>
<StartDate>07/20/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002430742</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RENSSELAER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002430742</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rensselaer Polytechnic Institute]]></Name>
<CityName>Troy</CityName>
<StateCode>NY</StateCode>
<ZipCode>121803522</ZipCode>
<StreetAddress><![CDATA[110 8th St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~202421</FUND_OBLG>
<FUND_OBLG>2012~8000</FUND_OBLG>
<FUND_OBLG>2013~8000</FUND_OBLG>
<FUND_OBLG>2014~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="font-family: Times New Roman; font-size: small;"> </span></p> <p style="line-height: 12.75pt;"><span>Machine learning plays a very important role nowadays in computer vision. The existing visual learning algorithms are largely data-driven, ignoring the related computer vision models and domain specific knowledge.&nbsp; The goal of this research is to introduce a hybrid visual learning approach, whereby data and prior knowledge can be simultaneously exploited to achieve robust and generalizable vision algorithms</span></p> <p><span style="font-family: Times New Roman; font-size: small;"> </span></p> <p style="line-height: 12.75pt;"><span>To this goal, throughout this research, we first identify different types of prior knowledge from different sources and then&nbsp;develop advanced&nbsp;methods to encode&nbsp;them into different stages of&nbsp;visual learning.&nbsp; Specifically, we identified three types of prior knowledge: domain-specific permanent theoretical knowledge, contextual knowledge, and computer vision theories.&nbsp;&nbsp; We developed methods to encode these prior knowledge into visual learning. These methods include probabilistic graphical models to capture permanent theoretical knowledge,&nbsp; learning with privileged information method for capturing contextual information, and regularization&nbsp; and data augmentation methods for encoding computer vision theories.&nbsp; Finally, we demonstrate the performance of our knowledge-augmented visual learning methods for&nbsp;</span><span>&nbsp;a wide range of computer vision problems including facial expression/action recognition, human event and action recognition, object category recognition, and 3D reconstruction.&nbsp;&nbsp; Experiments on benchmark datasets demonstrate the improved performance of our methods over state of the art methods. This work contributes not only to computer vision but also to machine learning and pattern recognition fields.&nbsp; </span><span>It represents a paradigm-shift from the traditional data-driven approaches to a hybrid approach that can reduce dependence on training data, reduce efforts for data annotation, and produce more robust and generalizable learning methods. </span></p> <p><span style="font-family: Times New Roman; font-size: small;"> </span></p> <p style="line-height: 12.75pt;"><span>The project so far has provided training for both graduate and undergraduate students.<span style="mso-spacerun: yes;">&nbsp; </span>For graduate student, the project supported in part the training of&nbsp;one Ph.D student in theoretical developments, software implementation, technical paper writing, and in public presentation of his work.&nbsp;&nbsp;&nbsp; For undergraduate students, this project has supported three undergraduate students.<span style="mso-spacerun: yes;">&nbsp;</span>&nbsp; It trained them in software development, algorithm development, data collection and annotation, documentations and reports, and public presentations.<span style="mso-spacerun: yes;">&nbsp;&nbsp;</span>Two of the three students have decided to pursue graduate studies upon their graduation.<span style="mso-spacerun: yes;">&nbsp; </span>In terms of dissemination of the research results , this project so far has yielded&nbsp;five conference&nbsp;papers and&nbsp;&nbsp;one journal&nbsp;paper under review.&nbsp; It has also led to a Ph.D dissertation. </span></p> <p><span style="font-family: Times New Roman; font-size: small;"> </span></p><br> <p>            Last Modified: 12/26/2015<br>      Modified by: Qiang&nbsp;Ji</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Machine learning plays a very important role nowadays in computer vision. The existing visual learning algorithms are largely data-driven, ignoring the related computer vision models and domain specific knowledge.  The goal of this research is to introduce a hybrid visual learning approach, whereby data and prior knowledge can be simultaneously exploited to achieve robust and generalizable vision algorithms    To this goal, throughout this research, we first identify different types of prior knowledge from different sources and then develop advanced methods to encode them into different stages of visual learning.  Specifically, we identified three types of prior knowledge: domain-specific permanent theoretical knowledge, contextual knowledge, and computer vision theories.   We developed methods to encode these prior knowledge into visual learning. These methods include probabilistic graphical models to capture permanent theoretical knowledge,  learning with privileged information method for capturing contextual information, and regularization  and data augmentation methods for encoding computer vision theories.  Finally, we demonstrate the performance of our knowledge-augmented visual learning methods for  a wide range of computer vision problems including facial expression/action recognition, human event and action recognition, object category recognition, and 3D reconstruction.   Experiments on benchmark datasets demonstrate the improved performance of our methods over state of the art methods. This work contributes not only to computer vision but also to machine learning and pattern recognition fields.  It represents a paradigm-shift from the traditional data-driven approaches to a hybrid approach that can reduce dependence on training data, reduce efforts for data annotation, and produce more robust and generalizable learning methods.     The project so far has provided training for both graduate and undergraduate students.  For graduate student, the project supported in part the training of one Ph.D student in theoretical developments, software implementation, technical paper writing, and in public presentation of his work.    For undergraduate students, this project has supported three undergraduate students.   It trained them in software development, algorithm development, data collection and annotation, documentations and reports, and public presentations.  Two of the three students have decided to pursue graduate studies upon their graduation.  In terms of dissemination of the research results , this project so far has yielded five conference papers and  one journal paper under review.  It has also led to a Ph.D dissertation.           Last Modified: 12/26/2015       Submitted by: Qiang Ji]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
