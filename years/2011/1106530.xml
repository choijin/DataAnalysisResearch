<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Geometric and information-theoretic aspects of high-dimensional phenomena</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2011</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>330000.00</AwardTotalIntnAmount>
<AwardAmount>330000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tomek Bartoszynski</SignBlockName>
<PO_EMAI>tbartosz@nsf.gov</PO_EMAI>
<PO_PHON>7032924885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This proposal focuses on the study of geometric, analytic and &lt;br/&gt;information-theoretic aspects of high dimensional phenomena&lt;br/&gt;on the border of probability, convex geometry and analysis. &lt;br/&gt;One part of the project concerns the problem of rates of&lt;br/&gt;convergence in the entropic central limit theorem, and is devoted &lt;br/&gt;to obtaining new asymptotic expansions for the relative entropy &lt;br/&gt;with respect to the growing dimension. In other part, &lt;br/&gt;it is proposed to perform a systematic study of the &lt;br/&gt;dimensional behavior of the entropy and information for &lt;br/&gt;different classes of probability distributions, satisfying &lt;br/&gt;convexity conditions. In particular, new concentration properties &lt;br/&gt;of the information content will be considered for dependent &lt;br/&gt;high-dimensional data. It is planned to introduce and explore &lt;br/&gt;special positions of probability measures, responsible for &lt;br/&gt;correct behaviour of sums of independent summands&lt;br/&gt;(when the entropy power inequality can be reversed).&lt;br/&gt;Another part addresses the stability problem, raised by Kac &lt;br/&gt;and McKean, in the entropic variant of Cramer's&lt;br/&gt;characterization of the normal law.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The main theme of the proposal is the development of the &lt;br/&gt;information-theoretic approach to high dimensional phenomena,&lt;br/&gt;with focus on obtaining new asymptotic bounds on the entropy and &lt;br/&gt;information. The study of entropy is dictated by various &lt;br/&gt;applications within and beyond pure mathematics. Entropy plays &lt;br/&gt;a key role in statistical physics (in order to capture&lt;br/&gt;the amount of disorder in a system), in statistics&lt;br/&gt;(to measure the performance of statistical estimators),&lt;br/&gt;in engineering and mathematical theory of communication.&lt;br/&gt;The proposed research also aims to provide new connections between &lt;br/&gt;probability, geometric functional analysis and information theory,&lt;br/&gt;and to demonstrate an increasing role of entropy&lt;br/&gt;bounds in purely mathematical fields.&lt;br/&gt;&lt;br/&gt;An integral component of the project is the involvement and &lt;br/&gt;training of the graduate and undergraduate students.</AbstractNarration>
<MinAmdLetterDate>05/23/2011</MinAmdLetterDate>
<MaxAmdLetterDate>04/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1106530</AwardID>
<Investigator>
<FirstName>Sergey</FirstName>
<LastName>Bobkov</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sergey Bobkov</PI_FULL_NAME>
<EmailAddress>bobkov@math.umn.edu</EmailAddress>
<PI_PHON>6126251840</PI_PHON>
<NSF_ID>000252025</NSF_ID>
<StartDate>05/23/2011</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554552070</ZipCode>
<StreetAddress><![CDATA[200 OAK ST SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1263</Code>
<Text>PROBABILITY</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~114566</FUND_OBLG>
<FUND_OBLG>2012~106348</FUND_OBLG>
<FUND_OBLG>2013~109086</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p style="text-align: left; padding-left: 30px;">The main goal of the project was the development of the information-theoretic approach to high dimensional phenomena, with focus on obtaining new asymptotic bounds on the entropy and information. The study of entropy is dictated by various applications within and beyond pure mathematics.<br /><br />The research outcome of the project may be divided into several topics. In the recent years jointly with collaborators the PI was involved in the development of the central limit theorem, which describes a normal approximation for distributions of a large number of small summands. Under moment conditions, we explored exact rates of such approximation in terms of information-theoretic distances including the relative entropy and the relative Fisher information. Using the Fourier approach, we have obtained new asymptotic expansions for distributions of sums by means of Edgeworth corrections. Part of the results addressed the stability problem, raised by Kac and McKean in 1960's, in the entropic variant of Cramer's characterization of the normal law. Another line of research was devoted to the systematic study of the dimensional behavior of entropy and information for different classes of probability distributions satisfying convexity conditions. In particular, we have discovered new concentration properties of the information content for dependent high-dimensional data. As a related issue, the classical entropy power inequality has been extended to the Renyi entropy of an arbitrary index. The obtained result also applies in the problem of bounding the density of sums of independent random vectors.</p> <p style="text-align: left; padding-left: 30px;">The third part of the project dealt with the study of geometric and Sobolev-type inequalities on spaces of high dimension. The problem of the estimation of the deficit in the logarithmic Sobolev inequality in Gauss space has been considered in terms of the transport distances. In addition, new K-L-S-type isoperimetric inequalities are proposed for the class of log-concave probability distributions. The obtained results include and extend many of known lower bounds on the Cheeger isoperimetric constants. In addition, the localization technique of Kannan, Lovasz and Simonovits was extended to infinite dimensional locally convex spaces. Thus, dilation-type inequalities for convex (hyperbolic) measures are established in a more general framework; they may be applied to distributions of various stochastic processes related to the Brownian motion. On general metric spaces, new relations have been studied between the Renyi divergence power (which extend the usual relative entropies) and the optimal transport in terms of the Kantorovich distance.<br /><br />An educational outcome of this project was the involvement and training of graduate and REU undergraduate students, as well as mentoring postdocs. It resulted in two PhD thesis defended by J.-H. Kim in April 2013 (she currently works as an industrial scientist at Citigroup, CIB), and by J. Melbourne in May 2015 (postdoc at the University of Delaware).</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/12/2015<br>      Modified by: Sergey&nbsp;Bobkov</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The main goal of the project was the development of the information-theoretic approach to high dimensional phenomena, with focus on obtaining new asymptotic bounds on the entropy and information. The study of entropy is dictated by various applications within and beyond pure mathematics.  The research outcome of the project may be divided into several topics. In the recent years jointly with collaborators the PI was involved in the development of the central limit theorem, which describes a normal approximation for distributions of a large number of small summands. Under moment conditions, we explored exact rates of such approximation in terms of information-theoretic distances including the relative entropy and the relative Fisher information. Using the Fourier approach, we have obtained new asymptotic expansions for distributions of sums by means of Edgeworth corrections. Part of the results addressed the stability problem, raised by Kac and McKean in 1960's, in the entropic variant of Cramer's characterization of the normal law. Another line of research was devoted to the systematic study of the dimensional behavior of entropy and information for different classes of probability distributions satisfying convexity conditions. In particular, we have discovered new concentration properties of the information content for dependent high-dimensional data. As a related issue, the classical entropy power inequality has been extended to the Renyi entropy of an arbitrary index. The obtained result also applies in the problem of bounding the density of sums of independent random vectors. The third part of the project dealt with the study of geometric and Sobolev-type inequalities on spaces of high dimension. The problem of the estimation of the deficit in the logarithmic Sobolev inequality in Gauss space has been considered in terms of the transport distances. In addition, new K-L-S-type isoperimetric inequalities are proposed for the class of log-concave probability distributions. The obtained results include and extend many of known lower bounds on the Cheeger isoperimetric constants. In addition, the localization technique of Kannan, Lovasz and Simonovits was extended to infinite dimensional locally convex spaces. Thus, dilation-type inequalities for convex (hyperbolic) measures are established in a more general framework; they may be applied to distributions of various stochastic processes related to the Brownian motion. On general metric spaces, new relations have been studied between the Renyi divergence power (which extend the usual relative entropies) and the optimal transport in terms of the Kantorovich distance.  An educational outcome of this project was the involvement and training of graduate and REU undergraduate students, as well as mentoring postdocs. It resulted in two PhD thesis defended by J.-H. Kim in April 2013 (she currently works as an industrial scientist at Citigroup, CIB), and by J. Melbourne in May 2015 (postdoc at the University of Delaware).          Last Modified: 08/12/2015       Submitted by: Sergey Bobkov]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
