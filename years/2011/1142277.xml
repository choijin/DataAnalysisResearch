<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Haptic Robotics for Kitting Powertrain Components</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2012</AwardEffectiveDate>
<AwardExpirationDate>06/30/2012</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>148952</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project proposes that haptic robots offer effective and&lt;br/&gt;attractive solutions to the common tasks of Bin-Picking and Kitting, which currently require human workers. A&lt;br/&gt;popular application area is programming an industrial robot to work with specific powertrain parts. The&lt;br/&gt;Problem: Bin-picking robots can only manipulate strong parts with simple geometries in structured or semistructured&lt;br/&gt;configurations; machine vision deals poorly with overlapping objects and unstable and unpredictable&lt;br/&gt;loads or grips. The Opportunity: Haptic systems can compliment machine vision systems using tactile sensory&lt;br/&gt;data to cope with overlapping objects and unstable grip conditions. The Solution: A robotic hand/arm&lt;br/&gt;equipped with unique biomimetic tactile sensors to make a platform for developing grip algorithms for parts&lt;br/&gt;picking and kitting. Innovations include develop algorithms for slip-detection and force-cone grip adjustment;&lt;br/&gt;developing adaptive algorithms using tactile feedback to improve grip pre-shaping; validating algorithms with&lt;br/&gt;physical powertrain parts; and challenging algorithms with real-world uncertainties that are difficult to detect&lt;br/&gt;using machine vision.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project will result in robots that have more humanlike haptic&lt;br/&gt;capabilities. Currently robots lack tactile sensing and rely on specialized component feeders and gripping tools&lt;br/&gt;to handle individual objects with predetermined gripping features. These items add cost, occupy space, and&lt;br/&gt;consume time, especially when many different objects must be handled. This puts robots at a significant&lt;br/&gt;disadvantage to human workers who use their hands dexterously to handle an unlimited variety of objects.&lt;br/&gt;Nevertheless, robots are best suited to handle tasks that are highly repetitive or dangerous to humans. When&lt;br/&gt;robots handle hazardous materials or manufacturing tasks, they relieve humans of these burdens while often&lt;br/&gt;yielding increased productivity and cost-savings. At the end of Phase I we will have developed a proof of&lt;br/&gt;concept so that our Phase II research can integrate the system into an industrial environment. By addressing the&lt;br/&gt;picking of objects with errors in object pose, position and part-to-part interaction, haptic robots will transform&lt;br/&gt;this important part of the manufacturing process. Such technology will have widespread impact on many&lt;br/&gt;aspects of manufacturing and automation.</AbstractNarration>
<MinAmdLetterDate>11/17/2011</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1142277</AwardID>
<Investigator>
<FirstName>Nicholas</FirstName>
<LastName>Wettels</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nicholas B Wettels</PI_FULL_NAME>
<EmailAddress>nick.wettels@syntouchllc.com</EmailAddress>
<PI_PHON>2134770710</PI_PHON>
<NSF_ID>000517608</NSF_ID>
<StartDate>11/17/2011</StartDate>
<EndDate>06/27/2012</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tomonori</FirstName>
<LastName>Yamamoto</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tomonori Yamamoto</PI_FULL_NAME>
<EmailAddress>Tomonori.Yamamoto@SynTouchLLC.com</EmailAddress>
<PI_PHON>2139734102</PI_PHON>
<NSF_ID>000606415</NSF_ID>
<StartDate>06/27/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SynTouch LLC</Name>
<CityName>Montrose</CityName>
<ZipCode>910201516</ZipCode>
<PhoneNumber>3108075786</PhoneNumber>
<StreetAddress>3720 Clifton Place</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>28</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA28</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>827484929</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SYNTOUCH L.L.C.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117367572</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SynTouch LLC]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900076601</ZipCode>
<StreetAddress><![CDATA[2222 South Figueroa St PH2]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~148952</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We were successful in procuring and assembling the robotic testbed and completing most of the specific research aims of this project (development of slip-detection, force-cone grip adjustment and grip reshaping algorithms, validation with automotive parts, and challenging the algorithms with real-world uncertainties).&nbsp; Additional validation of the grip-adjustment algorithms will be conducted in the future to better quantify the performance of our system. <br /><br />No major complications were encountered over the course of this work. While the performance of the system to use tactile feedback to compensate for object location and orientation uncertainty was quite good, further analysis of the bin-picking application and alternative available technologies suggested that tactile sensing would be difficult to integrate with machine vision and might not offer sufficient advantages. <br /><br />With this in consideration, we have identified a more appropriate application of this technology in assistive robotics.&nbsp; Objects in the home are more likely to be fragile and their orientation with respect to the gripper is more uncertain because the robot is steered manually by a teleoperator. In such situations, we anticipate the relative benefits of our system to be more substantial.</p> <p>The results of this Phase I study have demonstrated the ability to stabilize grip when the exact location of the object is uncertain. While these algorithms were found to be highly effective, the question of their utility in a given robotic application is still unclear. A robot equipped with a vision system that can accurately locate and identify the exact object position and orientation of rigid objects may not benefit significantly from tactile feedback (although slip detection still offers some benefit). Instead of maintaining focus on the original task of automated bin picking of objects, we propose a new task to better take advantage of these algorithms for Phase II. Assistive robots (such as the Jaco from Kinova) are frequently used to help with everyday tasks in severely disabled wheelchair users suffering from paraplegia, stroke, muscular dystrophy, etc.&nbsp; While subjects are fully capable mentally, they have limited strength or mobility in their arms and legs. In these cases a robotic grasper enables them to do such tasks as feeding themselves, picking objects off the floor, opening doors, etc. for which they would otherwise require a human caregiver.&nbsp; Such a robotic personal assistant would be functioning like a telerobot, but industrial telerobots are difficult to control under visual guidance in the absence of tactile feedback.&nbsp; We believe that our BioTac sensors can be integrated with simple joystick controllers to provide an intuitive yet powerful system.</p><br> <p>            Last Modified: 08/02/2012<br>      Modified by: Tomonori&nbsp;Yamamoto</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2012/1142277/1142277_10142707_1343925370183_-BarrettandComauInstallationwithBioTacs--rgov-214x142.jpg" original="/por/images/Reports/POR/2012/1142277/1142277_10142707_1343925370183_-BarrettandComauInstallationwithBioTacs--rgov-800width.jpg" title="- Barrett and Comau Installation with BioTacs"><img src="/por/images/Reports/POR/2012/1142277/1142277_10142707_1343925370183_-BarrettandComauInstallationwithBioTacs--rgov-66x44.jpg" alt="- Barrett and Comau Installation with BioTacs">...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We were successful in procuring and assembling the robotic testbed and completing most of the specific research aims of this project (development of slip-detection, force-cone grip adjustment and grip reshaping algorithms, validation with automotive parts, and challenging the algorithms with real-world uncertainties).  Additional validation of the grip-adjustment algorithms will be conducted in the future to better quantify the performance of our system.   No major complications were encountered over the course of this work. While the performance of the system to use tactile feedback to compensate for object location and orientation uncertainty was quite good, further analysis of the bin-picking application and alternative available technologies suggested that tactile sensing would be difficult to integrate with machine vision and might not offer sufficient advantages.   With this in consideration, we have identified a more appropriate application of this technology in assistive robotics.  Objects in the home are more likely to be fragile and their orientation with respect to the gripper is more uncertain because the robot is steered manually by a teleoperator. In such situations, we anticipate the relative benefits of our system to be more substantial.  The results of this Phase I study have demonstrated the ability to stabilize grip when the exact location of the object is uncertain. While these algorithms were found to be highly effective, the question of their utility in a given robotic application is still unclear. A robot equipped with a vision system that can accurately locate and identify the exact object position and orientation of rigid objects may not benefit significantly from tactile feedback (although slip detection still offers some benefit). Instead of maintaining focus on the original task of automated bin picking of objects, we propose a new task to better take advantage of these algorithms for Phase II. Assistive robots (such as the Jaco from Kinova) are frequently used to help with everyday tasks in severely disabled wheelchair users suffering from paraplegia, stroke, muscular dystrophy, etc.  While subjects are fully capable mentally, they have limited strength or mobility in their arms and legs. In these cases a robotic grasper enables them to do such tasks as feeding themselves, picking objects off the floor, opening doors, etc. for which they would otherwise require a human caregiver.  Such a robotic personal assistant would be functioning like a telerobot, but industrial telerobots are difficult to control under visual guidance in the absence of tactile feedback.  We believe that our BioTac sensors can be integrated with simple joystick controllers to provide an intuitive yet powerful system.       Last Modified: 08/02/2012       Submitted by: Tomonori Yamamoto]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
