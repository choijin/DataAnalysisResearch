<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Adjoint-based control of human phonation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ron Joslin</SignBlockName>
<PO_EMAI>rjoslin@nsf.gov</PO_EMAI>
<PO_PHON>7032927030</PO_PHON>
</ProgramOfficer>
<AbstractNarration>1150439&lt;br/&gt;Bodony&lt;br/&gt;&lt;br/&gt;The human voice comes from a complex interaction between the flexible vocal folds and the transient glottal jet induced by air forced by the diaphragm through the glottis.  Traumatized vocal folds disrupt speech and little is known how to efficiently recover the lost voice.  First-principles, three-dimensional simulations of the dynamic vocal folds coupled to the unsteady, turbulent motion of the air past them, and resulting acoustic field from the nose and mouth, will guide voice recovery methods by quantitatively determining the acoustic source and by utilizing a new multi-physics optimization methodology to find effective methods of recovering lost voice via vocal fold augmentation.  Realistic geometries taken from newly acquired static and dynamic MRI data, along with corresponding acoustic measurements, will provide validation.  Results from predictive and controlled vocal fold simulations will provide new and complete information on human voice production, guidance for restoring the voice after its loss, and low-order, approximate dynamical models of phonation and its sensitivity to vocal fold modification.&lt;br/&gt;&lt;br/&gt;The numerical datasets, their reduced order descriptions, and the validation data will provide a reliable database on which to build cross-cutting biomedical investigations of brain-speech coupling using functional MRI as well as showing a path towards patient-specific vocal fold restorative surgeries.  The new adjoint-based optimization methodology is applicable to a broad class of flows beyond phonation, including optimization of highly flexible bio-inspired engineering systems, biological sonation, and boundary layer control.  &lt;br/&gt;&lt;br/&gt;The work will also be the central theme in a multi-level education program.  The fluid-structure optimization methodology will be incorporated into graduate level instruction while simplified fluid-structure interaction algorithms will be brought into an undergraduate course on numerical algorithms through mini-projects using problem-based learning.  Summer undergraduate research experience through NSF and NASA programs will be used to attract and retain engineering students from under-represented groups.  Further, human phonation and biological sonation will be central themes in STEM K-12 outreach programs: one based at the University of Illinois and one part of a larger, national STEM effort.   The outreach programs are aimed at high school students and culminate with the students building a mechanical larynx and seeing for themselves the process of phonation.</AbstractNarration>
<MinAmdLetterDate>02/25/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1150439</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Bodony</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel J Bodony</PI_FULL_NAME>
<EmailAddress>bodony@illinois.edu</EmailAddress>
<PI_PHON>2172443844</PI_PHON>
<NSF_ID>000525441</NSF_ID>
<StartDate>02/25/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Urbana</CityName>
<StateCode>IL</StateCode>
<ZipCode>618012958</ZipCode>
<StreetAddress><![CDATA[104 S. Wright St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1443</Code>
<Text>FD-Fluid Dynamics</Text>
</ProgramElement>
<ProgramReference>
<Code>059E</Code>
<Text>Complex fluids</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~75152</FUND_OBLG>
<FUND_OBLG>2013~77639</FUND_OBLG>
<FUND_OBLG>2014~80122</FUND_OBLG>
<FUND_OBLG>2015~82327</FUND_OBLG>
<FUND_OBLG>2016~84760</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Speaking is a critical means by which people communicate, convey meaning, and express emotions. &nbsp;Voiced human speech is characterized by the air-induced vibration of two vocal folds, each comprised of layers of active and passive tissues of different stiffnesses, whose motion is induced by the expulsion of air from the lungs through the trachea and, ulitimately, out of the mouth and nose. &nbsp;For healthy individuals, the vocal folds oscillate in unison and are controllable by neurological inputs to nearby muscles. &nbsp;When the vocal folds become diseased or acquire neurological damage, the ability to speak is lost or reduced, and the impact is traumatic. &nbsp;Recovering lost or low quality speech requires surgical and nonsurgical procedures whose success rate is relatively low.&nbsp;</p> <p><br />This project was to develop a computational model of human phonation with sufficient realism to predict healthy speech as well as when vocal fold degredation or paralysis was present. &nbsp; This project focuses on the numerical prediction of a simple voiced sound, the /a:/ ("ah") phonem, where only the vocal folds vibrate and the mouth, lips, and tongue are stationary. &nbsp;A multilayered structure of the vocal folds was modeled within a finite element structural dynamics framework coupled to a computational fluid dynamic solver to predict the motion of the air within the trachea, the generation of sound immediately downstream of the vocal folds, and the propagation of sound outside the body.</p> <p>&nbsp;<br />Predictions of the speech by a healthy male uttering the "ah" sound were made from which simulation databases were created containing the motion of the vocal folds, the motion of air in and around them, as well as the sound produced in the glottis and escaping the mouth and into the surrounding environment. &nbsp;Parameter and model studies were performed to establish the reliability of the predicitions and estimate predicted sound variations. &nbsp;The work definitively showed that voiced sound is sensitive to small changes in the vocal fold properties and behavior, indicating the need for future research to better measure healthy vocal fold properties.</p> <p><br />Vocal fold pathologies were studied to demonstrate the computational human phonation model's ability to predict degraded and speech loss. &nbsp;Unilateral vocal fold paralysis (UVFP), wherein neurological damage causes on vocal fold to be inactive, was studied in detail. &nbsp;The clinically-used measure of phontation threshold pressure, or PTP, to indicate speaking difficulty was quantitatively predicted for increasing levels of pathology. &nbsp;Importantly, the computational model was able to simulate the outcome of surgical implantation of a stiff material into the inactive vocal fold in UVFP, a procedure called medialization laryngoplasty, to reduce the PTP and subsequently improve speech.</p> <p><br />The primary outcome of the project was the computational model suitable for fundamental exploration of healthy and pathological human speech. &nbsp;The data generated by the model will be critically useful for developing simpler descriptions of human speech for use in holistic models of human perception as well as a foundation on which to build more complete models of aural communication.</p><br> <p>            Last Modified: 11/28/2017<br>      Modified by: Daniel&nbsp;J&nbsp;Bodony</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1150439/1150439_10155328_1511895285243_project-outcomes-image--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1150439/1150439_10155328_1511895285243_project-outcomes-image--rgov-800width.jpg" title="Direct numerical simulation of the human voice"><img src="/por/images/Reports/POR/2017/1150439/1150439_10155328_1511895285243_project-outcomes-image--rgov-66x44.jpg" alt="Direct numerical simulation of the human voice"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The sound produced by an adult male saying "ah" is predicted using computational fluid dynamics and computational solid dynamics with a physiological model of the vocal folds and upper respiratory system.</div> <div class="imageCredit">Daniel J. Bodony</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Daniel&nbsp;J&nbsp;Bodony</div> <div class="imageTitle">Direct numerical simulation of the human voice</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Speaking is a critical means by which people communicate, convey meaning, and express emotions.  Voiced human speech is characterized by the air-induced vibration of two vocal folds, each comprised of layers of active and passive tissues of different stiffnesses, whose motion is induced by the expulsion of air from the lungs through the trachea and, ulitimately, out of the mouth and nose.  For healthy individuals, the vocal folds oscillate in unison and are controllable by neurological inputs to nearby muscles.  When the vocal folds become diseased or acquire neurological damage, the ability to speak is lost or reduced, and the impact is traumatic.  Recovering lost or low quality speech requires surgical and nonsurgical procedures whose success rate is relatively low.    This project was to develop a computational model of human phonation with sufficient realism to predict healthy speech as well as when vocal fold degredation or paralysis was present.   This project focuses on the numerical prediction of a simple voiced sound, the /a:/ ("ah") phonem, where only the vocal folds vibrate and the mouth, lips, and tongue are stationary.  A multilayered structure of the vocal folds was modeled within a finite element structural dynamics framework coupled to a computational fluid dynamic solver to predict the motion of the air within the trachea, the generation of sound immediately downstream of the vocal folds, and the propagation of sound outside the body.    Predictions of the speech by a healthy male uttering the "ah" sound were made from which simulation databases were created containing the motion of the vocal folds, the motion of air in and around them, as well as the sound produced in the glottis and escaping the mouth and into the surrounding environment.  Parameter and model studies were performed to establish the reliability of the predicitions and estimate predicted sound variations.  The work definitively showed that voiced sound is sensitive to small changes in the vocal fold properties and behavior, indicating the need for future research to better measure healthy vocal fold properties.   Vocal fold pathologies were studied to demonstrate the computational human phonation model's ability to predict degraded and speech loss.  Unilateral vocal fold paralysis (UVFP), wherein neurological damage causes on vocal fold to be inactive, was studied in detail.  The clinically-used measure of phontation threshold pressure, or PTP, to indicate speaking difficulty was quantitatively predicted for increasing levels of pathology.  Importantly, the computational model was able to simulate the outcome of surgical implantation of a stiff material into the inactive vocal fold in UVFP, a procedure called medialization laryngoplasty, to reduce the PTP and subsequently improve speech.   The primary outcome of the project was the computational model suitable for fundamental exploration of healthy and pathological human speech.  The data generated by the model will be critically useful for developing simpler descriptions of human speech for use in holistic models of human perception as well as a foundation on which to build more complete models of aural communication.       Last Modified: 11/28/2017       Submitted by: Daniel J Bodony]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
