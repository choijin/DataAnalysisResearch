<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ABI Innovation:  Interactive Learning Tools For Individual Identification in Large Biological Image Databases</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2012</AwardEffectiveDate>
<AwardExpirationDate>05/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>432477.00</AwardTotalIntnAmount>
<AwardAmount>432477</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08080000</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DBI</Abbreviation>
<LongName>Div Of Biological Infrastructure</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jennifer Weller</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The goal of this research is to develop scalable methods for individual identification in large biological databases with application to multiple species in ongoing conservation efforts around the world. This work couples crowd-sourcing with computational learning. In an identification system that learns from user inputs, multiple inputs can accelerate the quality and rate of identification, which in turn dramatically reduces subsequent work-cycles any human performs. The hypothesis is that Computational learning will improve the quality of human-machine coupled system's solutions to help solve large and diverse identification problems. Several interactive learning algorithms are proposed in all stages of indexing and search in Biological Image Databases. The algorithms are based on non-parametric Bayesian inference and deliver incremental online learning methods. To test the interactive learning hypothesis, the MIT Sloop system will be extended to include the proposed interactive learning tools. Sloop is a robust toolkit for vision tools that has been tested on multiple species and supports an operational deployment. As part of this research a distributed Sloop system indexing multiple species will be developed.&lt;br/&gt; &lt;br/&gt;It is difficult to accurately estimate the effectiveness of conservation efforts for many rare and endangered species without an ability to quantify the spatial scales and other statistics of animal migration and movement. Tagging, an established method, is of limited effectiveness because it is often invasive and cannot be conducted in large numbers. This research looks at whether a large number of animals in multiple species can be identified individually using photographs stored in a database. The "Animal biometrics" proposed here will examine how citizen scientists can crowd-source relevance judgments and other inputs, how judgments can improve the computer's identification performance, and how improved performance reduces the citizen or expert scientist's workload. The mechanics of the symbiotic human-computer interaction mediated by machine learning, and the methods by which patterns are indexed and searched also have impacts in other fields. For example, some of the tools developed here have been applied in Geosciences and Weather Prediction.</AbstractNarration>
<MinAmdLetterDate>06/11/2012</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1146747</AwardID>
<Investigator>
<FirstName>Srinivas</FirstName>
<LastName>Ravela</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Srinivas S Ravela</PI_FULL_NAME>
<EmailAddress>ravela@mit.edu</EmailAddress>
<PI_PHON>6172530997</PI_PHON>
<NSF_ID>000104787</NSF_ID>
<StartDate>06/11/2012</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName/>
<StateCode>MA</StateCode>
<ZipCode>021394703</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1165</Code>
<Text>ADVANCES IN BIO INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~432477</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The MIT Sloop system enables conservation biologists to maintain up-to-date inventories of individuals in a species using a pattern recognition. When biologists and ecologists seek to maintain accurate catalogs, they must be able to track all repeated occurances of an individual. Our system enables them to do that using photographs and no additional special or general markings. Our system does not rely on particular features of the individual for the biologist to identify. Rather, it uses feedback from the biologist to improve by learning the kinds of image features and their juxtapositions, along with learning &nbsp;combinations of methods that would maximize the chance of finding other occurances of the individual. Our system is not fully automated, it in fact relies on a feedback between the humans and machines, we find this approach to be particularly powerful at recalling all occurances of an individual quickly. We found that the interaction, obtained in the form of feedback "yes I did correctly", "no I did not", is sufficient to quickly locate other individuals when a biologist initially catalogs the data and then subsequently maintains it.</p> <p>&nbsp;</p> <p>Many algorithms went into creating the Sloop system. It is operationally deployed and the over 97% recognition performance attained is the best in its class. It has been applied to multiple species, reported in the community and with reporting in the popular press as well. It is freely available for download and is developed in a unique architecture that enables full ownership of the biological data to remain with the user while the algorithms can be easily updated. Sloop systems can run in networks, and one can leverage the computational benefits of other running sloops without compromising security.&nbsp;</p> <p>Some key aspects of our research involved the development of new workflows, testing ideas pertaining to how much human input is necessary for improved performance, and what the most sustainable computational architecture may be.</p> <p>Six students a staff member, in addition to the PI contributed to this project. Some of the benefits accrued include further placement of students and the award of the MITs infinite kilometer award to the PI.&nbsp;</p><br> <p>            Last Modified: 01/03/2017<br>      Modified by: Srinivas&nbsp;S&nbsp;Ravela</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The MIT Sloop system enables conservation biologists to maintain up-to-date inventories of individuals in a species using a pattern recognition. When biologists and ecologists seek to maintain accurate catalogs, they must be able to track all repeated occurances of an individual. Our system enables them to do that using photographs and no additional special or general markings. Our system does not rely on particular features of the individual for the biologist to identify. Rather, it uses feedback from the biologist to improve by learning the kinds of image features and their juxtapositions, along with learning  combinations of methods that would maximize the chance of finding other occurances of the individual. Our system is not fully automated, it in fact relies on a feedback between the humans and machines, we find this approach to be particularly powerful at recalling all occurances of an individual quickly. We found that the interaction, obtained in the form of feedback "yes I did correctly", "no I did not", is sufficient to quickly locate other individuals when a biologist initially catalogs the data and then subsequently maintains it.     Many algorithms went into creating the Sloop system. It is operationally deployed and the over 97% recognition performance attained is the best in its class. It has been applied to multiple species, reported in the community and with reporting in the popular press as well. It is freely available for download and is developed in a unique architecture that enables full ownership of the biological data to remain with the user while the algorithms can be easily updated. Sloop systems can run in networks, and one can leverage the computational benefits of other running sloops without compromising security.   Some key aspects of our research involved the development of new workflows, testing ideas pertaining to how much human input is necessary for improved performance, and what the most sustainable computational architecture may be.  Six students a staff member, in addition to the PI contributed to this project. Some of the benefits accrued include further placement of students and the award of the MITs infinite kilometer award to the PI.        Last Modified: 01/03/2017       Submitted by: Srinivas S Ravela]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
