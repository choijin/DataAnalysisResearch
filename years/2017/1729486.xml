<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:   CI-P: ShapeNet: An Information-Rich 3D Model Repository for Graphics, Vision and Robotics Research</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>33333.00</AwardTotalIntnAmount>
<AwardAmount>33333</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
<PO_EMAI>jdonlon@nsf.gov</PO_EMAI>
<PO_PHON>7032928074</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to plan the development of a richly annotated repository of 3D models called ShapeNet that currently exists only in a preliminary form. ShapeNet will include 3-4 million 3D models of everyday objects in 4-5 thousand categories, in a variety of representations. Models in the ShapeNet repository will be annotated with multiple annotation types: geometric (parts, symmetries), semantic (keywords for the shape and its parts), physical (weight, size), and functional (affordances, scene context). The availability of ShapeNet data, capturing the 3D geometry of a significant fraction of object categories in the world, together with associated detailed meta-data and semantic information, will catalyze major developments in graphics, vision and robotics by providing adequate data against which new proposed techniques and methodologies for shape or scene analysis and synthesis can be vetted -- and with which machine learning algorithms can be trained. ShapeNet can be considered an encyclopedia that facilitates the creation of intelligent systems and agents capable of operating autonomously in the world --- because they can have deep knowledge of that world.&lt;br/&gt;&lt;br/&gt;While most of the ShapeNet models will be initially found on the Web, the annotations will be obtained through an active learning combination of modest human input (including crowd-sourcing), extensive algorithmic transport, and human verification. During the planning period the effort will focus on mathematical representations of the semantic knowledge associated with 3D models, as well as on a design framework for key algorithms allowing knowledge transport from one model to another. Further challenges to be addressed include the quantification of data quality issues and the specification of all the multimodal (3D, image, language) UIs and APIs needed for users to be able to exploit and search this wealth of data, or to contribute additional models and annotations to it.</AbstractNarration>
<MinAmdLetterDate>06/07/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1729486</AwardID>
<Investigator>
<FirstName>Qixing</FirstName>
<LastName>Huang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qixing Huang</PI_FULL_NAME>
<EmailAddress>huangqx@cs.utexas.edu</EmailAddress>
<PI_PHON>7738340409</PI_PHON>
<NSF_ID>000682606</NSF_ID>
<StartDate>06/07/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121532</ZipCode>
<StreetAddress><![CDATA[101 E. 27th Street, Suite 5.300]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~33333</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project supports the development and maintenance of ShapeNet: An Information-Rich 3D Model Repository. ShapeNet has been widely used across computer vision, computer graphics, and robotics. This project supports the 3D machine learning research across these disciplines in the deep learning era as a learning benchmark dataset for experimental evaluation. The tasks that involve ShapeNet include shape classification, shape segmentation, pose estimation, and differential rendering, which are crucial 3D recognition tasks in graphics and robotics. ShapeNet has also been widely used for simulating training data for 3D vision tasks such as single-view 3D reconstruction and novel-view synthesis. ShapeNet is a leading benchmark dataset for developing and evaluating 3D representation learning, such as point clouds, deep implicit models, and equivariant shape representations from the machine learning perspective. In particular, it promoted the development of several prominent deep learning models used in the industry. <br /><br />Based on the analysis of the usage of ShapeNet, we developed another benchmark dataset of 3D mechanical part models (MCB) to support the future growth of 3D machine learning. This new benchmark can address the saturation issue of ShapeNet for the shape classification task. The shapes in MCB possess rich primitive and symmetry structures, which will support advances in the analysis of primitive structures, an important problem in shape analysis (for applications in robotics and mechanical engineering), but less developed in the deep learning era.</p><br> <p>            Last Modified: 12/06/2020<br>      Modified by: Qixing&nbsp;Huang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project supports the development and maintenance of ShapeNet: An Information-Rich 3D Model Repository. ShapeNet has been widely used across computer vision, computer graphics, and robotics. This project supports the 3D machine learning research across these disciplines in the deep learning era as a learning benchmark dataset for experimental evaluation. The tasks that involve ShapeNet include shape classification, shape segmentation, pose estimation, and differential rendering, which are crucial 3D recognition tasks in graphics and robotics. ShapeNet has also been widely used for simulating training data for 3D vision tasks such as single-view 3D reconstruction and novel-view synthesis. ShapeNet is a leading benchmark dataset for developing and evaluating 3D representation learning, such as point clouds, deep implicit models, and equivariant shape representations from the machine learning perspective. In particular, it promoted the development of several prominent deep learning models used in the industry.   Based on the analysis of the usage of ShapeNet, we developed another benchmark dataset of 3D mechanical part models (MCB) to support the future growth of 3D machine learning. This new benchmark can address the saturation issue of ShapeNet for the shape classification task. The shapes in MCB possess rich primitive and symmetry structures, which will support advances in the analysis of primitive structures, an important problem in shape analysis (for applications in robotics and mechanical engineering), but less developed in the deep learning era.       Last Modified: 12/06/2020       Submitted by: Qixing Huang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
