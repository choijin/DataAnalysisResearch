<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Towards End-to-End Knowledge Discovery in Complex Brain Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>226217.00</AwardTotalIntnAmount>
<AwardAmount>226217</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Modeling the brain as a networked system has become a popular paradigm in neuroscience. Knowledge discovery on brain network data has the potential to revolutionize the way we understand the brain and provide a basis for developing new treatments for neurological disorders. However, today knowledge discovery systems on brain networks are still extremely hard to build. Researchers must be taught in tedious details how to design the pipeline of data processing and adjust the parameter settings in different processing stages. To address this problem, the project will aim to build an end-to-end system for knowledge discovery in brain networks that learns to integrate different processing stages and self-adjust with minimal human intervention. Educational activities will include curriculum development and training of students in the areas of data science and neuroscience. Result dissemination is planned via publication in relevant peer-reviewed conferences and journals.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;To make fundamental contributions to realizing this vision, it is necessary to go beyond the pipeline-based approaches, where the multiple stages of the knowledge discovery are studied in isolation. It has been shown that end-to-end systems can significantly alleviate the problem of laborious efforts in building pipelines and making adjustments. In the planned system, the four stages of the knowledge discovery on brain networks (i.e., node discovery, edge discovery, feature mining and statistical learning) will be integrated and studied together instead of being studied in isolation. This project will investigate innovative ideas on unifying different stages of knowledge discovery in brain networks: (1) collective brain network discovery, where the node discovery and edge discovery stages are deeply integrated into a unified framework; (2) label-contrasting edge discovery, which unifies edge discovery with model inference stages; (3) collective edge discovery unifies the edge discovery and statistical learning stages; (4) node-compressing sub-graph mining, node discovery stage and feature mining stage; (5) an end-to-end system across all four stages, which allows the learners in different stages to work together and form a unified learner for brain network analysis. The project will takes a next logical step in brain network research. It will build intellectual and formal connections between data mining and neuroscience. The project results have the potential for automating brain network analysis. In terms of broader impacts, the project will deliver new analytic tools that are broadly relevant to the study of the brain in cognitive neuroscience. These tools also have broad clinical applicability for early diagnosis of neurological injury, for evaluation of treatment response, etc. Educational activities will include curriculum development and training of students in the areas of data science and neuroscience.</AbstractNarration>
<MinAmdLetterDate>07/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1718070</AwardID>
<Investigator>
<FirstName>Constance</FirstName>
<LastName>Moore</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Constance M Moore</PI_FULL_NAME>
<EmailAddress>constance.moore@umassmed.edu</EmailAddress>
<PI_PHON>7744554271</PI_PHON>
<NSF_ID>000693314</NSF_ID>
<StartDate>07/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Medical School</Name>
<CityName>Worcester</CityName>
<ZipCode>016550002</ZipCode>
<PhoneNumber>5088562119</PhoneNumber>
<StreetAddress>55 Lake Avenue North</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>603847393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Medical School]]></Name>
<CityName>Worcester</CityName>
<StateCode>MA</StateCode>
<ZipCode>016550002</ZipCode>
<StreetAddress><![CDATA[55 Lake Ave. North]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~226217</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="gmail_default"> <p><strong>Overview:</strong></p> <p>The objective of this project is to develop end-to-end approaches for analysing the brain networks in the functional MRI data that are a) high-dimensional, b) small in sample sizes, c) temporal in each voxel.&nbsp; We broke the project into 5 tasks: 1) Collective Brain Network Discovery by discovering both nodes and edges of brain networks; 2) Label-Contrasting Edge Discovery by discovering edges and perform classification; 3) Deep Convolutional Networks for Brain Network Discovery; 4) Node-Compressing Subgraph Mining; 5) End-To-End Brain Network Mining.</p> <p><strong>Key findings</strong>&nbsp;from our work&nbsp; include:</p> <p>1.&nbsp;Neuroimaging data typically require several preprocessing steps before further analysis and mining can be done. Affine image registration is one of the important tasks during preprocessing. Recently, several image registration methods which are based on Convolutional Neural Networks have been proposed. However, due to the high computational and memory requirements of CNNs, these methods cannot be used in real-time for large neuroimaging data like fMRI.&nbsp; We propose a Dual-Attention Recurrent Network (DRN) which uses a hard attention mechanism to allow the model to focus on small, but task-relevant, parts of the input Significant Results: Key outcomes or Other achievements: image &ndash; thus reducing computational and memory costs. Furthermore, DRN naturally supports inhomogeneity between the raw input image (e.g., fMRI) and the image we want to align it to (e.g., anatomical MRI) so it can be applied to harder registration tasks such as fMRI coregistration and normalization. Extensive experiments on two different datasets demonstrate that DRN significantly reduces the computational and memory costs compared with other neural network-based methods without sacrificing the quality of image registration.</p> <p>2.&nbsp;Attention-based neuroimage classification has gained increasing popularity in recent years. State-of-the-art methods for attention-based classification typically require a large training set and operate under the assumption that the label of an image depends solely on a single object (i.e., region of interest) in the image. However, in medical imaging, it is very expensive to collect a large training set. Moreover, the label of each image is usually determined jointly by multiple regions of interest (ROIs). Fortunately, for such applications, it is often possible to collect the locations of the ROIs in each training image. We studied the problem of guided multi-attention classification, the goal of which is to achieve high accuracy under the dual constraints of (1) small sample size, and (2) multiple ROIs for each image. We propose a model, called Guided Attention Recurrent Network, for multi-attention classification. Different from existing attention- based methods, GARN utilizes guidance information regarding multiple ROIs thus allowing it to work well even when sample size is small. Empirical studies on three different visual tasks show that our guided attention approach can effectively boost model performance for multi-attention image classification.</p> <p>3.&nbsp; One of the primary tasks in neuroimaging is to simplify spatiotemporal scans of the brain by partitioning the voxels into a set of functional brain regions. An emerging line of research utilizes multiple fMRI scans, from a group of subjects, to calculate a single group consensus functional partition. This consensus- based approach is promising as it allows the model to improve the signal-to-noise ratio in the data. However, existing approaches are primarily non-parametric which poses problems when new samples are introduced. Furthermore, most existing approaches calculate a single partition for multiple subjects which fails to account for the functional and anatomical variability between different subjects. We studied the problem of group-cohesive functional brain region discovery where the goal is to use information from a group of subjects to learn "group-cohesive" but individualized brain partitions for multiple fMRI scans. This problem is challenging since neuroimaging datasets are usually quite small and noisy. We introduce a novel deep parametric model based upon graph convolution, called the Brain Region Extraction Network. By treating the fMRI data as a graph, we are able to integrate information from neighboring voxels during brain region discovery which helps reduce noise for each subject. Our model is trained with a Siamese architecture to encourage partitions that are group-cohesive. Experiments on both synthetic and real-world data show the effectiveness of our proposed approach.</p> <p><strong>Training and Development:</strong></p> <p>Two Ph.D. students have been mainly involved in this project on a full-time basis. They have been studying a broad range of topics, including deep learning, graph mining, time-series analysis and neuroimaging data analysis.&nbsp; They have also greatly improved their understanding of PyTorch, Tensorflow, as well as their Python programming skills. Both of them have defended their PhD theses.</p> <p>Two additional Ph.D. students have been involved part-time in this project. They learnt about the deep learning technology we are utilizing, in particular, Tensorflow, PyTorch, etc. One of them has been focussed on attention-based deep learning models that can effectively analyze imaging data, while the other has been focused on sparse machine learning methods for extracting structures from high-dimensional data.</p> </div> <p><span class="im"> </span></p> <p>&nbsp;</p><br> <p>            Last Modified: 03/22/2021<br>      Modified by: Constance&nbsp;M&nbsp;Moore</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Overview:  The objective of this project is to develop end-to-end approaches for analysing the brain networks in the functional MRI data that are a) high-dimensional, b) small in sample sizes, c) temporal in each voxel.  We broke the project into 5 tasks: 1) Collective Brain Network Discovery by discovering both nodes and edges of brain networks; 2) Label-Contrasting Edge Discovery by discovering edges and perform classification; 3) Deep Convolutional Networks for Brain Network Discovery; 4) Node-Compressing Subgraph Mining; 5) End-To-End Brain Network Mining.  Key findings from our work  include:  1. Neuroimaging data typically require several preprocessing steps before further analysis and mining can be done. Affine image registration is one of the important tasks during preprocessing. Recently, several image registration methods which are based on Convolutional Neural Networks have been proposed. However, due to the high computational and memory requirements of CNNs, these methods cannot be used in real-time for large neuroimaging data like fMRI.  We propose a Dual-Attention Recurrent Network (DRN) which uses a hard attention mechanism to allow the model to focus on small, but task-relevant, parts of the input Significant Results: Key outcomes or Other achievements: image &ndash; thus reducing computational and memory costs. Furthermore, DRN naturally supports inhomogeneity between the raw input image (e.g., fMRI) and the image we want to align it to (e.g., anatomical MRI) so it can be applied to harder registration tasks such as fMRI coregistration and normalization. Extensive experiments on two different datasets demonstrate that DRN significantly reduces the computational and memory costs compared with other neural network-based methods without sacrificing the quality of image registration.  2. Attention-based neuroimage classification has gained increasing popularity in recent years. State-of-the-art methods for attention-based classification typically require a large training set and operate under the assumption that the label of an image depends solely on a single object (i.e., region of interest) in the image. However, in medical imaging, it is very expensive to collect a large training set. Moreover, the label of each image is usually determined jointly by multiple regions of interest (ROIs). Fortunately, for such applications, it is often possible to collect the locations of the ROIs in each training image. We studied the problem of guided multi-attention classification, the goal of which is to achieve high accuracy under the dual constraints of (1) small sample size, and (2) multiple ROIs for each image. We propose a model, called Guided Attention Recurrent Network, for multi-attention classification. Different from existing attention- based methods, GARN utilizes guidance information regarding multiple ROIs thus allowing it to work well even when sample size is small. Empirical studies on three different visual tasks show that our guided attention approach can effectively boost model performance for multi-attention image classification.  3.  One of the primary tasks in neuroimaging is to simplify spatiotemporal scans of the brain by partitioning the voxels into a set of functional brain regions. An emerging line of research utilizes multiple fMRI scans, from a group of subjects, to calculate a single group consensus functional partition. This consensus- based approach is promising as it allows the model to improve the signal-to-noise ratio in the data. However, existing approaches are primarily non-parametric which poses problems when new samples are introduced. Furthermore, most existing approaches calculate a single partition for multiple subjects which fails to account for the functional and anatomical variability between different subjects. We studied the problem of group-cohesive functional brain region discovery where the goal is to use information from a group of subjects to learn "group-cohesive" but individualized brain partitions for multiple fMRI scans. This problem is challenging since neuroimaging datasets are usually quite small and noisy. We introduce a novel deep parametric model based upon graph convolution, called the Brain Region Extraction Network. By treating the fMRI data as a graph, we are able to integrate information from neighboring voxels during brain region discovery which helps reduce noise for each subject. Our model is trained with a Siamese architecture to encourage partitions that are group-cohesive. Experiments on both synthetic and real-world data show the effectiveness of our proposed approach.  Training and Development:  Two Ph.D. students have been mainly involved in this project on a full-time basis. They have been studying a broad range of topics, including deep learning, graph mining, time-series analysis and neuroimaging data analysis.  They have also greatly improved their understanding of PyTorch, Tensorflow, as well as their Python programming skills. Both of them have defended their PhD theses.  Two additional Ph.D. students have been involved part-time in this project. They learnt about the deep learning technology we are utilizing, in particular, Tensorflow, PyTorch, etc. One of them has been focussed on attention-based deep learning models that can effectively analyze imaging data, while the other has been focused on sparse machine learning methods for extracting structures from high-dimensional data.              Last Modified: 03/22/2021       Submitted by: Constance M Moore]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
