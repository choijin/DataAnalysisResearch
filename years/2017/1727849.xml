<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  Improving the Validity and Reliability of  Creativity Ratings in Engineering Design</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>214147.00</AwardTotalIntnAmount>
<AwardAmount>214147</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Georgia-Ann Klutke</SignBlockName>
<PO_EMAI>gaklutke@nsf.gov</PO_EMAI>
<PO_PHON>7032922443</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Without creativity, there is no potential for innovation. Consequently, creativity is seen as an essential component of engineering design. Numerous creativity metrics have been developed to assess the creativity of designs people produce. Such metrics are important for assessing business and engineering practices, a key part of improving US innovation and economic competitiveness. However, existing metrics are often scattered across different, specialized domains and it is difficult to validate their ability to accurately measure the creativity of the wide variety of engineered solutions that are produced. In addition, past research provides limited guidance on how to use and validate creativity metrics for a given design problem. This has led to universally applying metrics without systematic assessment of where and when a given metric is appropriate for a given task. This award supports fundamental research into how to evaluate the effectiveness of different creativity metrics for different types of products or services. This project does so by unifying statistical models that can experimentally validate how well different creativity metrics perform across design domains. Thus, the work will impact society by providing a verifiable method for identifying what does and does not improve creativity. Because creativity and innovation are the drivers of economic success, the work has the opportunity to drive design innovation and, as a bi-product, help stimulate the economy. In addition, the unified statistical framework developed as part of the research will advance the field of engineering design and applied mathematics by providing evidence on the utility of this approach for measuring accuracy and precision. The research involves several disciplines including engineering, psychology and applied mathematics. The multidisciplinary approach will help broaden participation of underrepresented groups in research.&lt;br/&gt;&lt;br/&gt;The technical objectives of this project are to: (1) evaluate the effectiveness of creativity metrics through the development of a unified statistical framework that combines two techniques--the minimax conditional entropy principle and the Lovasz-Bregman Divergence--to compare the accuracy and precision of different metrics for a given problem; and (2) experimentally validate a methodology for validating the transfer of creativity metrics across different design domains to identify metrics that are robust across different applications within design and systems engineering via variance and confidence measures of the Lovasz-Bregman Divergence. The results from this project will advance the field of engineering by developing a unified method of measuring and comparing mathematical, computational, and human-judgment models of creativity. This new knowledge will provide a rigorous foundation upon which to build and verify methods of design creativity across a wide variety of design disciplines (e.g., arts and architecture, psychology, engineering, business).</AbstractNarration>
<MinAmdLetterDate>07/17/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/17/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1727849</AwardID>
<Investigator>
<FirstName>Samuel</FirstName>
<LastName>Hunter</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Samuel T Hunter</PI_FULL_NAME>
<EmailAddress>samhunter@psu.edu</EmailAddress>
<PI_PHON>8148651372</PI_PHON>
<NSF_ID>000079460</NSF_ID>
<StartDate>07/17/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Scarlett</FirstName>
<LastName>Miller</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Scarlett Miller</PI_FULL_NAME>
<EmailAddress>shm13@psu.edu</EmailAddress>
<PI_PHON>8148651372</PI_PHON>
<NSF_ID>000620009</NSF_ID>
<StartDate>07/17/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Pennsylvania State University]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021400</ZipCode>
<StreetAddress><![CDATA[213P Hammond Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1464</Code>
<Text>ESD-Eng &amp; Systems Design</Text>
</ProgramElement>
<ProgramReference>
<Code>067E</Code>
<Text>DESIGN TOOLS</Text>
</ProgramReference>
<ProgramReference>
<Code>068E</Code>
<Text>DESIGN THEORY</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~214147</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Creativity has long been recognized as a fundamental component of successful engineering solutions due to the relationship between creativity and long-term economic and societal success. However, research has long been hindered by the availability of validated, objective assessments of design creativity. These metrics are vital to the engineering discipline because they help researchers determine which design methods help individuals or teams generate creative ideas most effectively or prolifically and they provide a means for designers to properly assess the creativity of their own ideas in hopes of developing more innovative solutions. However, there has been a lack of consistency across the engineering literature for which creativity metric to use and when.</p> <p>&nbsp;</p> <p>The goal of this two-year investigation was to evaluate the effectiveness of creativity metrics used in the engineering sciences through the development of a unified statistical framework. We also sought to develop a methodology for validating the transfer of creativity metrics. Towards this end, advanced mathematical investigations (latent representations, triplet embeddings, Sharma-Mittal entropy) were conducted to provide evidence on the validity and transferability of creativity metrics across engineering design domains (e.g. systems, transportation, electro-mechanical design).</p> <p>&nbsp;</p> <p>This research identified stark differences in the creativity ratings employed in engineering for measuring design creativity &ndash; further justifying the need for validated methodologies. &nbsp;The research also identified discrepancies in the reliability and consistency of global ratings of creativity between novice and expert raters, bringing to light the need to identify what we define as the construct of creativity in engineering design. We also explored and validated the use of Sharma-Mittal entropy for creativity ratings, named the Herfindahl&ndash;Hirschman Index for Design (HHID), showing that HHID better aligned with human ratings (more accurate), had a higher sensitivity, allowed for easier and efficient optimization, and generalizes to multiple problems compared to other metrics currently used in the engineering sciences. Finally, this research contributed a procedure for comparing metrics used to measure variety via constructing ground truth datasets from pairwise comparisons.</p> <p>&nbsp;</p> <p>The results from this proposal have advanced the field of engineering by developing a standardized and repeatable methodology for validating creativity metrics in the engineering sciences and scientifically reporting validation procedures. Because&nbsp;creativity metrics are use across a variety of fields (e.g. arts and architecture, psychology, engineering, business), the&nbsp;new knowledge developed from this project provides a rigorous foundation upon which to build and verify creativity methods across a wide variety of design disciplines.&nbsp;These results also enhance scientific and technological understanding of design creativity through the development of an online, open-source website that contains a benchmark dataset with creativity ratings for a wide variety of design problems (2000+ concepts from 6 design problems) - https://sites.psu.edu/creativitymetrics. This database includes codes that enable others to replicate such tests across new problems.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/05/2020<br>      Modified by: Scarlett&nbsp;Miller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Creativity has long been recognized as a fundamental component of successful engineering solutions due to the relationship between creativity and long-term economic and societal success. However, research has long been hindered by the availability of validated, objective assessments of design creativity. These metrics are vital to the engineering discipline because they help researchers determine which design methods help individuals or teams generate creative ideas most effectively or prolifically and they provide a means for designers to properly assess the creativity of their own ideas in hopes of developing more innovative solutions. However, there has been a lack of consistency across the engineering literature for which creativity metric to use and when.     The goal of this two-year investigation was to evaluate the effectiveness of creativity metrics used in the engineering sciences through the development of a unified statistical framework. We also sought to develop a methodology for validating the transfer of creativity metrics. Towards this end, advanced mathematical investigations (latent representations, triplet embeddings, Sharma-Mittal entropy) were conducted to provide evidence on the validity and transferability of creativity metrics across engineering design domains (e.g. systems, transportation, electro-mechanical design).     This research identified stark differences in the creativity ratings employed in engineering for measuring design creativity &ndash; further justifying the need for validated methodologies.  The research also identified discrepancies in the reliability and consistency of global ratings of creativity between novice and expert raters, bringing to light the need to identify what we define as the construct of creativity in engineering design. We also explored and validated the use of Sharma-Mittal entropy for creativity ratings, named the Herfindahl&ndash;Hirschman Index for Design (HHID), showing that HHID better aligned with human ratings (more accurate), had a higher sensitivity, allowed for easier and efficient optimization, and generalizes to multiple problems compared to other metrics currently used in the engineering sciences. Finally, this research contributed a procedure for comparing metrics used to measure variety via constructing ground truth datasets from pairwise comparisons.     The results from this proposal have advanced the field of engineering by developing a standardized and repeatable methodology for validating creativity metrics in the engineering sciences and scientifically reporting validation procedures. Because creativity metrics are use across a variety of fields (e.g. arts and architecture, psychology, engineering, business), the new knowledge developed from this project provides a rigorous foundation upon which to build and verify creativity methods across a wide variety of design disciplines. These results also enhance scientific and technological understanding of design creativity through the development of an online, open-source website that contains a benchmark dataset with creativity ratings for a wide variety of design problems (2000+ concepts from 6 design problems) - https://sites.psu.edu/creativitymetrics. This database includes codes that enable others to replicate such tests across new problems.                Last Modified: 11/05/2020       Submitted by: Scarlett Miller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
