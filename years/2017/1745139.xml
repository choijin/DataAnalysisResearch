<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER:   Reliable Control for Soft Robots through Sensor Placement</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>147746.00</AwardTotalIntnAmount>
<AwardAmount>147746</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Irina Dolinskaya</SignBlockName>
<PO_EMAI>idolinsk@nsf.gov</PO_EMAI>
<PO_PHON>7032927078</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This EArly-concept Grant for Exploratory Research (EAGER) project will create new sensor-based control algorithms to enable soft robots to use a novel soft optical sensor in order to react in real time to changes in the robot and the environment. Soft robots -- that is, robots made of soft materials such as rubber -- have the potential to revolutionize the way robots are designed, manufactured and deployed. Rapid prototyping techniques can produce new robots in a matter of hours, not months, robot design can be customized to fit both the robot's environment and task, and these robots are inherently safe, enabling close interaction with people. However, there are currently few examples of reliable, long duration use of soft robots in complex environments. Reasons for this lack of robust behavior include the difficulty of modeling the robot's interaction with the environment, for example the way the legs bend when walking on sand vs. concrete, the higher failure rate of soft actuators versus rigid actuators, and relative lack of good soft sensors versus traditional rigid sensors. This project addresses all three of these challenges, because the soft sensors are physically robust and, together with the new control algorithms, greatly reduce the need for accurate models. &lt;br/&gt;&lt;br/&gt;The objective of this EAGER project is to collect preliminary data and assess the feasibility of co-designing control and sensor placement for foam-based robots embedded with stretchable optical waveguides which can be used to sense deformations in the soft robot?s body. The outcomes of this project will advance the vision of soft robots that can be predictably and reliably controlled in a variety of environments. The novel soft optical sensors can be embedded throughout the actuator in a plurality of configurations; therefore, the placement can be designed with the control objective in mind. Due to the difficulty in exact modeling of soft actuators, especially those that can be created in different shapes, in order to create reliable and repeatable control for soft robots, sensors must be embedded in the body of the soft robot. The information the sensors provide, together with simplified models of robot motion, should be used to control the robot. This project will produce (i) a characterization of the information that can be obtained from a stretchable optical waveguide embedded in a foam actuator, (ii) physical limits on the quality, spatial resolution, and type of information that can be collected from multiple embedded sensors due to manufacturing constraints and the cross-influence of the sensors on the foam actuator and each other, and (iii) an algorithm that given a fixed multi-legged robot returns the required sensor placements and the feedback controller that will create predictable motions over a specific terrain. The real breakthrough that will enable reliable and robust control of soft robots will require a radical new approach to combining sensing, actuation and control, where the control objective, together with physical limitations, determines sensor placement and feedback control.</AbstractNarration>
<MinAmdLetterDate>07/07/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1745139</AwardID>
<Investigator>
<FirstName>Hadas</FirstName>
<LastName>Kress Gazit</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hadas Kress Gazit</PI_FULL_NAME>
<EmailAddress>hadaskg@cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000521463</NSF_ID>
<StartDate>07/07/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Shepherd</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert Shepherd</PI_FULL_NAME>
<EmailAddress>rfs247@cornell.edu</EmailAddress>
<PI_PHON>6072555014</PI_PHON>
<NSF_ID>000644350</NSF_ID>
<StartDate>07/07/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148537501</ZipCode>
<StreetAddress><![CDATA[124 Hoy Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7569</Code>
<Text>Dynamics, Control and System D</Text>
</ProgramElement>
<ProgramReference>
<Code>030E</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>034E</Code>
<Text>Dynamical systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8024</Code>
<Text>Complex Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~147746</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Soft robots -- that is, robots made of soft materials such as rubber -- have the potential to revolutionize the way robots are designed, manufactured and deployed. Rapid prototyping techniques can produce new robots in a matter of hours, not months, robot design can be customized to fit both the robot's environment and task, and these robots are inherently safe, enabling close interaction with people. However, there are currently few examples of reliable, long duration use of soft robots in complex environments. Reasons for this lack of robust behavior include the difficulty of modeling the robot's interaction with the environment, the higher failure rate of soft actuators versus rigid actuators, and relative lack of good soft sensors versus traditional rigid sensors.</p> <p>&nbsp;</p> <p>In this project we have advanced the state of the art in reliable control of soft robots by (i) developing new techniques for creating and embedding soft sensors in soft actuators, (ii) analyzing and abstracting the information these sensors provide so that it can be used by a high-level controller, (iii) creating robot control that identifies actuator failure and is robust to it, and (iv) demonstrating a walking soft robot that detects when its actuators (legs) fail and autonomously changes its behavior (gait and where it is going next) to accomplish a patrolling mission.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/04/2018<br>      Modified by: Hadas&nbsp;Kress Gazit</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1745139/1745139_10499947_1543844681366_ActuatorDiagram2--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1745139/1745139_10499947_1543844681366_ActuatorDiagram2--rgov-800width.jpg" title="Sensor-embedded soft actuator"><img src="/por/images/Reports/POR/2018/1745139/1745139_10499947_1543844681366_ActuatorDiagram2--rgov-66x44.jpg" alt="Sensor-embedded soft actuator"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Actuators with embedded soft sensors for high-level control of walking soft robots</div> <div class="imageCredit">Scott Hamill</div> <div class="imageSubmitted">Hadas&nbsp;Kress Gazit</div> <div class="imageTitle">Sensor-embedded soft actuator</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1745139/1745139_10499947_1543940499767_actuatorMotion--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1745139/1745139_10499947_1543940499767_actuatorMotion--rgov-800width.jpg" title="Walking soft robot"><img src="/por/images/Reports/POR/2018/1745139/1745139_10499947_1543940499767_actuatorMotion--rgov-66x44.jpg" alt="Walking soft robot"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Walking soft robot used to demonstrate high-level reliable control of soft actuators</div> <div class="imageCredit">Scott Hamill</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Hadas&nbsp;Kress Gazit</div> <div class="imageTitle">Walking soft robot</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Soft robots -- that is, robots made of soft materials such as rubber -- have the potential to revolutionize the way robots are designed, manufactured and deployed. Rapid prototyping techniques can produce new robots in a matter of hours, not months, robot design can be customized to fit both the robot's environment and task, and these robots are inherently safe, enabling close interaction with people. However, there are currently few examples of reliable, long duration use of soft robots in complex environments. Reasons for this lack of robust behavior include the difficulty of modeling the robot's interaction with the environment, the higher failure rate of soft actuators versus rigid actuators, and relative lack of good soft sensors versus traditional rigid sensors.     In this project we have advanced the state of the art in reliable control of soft robots by (i) developing new techniques for creating and embedding soft sensors in soft actuators, (ii) analyzing and abstracting the information these sensors provide so that it can be used by a high-level controller, (iii) creating robot control that identifies actuator failure and is robust to it, and (iv) demonstrating a walking soft robot that detects when its actuators (legs) fail and autonomously changes its behavior (gait and where it is going next) to accomplish a patrolling mission.             Last Modified: 12/04/2018       Submitted by: Hadas Kress Gazit]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
