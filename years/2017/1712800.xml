<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Discovering What Matters: Informative and Reproducible Variable Selection with Applications to Genomics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>420000.00</AwardTotalIntnAmount>
<AwardAmount>420000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will develop statistical methods to discover which variables, in a large collection, are meaningfully related to an outcome of interest. An example of the problem is the identification of which genetic variants, among the millions we measure, influence disease risk. The methods developed will allow analysis of all variables at the same time, accounting for their interdependence, and leading to the identification of "actionable" ones. The approaches put forward come with the guarantee that, on average, a large fraction of the discovered features truly influence the outcome.  The ability to correctly identify important variables will increase knowledge in many domains, and allow experts to devise interventions.  For example, understanding which of the variables recorded on a patient are more relevant with respect to his/her response to therapy, can help develop personalized medical interventions with a higher success rate.&lt;br/&gt;&lt;br/&gt;The methods developed will enlarge the tool-box available to statisticians and data scientists as they attempt to extract meaningful information from datasets comprising a very large number of variables. The approach builds on the "knock-off" framework, a very flexible and novel approach that does not require specifying a model for the relation between an outcome of interest and possible co-variates. The inferential guarantees provided are on the selected variables, with control of the False Discovery Rate (FDR), where a discovery is considered false if a selected variable is independent of the outcome given the remaining covariates.  This provides assurance on the reproducibility of results, as well as on their interpretability.  The approaches developed will be used to analyze genetics datasets with the goal of obtaining more complete models of how DNA variation influences medically relevant phenotypes.  This project is supported by the Division of Mathematical Sciences and the Division of Molecular and Cellular Biosciences.</AbstractNarration>
<MinAmdLetterDate>06/14/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1712800</AwardID>
<Investigator>
<FirstName>Chiara</FirstName>
<LastName>Sabatti</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chiara Sabatti</PI_FULL_NAME>
<EmailAddress>sabatti@stanford.edu</EmailAddress>
<PI_PHON>6507215338</PI_PHON>
<NSF_ID>000096092</NSF_ID>
<StartDate>06/14/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Emmanuel</FirstName>
<LastName>Candes</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emmanuel Candes</PI_FULL_NAME>
<EmailAddress>candes@stanford.edu</EmailAddress>
<PI_PHON>6507232974</PI_PHON>
<NSF_ID>000487480</NSF_ID>
<StartDate>06/14/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943054020</ZipCode>
<StreetAddress><![CDATA[390 Serra Mall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1112</Code>
<Text>Genetic Mechanisms</Text>
</ProgramElement>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<ProgramReference>
<Code>7465</Code>
<Text>NANOSCALE BIO CORE</Text>
</ProgramReference>
<ProgramReference>
<Code>8007</Code>
<Text>BioMaPS</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~420000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-2dad5ebd-7fff-f135-f84f-7ec199735ea8">&nbsp;</span></p> <p dir="ltr"><span>The data science revolution has been driven by impressive technological advances in the capture, storage, and processing of data. Our concern is the recent progress in machine learning which provides us with many potentially effective tools to learn from large datasets and make useful predictions. While scientists and engineers are getting comfortable with the idea of using models that are extremely difficult to interpret &mdash; black boxes &mdash; two things cannot be compromised upon. The first is the reproducibility of scientific results. If I use a black box to determine which genomic regions influence a trait, e.g. the susceptibility to autism, how do I make sure that my findings can be reproduced in follow-up studies? How do I make sure they are robust and will not be rapidly dismissed? The second concerns the validity of predictions. As we are increasingly turning to machine learning systems to support human decisions, how do we determine their validity? If a learning algorithm predicts the GPA of a prospective college applicant, what guarantees do I have concerning the accuracy of this prediction? Our project has addressed both these concerns: we have developed broad methodologies that can be wrapped around any black box to produce results that can be trusted.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>First, replicability. This project addressed a crucial need, namely, the development of statistical methods which, in a sea of noise, (1) discover factors that are important for an outcome of interest, and&nbsp; (2) control the number of false positives so that we do not run into the problem of irreplicability. This was achieved by developing the theory and practice of </span><span>knockoffs</span><span>.&nbsp; The idea behind knockoffs is to manufacture fake variables, which must obey some delicate stochastic relationship with the original variables under study, and can</span><span> </span><span>essentially be used as `negative controls.&rsquo; By comparing how any algorithm scores the importance of a variable against its knockoff, the statistician learns how to tease out real effects from spurious correlations that will fail to replicate. This project effectively transformed the mere idea of knockoffs into a series of highly operational procedures and algorithms. We have shown how to construct knockoffs for essentially any data distribution and all statistical models in common use. Further, when a good stochastic model is not available to describe the distribution of the features, we have shown how to use ideas from deep learning and generative modeling to generate accurate knockoffs in an entirely data-driven/model free&nbsp; fashion. We have applied this to create accurate knockoffs for individual genotypes taken from large genetic studies, including studies that contain related individuals and complicated population structure. We have developed a full data analysis pipeline&nbsp; for the genetic mapping of complex traits at multiple resolutions, which localizes causal variants precisely. This method is equally valid for quantitative and binary phenotypes, making no assumptions about their genetic architectures. This pipeline detects more associations than mixed effects models and achieves fine-mapping precision, at comparable computational cost. This results in many new findings when applied to the UK Biobank data, and has the potential to impact the way we perform genome-wide association studies. At the methodological level, we showed how to combine knockoffs with information from other studies to increase power, and to improve the selection algorithm itself so that runs on similar data sets produce consistent outcomes. Because of this, knockoffs has become a standard tool, and is routinely applied in a number of different fields ranging from spectrometry to the study of psoriatic arthritis in clinical trials.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>We also introduced new techniques to rigorously draw causal inferences--inferences provably immune to all confounding variables&mdash;from some observational data, and most notably from genetic studies with parent-child trio data.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>Second, validity. We have developed new methods giving meaningful inference guarantees and, yet, are sufficiently flexible so that they apply regardless of data distribution or of the types of algorithms that are fitted to the data (so that the algorithms can be considered as black boxes). This extends and improves upon a line of work started by Vovk known under the name of </span><span>conformal inference</span><span>. In particular, we have provided solutions for constructing predictive intervals -- intervals containing the unknown label 90% of the time, say -- in extremely common situations where there is a distributional shift between training and testing (everyone in machine learning cares about this). Also, we have developed new techniques which use data samples to train a predictive model and to calibrate the prediction intervals at the same time; this is extremely important in applications where data is scarce.&nbsp; Finally, we laid out the fundamental limits of performance in conditional predictive inference. </span><span><span> </span></span><span><span> </span></span><span><span> </span></span><span><span> </span></span></p> <p dir="ltr"><span>Five graduate students were trained while working on this project. Two of them have moved on to Assistant Professorship positions at leading universities. One works at Apple Inc. The other two are still in training.&nbsp;</span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/28/2020<br>      Modified by: Chiara&nbsp;Sabatti</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The data science revolution has been driven by impressive technological advances in the capture, storage, and processing of data. Our concern is the recent progress in machine learning which provides us with many potentially effective tools to learn from large datasets and make useful predictions. While scientists and engineers are getting comfortable with the idea of using models that are extremely difficult to interpret &mdash; black boxes &mdash; two things cannot be compromised upon. The first is the reproducibility of scientific results. If I use a black box to determine which genomic regions influence a trait, e.g. the susceptibility to autism, how do I make sure that my findings can be reproduced in follow-up studies? How do I make sure they are robust and will not be rapidly dismissed? The second concerns the validity of predictions. As we are increasingly turning to machine learning systems to support human decisions, how do we determine their validity? If a learning algorithm predicts the GPA of a prospective college applicant, what guarantees do I have concerning the accuracy of this prediction? Our project has addressed both these concerns: we have developed broad methodologies that can be wrapped around any black box to produce results that can be trusted.    First, replicability. This project addressed a crucial need, namely, the development of statistical methods which, in a sea of noise, (1) discover factors that are important for an outcome of interest, and  (2) control the number of false positives so that we do not run into the problem of irreplicability. This was achieved by developing the theory and practice of knockoffs.  The idea behind knockoffs is to manufacture fake variables, which must obey some delicate stochastic relationship with the original variables under study, and can essentially be used as `negative controls.’ By comparing how any algorithm scores the importance of a variable against its knockoff, the statistician learns how to tease out real effects from spurious correlations that will fail to replicate. This project effectively transformed the mere idea of knockoffs into a series of highly operational procedures and algorithms. We have shown how to construct knockoffs for essentially any data distribution and all statistical models in common use. Further, when a good stochastic model is not available to describe the distribution of the features, we have shown how to use ideas from deep learning and generative modeling to generate accurate knockoffs in an entirely data-driven/model free  fashion. We have applied this to create accurate knockoffs for individual genotypes taken from large genetic studies, including studies that contain related individuals and complicated population structure. We have developed a full data analysis pipeline  for the genetic mapping of complex traits at multiple resolutions, which localizes causal variants precisely. This method is equally valid for quantitative and binary phenotypes, making no assumptions about their genetic architectures. This pipeline detects more associations than mixed effects models and achieves fine-mapping precision, at comparable computational cost. This results in many new findings when applied to the UK Biobank data, and has the potential to impact the way we perform genome-wide association studies. At the methodological level, we showed how to combine knockoffs with information from other studies to increase power, and to improve the selection algorithm itself so that runs on similar data sets produce consistent outcomes. Because of this, knockoffs has become a standard tool, and is routinely applied in a number of different fields ranging from spectrometry to the study of psoriatic arthritis in clinical trials.     We also introduced new techniques to rigorously draw causal inferences--inferences provably immune to all confounding variables&mdash;from some observational data, and most notably from genetic studies with parent-child trio data.     Second, validity. We have developed new methods giving meaningful inference guarantees and, yet, are sufficiently flexible so that they apply regardless of data distribution or of the types of algorithms that are fitted to the data (so that the algorithms can be considered as black boxes). This extends and improves upon a line of work started by Vovk known under the name of conformal inference. In particular, we have provided solutions for constructing predictive intervals -- intervals containing the unknown label 90% of the time, say -- in extremely common situations where there is a distributional shift between training and testing (everyone in machine learning cares about this). Also, we have developed new techniques which use data samples to train a predictive model and to calibrate the prediction intervals at the same time; this is extremely important in applications where data is scarce.  Finally, we laid out the fundamental limits of performance in conditional predictive inference.      Five graduate students were trained while working on this project. Two of them have moved on to Assistant Professorship positions at leading universities. One works at Apple Inc. The other two are still in training.              Last Modified: 12/28/2020       Submitted by: Chiara Sabatti]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
