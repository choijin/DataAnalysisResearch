<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Empirical Tuning for Extreme Scale</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>02/28/2018</AwardExpirationDate>
<AwardTotalIntnAmount>138072.00</AwardTotalIntnAmount>
<AwardAmount>154686</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sushil K Prasad</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Today, simulation and scientific computation underlie many if not most areas of science and engineering. For many of these areas, there is no such thing as enough compute power: as processing speed is increased, the scientist is free to increase the complexity, and thus accuracy, of the simulation or computation. It is therefore critical that scientific computing software extract the maximal level of performance on all the various hardware used by researchers. Unfortunately, getting software to run at near-peak speeds while maintaining numerical accuracy is a challenging problem for even the most well-informed computer scientist, and is almost impossible for those in other fields to achieve. Performance tuning requires the application of a vast array of optimizations, many of which are almost unknown outside of specialized computer science literature. An optimization that provides large speedup on one machine may cause performance loss on another, so that even computer scientists who specialize in optimization research have struggled to provide computational scientists with kernels that deliver deliver outstanding performance across all available machines. The only known way to address this critical problem is to build software frameworks which can use empirical timings on the user's actual hardware to automatically select the best optimizations to apply. In this way, instead of writing a library of routines optimized for only a handful of architectures, the computer scientists builds a software framework that automatically adapt each kernel of interest to the particular hardware possessed by the scientist or engineer. If such frameworks are to be used by researchers who are not themselves sophisticated in computer science, the self-adapting framework must be robust numerically and require little or no knowledge of the hardware from the installer.&lt;br/&gt;&lt;br/&gt;The PI's ATLAS (Automatically Tuned Linear Algebra Software) autotuning framework was one of the pioneering projects that showed that empirical auto-tuning could address this vital need, mostly in the context of serial or low-parallel computation. The PI's career plan calls for performing the cutting-edge systems research necessary to extend ATLAS to address today's need for extreme-scale computation, and to exploit the ongoing evolution of computer architecture, thus helping the hundreds of thousands of scientists and engineers that rely on linear algebra for their computational performance. In order to make the impact of this CAREER plan even wider, the PI and collaborators will undertake groundbreaking research in empirical compilation and embody the fruits of this labor into a freely available empirical optimizing compiler, which will enable autotuning for almost any scientific computation. Most of this work will be undertaken by students at a minority serving institution, and since this work requires a deep understanding of architecture, parallel computing, and backend compiler research, these students will obtain outstanding educational benefit. Further, the results of this fundamental systems research will allow us to drastically improve our curricula, particularly in graduate and undergraduate Parallel Programming, Computer Architecture, and advanced optimization classes.</AbstractNarration>
<MinAmdLetterDate>09/22/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/22/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1753923</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Whaley</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard C Whaley</PI_FULL_NAME>
<EmailAddress>rcwhaley@iu.edu</EmailAddress>
<PI_PHON>2257167260</PI_PHON>
<NSF_ID>000364787</NSF_ID>
<StartDate>09/22/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474013654</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~33146</FUND_OBLG>
<FUND_OBLG>2016~121540</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>ATLAS (Automatically Tuned Linear Algebra Software) is critical cyberinfrastructure for high performance computing and computational science.&nbsp; It is used by government, academia, and industry.&nbsp; This grant has supported the modernization of this framework for current extreme-scale parallel architectures.&nbsp; Because fields as disparate as computional science, spam filtering, machine learning, movie special effects and medical imaging all require extremely efficient linear algebra, having a high quality open source library is critical to continued advancement in all these areas.&nbsp; There have been 58 developer releases, and 4 stable releases of ATLAS supported by this award.</p> <p>This grant also supported the further development of iFKO (iterative Floating Point Kernel Optimizer), which is a compiler specialized to make arbitrary computational kernels run at near-peak speeds.&nbsp; If this research is successful, high performance will be available to anyone needing efficient computation, which will allow this work even wider impact.&nbsp; There has been one public release of iFKO so far.</p> <p>Academically, this grant has supported 3 PhDs and 3 Masters degrees in computer science; all of these students are using these skills in the American workforce.&nbsp; It supported the development of two new classes currently being&nbsp; taught at American universities, and has so far resulted in one journal article (with two presently under preperation),&nbsp; two conference publications,&nbsp; one academic poster,&nbsp; and one invited talk.</p><br> <p>            Last Modified: 05/28/2018<br>      Modified by: Richard&nbsp;C&nbsp;Whaley</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ ATLAS (Automatically Tuned Linear Algebra Software) is critical cyberinfrastructure for high performance computing and computational science.  It is used by government, academia, and industry.  This grant has supported the modernization of this framework for current extreme-scale parallel architectures.  Because fields as disparate as computional science, spam filtering, machine learning, movie special effects and medical imaging all require extremely efficient linear algebra, having a high quality open source library is critical to continued advancement in all these areas.  There have been 58 developer releases, and 4 stable releases of ATLAS supported by this award.  This grant also supported the further development of iFKO (iterative Floating Point Kernel Optimizer), which is a compiler specialized to make arbitrary computational kernels run at near-peak speeds.  If this research is successful, high performance will be available to anyone needing efficient computation, which will allow this work even wider impact.  There has been one public release of iFKO so far.  Academically, this grant has supported 3 PhDs and 3 Masters degrees in computer science; all of these students are using these skills in the American workforce.  It supported the development of two new classes currently being  taught at American universities, and has so far resulted in one journal article (with two presently under preperation),  two conference publications,  one academic poster,  and one invited talk.       Last Modified: 05/28/2018       Submitted by: Richard C Whaley]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
