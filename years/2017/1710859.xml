<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Data-driven distributed control of mobile robotic networks: Where machine learning meets game theory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2017</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Donald Wunsch</SignBlockName>
<PO_EMAI>dwunsch@nsf.gov</PO_EMAI>
<PO_PHON>7032927102</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Mobile robotic networks; (e.g., fleets of unmanned aerial vehicles) offer expanded capabilities for recognized military uses as well as a wide variety of civilian uses. There are several factors that contribute to their increasing potential and importance. In particular, technological advances have enabled smaller platforms with increased sensing, communication, and processing capabilities. In addition, autonomous operations offer several competitive advantages such as persistent surveillance that exceeds human fatigue limitations or remote operation capabilities without the logistical transport costs for assets and personnel. &lt;br/&gt;&lt;br/&gt;Intellectual Merit: Distributed control becomes key to fully realize the potentials of mobile robotic networks. Current distributed control paradigms are mainly model-based and inadequate to handle significant uncertainties, including (1) environmental uncertainties; i.e., unforeseeable elements in unstructured environments where mobile robots operate; (2) dynamic uncertainties; i.e., inaccuracies of the physical dynamics of mobile robots. To bridge the gaps, this project will leverage reinforcement learning, an area of machine learning, and game theory, initially developed in economics, to develop a new data-driven (more specifically, model-free) distributed control framework. The developed framework is model-free, fully distributed, autonomous, and its performance is rigorously provable. The framework will significantly improve the autonomy of mobile robots when they face significant environmental uncertainties and dynamic uncertainties especially in long-term missions. &lt;br/&gt;&lt;br/&gt;Broader Impacts: Successful completion of this research will provide engineering guidelines in analysis, synthesis and prototyping of mobile robotic networks which can effectively operate in unstructured environments. The research findings profoundly impact a variety of engineering disciplines, including scientific data collection, homeland security operations and intelligent transportation systems. The proposed research is interdisciplinary and involves interactions among game theory, machine learning, control, robotic motion planning and distributed algorithms. This will lead to educational and training opportunities that cross traditional disciplinary boundaries for high-school, undergraduate and graduate students in STEM. The collaborations with industrial partners stress the potentials to make an impact beyond academia.</AbstractNarration>
<MinAmdLetterDate>06/15/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/15/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1710859</AwardID>
<Investigator>
<FirstName>Minghui</FirstName>
<LastName>Zhu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Minghui Zhu</PI_FULL_NAME>
<EmailAddress>muz16@psu.edu</EmailAddress>
<PI_PHON>8148651372</PI_PHON>
<NSF_ID>000655619</NSF_ID>
<StartDate>06/15/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>State College</CityName>
<StateCode>PA</StateCode>
<ZipCode>168027000</ZipCode>
<StreetAddress><![CDATA[227E Electrical Engineering West]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT/>
<CONGRESS_DISTRICT_PERF>PA"</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Multi-robot systems; e.g., fleets of unmanned aerial/ground vehicles, offer expanded capabilities for recognized civilian uses as well as a wide variety of military uses; e.g., search and rescue, cargo delivery, scientific data collection, and homeland security operations. Distributed control has emerged as an effective way to coordinate multi-robot systems. However, current distributed control paradigms are mainly model-based and inadequate to handle the significant uncertainties of operating environments and robot dynamics. In this project, the PI develops new data-driven distributed control paradigms to complement the existing model-based counterparts.</p> <p>&nbsp;</p> <p>The PI investigates a class of multi-player discrete games where each player aims to maximize its own utility function. Each player does not know the other players? action sets, their deployed actions or the structures of its own or the others? utility functions. Instead, each player only knows its own deployed actions and its received utility values in recent history. The PI proposes a distributed reinforcement learning algorithm which converges to the set of action profiles which have maximal stochastic potential with probability one. Furthermore, an upper bound on the convergence rate is derived and minimized when the exploration rates are restricted to&nbsp;p-series. The algorithm performance is verified using a case study of demand response in the smart grid.</p> <p>&nbsp;</p> <p>In addition, the PI considers the problem where a group of agents aim to collaboratively learn a common latent function through streaming data. The PI proposes a distributed Gaussian process regression (GPR) algorithm, which is cognizant of agents? limited capabilities in communication, computation and memory. The analysis reveals that limited inter-agent communication improves learning performances in the sense of Pareto, i.e., some agents? performances improve without sacrificing other agents? performances. The agents with lower dispersion of data samples (or observation noise of lower variance) help improve the performance of the agents with higher dispersion (or observation noise of higher variance). This work is the first time to quantify the improvement of individual agent?s learning performance brought by limited inter-agent communication.</p> <p>&nbsp;</p> <p>Furthermore, the PI investigates a class of multi-robot motion planning problems where multiple robots aim to reach their respective goal regions as soon as possible. The robots are restricted to complex dynamic constraints and need to avoid the collisions with static obstacles and other robots. Pareto optimality is used as the solution notion where no robot can reduce its own travelling time without extending others?. A numerical algorithm is proposed to identify the Pareto optimal solutions. It is shown that, under mild regularity conditions, the algorithm can consistently approximate the epigraph of the minimal arrival time function. Experiments on an indoor multi-robot platform and computer simulations on unicycle robots are conducted to demonstrate the anytime property of the proposed algorithm; i.e., it is able to quickly return a feasible control policy that safely steers the robots to their goal regions and it keeps improving policy optimality if more time is given.</p> <p>&nbsp;</p> <p>The research findings of this project significantly improve the capabilities of multi-robot systems to autonomously operate in unstructured, uncertain and dynamic environments without human intervention. The improved capabilities will profoundly impact a variety of engineering disciplines, including manufacturing, homeland security, power systems and transportation. The project opens new opportunities to study multi-robot coordination from the perspectives of contemporary machine learning. Undergraduate, Master and Ph.D. students, who participate in the project, are trained in the intersection of game theory, machine learning, control, robotic motion planning and distributed algorithms. The PI collaborates with researchers at the GE Research and the Mitsubishi Electric Research Laboratories. The research findings are published at major journals and conferences of control, robotics and machine learning.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/01/2021<br>      Modified by: Minghui&nbsp;Zhu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Multi-robot systems; e.g., fleets of unmanned aerial/ground vehicles, offer expanded capabilities for recognized civilian uses as well as a wide variety of military uses; e.g., search and rescue, cargo delivery, scientific data collection, and homeland security operations. Distributed control has emerged as an effective way to coordinate multi-robot systems. However, current distributed control paradigms are mainly model-based and inadequate to handle the significant uncertainties of operating environments and robot dynamics. In this project, the PI develops new data-driven distributed control paradigms to complement the existing model-based counterparts.     The PI investigates a class of multi-player discrete games where each player aims to maximize its own utility function. Each player does not know the other players? action sets, their deployed actions or the structures of its own or the others? utility functions. Instead, each player only knows its own deployed actions and its received utility values in recent history. The PI proposes a distributed reinforcement learning algorithm which converges to the set of action profiles which have maximal stochastic potential with probability one. Furthermore, an upper bound on the convergence rate is derived and minimized when the exploration rates are restricted to p-series. The algorithm performance is verified using a case study of demand response in the smart grid.     In addition, the PI considers the problem where a group of agents aim to collaboratively learn a common latent function through streaming data. The PI proposes a distributed Gaussian process regression (GPR) algorithm, which is cognizant of agents? limited capabilities in communication, computation and memory. The analysis reveals that limited inter-agent communication improves learning performances in the sense of Pareto, i.e., some agents? performances improve without sacrificing other agents? performances. The agents with lower dispersion of data samples (or observation noise of lower variance) help improve the performance of the agents with higher dispersion (or observation noise of higher variance). This work is the first time to quantify the improvement of individual agent?s learning performance brought by limited inter-agent communication.     Furthermore, the PI investigates a class of multi-robot motion planning problems where multiple robots aim to reach their respective goal regions as soon as possible. The robots are restricted to complex dynamic constraints and need to avoid the collisions with static obstacles and other robots. Pareto optimality is used as the solution notion where no robot can reduce its own travelling time without extending others?. A numerical algorithm is proposed to identify the Pareto optimal solutions. It is shown that, under mild regularity conditions, the algorithm can consistently approximate the epigraph of the minimal arrival time function. Experiments on an indoor multi-robot platform and computer simulations on unicycle robots are conducted to demonstrate the anytime property of the proposed algorithm; i.e., it is able to quickly return a feasible control policy that safely steers the robots to their goal regions and it keeps improving policy optimality if more time is given.     The research findings of this project significantly improve the capabilities of multi-robot systems to autonomously operate in unstructured, uncertain and dynamic environments without human intervention. The improved capabilities will profoundly impact a variety of engineering disciplines, including manufacturing, homeland security, power systems and transportation. The project opens new opportunities to study multi-robot coordination from the perspectives of contemporary machine learning. Undergraduate, Master and Ph.D. students, who participate in the project, are trained in the intersection of game theory, machine learning, control, robotic motion planning and distributed algorithms. The PI collaborates with researchers at the GE Research and the Mitsubishi Electric Research Laboratories. The research findings are published at major journals and conferences of control, robotics and machine learning.          Last Modified: 08/01/2021       Submitted by: Minghui Zhu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
