<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: IA: Distributed Semi-Supervised Training of Deep Models and Its Applications in Video Understanding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>662431.00</AwardTotalIntnAmount>
<AwardAmount>662431</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project investigates semi-supervised training of deep neural network models using large-scale labeled and unlabeled data in a distributed fashion. Deep neural networks have recently been widely deployed in artificial intelligence and related scientific fields, largely attributing to well-labeled big datasets and improved computing capabilities. However, the unlabeled data, which is often bigger, is inherently ruled out by the prevailing supervised training of the deep models. It is indeed highly challenging to model the unlabeled parts of many recent and emerging datasets, which are often unstructured and distributed over different nodes of a network (e.g., the videos captured by a camera network). This project aims to explore how to effectively use the unlabeled and distributed data to complement the discriminative cues of the labeled data, to jointly learn accurate and robust deep models. The research seamlessly unifies machine learning, computer vision, and parallel computing, and fosters unique interdisciplinary research and education programs for the graduate and undergraduate students.&lt;br/&gt;&lt;br/&gt;Despite the progress on semi-supervised learning and deep learning, the confluence of these two is mostly studied on a small scale in single-machine environment. However, many new datasets easily grow beyond the computation or even storage capacity of a single machine. Hence, it becomes a pressing need to investigate the semi-supervised learning of deep models on parallel computing platforms. To better account for this scenario, this project develops improved network architectures to facilitate the parallel training, and the training procedure developed adaptively switches between synchronized and asynchronized modes for optimal efficiency. The main idea is to incorporate a parametric distribution to the neural network and use covariate matching to coordinate the network behaviors across different machines. The researchers also explore a novel application, extreme-scale spatial-temporal action annotation of video sequences, to benchmark the algorithms and frameworks in this project.</AbstractNarration>
<MinAmdLetterDate>08/29/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1741431</AwardID>
<Investigator>
<FirstName>Liqiang</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Liqiang Wang</PI_FULL_NAME>
<EmailAddress>lwang@cs.ucf.edu</EmailAddress>
<PI_PHON>4078233187</PI_PHON>
<NSF_ID>000248300</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mubarak</FirstName>
<LastName>Shah</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mubarak Shah</PI_FULL_NAME>
<EmailAddress>shah@crcv.ucf.edu</EmailAddress>
<PI_PHON>4078232004</PI_PHON>
<NSF_ID>000698706</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate>07/07/2018</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mubarak</FirstName>
<LastName>Shah</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mubarak Shah</PI_FULL_NAME>
<EmailAddress>shah@crcv.ucf.edu</EmailAddress>
<PI_PHON>4078232004</PI_PHON>
<NSF_ID>000698706</NSF_ID>
<StartDate>07/07/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Boqing</FirstName>
<LastName>Gong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Boqing Gong</PI_FULL_NAME>
<EmailAddress>bgong@icsi.berkeley.edu</EmailAddress>
<PI_PHON>2138107118</PI_PHON>
<NSF_ID>000703661</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate>07/07/2018</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>The University of Central Florida Board of Trustees</Name>
<CityName>Orlando</CityName>
<ZipCode>328168005</ZipCode>
<PhoneNumber>4078230387</PhoneNumber>
<StreetAddress>4000 CNTRL FLORIDA BLVD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>150805653</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Central Florida]]></Name>
<CityName>ORLANDO</CityName>
<StateCode>FL</StateCode>
<ZipCode>328168005</ZipCode>
<StreetAddress><![CDATA[4000 CNTRL FLORIDA BLVD]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~662431</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="OutlineElement Ltr SCXW249434164 BCX0"> <p class="Paragraph SCXW249434164 BCX0">We have made&nbsp;a&nbsp;significant progress in semi-supervised and distributed learning.&nbsp;The&nbsp;improvement in analysis of images and videos&nbsp;using big data&nbsp;is also noteworthy. Over the course of this project we have published&nbsp;around 20 papers at top venues&nbsp;such as CVPR, PAMI, ICCV, ICML, AAAI, BMVC and WACV.&nbsp;Many&nbsp;graduate students have been&nbsp;funded&nbsp;under this project namely,&nbsp;Amir Mazaheri, Yifan Ding, Marzieh Edraki, Mohamed Elfeki, Muhammad Abdullah Jamal, Ehsan Kazemi Foroushani, Jyoti Kini, Yandong Li, Bingbing Rao, Sarah Shiraz and Dongdong Wang.&nbsp;&nbsp;Several&nbsp;undergraduate and high school students&nbsp;supported on other grants&nbsp;have also been&nbsp;exposed to big video data and semi-supervised&nbsp;and distributed learning&nbsp;and trained&nbsp;during this project.&nbsp;</p> </div> <div class="OutlineElement Ltr SCXW249434164 BCX0"> <p class="Paragraph SCXW249434164 BCX0">Our proposed&nbsp;semi-supervised&nbsp;approaches&nbsp;make use&nbsp;of large amount of unlabeled or weakly labeled data to enable&nbsp;better learning via deep learning methods.&nbsp;We employ our methods&nbsp;for&nbsp;several&nbsp;computer vision&nbsp;tasks.&nbsp;For&nbsp;semantic segmentation,&nbsp;an important computer vision task&nbsp;which&nbsp;requires extensive labels&nbsp;for each pixel,&nbsp;we&nbsp;designed a&nbsp;semi-supervised approach using&nbsp;Generative adversarial networks&nbsp;(GAN)&nbsp;and achieved&nbsp;better results than supervised approaches.&nbsp;We also&nbsp;developed&nbsp;a semi-supervised approach&nbsp;to address noise in&nbsp;bigdata,&nbsp;i.e.&nbsp;labels required for training are either incorrect or missing.&nbsp;The proposed&nbsp;two-stage&nbsp;semi-supervised&nbsp;approach&nbsp;make use&nbsp;of&nbsp;a large set of&nbsp;noisy data&nbsp;by ignoring the incorrectly labeled set.&nbsp;We also proposed&nbsp;a novel&nbsp;visual text correction&nbsp;method&nbsp;which utilize visual&nbsp;cues from videos to correct any errors in the corresponding text. This can be beneficial&nbsp;for&nbsp;noisy labels&nbsp;and&nbsp;improve the&nbsp;data quality&nbsp;for further&nbsp;use.&nbsp;All these&nbsp;methods have been&nbsp;evaluated on multiple datasets and published at top conferences.&nbsp;&nbsp;</p> </div> <div class="OutlineElement Ltr SCXW249434164 BCX0"> <p class="Paragraph SCXW249434164 BCX0">Distributed learning&nbsp;was&nbsp;one of the objectives of this project.&nbsp;Our integrated solution to the distributed semi-supervised training of deep models could be applied to other scientific domains. The proposed research enriched&nbsp;the family of deep learning methods by modeling the inherent characteristics of data to enable effective learning from the distributed, and heterogeneous image and video data. To further facilitate faster and scalable training of the deep models, we also developed&nbsp;a novel parallel computing framework tailored for the deep neural networks.&nbsp;For faster training of deep learning&nbsp;models,&nbsp;we also proposed a mix normalization approach which reduces the number of gradient updates.&nbsp;The carefully chosen application domains enable us to additionally explore the temporal structures and models.&nbsp;&nbsp;</p> </div> <div class="OutlineElement Ltr SCXW249434164 BCX0"> <p class="Paragraph SCXW249434164 BCX0">Improvement in&nbsp;video analysis&nbsp;was&nbsp;another objective of this project.&nbsp;Our research in video analysis can be applied to improve tracking, autonomous driving, surveillance, and to robustify robotics.&nbsp;Our methods&nbsp;on video object segmentation and action segmentation demonstrated&nbsp;state-of-the-art performance.&nbsp;We&nbsp;also&nbsp;proposed a structure preserving&nbsp;representative algorithm&nbsp;and&nbsp;evaluate it for&nbsp;various tasks&nbsp;such as&nbsp;active learning for video action recognition,&nbsp;training a generative adversarial network (GAN) to generate multi-view images from a single-view input,&nbsp;and video summarization.&nbsp;We also proposed a compact model with multi-domain learning using depth-wise separable convolutions.&nbsp;Our&nbsp;proposed&nbsp;Task Focused visual Attention (TFA) which improved accuracy in&nbsp;pick-up and push tasks&nbsp;is&nbsp;important&nbsp;for robustifying&nbsp;the&nbsp;visuomotor&nbsp;policy.&nbsp;&nbsp;</p> </div> <p>&nbsp;</p><br> <p>            Last Modified: 12/03/2020<br>      Modified by: Mubarak&nbsp;Shah</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We have made a significant progress in semi-supervised and distributed learning. The improvement in analysis of images and videos using big data is also noteworthy. Over the course of this project we have published around 20 papers at top venues such as CVPR, PAMI, ICCV, ICML, AAAI, BMVC and WACV. Many graduate students have been funded under this project namely, Amir Mazaheri, Yifan Ding, Marzieh Edraki, Mohamed Elfeki, Muhammad Abdullah Jamal, Ehsan Kazemi Foroushani, Jyoti Kini, Yandong Li, Bingbing Rao, Sarah Shiraz and Dongdong Wang.  Several undergraduate and high school students supported on other grants have also been exposed to big video data and semi-supervised and distributed learning and trained during this project.    Our proposed semi-supervised approaches make use of large amount of unlabeled or weakly labeled data to enable better learning via deep learning methods. We employ our methods for several computer vision tasks. For semantic segmentation, an important computer vision task which requires extensive labels for each pixel, we designed a semi-supervised approach using Generative adversarial networks (GAN) and achieved better results than supervised approaches. We also developed a semi-supervised approach to address noise in bigdata, i.e. labels required for training are either incorrect or missing. The proposed two-stage semi-supervised approach make use of a large set of noisy data by ignoring the incorrectly labeled set. We also proposed a novel visual text correction method which utilize visual cues from videos to correct any errors in the corresponding text. This can be beneficial for noisy labels and improve the data quality for further use. All these methods have been evaluated on multiple datasets and published at top conferences.     Distributed learning was one of the objectives of this project. Our integrated solution to the distributed semi-supervised training of deep models could be applied to other scientific domains. The proposed research enriched the family of deep learning methods by modeling the inherent characteristics of data to enable effective learning from the distributed, and heterogeneous image and video data. To further facilitate faster and scalable training of the deep models, we also developed a novel parallel computing framework tailored for the deep neural networks. For faster training of deep learning models, we also proposed a mix normalization approach which reduces the number of gradient updates. The carefully chosen application domains enable us to additionally explore the temporal structures and models.     Improvement in video analysis was another objective of this project. Our research in video analysis can be applied to improve tracking, autonomous driving, surveillance, and to robustify robotics. Our methods on video object segmentation and action segmentation demonstrated state-of-the-art performance. We also proposed a structure preserving representative algorithm and evaluate it for various tasks such as active learning for video action recognition, training a generative adversarial network (GAN) to generate multi-view images from a single-view input, and video summarization. We also proposed a compact model with multi-domain learning using depth-wise separable convolutions. Our proposed Task Focused visual Attention (TFA) which improved accuracy in pick-up and push tasks is important for robustifying the visuomotor policy.             Last Modified: 12/03/2020       Submitted by: Mubarak Shah]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
