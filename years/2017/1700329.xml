<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Quantitative Methods for Modeling Properties of Random Media</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2017</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>180000.00</AwardTotalIntnAmount>
<AwardAmount>180000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marian Bocea</SignBlockName>
<PO_EMAI>mbocea@nsf.gov</PO_EMAI>
<PO_PHON>7032922595</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many physical systems are best understood as the collective behavior of many smaller irregularities. An example is a cloud of gas comprised of a huge number of individual particles colliding with each other. On a larger (macroscopic) scale, this very seemingly complicated system may have a much simpler, but still very precise, description (the ideal gas law, for instance) due to the effects of the incalculable number of smaller scale interactions "averaging out." Other examples include the modeling of water moving through a porous rock, or the physical properties of composite materials. The derivation of large-scale, "averaged" laws from complicated small-scale irregularities and interactions lies in the realm of statistical physics. The goal of this project is to develop mathematical tools for a rigorous understanding of such problems under the assumption that the small-scale irregularities are occurring randomly. We would like to answer such questions as: How can the large-scale physical law, including the proportionality constants, be accurately predicted from the behavior of the small-scale interactions? What is the error in the large-scale law, in other words, what length scale is large enough that we observe the averaged behavior rather than seeing the complicated random fluctuations? Such questions are not just important to statistical physics and probability, but they also have wider applications, such as to the design of optimal composite materials or the construction of geothermal power plants. &lt;br/&gt;&lt;br/&gt;Partial differential equations are used to model many important physical systems, and the focus of the project is to understand the large-scale behavior of solutions to such equations under the assumption that the coefficients exhibit small-scale random oscillations. Obtaining an "averaged" partial differential equation that describes the large-scale behavior of the original, more complicated equation is called "homogenization" in the mathematical literature. If randomness is incorporated in the model, it is usually referred to as "stochastic homogenization." In recent years, researchers have developed a rather complete quantitative theory of stochastic homogenization for the simplest situation: uniformly elliptic equations. These equations model electrostatic properties of composite materials, for instance. The present project aims to go further by obtaining a quantitative theory of homogenization for "degenerate" equations as well as equations in porous media. Particular goals include rigorously justifying the Darcy-Brinkman law for fluid flow in a porous rock with quantitative error bounds; deriving the effective viscosity of a dilute suspension of particles in a fluid; obtaining bounds for the diffusivity of a particle moving randomly on a percolation cluster as well as more precise estimates for the long-time behavior (intermediate asymptotics) of a diffusion in a random medium; the analysis of boundary layers in periodic and stochastic homogenization; and obtaining homogenization results for shape optimization problems. For each of these problems, the goal is to develop a quantitative mathematical theory that provides explicit error bounds and robust analytic techniques.</AbstractNarration>
<MinAmdLetterDate>07/07/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/01/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1700329</AwardID>
<Investigator>
<FirstName>Scott</FirstName>
<LastName>Armstrong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Scott Armstrong</PI_FULL_NAME>
<EmailAddress>sa3602@nyu.edu</EmailAddress>
<PI_PHON>2129983001</PI_PHON>
<NSF_ID>000733201</NSF_ID>
<StartDate>07/07/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>100121110</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1263</Code>
<Text>PROBABILITY</Text>
</ProgramElement>
<ProgramElement>
<Code>1281</Code>
<Text>ANALYSIS PROGRAM</Text>
</ProgramElement>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~120000</FUND_OBLG>
<FUND_OBLG>2019~60000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project was focused on developing new mathematical techniques for understanding physical systems which have complicated small-scale structure but are expected to have simpler properties when viewed from a large ("macroscopic") scale. As an example, one can think of composite materials, which under a microscope may be revealed to be composed of two or more different constituent materials (carbon and silicon, perhaps) which are arranged in some erratic or random way. On large scales, however, one sees a "homogeneous" material with properties which are different from each of the consituents. The question then becomes how to understand or predict the emergent physical properties of the macroscopic material from those of the constituents and geometry of the small-scale mixing. A related question is how "regular" one can expect the macroscopic material to be, in other words, how far do you need to "zoom out" before you see homogenization occur, and what should we expect the error to be in the homogenization approximation?</p> <p>These kinds of problems are classical in statistical physics, probability theory, and other related disciplines like the theory of fluid dynamics and turbulence. For instance, to understand the magnetism of an iron bar one really has to zoom in to the scale of individual atoms and observe how their spins tend to line up in the same direction. The magnetism which is observed on the&nbsp;macroscopic&nbsp; is a result of the cumulative behavior of the collective behavior of the individual atoms.</p> <p>In recent years, a new mathematical theory of <em>quantitative stochastic homogenization</em>&nbsp;has emerged, which describes the way in which partial differential equations (the mathematical description of the physical processes) with random, highly oscillating coefficients (modeling the small scale disorder) behave on large "macroscopic" scales. It is foscused, as its name suggets, on quantitative questions of the exactly the sort asked in the first paragraph above. However, since the theory is still in its infancy, most of the mathematical results so far have been focused on relatively simple or idealized equations, under the strongest assumptions. To tackle more realistic physical models, it is necessary to push the limits of this theory and develope new ideas for extending it.</p> <p>In this project, the mathematical ideas of quantitative homogenization were used to solve some important problems in statistical physics (for so-called gradient lattice models) which had been unsolved for many years. Certain aspects of the mathematical theory were extended from linear to nonlinear equations (a much more difficult case). Finally, ideas from the theory of homogenization led to the development of new algorithms for the practical numerical computation of solutions of the equations. These advances have been written in research articles which are now published in academic journals. In addition, the PI co-wrote a textbook on the topic which will hopefully influence a new generation of researchers.&nbsp;</p> <p>During the award period, the grant also supported the education and research of several PhD students who have since completed their degree. Some have continued their career in academia, and others now apply the expertise they have acquired in industry.&nbsp;</p><br> <p>            Last Modified: 12/06/2020<br>      Modified by: Scott&nbsp;Armstrong</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project was focused on developing new mathematical techniques for understanding physical systems which have complicated small-scale structure but are expected to have simpler properties when viewed from a large ("macroscopic") scale. As an example, one can think of composite materials, which under a microscope may be revealed to be composed of two or more different constituent materials (carbon and silicon, perhaps) which are arranged in some erratic or random way. On large scales, however, one sees a "homogeneous" material with properties which are different from each of the consituents. The question then becomes how to understand or predict the emergent physical properties of the macroscopic material from those of the constituents and geometry of the small-scale mixing. A related question is how "regular" one can expect the macroscopic material to be, in other words, how far do you need to "zoom out" before you see homogenization occur, and what should we expect the error to be in the homogenization approximation?  These kinds of problems are classical in statistical physics, probability theory, and other related disciplines like the theory of fluid dynamics and turbulence. For instance, to understand the magnetism of an iron bar one really has to zoom in to the scale of individual atoms and observe how their spins tend to line up in the same direction. The magnetism which is observed on the macroscopic  is a result of the cumulative behavior of the collective behavior of the individual atoms.  In recent years, a new mathematical theory of quantitative stochastic homogenization has emerged, which describes the way in which partial differential equations (the mathematical description of the physical processes) with random, highly oscillating coefficients (modeling the small scale disorder) behave on large "macroscopic" scales. It is foscused, as its name suggets, on quantitative questions of the exactly the sort asked in the first paragraph above. However, since the theory is still in its infancy, most of the mathematical results so far have been focused on relatively simple or idealized equations, under the strongest assumptions. To tackle more realistic physical models, it is necessary to push the limits of this theory and develope new ideas for extending it.  In this project, the mathematical ideas of quantitative homogenization were used to solve some important problems in statistical physics (for so-called gradient lattice models) which had been unsolved for many years. Certain aspects of the mathematical theory were extended from linear to nonlinear equations (a much more difficult case). Finally, ideas from the theory of homogenization led to the development of new algorithms for the practical numerical computation of solutions of the equations. These advances have been written in research articles which are now published in academic journals. In addition, the PI co-wrote a textbook on the topic which will hopefully influence a new generation of researchers.   During the award period, the grant also supported the education and research of several PhD students who have since completed their degree. Some have continued their career in academia, and others now apply the expertise they have acquired in industry.        Last Modified: 12/06/2020       Submitted by: Scott Armstrong]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
