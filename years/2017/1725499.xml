<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SPX: Collaborative Research: Cross-layer Application-Aware Resilience at Extreme Scale (CAARES)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>266674.00</AwardTotalIntnAmount>
<AwardAmount>266674</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The increasing demands of science and engineering applications push the limits of current large-scale systems, and is expected to achieve exascale (10^18 FLOPS) performance early in the next decade. One of the lesser studied challenge at extreme scales is the reliability of the computing system itself, primarily due to the very large number of cores and components utilized and to the sharp decrease of the Mean Time Between Failures on such systems (in the order of tens of minutes). This project departs from the traditional single component fault management model, and explores how multiple software libraries (and application components) used in the context of a single parallel application can interact to provide the holistic fault management support necessary for parallel applications targeting capability computing. This exploration will not be limited to software developed using a single parallel programming paradigm, but will be extended to encompass the more challenging case where multiple programming paradigms can be combined to achieve a common goal, to simulate a set of large scale scientific applications in use today. &lt;br/&gt; &lt;br/&gt;The goal of this project is to depart from the current siloed resilience mechanisms, and propose cross-layer composition solutions that can fundamentally address these resilience challenges at extreme scales. This exploration will not be limited to software developed using a single parallel programming paradigm, but will be extended to encompass the more challenging case where multiple programming paradigms can be combined to achieve a common goal, to simulate a set of large scale scientific applications in use today. More specifically, this proposal will address the following research challenges: (1) development of a theoretical foundation for a deeper understanding of the challenges and opportunities arising from combining different resilience models and methodologies; (2) design of a flexible programming abstraction to allow different resilience models and mechanisms to be combined to cooperate and address resilience in a more holistic manner; and (3) development of basic, programming paradigm independent, constructs necessary to implement cross-layer and domain-specific approaches to support resilience and to understand related performance / quality trade-offs. The proposed approach will be validated by exposing these generic abstractions in two different programming paradigms (MPI and OpenSHMEM), by creating and developing specialized concepts for each of these paradigms. This will enable the assessment of the validity of the concepts and the corresponding overheads imposed by the different software layers, using few software frameworks and applications.</AbstractNarration>
<MinAmdLetterDate>08/09/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/09/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1725499</AwardID>
<Investigator>
<FirstName>Barbara</FirstName>
<LastName>Chapman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Barbara Chapman</PI_FULL_NAME>
<EmailAddress>barbara.chapman@stonybrook.edu</EmailAddress>
<PI_PHON>6316322351</PI_PHON>
<NSF_ID>000306370</NSF_ID>
<StartDate>08/09/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName>Stony Brook</CityName>
<StateCode>NY</StateCode>
<ZipCode>117940001</ZipCode>
<StreetAddress><![CDATA[WEST 5510 FRK MEL LIB]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>042Y</Code>
<Text>PPoSS-PP of Scalable Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>026Z</Code>
<Text>NSCI: National Strategic Computing Initi</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~266674</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>High performance computing (HPC) applications solve large-scale computational problems in science and engineering. They enable weather prediction, facilitate climate modeling, develop drug therapies for treating COVID-19 patients, and much more.&nbsp; These application codes are often long-running; they may execute for days, weeks or even months to generate the desired results.&nbsp; The parallel programming models that are used to create them enable the application developer to specify that regions of the code may execute in parallel on the nodes of large HPC platforms. As a result of the expression of parallelism in the application code, new kinds of programming errors are possible such as, for example, when two code regions need to be executed in a certain order, but this ordering is not imposed by the program. The errors that are possible will partly depend on the features provided by the parallel programming models used.&nbsp; Thus, specialized tools are needed that can help find bugs arising as the result of incorrect use of the constructs of a given parallel programming model.</p> <p>Moreover, HPC systems may fail due to problems in hardware, software, or a combination of the two. The larger the system, the more frequently failures are to be expected. Hence system failures may potentially interfere with the ability of an HPC application to produce the desired results. To ensure that HPC applications run to completion, resilient applications that are free of programming errors and have the ability to recover from system failure, are needed.&nbsp;</p> <p>This project has developed tools and techniques to facilitate the construction of resilient applications that are based upon OpenSHMEM, a popular vendor-independent parallel programming model for creating HPC applications.</p> <p>It has created a tool to analyze an OpenSHMEM-based application code and identify any occurrences of a set of bugs that may occur as a result of the incorrect use of certain OpenSHMEM features.&nbsp; In order to accomplish this, the project built these features on top of the popular open source LLVM infrastructure.</p> <p>It has also developed techniques to support the use of checkpoint-restart (C/R) in OpenSHMEM programs.&nbsp; Application-level C/R involves periodically saving all or part of the data of an application program during execution so that if the program terminates for any reason, the program can be restarted from the last saved checkpoint position instead of starting again from the beginning. However, using C/R efficiently and effectively can be challenging, as it requires a user to determine what data needs to be saved and where to insert checkpoints into the code. For OpenSHMEM, it is important to insert checkpoints in places where the data Is consistent, which requires some tricky reasoning. To support application developers who wish to make their application codes resilient, the project has also developed CAFTan, a tool that helps create resilient OpenSHMEM application code by providing information to answer these questions and to enable C/R to be incorporated in their application code. The CAFTan code is also open source.</p> <p>Very little prior work had been performed to explore the bugs that may arise as a result of OpenSHMEM&rsquo;s reliance on single-sided communications, or the points in a code at which C/R may be safely invoked.&nbsp; The project identified a set of common bugs, determined how to identify safe points for CR, and shared its findings on these with the OpenSHMEM community. It has therefore contributed to the ability of OpenSHMEM to support the deployment of large-scale HPC applications to advance our knowledge of some critical problems in science.</p> <p>The project also enabled information on OpenSHMEM and its usage to be incorporated in a relevant graduate course. The participating students attended several important events in HPC, including Supercomputing.&nbsp; Moreover, the project enabled participation in two events that aim to increase diversity in the field of Computer Science, the Tapia Celebration of Diversity Conference, and the New York Celebration of Women in Computing.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/15/2021<br>      Modified by: Barbara&nbsp;Chapman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ High performance computing (HPC) applications solve large-scale computational problems in science and engineering. They enable weather prediction, facilitate climate modeling, develop drug therapies for treating COVID-19 patients, and much more.  These application codes are often long-running; they may execute for days, weeks or even months to generate the desired results.  The parallel programming models that are used to create them enable the application developer to specify that regions of the code may execute in parallel on the nodes of large HPC platforms. As a result of the expression of parallelism in the application code, new kinds of programming errors are possible such as, for example, when two code regions need to be executed in a certain order, but this ordering is not imposed by the program. The errors that are possible will partly depend on the features provided by the parallel programming models used.  Thus, specialized tools are needed that can help find bugs arising as the result of incorrect use of the constructs of a given parallel programming model.  Moreover, HPC systems may fail due to problems in hardware, software, or a combination of the two. The larger the system, the more frequently failures are to be expected. Hence system failures may potentially interfere with the ability of an HPC application to produce the desired results. To ensure that HPC applications run to completion, resilient applications that are free of programming errors and have the ability to recover from system failure, are needed.   This project has developed tools and techniques to facilitate the construction of resilient applications that are based upon OpenSHMEM, a popular vendor-independent parallel programming model for creating HPC applications.  It has created a tool to analyze an OpenSHMEM-based application code and identify any occurrences of a set of bugs that may occur as a result of the incorrect use of certain OpenSHMEM features.  In order to accomplish this, the project built these features on top of the popular open source LLVM infrastructure.  It has also developed techniques to support the use of checkpoint-restart (C/R) in OpenSHMEM programs.  Application-level C/R involves periodically saving all or part of the data of an application program during execution so that if the program terminates for any reason, the program can be restarted from the last saved checkpoint position instead of starting again from the beginning. However, using C/R efficiently and effectively can be challenging, as it requires a user to determine what data needs to be saved and where to insert checkpoints into the code. For OpenSHMEM, it is important to insert checkpoints in places where the data Is consistent, which requires some tricky reasoning. To support application developers who wish to make their application codes resilient, the project has also developed CAFTan, a tool that helps create resilient OpenSHMEM application code by providing information to answer these questions and to enable C/R to be incorporated in their application code. The CAFTan code is also open source.  Very little prior work had been performed to explore the bugs that may arise as a result of OpenSHMEM’s reliance on single-sided communications, or the points in a code at which C/R may be safely invoked.  The project identified a set of common bugs, determined how to identify safe points for CR, and shared its findings on these with the OpenSHMEM community. It has therefore contributed to the ability of OpenSHMEM to support the deployment of large-scale HPC applications to advance our knowledge of some critical problems in science.  The project also enabled information on OpenSHMEM and its usage to be incorporated in a relevant graduate course. The participating students attended several important events in HPC, including Supercomputing.  Moreover, the project enabled participation in two events that aim to increase diversity in the field of Computer Science, the Tapia Celebration of Diversity Conference, and the New York Celebration of Women in Computing.          Last Modified: 08/15/2021       Submitted by: Barbara Chapman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
