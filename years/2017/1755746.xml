<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CHS: Bridging the Age-Related Performance Gap: Multimodal Interfaces to Support Older Adults in Transitioning to Manual Control in Autonomous Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Advanced autonomous systems have the potential to significantly reduce workload and extend human capabilities in a number of safety-critical transportation and work environments, such as driving, medicine, and manufacturing.  However, even the most sophisticated systems are often constrained by design limits and/or may experience occasional malfunctions requiring human-in-the-loop manual interventions.  To date, there is no consensus on how best to assist operators of varying age and ability levels in noticing, diagnosing, and recovering manual control across a wide range of autonomous systems.  Adults 65 years and older are now the fastest growing age group, and are expected to encounter systems with increasing levels of automation throughout later stages of life, yet perceptual and cognitive challenges often prevent their effective use of such technology.  The goals of this project are to better understand age-related differences in human-automation interactions, and to begin the development of methods and tools that support the manual recovery of older adults for various automated technologies.  Combined sensory feedback will be explored as a potential technique to these ends, as it has been shown to improve attention management and benefit older individuals.  Project outcomes will contribute to a more in-depth understanding of the capabilities and limitations of different operator demographics, and will help guide the development of next generation human-machine interfaces.  The work has broader implications for enhancing safety in many complex operations, such as autonomous driving and automated process assembly.  Public educational activities will include community and study population (senior) focused workshops, pre-college and summer outreach, and undergraduate research programs for underrepresented students.&lt;br/&gt;&lt;br/&gt;Multimodal interfaces present information to the visual, auditory, and tactile sensory channels.  By manipulating signal parameters, these interfaces are able to capture attention, inform operators of system status, and provide decision aids to perform needed actions.  However, the extent to which this approach can effectively communicate to a range of operators with considerable variability in sensory and cognitive abilities in the context of transfer-of-authority has not been quantified.  Given the rapid development of advanced autonomous technology and the projected population changes expected within the next decade, it will be critical to fill these research gaps.  This project will generate age-related empirical data on complex interactions within autonomous systems.  A series of experiments will be conducted using semi-autonomous driving simulations and involving subjects from different age groups.  The research will quantify age-related time differences in noticing multimodal transition (takeover) requests, determine age-specific transition times as a function of lead time and sensory modality notification, and investigate the effectiveness of various tactile signals to support situation awareness and reduce transition times.  Results are expected to inform quantitative and qualitative models of human perception, information processing, and performance.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/26/2018</MinAmdLetterDate>
<MaxAmdLetterDate>03/26/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1755746</AwardID>
<Investigator>
<FirstName>Brandon</FirstName>
<LastName>Pitts</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brandon Pitts</PI_FULL_NAME>
<EmailAddress>bjpitts@purdue.edu</EmailAddress>
<PI_PHON>7654940062</PI_PHON>
<NSF_ID>000752324</NSF_ID>
<StartDate>03/26/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072023</ZipCode>
<StreetAddress><![CDATA[315 N. Grant Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~175000</FUND_OBLG>
</Award>
</rootTag>
