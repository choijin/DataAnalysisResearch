<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: EAGER: SCIENCE: Systemic Cultivation of Inclusive Equitable Nurturing Classroom Ecology</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>89000.00</AwardTotalIntnAmount>
<AwardAmount>89000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Chia Shen</SignBlockName>
<PO_EMAI>cshen@nsf.gov</PO_EMAI>
<PO_PHON>7032928447</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In this collaborative proposal, a team of human-computer interaction and learning science researchers will collaborate with science education practitioners to develop and study a novel learning genre that aims to promote equity in science education for 4th-9th graders. The research program targets students with visual impairments (VIs), who face many challenges in the education system, especially in science courses. Unlike subjects in the humanities and social sciences, science education relies heavily on visualizations using charts, diagrams, and images, in addition to print materials. Consequently, students with VIs cannot readily access those visualizations and are burdened with misconceptions of science-related constructs. The proposed learning genre addresses this critical need for equitable access by including innovative  multimodal artifacts and a new pedagogical methodology for science education for both sighted and visually impaired students. These multimodal artifacts called Sensables, the innovation at the center of the learning genre, leverage burgeoning technologies and movements such as maker technology and culture, computer vision, and mobile devices. Sensables are 3D printed models that have "hotspots" that respond to a user's touch by playing a media file on a nearby device. These media files can be audio descriptions of the model component, related sounds or images, or even braille annotations. The investigators will study how students learn with these artifacts, and create a web-based sharing and discussion portal, software tools, and instructional resources for teachers to promote broad adoption of the learning genre in the classroom.&lt;br/&gt;&lt;br/&gt;Through iterative design and engineering, evaluation, and data analysis, this interdisciplinary design-based research program will contribute to both the human-computer interaction and learning science fields. The investigators will conduct a single case design study to evaluate and refine the design of Sensables. The project's output includes new curricular materials and a pedagogical methodology for using Sensables in science education. The study will answer the following research questions: (1) What aspects of the Sensables artifacts and pedagogical methodology afford learning? (2) To what extent do Sensables help students learn material compared to current standards? (3) What type of science content are Sensables best suited for? Similarly, what type of content is not appropriate for learning with Sensables? The investigators will develop and disseminate their research outcome to the academic community as well as education and disability professionals to pave the way for broad use and adoption of this learning technology.</AbstractNarration>
<MinAmdLetterDate>08/29/2017</MinAmdLetterDate>
<MaxAmdLetterDate>10/21/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1746128</AwardID>
<Investigator>
<FirstName>Holly</FirstName>
<LastName>Lawson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Holly Lawson</PI_FULL_NAME>
<EmailAddress>holly.lawson@pdx.edu</EmailAddress>
<PI_PHON>5037259900</PI_PHON>
<NSF_ID>000711530</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Portland State University</Name>
<CityName>Portland</CityName>
<CountyName/>
<ZipCode>972070751</ZipCode>
<PhoneNumber>5037259900</PhoneNumber>
<StreetAddress>1600 SW 4th Ave</StreetAddress>
<StreetAddress2><![CDATA[Attn: Sponsored Projects Admin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052226800</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PORTLAND STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052226800</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Portland State University]]></Name>
<CityName/>
<CountyName/>
<StateCode>OR</StateCode>
<ZipCode>972070751</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~89000</FUND_OBLG>
</Award>
</rootTag>
