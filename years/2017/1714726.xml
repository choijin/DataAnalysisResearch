<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Interactions between word learning and visual category development in infancy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>138000.00</AwardTotalIntnAmount>
<AwardAmount>138000</AwardAmount>
<AwardInstrument>
<Value>Fellowship Award</Value>
</AwardInstrument>
<Organization>
<Code>04010000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SMA</Abbreviation>
<LongName>SBE Off Of Multidisciplinary Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Josie S. Welkom</SignBlockName>
<PO_EMAI>jwelkom@nsf.gov</PO_EMAI>
<PO_PHON>7032927376</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award was provided as part of NSF's Social, Behavioral and Economic Sciences Postdoctoral Research Fellowships (SPRF) program. The goal of the SPRF program is to prepare promising, early career doctoral-level scientists for scientific careers in academia, industry or private sector, and government. SPRF awards involve two years of training under the sponsorship of established scientists and encourage Postdoctoral Fellows to perform independent research. NSF seeks to promote the participation of scientists from all segments of the scientific community, including those from underrepresented groups, in its research programs and activities; the postdoctoral period is considered to be an important level of professional development in attaining this goal. Each Postdoctoral Fellow must address important scientific questions that advance their respective disciplinary fields. To learn a concrete noun (e.g., dog), infants must learn how to generalize this word to multiple instances from the same category (e.g., to both golden retrievers and Chihuahuas). How do infants accomplish this feat?  The overarching goal of this project is to broaden our understanding of how infants learn the visual categories that words refer to.  Specifically, this project tests whether novel labels serve as social cues to help infants form more specific representations of new visual categories. To accomplish this, the project will fuse techniques from vision science and word learning to examine the kind of visual information infants map to novel words (vs. novel tones) during short eye-tracking experiments. Furthermore, the project will model infants' behaviors using computational models of word learning. Thus, this project will paint a detailed picture of the visual information that infants map to novel words. The outcome of this proposal could have implications for children with autism spectrum disorders (ASD), who tend to have difficulty processing social cues during word learning. Eventually, performance on these short eye-tracking tasks could serve as assessments for infants at-risk for ASD and as outcome measures in ASD intervention studies. Finally, this project will also create new datasets and tools that will be made publicly available using the Open Science Framework.&lt;br/&gt;&lt;br/&gt;How do infants generalize from individual instances to learn the visual category that a word refers to? Perhaps language plays a role in binding instances together. Prior work suggests that when infants hear a novel label (versus a novel tone), they expect to see objects from a new visual category. However, if infants treat novel labels as strong social cues that they should form an object category, Bayesian models of word learning predict that novel labels should also help infants form a more specific representation of this category. This project tests this hypothesis by combining eye-tracking behavioral experiments, computational models of early visual processing, and Bayesian models of word learning. First, the project will examine if labels help infants form tighter visual representations of novel categories with respect to other, novel objects. Second, the project will examine if labels change the kinds of visual features (e.g., texture vs. 3D form) infants use to represent novel categories, leveraging both texture synthesis models and 3D printing techniques. Third, the project will examine if an optimal model of Bayesian word learning predicts the behavioral results. This project takes a novel approach to studying early word learning by incorporating modern tools from visual perception, and thus makes new connections between the fields of language acquisition and visual cognitive development while furthering our understanding of both.</AbstractNarration>
<MinAmdLetterDate>07/26/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/26/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1714726</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Frank</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael C Frank</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>6507244003</PI_PHON>
<NSF_ID>000179112</NSF_ID>
<StartDate>07/26/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Bria</FirstName>
<LastName>Long</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bria Long</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>6506447235</PI_PHON>
<NSF_ID>000737048</NSF_ID>
<StartDate>07/26/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Long                    Bria</Name>
<CityName>Cambridge</CityName>
<ZipCode>021402214</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM/>
<ORG_LGL_BUS_NAME/>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943052004</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>040Y</Code>
<Text>(SPRF-FR) SBE Postdoctoral Res</Text>
</ProgramElement>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~138000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-f5e1fe3e-7fff-10b3-5243-d5494ba3a6c0"> </span></p> <p dir="ltr"><span>Category learning is a key challenge for early word learning. Infants must learn, for example, that the word &ldquo;dog&rdquo; refers to a category that includes golden retrievers, Chihuahuas, etc., but does not include cows or other four-legged animals (Markman, 1990).&nbsp; How do infants learn the categories that words refer to? This project integrated novel advances in vision science with classic paradigms in developmental psychology to create a set of new experimental methods for evaluating how infants learn these object categories. These advancements include a substantive meta-analysis of the relevant literature (see metalab.stanford.edu), the use of deep neural networks to more carefully manipulate and control differences between visual stimuli presented to infants, and the use of a new, online platform for the recruitment and testing of infants in looking time experiments (see&nbsp;</span><a href="https://lookit.mit.edu/"><span>lookit.mit.edu</span></a><span>). These new methods, made publicly available via online repositories, will enable researchers to more precisely understand the mechanisms that allow infants to map words to novel visual concepts.</span></p> <p>&nbsp;</p> <p dir="ltr"><span>This award has also trained one postdoctoral fellow, Bria Long, who has continued as a postdoctoral fellow at Stanford University. The training has resulted in a suite of new technical competences that have led to the submission of numerous conference proceedings and have significantly advanced her scientific career.</span></p><br> <p>            Last Modified: 12/23/2019<br>      Modified by: Bria&nbsp;Long</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Category learning is a key challenge for early word learning. Infants must learn, for example, that the word "dog" refers to a category that includes golden retrievers, Chihuahuas, etc., but does not include cows or other four-legged animals (Markman, 1990).  How do infants learn the categories that words refer to? This project integrated novel advances in vision science with classic paradigms in developmental psychology to create a set of new experimental methods for evaluating how infants learn these object categories. These advancements include a substantive meta-analysis of the relevant literature (see metalab.stanford.edu), the use of deep neural networks to more carefully manipulate and control differences between visual stimuli presented to infants, and the use of a new, online platform for the recruitment and testing of infants in looking time experiments (see lookit.mit.edu). These new methods, made publicly available via online repositories, will enable researchers to more precisely understand the mechanisms that allow infants to map words to novel visual concepts.    This award has also trained one postdoctoral fellow, Bria Long, who has continued as a postdoctoral fellow at Stanford University. The training has resulted in a suite of new technical competences that have led to the submission of numerous conference proceedings and have significantly advanced her scientific career.       Last Modified: 12/23/2019       Submitted by: Bria Long]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
