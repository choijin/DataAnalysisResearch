<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: SCH: Semi-Supervised Physics-Based Generative Model for Data Augmentation and Cross-Modality Data Reconstruction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2018</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>168698.00</AwardTotalIntnAmount>
<AwardAmount>168698</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Deep learning approaches have been rapidly adopted across a wide range of fields because of their accuracy and flexibility, but require large labeled training sets. This presents a fundamental problem for applications with limited, expensive or private data, such as in healthcare. One example of these applications with the small data challenges is human in-bed pose and pressure estimation. In-bed pose estimation can be a critical part of prevention, prediction, and management of movement-related problems like pressure ulcers. These pressure ulcers often lead to costly and painful conditions such as bedsores. In this research, we propose a semi-supervised generative model based on novel data augmentation and cross-modality data reconstruction techniques to expand the use of powerful deep learning approaches to the in-bed pose and pressure estimation problems. This grant will directly fund the education and mentorship of graduate students involved in researching these problems. In addition, middle school and high school students will be engaged through summer school mentorship programs at Northeastern University.The educational outreach funded by this grant will be used to mentor at schools primarily serving minority student populations. This comprehensive mentorship from middle school to PhD creates a pipeline of experienced students in this important area. The PI actively maintains a diverse research group which includes 50% women and other members of under-represented groups. &lt;br/&gt;&lt;br/&gt;This proposed research explores the use of semi-supervised physics-based generative models to bridge the gap between state-of-the-art deep learning techniques and the small data problem common in personalized healthcare and other data-limited domains. The use of a physics-based approach to generate image data from a low-dimensional parameter space is unique and transformative. This proposal organizes the research to two Thrusts: (I) data augmentation, which synthesizes the large training set required to train a deep learning model to recognize the in-bed pose from an image; and (II) cross-modality data reconstruction, which extracts pose parameters from one image modality to generate data in another image modality. The success of the data augmentation will be measured by using the synthesized image data to train a network, which will be tested against deep and non-deep models trained on publicly-available pose datasets. The accuracy of the pressure image reconstruction will be tested by comparing the results to pressure images taken from a high-resolution pressure sensing mat. The successful completion of this project enables (1) the use of high-accuracy deep learning techniques for robustly recognizing objects and object poses for which articulated 3D models are available or can be generated; and (2) generating highly realistic images of posable figures in one sensory domain using data from another, when one sensory domain is cheaper or easier to gather data in than others.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/31/2018</MinAmdLetterDate>
<MaxAmdLetterDate>05/31/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1755695</AwardID>
<Investigator>
<FirstName>Sarah</FirstName>
<LastName>Ostadabbas</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sarah Ostadabbas</PI_FULL_NAME>
<EmailAddress>ostadabbas@ece.neu.edu</EmailAddress>
<PI_PHON>6173734992</PI_PHON>
<NSF_ID>000704085</NSF_ID>
<StartDate>05/31/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Avenue, 540-177]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~168698</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1"><span class="s1">This research is unfolded around addressing small data relevant problems in the context of human pose estimation by leveraging the existing research and filling in key gaps with original work. We started with introducing a specific human pose estimation problem, in-bed human pose estimation and presented our solutions to this problem in an increasing order of feasibility, that make use of (1) conventional non-deep inference model, (2) fine-tuning already trained deep model, and (3) building and training a pose model from scratch. In order to address the small data challenge in a more general way, we have also focused on pose data augmentation approaches in this research by presenting a pose guided approach to augment existing 2D human figure images while preserving their background. We also introduced a semi-supervised data augmentation approach via the use of 3D graphical engines and tested its effectiveness in training pose inference models against real human pose data. This project has shipped many major activities in my lab, Augmented Cognition Lab (ACLab) at Northeatern University and has led to the training of the first generation of the students at the ACLab. In short, this CRII grant enabled my lab to (1) support the research activities including dissertation/thesis/projects of 2 PhD students, 3 Ms students, 4 undergraduate students, and 3 high school students, (2) publish journal and conference papers in flagship ML/CV conferences including TPAMI, ECCV, MICCAI, MLSP, etc., (3) build and publicly release several much-needed human pose datasets both from synthetic models as well as real human subjects including SLP, ScanAVA, Mannequin RGB/IRS in-bed datasets, (4) be featured in several news outlets based on the outcomes of this project including NU Litmus podcast, Signal Processing Newsletters, News@Northeastern, and Experience Magazine, (5) be invited to give talks and lectures in more than 16 universities/companies/government agencies on the major outcomes of this project, and (6) organize 2021 IEEE Video and Image Processing Cup (VIP Cup) on "Privacy-Preserving In-Bed Human Pose Estimation," based on the outcome of this project.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 06/02/2021<br>      Modified by: Sarah&nbsp;Ostadabbas</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[This research is unfolded around addressing small data relevant problems in the context of human pose estimation by leveraging the existing research and filling in key gaps with original work. We started with introducing a specific human pose estimation problem, in-bed human pose estimation and presented our solutions to this problem in an increasing order of feasibility, that make use of (1) conventional non-deep inference model, (2) fine-tuning already trained deep model, and (3) building and training a pose model from scratch. In order to address the small data challenge in a more general way, we have also focused on pose data augmentation approaches in this research by presenting a pose guided approach to augment existing 2D human figure images while preserving their background. We also introduced a semi-supervised data augmentation approach via the use of 3D graphical engines and tested its effectiveness in training pose inference models against real human pose data. This project has shipped many major activities in my lab, Augmented Cognition Lab (ACLab) at Northeatern University and has led to the training of the first generation of the students at the ACLab. In short, this CRII grant enabled my lab to (1) support the research activities including dissertation/thesis/projects of 2 PhD students, 3 Ms students, 4 undergraduate students, and 3 high school students, (2) publish journal and conference papers in flagship ML/CV conferences including TPAMI, ECCV, MICCAI, MLSP, etc., (3) build and publicly release several much-needed human pose datasets both from synthetic models as well as real human subjects including SLP, ScanAVA, Mannequin RGB/IRS in-bed datasets, (4) be featured in several news outlets based on the outcomes of this project including NU Litmus podcast, Signal Processing Newsletters, News@Northeastern, and Experience Magazine, (5) be invited to give talks and lectures in more than 16 universities/companies/government agencies on the major outcomes of this project, and (6) organize 2021 IEEE Video and Image Processing Cup (VIP Cup) on "Privacy-Preserving In-Bed Human Pose Estimation," based on the outcome of this project.          Last Modified: 06/02/2021       Submitted by: Sarah Ostadabbas]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
