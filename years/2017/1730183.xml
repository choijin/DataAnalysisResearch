<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRI II-NEW: IIS: Omniview Multi-modal Sensor Laboratory for Understanding Human Interactions in Ubiquitous Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>746916.00</AwardTotalIntnAmount>
<AwardAmount>746916</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Understanding how people interact with objects and with each other is an important research area in human-computer interaction, particularly in contexts where phones, cameras, sensors, voice assistants, robots, and other computing devices help people accomplish their goals.  To study these interactions, this project will equip a lab with state of the art equipment for capturing human activity that doesn't require attaching markers, wires, or sensors to people, and develop software to manage the large amounts of captured data and interfaces that help researchers and designers make use of the data.  Much of the envisioned fundamental research will focus on how age, gender, physical ability, and experience level affect the way people interact with objects, as well as on using social cues such as emotions, inter-person distances, and gestures to understand how people interact with each other.  A number of researchers at the lead investigators' institution will use the lab for related projects around people- and object-aware technologies, including assistive robotics, self-driving vehicles, teams and collaboration, and smart environments.  The lab will also provide training for a postdoctoral researcher and research opportunities for undergraduates, support a number of courses taught at the PIs' institution, and provide new opportunities for interdisciplinary research.&lt;br/&gt;&lt;br/&gt;The PIs will develop a temporally synchronized and spatially calibrated sensor system that includes force plates, microphones, RGB and infrared cameras, and Kinect sensors, and deploy it in 20x20x12 foot lab.  Data will be synchronized using linear time codes (LTCs), including custom hardware previously developed by the PIs to add LTC data to Kinects, and managed by a large cluster of computers and network attached storage devices.  The infrastructure will use computer vision and sound reconstruction algorithms on the raw sensor data to reconstruct 3D spatiotemporal data that provides a full range 3D visualization of human interactions.  By combining data from multiple sensor modalities in 3D, the infrastructure enables research in strengthening recognition of gestures and emotions of people engaged in interactions by analysis of prosody changes, face points, body skeletons, spatiotemporal motions, linguistics, heat signatures, and emotion- or task-driven physical impact.  Further, the PIs will develop large repositories of omniview multi-modal 3D spatiotemporal data, and conduct research on tying these repositories to sensors on next-generation ubiquitous devices to make them people- and object-aware.</AbstractNarration>
<MinAmdLetterDate>04/28/2017</MinAmdLetterDate>
<MaxAmdLetterDate>04/28/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1730183</AwardID>
<Investigator>
<FirstName>Sean</FirstName>
<LastName>Banerjee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sean Banerjee</PI_FULL_NAME>
<EmailAddress>sbanerje@clarkson.edu</EmailAddress>
<PI_PHON>3152686510</PI_PHON>
<NSF_ID>000703063</NSF_ID>
<StartDate>04/28/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Natasha</FirstName>
<LastName>Banerjee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Natasha Banerjee</PI_FULL_NAME>
<EmailAddress>nbanerje@clarkson.edu</EmailAddress>
<PI_PHON>3152683831</PI_PHON>
<NSF_ID>000703066</NSF_ID>
<StartDate>04/28/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Clarkson University</Name>
<CityName>Potsdam</CityName>
<CountyName>ST LAWRENCE</CountyName>
<ZipCode>136761401</ZipCode>
<PhoneNumber>3152686475</PhoneNumber>
<StreetAddress>8 Clarkson Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>21</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY21</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041590993</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CLARKSON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041590993</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Clarkson University]]></Name>
<CityName>Potsdam</CityName>
<CountyName>ST LAWRENCE</CountyName>
<StateCode>NY</StateCode>
<ZipCode>136761401</ZipCode>
<StreetAddress><![CDATA[8 Clarkson Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>21</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY21</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~746916</FUND_OBLG>
</Award>
</rootTag>
