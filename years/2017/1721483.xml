<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  A tool for estimating objective outcome measures in clinical speech applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2017</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nancy Kamei</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of the Small Business Innovation Research (SBIR) Phase I project is to make uniformly high quality practice by Speech-Language Pathologists (SLPs) accessible to non-ambulatory and underserved rural populations. Because the inability to engage in spoken communication is among the most debilitating of all human conditions, poor access to high quality speech-language pathology services is an important societal issue. It creates significant health disparities affecting not only the quality of peoples' lives but also the economics of their communities. Because speech-language pathology treatment is highly behavioral and intensive, any proposed solution must improve both the performance and productivity of individual SLPs. To provide the necessary scalability required for a nation-wide problem, any implementation must include networked mobile tools as well as a strong algorithmic foundation that automatically generates objective, reliable, and sensitive outcome measures. The project has the potential for significant commercial impact. There are currently 160K SLPs in the US and that number expected to exceed 240K by 2024. Following a software-as-a-service model where clinicians freely download software to their mobile device but need active a subscription to access outcome ratings, projects to a total clinical market of between $20M and $100M.&lt;br/&gt;&lt;br/&gt;The proposed project addresses the strong demand for the development of dependent objective measures of pathological speech that exists in a variety of clinical settings. Currently, perceptual (subjective) ratings of speech conducted by clinicians are the gold standard for evaluating speech improvement or decline. While it is acknowledged that subjective ratings have poor validity and reliability, objective measures have not been readily available. This project takes a novel intellectual approach to the problem by building machine-learning algorithms that objectively model experts' subjective ratings, but with levels of reliability that far exceed that of clinicians. The computational engine takes as an input a set of speech samples from a speaker and automatically evaluates the speech along clinically-standard perceptual dimensions. This yields outputs that are immediately clinical interpretable, thereby exceeding the value of norm-based objective outcomes. The project goals are, (i) to refine and extend existing technology for the evaluation of pathological speech; and (ii) to rigorously evaluate its performance and utility using beta testing. Statistical analyses will determine whether the model outperforms the human ratings with respect to reliability and sensitivity, as has been the case in pilot tests.</AbstractNarration>
<MinAmdLetterDate>07/10/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/10/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1721483</AwardID>
<Investigator>
<FirstName>Harry</FirstName>
<LastName>Schmitt</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Harry Schmitt</PI_FULL_NAME>
<EmailAddress>harry.schmitt@auralanalytics.com</EmailAddress>
<PI_PHON>5203067639</PI_PHON>
<NSF_ID>000693555</NSF_ID>
<StartDate>07/10/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Aural Analytics</Name>
<CityName>tempe</CityName>
<ZipCode>852870102</ZipCode>
<PhoneNumber>4803297528</PhoneNumber>
<StreetAddress>975 S. MYRTLE AVE. COOR 3472</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079590679</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AURAL ANALYTICS LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[SkySong]]></Name>
<CityName>Scottsdale</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852875706</ZipCode>
<StreetAddress><![CDATA[1475 N Scottsdale Rd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8042</Code>
<Text>Health and Safety</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Aural Analytics' mission is to be the recognized leader in brain health monitoring by providing clinical decision makers with remote, interpretable, and actionable insight regarding the neurological health of their patients. Our unique combination of technical and clinical expertise, access to key opinion leaders, existing traction in this space and commitment to using science to yield benefits for patients makes us uniquely qualified to execute on our vision. Our focus is on the design, development and implementation of objective measures of brain health. Speech can provide an unparalleled look into neurological health. Our proprietary technology algorithmically evaluates a speech signal along a number of perceptual dimensions that directly impact intelligibility and produces a set of objective outcome measures that allow clinicians to make data-informed decisions about the initiation, continuation, adaptation or termination of a given treatment protocol. This framework is mature and customizable to different applications. Our Phase I project focused on adapting our analytics framework to develop new speech evaluation tools for the speech of individuals with neurological disorders.</p> <p>Intellectual Merit: Speech production is deceptively complex. To translate our thoughts ideas into strings of words, we activate complex neural circuits involving cortical and subcortical pathways, to select and sequence the words that best convey our ideas. Only then does the brain send signals to the various muscle groups involved in speech production. The speaker first takes a breath and the column of exhaled air sets our vocal folds into vibration, which chops up the airstream to produce the sound of the voice. This excited airstream is then filtered through the rest of the vocal tract, and is modulated by movements of our articulators that change the shape of our oral and nasal cavities. If there is a disturbance to any of the neural circuits that control this process, the result can be detected in the speech signal. We develop technology that extracts this clinically-relevant information from the speech signal and provides clinicians with information regarding the integrity of the various subsystems involved in speech production. To do this, we have developed an advanced AI engine to monitor clinically relevant changes in speech that have application in both clinical practice (speech language pathology and neurology) and as endpoints in clinical trials for pharmaceutical companies.</p> <p>Program Outcome: Our existing automated speech rating engine has shown impressive laboratory performance using a model with only five speech metrics - severity, articulatory precision, nasality, vocal quality, and prosody. Our first Phase I objective was to extend this model to include new speech measures to enable more sensitive therapeutic tracking of patient progress and make our technology more broadly applicable. Our approach for accomplishing these goals was to choose additional metrics that both deepen the granularity of information available to the clinician and provide additional relevant information on the physiological systems involved in speech production. Our expanded model now extracts multiple clinically-interpretable features that provide direct insight into the integrity of the various subsystems used in speech production, such as respiration, vocal fold vibration and muscle movement in lips, jaw, velum, and face. We evaluated our algorithms using data collected in a collaboration with Barrow Neurological Institute in their ALS@Home study. We were able to show that (1) our new speech metrics were able to separate patients with ALS from a control group and (2) our metrics were more sensitive to change than the ALS-FRS.</p> <p>Our second Phase I objective was to create a seamless way of collecting speech samples from participants without bringing them physically into the clinic. We are approaching this goal by developing a mobile application that is deployed to the patient&rsquo;s hand-held device to collect customized speech samples based on the study and its requirements. We have a prototype application that has the ability to fill this need. The application has a front end that a clinician can use to perform various speech collection tasks using an easy-to-use and intuitive interface while connecting to a robust back end running our speech analytics engine. In Phase I we developed and exhaustively tested an Application Programming Interface (API) to facilitate communication between our mobile application and analytics engine.&nbsp; This is a key component for achieving the real-time performance ultimately required for clinical applications</p> <p>Broader Impact: Because the inability to engage in spoken communication is among the most debilitating of all human conditions, poor access to high quality treatment options is an important societal issue. It creates significant health disparities affecting not only the quality of peoples&rsquo; lives but also the economics of their communities. Because speech-language pathology treatment is highly behavioral and intensive, any proposed solution must improve both the performance and productivity of individual clinicians. Our Phase I program has convincing demonstrated one approach that has sufficient accuracy and the scalability required to begin to address this critical need.</p><br> <p>            Last Modified: 07/22/2018<br>      Modified by: Harry&nbsp;Schmitt</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Aural Analytics' mission is to be the recognized leader in brain health monitoring by providing clinical decision makers with remote, interpretable, and actionable insight regarding the neurological health of their patients. Our unique combination of technical and clinical expertise, access to key opinion leaders, existing traction in this space and commitment to using science to yield benefits for patients makes us uniquely qualified to execute on our vision. Our focus is on the design, development and implementation of objective measures of brain health. Speech can provide an unparalleled look into neurological health. Our proprietary technology algorithmically evaluates a speech signal along a number of perceptual dimensions that directly impact intelligibility and produces a set of objective outcome measures that allow clinicians to make data-informed decisions about the initiation, continuation, adaptation or termination of a given treatment protocol. This framework is mature and customizable to different applications. Our Phase I project focused on adapting our analytics framework to develop new speech evaluation tools for the speech of individuals with neurological disorders.  Intellectual Merit: Speech production is deceptively complex. To translate our thoughts ideas into strings of words, we activate complex neural circuits involving cortical and subcortical pathways, to select and sequence the words that best convey our ideas. Only then does the brain send signals to the various muscle groups involved in speech production. The speaker first takes a breath and the column of exhaled air sets our vocal folds into vibration, which chops up the airstream to produce the sound of the voice. This excited airstream is then filtered through the rest of the vocal tract, and is modulated by movements of our articulators that change the shape of our oral and nasal cavities. If there is a disturbance to any of the neural circuits that control this process, the result can be detected in the speech signal. We develop technology that extracts this clinically-relevant information from the speech signal and provides clinicians with information regarding the integrity of the various subsystems involved in speech production. To do this, we have developed an advanced AI engine to monitor clinically relevant changes in speech that have application in both clinical practice (speech language pathology and neurology) and as endpoints in clinical trials for pharmaceutical companies.  Program Outcome: Our existing automated speech rating engine has shown impressive laboratory performance using a model with only five speech metrics - severity, articulatory precision, nasality, vocal quality, and prosody. Our first Phase I objective was to extend this model to include new speech measures to enable more sensitive therapeutic tracking of patient progress and make our technology more broadly applicable. Our approach for accomplishing these goals was to choose additional metrics that both deepen the granularity of information available to the clinician and provide additional relevant information on the physiological systems involved in speech production. Our expanded model now extracts multiple clinically-interpretable features that provide direct insight into the integrity of the various subsystems used in speech production, such as respiration, vocal fold vibration and muscle movement in lips, jaw, velum, and face. We evaluated our algorithms using data collected in a collaboration with Barrow Neurological Institute in their ALS@Home study. We were able to show that (1) our new speech metrics were able to separate patients with ALS from a control group and (2) our metrics were more sensitive to change than the ALS-FRS.  Our second Phase I objective was to create a seamless way of collecting speech samples from participants without bringing them physically into the clinic. We are approaching this goal by developing a mobile application that is deployed to the patient?s hand-held device to collect customized speech samples based on the study and its requirements. We have a prototype application that has the ability to fill this need. The application has a front end that a clinician can use to perform various speech collection tasks using an easy-to-use and intuitive interface while connecting to a robust back end running our speech analytics engine. In Phase I we developed and exhaustively tested an Application Programming Interface (API) to facilitate communication between our mobile application and analytics engine.  This is a key component for achieving the real-time performance ultimately required for clinical applications  Broader Impact: Because the inability to engage in spoken communication is among the most debilitating of all human conditions, poor access to high quality treatment options is an important societal issue. It creates significant health disparities affecting not only the quality of peoples? lives but also the economics of their communities. Because speech-language pathology treatment is highly behavioral and intensive, any proposed solution must improve both the performance and productivity of individual clinicians. Our Phase I program has convincing demonstrated one approach that has sufficient accuracy and the scalability required to begin to address this critical need.       Last Modified: 07/22/2018       Submitted by: Harry Schmitt]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
