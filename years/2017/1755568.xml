<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: RI: Lyapunov-Certified Cognitive Control for Safe Autonomous Navigation in Unknown Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>173130.00</AwardTotalIntnAmount>
<AwardAmount>173130</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Erion Plaku</SignBlockName>
<PO_EMAI>eplaku@nsf.gov</PO_EMAI>
<PO_PHON>7032928695</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Applications for unmanned aerial and ground vehicles requiring autonomous navigation in unknown, cluttered, and dynamically changing environments are increasing in fields such as transportation, delivery, agriculture, environmental monitoring, and construction. To achieve safe, resilient, and self-improving autonomous navigation, this project focuses on the design of adaptive online environment understanding that guarantees stable and collision-free operation in challenging conditions. The proposed research is important because current practices rely on prior maps or hand-crafted online mapping that attempt to capture the whole environment, even if parts are irrelevant for specific navigation tasks. This increases memory and computation requirements, spreads the effects of noise, and makes current approaches brittle, particularly in conditions involving dynamic obstacles, unreliable localization, or illumination variation.&lt;br/&gt;&lt;br/&gt;The proposal offers two technical innovations to achieve safe autonomous navigation. First, it develops a learnable neural map based on 3-D convolution over hierarchical (octree) partitioning of space to extract navigation-specific features and on differentiable memory to infer long-term dependence among the features. The neural map parameters are trained from navigation experience not to produce accurate maps but to quantify the collision probabilities of intended motion trajectories accurately. The second innovation is a Lyapunov-theoretic control approach that uses the total energy of an autonomous system with respect to a virtual kinematic system (that can stop immediately) to derive conditions that guarantee stable and collision-free tracking of the trajectories proposed by the neural network. The proposed learnable neural map significantly increases the robustness of collision prediction, while the Lyapunov-theoretic control guarantees stable and safe navigation in new, unpredictable, and cluttered environments.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/25/2018</MinAmdLetterDate>
<MaxAmdLetterDate>04/25/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1755568</AwardID>
<Investigator>
<FirstName>Nikolay</FirstName>
<LastName>Atanasov</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nikolay A Atanasov</PI_FULL_NAME>
<EmailAddress>natanasov@ucsd.edu</EmailAddress>
<PI_PHON>8585344105</PI_PHON>
<NSF_ID>000739678</NSF_ID>
<StartDate>04/25/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress><![CDATA[9500 Gilman Drive MC 0436]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~173130</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed techniques for safe autonomous robot navigation in unknown environments. Specifying safety constraints for autonomous navigation by hand, in terms of a mathematical cost function, is very challenging due to the various conditions that need to be captured. The project developed inverse reinforcement learning techniques that allow learning such cost functions from expert demonstrations. An expert is an experienced human user or an optimized algorithm that can demonstrate safe navigation and implicitly satisfy the safety constraints. The contributions of the project include an online mapping approach that recognizes semantically meaningful regions (road lanes, sidewalks, buildings), a cost model that associates these regions with navigation costs, and a model of the expert user's behavior that allows approximating the costs from the expert demonstrations. Once optimized, these models allow planning autonomous robot behavior in previously unseen environments by estimating the semantics, predicting the navigation costs, and generating a navigation plan that minimizes the costs. To ensure that the planned behavior is actually executed safely, our work also proposed techniques for closed-loop robot control with theoretical safety and stability guarantees. We defined a notion of local safety, called dynamic safety margin, based on the system's kinetic energy (related to the speed of motion), potential energy (related to the distance from the desired trajectory), and distance to obstacles. We designed an adaptive controller for trajectory tracking, whose tracking speed is determined by the size of the dynamic safety margin. For example, if the dynamic safety margin is large, the system is safe and can move quickly, while if the dynamic safety margin is small, the system may be in danger of collision and may need to stop. Assuming that obstacles are detected reliably, our work shows theoretically that the adaptive controller guarantees system stability and safety. These techniques were demonstrated in the CARLA Autonomous Driving simulator to achieve autonomous lane following from demonstration as well as in physical experiments with a small wheeled autonomous robot. The outcomes of this project have the potential to allow humans to demonstrate desirable operation by example and improve the safety of autonomous systems in transportation and delivery services.<br /><br />The project provided training and professional development opportunities to two PhD students and eleven undergraduate students in the ECE department at UC San Diego. The PhD students contributed to the research activities in inverse reinforcement learning and system control with safety and stability guarantees. The project allowed the PhD students to participate in and present their work at premier conferences on robotics (ICRA) and control (L4DC) and to prepare journal articles for the International Journal of Robotics Research (IJRR) and Automatica. The project enabled outreach and research initiation activities for undergraduate students through several programs at UC San Diego: the Regents Scholar Research Initiative (RSRI), the ENLACE bi-national summer research program, the Summer Training Academy for Research Success (STARS) program, and the International Summer Research Program (ISRP), and the ECE department's Summer Research Internship Program (SRIP). The undergraduate students learned about the theory of fundamental algorithms for localization, mapping, planning, and control in robotics and worked on implementing particle-filter localization, occupancy grid mapping, and graph-search motion planning using a simulated racecar robot equipped with lidar and camera sensors in a PyBullet simulation environment.</p><br> <p>            Last Modified: 01/31/2021<br>      Modified by: Nikolay&nbsp;A&nbsp;Atanasov</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1755568/1755568_10540875_1612153487292_InverseNavigationCostLearning--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1755568/1755568_10540875_1612153487292_InverseNavigationCostLearning--rgov-800width.jpg" title="Learning Navigation Costs from Demonstrations with Semantic Observations"><img src="/por/images/Reports/POR/2021/1755568/1755568_10540875_1612153487292_InverseNavigationCostLearning--rgov-66x44.jpg" alt="Learning Navigation Costs from Demonstrations with Semantic Observations"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our work enables online construction of a semantic map (top right) from distance and semantic segmentation measurements, estimation of a cost function (bottom right) that explains demonstrated expert navigation behavior and generation of autonomous navigation in new operational conditions.</div> <div class="imageCredit">T. Wang, V. Dhiman, N. Atanasov, "Learning Navigation Costs from Demonstrations with Semantic Observations," Learning for Dynamics and Control (L4DC), 2020.</div> <div class="imageSubmitted">Nikolay&nbsp;A&nbsp;Atanasov</div> <div class="imageTitle">Learning Navigation Costs from Demonstrations with Semantic Observations</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1755568/1755568_10540875_1612153884865_SafeControl--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1755568/1755568_10540875_1612153884865_SafeControl--rgov-800width.jpg" title="Safe and Stable Trajectory Tracking with Locally Sensed Constraints"><img src="/por/images/Reports/POR/2021/1755568/1755568_10540875_1612153884865_SafeControl--rgov-66x44.jpg" alt="Safe and Stable Trajectory Tracking with Locally Sensed Constraints"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An adaptive controller guarantees safety and stability based on the difference between the reachable set (yellow) and the nearest obstacles (gray) for an autonomous Ackerman-drive vehicle, navigating in an unknown environment and measuring distances (red) to the obstacles via a LiDAR sensor.</div> <div class="imageCredit">Z. Li, O. Arslan, N. Atanasov, "Fast and Safe Path-Following Control using a State-Dependent Directional Metric," IEEE International Conference on Robotics and Automation (ICRA), 2020.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Nikolay&nbsp;A&nbsp;Atanasov</div> <div class="imageTitle">Safe and Stable Trajectory Tracking with Locally Sensed Constraints</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed techniques for safe autonomous robot navigation in unknown environments. Specifying safety constraints for autonomous navigation by hand, in terms of a mathematical cost function, is very challenging due to the various conditions that need to be captured. The project developed inverse reinforcement learning techniques that allow learning such cost functions from expert demonstrations. An expert is an experienced human user or an optimized algorithm that can demonstrate safe navigation and implicitly satisfy the safety constraints. The contributions of the project include an online mapping approach that recognizes semantically meaningful regions (road lanes, sidewalks, buildings), a cost model that associates these regions with navigation costs, and a model of the expert user's behavior that allows approximating the costs from the expert demonstrations. Once optimized, these models allow planning autonomous robot behavior in previously unseen environments by estimating the semantics, predicting the navigation costs, and generating a navigation plan that minimizes the costs. To ensure that the planned behavior is actually executed safely, our work also proposed techniques for closed-loop robot control with theoretical safety and stability guarantees. We defined a notion of local safety, called dynamic safety margin, based on the system's kinetic energy (related to the speed of motion), potential energy (related to the distance from the desired trajectory), and distance to obstacles. We designed an adaptive controller for trajectory tracking, whose tracking speed is determined by the size of the dynamic safety margin. For example, if the dynamic safety margin is large, the system is safe and can move quickly, while if the dynamic safety margin is small, the system may be in danger of collision and may need to stop. Assuming that obstacles are detected reliably, our work shows theoretically that the adaptive controller guarantees system stability and safety. These techniques were demonstrated in the CARLA Autonomous Driving simulator to achieve autonomous lane following from demonstration as well as in physical experiments with a small wheeled autonomous robot. The outcomes of this project have the potential to allow humans to demonstrate desirable operation by example and improve the safety of autonomous systems in transportation and delivery services.  The project provided training and professional development opportunities to two PhD students and eleven undergraduate students in the ECE department at UC San Diego. The PhD students contributed to the research activities in inverse reinforcement learning and system control with safety and stability guarantees. The project allowed the PhD students to participate in and present their work at premier conferences on robotics (ICRA) and control (L4DC) and to prepare journal articles for the International Journal of Robotics Research (IJRR) and Automatica. The project enabled outreach and research initiation activities for undergraduate students through several programs at UC San Diego: the Regents Scholar Research Initiative (RSRI), the ENLACE bi-national summer research program, the Summer Training Academy for Research Success (STARS) program, and the International Summer Research Program (ISRP), and the ECE department's Summer Research Internship Program (SRIP). The undergraduate students learned about the theory of fundamental algorithms for localization, mapping, planning, and control in robotics and worked on implementing particle-filter localization, occupancy grid mapping, and graph-search motion planning using a simulated racecar robot equipped with lidar and camera sensors in a PyBullet simulation environment.       Last Modified: 01/31/2021       Submitted by: Nikolay A Atanasov]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
