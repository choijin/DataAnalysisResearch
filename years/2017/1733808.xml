<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AitF: Collaborative Research: Fast, Accurate, and Practical: Adaptive Sublinear Algorithms for Scalable Visualization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>232999.00</AwardTotalIntnAmount>
<AwardAmount>232999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Brass</SignBlockName>
<PO_EMAI>pbrass@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>With the wealth of data being generated in every sphere of human endeavor, data exploration--analyzing, understanding, and extracting value from data--has become absolutely vital. Data visualization is by far the most common data exploration mechanism, used by novice and expert data analysts alike. Yet data visualization on increasingly larger datasets remains difficult: even simple visualizations of a large dataset can be slow and non-interactive,  while visualizations of a sampled fraction of a dataset can mislead an analyst. &lt;br/&gt;&lt;br/&gt;The project aims to develop FastViz, a scalable visualization engine, that will not only enable visualization on datasets that are orders of magnitude larger in the same time, but also ensure the resulting visualizations satisfy key properties essential for correct analysis by end-users. To ensure immediate utilization, FastViz will be applied to three real-world application domains: battery science, advertising analysis, and genomic data analysis, and implemented in Zenvisage, an open-source visual exploration platform developed by the PIs.  Students in the project gain invaluable experience in combining the algorithmic and systems considerations that enable data exploration. &lt;br/&gt;&lt;br/&gt;FastViz's development is driven by simultaneous investigation of systems considerations, such as indexing and storage techniques that enable various forms of online sampling, and algorithmic considerations for &lt;br/&gt;(a) visualization generation, where the goal is to produce incrementally improving visualizations in which the important features are displayed first, and &lt;br/&gt;(b) visualization selection, where the goal is to select, from a collection of as yet not generated visualizations, those that that satisfy desired criteria. &lt;br/&gt;On the systems front, FastViz will leverage and contribute back to recent developments on online sampling systems that enable the use of more powerful sampling modalities.  &lt;br/&gt;On the algorithms front, FastViz will draw ideas from testing, distribution learning, and sublinear algorithms literature that, to the best knowledge of the PIs, have not been adapted in practice.  The algorithms developed will obey optimality guarantees, and wherever possible, instance-optimality guarantees, ensuring that they will adapt to data characteristics in the most efficient way possible.  &lt;br/&gt;&lt;br/&gt;The project will lead to a better understanding of the interplay between sampling algorithms development and systems design, facilitating the adoption of more realistic models and algorithms on the one hand, and the development of more powerful sampling engines that enable the models required within the algorithms.</AbstractNarration>
<MinAmdLetterDate>09/08/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/08/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1733808</AwardID>
<Investigator>
<FirstName>Ronitt</FirstName>
<LastName>Rubinfeld</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ronitt Rubinfeld</PI_FULL_NAME>
<EmailAddress>ronitt@csail.mit.edu</EmailAddress>
<PI_PHON>6172530884</PI_PHON>
<NSF_ID>000322655</NSF_ID>
<StartDate>09/08/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394307</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7239</Code>
<Text>Algorithms in the Field</Text>
</ProgramElement>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~232999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project investigates statistical bounds that can be achieved in a data-dependent way. Provably correct bounds used in existing systems are dataindependent, and thus have to work even in extreme cases, such as when half of the data-points are at the min range value and half are at the max. This means that they are typically much wider than necessary, and will thus result in unnecessarily long query latencies in most cases. This project explores the development of confidence bounds that can take advantage of data characteristics for early&nbsp; termination.&nbsp;&nbsp; This project has designed an algorithm for mean estimation&nbsp; that beats standard methods in non-worst case settings.&nbsp;</p> <p>A second direction explored by this project is to find techniques for developing differentially private testing of distributions over large domains. Previously algorithms had been designed for fundamental problems of statistics, such as identity testing and two-sample testing, over large discrete domains, which require a number of samples that is sublinear in the size of the domain. The question studied in this project is whether it is possible to achieve these surprising bounds, while still guaranteeing differential privacy to the individuals of the population. Work on this project has developed testers that nearly maintain the sample efficiency of the previous testers while additionally guaranteeing such privacy.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p> <p>A third direction explored by this project is to find&nbsp; algorithms for understanding the shape of a distributions.&nbsp;&nbsp; Understanding the shape of a distribution of data is of&nbsp; interest to people in a great variety of fields, as it may affect the types of algorithms used for that data. Given samples from a distribution, a user often needs to understand how many elements appear infrequently, that is, to characterize the tail of the distribution.&nbsp; This project develops an algorithm that distinguishes heavy-tailed distributions from&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; non-heavy-tailed ones.&nbsp;</p><br> <p>            Last Modified: 01/06/2021<br>      Modified by: Ronitt&nbsp;Rubinfeld</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project investigates statistical bounds that can be achieved in a data-dependent way. Provably correct bounds used in existing systems are dataindependent, and thus have to work even in extreme cases, such as when half of the data-points are at the min range value and half are at the max. This means that they are typically much wider than necessary, and will thus result in unnecessarily long query latencies in most cases. This project explores the development of confidence bounds that can take advantage of data characteristics for early  termination.   This project has designed an algorithm for mean estimation  that beats standard methods in non-worst case settings.   A second direction explored by this project is to find techniques for developing differentially private testing of distributions over large domains. Previously algorithms had been designed for fundamental problems of statistics, such as identity testing and two-sample testing, over large discrete domains, which require a number of samples that is sublinear in the size of the domain. The question studied in this project is whether it is possible to achieve these surprising bounds, while still guaranteeing differential privacy to the individuals of the population. Work on this project has developed testers that nearly maintain the sample efficiency of the previous testers while additionally guaranteeing such privacy.                                                                                         A third direction explored by this project is to find  algorithms for understanding the shape of a distributions.   Understanding the shape of a distribution of data is of  interest to people in a great variety of fields, as it may affect the types of algorithms used for that data. Given samples from a distribution, a user often needs to understand how many elements appear infrequently, that is, to characterize the tail of the distribution.  This project develops an algorithm that distinguishes heavy-tailed distributions from          non-heavy-tailed ones.        Last Modified: 01/06/2021       Submitted by: Ronitt Rubinfeld]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
