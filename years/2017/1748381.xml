<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Workshop on Trustworthy Algorithmic Decision-Making</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>93909.00</AwardTotalIntnAmount>
<AwardAmount>93909</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dan Cosley</SignBlockName>
<PO_EMAI>dcosley@nsf.gov</PO_EMAI>
<PO_PHON>7032928832</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Algorithms are increasingly being used in systems that make decisions that affect people, including filtering news and updates we see, setting prices for items, scoring resumes and credit applications, recommending routes and places, and controlling smart homes and autonomous cars.  As algorithms make these decisions, it is natural to ask whether, when, and why we should trust them, and to consider ways to improve their trustworthiness.  To this end, researchers, regulators, and industry have increasingly called for methods to audit and account for algorithmic decisions to ensure their transparency and fairness.  This project's goal is to integrate these perspectives, bringing together people who design and study these algorithms for a two-day workshop to lay out the problem space and possible ways forward for algorithmic trustworthiness.  The workshop organizers will emphasize diversity of perspectives, recruiting participants from a wide variety of disciplines, jobs, and backgrounds with a particular focus on including people from underrepresented groups in computing and PhD students. &lt;br/&gt;&lt;br/&gt;The focus will be on developing interdisciplinary and convergent perspectives on algorithmic decision-making by bringing together researchers, designers, and policy-makers working on different aspects of the problem and different domains, with the goal of integrating their ideas to get a bigger picture of the larger question of trustworthiness of these algorithms in society.  The main output will be a report describing the problem space of trustworthy algorithmic decision-making, outlining the major issues that need research to move these algorithms and the decisions they make toward being trustworthy, and identifying promising opportunities and approaches for studying these issues. It will also identify some of the major challenges and constraints that will make progress on these issues difficult, and will further the discussion of moving past these challenges.  In addition to the report, the participants will produce a set of whitepapers that will illuminate important aspects of this problem, along with responses and additional reflections by attendees.</AbstractNarration>
<MinAmdLetterDate>08/02/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1748381</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Wash</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard Wash</PI_FULL_NAME>
<EmailAddress>wash@msu.edu</EmailAddress>
<PI_PHON>5173555040</PI_PHON>
<NSF_ID>000575042</NSF_ID>
<StartDate>08/02/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Emilee</FirstName>
<LastName>Rader</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emilee J Rader</PI_FULL_NAME>
<EmailAddress>emilee@msu.edu</EmailAddress>
<PI_PHON>5173558372</PI_PHON>
<NSF_ID>000580969</NSF_ID>
<StartDate>08/02/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName>East Lansing</CityName>
<StateCode>MI</StateCode>
<ZipCode>488242600</ZipCode>
<StreetAddress><![CDATA[404 Wilson Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~93909</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Computer-based algorithms are increasingly being used in systems that automatically make important decisions on behalf of people, including determining what news people see online, controlling speed and steering of cars, choosing prices for goods and services, filtering job applicants, recognizing and categorizing airport travelers, and making sentencing recommendations for people convicted of crimes. As these algorithms simultaneously become more common and more complicated, it is important to understand whether they can be trusted to make decisions like these, what makes algorithms trustworthy, and how algorithms can be made more trustworthy.</p> <p>Fundamentally, these algorithms operate in a complicated socio-technical context that includes the designers of the algorithms, the data used as an input to the algorithms, the interface that presents and uses the outputs, the people who make choices about goals of algorithms and when to use algorithms, and societal laws and norms that influence their use. All aspects of this context influence the outputs of the algorithms, and also impact whether they are worthy of being trusted to make important decisions.</p> <p>A group of researchers, practitioners, and policy-makers convened at a workshop on December 4&ndash;5, 2017 in Arlington, VA to discuss these issues. The group identified five challenges that future research needs to focus on to help algorithms be more trustworthy:</p> <p>1. People, processes, and training: Who defines and how do we ensure good practice in data science and machine learning? What are the avenues for education? What are the appropriate tools for ensuring good practice in machine learning and algorithm development?</p> <p>2. Evidence, accountability, and oversight: How do we integratively assess the impact of an algorithmic system on the public good?</p> <p>3. Handling uncertainty: How do we holistically treat and attribute uncertainty throughout data analysis and decision making?</p> <p>4. Adversaries, workarounds, and feedback loops: How should trustworthy algorithms account for and be resilient to adversaries who try to manipulate the algorithms, workarounds from people trying to achieve their goals, and feedback loops where algorithm outputs become future inputs?</p> <p>5. How do we trust algorithms? What are the processes through which different stakeholders come to trust an algorithm?</p> <p>The project produced a report that expands on these five challenges and provides recommendations for progress. The report was delivered to the National Science Foundation, and is also posted publicly on the workshop website for anyone to read.</p> <p>In addition, the workshop explicitly included five PhD students -- next generation scholars -- as full participants in the workshop, and also provided additional training to help them understand how the larger research community functions.</p><br> <p>            Last Modified: 10/29/2018<br>      Modified by: Richard&nbsp;Wash</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Computer-based algorithms are increasingly being used in systems that automatically make important decisions on behalf of people, including determining what news people see online, controlling speed and steering of cars, choosing prices for goods and services, filtering job applicants, recognizing and categorizing airport travelers, and making sentencing recommendations for people convicted of crimes. As these algorithms simultaneously become more common and more complicated, it is important to understand whether they can be trusted to make decisions like these, what makes algorithms trustworthy, and how algorithms can be made more trustworthy.  Fundamentally, these algorithms operate in a complicated socio-technical context that includes the designers of the algorithms, the data used as an input to the algorithms, the interface that presents and uses the outputs, the people who make choices about goals of algorithms and when to use algorithms, and societal laws and norms that influence their use. All aspects of this context influence the outputs of the algorithms, and also impact whether they are worthy of being trusted to make important decisions.  A group of researchers, practitioners, and policy-makers convened at a workshop on December 4&ndash;5, 2017 in Arlington, VA to discuss these issues. The group identified five challenges that future research needs to focus on to help algorithms be more trustworthy:  1. People, processes, and training: Who defines and how do we ensure good practice in data science and machine learning? What are the avenues for education? What are the appropriate tools for ensuring good practice in machine learning and algorithm development?  2. Evidence, accountability, and oversight: How do we integratively assess the impact of an algorithmic system on the public good?  3. Handling uncertainty: How do we holistically treat and attribute uncertainty throughout data analysis and decision making?  4. Adversaries, workarounds, and feedback loops: How should trustworthy algorithms account for and be resilient to adversaries who try to manipulate the algorithms, workarounds from people trying to achieve their goals, and feedback loops where algorithm outputs become future inputs?  5. How do we trust algorithms? What are the processes through which different stakeholders come to trust an algorithm?  The project produced a report that expands on these five challenges and provides recommendations for progress. The report was delivered to the National Science Foundation, and is also posted publicly on the workshop website for anyone to read.  In addition, the workshop explicitly included five PhD students -- next generation scholars -- as full participants in the workshop, and also provided additional training to help them understand how the larger research community functions.       Last Modified: 10/29/2018       Submitted by: Richard Wash]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
