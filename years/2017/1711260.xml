<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Assessing "Systems Thinking" Skills and Learning in Interdisciplinary STEM Courses</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>11/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>182698.00</AwardTotalIntnAmount>
<AwardAmount>182698</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>R. Corby Hovis</SignBlockName>
<PO_EMAI>chovis@nsf.gov</PO_EMAI>
<PO_PHON>7032924625</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This is a collaborative project involving investigators from Michigan State University (Award DUE-1711260), the American Museum of Natural History (Award DUE-1711411), and Rutgers University-New Brunswick (Award DUE-1712034). Understanding complex interdisciplinary issues such as large-scale ecosystem change, food security, and the decline in global fisheries requires that the next generation of scientists develop Systems Thinking (ST) skills that will allow them to understand the structure and function of coupled human and natural systems and identify the leverage points for addressing problems most effectively and efficiently. Students who are able to think deeply about the complex dynamics of a system are better prepared to predict the system's behavior, engineer more favorable outcomes, and evaluate the trade-offs between different policy and management decisions. However, even though ST skills are often the foundation of sustainability science curricula at universities nationwide, few resources are available for instructors to promote and assess ST skills in their classrooms. In this project, the investigators will test a method for teaching, assessing, and improving ST skills in STEM classrooms using cognitive mapping software called Mental Modeler (http://www.mentalmodeler.org/), which allows students to represent their understanding of a problem through easy-to-use system-modeling tools and to rearrange components of the problem to analyze scenarios and revise their understanding. This approach will be tested in several environmental science, environmental studies, and sustainability-related courses focusing on problems related to food systems.&lt;br/&gt;&lt;br/&gt;Building on previous NSF-funded research, this project will (1) produce tools and modules that support and measure ST learning in integrated STEM disciplines and (2) further develop and test the Mental Modeler software for visualizing complex systems. Mental Modeler is a multidimensional visualization and modeling software platform that allows users to identify the structure, function, and leverage points of a system and to run system-level scenario analyses. The software will help educators determine aspects of ST assessment that are applicable across STEM fields and measure students' ST learning over time. Specifically, the project will address three questions: (1) What are the standardized ST assessment dimensions that are applicable across STEM fields? (2) Can students' ST learning progressions be measured over time through structural network metrics, functional scenario analyses, and qualitative descriptions defined within semi-quantitative cognitive maps (a) within a specific course and (b) across courses in a curriculum? (3) Are there predictable student learning trajectories or progressions with regard to ST?</AbstractNarration>
<MinAmdLetterDate>07/31/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1711260</AwardID>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Gray</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven Gray</PI_FULL_NAME>
<EmailAddress>stevenallangray@gmail.com</EmailAddress>
<PI_PHON>6469152915</PI_PHON>
<NSF_ID>000372716</NSF_ID>
<StartDate>07/31/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName>East Lansing</CityName>
<StateCode>MI</StateCode>
<ZipCode>488246446</ZipCode>
<StreetAddress><![CDATA[480 Wilson Road, Rm 131]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1998</Code>
<Text>IUSE</Text>
</ProgramElement>
<ProgramReference>
<Code>8209</Code>
<Text>Improv Undergrad STEM Ed(IUSE)</Text>
</ProgramReference>
<ProgramReference>
<Code>8244</Code>
<Text>EHR CL Opportunities (NSF 14-302)</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0417</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~182698</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>During this project, we worked to identify standardized systems thinking (ST) assessment tools applicable across STEM fields and explored if there are predictable student learning progressions with regard to ST. These areas of investigation are particularly important because addressing contemporary social-ecological problems in an increasingly complex world requires a generation of STEM scientists with ST skills. These skills will allow them to integrate concepts across disciplines, grasp the structure and function of coupled human and natural problems, and identify leverage points for system change. Over the course of three years, we formalized four assessment dimensions (system structure, system function, identification of leverage points for change, and trade-off analysis) that are applicable across fields, with measurable learning progressions and predictable learning trajectories. We also developed techniques to integrate qualitative and quantitative assessment of ST, along with a scaffolded approach to introducing students to ST tools, beginning with qualitative tools and moving into quantitative approaches.</p> <p>We employed several approaches to the areas of investigation described above. We worked across five institutions (Michigan State University, Columbia University, Rutgers University, University of Maryland, Middlebury College), reaching more than 1000 students across different interdisciplinary STEM courses. During the initial phase of our collaboration, we leveraged (1) recent NSF-funded research that developed semi-quantitative modeling tools (complex systems visualization software called Mental Modeler), and (2) novel teaching and assessment modules in integrated STEM disciplines, to develop comprehensive interdisciplinary food and other socio-environmental systems curricular materials that we piloted in six separate courses. These materials included lesson plans for both traditional lectures and flipped classes, in-class exercises, a multi-part homework assignment using a cognitive mapping technique, and assessment tools including a rubric centered on the four dimensions of ST noted above.</p> <p>The results from the pilot indicated that there are measurable student learning progressions with regard to ST, with students progressing through each of the four dimensions (Figure 1). We refined the curricular materials through courses taught at Michigan State University (MSU) and Columbia University. For example at MSU, we developed and tested different assessment rubrics using quantitative and qualitative approaches to measure students&rsquo; ST progression (Figure 2).</p> <p>In our quantitative assessments, student cognitive maps showed clear progressions in three major network graph categories over time indicating that as students progress in ST, they focus less on exogenous (i.e. driving) variables, and shift their thinking in terms of which concepts are conceptually more or less important in terms of systems function.</p> <p>In our qualitative assessment, we found that emergent coding of written responses over time in tandem with cognitive maps provided considerable insight into refining sub-dimensions of ST for learning and assessment. Figure 3 identifies evidence of students articulating important parts of a system and important causal relationships, followed by an increase in students&rsquo; ability to reason and provide evidence for their arguments and representations and make predictions about systems-level changes. Qualitative analysis also indicated that these phases are followed by a student's ability to think about the relationship between system structure and system function before ultimately gaining the ability to identify system complexity, identifying areas of uncertainty (or certainty), and being able to articulate and predict consequences of intervention or other changes.</p> <p>We have identified next steps for collaborative initiatives to continue this work, including a new collaboration with Oberlin College to further develop approaches to promoting and measuring ST in the undergraduate STEM curriculum, and this work will be expanded to include University of Utah among others in 2020<strong><em>&mdash;</em></strong>2021.&nbsp;</p> <p>Though our work is ongoing, we have several outcomes to highlight. Indications from course evaluations have shown that students are able to reflect on the learning they have done and the skills they have gained in ST. Several students from the Columbia University courses have used the Mental Modeler tool in other courses, senior theses, or dissertations. As just one example of the impact of this work beyond students, a Research Assistant in one course began employment with The Nature Conservancy and is using the skills she developed for the course to use systems thinking in the development of a strategic plan for land and water protection in New Jersey. Usage of the Mental Modeler software has steadily increased, with a six-fold increase in usage over 18 months (Figure 4A and 4B). We published a subset of our initial results in the journal <em>Sustainability </em>(Gray et al. 2019) and presented our results at numerous educational conferences. A subset of the curricular materials from this project have been peer-reviewed and will be published by the Network of Conservation Educators and Practitioners (a capacity development network centered at the American Museum of Natural History&rsquo;s Center for Biodiversity and Conservation) in their open-access module collection and in their annual journal <em>Lessons in Conservation. </em></p><br> <p>            Last Modified: 03/29/2021<br>      Modified by: Steven&nbsp;Gray</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ During this project, we worked to identify standardized systems thinking (ST) assessment tools applicable across STEM fields and explored if there are predictable student learning progressions with regard to ST. These areas of investigation are particularly important because addressing contemporary social-ecological problems in an increasingly complex world requires a generation of STEM scientists with ST skills. These skills will allow them to integrate concepts across disciplines, grasp the structure and function of coupled human and natural problems, and identify leverage points for system change. Over the course of three years, we formalized four assessment dimensions (system structure, system function, identification of leverage points for change, and trade-off analysis) that are applicable across fields, with measurable learning progressions and predictable learning trajectories. We also developed techniques to integrate qualitative and quantitative assessment of ST, along with a scaffolded approach to introducing students to ST tools, beginning with qualitative tools and moving into quantitative approaches.  We employed several approaches to the areas of investigation described above. We worked across five institutions (Michigan State University, Columbia University, Rutgers University, University of Maryland, Middlebury College), reaching more than 1000 students across different interdisciplinary STEM courses. During the initial phase of our collaboration, we leveraged (1) recent NSF-funded research that developed semi-quantitative modeling tools (complex systems visualization software called Mental Modeler), and (2) novel teaching and assessment modules in integrated STEM disciplines, to develop comprehensive interdisciplinary food and other socio-environmental systems curricular materials that we piloted in six separate courses. These materials included lesson plans for both traditional lectures and flipped classes, in-class exercises, a multi-part homework assignment using a cognitive mapping technique, and assessment tools including a rubric centered on the four dimensions of ST noted above.  The results from the pilot indicated that there are measurable student learning progressions with regard to ST, with students progressing through each of the four dimensions (Figure 1). We refined the curricular materials through courses taught at Michigan State University (MSU) and Columbia University. For example at MSU, we developed and tested different assessment rubrics using quantitative and qualitative approaches to measure students’ ST progression (Figure 2).  In our quantitative assessments, student cognitive maps showed clear progressions in three major network graph categories over time indicating that as students progress in ST, they focus less on exogenous (i.e. driving) variables, and shift their thinking in terms of which concepts are conceptually more or less important in terms of systems function.  In our qualitative assessment, we found that emergent coding of written responses over time in tandem with cognitive maps provided considerable insight into refining sub-dimensions of ST for learning and assessment. Figure 3 identifies evidence of students articulating important parts of a system and important causal relationships, followed by an increase in students’ ability to reason and provide evidence for their arguments and representations and make predictions about systems-level changes. Qualitative analysis also indicated that these phases are followed by a student's ability to think about the relationship between system structure and system function before ultimately gaining the ability to identify system complexity, identifying areas of uncertainty (or certainty), and being able to articulate and predict consequences of intervention or other changes.  We have identified next steps for collaborative initiatives to continue this work, including a new collaboration with Oberlin College to further develop approaches to promoting and measuring ST in the undergraduate STEM curriculum, and this work will be expanded to include University of Utah among others in 2020&mdash;2021.   Though our work is ongoing, we have several outcomes to highlight. Indications from course evaluations have shown that students are able to reflect on the learning they have done and the skills they have gained in ST. Several students from the Columbia University courses have used the Mental Modeler tool in other courses, senior theses, or dissertations. As just one example of the impact of this work beyond students, a Research Assistant in one course began employment with The Nature Conservancy and is using the skills she developed for the course to use systems thinking in the development of a strategic plan for land and water protection in New Jersey. Usage of the Mental Modeler software has steadily increased, with a six-fold increase in usage over 18 months (Figure 4A and 4B). We published a subset of our initial results in the journal Sustainability (Gray et al. 2019) and presented our results at numerous educational conferences. A subset of the curricular materials from this project have been peer-reviewed and will be published by the Network of Conservation Educators and Practitioners (a capacity development network centered at the American Museum of Natural History’s Center for Biodiversity and Conservation) in their open-access module collection and in their annual journal Lessons in Conservation.        Last Modified: 03/29/2021       Submitted by: Steven Gray]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
