<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: The interaction of expectations and evidence in pragmatic inference and generalizations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>01/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>11813.00</AwardTotalIntnAmount>
<AwardAmount>11813</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Spoken language not only communicates information about a speaker's thoughts or desires; it also conveys information about the speaker's identity. By simply listening to speakers' voices, accents, and word choice, we can learn a great deal about them, in addition to what is being talked about. Previous studies of language processing, however, have almost exclusively focused on the linguistic signal abstracted from individual speakers, investigating what listeners think is true about the world based on what an individual speaker has said. The project aims to explore the mechanism by which listeners extract information about the speaker through processing the linguistic signal. It then addresses the question of whether, and if so how, the increased knowledge about the speaker facilitates language comprehension. This research, consequently allows researchers to build a foundation for exploring how young children may learn speaker differences, which can contribute to new pedagogical tools for helping children to better interact with, and learn from, diverse populations. Secondly, the work will likely have industry applications for artificial intelligence technology, allowing it to better adapt its functionality to an individual user's talking style. &lt;br/&gt;&lt;br/&gt;This dissertation project employs two approaches to investigating what information listeners extract from spoken utterances. First, a large-scale online survey technique will be used to solicit responses from participants from a wider variety of linguistic and cultural backgrounds than those included in previous studies. Participants are exposed to utterances produced by two speakers and subsequently answer questions that probe their sensitivity to across-speaker differences. In the second set of experiments, a combination of an artificial language learning paradigm and an eye-tracking methodology will be used to study real-time language comprehension behaviors. Listeners' eye-gaze will be used to gain fine-grained information about the real-time development of their linguistic expectations. By combining these experimental approaches, the researchers elucidate how the human language comprehension system derives fine-grained expectations for future linguistic input and how the mechanism develops as a function of increased knowledge about linguistic communication.</AbstractNarration>
<MinAmdLetterDate>07/20/2017</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1727336</AwardID>
<Investigator>
<FirstName>Chigusa</FirstName>
<LastName>Kurumada</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chigusa Kurumada</PI_FULL_NAME>
<EmailAddress>ckuruma2@ur.rochester.edu</EmailAddress>
<PI_PHON>5852754031</PI_PHON>
<NSF_ID>000693250</NSF_ID>
<StartDate>07/20/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Amanda</FirstName>
<LastName>Pogue</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amanda Pogue</PI_FULL_NAME>
<EmailAddress>apogue@ur.rochester.edu</EmailAddress>
<PI_PHON>5852754031</PI_PHON>
<NSF_ID>000725142</NSF_ID>
<StartDate>07/20/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Rochester]]></Name>
<CityName>Rochester</CityName>
<StateCode>NY</StateCode>
<ZipCode>146270268</ZipCode>
<StreetAddress><![CDATA[BCS, Meliora Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8374</Code>
<Text>DDRI Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~11813</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Amanda Pogue has completed research for her dissertation&nbsp;"Talker-specific adaptation and generalization of pragmatic expectations" supported by the NSF Doctoral Dissertation Improvement Grant. During her funding period, Amanda actively conducted the experimental research, mentored more than 10 undergraduate students, and disseminated her research outcomes at multiple international conferences (e.g., in USA, Germany).</p> <p>&nbsp;</p> <p>Amanda's research focused on a fundamental aspect of human language, namely its ability to communicate meaning. Studies in the field of psycholinguistics have almost exclusively examined the roles of words and sentences produced during linguistic communication. However, meaning as understood by the listener draws heavily on extralinguistic information, such as common knowledge and shared context. The current study expanded existing experimental methods to include visual (e.g., eye-gaze and gestures), contextual (special arrangements of objects in a scene), and social knowledge as important determinants of linguistic meanings.</p> <p>&nbsp;</p> <p>Amanda's study approached this topic based on two lines of experimental studies. First, she asked whether and, if so, how listeners evaluate a speaker?s ability to effectively communicate in context. An effective speaker calibrates the amount and types of information in their speech in accordance with what is already shared in context. Her experiments (conducted via a novel, internet-based paradigm using 293 participants) revealed that listeners evaluate the effectiveness of a speaker based not only on language use but also other social cues (gestures, eye-gaze). Furthermore, listeners were sensitive to the degree to which a speaker takes the perspective of the conversational partner and adjusted their interpretations of subsequent, unseen, linguistic input from the same speaker. This finding extended existing knowledge by showing that the comprehension of meaning critically hinges on the demonstrated effectiveness of using information in context.</p> <p><br /> The second line of work further extended this insight and offered methodological innovation. Amanda developed an experimental paradigm in which participants learned a new set of words associated with new concepts (e.g., novel fictitious animals). She used an eye-tracking paradigm (90 subjects) to observe changes in the speed and accuracy of language processing. This allowed her to observe how listeners would gradually develop the ability to take the context into account as their increasing familiarity with the novel frees up some cognitive resources to integrate extralinguistic information. This paradigm can be extended to investigate young children's social and linguistic development. In particular, the eye-tracking paradigm holds the promise of illuminating relationships between linguistic abilities and children?s visual attention as well as their social engagement.</p> <p>&nbsp;</p> <p>Overall, Amanda's study has opened up multiple avenues for future language researchers who investigate communication in conjunction with visual and interactive contexts. The insights derived from the experiments will have cascading effects on research in neighboring domains, such as the: 1) development of artificial intelligence and automatic speech recognition systems with improved interactive capabilities, 2) facilitation of language education and teaching with an emphasis on communicative efficiency, and 3) better characterization of language and social development in young children. The current project also achieved an educational goal by providing research training to undergraduate students from under-represented minority groups and first-generation college students.</p> <p>&nbsp;</p><br> <p>            Last Modified: 05/03/2019<br>      Modified by: Chigusa&nbsp;Kurumada</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556914153404_Figure1-small-99--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556914153404_Figure1-small-99--rgov-800width.jpg" title="Eye-tracking paradigm used in the study"><img src="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556914153404_Figure1-small-99--rgov-66x44.jpg" alt="Eye-tracking paradigm used in the study"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The study made use of an eye-tracking technique to observe patterns of realtime understanding of meaning in conjunction with visual context</div> <div class="imageCredit">Anne Pier Salverda</div> <div class="imagePermisssions">Royalty-free (restricted use - cannot be shared)</div> <div class="imageSubmitted">Chigusa&nbsp;Kurumada</div> <div class="imageTitle">Eye-tracking paradigm used in the study</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556913674869_CUNY2018--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556913674869_CUNY2018--rgov-800width.jpg" title="Poster presented at the annual CUNY conference on Sentence Processing"><img src="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556913674869_CUNY2018--rgov-66x44.jpg" alt="Poster presented at the annual CUNY conference on Sentence Processing"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Amanda and her undergraduate mentee Bethany Gardner presented their eye-tracking experiment at an international conference in March 2018.</div> <div class="imageCredit">Bethany Gardner and Amanda Pogue</div> <div class="imageSubmitted">Chigusa&nbsp;Kurumada</div> <div class="imageTitle">Poster presented at the annual CUNY conference on Sentence Processing</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556911303423_CSLIposter--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556911303423_CSLIposter--rgov-800width.jpg" title="Poster presented at a CSLI workshop at Stanford University"><img src="/por/images/Reports/POR/2019/1727336/1727336_10504680_1556911303423_CSLIposter--rgov-66x44.jpg" alt="Poster presented at a CSLI workshop at Stanford University"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Amanda presented a poster at a workshop "the CSLI workshop: Bridging computational and psycholinguistic approaches to the study of meaning" at Stanford University in February, 2017.at Stanford University</div> <div class="imageCredit">Amanda Pogue</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Chigusa&nbsp;Kurumada</div> <div class="imageTitle">Poster presented at a CSLI workshop at Stanford University</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Amanda Pogue has completed research for her dissertation "Talker-specific adaptation and generalization of pragmatic expectations" supported by the NSF Doctoral Dissertation Improvement Grant. During her funding period, Amanda actively conducted the experimental research, mentored more than 10 undergraduate students, and disseminated her research outcomes at multiple international conferences (e.g., in USA, Germany).     Amanda's research focused on a fundamental aspect of human language, namely its ability to communicate meaning. Studies in the field of psycholinguistics have almost exclusively examined the roles of words and sentences produced during linguistic communication. However, meaning as understood by the listener draws heavily on extralinguistic information, such as common knowledge and shared context. The current study expanded existing experimental methods to include visual (e.g., eye-gaze and gestures), contextual (special arrangements of objects in a scene), and social knowledge as important determinants of linguistic meanings.     Amanda's study approached this topic based on two lines of experimental studies. First, she asked whether and, if so, how listeners evaluate a speaker?s ability to effectively communicate in context. An effective speaker calibrates the amount and types of information in their speech in accordance with what is already shared in context. Her experiments (conducted via a novel, internet-based paradigm using 293 participants) revealed that listeners evaluate the effectiveness of a speaker based not only on language use but also other social cues (gestures, eye-gaze). Furthermore, listeners were sensitive to the degree to which a speaker takes the perspective of the conversational partner and adjusted their interpretations of subsequent, unseen, linguistic input from the same speaker. This finding extended existing knowledge by showing that the comprehension of meaning critically hinges on the demonstrated effectiveness of using information in context.    The second line of work further extended this insight and offered methodological innovation. Amanda developed an experimental paradigm in which participants learned a new set of words associated with new concepts (e.g., novel fictitious animals). She used an eye-tracking paradigm (90 subjects) to observe changes in the speed and accuracy of language processing. This allowed her to observe how listeners would gradually develop the ability to take the context into account as their increasing familiarity with the novel frees up some cognitive resources to integrate extralinguistic information. This paradigm can be extended to investigate young children's social and linguistic development. In particular, the eye-tracking paradigm holds the promise of illuminating relationships between linguistic abilities and children?s visual attention as well as their social engagement.     Overall, Amanda's study has opened up multiple avenues for future language researchers who investigate communication in conjunction with visual and interactive contexts. The insights derived from the experiments will have cascading effects on research in neighboring domains, such as the: 1) development of artificial intelligence and automatic speech recognition systems with improved interactive capabilities, 2) facilitation of language education and teaching with an emphasis on communicative efficiency, and 3) better characterization of language and social development in young children. The current project also achieved an educational goal by providing research training to undergraduate students from under-represented minority groups and first-generation college students.          Last Modified: 05/03/2019       Submitted by: Chigusa Kurumada]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
