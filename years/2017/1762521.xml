<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Visual Cortex on Silicon</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>477157.00</AwardTotalIntnAmount>
<AwardAmount>177277</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.&lt;br/&gt;&lt;br/&gt;While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions.  In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.&lt;br/&gt;&lt;br/&gt;Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.</AbstractNarration>
<MinAmdLetterDate>11/07/2017</MinAmdLetterDate>
<MaxAmdLetterDate>11/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1762521</AwardID>
<Investigator>
<FirstName>Alan</FirstName>
<LastName>Yuille</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alan L Yuille</PI_FULL_NAME>
<EmailAddress>ayuille1@jhu.edu</EmailAddress>
<PI_PHON>4105166745</PI_PHON>
<NSF_ID>000107159</NSF_ID>
<StartDate>11/07/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName/>
<StateCode>MD</StateCode>
<ZipCode>212182608</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7723</Code>
<Text>Expeditions in Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7723</Code>
<Text>EXPERIMENTAL EXPEDITIONS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~177277</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>The goal of this project was to develop computer vision algroithms inspired by the properties of the human visual system and to implement these algorithms in special purpose hardware. Much of the work done in this project involved developing vision algorithms, in particular deeo neural networks, and evaluating their performance for tasks such as object recognition and parsing humans. by detecting their constiituent parts (e.g., arms, legs, torso). We also developed algorithms for detecting objects in supermarkets and for detecting the orientation of the camera to the supermarket aisle. These types of algorithms have a huge range of applications ranging from automatic medical diagnoisis to developing autonomous cars to developing automatic visual systems to help the visually imparied. These algorithms can also be implmented in silicon hardware, which makes them use much less energy than standard computers. They are also motivated by properties of the human visual system and hence they give understanding into the workings of the human brain. The output of the work consists of peer revised publications (thirty five for this grant) and the development of software code that is available on opensource platforms like Github. In addition, this grant helped develop&nbsp;UnrealCV&nbsp;which is an open source project to help computer vision researchers build virtual worlds for training and evaluating vision algorithms such as deeo networks.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/29/2020<br>      Modified by: Alan&nbsp;L&nbsp;Yuille</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    The goal of this project was to develop computer vision algroithms inspired by the properties of the human visual system and to implement these algorithms in special purpose hardware. Much of the work done in this project involved developing vision algorithms, in particular deeo neural networks, and evaluating their performance for tasks such as object recognition and parsing humans. by detecting their constiituent parts (e.g., arms, legs, torso). We also developed algorithms for detecting objects in supermarkets and for detecting the orientation of the camera to the supermarket aisle. These types of algorithms have a huge range of applications ranging from automatic medical diagnoisis to developing autonomous cars to developing automatic visual systems to help the visually imparied. These algorithms can also be implmented in silicon hardware, which makes them use much less energy than standard computers. They are also motivated by properties of the human visual system and hence they give understanding into the workings of the human brain. The output of the work consists of peer revised publications (thirty five for this grant) and the development of software code that is available on opensource platforms like Github. In addition, this grant helped develop UnrealCV which is an open source project to help computer vision researchers build virtual worlds for training and evaluating vision algorithms such as deeo networks.                Last Modified: 07/29/2020       Submitted by: Alan L Yuille]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
