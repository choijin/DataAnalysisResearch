<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Addressing the memory bottleneck in deep neural networks in cloud platforms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>224586.00</AwardTotalIntnAmount>
<AwardAmount>224586</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will consist in defining the way toward an ultra-fast and energy efficient accelerator for Machine Learning applications deployed on cloud computing. The merging of cloud computing and Machine Learning is shaping our everyday life experience. Examples of applications running on the cloud and exploiting Machine Learning algorithms include data mining, natural language processing and pattern recognition. These three together represent cognitive computing and, due to a vast and growing number of APIs for developers, it is becoming easier to access the computational power of the cloud and develop new applications. This new computation potential is used by businesses to connect data and find patterns valuable for commerce or to improve cybersecurity.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will define a new kind of hardware accelerator, able to speed up cognitive computation by orders of magnitude while reducing energy consumption compared with state-of-the-art processors. The proposed technology is fast and energy efficient, but can be prone to low precision and temperature variation sensitivity. During Phase I, the company will define the hardware accelerator at the system level, optimizing the design for ultra-high speed and sufficient precision to carry out the cognitive computation required. At the same time, the effect of temperature variation and noise will be minimized through improved design. Finally, the energy consumption of the new designs will be estimated and compared with the overall performance of state-of-the-art competitive architectures.</AbstractNarration>
<MinAmdLetterDate>12/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>12/27/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1747360</AwardID>
<Investigator>
<FirstName>Farnood</FirstName>
<LastName>Merrikh Bayat</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Farnood Merrikh Bayat</PI_FULL_NAME>
<EmailAddress>farnoodmb@mentiumtech.com</EmailAddress>
<PI_PHON>8057084652</PI_PHON>
<NSF_ID>000750943</NSF_ID>
<StartDate>12/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Mentium Technologies Inc.</Name>
<CityName>Goleta</CityName>
<ZipCode>931175494</ZipCode>
<PhoneNumber>8056176245</PhoneNumber>
<StreetAddress>2208 Pacific Coast Dr</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA24</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080596325</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MENTIUM TECHNOLOGIES INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Mentium Technologies Inc.]]></Name>
<CityName>Goleta</CityName>
<StateCode>CA</StateCode>
<ZipCode>931175494</ZipCode>
<StreetAddress><![CDATA[2208 Pacific Coast Dr]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>24</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA24</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~224586</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Nowadays, Artificial Intelligence algorithms are applied in many  different fields and are spreading even further: high frequency stock  trading, scientific data Analysis, healthcare diagnosis, security  cameras, cybersecurity, autonomous vehicles and many more.</p> <p>The big bang of this AI explosion dates back to 2012, when an  algorithm based on Deep Neural Networks (DNNs) beat all classical  Computer Vision algorithm in recognizing real-world objects. This  revolution was triggered by the availability of enough computational  power (Nvidia GPUs) to limit the optimization time of Neural Network?s  parameters (so-called ?Network Training?) to almost a week.</p> <p>We now have huge improvements on the DNNs architectures, i.e. capable  of reaching better accuracy in object classification and localization,  or even succeeding in the difficult art of speech recognition. As these  architectures become more complex and require higher computation  capabilities, the need for more powerful hardware has increased,  representing, now more than in the past, the bottleneck toward better AI  applications.</p> <p>to be more specific, since the invention of the modern computer  during the Second World War, the basic of its architecture relied on a  physically separated memory to store data and on a processor to perform  computation on such data. Hence, the input data and the results of the  computation must be transported from the memory to the processor and  back. This transfer of information requires time and energy,  representing a huge inefficiency in the whole processing, an  inefficiency that now, given the needs of AI, represents the main  bottleneck for the AI applications.</p> <p>Mentium solutions to the  hardware bottleneck relies on two main pillars: in-memory computation  and analog instead of digital processing.</p> <p>In our architecture the very same physical memory devices that are  used to store the biggest part of the data (the Neural Networks  parameters) are used to carry out the computation. This reduces the  transfer of the data to a very small fraction (from 1/100 to 1/10000 and  even less) of what would be in a ?normal? computer, solving the memory  bottleneck issue.</p> <p>On top of that, the calculations are carried out using analog values  instead of digital. The consequence are much higher energy efficiency,  speed and density, since a single transistor is now used to carry out a  multiplication instead of tens of transistors as it would be the case  for a digital implementation.</p> <p>The result is an architecture able to deliver 100x in speed and efficiency advantage compared to future state-of-the-art.</p> <p>This NSF SBIR Phase I award  allowed us to complete a feasibility study that confirmed the advantages  in terms of speed, efficiency and area, as well as the practicality of  the architecture.<br />The project started from the search for the best  DNN architecture for the market need, to then move to a block design for  a chip able to efficiently implement such DNN. The architecture has  been validated against noise and low precision computation, two effects  that are inherent to analog computation. Extensive simulations have been carried out taking into account the effect of the hardware implementation on the DNN performances.<br />The results validated the  overall architecture. <br />Particular efforts have been dedicated to  identify the market needs and to validate the product idea, a process  definitely facilitated by the NSF Bootcamp program.</p> <p>The possibility to bring such computational power to battery powered devices opens up new possibilities and the impact of this technology is as wide as the scope of AI applications, going from autonomous vehicles to healthcare, from security to social interaction and integration.</p><br> <p>            Last Modified: 10/22/2018<br>      Modified by: Farnood&nbsp;Merrikh Bayat</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Nowadays, Artificial Intelligence algorithms are applied in many  different fields and are spreading even further: high frequency stock  trading, scientific data Analysis, healthcare diagnosis, security  cameras, cybersecurity, autonomous vehicles and many more.  The big bang of this AI explosion dates back to 2012, when an  algorithm based on Deep Neural Networks (DNNs) beat all classical  Computer Vision algorithm in recognizing real-world objects. This  revolution was triggered by the availability of enough computational  power (Nvidia GPUs) to limit the optimization time of Neural Network?s  parameters (so-called ?Network Training?) to almost a week.  We now have huge improvements on the DNNs architectures, i.e. capable  of reaching better accuracy in object classification and localization,  or even succeeding in the difficult art of speech recognition. As these  architectures become more complex and require higher computation  capabilities, the need for more powerful hardware has increased,  representing, now more than in the past, the bottleneck toward better AI  applications.  to be more specific, since the invention of the modern computer  during the Second World War, the basic of its architecture relied on a  physically separated memory to store data and on a processor to perform  computation on such data. Hence, the input data and the results of the  computation must be transported from the memory to the processor and  back. This transfer of information requires time and energy,  representing a huge inefficiency in the whole processing, an  inefficiency that now, given the needs of AI, represents the main  bottleneck for the AI applications.  Mentium solutions to the  hardware bottleneck relies on two main pillars: in-memory computation  and analog instead of digital processing.  In our architecture the very same physical memory devices that are  used to store the biggest part of the data (the Neural Networks  parameters) are used to carry out the computation. This reduces the  transfer of the data to a very small fraction (from 1/100 to 1/10000 and  even less) of what would be in a ?normal? computer, solving the memory  bottleneck issue.  On top of that, the calculations are carried out using analog values  instead of digital. The consequence are much higher energy efficiency,  speed and density, since a single transistor is now used to carry out a  multiplication instead of tens of transistors as it would be the case  for a digital implementation.  The result is an architecture able to deliver 100x in speed and efficiency advantage compared to future state-of-the-art.  This NSF SBIR Phase I award  allowed us to complete a feasibility study that confirmed the advantages  in terms of speed, efficiency and area, as well as the practicality of  the architecture. The project started from the search for the best  DNN architecture for the market need, to then move to a block design for  a chip able to efficiently implement such DNN. The architecture has  been validated against noise and low precision computation, two effects  that are inherent to analog computation. Extensive simulations have been carried out taking into account the effect of the hardware implementation on the DNN performances. The results validated the  overall architecture.  Particular efforts have been dedicated to  identify the market needs and to validate the product idea, a process  definitely facilitated by the NSF Bootcamp program.  The possibility to bring such computational power to battery powered devices opens up new possibilities and the impact of this technology is as wide as the scope of AI applications, going from autonomous vehicles to healthcare, from security to social interaction and integration.       Last Modified: 10/22/2018       Submitted by: Farnood Merrikh Bayat]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
