<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CHS: Enabling Safe and Adaptive Robot-aided Gait Training through Biomechanical Characterization and Learning from Demonstration</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>191000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The unprecedented growth in the elderly population is generating a high demand for gait rehabilitation due to age-related neurological diseases.  To address this urgent need various assistive robots have been developed to improve gait training outcomes, and impedance control (controlling the force of resistance to external motions that are produced by the environment) has been widely employed in these robots to ensure safe human-robot interaction.  However, it is difficult to personalize the virtual impedance for such robots due to the complex nature of human neurological and musculoskeletal dynamics.  On the other hand, a physical therapist can provide adaptive assistance to a patient at the correct moment in a gait cycle based on real-time sensory feedback and clinical experience.  Inspired by this observation, one could imagine designing an assistive robot control system by learning from therapists' demonstrations, but such a purely data-driven approach could lead to significantly degraded performance with new gait patterns, which creates safety risks for users. This research will develop a hybrid assistive robot control approach, which integrates model-based impedance control with machine learning from therapists' behaviors so that the resultant robot assistance is safe yet adaptive.  Project outcomes will include a novel algorithm framework for physical human-robot collaboration that exhibits both performance guarantees due to the model-based control and intelligent adaptation resulting from robot learning.  The new technology will have a wide range of applications in many other safety-critical human-robot collaboration scenarios, including collaborative manufacturing, (semi) autonomous driving, and service robots.  The broader impacts of the work will be further enhanced by tight integration of the research with educational activities including new modules in existing robotics classes, research opportunities for undergraduate students from underrepresented groups, and internships for local high-school students.&lt;br/&gt;  &lt;br/&gt;The scientific contribution of the work will include: 1) integration of heterogeneous wearable sensor data to build the robot learning model from therapists' demonstrations, and human knee impedance characterization to build the robot impedance control model; 2) a robot planning approach based on a fusion of learning from demonstration and impedance control, with the weights determined by the degree of confidence in the robot learning model; and 3) automatic requests for new demonstration data and incorporation of subject feedback to refine both the robot learning and impedance control models.  Performance of the approach will be assessed in biomechanical simulations, in lab tests with healthy subjects, and in a pilot study with stroke and Parkinson's disease patients.  It is envisioned that project outcomes will make assistive robots highly intelligent so that a therapist could work with multiple patients simultaneously and even remotely, which could significantly reduce both the therapists' labor intensity and cost of rehabilitation training for patients.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/16/2018</MinAmdLetterDate>
<MaxAmdLetterDate>05/12/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1756031</AwardID>
<Investigator>
<FirstName>Wenlong</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Wenlong Zhang</PI_FULL_NAME>
<EmailAddress>Wenlong.Zhang@asu.edu</EmailAddress>
<PI_PHON>4807275276</PI_PHON>
<NSF_ID>000706436</NSF_ID>
<StartDate>03/16/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<CountyName/>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2><![CDATA[660 South Mill Avenue, Suite 310]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>Tempe</CityName>
<CountyName/>
<StateCode>AZ</StateCode>
<ZipCode>852816011</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~175000</FUND_OBLG>
<FUND_OBLG>2020~16000</FUND_OBLG>
</Award>
</rootTag>
