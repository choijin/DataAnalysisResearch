<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Proposal: EarthCube Integration: ICEBERG: Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2017</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>212395.00</AwardTotalIntnAmount>
<AwardAmount>212395</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>06010000</Code>
<Directorate>
<Abbreviation>GEO</Abbreviation>
<LongName>Directorate For Geosciences</LongName>
</Directorate>
<Division>
<Abbreviation>ICER</Abbreviation>
<LongName>ICER</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Eva Zanzerkia</SignBlockName>
<PO_EMAI>ezanzerk@nsf.gov</PO_EMAI>
<PO_PHON>7032924734</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Satellite imagery is rapidly transforming the way we see the planet, including our ability to study the most remote parts of the Arctic and Antarctic. Satellite imagery can help us map networks of rivers, study changes in the flow and thickness of glaciers, identify rock and soil types, and even find animals like penguins and seals. Because the availability of imagery in polar areas has increased rapidly over the last decade, we are now faced with a challenge: To move from small pilot-studies to pan-Arctic or pan-Antarctic analyses of geological and biological processes requires new infrastructures that link scientists, satellite imagery, and fast computing. The project, called ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, aims to build the cyberinfrastructure required to make the most of satellite imagery for geosciences, starting with researchers working in polar areas, and then branching out to the larger community. The Broader Impacts of this proposal include the training of undergraduate and graduate students, as well as young investigators and female scientists. Moreover, the scientific findings enabled by this proposed cyberinfrastructure will have immediate benefits for our ability to predict the future dynamics of the polar regions, and critical to the management of Arctic and Antarctic resources. &lt;br/&gt;&lt;br/&gt;Polar geosciences stands at the precipice of a revolution, one enabled by the confluence of cutting edge analytical tools, petabytes of high-resolution imagery, and an ever growing array of high performance computing resources. With these tools at hand, we can look beyond incremental improvements in our understanding of the polar regions. Near-real time datasets of geological and biological importance at the continental scale are within our reach if we create those critical cyberinfrastructure components that allow the geosciences community to exploit existing assets and establish a common workflow for reproducible imagery-enabled science. The research objective of this proposal is to understand the biological, geological, and hydrological functioning of the polar regions at spatial scales heretofore beyond the reach of individual PIs, and to develop tools for imagery-enabled science that can be applied globally. The resulting cyberinfrastructure, which we call ICEBERG - Imagery Cyberinfrastructure and Extensible Building-Blocks to Enhance Research in the Geosciences, is an extensible system for coupling open-source image analysis tools with the use of high performance and distributed computing (HPDC) for imagery-enabled geoscience research. We propose a project to (1) develop open source image classification tools tailored to high-resolution satellite imagery of the Arctic and Antarctic to be used on HPDC resources, (2) create easy-to-use interfaces to facilitate the development and testing of algorithms for application specific geoscience requirements, (3) apply these tools through use cases that span the biological, hydrological, and geoscience needs of the polar community, (4) transfer these tools to the larger non-polar community.</AbstractNarration>
<MinAmdLetterDate>09/14/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/14/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.050</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1740575</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Willis</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael J Willis</PI_FULL_NAME>
<EmailAddress>mike.willis@colorado.edu</EmailAddress>
<PI_PHON>6142098997</PI_PHON>
<NSF_ID>000508865</NSF_ID>
<StartDate>09/14/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Boulder</Name>
<CityName>Boulder</CityName>
<ZipCode>803031058</ZipCode>
<PhoneNumber>3034926221</PhoneNumber>
<StreetAddress>3100 Marine Street, Room 481</StreetAddress>
<StreetAddress2><![CDATA[572 UCB]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>007431505</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF COLORADO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431505</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Colorado at Boulder]]></Name>
<CityName>Boulder</CityName>
<StateCode>CO</StateCode>
<ZipCode>803031058</ZipCode>
<StreetAddress><![CDATA[3100 Marine Street Room 479]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8074</Code>
<Text>EarthCube</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~212395</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our project had two major themes. The first theme we explored is to use machine learning combined with recent very high resolution satellite images and digital elevation models to correct the assumed positions of 350,000 historic aerial photographs of Antarctica taken between 1930 and 1980. Navigation when the air photos were taken was rudimentary at best, with dead reckoning, sun-shots and pressure barometers being the main ways to locate the aircraft position as the pilots flew across the Antarctic continent. As a result, we know now that many of the locations were the photos were thought to have been taken are &ldquo;off&rdquo;, mislocated by up to several hundred kilometers. If we knew where the photos were actually taken we could use them to examine the extent of the Antarctic Ice Sheet for periods well before the satellite era. The extents of the ice sheet in the past are important calibration targets for ice sheet dynamic models. These models are used to predict what the ice sheet may do in the future, affecting sea level and coastal communities.</p> <p>We researched using unchanging visual elements, such as bedrock outcrops to link the historical aerial imagery and the up-to-date satellite imagery. Different visual feature representations were used to try to obtain matching features, for example, SIFT, RootSift, A-SIFT, PCA-SIFT, even the deep learning based feature LIFT. However the historical aerial images are often over-exposed and of low visual quality, and both the photos and the satellite images contain large homogeneous regions with no defined surface texture, such as large areas covered with ice and snow.&nbsp; While we achieve registration between the photos and satellite images for some parts of the data they were, unfortunately not always reliable. We continue on our own time to research improvements for cross modality registration to improve on our tantalizing initial registration results.</p> <p>Our second theme used machine learning to derive new very-high resolution bedrock masks otherwise know as vector outlines of bedrock extents for Antarctica. We used a moderate to low-resolution mask from the Landsat Image Mosaic of Antarctica (LIMA) as a rough approximation of where bedrock is exposed. We then used the Reference Elevation Model of Antarctica imagery from the Polar Geospatial Center as our high resolution source. This commercial image source is composed of orthorectified satellite images from the DigitalGlobe/Maxar constellation. We used multispectral images from Quickbird-2, Worldview-2 and -3 and trained our learning algorithm from seven different areas of bedrock in Antarctica. Our rationale Is that the bedrock in the Transantarctic Mountains is likely to look different than the bedrock of the Antarctic Peninsula and elsewhere. Our code is based on a Deep Convolutional Neural Network, or a deep learning algorithm. We simplified our initial attempts as they were computationally inefficient and overfit the data. We found that our system worked extremely well for test areas of the McMurdo Dry Valleys, improving the delineation between snow, ice, water and bedrock rapidly and accurately. Bedrock masks are useful as their extent can be rapidly calculated to see if changing surface mass balance or ice dynamics show up as changes in glacier thickness and extent. Bedrock masks also provide a quick means of finding calibrations sites for geodetic altimeter satellite missions such as ICESat-2. Repeat tracks over bedrock outcrops help identify any instrument drift or errors.</p><br> <p>            Last Modified: 03/04/2021<br>      Modified by: Michael&nbsp;J&nbsp;Willis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our project had two major themes. The first theme we explored is to use machine learning combined with recent very high resolution satellite images and digital elevation models to correct the assumed positions of 350,000 historic aerial photographs of Antarctica taken between 1930 and 1980. Navigation when the air photos were taken was rudimentary at best, with dead reckoning, sun-shots and pressure barometers being the main ways to locate the aircraft position as the pilots flew across the Antarctic continent. As a result, we know now that many of the locations were the photos were thought to have been taken are "off", mislocated by up to several hundred kilometers. If we knew where the photos were actually taken we could use them to examine the extent of the Antarctic Ice Sheet for periods well before the satellite era. The extents of the ice sheet in the past are important calibration targets for ice sheet dynamic models. These models are used to predict what the ice sheet may do in the future, affecting sea level and coastal communities.  We researched using unchanging visual elements, such as bedrock outcrops to link the historical aerial imagery and the up-to-date satellite imagery. Different visual feature representations were used to try to obtain matching features, for example, SIFT, RootSift, A-SIFT, PCA-SIFT, even the deep learning based feature LIFT. However the historical aerial images are often over-exposed and of low visual quality, and both the photos and the satellite images contain large homogeneous regions with no defined surface texture, such as large areas covered with ice and snow.  While we achieve registration between the photos and satellite images for some parts of the data they were, unfortunately not always reliable. We continue on our own time to research improvements for cross modality registration to improve on our tantalizing initial registration results.  Our second theme used machine learning to derive new very-high resolution bedrock masks otherwise know as vector outlines of bedrock extents for Antarctica. We used a moderate to low-resolution mask from the Landsat Image Mosaic of Antarctica (LIMA) as a rough approximation of where bedrock is exposed. We then used the Reference Elevation Model of Antarctica imagery from the Polar Geospatial Center as our high resolution source. This commercial image source is composed of orthorectified satellite images from the DigitalGlobe/Maxar constellation. We used multispectral images from Quickbird-2, Worldview-2 and -3 and trained our learning algorithm from seven different areas of bedrock in Antarctica. Our rationale Is that the bedrock in the Transantarctic Mountains is likely to look different than the bedrock of the Antarctic Peninsula and elsewhere. Our code is based on a Deep Convolutional Neural Network, or a deep learning algorithm. We simplified our initial attempts as they were computationally inefficient and overfit the data. We found that our system worked extremely well for test areas of the McMurdo Dry Valleys, improving the delineation between snow, ice, water and bedrock rapidly and accurately. Bedrock masks are useful as their extent can be rapidly calculated to see if changing surface mass balance or ice dynamics show up as changes in glacier thickness and extent. Bedrock masks also provide a quick means of finding calibrations sites for geodetic altimeter satellite missions such as ICESat-2. Repeat tracks over bedrock outcrops help identify any instrument drift or errors.       Last Modified: 03/04/2021       Submitted by: Michael J Willis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
