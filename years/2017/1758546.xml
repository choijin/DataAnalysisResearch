<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Energy-Efficient Perception for Autonomous Road Vehicles</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2018</AwardEffectiveDate>
<AwardExpirationDate>10/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>760000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project will be to allow more consumers to make use of assisted and autonomous driving systems in automobiles. Fully Autonomous Vehicles (AV) will reduce traffic collisions and enable humans to spend less time driving and more time on productive activities. Commercially deploying AVs requires a number of key technologies including sensing, perceptual systems, motion planning, and actuation. Our discussions with leaders and decisionmakers at automotive companies have shown that the development of robust, accurate, and energy-efficient perception systems is a major technical obstacle to creating mass-producible autonomous road vehicles. Of particular interest to automakers is scaling down the computational requirements of perceptual systems while preserving high levels of accuracy and robustness.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase II project will use deep learning to create perception systems that are (a) scalable across different computational platforms and (b) scalable across smaller or larger sensor sets. Specifically, the company will develop scalable systems from small compute platforms (used for Highly Automated Driving) to somewhat larger compute platforms (used for Fully Automated Driving). Further, the company will develop perceptual systems that scale from few sensors to many sensors. The goal is to "do more with less," advancing the pareto-optimal frontier of efficiency-accuracy and price-accuracy tradeoffs. The company has already engaged with automotive OEMs and suppliers to develop partnerships and to define metrics for success in this endeavor.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/04/2018</MinAmdLetterDate>
<MaxAmdLetterDate>09/19/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1758546</AwardID>
<Investigator>
<FirstName>Forrest</FirstName>
<LastName>Iandola</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Forrest Iandola</PI_FULL_NAME>
<EmailAddress>forrest@deepscale.ai</EmailAddress>
<PI_PHON>6502000082</PI_PHON>
<NSF_ID>000724046</NSF_ID>
<StartDate>04/04/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>DeepScale, Inc</Name>
<CityName>San Jose</CityName>
<ZipCode>951312912</ZipCode>
<PhoneNumber>6502000082</PhoneNumber>
<StreetAddress>1232 Royal Crest Dr</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080268781</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DEEPSCALE, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[DeepScale, Inc.]]></Name>
<CityName>Mountain View</CityName>
<StateCode>CA</StateCode>
<ZipCode>940431823</ZipCode>
<StreetAddress><![CDATA[970 Terra Bella Ave., Suite 1]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>165E</Code>
<Text>SBIR Phase IIB</Text>
</ProgramReference>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8240</Code>
<Text>SBIR/STTR CAP</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~760000</FUND_OBLG>
<FUND_OBLG>2019~0</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-0a144724-7fff-8627-4623-eb2a8f386eb1"> </span></p> <p dir="ltr"><span>With the support of the National Science Foundation Small Business Innovative Research program (NSF SBIR), DeepScale, Inc. is using its proprietary </span><span>artificial intelligence (AI) and deep neural network (DNN) based technology</span><span> to develop </span><span>software to power perception systems for advanced driver assistance systems (ADAS) and autonomous vehicles (AV). Our goal is to provide a cost effective, real-time, integrated visual perception system the global automotive industry requires to enable the development of safe, commercially available, fully autonomous passenger cars to the consumer market and the growing e-hailing taxi industry.</span></p> <p dir="ltr"><span>Funded by our SBIR Phase II Grant, DeepScale built a deep learning based perception product for automotive applications. This product is geared toward ADAS applications medium term, but is based on an approach that will evolve toward increasing levels of autonomy.&nbsp; We demonstrated our product successfully at CES 2019.  Our technology achieved close to state-of-the-art accuracy with a much smaller compute footprint. We have demonstrated a variety of capabilities central to evolving ADAS features and autonomous driving including: object detection, semantic segmentation (for drivable area estimation), lane line estimation, monocam-based depth estimation, and tracking.&nbsp;</span></p> <p dir="ltr"><span>The quest for the fully autonomous car is surely one of the most significant technical challenges of our time.&nbsp; Tesla&rsquo;s AutoPilot has become the gold standard for advanced driving capabilities, and most major automakers across the globe are allocating huge budgets to develop comparable products. Big name tech giants such as Apple and Google have joined the race. Independent crowd-sourced ride-hailing ventures such as Uber have declared their intention to put fleets of autonomous taxis on the streets in major metropolitan areas in the next few years, and they have mounted their own development efforts as well.</span></p> <p dir="ltr"><span>The impact of autonomous driving technology on the auto industry and consumer mobility behavior cannot be overstated. Mckinsey and Company, in a 2016 report suggest that shared mobility (e.g. car sharing and e-hailing services) as well as car connectivity could increase the automotive revenue pool by as much as 30%</span><span>, </span><span>or $1.5 trillion annually, by 2030. Moreover, McKinsey anticipates that such shared mobility solutions and a fit for purpose approach to personal transportation will markedly decrease the centrality of private-car ownership in the coming decades. [Mckinsey&amp;Company2016]</span></p> <p dir="ltr"><span>Autonomous vehicles also promise a variety of meaningful societal benefits, from reduced energy consumption, increased leisure time, decreased traffic congestion to a significant reduction in traffic accidents.&nbsp; Safety will be a critical product characteristic of autonomous vehicles which hold the promise of reducing the 30,000 to 40,000 traffic fatalities, as well as 2.4 million in injuries and over $200 billion in economic losses, on our nation&rsquo;s roadways each year, as 94% of motor vehicle crashes can be attributed to human error according to a recent National Highway Transportation Safety Administration report. [NHTSA2017]</span></p> <p dir="ltr"><span>[Mckinsey &amp; Company2016] Mckinsey &amp; Company, &ldquo;Disruptive trends that will transform the auto industry,&rdquo; January 2016.</span></p> <p dir="ltr"><span>[NHTSA2017] National Highway Transportation Safety Administration, &ldquo;2015 Summary of Motor Vehicle Crashes (Early Edition) Traffic Safety Facts&rdquo;, DOT HS 812375, Feb 2017.</span></p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/19/2019<br>      Modified by: Forrest&nbsp;Iandola</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   With the support of the National Science Foundation Small Business Innovative Research program (NSF SBIR), DeepScale, Inc. is using its proprietary artificial intelligence (AI) and deep neural network (DNN) based technology to develop software to power perception systems for advanced driver assistance systems (ADAS) and autonomous vehicles (AV). Our goal is to provide a cost effective, real-time, integrated visual perception system the global automotive industry requires to enable the development of safe, commercially available, fully autonomous passenger cars to the consumer market and the growing e-hailing taxi industry. Funded by our SBIR Phase II Grant, DeepScale built a deep learning based perception product for automotive applications. This product is geared toward ADAS applications medium term, but is based on an approach that will evolve toward increasing levels of autonomy.  We demonstrated our product successfully at CES 2019.  Our technology achieved close to state-of-the-art accuracy with a much smaller compute footprint. We have demonstrated a variety of capabilities central to evolving ADAS features and autonomous driving including: object detection, semantic segmentation (for drivable area estimation), lane line estimation, monocam-based depth estimation, and tracking.  The quest for the fully autonomous car is surely one of the most significant technical challenges of our time.  Tesla?s AutoPilot has become the gold standard for advanced driving capabilities, and most major automakers across the globe are allocating huge budgets to develop comparable products. Big name tech giants such as Apple and Google have joined the race. Independent crowd-sourced ride-hailing ventures such as Uber have declared their intention to put fleets of autonomous taxis on the streets in major metropolitan areas in the next few years, and they have mounted their own development efforts as well. The impact of autonomous driving technology on the auto industry and consumer mobility behavior cannot be overstated. Mckinsey and Company, in a 2016 report suggest that shared mobility (e.g. car sharing and e-hailing services) as well as car connectivity could increase the automotive revenue pool by as much as 30%, or $1.5 trillion annually, by 2030. Moreover, McKinsey anticipates that such shared mobility solutions and a fit for purpose approach to personal transportation will markedly decrease the centrality of private-car ownership in the coming decades. [Mckinsey&amp;Company2016] Autonomous vehicles also promise a variety of meaningful societal benefits, from reduced energy consumption, increased leisure time, decreased traffic congestion to a significant reduction in traffic accidents.  Safety will be a critical product characteristic of autonomous vehicles which hold the promise of reducing the 30,000 to 40,000 traffic fatalities, as well as 2.4 million in injuries and over $200 billion in economic losses, on our nation?s roadways each year, as 94% of motor vehicle crashes can be attributed to human error according to a recent National Highway Transportation Safety Administration report. [NHTSA2017] [Mckinsey &amp; Company2016] Mckinsey &amp; Company, "Disruptive trends that will transform the auto industry," January 2016. [NHTSA2017] National Highway Transportation Safety Administration, "2015 Summary of Motor Vehicle Crashes (Early Edition) Traffic Safety Facts", DOT HS 812375, Feb 2017.                Last Modified: 09/19/2019       Submitted by: Forrest Iandola]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
