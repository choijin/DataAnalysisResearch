<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Scalable Methods for Classification of Heterogeneous High-Dimensional Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2017</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>162539.00</AwardTotalIntnAmount>
<AwardAmount>162539</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent technological advances have enabled routine collection of large-scale high-dimensional data in the biomedical fields. For example, in cancer research it is common to use multiple high-throughput technology platforms to measure genotype, gene expression levels, and methylation levels. One of the main challenges in the analysis of such data is the identification of key biological measurements that can be used to classify the subject into a known cancer subtype.  While significant progress has been made in the development of computationally efficient classification methods to address this challenge, existing methods do not adequately take into account the heterogeneity across the cancer subtypes and the mixed types of measurements (binary/count/continuous) across technology platforms.  As such, existing methods may fail to identify relevant biological patterns. The goal of this project is to develop new classification methods that explicitly take into account the type and heterogeneity of measurements. While the primary focus is on methodology, high priority will be given to computational considerations and software development to encourage dissemination and ensure ease of use for domain scientists.  &lt;br/&gt;&lt;br/&gt;Regularized linear discriminant methods are commonly used for simultaneous classification and variable selection due to their interpretability and computational efficiency. These methods, however, rely on unrealistic assumptions of equality of group-covariance matrices and normality of measurements. This project aims to address the limitations present in current discriminant approaches, and has three objectives: (1) to develop computationally efficient quadratic classification rules that perform variable selection; (2) to generalize the discriminant analysis framework to non-normal measurements; (3) to develop a classification framework for mixed type data coming from multiple technology platforms collected on the same set of subjects. The key methodological innovation is the combination of sparse low-rank singular value decomposition, which enables computational efficiency, with geometric interpretation of linear discriminant analysis, which allows for the construction of nonlinear classification rules by redefining the space for discrimination.</AbstractNarration>
<MinAmdLetterDate>05/11/2017</MinAmdLetterDate>
<MaxAmdLetterDate>05/11/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1712943</AwardID>
<Investigator>
<FirstName>Irina</FirstName>
<LastName>Gaynanova</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Irina Gaynanova</PI_FULL_NAME>
<EmailAddress>irinag@stat.tamu.edu</EmailAddress>
<PI_PHON>9798626777</PI_PHON>
<NSF_ID>000735944</NSF_ID>
<StartDate>05/11/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M University</Name>
<CityName>College Station</CityName>
<ZipCode>778454375</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Pkwy South</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>020271826</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A &amp; M UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042915991</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M University Main Campus]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778454375</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~162539</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p style="text-align: left;">This project has been motivated by the need to develop more flexible classification methods for modern large-scale biological data, e.g. gene expression and microbiome data. The restrictive assumptions of existing classification methods (e.g. linear discrimination boundary and normality of measurements) do not match the complexity of actual data, which may lead to a failure to identify relevant biological patterns. The investigator pursued three topics in this direction: development of computationally efficient quadratic classification rules (relaxation of linearity), generalization of classification framework to non-normal measurements (relaxation of normality) and classification framework for data collected from multiple technology platforms (simultaneous analysis of data from multiple sources).</p> <p>&nbsp;</p> <p>The results achieved in this project are summarized as follows. First, new nonlinear classification rules were developed with higher prediction accuracy and better interpretability (thanks to variable selection). These new methods have dramatically smaller computation times than competitors due to developed optimization algorithms and software design. Secondly, the project has led to an improved theoretical understanding of the similarities and differences between classification and linear regression problems, which provided theoretical support for observed similarities in performance. Finally, the project advanced the methods for joint analyses of multi-view data (data collected on the same subjects from different sources). The project has led to the creation of a new truncated model for zero-inflated data, which are common with advances in modern sequencing technologies. The new model accounts for the limiting sequencing depth (many observed zeros are due to censoring rather than the actual zero values), and allows to jointly analyze mixed types of measurements (binary, continuous, zero-inflated). The proposed estimation framework leads to more accurate characterization of underlying associations between the measurements than existing methods that assume&nbsp;normality.&nbsp;&nbsp;The project also resulted in the creation of a new method for simultaneous non-gaussian component analysis, which is useful for finding joint structure in multiple neuroimaging modalities with highly non-gaussian measurements.&nbsp;These methods were distributed through refereed publications across statistics, machine learning and&nbsp;genomics communities, and as multiple R packages.</p> <p>&nbsp;</p> <p>As for the broader impacts of the project, the investigator served as a research mentor for one (female) postdoc and four graduate students (one female, three males), therefore supporting the future STEM workforce. The investigator also developed a new core PhD course on Statistical Computing focused on contemporary optimization algorithms, reproducible research practices and R packages; with multiple case studies for the course arising directly from the project.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/10/2020<br>      Modified by: Irina&nbsp;Gaynanova</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[This project has been motivated by the need to develop more flexible classification methods for modern large-scale biological data, e.g. gene expression and microbiome data. The restrictive assumptions of existing classification methods (e.g. linear discrimination boundary and normality of measurements) do not match the complexity of actual data, which may lead to a failure to identify relevant biological patterns. The investigator pursued three topics in this direction: development of computationally efficient quadratic classification rules (relaxation of linearity), generalization of classification framework to non-normal measurements (relaxation of normality) and classification framework for data collected from multiple technology platforms (simultaneous analysis of data from multiple sources).     The results achieved in this project are summarized as follows. First, new nonlinear classification rules were developed with higher prediction accuracy and better interpretability (thanks to variable selection). These new methods have dramatically smaller computation times than competitors due to developed optimization algorithms and software design. Secondly, the project has led to an improved theoretical understanding of the similarities and differences between classification and linear regression problems, which provided theoretical support for observed similarities in performance. Finally, the project advanced the methods for joint analyses of multi-view data (data collected on the same subjects from different sources). The project has led to the creation of a new truncated model for zero-inflated data, which are common with advances in modern sequencing technologies. The new model accounts for the limiting sequencing depth (many observed zeros are due to censoring rather than the actual zero values), and allows to jointly analyze mixed types of measurements (binary, continuous, zero-inflated). The proposed estimation framework leads to more accurate characterization of underlying associations between the measurements than existing methods that assume normality.  The project also resulted in the creation of a new method for simultaneous non-gaussian component analysis, which is useful for finding joint structure in multiple neuroimaging modalities with highly non-gaussian measurements. These methods were distributed through refereed publications across statistics, machine learning and genomics communities, and as multiple R packages.     As for the broader impacts of the project, the investigator served as a research mentor for one (female) postdoc and four graduate students (one female, three males), therefore supporting the future STEM workforce. The investigator also developed a new core PhD course on Statistical Computing focused on contemporary optimization algorithms, reproducible research practices and R packages; with multiple case studies for the course arising directly from the project.          Last Modified: 10/10/2020       Submitted by: Irina Gaynanova]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
