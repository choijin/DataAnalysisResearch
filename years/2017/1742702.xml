<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Training Computers and Humans to Detect Misinformation by Combining Computational and Theoretical Analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>316000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
<PO_EMAI>skiesler@nsf.gov</PO_EMAI>
<PO_PHON>7032928643</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Awareness of misinformation online is becoming an increasingly important issue, especially when information is presented in the format of a news story, because (a) people may over-trust content that looks like news and fail to critically evaluate it, and (b) such stories can be easily spread, amplifying the effect of misinformation.  Using machine learning methods to analyze a large database of articles labeled as more or less likely to contain misinformation, along with theoretical analyses from the fields of communication, psychology, and information science, the project team will first characterize what distinguishes stories that are likely to contain misinformation from others.  These characteristics will be used to build a tool that calls out characteristics of a given article that are known to correlate with misinformation; they will also be used to develop training materials to help people make these judgments.  The tool and training materials will be tested through a series of experiments in which articles are evaluated by the tool and by people both before and after undergoing training.  The goal is to have a positive impact on online discourse by improving both readers' and moderators' ability to reduce the impact of misinformation campaigns.  The team will make the models, tools, and training materials publicly available for others to use in research, in classes, and online.&lt;br/&gt;&lt;br/&gt;The team will use two main approaches to characterize articles that are more likely to contain misinformation.  The first is a concept explication approach from the social sciences based on a deep analysis of research writing around information dissemination and evaluation. The second is a supervised machine learning approach to be trained on large datasets of labeled articles, including verified examples of misinformation.  Both approaches will consider characteristics of the content; of its visual presentation; of the people who create, consume, and share it; and of the networks it moves through.  These models will be translated into a set of weighted rules that combine the insights from the two approaches, then instantiated in Markov Logic Networks.  These leverage the strengths of both first order logic and probabilistic graphic models, allow for a variety of efficient inference methods, and have been applied to a number of related problems; the models will be evaluated offline against test data using standard machine learning techniques.  Finally, the team will develop training materials based on existing work from the International Federation of Library Associations and Institutions and on heuristic guidelines derived from the modeling work in the first two tasks, evaluate them through the experiments described earlier, and disseminate them online along with the developed models.</AbstractNarration>
<MinAmdLetterDate>08/14/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/27/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1742702</AwardID>
<Investigator>
<FirstName>S. Shyam</FirstName>
<LastName>Sundar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>S. Shyam Sundar</PI_FULL_NAME>
<EmailAddress>SSS12@psu.edu</EmailAddress>
<PI_PHON>8148652173</PI_PHON>
<NSF_ID>000350722</NSF_ID>
<StartDate>08/14/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dongwon</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dongwon Lee</PI_FULL_NAME>
<EmailAddress>dongwon@psu.edu</EmailAddress>
<PI_PHON>8148650687</PI_PHON>
<NSF_ID>000139387</NSF_ID>
<StartDate>08/14/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pennsylvania State Univ University Park</Name>
<CityName>University Park</CityName>
<ZipCode>168021503</ZipCode>
<PhoneNumber>8148651372</PhoneNumber>
<StreetAddress>201 Old Main</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>003403953</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PENNSYLVANIA STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003403953</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pennsylvania State Univ University Park]]></Name>
<CityName>University Park</CityName>
<StateCode>PA</StateCode>
<ZipCode>168021503</ZipCode>
<StreetAddress><![CDATA[201 Old Main]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>065Z</Code>
<Text>Human factors for security research</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8225</Code>
<Text>SaTC Special Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~300000</FUND_OBLG>
<FUND_OBLG>2018~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The outcomes of this EAGER project include: (1) the improved understanding on the wide spectrum and multiple sub-types of misinformation therein via a concept explication from social science perspective, (2) the identification and validation of computational and operational features of the identified sub-types of misinformation (e.g., clickbait, propaganda, native advertisement, fake news) across genres (e.g., politics, health), (3) the design and development of machine learning based solutions to detect sub-types of misinformation accurately, (4) the development of foundational techniques to be able to explain why a piece of information is true or fake using user comments or counter-examples, (5) the improved understanding on people&rsquo;s susceptibility toward misinformation, and people&rsquo;s ability to discriminate misinformation from true news, (6) the demonstration of a possibility for machine learning based detection models to get attacked by adversaries and forced to make wrong predictions on the veracity of news, and (7) suggestions on potential defense toward such attacks for machine learning based detection models.</p> <p>The project has supported and trained three Ph.D. students (one of them graduated and joined Michigan State University as a faculty member), three REU students (two of them graduated and joined graduate schools at CMU and UT Austin, respectively), and three undergraduate students (all of them graduated and joined the industry). The project has also contributed to developing public benchmark dataset, FakeNewsNet, to evaluate and compare the performance of machine learning based misinformation detection, which has become the most widely-used dataset in the research community.</p><br> <p>            Last Modified: 02/03/2021<br>      Modified by: Dongwon&nbsp;Lee</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The outcomes of this EAGER project include: (1) the improved understanding on the wide spectrum and multiple sub-types of misinformation therein via a concept explication from social science perspective, (2) the identification and validation of computational and operational features of the identified sub-types of misinformation (e.g., clickbait, propaganda, native advertisement, fake news) across genres (e.g., politics, health), (3) the design and development of machine learning based solutions to detect sub-types of misinformation accurately, (4) the development of foundational techniques to be able to explain why a piece of information is true or fake using user comments or counter-examples, (5) the improved understanding on people’s susceptibility toward misinformation, and people’s ability to discriminate misinformation from true news, (6) the demonstration of a possibility for machine learning based detection models to get attacked by adversaries and forced to make wrong predictions on the veracity of news, and (7) suggestions on potential defense toward such attacks for machine learning based detection models.  The project has supported and trained three Ph.D. students (one of them graduated and joined Michigan State University as a faculty member), three REU students (two of them graduated and joined graduate schools at CMU and UT Austin, respectively), and three undergraduate students (all of them graduated and joined the industry). The project has also contributed to developing public benchmark dataset, FakeNewsNet, to evaluate and compare the performance of machine learning based misinformation detection, which has become the most widely-used dataset in the research community.       Last Modified: 02/03/2021       Submitted by: Dongwon Lee]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
