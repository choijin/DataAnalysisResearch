<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Structured Dictionary Models and Learning for High Resolution Images</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>105494.00</AwardTotalIntnAmount>
<AwardAmount>105494</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>We will develop novel techniques for the multi-resolution analysis of high-resolution images, to obtain novel efficient and information representations. These representations will take into account natural invariances in images, and will lead to novel dictionary learning constructions and algorithms for images and in signal processing in general. These representations will then be used to analyze, search, and recognize similar objects or features in collections of (scans of) paintings, in particular a large collection by the baroque artist Jan Brueghel. The distances between images and portions thereof, the features learned by the extensions of dictionary learning we will construct, and the associated statistical similarities, together with labels provided by experts to be used to train classifiers and algorithms that learn similarities among items to match those provided by expert, will enable us to enrich the current set of capabilities in building these large networks of paintings, to search through them more easily and with more general search patterns, and to visualize them according to different metrics by using dimensionality reduction techniques.&lt;br/&gt;&lt;br/&gt;The automatic learning of templates and patterns, and their statistical relationships, in images and signals in general is crucial in a wide variety of applications, such as automating object recognition, and in defining visually meaningful similarities between images, needed to enable searches in large image databases. We will both develop novel techniques for automatically learning good templates for images, that incorporate natural invariances such as translations and scalings, and novel ways of exploiting these templates for analyzing large collections images, measuring the similarities  between then, and finding and characterizing recurrent patterns in them. These novel techniques will be applied to the data on the Jan Brueghel Research site, that allows scholars to investigate and conceptualize a very different notion of old master pictures. Instead of creating absolute categories of genuine and not-genuine, the team will be drawing a map of interconnections between the thousands of paintings produced in the workshops of early modern Antwerp. These pictures were made over several generations, in the shops of masters ranging from world-famous (Pieter Brueghel, Rubens) to utterly obscure. The website will chart how ideas were generated, exchanged, reused and retooled by different artists, mapping networks of creation and production well beyond those traceable through archival documents.</AbstractNarration>
<MinAmdLetterDate>01/26/2017</MinAmdLetterDate>
<MaxAmdLetterDate>01/26/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1724979</AwardID>
<Investigator>
<FirstName>Mauro</FirstName>
<LastName>Maggioni</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mauro Maggioni</PI_FULL_NAME>
<EmailAddress>mauro.maggioni@jhu.edu</EmailAddress>
<PI_PHON>4105166524</PI_PHON>
<NSF_ID>000398937</NSF_ID>
<StartDate>01/26/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182687</ZipCode>
<StreetAddress><![CDATA[3400 N. Charles Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~105494</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Large data sets are ubiquitous, and include many different data types (ranking from 2-d and 3-d images, to text documents, to 3-d sensor measurements of shapes, to observations and measurements of physical systems, etc...). Many such data sets are very high dimensional, and seeking parsimonious yet expressive representations is a key challenge. In this project we developed novel techniques for learning ``dictionaries&rsquo;&rsquo; for data: given a collection of data points (e.g. images, or portions thereof) we created algorithms that output a set of templates (``dictionary&rsquo;&rsquo;) such that each data point may be represented by a combination of a small number of such templates. This learning algorithm also outputs a way of computing, for each data point, which dictionary elements should be used in its representation, and how. Not only is the algorithm computationally efficient, but it is guaranteed, under suitable conditions on hidden low-dimensional structures underlying the data, to perform well, in terms of size of the dictionary produced, accuracy in approximating the data (past and future, of course for data from the same source), as soon as the data used to train the algorithm is sufficiently large (we quantify carefully how large). We believe these requirements and guarantees are essentially best possible in this context.</span></p> <p><span>&nbsp;</span></p> <p><span>We also considered the problem of learning maps between different data sets, in order to discover relationships between them, and to re-use information acquired or learned on one data set for another data set (transfer learning). We developed both fast algorithms for computing robust matchings between high-dimensional data, and new techniques for efficiently encoding such maps. We have explored the use of these maps for mapping shapes, point clouds, and learning relationships between different data sources.</span></p> <p><span>&nbsp;</span></p> <p><span>Finally, we developed techniques for performing object recognition on collections of images, namely drawings and paintings, using neural network algorithms trained on a large corpus of photographic images of natural objects, by adapting and transferring the neural network trained on photos to the &ldquo;context&rdquo; of drawings. If the neural network was thought of as an artificial vision system, the transfer process we implemented may be thought of as replacing the lowest levels of such system, tuning it towards the type of features (e.g. edges) prominent in drawings vs. the ones learned on photographs. This enabled us to obtain good performance in object recognition tasks on a set of images that would have been too small to be able to train a neural network.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 12/21/2018<br>      Modified by: Mauro&nbsp;Maggioni</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Large data sets are ubiquitous, and include many different data types (ranking from 2-d and 3-d images, to text documents, to 3-d sensor measurements of shapes, to observations and measurements of physical systems, etc...). Many such data sets are very high dimensional, and seeking parsimonious yet expressive representations is a key challenge. In this project we developed novel techniques for learning ``dictionaries?? for data: given a collection of data points (e.g. images, or portions thereof) we created algorithms that output a set of templates (``dictionary??) such that each data point may be represented by a combination of a small number of such templates. This learning algorithm also outputs a way of computing, for each data point, which dictionary elements should be used in its representation, and how. Not only is the algorithm computationally efficient, but it is guaranteed, under suitable conditions on hidden low-dimensional structures underlying the data, to perform well, in terms of size of the dictionary produced, accuracy in approximating the data (past and future, of course for data from the same source), as soon as the data used to train the algorithm is sufficiently large (we quantify carefully how large). We believe these requirements and guarantees are essentially best possible in this context.     We also considered the problem of learning maps between different data sets, in order to discover relationships between them, and to re-use information acquired or learned on one data set for another data set (transfer learning). We developed both fast algorithms for computing robust matchings between high-dimensional data, and new techniques for efficiently encoding such maps. We have explored the use of these maps for mapping shapes, point clouds, and learning relationships between different data sources.     Finally, we developed techniques for performing object recognition on collections of images, namely drawings and paintings, using neural network algorithms trained on a large corpus of photographic images of natural objects, by adapting and transferring the neural network trained on photos to the "context" of drawings. If the neural network was thought of as an artificial vision system, the transfer process we implemented may be thought of as replacing the lowest levels of such system, tuning it towards the type of features (e.g. edges) prominent in drawings vs. the ones learned on photographs. This enabled us to obtain good performance in object recognition tasks on a set of images that would have been too small to be able to train a neural network.          Last Modified: 12/21/2018       Submitted by: Mauro Maggioni]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
