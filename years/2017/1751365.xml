<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Physically-Motivated Learning of 3D Shape and Semantics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2018</AwardEffectiveDate>
<AwardExpirationDate>03/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>548581.00</AwardTotalIntnAmount>
<AwardAmount>457138</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A system that navigates or interacts with the real world must reason about 3D geometric properties such as distances or orientations of objects, as well as semantic properties such as part locations or object types. This project combines physics-based modeling of images and shapes, with the versatility of robust optimization and deep learning, to recover 3D shape and semantic information. The work establishes connections between computer vision, machine learning, computer graphics and perception. Vision is a powerful sensing modality since images encode rich information about shape and semantics. However, image formation is a physical phenomenon that often includes complex factors like shape deformations, occlusions, material properties and participating media. Consequently, practical deployment of autonomous or intelligent vision-based systems requires robustness to the effects of diverse physical factors. Such effects may be inverted by modeling the image formation process, but hand-crafted features and hard-coded rules face limitations for data inconsistent with the model. Recent advances in deep learning have led to impressive performances, but generalization of a purely data-driven approach to handle such complex effects is expensive. To address these challenges, this project develops technologies of handling the diversity of real-world images through incorporation of physical models of image formation within deep learning frameworks. The project creates a cross-disciplinary educational program in vision, graphics, learning and perception through coursework that draws connections across wide areas such as physically-based modeling, deep learning, 3D reconstruction and semantic understanding. The program also develops K-12 educative modules that provide experiential insight into novel technologies such as virtual reality or self-driving, with a focus on outreach to students from under-represented backgrounds.&lt;br/&gt;&lt;br/&gt;This research lays the foundations for physically-motivated learning of 3D shape and semantics, with benefits such as higher accuracy, better generalization or greater ease of training. It develops theoretical frameworks that relate unknown material behavior to 3D shape, which allows robust optimization frameworks and convolutional neural network architectures for material-invariant shape estimation. It designs novel network structures that model complex transformations, to generalize recovery of shape or semantics across non-rigid and articulated deformations, or distortions due to refraction and participating media. Further, it uses physical models of appearance or motion to bridge the domain gap between simulations and real images, leading to weakly supervised frameworks that mitigate the expense of data annotation. These advances enable novel applications for light field imaging, augmented reality, self-driving in challenging weather, or underwater robotic exploration.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/16/2018</MinAmdLetterDate>
<MaxAmdLetterDate>04/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1751365</AwardID>
<Investigator>
<FirstName>Manmohan</FirstName>
<LastName>Chandraker</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Manmohan K Chandraker</PI_FULL_NAME>
<EmailAddress>mkchandraker@eng.ucsd.edu</EmailAddress>
<PI_PHON>8584010407</PI_PHON>
<NSF_ID>000727279</NSF_ID>
<StartDate>03/16/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-San Diego]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930934</ZipCode>
<StreetAddress><![CDATA[9500 Gilman Drive MC0934]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~126886</FUND_OBLG>
<FUND_OBLG>2019~113228</FUND_OBLG>
<FUND_OBLG>2020~116796</FUND_OBLG>
<FUND_OBLG>2021~100228</FUND_OBLG>
</Award>
</rootTag>
