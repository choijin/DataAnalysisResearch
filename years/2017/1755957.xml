<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CHS: Understanding cognitive potentials of interactive visualizations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>162650.00</AwardTotalIntnAmount>
<AwardAmount>194650</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
<PO_EMAI>bprabhak@nsf.gov</PO_EMAI>
<PO_PHON>7032924847</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Visualizations are increasingly used to support analysis and understanding of data; however, little is known about just how visualizations affect people's mental models of the underlying data and their resulting influence on analysis task performance.  To that end, this project will conduct a number of experiments to address two key questions that link visualization design to cognition.  The first question addresses how different techniques for visualizing the same data affect people's ability to carry out common analysis tasks, as well as how the designs affect their visual perception of and attention to different aspects of the data.  The second focuses on the kinds of conceptual models people form about a dataset when they explore it using different visualization designs, and how visual and interactive elements of the designs affect those models.  Developing better understandings of how people reason with visualizations will advance both cognitive psychology and visualization design.  Students studying information visualization will be involved in the research, directly benefiting their design abilities and having potential benefits in domains where visualizations are becoming increasingly common, including journalism, education, business, and medicine. &lt;br/&gt;&lt;br/&gt;To address questions of how visual and spatial elements of a given design affect attention and task performance, the project team will first create a taxonomy of the visuo-spatial properties of common visualizations based on existing research scattered across a variety of academic disciplines, mapping visualization features to their ability to support various analysis tasks such as comparison, interpretation, ranking, and categorization.  They will validate and extend the taxonomy through a series of experiments that look at time spent, error rates, eye gaze data, and qualitative participant feedback to triangulate conclusions about how different designs support observations and inferences over the data and which kinds of visualizations provide observational advantages for which kinds of tasks.  The project team will design a series of analysis tasks that emphasize different cognitive processes derived from both Bloom's taxonomy and different types of knowledge (factual, conceptual, and procedural) in order to conduct experiments that get at the kinds of mental models people form when using different visualization designs.  Participants in these experiments will be given time to explore the visualizations, then perform the tasks using a think-aloud protocol while the project team collects eye gaze data.  Participants will then be asked to reflect on their analysis activities through a series of interviews, and draw a series of representations of the data that capture different sorts of relationships that might compose a mental model.  A followup study will look at the effect of providing multiple visualizations and levels of control of which visualizations are shown, to address how interacting with multiple visualizations of the same data affects the mental models that people form.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/09/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/17/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1755957</AwardID>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Parsons</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Paul Parsons</PI_FULL_NAME>
<EmailAddress>parsonsp@purdue.edu</EmailAddress>
<PI_PHON>7654940511</PI_PHON>
<NSF_ID>000711182</NSF_ID>
<StartDate>03/09/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479062021</ZipCode>
<StreetAddress><![CDATA[401 N Grant Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~178650</FUND_OBLG>
<FUND_OBLG>2019~16000</FUND_OBLG>
</Award>
</rootTag>
