<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: RUI: Uncovering the Neural Dynamics of Scene Categorization through Electroencephalography, Machine Learning, and Neuromodulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>304266.00</AwardTotalIntnAmount>
<AwardAmount>304266</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Fritz</SignBlockName>
<PO_EMAI>jfritz@nsf.gov</PO_EMAI>
<PO_PHON>7032927923</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A long-standing problem in cognitive neuroscience is understanding how we can categorize a novel scene in about the same amount of time that it takes to blink one's eyes. Categorization aids both identifying objects and locating them in cluttered scenes, and thus allows for intelligent action in the world. How do we derive semantically meaningful categories from the raw image pixels? Currently, there is experimental support for multiple mechanisms supporting scene categorization, such as through recognizing the scene's objects or other visual features such as spatial layout, color, or texture. Crucially, substantial correlations exist between all of these proposed features. This make it difficult to disentangle their relative contributions to categorization. For example, if two scenes share an object, they will often also share the texture features associated with that object. In this work, the PI (Dr. Bruce C Hansen, Colgate University) and co-PI (Dr. Michelle R Greene, Bates College) seek to disentangle the contribution of such features, and also to determine when these features become available for use, and how they combine to support scene categorization. By understanding the temporal dynamics of the brain activity related to scene categorization, it will be possible to obtain critical insights into how people rapidly but flexibly extract information from the environment. This work forms a bridge across several disciplines including psychology, cognitive neuroscience, computer vision, and machine learning. As such, the project will engage undergraduate students in truly interdisciplinary training that is at the cutting edge of multiple fields.&lt;br/&gt;&lt;br/&gt;This project will make use of high-density EEG combined with machine learning, computational modeling behavioral measures, and advanced neuromodulation to determine how and when the behaviorally relevant features support scene categorization. First, the work will link the encoding of these features to visual event related potentials (vERPs) and also to category information using multivariate classification techniques from machine learning. Taken together, these techniques will allow the PIs to determine the unique contributions of each feature to category-related brain activity over time. A hallmark of intelligent action is flexibility. Therefore, the project will also investigate the flexibility of feature use by manipulating the diagnosticity of information available to observers. These studies will provide insights regarding feature space usage as a function of task demands, as well as the impact of such demands on the time course of feature space availability as indexed by vERPs. Lastly, the project will test for a potential causal role of vERPs to categorization through the use of advanced neuromodulation techniques.</AbstractNarration>
<MinAmdLetterDate>06/29/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1736274</AwardID>
<Investigator>
<FirstName>Michelle</FirstName>
<LastName>Greene</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michelle R Greene</PI_FULL_NAME>
<EmailAddress>mgreene2@bates.edu</EmailAddress>
<PI_PHON>2077866243</PI_PHON>
<NSF_ID>000742245</NSF_ID>
<StartDate>06/29/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Bates College</Name>
<CityName>Lewiston</CityName>
<ZipCode>042406028</ZipCode>
<PhoneNumber>2077868375</PhoneNumber>
<StreetAddress>2 Andrews Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maine</StateName>
<StateCode>ME</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>ME02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>058951401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT &amp; TRUSTEES OF BATES COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>058951401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Bates College]]></Name>
<CityName/>
<StateCode>ME</StateCode>
<ZipCode>042406030</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maine</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>ME02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~304266</FUND_OBLG>
</Award>
</rootTag>
