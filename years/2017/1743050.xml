<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Parallel Semi-supervised Machine Learning for Volumetric Datasets</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2017</AwardEffectiveDate>
<AwardExpirationDate>11/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>99998.00</AwardTotalIntnAmount>
<AwardAmount>99998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wei Ding</SignBlockName>
<PO_EMAI>weiding@nsf.gov</PO_EMAI>
<PO_PHON>7032928017</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Machine learning and parallel computing have come of age. Rapid advances have been made in this decade in the automated recognition of objects and faces in images with "deep learning" almost becoming a household term at the present time. However, a clear limitation in most of the present work is the restriction to two dimensional datasets such as images and the like. When the focus shifts to large three dimensional datasets such as 3D medical imaging, fluid dynamics simulations, remote sensing and electron microscopy, the problems become more difficult by several orders of magnitude. The automatic labeling of three dimensional structures in large datasets requires a comprehensive integration of machine learning and parallel computing with a "from the ground up redesign" to be efficient, accurate and capable of scaling to ever larger volumes. The benefits to the engineering communities and society at large are clear. Successful execution of this project will enable experts in a variety of disciplines in which three dimensional data are generated to efficiently perform large scale automated labeling of structures of interest like the hippocampus in brain images or vortices in fluid dynamics simulations. Students trained in this nexus of machine learning and parallel computing will be capable of making their own contributions ranging from academic research to commercialization. Finally, the software suites generated by this project should play a role in the formation of vertically integrated enterprises.&lt;br/&gt;&lt;br/&gt;Volumetric applications require the development of novel, efficient and scalable machine learning algorithms as existing approaches are computationally intensive and are limited to small size images/video. Volumetric data require that approaches classify homogeneous regions into single categories while maintaining clear-cut region boundaries between classes (urban versus forest for example in terrain classification). To this end, new methods are developed for extracting supervoxels from volumetric datasets, using three dimensional filters, nonlinear dimensionality reduction and Hamilton-Jacobi or Schrodinger geodesic solvers. Next, deep learning principles which have resulted in automated feature extraction and discriminative convolutional filters must be adapted to work on volumetric data. Consequently, the integration of supervoxels and deep learning is central to the proposed work. Very limited expert interaction is permitted since the volume of the datasets is too large, therefore calling for semi-supervised learning approaches. The integrated machine learning and parallel processing software suite created by this project will be disseminated using software management repositories and open source licensing. In summary, the intellectual merit lies in the careful integration of semi-supervised learning, volumetric supervoxel driven segmentation, deep learning and parallel processing.</AbstractNarration>
<MinAmdLetterDate>05/10/2017</MinAmdLetterDate>
<MaxAmdLetterDate>05/10/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1743050</AwardID>
<Investigator>
<FirstName>Sanjay</FirstName>
<LastName>Ranka</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sanjay Ranka</PI_FULL_NAME>
<EmailAddress>ranka@cise.ufl.edu</EmailAddress>
<PI_PHON>3525144213</PI_PHON>
<NSF_ID>000381796</NSF_ID>
<StartDate>05/10/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>S.</FirstName>
<LastName>Balachandar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>S. Balachandar</PI_FULL_NAME>
<EmailAddress>bala1s@ufl.edu</EmailAddress>
<PI_PHON>3523928909</PI_PHON>
<NSF_ID>000110972</NSF_ID>
<StartDate>05/10/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Anand</FirstName>
<LastName>Rangarajan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anand Rangarajan</PI_FULL_NAME>
<EmailAddress>anand@cise.ufl.edu</EmailAddress>
<PI_PHON>3523921507</PI_PHON>
<NSF_ID>000438535</NSF_ID>
<StartDate>05/10/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Florida</Name>
<CityName>GAINESVILLE</CityName>
<ZipCode>326112002</ZipCode>
<PhoneNumber>3523923516</PhoneNumber>
<StreetAddress>1 UNIVERSITY OF FLORIDA</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>969663814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF FLORIDA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Florida]]></Name>
<CityName/>
<StateCode>FL</StateCode>
<ZipCode>326116120</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~99998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>While machine learning methods have become ubiquitous in image classification, the same cannot be said for volumetric datasets. The first goal of this work was consequently to extend well known 2D image parcellation techniques to 3D. And to be expected, the volumetric counterparts of the 2D image parcellation techniques constructed by us performed quite well on 3D datasets and so this is a key contribution of the work. However, an interesting (empirical) finding of the project was in the extension of volumetric machine learning techniques to video. Here we conceived of stacks of images with similar content as comprising a volumetric dataset and applied our 3D techniques to it. As expected, the methods performed quite well. But, when we corrected for the apparent motion of objects in 2D by performing motion correction (through a technique called optical flow) and then applied the 3D techniques, the results were clearly improved: a finding of our work is that spatio-temporal coherence of volumetric parcellation is improved when motion correction is dovetailed with machine learning. Buoyed by this unexpected finding, we then focused on this representation (for stacks of images) in image registration. Here, the goal is to align (by locally stretching and pulling) images until they mutually match up well with corresponding sets of features lined up. Treating the entire stack of images as a single object (while allowing spatial transformations on each one) we were able to extend the previous idea to image alignment: all images in the stack mutually adjust to each other while satisfying a single geometric criterion and come into alignment. Next, we responded to the research milieu asking for explainable AI: we took the black box representation discovered by machine learning techniques and attempted to explain what had been automatically obtained via sensitivity analysis. The basic idea here is to approximately discover what the AI has done, by first using the black box as a source of data, and then performing a sensitivity analysis on brain image volumetric parcellation to get a meaningful result. This is still very fledgling work but appears to be promising and we are currently extending the work to using interpretation trees. Finally, we attempted to ensure that all our implementations used parallel (or readily parallelizable) algorithms and leveraged modern GPU hardware. We were able to make several contributions running the gamut from machine learning classification (on multi-label datasets) to spectral embedding for feature matching. A common methodological thread runs through all the diverse contributions and is rooted in the volumetric parcellation work that kicked off the project.</p><br> <p>            Last Modified: 03/29/2020<br>      Modified by: Anand&nbsp;Rangarajan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ While machine learning methods have become ubiquitous in image classification, the same cannot be said for volumetric datasets. The first goal of this work was consequently to extend well known 2D image parcellation techniques to 3D. And to be expected, the volumetric counterparts of the 2D image parcellation techniques constructed by us performed quite well on 3D datasets and so this is a key contribution of the work. However, an interesting (empirical) finding of the project was in the extension of volumetric machine learning techniques to video. Here we conceived of stacks of images with similar content as comprising a volumetric dataset and applied our 3D techniques to it. As expected, the methods performed quite well. But, when we corrected for the apparent motion of objects in 2D by performing motion correction (through a technique called optical flow) and then applied the 3D techniques, the results were clearly improved: a finding of our work is that spatio-temporal coherence of volumetric parcellation is improved when motion correction is dovetailed with machine learning. Buoyed by this unexpected finding, we then focused on this representation (for stacks of images) in image registration. Here, the goal is to align (by locally stretching and pulling) images until they mutually match up well with corresponding sets of features lined up. Treating the entire stack of images as a single object (while allowing spatial transformations on each one) we were able to extend the previous idea to image alignment: all images in the stack mutually adjust to each other while satisfying a single geometric criterion and come into alignment. Next, we responded to the research milieu asking for explainable AI: we took the black box representation discovered by machine learning techniques and attempted to explain what had been automatically obtained via sensitivity analysis. The basic idea here is to approximately discover what the AI has done, by first using the black box as a source of data, and then performing a sensitivity analysis on brain image volumetric parcellation to get a meaningful result. This is still very fledgling work but appears to be promising and we are currently extending the work to using interpretation trees. Finally, we attempted to ensure that all our implementations used parallel (or readily parallelizable) algorithms and leveraged modern GPU hardware. We were able to make several contributions running the gamut from machine learning classification (on multi-label datasets) to spectral embedding for feature matching. A common methodological thread runs through all the diverse contributions and is rooted in the volumetric parcellation work that kicked off the project.       Last Modified: 03/29/2020       Submitted by: Anand Rangarajan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
