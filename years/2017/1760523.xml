<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: RI: Learning Structured Prediction Models with Auxiliary Supervision</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2017</AwardEffectiveDate>
<AwardExpirationDate>02/29/2020</AwardExpirationDate>
<AwardTotalIntnAmount>170865.00</AwardTotalIntnAmount>
<AwardAmount>170865</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many machine learning problems involve making joint predictions over a set or a sequence of mutually dependent outputs. As an example, consider recognizing a handwritten word, where each character must be recognized in order for the word to be understood. It is important to consider the correlations between the predictions of adjacent characters to aid the individual predictions of characters. Structured prediction models are proposed to solve problems of this type. They have been shown to be successful in many real-world applications, including speech recognition, natural language understanding, and object detection in images. Despite its success, training a structured prediction model requires an extensive collection of training data. However, obtaining human annotations with complex structures is costly. For example, it takes a professionally trained linguist several minutes to label a syntactic parse tree for a single sentence, making it expensive to obtain high-quality annotations. The objective of this research is to develop methods that utilize learning signals that do not directly aim to achieve the target tasks. The outcome of this project will create a fundamental shift in the applicability of structured prediction models, enabling applications in which complex decisions are required and annotated data are expensive to acquire. This will bring new collaboration opportunities with other areas, including education, healthcare, and social and behavioral sciences.&lt;br/&gt;&lt;br/&gt;The goals of this project are to study algorithms for training structured prediction models from heterogeneous learning signals, design automatic algorithms for mining useful information from massive columns of structured and unstructured data, and apply the proposed techniques in real-world applications. The proposed algorithms will be evaluated on a broad range of natural language processing applications, including the algebra word problem, co-reference resolution, and grammatical error correction. The results of the project will be disseminated by publishing papers, releasing open-source software and data sets, organizing workshops and tutorials, and creating new courses on natural language processing and machine learning.</AbstractNarration>
<MinAmdLetterDate>10/17/2017</MinAmdLetterDate>
<MaxAmdLetterDate>10/17/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1760523</AwardID>
<Investigator>
<FirstName>Kai-Wei</FirstName>
<LastName>Chang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kai-Wei Chang</PI_FULL_NAME>
<EmailAddress>kw@kwchang.net</EmailAddress>
<PI_PHON>3102064395</PI_PHON>
<NSF_ID>000726790</NSF_ID>
<StartDate>10/17/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UNIVERSITY OF CALIFORNIA Los Angeles]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951406</ZipCode>
<StreetAddress><![CDATA[10889 Wilshire Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~170865</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-92554a22-7fff-d644-e188-0236a585391d"> </span></p> <p><span id="docs-internal-guid-ca2f8652-7fff-a5df-753a-c361d7fffde3"> </span></p> <p dir="ltr"><span>The goal of this CRII project was</span><span> to develop approaches to utilizing indirect supervised signals of the data which are not directly visible at first sight while aiming the target tasks. </span><span>Overall, we successfully met the objectives of this project, and we further extend the scope of the proposal. We summarize the key outcomes of this project in the following.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>1. New algorithms for training structured output prediction models.&nbsp;</span></p> <p dir="ltr"><span>We developed a new parallel algorithm for learning structured output prediction models on multiple machines. Our approach is flexible and is capable of solving any problems in empirical risk minimization, allowing us to leverage auxiliary signals when learning a model.&nbsp;</span></p> <p dir="ltr"><span>2. Improve cross-lingual transfer learning</span></p> <p>Cross-lingual transfer, where a model learned from one language is transferred to another, has become an important technique to improve the quality and coverage of natural language processing (NLP) tools for low-resource languages in the world. We identified the key challenge in the cross-lingual transfer is that the word order is a significant distinctive feature to differentiate languages. To solve this issue, we proposed several approaches to leveraging linguistic knowledge as auxiliary learning signals to facilitate cross-lingual transfer learning.&nbsp;</p> <p>&nbsp;</p> <p dir="ltr"><span>&nbsp;3. Reducing social bias in prediction models by auxiliary supervised signals.</span></p> <p dir="ltr"><span>Natural language processing techniques play important roles in our daily life. However, they run the risk of exploiting and reinforcing the societal biases (e.g. gender bias) that are present in the underlying data. For example, we observed that coreference resolution systems tend to leverage the implicit association between gender pronouns and occupation words as features. We proposed a series of approaches to quantifying and mitigating bias in a variety of NLP systems by leveraging side data.&nbsp;</span></p> <p>&nbsp;</p> <p dir="ltr"><span>4.&nbsp; Enhancing the robustness of a model by leveraging side information</span></p> <p dir="ltr"><span>Despite NLP models perform well on benchmarks, they are vulnerable to perturbation of the input. For example, replacing a word with its synonym in a correctly classified example may cause the model misclassify the example. We proposed approaches to enhancing the robustness of NLP models by leveraging linguistic knowledge and corpora such as a sentence paraphrase corpus.&nbsp;</span></p> <p dir="ltr"><span>5. Broader Impact</span></p> <p dir="ltr"><span>Beyond the technical goals of the project, contributions were made to three tutorials and more than 10 invited talks; 8 graduate students and 5 undergraduate students were trained for conducting research. Software and datasets have been released for reproducing the experiment results and for use by other researchers.&nbsp;</span></p> <div><span><br /></span></div> <p>&nbsp;</p> <p dir="ltr">&nbsp;</p><br> <p>            Last Modified: 07/17/2020<br>      Modified by: Kai-Wei&nbsp;Chang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[      The goal of this CRII project was to develop approaches to utilizing indirect supervised signals of the data which are not directly visible at first sight while aiming the target tasks. Overall, we successfully met the objectives of this project, and we further extend the scope of the proposal. We summarize the key outcomes of this project in the following.     1. New algorithms for training structured output prediction models.  We developed a new parallel algorithm for learning structured output prediction models on multiple machines. Our approach is flexible and is capable of solving any problems in empirical risk minimization, allowing us to leverage auxiliary signals when learning a model.  2. Improve cross-lingual transfer learning  Cross-lingual transfer, where a model learned from one language is transferred to another, has become an important technique to improve the quality and coverage of natural language processing (NLP) tools for low-resource languages in the world. We identified the key challenge in the cross-lingual transfer is that the word order is a significant distinctive feature to differentiate languages. To solve this issue, we proposed several approaches to leveraging linguistic knowledge as auxiliary learning signals to facilitate cross-lingual transfer learning.      3. Reducing social bias in prediction models by auxiliary supervised signals. Natural language processing techniques play important roles in our daily life. However, they run the risk of exploiting and reinforcing the societal biases (e.g. gender bias) that are present in the underlying data. For example, we observed that coreference resolution systems tend to leverage the implicit association between gender pronouns and occupation words as features. We proposed a series of approaches to quantifying and mitigating bias in a variety of NLP systems by leveraging side data.     4.  Enhancing the robustness of a model by leveraging side information Despite NLP models perform well on benchmarks, they are vulnerable to perturbation of the input. For example, replacing a word with its synonym in a correctly classified example may cause the model misclassify the example. We proposed approaches to enhancing the robustness of NLP models by leveraging linguistic knowledge and corpora such as a sentence paraphrase corpus.  5. Broader Impact Beyond the technical goals of the project, contributions were made to three tutorials and more than 10 invited talks; 8 graduate students and 5 undergraduate students were trained for conducting research. Software and datasets have been released for reproducing the experiment results and for use by other researchers.               Last Modified: 07/17/2020       Submitted by: Kai-Wei Chang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
