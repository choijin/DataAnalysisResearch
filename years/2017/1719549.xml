<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Novel Numerical Approaches for Structured Optimization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2017</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>96000.00</AwardTotalIntnAmount>
<AwardAmount>96000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The data sets involved in many modern applications are extremely large, and are often collected at distributed locations and continuously with the progression of time. Common examples are data sets associated with searches on the Internet, social networks, information technology, healthcare, biology, finance, and engineering. Analyzing and learning from these massive data sets imposes great challenges on computation, data storage, and data transfer. On the other hand, high performance computers are now readily available. This project aims to develop novel computational methods to enable high performance computing for questions involving extremely large data sets. The approaches address several computational challenges that emerge from applications across data sciences and engineering.  Undergraduate and graduate students are involved in the project.&lt;br/&gt;&lt;br/&gt;This project is focused on designing novel computational algorithms and analyzing their theoretical behaviors for solving structured optimization problems that involve huge data sets and are parameterized by large numbers of variables. Both the defining objective functions and the optimal solutions exhibit particular structures, including convexity, smoothness, and multi-linearity for the former, and sparsity, low-rank, and orthogonality for the latter. This research aims to take advantage of this structure in designing efficient computational methods. The project includes several research directions, from variable splitting for handling complicated regularizers, to adaptive asynchronous parallel computing and analysis of convergence rates. Stochastic approximations will be used for dealing with problems involving stream data, and novel numerical approaches will be used to solve non-linearly constrained problems via primal-dual updates. Problems with multi-array structure will also be investigated. The research aims to significantly speed up existing algorithms both theoretically and practically, lead to new theoretical results of existing algorithms that currently lack convergence analysis, and give rise to novel algorithms for computing solutions to complicated problems that are currently not efficiently solvable.</AbstractNarration>
<MinAmdLetterDate>06/16/2017</MinAmdLetterDate>
<MaxAmdLetterDate>06/05/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1719549</AwardID>
<Investigator>
<FirstName>Yangyang</FirstName>
<LastName>Xu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yangyang Xu</PI_FULL_NAME>
<EmailAddress>xuy21@rpi.edu</EmailAddress>
<PI_PHON>5182766902</PI_PHON>
<NSF_ID>000730012</NSF_ID>
<StartDate>06/16/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002430742</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RENSSELAER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002430742</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rensselaer Polytechnic Institute]]></Name>
<CityName>Troy</CityName>
<StateCode>NY</StateCode>
<ZipCode>121803522</ZipCode>
<StreetAddress><![CDATA[110 8th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~32000</FUND_OBLG>
<FUND_OBLG>2018~32000</FUND_OBLG>
<FUND_OBLG>2019~32000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>During the project period, the PI has finished over 10 papers, partly supported by this NSF grant. He also attended a few conferences of SIAM, INFORMS, and Mathematical Optimization Society to disseminate the findings from this project. One RPI PhD student has been mentored to work on some proposed topics of this project, and two undergraduate students have participated in this project by performing numerical simulations of the proposed algorithms. One paper has been published with an undergraduate student.&nbsp;</p> <p><br />The PI has developed several algorithms that were proposed in this project for solving structured optimization problems. Asynchronous block coordinate update methods have been developed and analyzed under more realistic assumptions for block-structured problems. For linearly-constrained problems that have nice block structure, primal-dual block coordinate update methods, along with asynchronous parallel implementation and accelerated version, have been developed. Lower complexity bound results have been established for linearly-constrained convex problems and for bilinear convex-concave saddle-point problems. In addition, deterministic or stochastic gradient-type methods are developed for solving deterministic or stochastic problems with nonlinear functional constraints. One stochastic coordinate update method that was developed by the PI has been applied to the reinforcement learning.</p> <p><br />All the developed algorithms have been coded up in MATLAB and/or C++, and the source code has been released through the PI's personal webpage. In addition, a software package based on the asynchronous parallel coordinate update method has been released over GitHub, with demonstrations on how to run the package and with examples on portfolio optimization, machine learning, nonnegative matrix factorization, and so on. Furthermore, through teaching optimization courses such as ``Computational Optimization'' and ``Optimization Methods in Data Analysis'', the PI has exposed to RPI undergraduate and graduate students several algorithms that are developed from this project.</p><br> <p>            Last Modified: 09/07/2020<br>      Modified by: Yangyang&nbsp;Xu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ During the project period, the PI has finished over 10 papers, partly supported by this NSF grant. He also attended a few conferences of SIAM, INFORMS, and Mathematical Optimization Society to disseminate the findings from this project. One RPI PhD student has been mentored to work on some proposed topics of this project, and two undergraduate students have participated in this project by performing numerical simulations of the proposed algorithms. One paper has been published with an undergraduate student.    The PI has developed several algorithms that were proposed in this project for solving structured optimization problems. Asynchronous block coordinate update methods have been developed and analyzed under more realistic assumptions for block-structured problems. For linearly-constrained problems that have nice block structure, primal-dual block coordinate update methods, along with asynchronous parallel implementation and accelerated version, have been developed. Lower complexity bound results have been established for linearly-constrained convex problems and for bilinear convex-concave saddle-point problems. In addition, deterministic or stochastic gradient-type methods are developed for solving deterministic or stochastic problems with nonlinear functional constraints. One stochastic coordinate update method that was developed by the PI has been applied to the reinforcement learning.   All the developed algorithms have been coded up in MATLAB and/or C++, and the source code has been released through the PI's personal webpage. In addition, a software package based on the asynchronous parallel coordinate update method has been released over GitHub, with demonstrations on how to run the package and with examples on portfolio optimization, machine learning, nonnegative matrix factorization, and so on. Furthermore, through teaching optimization courses such as ``Computational Optimization'' and ``Optimization Methods in Data Analysis'', the PI has exposed to RPI undergraduate and graduate students several algorithms that are developed from this project.       Last Modified: 09/07/2020       Submitted by: Yangyang Xu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
