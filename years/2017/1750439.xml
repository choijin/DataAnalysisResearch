<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Learning Nonverbal Signatures</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/15/2018</AwardEffectiveDate>
<AwardExpirationDate>01/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>550000.00</AwardTotalIntnAmount>
<AwardAmount>474298</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Roger Mailler</SignBlockName>
<PO_EMAI>rmailler@nsf.gov</PO_EMAI>
<PO_PHON>7032927982</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Nonverbal communication is an essential component of our daily life. A quick eyebrow frown from a student will inform the teacher of possible confusion. A tilt of the head may show doubt during negotiation. A patient's smile dynamics can even predict their future recovery. This project will build innovative technologies to allow computers to understand subtle nonverbal behaviors of human users. The main novelty of this project will be in its capacity to learn the inherent variability between individuals on how nonverbal behaviors are expressed. The same emotion can be expressed very differently by different people. A nonverbal signature is how a specific person gestures visually when talking with other people. By recognizing these nonverbal communicative behaviors such as facial expressions, head gestures and eye contact, computers and mobile devices will be able to better understand the user's emotions and affective states. In mental health treatment, the developed technologies have the potential to change how doctors assess disorders with new behavioral objective measures and possibily to predict eventual relapse for the patient. For researchers and animators of virtual characters (e.g., movie studies), the nonverbal signatures will enable an "a la carte" selection of the virtual human nonverbal signature that best aligns with the character's profile and personality. In education and online learning, the student's nonverbal signature will help to assess engagement and perceive affective states related to success in learning.   &lt;br/&gt;&lt;br/&gt;This project will advocate a novel paradigm for learning visual representations of human nonverbal behaviors: a major focus on intra-personal variability followed by analysis of group structures and eventual learning of visual representations generalizable across the population. The research methodology will be motivated by well-studied concepts of idiosyncrasy in nonverbal behavior expressions. The project will introduce the concept of nonverbal signatures which are low-dimensional computational representations of an individual's nonverbal behaviors contextualized by the verbal content and affective context. This project will address four fundamental research challenges: (1) personalized nonverbal embedding -- learning computational representations that summarize the individual variations in nonverbal appearance, (2) learning nonverbal signatures -- contextualizing the nonverbal behaviors with verbal and affective cues to learn more effective representations, (3) signature portfolio analysis -- discovering structure, prototypes and idiosyncrasy from a collection of nonverbal signatures, and (4) generalized nonverbal representations -- learning generalizable nonverbal representations able to adapt to new individuals. These four research aims will be complemented by a comprehensive evaluation plan to include four intermediate evaluations and a continuous overarching evaluation. This research effort will open the door to new sources of human-centric data where accurate interpretation of nonverbal behaviors is essential.</AbstractNarration>
<MinAmdLetterDate>02/05/2018</MinAmdLetterDate>
<MaxAmdLetterDate>02/05/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1750439</AwardID>
<Investigator>
<FirstName>Louis-Philippe</FirstName>
<LastName>Morency</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Louis-Philippe Morency</PI_FULL_NAME>
<EmailAddress>morency@cs.cmu.edu</EmailAddress>
<PI_PHON>3104485323</PI_PHON>
<NSF_ID>000519300</NSF_ID>
<StartDate>02/05/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~128640</FUND_OBLG>
<FUND_OBLG>2019~117400</FUND_OBLG>
<FUND_OBLG>2020~120761</FUND_OBLG>
<FUND_OBLG>2021~107497</FUND_OBLG>
</Award>
</rootTag>
