<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Human agent prediction for autonomous vehicles</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2017</AwardEffectiveDate>
<AwardExpirationDate>01/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>749955.00</AwardTotalIntnAmount>
<AwardAmount>749955</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project results from the fact that it will unlock the potential of autonomous vehicles in dense urban environments in such a way that these vehicles will be safe, effective, and able to operate in environments with a wide range of often-vulnerable road users.  By providing a system for autonomous vehicles to understand the goals and behaviors of humans on the road, the technology will allow autonomous vehicles to react to humans safely and effectively. Without the innovations commercialized with the help of this award, autonomous vehicles will be at best uselessly timid and dangerous additions to urban roads, and at worst a deadly obstacle to the goal of safe, livable cities.  Every autonomous vehicle that is capable enough to be on the market will need to solve the problem that this project is helping to solve.&lt;br/&gt; &lt;br/&gt;This Small Business Innovation Research (SBIR) Phase II project will help to address one of the thorniest problems in autonomous vehicles. The question of how a computer system can gain an understanding of human mental states has occupied researchers and laypeople with an interest in machine intelligence since the coining of the term.  By building an approach based on the leveraging of careful human measurement and state-of-the-art learning algorithms, the innovations developed in this project will help pave a new path towards the computational modeling of cognitive facilities that are central to human intelligence but historically intractable to model using conventional machine learning or computer vision techniques.  In addition to helping solve the central problem of human understanding for autonomous vehicles, the research published from this project will open new avenues for understanding a broad class of problems where the question of "ground truth" about the world is difficult or impossible to answer.</AbstractNarration>
<MinAmdLetterDate>09/19/2017</MinAmdLetterDate>
<MaxAmdLetterDate>09/19/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1738479</AwardID>
<Investigator>
<FirstName>Samuel</FirstName>
<LastName>Anthony</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Samuel E Anthony</PI_FULL_NAME>
<EmailAddress>santhony@perceptiveautomata.com</EmailAddress>
<PI_PHON/>
<NSF_ID>000707993</NSF_ID>
<StartDate>09/19/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Perceptive Automata, Inc.</Name>
<CityName>Cambridge</CityName>
<ZipCode>021421190</ZipCode>
<PhoneNumber>6172991296</PhoneNumber>
<StreetAddress>1 Broadway 5th Fl</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080016534</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PERCEPTIVE AUTOMATA, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>080016534</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Perceptive Automata, Inc.]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021421190</ZipCode>
<StreetAddress><![CDATA[1 Broadway 5th Fl]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~749955</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>One of the hardest problems in highly automated driving is: how do we make <span>autonomous vehicles understand the human state of mind and predict&nbsp;</span>our behaviors?</p> <p>Humans are great at reading non-verbal cues and making intuitive judgments about the people around them. At a busy urban intersection, there are dozens of instances where one person instinctively scans the area and makes immediate and correct assessments about what every other pedestrian, cyclist and driver is going to do. This constant silent communication is the key to safe, smooth and considerate driving. Humans take this ability for granted, but it is this critical ability that machines lack which has thus far made real-world autonomous vehicle deployment impossible.&nbsp;</p> <p>Currently deployed approaches to AV motion planning use physics to locate people and then calculate their trajectory based on past motion and spatial context. This is insufficient for pedestrian motion prediction and leads to many false-starts and stops. In human-dense environments, this creates a nauseating ride for the passenger and leads to many rear ends. It is now&nbsp;<a href="https://www.perceptiveautomata.com/expert-perspectives">widely understood</a>&nbsp;that there will be no meaningful self-driving vehicles in the real world without solving the problem of human understanding.&nbsp;</p> <p><a href="https://www.perceptiveautomata.com/">Perceptive Automata</a>&nbsp;has developed a unique solution to this central problem in automated driving using a combination of cognitive science, computer vision, and machine learning.&nbsp;&nbsp;Our work has garnered global enthusiasm and our company is now viewed as the innovation leader for human behavior prediction AI.&nbsp;</p> <p>In this Phase II SBIR, Perceptive Automata has advanced the pedestrian social attribute modeling approach we created in Phase I into a productized software module called the State of Mind AI or SOMAI. SOMAI has an API to integrate into an autonomous vehicle?s software system, where it processes, in real-time,&nbsp;<span>surrounding object data and outputs the state of mind attributes of pedestrian, cyclist and other motorists, such as ?intention? and ?awareness.? These social attribute signals enable AVs to anticipate human behavior before actual body motion is detected, increasing the safety and smoothness of the riding experience, even in human-dominated road environments.</span></p> <p>The Phase II efforts consisted of a series of major research activities that advanced our&nbsp;automatic social attribute assessment of human behavior for AV and automatic driver assistance systems (ADAS)&nbsp;applications toward a&nbsp;commercial offering:&nbsp;&nbsp;1) the extension of the social attribute modeling approach to cyclist analysis tasks; 2) the development of a fully functional cyclist analysis data processing pipeline; 3) the assessment of useful social attributes in analyzing other motorist behavior; 4) the development of a unified behavioral prediction model that integrates visual and other data from the AV with awareness and intent models; 5) the development of novel, reliable methods for large-scale model evaluation and optimization; 6) packaging and features-testing of SOMAI as a commercializable product, which includes customer software integration and support.</p> <p>Not only have we advanced our technology, but we have also made significant scientific contributions in the areas of computer vision machine learning. This work has resulted in the publication of four research papers, and one additional paper which is currently accepted and awaiting publication. This work has also led to one US patent and 17 pending patent applications.</p> <p>Phase II commercialization efforts focused on building AV industry capital, connections, and credibility. Over the course of the grant period, we successfully acquired $16M in Series A funding and are currently strategizing Series Bfundraising efforts. We worked with two dozen customers and partners to evaluate our product and have deployed the SOMAI module integration with two core customers. Based on the work funded by this grant, Perceptive Automata is now considered a breakthrough technology leader in the field. Of highly automated driving. We were&nbsp;named a&nbsp;<a href="https://www.prweb.com/releases/perceptive_automata_named_technology_pioneer_by_the_world_economic_forum/prweb16413362.htm">2019 Technology Pioneer by the World Economic Forum</a>,&nbsp;<a href="https://aibreakthroughawards.com/2019-winners/">Best Behavioral AI Solution in the 2019 AI Breakthrough Awards</a>, and frequently in&nbsp;<a href="https://www.perceptiveautomata.com/news">international and national publications</a>&nbsp;such as Bloomberg, Forbes, and&nbsp;<a href="https://www.fastcompany.com/90231475/perceptive-automata-helps-self-driving-cars-think-like-humans">Fast Company</a>, on panels during events such as&nbsp;<a href="https://www.youtube.com/watch?v=pg1Mjgf2Uyw&amp;feature=youtu.be">Bloomberg Live</a>&nbsp;and&nbsp;<a href="https://www.youtube.com/watch?v=bWOs2hn7_Bs">SXSW</a>, and on podcasts such as&nbsp;<a href="http://www.autonocast.com/blog/2018/8/2/96-sam-anthony-of-perceptive-automata">Autonocast</a>.</p> <p>In Phase II, Perceptive Automata successfully completed our goal of having a major impact on the AV and automotive safety industries. In the next phase of research, we aim to build out the end-to-end other motorist analysis pipeline and expand customer engagement with SOMAI for pedestrians and cyclists. Our goal in the coming years is to mature our product for large-scale distribution, including extending our core IP and know-how to autonomous driving applications such as automated sidewalk delivery robots and automated worksite robots that have different kinds of human-machine interaction challenges.</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/29/2020<br>      Modified by: Samuel&nbsp;E&nbsp;Anthony</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ One of the hardest problems in highly automated driving is: how do we make autonomous vehicles understand the human state of mind and predict our behaviors?  Humans are great at reading non-verbal cues and making intuitive judgments about the people around them. At a busy urban intersection, there are dozens of instances where one person instinctively scans the area and makes immediate and correct assessments about what every other pedestrian, cyclist and driver is going to do. This constant silent communication is the key to safe, smooth and considerate driving. Humans take this ability for granted, but it is this critical ability that machines lack which has thus far made real-world autonomous vehicle deployment impossible.   Currently deployed approaches to AV motion planning use physics to locate people and then calculate their trajectory based on past motion and spatial context. This is insufficient for pedestrian motion prediction and leads to many false-starts and stops. In human-dense environments, this creates a nauseating ride for the passenger and leads to many rear ends. It is now widely understood that there will be no meaningful self-driving vehicles in the real world without solving the problem of human understanding.   Perceptive Automata has developed a unique solution to this central problem in automated driving using a combination of cognitive science, computer vision, and machine learning.  Our work has garnered global enthusiasm and our company is now viewed as the innovation leader for human behavior prediction AI.   In this Phase II SBIR, Perceptive Automata has advanced the pedestrian social attribute modeling approach we created in Phase I into a productized software module called the State of Mind AI or SOMAI. SOMAI has an API to integrate into an autonomous vehicle?s software system, where it processes, in real-time, surrounding object data and outputs the state of mind attributes of pedestrian, cyclist and other motorists, such as ?intention? and ?awareness.? These social attribute signals enable AVs to anticipate human behavior before actual body motion is detected, increasing the safety and smoothness of the riding experience, even in human-dominated road environments.  The Phase II efforts consisted of a series of major research activities that advanced our automatic social attribute assessment of human behavior for AV and automatic driver assistance systems (ADAS) applications toward a commercial offering:  1) the extension of the social attribute modeling approach to cyclist analysis tasks; 2) the development of a fully functional cyclist analysis data processing pipeline; 3) the assessment of useful social attributes in analyzing other motorist behavior; 4) the development of a unified behavioral prediction model that integrates visual and other data from the AV with awareness and intent models; 5) the development of novel, reliable methods for large-scale model evaluation and optimization; 6) packaging and features-testing of SOMAI as a commercializable product, which includes customer software integration and support.  Not only have we advanced our technology, but we have also made significant scientific contributions in the areas of computer vision machine learning. This work has resulted in the publication of four research papers, and one additional paper which is currently accepted and awaiting publication. This work has also led to one US patent and 17 pending patent applications.  Phase II commercialization efforts focused on building AV industry capital, connections, and credibility. Over the course of the grant period, we successfully acquired $16M in Series A funding and are currently strategizing Series Bfundraising efforts. We worked with two dozen customers and partners to evaluate our product and have deployed the SOMAI module integration with two core customers. Based on the work funded by this grant, Perceptive Automata is now considered a breakthrough technology leader in the field. Of highly automated driving. We were named a 2019 Technology Pioneer by the World Economic Forum, Best Behavioral AI Solution in the 2019 AI Breakthrough Awards, and frequently in international and national publications such as Bloomberg, Forbes, and Fast Company, on panels during events such as Bloomberg Live and SXSW, and on podcasts such as Autonocast.  In Phase II, Perceptive Automata successfully completed our goal of having a major impact on the AV and automotive safety industries. In the next phase of research, we aim to build out the end-to-end other motorist analysis pipeline and expand customer engagement with SOMAI for pedestrians and cyclists. Our goal in the coming years is to mature our product for large-scale distribution, including extending our core IP and know-how to autonomous driving applications such as automated sidewalk delivery robots and automated worksite robots that have different kinds of human-machine interaction challenges.          Last Modified: 04/29/2020       Submitted by: Samuel E Anthony]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
