<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Bridging the Gap Between Theory and Applications: Robust and Scalable Statistical Estimation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>99985.00</AwardTotalIntnAmount>
<AwardAmount>99985</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Major challenges in modern data-rich environment require new statistical algorithms that succeed under realistic scenarios and model assumptions, such as estimation in the distributed setting, ability to handle heavy-tailed data, outliers, and missing observations. Research that will be performed by the Principal Investigator (PI) in the course of this project focuses on two important problems faced by contemporary statistical science: scalability and robustness. The goal of the project is to advance our understanding of statistical techniques that involve (a) high-dimension covariance matrix estimation, and (b) distributed statistical estimation protocols. Obtained results will be of interest to scientists working on theory as well as applications.&lt;br/&gt;&lt;br/&gt;One part of this project aims at answering open questions related to high-dimensional covariance matrix estimation for the heavy-tailed distributions. Such distributions serve as a viable model for data corrupted with outliers, an almost inevitable scenario in applications. Covariance matrix is one of the most fundamental objects in high-dimensional data analysis: many important statistical tools, such as Principal Component Analysis (PCA) and regression analysis, involve covariance estimation as a crucial step. For instance, PCA has striking connections to nonlinear dimension reduction and manifold learning techniques, genetics, computational biology, among many others. However, the assumptions underlying the theoretical analysis of most existing estimators, such as various modifications of the sample covariance matrix, are often restrictive and do not hold for real-world scenarios. Using tools from the random matrix theory,  the PI will develop a new class of robust estimators that are numerically tractable, show good practical performance and enjoy strong theoretical guarantees under much weaker conditions than currently available alternatives. Specifically, the goal of the project is to design estimators that admit tight concentration around the unknown "true" covariance matrix under weak assumptions on the underlying distribution, such as existence of moments of only low order.  Another part of this project is devoted to novel algorithms for scalable estimation that can take advantage of the "divide and conquer" approach. Divide and conquer paradigm assumes that data is stored and analyzed in a distributed way by a cluster consisting of several machines: each of the machines in a cluster works on its own sub-sample while communication among different machines is limited, and final results are obtained by piecing the outcomes of these distributed computations together. The PI will develop a class of new divide and conquer strategies supported by strong theoretical evidence. The project will investigate connections between the distributed estimation strategies and robustness of resulting algorithms -- an important characteristic of large distributed systems.</AbstractNarration>
<MinAmdLetterDate>08/17/2017</MinAmdLetterDate>
<MaxAmdLetterDate>08/17/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1712956</AwardID>
<Investigator>
<FirstName>Stanislav</FirstName>
<LastName>Minsker</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stanislav Minsker</PI_FULL_NAME>
<EmailAddress>minsker@usc.edu</EmailAddress>
<PI_PHON>2137407762</PI_PHON>
<NSF_ID>000737327</NSF_ID>
<StartDate>08/17/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900892532</ZipCode>
<StreetAddress><![CDATA[3620 S. Vermont Ave, KAP 406E]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~99985</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The first goal of this project was to develop new methods for estimating covariance matrices of high-dimensional data, while the second goal was to devise statistical algorithms that can take advantage of the distributed estimation framework.</p> <p>Covariance matrices are of interest due to the fact that they encode the dependency structure of the components of high-dimensional observations. Modern data obtained via unsupervised, automated collection process are often noisy and contain atypical values, commonly referred to as outliers. It is therefore crucial to apply covariance estimation methods that are robust, meaning that they can tolerate the presence of such outliers. Algorithms developed in the course of this project possess this essential characteristic, while being practical at the same time. In addition, the newly developed methods are supported by strong performance guarantees that hold under weak assumptions on the underlying data-generating process. These performance guarantees are based on novel mathematical results for matrix-valued U-statistics, a class of objects of utmost importance in statistical science. The key ideas behind the new techniques have also been extended to yield covariance estimators tailored to covariance matrices of special structure, such as matrices of low rank that correspond to data with low-dimensional intrinsic structure.</p> <p>The majority of statistical estimation methods operate in the "centralized datacenter" framework where all available data are processed on a single machine. On the other hand, distributed estimation protocols assume that data are stored and analyzed by a cluster consisting of several machines (nodes), and each of the machines in a cluster works on its own subset of the data while communication among different nodes is limited. Results obtained in the course of this project characterized robustness properties of such distributed algorithms. Obtained theoretical guarantees go beyond the initial scope of the project and extend to the class of robust empirical risk minimization algorithms, which includes versions of many classical statistical techniques such as regression and maximum likelihood estimation.</p> <p>The project provided training opportunities for students, including a summer research experience for undergraduate students at USC. It resulted in one Ph.D. dissertation in an area related to the main topics of the project. Key outcomes of the project have been disseminated to the research community via publications in leading journals and conference presentations.</p> <p><br /><br /><br /></p><br> <p>            Last Modified: 12/07/2020<br>      Modified by: Stanislav&nbsp;Minsker</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The first goal of this project was to develop new methods for estimating covariance matrices of high-dimensional data, while the second goal was to devise statistical algorithms that can take advantage of the distributed estimation framework.  Covariance matrices are of interest due to the fact that they encode the dependency structure of the components of high-dimensional observations. Modern data obtained via unsupervised, automated collection process are often noisy and contain atypical values, commonly referred to as outliers. It is therefore crucial to apply covariance estimation methods that are robust, meaning that they can tolerate the presence of such outliers. Algorithms developed in the course of this project possess this essential characteristic, while being practical at the same time. In addition, the newly developed methods are supported by strong performance guarantees that hold under weak assumptions on the underlying data-generating process. These performance guarantees are based on novel mathematical results for matrix-valued U-statistics, a class of objects of utmost importance in statistical science. The key ideas behind the new techniques have also been extended to yield covariance estimators tailored to covariance matrices of special structure, such as matrices of low rank that correspond to data with low-dimensional intrinsic structure.  The majority of statistical estimation methods operate in the "centralized datacenter" framework where all available data are processed on a single machine. On the other hand, distributed estimation protocols assume that data are stored and analyzed by a cluster consisting of several machines (nodes), and each of the machines in a cluster works on its own subset of the data while communication among different nodes is limited. Results obtained in the course of this project characterized robustness properties of such distributed algorithms. Obtained theoretical guarantees go beyond the initial scope of the project and extend to the class of robust empirical risk minimization algorithms, which includes versions of many classical statistical techniques such as regression and maximum likelihood estimation.  The project provided training opportunities for students, including a summer research experience for undergraduate students at USC. It resulted in one Ph.D. dissertation in an area related to the main topics of the project. Key outcomes of the project have been disseminated to the research community via publications in leading journals and conference presentations.            Last Modified: 12/07/2020       Submitted by: Stanislav Minsker]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
