<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Gene Golub SIAM Summer School: Data Sparse Approximations and Algorithms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2017</AwardEffectiveDate>
<AwardExpirationDate>12/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>10000.00</AwardTotalIntnAmount>
<AwardAmount>10000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project supports the participation of U.S. based PhD students to participate in the 2017 Gene Golub Society for Industrial and Applied Mathematics (SIAM) Summer School on Data Sparse Approximations and Algorithms, which will be held at Akademie Berlin-Schmockwitz in Germany, May 29 through June 9, 2017.  Detailed information can be found at http://www3.math.tu-berlin.de/numerik/G2S3/index.html. The topic of this summer school is motivated by the observation that in numerous modern applications throughout business, science and engineering, it is extremely challenging to efficiently and stably acquire, analyze, and process massive amounts of data. Recent mathematical advances have shown that massive data sets, and functions associated with them, can often be represented or accurately approximated by only a small number of relevant features; that is, massive data can be represented by a sparse set of features. The summer school will expose PhD students to recent mathematical and computational techniques used in the area of data sparse approximations, and this project ensures participation of well qualified students from U.S. based institutions.&lt;br/&gt;&lt;br/&gt;Techniques from several different mathematical fields have been used and continue to be developed in the context of data sparse representations and approximations. Among them are applied harmonic analysis, approximation theory, convex analysis, frame theory, graph theory, imaging science, inverse problems, probability theory, random matrix theory, reduced order modeling, and tensor analysis. In all applications, the outcome of the modeling, simulation, optimization, or approximation is a linear algebraic problem that encodes the underlying functions, the data, and thus also the resulting sparsity. Together with appropriately chosen regularizations and metrics or norms, a key role in the process is played by the fields of numerical linear algebra and optimization. A solid knowledge of these fields is required for working with, and making further advances in the field of data sparse approximations and algorithms.  The school will consist of four courses over the two-week period of the summer school: Two courses in the first week of the school will focus on the theory of sparse representation and approximation as well as tensor methods, and two courses in the second week will deal with sparse numerical linear algebra as well as optimization methods in the sparse context.  The courses will include lectures as well as computational exercises and small group projects for the participants.</AbstractNarration>
<MinAmdLetterDate>11/22/2016</MinAmdLetterDate>
<MaxAmdLetterDate>11/22/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1712970</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Nagy</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James G Nagy</PI_FULL_NAME>
<EmailAddress>jnagy@emory.edu</EmailAddress>
<PI_PHON>4047275601</PI_PHON>
<NSF_ID>000303676</NSF_ID>
<StartDate>11/22/2016</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Emory University</Name>
<CityName>Atlanta</CityName>
<ZipCode>303224250</ZipCode>
<PhoneNumber>4047272503</PhoneNumber>
<StreetAddress>1599 Clifton Rd NE, 4th Floor</StreetAddress>
<StreetAddress2><![CDATA[1599-001-1BA]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066469933</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>EMORY UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>066469933</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Emory University]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303224250</ZipCode>
<StreetAddress><![CDATA[400 Dowman Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~10000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Overview:</p> <p>The 2017 Gene Golub SIAM Summer School was held at Akademie Berlin-Schmockwitz in Germany, Monday, May 29, 2017, to Friday, June 9, 2017. The topic of the summer school was Data Sparse Approximations and Algorithms, and was taught by four international leading researchers. The school was held in conjunction with 2017 SIAG/LA International Summer School on Numerical Linear Algebra, which is an activity organized by the U.S. based Society of Industrial and Applied Mathematics (SIAM) Activity Group on Linear Algebra. The annual summer school is mainly supported through a generous donation by the estate of Gene Golub, a well known professor at Stanford University from 1962 until 2007. The Gene Golub donation is used support all local expenses for the students, such as accommodation, meals, and facility use. This NSF funding was used to provide travel support for 10 US-based PhD students to participate in the summer school.&nbsp;</p> <p><br />Intellectual Merit:</p> <p>The 21st century is often referred to as the &ldquo;century of big data", which poses serious challenges for scientists to efficiently and stably acquire, and analyze the massive and growing amount information. The intellectual merit of this proposal and the summer school comes from the essential observation that in numerous modern applications throughout science and engineering, data can often be represented or highly accurately approximated by only a small number of relevant features. Many large scale problems coming from the most diverse areas including medicine, materials, or meteorology have become tractable only because of the existence of such data sparse representations or approximations and their exploitation in suitable computational methods. Ground-breaking advances in this context were made in recent years using tensor based methods as well as low rank and low order representations and approximations. These new ground-breaking advances were the topics highlighted in the summer school lectures and exercises.</p> <p><br />Broader Impacts:</p> <p>The NSF funding ensured that 10 US-based PhD students would have the opportunity to receive an interdisciplinary education in Data Sparse Approximations and Algorithms, an area of research that is rapidly advancing in such a way that state-of-the-art techniques are not available in standard text books. The students, which included 5 women, were chosen from 7 different U.S. Universities. These students were exposed to the theoretical foundations of data sparse representation and they interactively participated in projects that combined algorithm design, numerical implementations, and empirical evaluations on real data.</p> <p><br />Outcomes:</p> <p>The students were exposed to the theoretical foundations of data sparse representations, and they interactively participated in projects that combined algorithm design, numerical implementations, and empirical evaluations on real data. The summer school helped to promote the professional development of the students by providing them with lectures by internationally recognized researchers on cutting-edge techniques used for data sparse applications.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/12/2018<br>      Modified by: James&nbsp;G&nbsp;Nagy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Overview:  The 2017 Gene Golub SIAM Summer School was held at Akademie Berlin-Schmockwitz in Germany, Monday, May 29, 2017, to Friday, June 9, 2017. The topic of the summer school was Data Sparse Approximations and Algorithms, and was taught by four international leading researchers. The school was held in conjunction with 2017 SIAG/LA International Summer School on Numerical Linear Algebra, which is an activity organized by the U.S. based Society of Industrial and Applied Mathematics (SIAM) Activity Group on Linear Algebra. The annual summer school is mainly supported through a generous donation by the estate of Gene Golub, a well known professor at Stanford University from 1962 until 2007. The Gene Golub donation is used support all local expenses for the students, such as accommodation, meals, and facility use. This NSF funding was used to provide travel support for 10 US-based PhD students to participate in the summer school.    Intellectual Merit:  The 21st century is often referred to as the "century of big data", which poses serious challenges for scientists to efficiently and stably acquire, and analyze the massive and growing amount information. The intellectual merit of this proposal and the summer school comes from the essential observation that in numerous modern applications throughout science and engineering, data can often be represented or highly accurately approximated by only a small number of relevant features. Many large scale problems coming from the most diverse areas including medicine, materials, or meteorology have become tractable only because of the existence of such data sparse representations or approximations and their exploitation in suitable computational methods. Ground-breaking advances in this context were made in recent years using tensor based methods as well as low rank and low order representations and approximations. These new ground-breaking advances were the topics highlighted in the summer school lectures and exercises.   Broader Impacts:  The NSF funding ensured that 10 US-based PhD students would have the opportunity to receive an interdisciplinary education in Data Sparse Approximations and Algorithms, an area of research that is rapidly advancing in such a way that state-of-the-art techniques are not available in standard text books. The students, which included 5 women, were chosen from 7 different U.S. Universities. These students were exposed to the theoretical foundations of data sparse representation and they interactively participated in projects that combined algorithm design, numerical implementations, and empirical evaluations on real data.   Outcomes:  The students were exposed to the theoretical foundations of data sparse representations, and they interactively participated in projects that combined algorithm design, numerical implementations, and empirical evaluations on real data. The summer school helped to promote the professional development of the students by providing them with lectures by internationally recognized researchers on cutting-edge techniques used for data sparse applications.           Last Modified: 03/12/2018       Submitted by: James G Nagy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
