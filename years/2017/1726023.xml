<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI:  Acquisition of Cutting-Edge GPU and Phi Nodes for the Interdisciplinary UMBC High Performance Computing Facility</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>552353.00</AwardTotalIntnAmount>
<AwardAmount>552353</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alejandro Suarez</SignBlockName>
<PO_EMAI>alsuarez@nsf.gov</PO_EMAI>
<PO_PHON>7032927092</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will expand the interdisciplinary University of Maryland Baltimore County (UMBC) High Performance Computing Facility (HPCF), the community-based, interdisciplinary core facility for scientific computing and research on parallel algorithms at UMBC.  The expansion will support the research projects of 51 researchers from 13 academic departments and research centers across the entire campus, including the areas of Computer Science, Information Systems, Mathematics, Statistics, Physics, Biology, Chemistry, Marine Biotechnology, Environmental Systems, Engineering (Computer, Electrical, Mechanical, Chemical, and Environmental), and research centers focused on environmental research, earth sciences, and imaging research.&lt;br/&gt;&lt;br/&gt;Specifically, the expanded computational facility will comprise a total of 84 compute nodes including cutting-edge NVIDIA GPU accelerators and Intel Xeon Phi KNL processors. The availability of the new resource will give researchers at UMBC the opportunity to increase scientific discovery significantly through the dramatic speedup in their simulation and modeling activities from state-of-the-art CPUs and cutting-edge GPUs and Phi KNL processors. An existing cluster at HPCF has already attracted a broad user base through a winning combination of sufficient hardware, tight integration of student education, freely available user support, and an appropriate usage policy. &lt;br/&gt;&lt;br/&gt;Moreover, the new expanded resources of HPCF will enabled UMBC to develop a powerful synergy between research and education at all levels. Through the project's consulting approach to user support, application researchers and their post-docs, graduate students, and undergraduate students will be exposed to the power of state-of-the-art computing software and hardware, a crucial experience for the future workforce. Synergistic integration of education and research is concretely exemplified by current NSF-funded initiatives at UMBC, including an REU Site on high performance computing, a proposed REU Site in quantitative biology, proposed CyberTraining initiatives, and a growing number of courses that use HPCF. HPCF also actively partners with other efforts on campus, such as the UMBC Meyerhoff Scholarship and the NIH-funded MARC programs, two nationally recognized programs that attract substantial numbers of students from underrepresented groups into the sciences.</AbstractNarration>
<MinAmdLetterDate>08/29/2017</MinAmdLetterDate>
<MaxAmdLetterDate>03/15/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1726023</AwardID>
<Investigator>
<FirstName>Matthias</FirstName>
<LastName>Gobbert</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthias K Gobbert</PI_FULL_NAME>
<EmailAddress>gobbert@umbc.edu</EmailAddress>
<PI_PHON>4104552404</PI_PHON>
<NSF_ID>000485133</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate>08/31/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthias</FirstName>
<LastName>Gobbert</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthias K Gobbert</PI_FULL_NAME>
<EmailAddress>gobbert@umbc.edu</EmailAddress>
<PI_PHON>4104552404</PI_PHON>
<NSF_ID>000485133</NSF_ID>
<StartDate>03/15/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Olano</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marc Olano</PI_FULL_NAME>
<EmailAddress>olano@csee.umbc.edu</EmailAddress>
<PI_PHON>4104553094</PI_PHON>
<NSF_ID>000233938</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jianwu</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jianwu Wang</PI_FULL_NAME>
<EmailAddress>jianwu@umbc.edu</EmailAddress>
<PI_PHON>4104553883</PI_PHON>
<NSF_ID>000567338</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meilin</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meilin Yu</PI_FULL_NAME>
<EmailAddress>mlyu@umbc.edu</EmailAddress>
<PI_PHON>4104553140</PI_PHON>
<NSF_ID>000677375</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate>08/31/2017</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meilin</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meilin Yu</PI_FULL_NAME>
<EmailAddress>mlyu@umbc.edu</EmailAddress>
<PI_PHON>4104553140</PI_PHON>
<NSF_ID>000677375</NSF_ID>
<StartDate>08/31/2017</StartDate>
<EndDate>03/15/2019</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meilin</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meilin Yu</PI_FULL_NAME>
<EmailAddress>mlyu@umbc.edu</EmailAddress>
<PI_PHON>4104553140</PI_PHON>
<NSF_ID>000677375</NSF_ID>
<StartDate>03/15/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Lobo</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>Dr.</PI_SUFX_NAME>
<PI_FULL_NAME>Daniel Lobo</PI_FULL_NAME>
<EmailAddress>lobo@umbc.edu</EmailAddress>
<PI_PHON>4104555726</PI_PHON>
<NSF_ID>000702575</NSF_ID>
<StartDate>08/29/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland Baltimore County</Name>
<CityName>Baltimore</CityName>
<ZipCode>212500002</ZipCode>
<PhoneNumber>4104553140</PhoneNumber>
<StreetAddress>1000 Hilltop Circle</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>061364808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND BALTIMORE COUNTY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland Baltimore County]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212500002</ZipCode>
<StreetAddress><![CDATA[1000 Hilltop Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1189</Code>
<Text>Major Research Instrumentation</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~552353</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The UMBC High Performance Computing Facility (HPCF) is the community-based, interdisciplinary core facility for scientific computing and research on parallel algorithms at UMBC. Started in 2008 by more than 20 researchers from ten academic departments and research centers from all academic colleges at UMBC, it is supported by faculty contributions, federal grants, and the UMBC administration. This MRI grant to a group of 51 researchers from 13 academic departments and research centers has been instrumental in fostering a true campus culture of computing. Since HPCF's inception, hundreds of users have profited from its computing clusters, including undergraduate and graduate students. The users generated over 400 publications, including 150 papers in peer-reviewed journals (including Nature, Science, and other top-tier journals in their fields), 50 refereed conference papers, and 50 theses.</p> <p>This grant from the NSF funded a purchase for about $790k in 2018 that expanded the CPU cluster by 44 nodes with two 18-core Intel Skylake CPUs and 384 GB of memory each and the GPU cluster by one node with four NVIDIA Tesla V100 GPUs connected by NVLink and created an 8-node Big Data cluster with 48 TB disk distributed space across 12 hard drives each.</p> <p>The system administration for HPCF is provided by the UMBC Division of Information Technology. See hpcf.umbc.edu for information on HPCF, extensive usage instructions, and lists of projects and publications. The following research snippets show the wide range of impact of HPCF enabled by this MRI funding.</p> <p>1. The NSF-funded grant <em>CyberTraining: Cross-Training of Researchers in Computing, Applied Mathematics and Atmospheric Sciences using Advanced Cyberinfrastructure Resources</em> (<a href="http://cybertraining.umbc.edu/">cybertraining.umbc.edu</a>), led by Dr. Jianwu Wang (PI) and Dr. Aryya Gangopadhyay (Information Systems), Dr. Matthias K. Gobbert (Mathematics and Statistics), and Dr. Zhibo Zhang from the (Physics), developed a new model for online team-based active-learning training to foster multidisciplinary research and education using advanced cyberinfrastructure (CI) resources and techniques. Using HPCF as computing resource, the initiative trained 58 participants (8 tenure-track faculty, 10 postdocs/scientists, 34 graduate students, and 6 undergraduate students; 27 female and 31 male) in 18 teams, resulting already in 18 technical reports, 14 peer-reviewed papers, three Master theses, and two undergraduate theses.</p> <p>2. The lab of Dr. Daniel Lobo from the Department of Biological Sciences uses HPCF to investigate machine learning methodologies and biophysical mathematical simulations towards the mechanistic understanding of biological growth and form regulation. The large computational capacity of HPCF has made possible the application of systems biology methods to discern the biological control of complex phenotypes. This research has explained the genetic mechanisms signaling planarian regeneration and fission, the role of cell adhesion during cell sorting, intercalation, and involution, and the metabolic dynamic pathways responsible for polysaccharide utilization by microorganisms.</p> <p>3. An interdisciplinary group co-led by Dr. Jianwu Wang from the Department of Information Systems and Dr. Zhibo Zhang from the Department of Physics used HPCF for scalable satellite date aggregation. With the advances of satellite remote sensing techniques, we receive massive amount of satellite observation data for the Earth. One common data processing task is to aggregate satellite observation data from original pixel level to latitude-longitude grid level to easily obtain global information and work with global climate models. The group focuses on how to best aggregate NASA MODIS satellite data products from pixel level to grid level using HPCF. They propose three different approaches of parallel data aggregation (file level, day level, and pixel level) and employ three parallel platforms (Spark, Dask, and MPI) to implement the approaches.</p> <p>4. The group of Dr. Meilin Yu at the Department of Mechanical Engineering used HPCF for high-fidelity computational fluid dynamics simulation of challenging unsteady aerodynamic problems. HPCF's large number of cores enabled the simulation of the laminar-turbulent transition flow over a SD7003 wing with an in-house high-order accurate dynamically load-balanced adaptive implicit large eddy simulation (ILES) flow solver that is parallelized using the Message Passing Interface (MPI).</p> <p>5. The group of Dr. Curtis Menyuk used HPCF to study the use of microresonators to generate broadband frequency combs using dynamical methods. Microresonators are circular optical resonators with diameters of less than 1 cm. The group developed a novel software implementation of dynamical methods to identify a new approach to creating broadband combs. In this approach, periodic waveforms are generated inside the microresonator that are called cnoidal waves.</p> <p>6. The group of Dr. Jerimy Polf at the University of Maryland School of Medicine, in collaboration with the group of Dr. Matthias Gobbert at UMBC, used HPCF to study the application of machine learning to analyze and reduce noise within images captures with a Compton camera of prompt gamma rays emitted from a patient during proton beam radiotherapy. A fully connected neural network was developed and trained to recognize gamma ray interactions in the camera that contribute to the image and those which only contribute noise.</p><br> <p>            Last Modified: 12/21/2020<br>      Modified by: Matthias&nbsp;K&nbsp;Gobbert</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607297285166_CyberTraining_REU_Photo--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607297285166_CyberTraining_REU_Photo--rgov-800width.jpg" title="Group photo of CyberTraining 2020 program"><img src="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607297285166_CyberTraining_REU_Photo--rgov-66x44.jpg" alt="Group photo of CyberTraining 2020 program"></a> <div class="imageCaptionContainer"> <div class="imageCaption">1. Group photo of the 6 REU Supplement funded UMBC undergraduate students, the 4 graduate assistants, and 4 faculty in the 2020 program.</div> <div class="imageCredit">Jianwu Wang</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Group photo of CyberTraining 2020 program</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607297403000_2_DanielLobo--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607297403000_2_DanielLobo--rgov-800width.jpg" title="Two dimensional biophysical simulations of cell sorting"><img src="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607297403000_2_DanielLobo--rgov-66x44.jpg" alt="Two dimensional biophysical simulations of cell sorting"></a> <div class="imageCaptionContainer"> <div class="imageCaption">2. Biophysical simulations of cell sorting by a population of cells expressing either of two CAM types. Asymmetrical homotypic adhesion strengths in the CAM types result in the engulfment of the cells with higher adhesive strength (red) by the cells with lower adhesion strength (green).</div> <div class="imageCredit">Daniel Lobo</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Two dimensional biophysical simulations of cell sorting</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378119710_3_modis_aggregation-speedup--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378119710_3_modis_aggregation-speedup--rgov-800width.jpg" title="Execution speedup evaluation for scalable satellite data aggregation."><img src="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378119710_3_modis_aggregation-speedup--rgov-66x44.jpg" alt="Execution speedup evaluation for scalable satellite data aggregation."></a> <div class="imageCaptionContainer"> <div class="imageCaption">3. Execution speedup evaluation for scalable satellite data aggregation.</div> <div class="imageCredit">Jianwu Wang</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Execution speedup evaluation for scalable satellite data aggregation.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378218396_4_MeilinYu--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378218396_4_MeilinYu--rgov-800width.jpg" title="Flow field from ILES and corresponding order of accuracy distributions"><img src="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378218396_4_MeilinYu--rgov-66x44.jpg" alt="Flow field from ILES and corresponding order of accuracy distributions"></a> <div class="imageCaptionContainer"> <div class="imageCaption">4. Flow field from ILES of laminar-turbulent transition over a SD7003 wing at Reynolds number 60,000, and the corresponding order of accuracy distributions at different wing cross-sections.</div> <div class="imageCredit">Meilin Yu</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Flow field from ILES and corresponding order of accuracy distributions</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378314871_5_drawing--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378314871_5_drawing--rgov-800width.jpg" title="Stable regions for cnoidal waves with different numbers of periods."><img src="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378314871_5_drawing--rgov-66x44.jpg" alt="Stable regions for cnoidal waves with different numbers of periods."></a> <div class="imageCaptionContainer"> <div class="imageCaption">5. Stable regions for cnoidal waves with different numbers of periods inside the microresonator. The figure shows a narrowband cnoidal wave with a large number of periods, eight in this example. Modifying the system parameters makes it possible to obtain a broadband comb.</div> <div class="imageCredit">Curtis Menyuk</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Stable regions for cnoidal waves with different numbers of periods.</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378419830_6_classifications--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378419830_6_classifications--rgov-800width.jpg" title="Compton camera images of gamma rays emitted from a patient."><img src="/por/images/Reports/POR/2020/1726023/1726023_10518937_1607378419830_6_classifications--rgov-66x44.jpg" alt="Compton camera images of gamma rays emitted from a patient."></a> <div class="imageCaptionContainer"> <div class="imageCaption">6. Compton camera images of gamma rays emitted from a patient. Left: Image taken during irradiation of a patient. Center and right: Images after identification of noise in the data by a neural network with nominal and perfect classification, respectively.</div> <div class="imageCredit">Matthias Gobbert</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Matthias&nbsp;K&nbsp;Gobbert</div> <div class="imageTitle">Compton camera images of gamma rays emitted from a patient.</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The UMBC High Performance Computing Facility (HPCF) is the community-based, interdisciplinary core facility for scientific computing and research on parallel algorithms at UMBC. Started in 2008 by more than 20 researchers from ten academic departments and research centers from all academic colleges at UMBC, it is supported by faculty contributions, federal grants, and the UMBC administration. This MRI grant to a group of 51 researchers from 13 academic departments and research centers has been instrumental in fostering a true campus culture of computing. Since HPCF's inception, hundreds of users have profited from its computing clusters, including undergraduate and graduate students. The users generated over 400 publications, including 150 papers in peer-reviewed journals (including Nature, Science, and other top-tier journals in their fields), 50 refereed conference papers, and 50 theses.  This grant from the NSF funded a purchase for about $790k in 2018 that expanded the CPU cluster by 44 nodes with two 18-core Intel Skylake CPUs and 384 GB of memory each and the GPU cluster by one node with four NVIDIA Tesla V100 GPUs connected by NVLink and created an 8-node Big Data cluster with 48 TB disk distributed space across 12 hard drives each.  The system administration for HPCF is provided by the UMBC Division of Information Technology. See hpcf.umbc.edu for information on HPCF, extensive usage instructions, and lists of projects and publications. The following research snippets show the wide range of impact of HPCF enabled by this MRI funding.  1. The NSF-funded grant CyberTraining: Cross-Training of Researchers in Computing, Applied Mathematics and Atmospheric Sciences using Advanced Cyberinfrastructure Resources (cybertraining.umbc.edu), led by Dr. Jianwu Wang (PI) and Dr. Aryya Gangopadhyay (Information Systems), Dr. Matthias K. Gobbert (Mathematics and Statistics), and Dr. Zhibo Zhang from the (Physics), developed a new model for online team-based active-learning training to foster multidisciplinary research and education using advanced cyberinfrastructure (CI) resources and techniques. Using HPCF as computing resource, the initiative trained 58 participants (8 tenure-track faculty, 10 postdocs/scientists, 34 graduate students, and 6 undergraduate students; 27 female and 31 male) in 18 teams, resulting already in 18 technical reports, 14 peer-reviewed papers, three Master theses, and two undergraduate theses.  2. The lab of Dr. Daniel Lobo from the Department of Biological Sciences uses HPCF to investigate machine learning methodologies and biophysical mathematical simulations towards the mechanistic understanding of biological growth and form regulation. The large computational capacity of HPCF has made possible the application of systems biology methods to discern the biological control of complex phenotypes. This research has explained the genetic mechanisms signaling planarian regeneration and fission, the role of cell adhesion during cell sorting, intercalation, and involution, and the metabolic dynamic pathways responsible for polysaccharide utilization by microorganisms.  3. An interdisciplinary group co-led by Dr. Jianwu Wang from the Department of Information Systems and Dr. Zhibo Zhang from the Department of Physics used HPCF for scalable satellite date aggregation. With the advances of satellite remote sensing techniques, we receive massive amount of satellite observation data for the Earth. One common data processing task is to aggregate satellite observation data from original pixel level to latitude-longitude grid level to easily obtain global information and work with global climate models. The group focuses on how to best aggregate NASA MODIS satellite data products from pixel level to grid level using HPCF. They propose three different approaches of parallel data aggregation (file level, day level, and pixel level) and employ three parallel platforms (Spark, Dask, and MPI) to implement the approaches.  4. The group of Dr. Meilin Yu at the Department of Mechanical Engineering used HPCF for high-fidelity computational fluid dynamics simulation of challenging unsteady aerodynamic problems. HPCF's large number of cores enabled the simulation of the laminar-turbulent transition flow over a SD7003 wing with an in-house high-order accurate dynamically load-balanced adaptive implicit large eddy simulation (ILES) flow solver that is parallelized using the Message Passing Interface (MPI).  5. The group of Dr. Curtis Menyuk used HPCF to study the use of microresonators to generate broadband frequency combs using dynamical methods. Microresonators are circular optical resonators with diameters of less than 1 cm. The group developed a novel software implementation of dynamical methods to identify a new approach to creating broadband combs. In this approach, periodic waveforms are generated inside the microresonator that are called cnoidal waves.  6. The group of Dr. Jerimy Polf at the University of Maryland School of Medicine, in collaboration with the group of Dr. Matthias Gobbert at UMBC, used HPCF to study the application of machine learning to analyze and reduce noise within images captures with a Compton camera of prompt gamma rays emitted from a patient during proton beam radiotherapy. A fully connected neural network was developed and trained to recognize gamma ray interactions in the camera that contribute to the image and those which only contribute noise.       Last Modified: 12/21/2020       Submitted by: Matthias K Gobbert]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
