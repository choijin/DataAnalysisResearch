<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>STTR Phase II:  Autonomous Landing of Small Unmanned Aircraft Systems onto Moving Platforms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2018</AwardEffectiveDate>
<AwardExpirationDate>02/28/2021</AwardExpirationDate>
<AwardTotalIntnAmount>748706.00</AwardTotalIntnAmount>
<AwardAmount>1420912</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this project will enable Unmanned Aerial Systems&lt;br/&gt;(UAS or drones) to safely and reliably operate from moving vehicles and moving vessels at sea.&lt;br/&gt;There is an immediate need for this capability in many industries. In commercial fishing, drones&lt;br/&gt;will replace manned aircraft for fish-finding operations, radically reducing cost and risk. In maritime&lt;br/&gt;security, drones will provide surveillance around ships, including locating a ?man-overboard? in&lt;br/&gt;time to save the person?s life. In the oil and gas industry, drones will provide rapid-response to oil&lt;br/&gt;spills by mapping the location and extent of the oil slick, limiting the environmental and economic&lt;br/&gt;damage. In hydrographic surveying, drones will identify and geo-locate navigation aids, at a&lt;br/&gt;fraction of the time and cost of current survey methods. In commercial shipping, drones will&lt;br/&gt;inspect and protect shipping vessels while they are underway. In the transport industry, drones&lt;br/&gt;will delivery packages the ?last mile? from a delivery truck to a customer?s door. In law enforcement&lt;br/&gt;and border security, drones will operate from moving patrol vehicles while officers remain safe&lt;br/&gt;and mobile in the vehicle. These applications are currently difficult or impossible, but will become&lt;br/&gt;radically safer and easier with the proposed technology.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase 2 project will advance the current state&lt;br/&gt;of the art in UAS/drone autonomy, to enable reliable drone operations from moving vehicles and&lt;br/&gt;moving vessels at sea. Shipboard landing is extremely difficult, due to the heaving and rolling of&lt;br/&gt;the ship deck, potential high winds, and the high precision control required during landing. Current&lt;br/&gt;drone technology does not facilitate landing on moving platforms; this prevents their use in&lt;br/&gt;maritime operations, and has become the main barrier to commercialization in this sector. The&lt;br/&gt;proposed research will develop a vision-aided relative navigation system that combines precise&lt;br/&gt;air-to-ship observations with onboard sensor measurements to accurately estimate the relative&lt;br/&gt;state between the drone and the ship. These relative state estimates will be used to dynamically&lt;br/&gt;route and control the drone safely on to the ship deck. Technical feasibility of this approach has&lt;br/&gt;been demonstrated during the Phase I project, which included demonstration of the technology&lt;br/&gt;in a relevant environment. The primary goals of the Phase 2 project are to improve system&lt;br/&gt;reliability, expand the operational envelope, and productize our system. The plan to achieve these&lt;br/&gt;goals includes scientific development paired with extensive testing, validation, and demonstration.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/15/2018</MinAmdLetterDate>
<MaxAmdLetterDate>03/26/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1758678</AwardID>
<Investigator>
<FirstName>Oliver</FirstName>
<LastName>Martin</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Oliver B Martin</PI_FULL_NAME>
<EmailAddress>oliver@planckaero.com</EmailAddress>
<PI_PHON>8588768734</PI_PHON>
<NSF_ID>000832315</NSF_ID>
<StartDate>07/13/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gaemus</FirstName>
<LastName>Collins</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gaemus Collins</PI_FULL_NAME>
<EmailAddress>gaemus@planckaero.com</EmailAddress>
<PI_PHON>8054533122</PI_PHON>
<NSF_ID>000704129</NSF_ID>
<StartDate>03/15/2018</StartDate>
<EndDate>07/13/2020</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Timothy</FirstName>
<LastName>McLain</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Timothy W McLain</PI_FULL_NAME>
<EmailAddress>mclain@byu.edu</EmailAddress>
<PI_PHON>8014226537</PI_PHON>
<NSF_ID>000365157</NSF_ID>
<StartDate>03/15/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Planck Aerosystems Inc</Name>
<CityName>San Diego</CityName>
<ZipCode>921102014</ZipCode>
<PhoneNumber>6192305049</PhoneNumber>
<StreetAddress>2065 Kurtz St.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>53</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA53</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079592990</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PLANCK AEROSYSTEMS INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Office of Research and Creative Activities, BYU]]></Name>
<CityName>Provo</CityName>
<StateCode>UT</StateCode>
<ZipCode>846021043</ZipCode>
<StreetAddress><![CDATA[A-285 ASB, BYU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1505</Code>
<Text>STTR Phase I</Text>
</ProgramElement>
<ProgramElement>
<Code>1591</Code>
<Text>STTR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>019Z</Code>
<Text>Grad Prep APG:Enhan. Experience</Text>
</ProgramReference>
<ProgramReference>
<Code>1591</Code>
<Text>STTR PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>165E</Code>
<Text>SBIR Phase IIB</Text>
</ProgramReference>
<ProgramReference>
<Code>169E</Code>
<Text>SBIR Tech Enhan Partner (TECP)</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8034</Code>
<Text>Hardware Components</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~898447</FUND_OBLG>
<FUND_OBLG>2019~522465</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Autonomous landing of small unmanned aircraft systems (sUAS) onto moving platforms is a deceptively difficult problem for many reasons. The difficulty of the challenge becomes more apparent when one considers manned aviation and the additional training that pilots require to land a fixed wing or rotorcraft on a ship. Doing so requires approximately three times the amount of training compared to operating the same aircraft from fixed, stationary locations. As many pilots will attest, landing on a moving platform is a mentally taxing process. A sUAS, on the other hand, cannot rely on the cognitive load of a skilled and highly training pilot. The landing must be autonomous, which means the system must be robust and intelligent. On a moving platform, no two landings are the same. The system must be able to detection conditions, predict a future state, and adjust immediately. The sUAS must quickly make decisions about what actions to take based on available information. Plus, there is very little room for error, since a mistake could result in not only a hard landing, but the aircraft ending up in the sea for a total loss. Furthermore, the autonomous landing system must be portable to a wide range of different unmanned aircraft, each of which has its own control system and dynamics. Finally, for the solution to be scalable, it must be capable of operating sUAS from vessels without certified flight decks.&nbsp;</p> <p><br />Despite the challenge, there is a massive value derived from an autonomous landing system for sUAS on moving platforms. It enables sUAS mission sets that are not possible without it. Missions include many areas of oceanographic research, emergency response such as search &amp; rescue and oil spill mapping, defense &amp; security operations, and logistics. The logistics application is particularly impactful, as it includes shore-to-ship and ship-to-ship transportation of cargo, documents, essential tools and equipment, and medicines that would otherwise require an arduous and costly deployment of a small boat at sea.&nbsp;</p> <p><br />Planck employed a vision-based localization scheme, coupled with advanced control system and artificial intelligence to address the challenge with great success. The vision-based approach has proven very reliable, and operates without GPS or other interferences. The primary focus was on performance improvements, including the ability to work at night and in fog without the need for GPS or RF beacons. Usability and interface improvements were also a major undertaking, which allowed for the technology to accommodate many different sUAS types. The project supported maturation, adaptation, testing, and integration of the technology into several products and unmanned aircraft. The integration process has been streamlined for repeatable, reliable deployment.&nbsp;</p> <p><br />Commercialization efforts have also proven quite successful. The technology has been used on multiple embedded products, complete sUAS, and third-party systems. End users cover many sectors: Science &amp; Research, Energy, Defense &amp; Security, and Logistics. The commercialization under this project has fostered relationships with unmanned systems and sensor manufacturers, including technology integration and demonstration opportunities for future deployment opportunities.&nbsp;</p> <p><br />The project?s success has broader impacts; it will contribute to the future proliferation of unmanned systems performing valuable tasks in all environments. For example, a new era of unmanned teaming is emerging, where aircraft are deployed from unmanned ground vehicles (UGV) and unmanned surface vehicles (USV). The technology provides a safe and reliable foundation for future vision-based aerial navigation, which is important for autonomous air mobility. GPS or external infrastructure will not always be available or reliable, yet air mobility platforms must be able to continue operations. This is especially true in disaster response scenarios. Autonomous docking for in-orbit refueling or servicing of geosynchronous satellites may be commonplace in the future, and this technology may pave the way. All told, the vision-based navigation technologies that were matured, adapted, and commercialized in this project will have a lasting impact across many sectors.&nbsp;</p><br> <p>            Last Modified: 03/31/2021<br>      Modified by: Oliver&nbsp;B&nbsp;Martin</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233865997_USV_UAS_Team--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233865997_USV_UAS_Team--rgov-800width.jpg" title="UAS-UAV Teaming"><img src="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233865997_USV_UAS_Team--rgov-66x44.jpg" alt="UAS-UAV Teaming"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Unmanned aircraft cooperatively teamed with a unmanned vessel for port security application.</div> <div class="imageCredit">David Twining</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Oliver&nbsp;B&nbsp;Martin</div> <div class="imageTitle">UAS-UAV Teaming</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233940711_TetheredsUASonBoat--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233940711_TetheredsUASonBoat--rgov-800width.jpg" title="Tethered UAS on a vessel"><img src="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617233940711_TetheredsUASonBoat--rgov-66x44.jpg" alt="Tethered UAS on a vessel"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Tethered aircraft deployed from a moving vessel providing a persistent mobile sensor platform</div> <div class="imageCredit">Allan Matthew</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Oliver&nbsp;B&nbsp;Martin</div> <div class="imageTitle">Tethered UAS on a vessel</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234059824_Vision-basednavigation--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234059824_Vision-basednavigation--rgov-800width.jpg" title="Vision-based navigation for UAS"><img src="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234059824_Vision-basednavigation--rgov-66x44.jpg" alt="Vision-based navigation for UAS"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Perspective from unmanned aircraft preparing to land on a small vessel at sea</div> <div class="imageCredit">Josh Wells</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Oliver&nbsp;B&nbsp;Martin</div> <div class="imageTitle">Vision-based navigation for UAS</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234309659_QGCformovingplatforms--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234309659_QGCformovingplatforms--rgov-800width.jpg" title="User interface for mobile operations"><img src="/por/images/Reports/POR/2021/1758678/1758678_10534581_1617234309659_QGCformovingplatforms--rgov-66x44.jpg" alt="User interface for mobile operations"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A graphical user interface can run on any computer or tablet device and provides vehicle-relative tools necessary for operating from moving platforms.</div> <div class="imageCredit">Allan Matthew</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Oliver&nbsp;B&nbsp;Martin</div> <div class="imageTitle">User interface for mobile operations</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Autonomous landing of small unmanned aircraft systems (sUAS) onto moving platforms is a deceptively difficult problem for many reasons. The difficulty of the challenge becomes more apparent when one considers manned aviation and the additional training that pilots require to land a fixed wing or rotorcraft on a ship. Doing so requires approximately three times the amount of training compared to operating the same aircraft from fixed, stationary locations. As many pilots will attest, landing on a moving platform is a mentally taxing process. A sUAS, on the other hand, cannot rely on the cognitive load of a skilled and highly training pilot. The landing must be autonomous, which means the system must be robust and intelligent. On a moving platform, no two landings are the same. The system must be able to detection conditions, predict a future state, and adjust immediately. The sUAS must quickly make decisions about what actions to take based on available information. Plus, there is very little room for error, since a mistake could result in not only a hard landing, but the aircraft ending up in the sea for a total loss. Furthermore, the autonomous landing system must be portable to a wide range of different unmanned aircraft, each of which has its own control system and dynamics. Finally, for the solution to be scalable, it must be capable of operating sUAS from vessels without certified flight decks.    Despite the challenge, there is a massive value derived from an autonomous landing system for sUAS on moving platforms. It enables sUAS mission sets that are not possible without it. Missions include many areas of oceanographic research, emergency response such as search &amp; rescue and oil spill mapping, defense &amp; security operations, and logistics. The logistics application is particularly impactful, as it includes shore-to-ship and ship-to-ship transportation of cargo, documents, essential tools and equipment, and medicines that would otherwise require an arduous and costly deployment of a small boat at sea.    Planck employed a vision-based localization scheme, coupled with advanced control system and artificial intelligence to address the challenge with great success. The vision-based approach has proven very reliable, and operates without GPS or other interferences. The primary focus was on performance improvements, including the ability to work at night and in fog without the need for GPS or RF beacons. Usability and interface improvements were also a major undertaking, which allowed for the technology to accommodate many different sUAS types. The project supported maturation, adaptation, testing, and integration of the technology into several products and unmanned aircraft. The integration process has been streamlined for repeatable, reliable deployment.    Commercialization efforts have also proven quite successful. The technology has been used on multiple embedded products, complete sUAS, and third-party systems. End users cover many sectors: Science &amp; Research, Energy, Defense &amp; Security, and Logistics. The commercialization under this project has fostered relationships with unmanned systems and sensor manufacturers, including technology integration and demonstration opportunities for future deployment opportunities.    The project?s success has broader impacts; it will contribute to the future proliferation of unmanned systems performing valuable tasks in all environments. For example, a new era of unmanned teaming is emerging, where aircraft are deployed from unmanned ground vehicles (UGV) and unmanned surface vehicles (USV). The technology provides a safe and reliable foundation for future vision-based aerial navigation, which is important for autonomous air mobility. GPS or external infrastructure will not always be available or reliable, yet air mobility platforms must be able to continue operations. This is especially true in disaster response scenarios. Autonomous docking for in-orbit refueling or servicing of geosynchronous satellites may be commonplace in the future, and this technology may pave the way. All told, the vision-based navigation technologies that were matured, adapted, and commercialized in this project will have a lasting impact across many sectors.        Last Modified: 03/31/2021       Submitted by: Oliver B Martin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
