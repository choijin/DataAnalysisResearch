<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: Automatically Synthesizing Valid, Personalized, Formative Assessments of CS1 Concepts</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>549857.00</AwardTotalIntnAmount>
<AwardAmount>620027</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amy Baylor</SignBlockName>
<PO_EMAI>abaylor@nsf.gov</PO_EMAI>
<PO_PHON>7032925126</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Millions of people worldwide are trying to learn to code in schools, colleges, universities, and online. To do so successfully, they need significant practice and meaningful feedback that responds to their specific confusions and builds upon the knowledge they already have. Unfortunately, good practice content is challenging to create at scale and skilled teachers capable of providing meaningful feedback are rare and often inaccessible. Moreover, popular online learning technologies only provide a fixed amount of static content and do little to provide meaningful feedback. Because of this, many people give up learning to code, and only those with privileged access to friends, family, mentors, or teachers who can provide this support persist. This limits access to this critical 21st century literacy and ultimately harms the gender, racial, ethnic, and intellectual diversity of our computing workforce. &lt;br/&gt;&lt;br/&gt;This project seeks to address part of this problem, applying advances in programming languages research that enable the creation of infinite amounts of diverse practice content, and advances in machine learning to build models of what learners do and do not know. By applying these two advances in computer science, the project will create a novel online learning technology that automatically generates assessment content, provides detailed immediate feedback about solutions, and uses assessment information of learners' performance to generate more personalized practice that individually targets concepts that learners are struggling to master. In creating such a system, new techniques for generating practice problems and new approaches to modeling learner knowledge of introductory programming concepts will be realized. The project will also explore students' current approach to practice, then deploy the new system into a large introductory classroom setting to experimentally measure its impact on learning and confidence. If the system is effective, the discoveries have the potential to provide learners in a range of settings more effective practice and learning. This may in turn improve both the competency and diversity of learners who further engage in computing education.</AbstractNarration>
<MinAmdLetterDate>07/27/2017</MinAmdLetterDate>
<MaxAmdLetterDate>05/12/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1735123</AwardID>
<Investigator>
<FirstName>Min</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Min Li</PI_FULL_NAME>
<EmailAddress>minli@u.washington.edu</EmailAddress>
<PI_PHON>2066166305</PI_PHON>
<NSF_ID>000486022</NSF_ID>
<StartDate>07/27/2017</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Amy</FirstName>
<LastName>Ko</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amy J Ko</PI_FULL_NAME>
<EmailAddress>ajko@uw.edu</EmailAddress>
<PI_PHON>2065434043</PI_PHON>
<NSF_ID>000510102</NSF_ID>
<StartDate>07/27/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981952350</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave. N.E.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>005Y</Code>
<Text>STEM + Computing (STEM+C) Part</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>019Z</Code>
<Text>Grad Prep APG:Enhan. Experience</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0417</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2017~549857</FUND_OBLG>
<FUND_OBLG>2018~20640</FUND_OBLG>
<FUND_OBLG>2019~16000</FUND_OBLG>
<FUND_OBLG>2020~33530</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-9c79b94e-7fff-1c46-c79b-921b79357a1a">&nbsp;</span></p> <p dir="ltr"><span>Interest in computer science has grown rapidly over the past twenty years, attracting learners to K-12 CS electives, higher education CS majors, private coding bootcamps, and online coding tutorials. When this learning is successful, it has significant potential to empower people to create with software, as well as pursue careers in software development. However, knowing that learning is successful requires careful assessment. Prior to this award, there had been little investigation into how to ensure that assessments of CS knowledge are reliable, valid, unbiased, and feasible to create in light of increasing demand for CS education.</span></p> <p dir="ltr"><span>This project investigated these problems of CS learning assessments, focusing specifically on programming knowledge. The project began by trying to understand what programming knowledge consists of. It contributed three new ideas in this space. First, it found that programming knowledge consists of at least four distinct kinds of knowledge: 1) reading programming language notations, 2) writing semantics in programming language notations, 3) reading templated patterns of computation in a programming language notation, and 4) writing patterns of computation in a programming language notation. Second, it found that programming knowledge also requires knowledge of application programming interfaces, which consists of three distinct kinds of knowledge: 1) knowledge of the domain concepts an API models (e.g., understanding an API that analyzes natural language might require understanding linguistic ideas like &ldquo;parts of speech&rdquo; and grammar); 2) knowledge of the hidden semantic rules that govern API execution, and 3) knowledge of patterns of API composition used to achieve particular goals. Finally, it found that programming knowledge also interacts with design knowledge in two forms: 1) program space design, which involves considering various ways to implement algorithms and data structures to achieve a goal, and 2) problem space design, which involves various ways of conceiving a problem one is addressing by creating new software. These three perspectives reveal the rich and complex space of programming knowledge that one might assess as the underlying construct and lead to important implications in constructing assessment tasks.</span></p> <p dir="ltr"><span>Building upon these theories of programming knowledge, the project explored several aspects of assessing this knowledge. It contributed a new way of procedurally generating assessments of programming language semantics readings skills, allowing future technologies to automatically generate reliable, valid assessments of programming language learning. It contributed guidelines for applying item validity and item bias to CS assessment design and validation. It investigated the impact of situating formative assessments in CS learning, finding that giving learners agency in reflecting on their progress to choose a next learning task does not consistently help with learning. A series of studies about interest development, transfer students, coding bootcamps, student career planning, and the COVID-19 pandemic showed how sociocultural factors in a learning community can strongly shape student perceptions of the value and meaning of assessment on their identities, interests, and professional aspirations.</span></p> <p dir="ltr"><span>The discoveries in this project have broadly impacted CS learning. The project taught more than 60 low-income students of color who were the first in their families to attend college, many of whom are now CS majors in institutions of higher education. The project&rsquo;s innovations in CS assessment have influenced the curriculum and teacher preparation at Code.org, which has impacted hundreds of thousands of students in K-12 CS education settings. The project also engaged 14 undergraduate students in research, 5 of whom pursued doctoral programs to further study CS education.</span></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/05/2020<br>      Modified by: Amy&nbsp;J&nbsp;Ko</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1735123/1735123_10507770_1601571384790_theory--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1735123/1735123_10507770_1601571384790_theory--rgov-800width.jpg" title="A 2 by 2 table of four types of programming knowledge"><img src="/por/images/Reports/POR/2020/1735123/1735123_10507770_1601571384790_theory--rgov-66x44.jpg" alt="A 2 by 2 table of four types of programming knowledge"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The project developed assessment that distinguished between reading and writing programs</div> <div class="imageCredit">Benjamin Xie</div> <div class="imageSubmitted">Amy&nbsp;J&nbsp;Ko</div> <div class="imageTitle">A 2 by 2 table of four types of programming knowledge</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1735123/1735123_10507770_1601579389763_asessment--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1735123/1735123_10507770_1601579389763_asessment--rgov-800width.jpg" title="Graphs portraying the underlying knowledge assessed by an assessment item"><img src="/por/images/Reports/POR/2020/1735123/1735123_10507770_1601579389763_asessment--rgov-66x44.jpg" alt="Graphs portraying the underlying knowledge assessed by an assessment item"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An approach to modeling aspects of a program that assessed particular knowledge of a programming language.</div> <div class="imageCredit">Greg Nelson</div> <div class="imageSubmitted">Amy&nbsp;J&nbsp;Ko</div> <div class="imageTitle">Graphs portraying the underlying knowledge assessed by an assessment item</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Interest in computer science has grown rapidly over the past twenty years, attracting learners to K-12 CS electives, higher education CS majors, private coding bootcamps, and online coding tutorials. When this learning is successful, it has significant potential to empower people to create with software, as well as pursue careers in software development. However, knowing that learning is successful requires careful assessment. Prior to this award, there had been little investigation into how to ensure that assessments of CS knowledge are reliable, valid, unbiased, and feasible to create in light of increasing demand for CS education. This project investigated these problems of CS learning assessments, focusing specifically on programming knowledge. The project began by trying to understand what programming knowledge consists of. It contributed three new ideas in this space. First, it found that programming knowledge consists of at least four distinct kinds of knowledge: 1) reading programming language notations, 2) writing semantics in programming language notations, 3) reading templated patterns of computation in a programming language notation, and 4) writing patterns of computation in a programming language notation. Second, it found that programming knowledge also requires knowledge of application programming interfaces, which consists of three distinct kinds of knowledge: 1) knowledge of the domain concepts an API models (e.g., understanding an API that analyzes natural language might require understanding linguistic ideas like "parts of speech" and grammar); 2) knowledge of the hidden semantic rules that govern API execution, and 3) knowledge of patterns of API composition used to achieve particular goals. Finally, it found that programming knowledge also interacts with design knowledge in two forms: 1) program space design, which involves considering various ways to implement algorithms and data structures to achieve a goal, and 2) problem space design, which involves various ways of conceiving a problem one is addressing by creating new software. These three perspectives reveal the rich and complex space of programming knowledge that one might assess as the underlying construct and lead to important implications in constructing assessment tasks. Building upon these theories of programming knowledge, the project explored several aspects of assessing this knowledge. It contributed a new way of procedurally generating assessments of programming language semantics readings skills, allowing future technologies to automatically generate reliable, valid assessments of programming language learning. It contributed guidelines for applying item validity and item bias to CS assessment design and validation. It investigated the impact of situating formative assessments in CS learning, finding that giving learners agency in reflecting on their progress to choose a next learning task does not consistently help with learning. A series of studies about interest development, transfer students, coding bootcamps, student career planning, and the COVID-19 pandemic showed how sociocultural factors in a learning community can strongly shape student perceptions of the value and meaning of assessment on their identities, interests, and professional aspirations. The discoveries in this project have broadly impacted CS learning. The project taught more than 60 low-income students of color who were the first in their families to attend college, many of whom are now CS majors in institutions of higher education. The project’s innovations in CS assessment have influenced the curriculum and teacher preparation at Code.org, which has impacted hundreds of thousands of students in K-12 CS education settings. The project also engaged 14 undergraduate students in research, 5 of whom pursued doctoral programs to further study CS education.             Last Modified: 10/05/2020       Submitted by: Amy J Ko]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
