<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Development of Selective Attention to Multisensory Information in Human Infants</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>832890.00</AwardTotalIntnAmount>
<AwardAmount>832890</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Vishton</SignBlockName>
<PO_EMAI>pvishton@nsf.gov</PO_EMAI>
<PO_PHON>7032928132</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Studies have found that infants perceive, learn, and remember better when they can simultaneously see and hear the objects and events in their everyday life as opposed to when they can only see or hear them. This project tests the hypothesis that the reason for this is because redundant (i.e., matching) multisensory information elicits greater attention than does either mis-matching multisensory information or unisensory information. The results from this project will provide key insights into infant perception, attention, learning, and memory and, as a result, they will suggest better ways for helping infants acquire critical cognitive and social skills. In addition, the results will provide new insights into the root causes of some developmental disabilities (e.g., autism) which are known to involve impaired perception and attention to multisensory information. Finally, the results from this project will provide a scientific foundation for the design of  tools that will permit clinicians to more effectively detect and ameliorate impaired attention to multisensory information in young children with developmental disabilities, thereby improving their cognitive and social development.&lt;br/&gt;&lt;br/&gt;By around 6 months of age, a previously rudimentary, reflex-like selective attention response system becomes transformed into an endogenously driven selective attention system. This new functionality permits infants to deploy their attention to sources of multisensory redundancy that are of specific interest to them. The project seeks to answer three main questions. First, what mechanisms underlie developmental changes in infant selective attention to sources of multisensory redundancy? Second, how does early experience contribute to developmental changes in selective attention to multisensory redundancy in infancy? Third, how does improving selective attention to multisensory redundancy contribute to information processing across different psychological domains? Infants residing in monolingual and bilingual households will be tested with eye tracking methods to assess attention to multisensory redundancy inherent in talking faces. In some cases, eye tracking will be used  with an intersensory matching procedure to examine infant matching of auditory and visual attributes of speech. In other cases, eye tracking will be used with a habituation/test procedure to investigate learning of multisensory events. The investigators will analyze the temporal distribution of attention as well as the latency of responses. The findings from this project will provide novel insights into the emergence of attention and learning in infancy, clues to maximizing attention and learning in typically developing infants, and clues to improving attention and learning in infants at risk for developmental disabilities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/28/2018</MinAmdLetterDate>
<MaxAmdLetterDate>02/28/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1749507</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Lewkowicz</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David J Lewkowicz</PI_FULL_NAME>
<EmailAddress>david.lewkowicz@yale.edu</EmailAddress>
<PI_PHON>2039982708</PI_PHON>
<NSF_ID>000229053</NSF_ID>
<StartDate>02/28/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<CountyName/>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<CountyName/>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~135891</FUND_OBLG>
</Award>
</rootTag>
