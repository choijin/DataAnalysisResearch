<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Learning Compositional Sparse Coding Models for Natural Images</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The general goal of this project is to develop generative models for images of natural scenes, as well as associated algorithms for unsupervised learning of such models from natural images. The learned models can then be used for image representation and pattern recognition. A particular class of models investigated in this project are the compositional sparse coding models, where the images are represented by automatically learned dictionaries of templates, and each template is a compositional pattern of wavelets that provide sparse coding of the images. The PI and collaborators also investigate related models where the templates are inhomogeneous Markov random fields whose energy functions are defined by the sparse coding wavelets. &lt;br/&gt; &lt;br/&gt;Image understanding is at the hearts of many modern technologies. It is also a major function of human brains. The key to image understanding is automatic discovery of patterns in the images. The goal of this project is to develop methods for learning dictionaries of patterns or "visual words" for representing images of our environments. The learned dictionaries can be very useful for image understanding and object recognition.</AbstractNarration>
<MinAmdLetterDate>07/23/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1310391</AwardID>
<Investigator>
<FirstName>Yingnian</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yingnian Wu</PI_FULL_NAME>
<EmailAddress>ywu@stat.ucla.edu</EmailAddress>
<PI_PHON>3102548332</PI_PHON>
<NSF_ID>000097763</NSF_ID>
<StartDate>07/23/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951554</ZipCode>
<StreetAddress><![CDATA[UCLA Department of Statistics]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~50072</FUND_OBLG>
<FUND_OBLG>2014~49964</FUND_OBLG>
<FUND_OBLG>2015~49964</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project is to learn probabilistic models that enable the computers to generate realistic images, videos and sounds. Such models represent our knowledge about the rich patterns in these signals, such as what a tiger looks like or what a flower looks like. They are probabilistic because they capture both the regularity and variability of the patterns. For example, we can sample from such a model to generate many different images of tigers. Such models enable the computers to learn from the data with little supervision. They can be used for pattern recognition, such as recognizing a tiger; pattern restoration, such as completing a partially occluded face; as well as computer graphics, such as generating photorealistic videos of flowing water.</p> <p>The attached images are generated by our probabilistic models learned from images of similar patterns. Intuitively, our models endow the computers with the gift of imagination, which is important for the computers to perform various tasks.&nbsp;</p> <p>One model we study in this project is a two-layer model, where the first layer consists of wavelets, and the second layer consists of their compositional patterns. Intuitively, the wavelets are like strokes, and their compositions are like the characters or words made up by the strokes. We develop a learning algorithm that can learn meaningful compositional patterns or visual words from image data.&nbsp;</p> <p>We then develop a random field model by composing the stroke-like wavelets. We show that the model can synthesize realistic images. &nbsp;</p> <p>After that, we generalize the above model by replacing the stoke-like wavelets by the more sophisticated non-linear filters or descriptors learned by the convolutional neural network (ConvNet or CNN), which has gained tremendous successes in recent years (it is a key ingredient in the Alpha-Go). The ConvNet is mainly used for the purpose of classification or prediction, such as telling us whether an image is a cat image or a tiger image. Such a ConvNet can be called a discriminator network. In our work, we show that the filters or descriptors in ConvNet can also be used for probabilistic modeling, e.g., telling us what a cat looks like or what a tiger looks like. We may call the resulting model the descriptor network.&nbsp;</p> <p>We then continue to develop the above descriptor network by learning it from scratch, instead of using pre-learned filters or descriptors in an existing discriminator network. We investigate the theoretical properties of the descriptor network. We show that it can be derived from the discriminator network. We also show that it has an auto-encoding structure, where the filters can be used to reconstruct the observed images.&nbsp;</p> <p>We also study a probabilistic model called the generator network that has explicit latent factors. These latent factors generate the signals by a ConvNet. We develop an alternating back-propagation algorithm to train such a generator network. We show that our algorithm is particularly suitable for learning from incomplete or indirect data, such as face images with a large percentage of pixels occluded or masked.&nbsp;</p> <p>More recently, we develop a cooperative training algorithm to train both the descriptor network and the generator network simultaneously, by letting the two networks borrow strengths from each other.&nbsp;</p> <p>We are currently further developing both the descriptor network and the generator network, and apply them to a variety of scientific problems.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/26/2016<br>      Modified by: Yingnian&nbsp;Wu</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296720992_flower--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296720992_flower--rgov-800width.jpg" title="flower"><img src="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296720992_flower--rgov-66x44.jpg" alt="flower"></a> <div class="imageCaptionContainer"> <div class="imageCaption">image generated by our model</div> <div class="imageCredit">Lu, Zhu, Wu</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yingnian&nbsp;Wu</div> <div class="imageTitle">flower</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296798574_tiger--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296798574_tiger--rgov-800width.jpg" title="tiger"><img src="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296798574_tiger--rgov-66x44.jpg" alt="tiger"></a> <div class="imageCaptionContainer"> <div class="imageCaption">image generated by our model</div> <div class="imageCredit">Lu, Zhu, Wu</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yingnian&nbsp;Wu</div> <div class="imageTitle">tiger</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296861534_cup--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296861534_cup--rgov-800width.jpg" title="cup"><img src="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296861534_cup--rgov-66x44.jpg" alt="cup"></a> <div class="imageCaptionContainer"> <div class="imageCaption">image generated by our model</div> <div class="imageCredit">Lu, Zhu, Wu</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yingnian&nbsp;Wu</div> <div class="imageTitle">cup</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296935280_ivy--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296935280_ivy--rgov-800width.jpg" title="ivy"><img src="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477296935280_ivy--rgov-66x44.jpg" alt="ivy"></a> <div class="imageCaptionContainer"> <div class="imageCaption">image generated by our model</div> <div class="imageCredit">Xie, Lu, Zhu, Wu</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yingnian&nbsp;Wu</div> <div class="imageTitle">ivy</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477297013740_water--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477297013740_water--rgov-800width.jpg" title="water"><img src="/por/images/Reports/POR/2016/1310391/1310391_10260435_1477297013740_water--rgov-66x44.jpg" alt="water"></a> <div class="imageCaptionContainer"> <div class="imageCaption">image generated by our model</div> <div class="imageCredit">Xie, Lu, Zhu, Wu</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yingnian&nbsp;Wu</div> <div class="imageTitle">water</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project is to learn probabilistic models that enable the computers to generate realistic images, videos and sounds. Such models represent our knowledge about the rich patterns in these signals, such as what a tiger looks like or what a flower looks like. They are probabilistic because they capture both the regularity and variability of the patterns. For example, we can sample from such a model to generate many different images of tigers. Such models enable the computers to learn from the data with little supervision. They can be used for pattern recognition, such as recognizing a tiger; pattern restoration, such as completing a partially occluded face; as well as computer graphics, such as generating photorealistic videos of flowing water.  The attached images are generated by our probabilistic models learned from images of similar patterns. Intuitively, our models endow the computers with the gift of imagination, which is important for the computers to perform various tasks.   One model we study in this project is a two-layer model, where the first layer consists of wavelets, and the second layer consists of their compositional patterns. Intuitively, the wavelets are like strokes, and their compositions are like the characters or words made up by the strokes. We develop a learning algorithm that can learn meaningful compositional patterns or visual words from image data.   We then develop a random field model by composing the stroke-like wavelets. We show that the model can synthesize realistic images.    After that, we generalize the above model by replacing the stoke-like wavelets by the more sophisticated non-linear filters or descriptors learned by the convolutional neural network (ConvNet or CNN), which has gained tremendous successes in recent years (it is a key ingredient in the Alpha-Go). The ConvNet is mainly used for the purpose of classification or prediction, such as telling us whether an image is a cat image or a tiger image. Such a ConvNet can be called a discriminator network. In our work, we show that the filters or descriptors in ConvNet can also be used for probabilistic modeling, e.g., telling us what a cat looks like or what a tiger looks like. We may call the resulting model the descriptor network.   We then continue to develop the above descriptor network by learning it from scratch, instead of using pre-learned filters or descriptors in an existing discriminator network. We investigate the theoretical properties of the descriptor network. We show that it can be derived from the discriminator network. We also show that it has an auto-encoding structure, where the filters can be used to reconstruct the observed images.   We also study a probabilistic model called the generator network that has explicit latent factors. These latent factors generate the signals by a ConvNet. We develop an alternating back-propagation algorithm to train such a generator network. We show that our algorithm is particularly suitable for learning from incomplete or indirect data, such as face images with a large percentage of pixels occluded or masked.   More recently, we develop a cooperative training algorithm to train both the descriptor network and the generator network simultaneously, by letting the two networks borrow strengths from each other.   We are currently further developing both the descriptor network and the generator network, and apply them to a variety of scientific problems.                          Last Modified: 10/26/2016       Submitted by: Yingnian Wu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
