<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: A Compositional Approach to Video Segmentation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>483443.00</AwardTotalIntnAmount>
<AwardAmount>499443</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is pursuing a novel strategy for video segmentation based on the decomposition of a video into multiple overlapping segments of pixels, and the subsequent composition of these segments into hypotheses about the existence of objects within the video. Given an input video, this approach produces a set of spatio-temporal pixel regions as its output, where the set of output regions has a high degree of overlap with the objects that are present in the video. The project further develops methods for semantic segmentation, occlusion analysis, and activity recognition which can exploit a segment-based video representation. The basis for the approach is a statistical framework known as composite likelihood, which implicitly models the joint distribution of a random vector through distributions of low-dimensional statistics on overlapping subsets of variables. This statistical model is ideally-suited to describing video objects as a collection of multiple overlapping segments. Using this framework, methods are being developed to track overlapping segments within a video and generate object hypotheses. Additional efforts are aimed at improving the computational efficiency of the approach in order to address applications in on-line video analysis.&lt;br/&gt;&lt;br/&gt;The resulting algorithms yield improved performance in video object segmentation and tracking, and provide new approaches to content-based video categorization and retrieval, for unstructured video collections such as those found on YouTube. The project is producing a novel publicly-available dataset containing fine-grained ground truth video object segmentations, in order to facilitate research activities in video analysis. The project is integrated with education and outreaches high school students to research in STEM.</AbstractNarration>
<MinAmdLetterDate>09/19/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/13/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320348</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Rehg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James Rehg</PI_FULL_NAME>
<EmailAddress>rehg@cc.gatech.edu</EmailAddress>
<PI_PHON>4048949105</PI_PHON>
<NSF_ID>000257071</NSF_ID>
<StartDate>09/19/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fuxin</FirstName>
<LastName>Li</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fuxin Li</PI_FULL_NAME>
<EmailAddress>lif@eecs.oregonstate.edu</EmailAddress>
<PI_PHON>4049061899</PI_PHON>
<NSF_ID>000637562</NSF_ID>
<StartDate>09/19/2013</StartDate>
<EndDate>07/13/2016</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320420</ZipCode>
<StreetAddress><![CDATA[225 North Ave NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~483443</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project addressed the problem of video segmentation, which takes an input video and organizes the content so that the pixels corresponding to individual objects are grouped together over time as they move through the video. Many tools exist for image segmentation, such as the Photoshop Lasso Tool, but video segmentation is much more challenging due to the complexity of moving objects which can change size and appear and disappear over time. Such a video segmentation tool would have broad practical applications in areas such as video editing and target tracking for video surveillance.&nbsp;</p> <p>This project developed a novel computational approach to video segmentation which efficiently generated a large number of object proposals in each frame and then combined them over time to form extended video tubes containing objects of interest. Our initial approach used methods from combinatorial optimization to efficiently search over the set of proposals. In later work, we developed a novel deep learning architecture which generated spatiotemporal region proposals containing objects of interest. We also developed a novel deep learning approach for multi-target tracking which addressed the problem of tracking objects in video as they move through occlusions. Our findings were published in top computer vision conferences such as the IEEE Conference on Computer Vision and Pattern Recognition and IEEE International Conference on Computer Vision.</p><br> <p>            Last Modified: 07/17/2019<br>      Modified by: James&nbsp;Rehg</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project addressed the problem of video segmentation, which takes an input video and organizes the content so that the pixels corresponding to individual objects are grouped together over time as they move through the video. Many tools exist for image segmentation, such as the Photoshop Lasso Tool, but video segmentation is much more challenging due to the complexity of moving objects which can change size and appear and disappear over time. Such a video segmentation tool would have broad practical applications in areas such as video editing and target tracking for video surveillance.   This project developed a novel computational approach to video segmentation which efficiently generated a large number of object proposals in each frame and then combined them over time to form extended video tubes containing objects of interest. Our initial approach used methods from combinatorial optimization to efficiently search over the set of proposals. In later work, we developed a novel deep learning architecture which generated spatiotemporal region proposals containing objects of interest. We also developed a novel deep learning approach for multi-target tracking which addressed the problem of tracking objects in video as they move through occlusions. Our findings were published in top computer vision conferences such as the IEEE Conference on Computer Vision and Pattern Recognition and IEEE International Conference on Computer Vision.       Last Modified: 07/17/2019       Submitted by: James Rehg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
