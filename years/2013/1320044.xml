<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Towards Cost-Efficient Guaranteed Performance Multicast in Fat-Tree Data Center Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Massive modern data centers consisting of tens of thousands of servers, such as Microsoft's Azure platform, Google's App engine, and Amazon's EC2 platform, have emerged to form the backbone of a variety of powerful distributed computing frameworks.  Meanwhile, many companies are moving their services such as e-commerce, scientific computing and social networking to the cloud, due to its ability to offer scalable and elastic computing and storage services. In such large-scale distributed computing frameworks, efficient communication is often required among huge datasets stored in tens of thousands of servers across a data center. The data center network (DCN) that connects different servers would become the bottleneck of the system, and its performance is essential to the successful operation of a data center. On the other hand, many online applications and back-end infrastructural computations hosted by data centers require one-to-many or multicast communication from a server to a group of servers. This research aims to investigate the fundamental and challenging issues faced in building cost-efficient multicast data center networks with guaranteed performance. As cloud computing is penetrating into all aspects of society, this research will have a profound impact on society and help change the world. &lt;br/&gt;&lt;br/&gt;The objective of this research is to design cost-efficient multicast fat-tree data center networks (DCNs) with guaranteed performance through exploring some unique novel features and techniques in data centers. The project combines theoretical analysis, algorithm design, network optimization, simulation, and prototyping techniques to provide a comprehensive working solution that enables high performance multicast in fat-tree DCNs. More specifically, the research focuses on following closely coupled issues: (1) cost-efficient provisioning of fat-tree DCNs to deploy guaranteed-bandwidth multicast by exploring server redundancy and link oversubscription in data centers; (2) leveraging the OpenFlow framework to develop practical multicast scheduling algorithms that ensure traffic load balance and efficient network utilization under volatile data center traffic; (3) employing virtual machine technology to offer multicast with differentiated bandwidth guarantees tailored to application-specific demand; (4) conducting a comprehensive performance evaluation through extensive simulations and implementation of proposed schemes in a network prototype. This research hopes to impact fundamental design principles of high performance multicast fat-tree DCNs. The outcome of this research has the potential to boost the performance of cloud computing applications currently hosted in data centers, and to facilitate cloud adoption for future applications that rely on group communication and demand predictable high bandwidth. A project goal is to train graduate students and promote the participation of female engineering students. The important findings of this project are to be disseminated to the research community by way of conferences, journals and web site access.</AbstractNarration>
<MinAmdLetterDate>07/25/2013</MinAmdLetterDate>
<MaxAmdLetterDate>11/28/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320044</AwardID>
<Investigator>
<FirstName>Yuanyuan</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yuanyuan Yang</PI_FULL_NAME>
<EmailAddress>yuanyuan.yang@stonybrook.edu</EmailAddress>
<PI_PHON>6316328474</PI_PHON>
<NSF_ID>000234042</NSF_ID>
<StartDate>07/25/2013</StartDate>
<EndDate>11/28/2017</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fan</FirstName>
<LastName>Ye</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fan Ye</PI_FULL_NAME>
<EmailAddress>fan.ye@stonybrook.edu</EmailAddress>
<PI_PHON>6316328393</PI_PHON>
<NSF_ID>000671755</NSF_ID>
<StartDate>11/28/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>117942350</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~450000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Project Outcomes<br />CCF-1320044 (fat-tree)<br /><br />Today&rsquo;s data centers are the foundations of almost all the day-to-day cloud computing, from personal banking to social network, from commercial services to scientific applications. The key to design and deploy a data center is the fabric which interconnects the servers, known as a data center network. This project focuses on the design issues in data center networks.<br />The most commonly seen problem of any networks is the congestion control, the same is true for data center networks. Similar to traffic jam, network congestion in data center networks is caused by the large amount of traffic. In order to solve this problem, we elaborately designed traffic scheduling algorithms for data center networks. The algorithms select the network devices carefully, so that the traffic can be routed smartly. Using our algorithms, the traffic not only uses less network resources, but also generates less interference. Moreover, the algorithms run very fast, which can be used for on-line scheduling.</p> <p><br />The cost of the data center networks contributes to a considerable proportion of the budget of a data center. In this project, we managed to reduce the cost of data center networks, but without hurting the performance of them. We proposed several effective approaches to reduce the cost. First, we noticed that the servers in data centers always have backups, or redundancy, for fault tolerance considerations. We can utilize this server redundancy to reduce the number of network devices. Using our approaches, the higher the redundancy level is, the more we can save on the cost of the network. Second, for each computing task running in the data centers, we assign its servers in a systematic manner so that the servers are located in a small vicinity. Moreover, we can even migrate a server from one location to another by software, so that we can take advantage of the structural features of the network. In this way, the mutual traffic among the collaborating servers can be routed efficiently, and less network devices are required in our data center networks. Third, we made some theoretical breakthrough on the general design of interconnection networks. After decades&rsquo; of other researchers efforts, we have moved one step further on the way to improve the performance and reduce the cost of general multistage interconnect networks. Our design achieves record low costs comparing to its predecessors, which can be used to guide the design of future data center networks.</p> <p><br />Furthermore, we have designed several new architectures for data center networks to meet the ever-changing demand of cloud computing. First, we designed an architecture which is featured by its ease of expanding. In other words, when we need to resize the network for larger capacity, there is no need to alter the existing system, but only to add new network devices into it. This architecture is also featured by its short diameter, which means the servers can also reach each other by a small number of hops. Second, we designed an architecture which is flexible in the sense that the band- width provisioning can be quantitatively tailored before deployment. Moreover, because of this flexibility, the network devices can be rearranged so that the network delivers higher performance.<br /><br />In this way, existing network devices can be reused in each upgrading cycle, instead of purchasing newer generations of products. Third, optical fiber communication is introduced to data center networks so that we can make use of its significant advantage in bandwidth capacity and power efficiency. But conventional (electrical) networks and optical networks are fundamentally different in so many ways that coordinating and collaborating the configuration of both networks is critical to reach the full potential of the hybrid network. We designed an algorithm to configure both of them in a complementary and time-efficient manner so that we can enjoy the strengths of two types of the networks at the same time.</p><br> <p>            Last Modified: 10/30/2018<br>      Modified by: Fan&nbsp;Ye</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Project Outcomes CCF-1320044 (fat-tree)  Today?s data centers are the foundations of almost all the day-to-day cloud computing, from personal banking to social network, from commercial services to scientific applications. The key to design and deploy a data center is the fabric which interconnects the servers, known as a data center network. This project focuses on the design issues in data center networks. The most commonly seen problem of any networks is the congestion control, the same is true for data center networks. Similar to traffic jam, network congestion in data center networks is caused by the large amount of traffic. In order to solve this problem, we elaborately designed traffic scheduling algorithms for data center networks. The algorithms select the network devices carefully, so that the traffic can be routed smartly. Using our algorithms, the traffic not only uses less network resources, but also generates less interference. Moreover, the algorithms run very fast, which can be used for on-line scheduling.   The cost of the data center networks contributes to a considerable proportion of the budget of a data center. In this project, we managed to reduce the cost of data center networks, but without hurting the performance of them. We proposed several effective approaches to reduce the cost. First, we noticed that the servers in data centers always have backups, or redundancy, for fault tolerance considerations. We can utilize this server redundancy to reduce the number of network devices. Using our approaches, the higher the redundancy level is, the more we can save on the cost of the network. Second, for each computing task running in the data centers, we assign its servers in a systematic manner so that the servers are located in a small vicinity. Moreover, we can even migrate a server from one location to another by software, so that we can take advantage of the structural features of the network. In this way, the mutual traffic among the collaborating servers can be routed efficiently, and less network devices are required in our data center networks. Third, we made some theoretical breakthrough on the general design of interconnection networks. After decades? of other researchers efforts, we have moved one step further on the way to improve the performance and reduce the cost of general multistage interconnect networks. Our design achieves record low costs comparing to its predecessors, which can be used to guide the design of future data center networks.   Furthermore, we have designed several new architectures for data center networks to meet the ever-changing demand of cloud computing. First, we designed an architecture which is featured by its ease of expanding. In other words, when we need to resize the network for larger capacity, there is no need to alter the existing system, but only to add new network devices into it. This architecture is also featured by its short diameter, which means the servers can also reach each other by a small number of hops. Second, we designed an architecture which is flexible in the sense that the band- width provisioning can be quantitatively tailored before deployment. Moreover, because of this flexibility, the network devices can be rearranged so that the network delivers higher performance.  In this way, existing network devices can be reused in each upgrading cycle, instead of purchasing newer generations of products. Third, optical fiber communication is introduced to data center networks so that we can make use of its significant advantage in bandwidth capacity and power efficiency. But conventional (electrical) networks and optical networks are fundamentally different in so many ways that coordinating and collaborating the configuration of both networks is critical to reach the full potential of the hybrid network. We designed an algorithm to configure both of them in a complementary and time-efficient manner so that we can enjoy the strengths of two types of the networks at the same time.       Last Modified: 10/30/2018       Submitted by: Fan Ye]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
