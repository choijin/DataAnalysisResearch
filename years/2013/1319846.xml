<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: RUI: AIR: Automatic Idiom Recognition</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>01/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>176514.00</AwardTotalIntnAmount>
<AwardAmount>176514</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The main goal of this research project is to develop a language independent method for automatic idiom recognition. Idiomatic expressions, such as 'a blessing in disguise' and 'kick the bucket' are plentiful in everyday language, though they remain mysterious, as it is not clear exactly how people learn and understand them. There is no single agreed-upon definition of idiom that covers all members of this class, but idioms tend to be relatively fixed in grammatical form and meaning, but with relatively little predictability in the relation between form and meaning. Also, many idiomatic expressions can appear with both literal, i.e. fully predictable, interpretations given their form -- compare 'The little girl made a face at her mother.' (idiomatic) vs. 'The little girl made a face on the snowman using a carrot and two buttons.' (literal) As a result, idioms present great challenges for a variety of natural language processing applications, including machine translation systems, which often do not detect idiomatic language. To address these challenges, an algorithm is proposed that neither relies on target idiom types, lexicons, or large manually annotated corpora, nor limits the search space by a particular type of linguistic construction. The starting point is that idioms are semantic outliers that violate cohesive structure, especially in local contexts. The following properties are quantified and are incorporated into the outlier detection algorithm: 1) lack of compositionality comparing to literal expressions or other types of collocations; 2) violation of local cohesive ties, so that they tend to be semantically distant from the local topics; 3) while not all semantic outliers are idioms, non-compositional semantic outliers are likely to be idiomatic; 4) idiomaticity is not a binary property; rather, idioms fall on the continuum from being compositional to being partly unanalyzable to completely non-compositional.&lt;br/&gt;&lt;br/&gt;This research contributes to the better understanding of idiomatic language, to the computational treatment of such phenomena and, with the creation of high quality, publicly available linguistic resources annotated for idioms, to the facilitation of machine learning research and big data science. Additional benefits include efficient algorithms for computing compositionality and topicality from large corpora, interesting new generalizations about the nature of figurative language, and the training of a cadre of undergraduate and graduate students in highly practical work on a difficult interdisciplinary problem.</AbstractNarration>
<MinAmdLetterDate>07/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>03/01/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1319846</AwardID>
<Investigator>
<FirstName>Jing</FirstName>
<LastName>Peng</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jing Peng</PI_FULL_NAME>
<EmailAddress>pengj@mail.montclair.edu</EmailAddress>
<PI_PHON>9736557975</PI_PHON>
<NSF_ID>000095160</NSF_ID>
<StartDate>07/29/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Anna</FirstName>
<LastName>Feldman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Anna Feldman</PI_FULL_NAME>
<EmailAddress>feldmana@mail.montclair.edu</EmailAddress>
<PI_PHON>9736554128</PI_PHON>
<NSF_ID>000277026</NSF_ID>
<StartDate>07/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Montclair State University</Name>
<CityName>Montclair</CityName>
<ZipCode>070431624</ZipCode>
<PhoneNumber>9736556923</PhoneNumber>
<StreetAddress>1 Normal Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ11</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>053506184</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MONTCLAIR STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Montclair State University]]></Name>
<CityName>Montclair</CityName>
<StateCode>NJ</StateCode>
<ZipCode>070431624</ZipCode>
<StreetAddress><![CDATA[1 Normal Avenue, Schmitt Hall 24]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ11</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~176514</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Over the decades, humans have been learning computer language. Natural Language Processing (NLP) means computers are now learning how humans use language, i.e., the comprehension by computers of the structure and meaning of human languages, allowing users to interact with computers using natural sentences.&nbsp; This task is not easy. One of the challenges is to "understand" meaning, e.g., draw inferences, derive sentiment relations, understand figurative language.</p> <p>This project&nbsp; has been concerned with developing an algorithm for detecting idiomatic expressions. Many idiomatic expressions are ambiguous. Ambiguities in semantics arise when multiple interpretations are possible. For example, hit the roof can be interpreted literally or idiomatically depending on the context: <em>sales hit the roof</em> vs.<em> hit the roof of the car</em>.&nbsp;&nbsp;</p> <p>The research team has explored various linguistic properties of idiomatic expressions cross-linguistically. In our earlier work, we approached the problem as outlier detection: literal expressions are semantically related to the rest of the context, while words that constitute an idiom appear inconsistent with the rest of the context. Our technique incorporated the following observations: (1) A sequence with literal meaning has many neighbors, whereas a figurative one has few. (2) Idiomatic expressions should demonstrate low semantic proximity between the words composing them. (3) Idiomatic expressions should demonstrate low semantic proximity between the expression and the preceding and subsequent segments.&nbsp;</p> <p>Later we refined our hypothesis and decided to work with text at the topic level structure. Informally, topics are just clusters of similar words. A document usually contains several topics. The idea is that topic words in a given text segment, such as a paragraph, are less likely to be a part of an idiomatic expression. Our additional hypothesis is that contexts in which idioms occur, typically, are more affective and therefore, we incorporate simple sentiment analysis, focusing on the intensity of emotions. This approach can be still viewed as outlier detection. This approach allowed us to differentiate idioms from literals using local semantic contexts with better accuracy.</p> <p>We further developed our approach and captured the intuition about cohesive ties, idioms and local context by using a vector representation of words, i.e., we created a representation for words that capture their meaning, semantic relationships and the different types of contexts they are used in and used it in our classification task. The performance results have improved significantly. We applied our approach to English and Russian, the two languages from two different language families, Germanic and Slavic, respectively, and whose structural and morphological properties are different enough to test if our method is (relatively) language-independent. Our experimental results were positive.&nbsp;</p> <p>The results of this study is a method for idiom detection that does not rely on resource-heavy linguistic technology, such as syntactic parsing, part-of-speech tagging or manual annotation. Our algorithm manages to capture the contextual differences in which literal and idiomatic expressions occur. This technology can be used in many other applications, such as machine translation, language understanding systems, sentiment and emotion analysis, among others.&nbsp;</p> <p>A number of undergraduate and graduate students had the opportunity to participate in active research and gain experience in working collaboratively on an interdisciplinary problem. The project involved students from a variety of disciplines: linguistics, computer science, literature, and mathematics.&nbsp;<br /><br /></p><br> <p>            Last Modified: 06/01/2018<br>      Modified by: Anna&nbsp;Feldman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Over the decades, humans have been learning computer language. Natural Language Processing (NLP) means computers are now learning how humans use language, i.e., the comprehension by computers of the structure and meaning of human languages, allowing users to interact with computers using natural sentences.  This task is not easy. One of the challenges is to "understand" meaning, e.g., draw inferences, derive sentiment relations, understand figurative language.  This project  has been concerned with developing an algorithm for detecting idiomatic expressions. Many idiomatic expressions are ambiguous. Ambiguities in semantics arise when multiple interpretations are possible. For example, hit the roof can be interpreted literally or idiomatically depending on the context: sales hit the roof vs. hit the roof of the car.    The research team has explored various linguistic properties of idiomatic expressions cross-linguistically. In our earlier work, we approached the problem as outlier detection: literal expressions are semantically related to the rest of the context, while words that constitute an idiom appear inconsistent with the rest of the context. Our technique incorporated the following observations: (1) A sequence with literal meaning has many neighbors, whereas a figurative one has few. (2) Idiomatic expressions should demonstrate low semantic proximity between the words composing them. (3) Idiomatic expressions should demonstrate low semantic proximity between the expression and the preceding and subsequent segments.   Later we refined our hypothesis and decided to work with text at the topic level structure. Informally, topics are just clusters of similar words. A document usually contains several topics. The idea is that topic words in a given text segment, such as a paragraph, are less likely to be a part of an idiomatic expression. Our additional hypothesis is that contexts in which idioms occur, typically, are more affective and therefore, we incorporate simple sentiment analysis, focusing on the intensity of emotions. This approach can be still viewed as outlier detection. This approach allowed us to differentiate idioms from literals using local semantic contexts with better accuracy.  We further developed our approach and captured the intuition about cohesive ties, idioms and local context by using a vector representation of words, i.e., we created a representation for words that capture their meaning, semantic relationships and the different types of contexts they are used in and used it in our classification task. The performance results have improved significantly. We applied our approach to English and Russian, the two languages from two different language families, Germanic and Slavic, respectively, and whose structural and morphological properties are different enough to test if our method is (relatively) language-independent. Our experimental results were positive.   The results of this study is a method for idiom detection that does not rely on resource-heavy linguistic technology, such as syntactic parsing, part-of-speech tagging or manual annotation. Our algorithm manages to capture the contextual differences in which literal and idiomatic expressions occur. This technology can be used in many other applications, such as machine translation, language understanding systems, sentiment and emotion analysis, among others.   A number of undergraduate and graduate students had the opportunity to participate in active research and gain experience in working collaboratively on an interdisciplinary problem. The project involved students from a variety of disciplines: linguistics, computer science, literature, and mathematics.          Last Modified: 06/01/2018       Submitted by: Anna Feldman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
