<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Theory and Methods for Simultaneous Variable Selection and Rank Reduction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2014</AwardEffectiveDate>
<AwardExpirationDate>05/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The data explosion in all fields of science creates an urgent need for methodologies for analyzing high dimensional multivariate data. The project deepens and broadens existing sparsity and low rank statistical theories and methods by making the following major scientific achievements: (a) an innovative selectable reduced rank methodology through simultaneous variable selection and projection, with guaranteed lower error rate than existing variable selection and rank reduction rates in theory, which paves the way to new frontiers in high dimensional statistics and information theory; (b) fast but simple-to-implement algorithms that can deal with all popular penalty functions (possibly nonconvex) in computation with guaranteed global convergence and local optimality, to ensure the practicality of the proposed approaches in big data applications; (c) a generic extension to non-Gaussian models capable of taking into account the correlation between multivariate responses, with a universal algorithm design based on manifold optimization; (d) a unified robustification scheme that can both identify and accommodate gross outliers occurring frequently in real data, to overcome the non-robustness of many conventional multivariate tools; (e) general-purpose model selection methods serving variable selection and/or rank reduction and achieving the finite-sample optimal prediction error rate with theoretical guarantee. &lt;br/&gt;  &lt;br/&gt;The need to recover low-dimensional signals from high dimensional multivariate noisy data permeates all fields of science and engineering. Hence a project of this nature, designed to develop transformative theory and methods for simultaneous variable selection and rank reduction, finds applications in a wide range of disciplines and areas such as machine learning, signal processing, and biostatistics, among others. By cross-fertilizing ideas from statistics, mathematics, engineering, and computer science, the integrated research and education help students develop critical thinking through cross-disciplinary training, and assist students in becoming life-long learners. The investigator uses the rich topics in this project to inspire the learning and discovery interest of the public and students of all ages. The educational plan consists of course development, student mentoring, outreach, and recruiting underrepresented students.</AbstractNarration>
<MinAmdLetterDate>02/11/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/22/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1352259</AwardID>
<Investigator>
<FirstName>Yiyuan</FirstName>
<LastName>She</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yiyuan She</PI_FULL_NAME>
<EmailAddress>yshe@stat.fsu.edu</EmailAddress>
<PI_PHON>8506443218</PI_PHON>
<NSF_ID>000549795</NSF_ID>
<StartDate>02/11/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida State University</Name>
<CityName>TALLAHASSEE</CityName>
<ZipCode>323064166</ZipCode>
<PhoneNumber>8506445260</PhoneNumber>
<StreetAddress>874 Traditions Way, 3rd Floor</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790877419</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida State University]]></Name>
<CityName>Tallahassee</CityName>
<StateCode>FL</StateCode>
<ZipCode>323064330</ZipCode>
<StreetAddress><![CDATA[117 N Woodward Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>8048</Code>
<Text>Division Co-Funding: CAREER</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~88786</FUND_OBLG>
<FUND_OBLG>2015~91738</FUND_OBLG>
<FUND_OBLG>2016~94817</FUND_OBLG>
<FUND_OBLG>2017~61377</FUND_OBLG>
<FUND_OBLG>2018~63282</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The data explosion in all fields of science and engineering creates an urgent need for analyzing high dimensional multivariate data. Recently, sparse learning techniques such as lasso and low-rank matrix estimation have attracted a good deal of attention from statisticians, engineers and computer scientists, but also meet some great challenges in theory, computation, parameter tuning and robust estimation in real world applications.</p> <p>&nbsp;</p> <p>To address these challenges, this project develops new theory and methods for simultaneous variable selection and rank reduction with broad applications in various areas including machine learning, image processing, macroeconomics, neuroscience and genomics. By the end of the project, the PI has achieved the following results: an innovative selective reduced rank methodology through joint selection and projection, which enjoys minimax optimality and a non-asymptotic oracle error rate lower than existing results in the literature; a class of fast but simple-to-implement algorithms that can deal with all popular regularizers (possibly nonconvex) with global convergence and prediction accuracy; a generic dependency graph learning framework applicable to non-Gaussian multivariate data that is capable of capturing dependency structures between a large number of responses; a unified robustification scheme to identify and accommodate gross outliers which are bound to occur in big data; a class of general-purpose model selection methods for parameter tuning in the use of joint regularization, with provable guarantees to achieve optimal prediction error in a finite-sample sense.</p> <p>The need to recover low-dimensional signals from high dimensional multivariate noisy data permeates all fields of science and engineering. Hence a project of this nature, designed to develop transformative theory and methods for simultaneous variable selection and rank reduction, finds applications in a wide range of disciplines and areas such as signal processing, biostatistics, machine learning, among others. By cross-fertilizing ideas from statistics, mathematics, engineering, and computer science, the integrated research and education help students develop critical thinking through cross-disciplinary training, and assist them in becoming life-long learners. The investigator uses the rich topics in this project to teach advanced statistics and optimization classes and inspire the learning and discovery interest of the public and students of all ages.</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/12/2019<br>      Modified by: Yiyuan&nbsp;She</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The data explosion in all fields of science and engineering creates an urgent need for analyzing high dimensional multivariate data. Recently, sparse learning techniques such as lasso and low-rank matrix estimation have attracted a good deal of attention from statisticians, engineers and computer scientists, but also meet some great challenges in theory, computation, parameter tuning and robust estimation in real world applications.     To address these challenges, this project develops new theory and methods for simultaneous variable selection and rank reduction with broad applications in various areas including machine learning, image processing, macroeconomics, neuroscience and genomics. By the end of the project, the PI has achieved the following results: an innovative selective reduced rank methodology through joint selection and projection, which enjoys minimax optimality and a non-asymptotic oracle error rate lower than existing results in the literature; a class of fast but simple-to-implement algorithms that can deal with all popular regularizers (possibly nonconvex) with global convergence and prediction accuracy; a generic dependency graph learning framework applicable to non-Gaussian multivariate data that is capable of capturing dependency structures between a large number of responses; a unified robustification scheme to identify and accommodate gross outliers which are bound to occur in big data; a class of general-purpose model selection methods for parameter tuning in the use of joint regularization, with provable guarantees to achieve optimal prediction error in a finite-sample sense.  The need to recover low-dimensional signals from high dimensional multivariate noisy data permeates all fields of science and engineering. Hence a project of this nature, designed to develop transformative theory and methods for simultaneous variable selection and rank reduction, finds applications in a wide range of disciplines and areas such as signal processing, biostatistics, machine learning, among others. By cross-fertilizing ideas from statistics, mathematics, engineering, and computer science, the integrated research and education help students develop critical thinking through cross-disciplinary training, and assist them in becoming life-long learners. The investigator uses the rich topics in this project to teach advanced statistics and optimization classes and inspire the learning and discovery interest of the public and students of all ages.          Last Modified: 04/12/2019       Submitted by: Yiyuan She]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
