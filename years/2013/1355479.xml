<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Common Prosody Platform for Testing Theories and Models of Speech Prosody</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>280228.00</AwardTotalIntnAmount>
<AwardAmount>280129</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Prosody plays an important role in the complex mapping between meaning and the spoken expression of words, phrases and sentences; it is critical to our understanding of human communication and to our ability to exploit prosodic information in both automated language production and meaning recognition.&lt;br/&gt;&lt;br/&gt;Prosody research has seen significant development in recent decades, and numerous theories and computational models have been proposed. However, many fundamental issues remain unresolved and some are still under heated debate. This lack of consensus has resulted in slow advances in developing speech applications with capabilities for processing prosody. This project is a collaborative effort to accelerate progress in prosody research by developing a Common Prosody Platform (CPP). CPP will consist of an open-access web site that hosts a collection of trainable models in the form of Praat scripts, each implementing a major theory of prosody. All the scripts will consist of A) a computational realization of the basic assumptions of a particular theory, which is capable of generating surface prosodic forms (initially, F0 and duration), and B) a set of learning algorithms for automatic analysis-by-synthesis and global optimization, which allow the script to be trained on any speech corpora marked up with theory-specific categories. CPP will therefore facilitate theory evaluation by enabling them to make numerical predictions that can be directly compared with natural prosody in fine detail. CPP will be tested on autosegmental-metrical (AM) theory, Parallel Encoding and Target Approximation (PENTA) model, articulatory phonology/task dynamic model (TADA), and command response (Fujisaki) model, and apply them to English, Greek, Mandarin and Itunyoso Trique (an endangered tone language).&lt;br/&gt;&lt;br/&gt;The development of CPP will help bridge the current gaps between theoretical conceptualization, empirical investigation and computational modeling. The computational nature of the resulting trainable models will also make them readily transferable to applied areas, including speech technology, language teaching and speech communication disorders. The research approach developed in this project may also be extendable to a general paradigm in speech research, namely, theory testing by computational modeling.</AbstractNarration>
<MinAmdLetterDate>03/15/2014</MinAmdLetterDate>
<MaxAmdLetterDate>12/15/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1355479</AwardID>
<Investigator>
<FirstName>Douglas</FirstName>
<LastName>Whalen</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Douglas H Whalen</PI_FULL_NAME>
<EmailAddress>whalen@haskins.yale.edu</EmailAddress>
<PI_PHON>2038656163</PI_PHON>
<NSF_ID>000542916</NSF_ID>
<StartDate>03/15/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yi</FirstName>
<LastName>Xu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yi Xu</PI_FULL_NAME>
<EmailAddress>yi.xu@ucl.ac.uk</EmailAddress>
<PI_PHON>2076794082</PI_PHON>
<NSF_ID>000584300</NSF_ID>
<StartDate>03/15/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Haskins Laboratories, Inc.</Name>
<CityName>New Haven</CityName>
<ZipCode>065116610</ZipCode>
<PhoneNumber>2038656163</PhoneNumber>
<StreetAddress>300 George Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>060010147</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>HASKINS LABORATORIES, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Haskins Laboratories, Inc.]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065116660</ZipCode>
<StreetAddress><![CDATA[300 George St., Suite 900]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~280129</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="New">Speech prosody refers to the manners with which utterances are spoken, which involve pitch, intensity, duration and voice quality. Prosody helps to determine whether an utterance is a statement, a question or a command, whether it starts or ends a conversational turn, which of the syllables go together to form a word, a phrase or a larger unit, or whether a particular word is emphasized. Many theories and computational models of prosody have been proposed over the years, and a large number of empirical studies have been conducted. Despite these efforts, however, many critical issues remain unresolved and some are still under heated debate. This lack of consensus has been a major obstacle to linking basic prosody research to applied areas, resulting in slow advances in developing applications with capabilities for processing prosody.</p> <p class="New">An important reason for this unsatisfactory situation is the lack of computational modelling in empirical research. Modelling forces translation of theories and empirical findings into predictive algorithms that generate continuous prosodic patterns, which can then be directly compared to real speech data. This further allows testing of how well theories can predict phonetic details beyond the issues for which they are proposed. Such testing is critical because, without it, the validity of any theory cannot be said to be adequately demonstrated, nor can it be known whether it is transferable to applied areas.</p> <p class="New">This project is an international collaborative effort to bridge the gaps in prosody research by developing four computational models, each corresponding to a major theoretical or modelling perspective, including the autosegmental-metrical theory (<em>AM</em>), the parallel encoding and target approximation model (<em>PENTA</em>), the articulatory phonology/task dynamic model (TADA), and the command response/Fujisaki model (<em>Fujisaki)</em>.</p> <p class="New">The two and half year project has achieved three objectives. The first is the development of the Common Prosody Platform (CPP) &mdash; a website that hosts all the computational models (http://commonprosodyplatform.org/). Each of the models implements one of the four theories of prosody, and is capable of generating surface prosodic forms (F0 and duration) based on the basic assumptions of the corresponding theory (Figures 1-3). Among the models, PENTAtrainer has achieved the capability to learn the model parameters from an entire corpus (Figures 4-5).</p> <p class="New">The second objective achieved is to perform a number of tests to assess the capabilities of the computational models. The results of these tests have been published in journal articles (Prom-on et al., 2016; Prom-on &amp; Xu, in press; Xu &amp; Prom-on, 2014), conference proceedings (Lee &amp; Xu, 2015; Liu et al., 2015; Prom-on et al., 2016) and book chapters (Arvaniti, in press; Xu &amp; Prom-on, 2015; Xu, Prom-on &amp; Liu, 2015, in press).</p> <p class="New">The third objective achieved is to hold a workshop (<a href="http://sites.bu.edu/speechprosody2016/satellite-workshop-cpp/">http://sites.bu.edu/speechprosody2016/satellite-workshop-cpp/</a>) and a tutorial (<a href="https://ubwp.buffalo.edu/tal2016/satellite-meetings/">https://ubwp.buffalo.edu/tal2016/satellite-meetings/</a>) to introduce the computational models and motivate wider application of modelling in speech research.</p> <p class="New">CPP therefore facilitates development of prosodic theories by enabling them to make numerical predictions that can be directly compared to natural prosody in fine detail. This is a major step toward bridging the gaps between theoretical conceptualization, empirical investigation and computational modeling. The computational nature of the resulting trainable models will also make them more readily transferable to applied areas.</p> <p class="New">&nbsp;</p> <p class="New">References:</p> <ol> <li>Arvaniti, A. (in press). The autosegmental metrical model of intonational phonology. In <em>Prosodic Theory and Practice</em>. J. Barnes and S. Shattuck-Hufnagel. Cambridge: MIT Press.</li> <li>Prom-on, S. and Xu, Y. (in press). Discovering underlying tonal representations by computational modeling: a case study of Thai. <em>Journal of Chinese Linguistics</em>.</li> <li>Xu, Y., Prom-on, S. and Liu, F. (in press). The PENTA model: Concepts, use and implications. In <em>Prosodic Theory and Practice</em>. J. Barnes and S. Shattuck-Hufnagel. Cambridge: MIT Press.</li> <li>Prom-on, S., Xu, Y., Gu, W., Arvaniti, A., Nam, H., &amp; Whalen, D. H. (2016). The Common Prosody Platform (CPP) &mdash; where Theories of Prosody can be Directly Compared. In <em>Proceedings of Speech Prosody 2016</em>, Boston, USA, pp. 1-5.</li> <li>Lee, A. and Xu, Y. (2015). Modelling Japanese intonation using pentatrainer2. In <em>Proceedings of the 18th International Congress of Phonetic Sciences</em>, Glasgow, UK.</li> <li>Liu, F., Prom-on, S., Xu, Y. and Whalen, D. H. (2015). Computational modelling of double focus in American English. In <em>Proceedings of the 18th International Congress of Phonetic Sciences</em>, Glasgow, UK.</li> <li>Xu, Y. and Prom-on, S. (2015). Degrees of freedom in prosody modeling. In <em>Speech Prosody in Speech Synthesis &mdash; Modeling, Realizing, Converting Prosody for High Quality and Flexible speech Synthesis</em>. K. Hirose and J. Tao (eds.): Springer pp. 19-34.</li> <li>Xu, Y. and Prom-on, S. (2014). Toward invariant functional representations of variable surface fundamental frequency contours: Synthesizing speech melody via model-based stochastic learning. <em>Speech Communication</em> 57, 181-208.</li> </ol><br> <p>            Last Modified: 11/29/2017<br>      Modified by: Douglas&nbsp;H&nbsp;Whalen</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030415113_Figure1--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030415113_Figure1--rgov-800width.jpg" title="F1. System diagram of CPP"><img src="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030415113_Figure1--rgov-66x44.jpg" alt="F1. System diagram of CPP"></a> <div class="imageCaptionContainer"> <div class="imageCaption">F1. System diagram of CPP</div> <div class="imageCredit">Prom-on et al., 2016</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yi&nbsp;Xu</div> <div class="imageTitle">F1. System diagram of CPP</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505035208316_Figure5--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505035208316_Figure5--rgov-800width.jpg" title="Figure 5. PENTAtrainer2 synthesis interface"><img src="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505035208316_Figure5--rgov-66x44.jpg" alt="Figure 5. PENTAtrainer2 synthesis interface"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 5. The interface facilitates direct comparison of model predicted f0 contours with those of natural speech</div> <div class="imageCredit">PENTAtrainer2 website</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yi&nbsp;Xu</div> <div class="imageTitle">Figure 5. PENTAtrainer2 synthesis interface</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030680107_Figure3--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030680107_Figure3--rgov-800width.jpg" title="Figure 3. F0 contour comparison"><img src="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030680107_Figure3--rgov-66x44.jpg" alt="Figure 3. F0 contour comparison"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 3. CPP resynthesis comparison window</div> <div class="imageCredit">Prom-on et al., 2016</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yi&nbsp;Xu</div> <div class="imageTitle">Figure 3. F0 contour comparison</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505033379215_Figure4--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505033379215_Figure4--rgov-800width.jpg" title="Figure 4. PENTAtrainer2 work flow"><img src="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505033379215_Figure4--rgov-66x44.jpg" alt="Figure 4. PENTAtrainer2 work flow"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 4. Workflow of PENTAtrainer2, which consists of the use of Annotation, Learning, and Synthesis tools. The number on the top-left of each toolindicates its order of application in the modeling process.</div> <div class="imageCredit">Xu & Prom-on (2014)</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Yi&nbsp;Xu</div> <div class="imageTitle">Figure 4. PENTAtrainer2 work flow</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030549331_Figure2--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030549331_Figure2--rgov-800width.jpg" title="Figure 2. CPP main interface"><img src="/por/images/Reports/POR/2017/1355479/1355479_10294799_1505030549331_Figure2--rgov-66x44.jpg" alt="Figure 2. CPP main interface"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Figure 2. Main interface of CPP</div> <div class="imageCredit">Prom-on et al., 2016</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Yi&nbsp;Xu</div> <div class="imageTitle">Figure 2. CPP main interface</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Speech prosody refers to the manners with which utterances are spoken, which involve pitch, intensity, duration and voice quality. Prosody helps to determine whether an utterance is a statement, a question or a command, whether it starts or ends a conversational turn, which of the syllables go together to form a word, a phrase or a larger unit, or whether a particular word is emphasized. Many theories and computational models of prosody have been proposed over the years, and a large number of empirical studies have been conducted. Despite these efforts, however, many critical issues remain unresolved and some are still under heated debate. This lack of consensus has been a major obstacle to linking basic prosody research to applied areas, resulting in slow advances in developing applications with capabilities for processing prosody. An important reason for this unsatisfactory situation is the lack of computational modelling in empirical research. Modelling forces translation of theories and empirical findings into predictive algorithms that generate continuous prosodic patterns, which can then be directly compared to real speech data. This further allows testing of how well theories can predict phonetic details beyond the issues for which they are proposed. Such testing is critical because, without it, the validity of any theory cannot be said to be adequately demonstrated, nor can it be known whether it is transferable to applied areas. This project is an international collaborative effort to bridge the gaps in prosody research by developing four computational models, each corresponding to a major theoretical or modelling perspective, including the autosegmental-metrical theory (AM), the parallel encoding and target approximation model (PENTA), the articulatory phonology/task dynamic model (TADA), and the command response/Fujisaki model (Fujisaki). The two and half year project has achieved three objectives. The first is the development of the Common Prosody Platform (CPP) &mdash; a website that hosts all the computational models (http://commonprosodyplatform.org/). Each of the models implements one of the four theories of prosody, and is capable of generating surface prosodic forms (F0 and duration) based on the basic assumptions of the corresponding theory (Figures 1-3). Among the models, PENTAtrainer has achieved the capability to learn the model parameters from an entire corpus (Figures 4-5). The second objective achieved is to perform a number of tests to assess the capabilities of the computational models. The results of these tests have been published in journal articles (Prom-on et al., 2016; Prom-on &amp; Xu, in press; Xu &amp; Prom-on, 2014), conference proceedings (Lee &amp; Xu, 2015; Liu et al., 2015; Prom-on et al., 2016) and book chapters (Arvaniti, in press; Xu &amp; Prom-on, 2015; Xu, Prom-on &amp; Liu, 2015, in press). The third objective achieved is to hold a workshop (http://sites.bu.edu/speechprosody2016/satellite-workshop-cpp/) and a tutorial (https://ubwp.buffalo.edu/tal2016/satellite-meetings/) to introduce the computational models and motivate wider application of modelling in speech research. CPP therefore facilitates development of prosodic theories by enabling them to make numerical predictions that can be directly compared to natural prosody in fine detail. This is a major step toward bridging the gaps between theoretical conceptualization, empirical investigation and computational modeling. The computational nature of the resulting trainable models will also make them more readily transferable to applied areas.   References:  Arvaniti, A. (in press). The autosegmental metrical model of intonational phonology. In Prosodic Theory and Practice. J. Barnes and S. Shattuck-Hufnagel. Cambridge: MIT Press. Prom-on, S. and Xu, Y. (in press). Discovering underlying tonal representations by computational modeling: a case study of Thai. Journal of Chinese Linguistics. Xu, Y., Prom-on, S. and Liu, F. (in press). The PENTA model: Concepts, use and implications. In Prosodic Theory and Practice. J. Barnes and S. Shattuck-Hufnagel. Cambridge: MIT Press. Prom-on, S., Xu, Y., Gu, W., Arvaniti, A., Nam, H., &amp; Whalen, D. H. (2016). The Common Prosody Platform (CPP) &mdash; where Theories of Prosody can be Directly Compared. In Proceedings of Speech Prosody 2016, Boston, USA, pp. 1-5. Lee, A. and Xu, Y. (2015). Modelling Japanese intonation using pentatrainer2. In Proceedings of the 18th International Congress of Phonetic Sciences, Glasgow, UK. Liu, F., Prom-on, S., Xu, Y. and Whalen, D. H. (2015). Computational modelling of double focus in American English. In Proceedings of the 18th International Congress of Phonetic Sciences, Glasgow, UK. Xu, Y. and Prom-on, S. (2015). Degrees of freedom in prosody modeling. In Speech Prosody in Speech Synthesis &mdash; Modeling, Realizing, Converting Prosody for High Quality and Flexible speech Synthesis. K. Hirose and J. Tao (eds.): Springer pp. 19-34. Xu, Y. and Prom-on, S. (2014). Toward invariant functional representations of variable surface fundamental frequency contours: Synthesizing speech melody via model-based stochastic learning. Speech Communication 57, 181-208.        Last Modified: 11/29/2017       Submitted by: Douglas H Whalen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
