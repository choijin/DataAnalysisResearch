<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps:  Real-Time Facial Tracking for Safety, Security and Medical applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2014</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rathindra DasGupta</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Facial expressions play a significant role in our daily communication. However, few accurate, robust and portable expression detection and analysis systems currently exist.  The project team has developed a system for real-time tracking and analyzing of the facial features of humans in video. The system, composed of software and a single camera can automatically analyze facial expressions, detect eye blinks and track the head orientation of a human target under varying conditions of illumination. With facial expression analysis, the barrier of machine detection of human emotion, which has existed since the invention of the earliest machines, could finally be lifted. This possibility allows the research team to explore not only the social innovations, such as expression based rating of media or sentiment of a social interaction, but the connection of human and machine through non-verbal, indirect communication. &lt;br/&gt;&lt;br/&gt;The recognition of human facial expressions through an automated system has extensive applications, such as; emotional reaction measurement, development of a facially controlled human-computer interface and a multitude of opportunities by releasing an individually configured input mapped facially controlled software interface to the public. Some of the possibilities of facial expression analysis could include enhanced search results based on the users approval, automatic word definition triggered by a "confused" expression and general and/or specific sentiment after the review of textual or video content. Through the fatigue detection capabilities of our software, the transportation industry can be made safer by the development of systems that can detect the alertness of pilots, drivers and vehicle operators at large and pair them with devices to alert them to their fatigued state.</AbstractNarration>
<MinAmdLetterDate>05/05/2014</MinAmdLetterDate>
<MaxAmdLetterDate>05/05/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1355304</AwardID>
<Investigator>
<FirstName>Dimitris</FirstName>
<LastName>Metaxas</LastName>
<PI_MID_INIT>N</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dimitris N Metaxas</PI_FULL_NAME>
<EmailAddress>dnm@cs.rutgers.edu</EmailAddress>
<PI_PHON>7324452914</PI_PHON>
<NSF_ID>000236186</NSF_ID>
<StartDate>05/05/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<StreetAddress2><![CDATA[2nd Floor East Wing]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001912864</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001912864</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName/>
<StateCode>NJ</StateCode>
<ZipCode>088543329</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~50000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="font-family: Times New Roman; font-size: small;"> </span><span style="color: black;">The I-Corps project, Real-Time Facial Tracking for Safety, Security and Medical Applications is one of the results of nearly 20 years of research into the facial tracking aspect of Human-Computer Interaction. The technology enables a computer with a single, standard resolution camera to track and quantify head pose and human facial expressions in real time. As an example, the technology can detect how much time a person spends smiling and to what degree, how drowsy a person is by measuring eyelid closure and duration, if they are looking in a specific direction or not, etc.<span style="mso-spacerun: yes;">&nbsp;&nbsp; </span>The purpose of the I-Corps project was to explore the commercial market for this technology and discover what applications would be most immediately useful to the general public.</span></p> <p><span style="font-family: Times New Roman; font-size: small;"> </span></p> <p style="margin: 0in 0in 0pt;"><span style="color: black;">The technology took on the name "FaceTrak" and shortly after the start of the I-Corp program, began testing the market for possible applications. After initially exploring the possibility of using FaceTrak for the treatment of autism during the 7 week I-Corps program, the effort began to focus more on applications in transportation safety. Specifically, FaceTrak can detect drowsiness in humans by measuring the range and duration of eyelid closure. The portability of the technology makes FaceTrak an ideal solution to observe drivers, pilots and other operators onboard nearly any type of vehicle. With the excellent coursework and real-world environment training of the I-Corps program, the project team was able to lay the groundwork for the start of the FaceTrak company, a startup firm that is actively working to commercialize the technology. With continued hard work and good fortune, the FaceTrak technology will soon be onboard vehicles and actively working to improve transportation safety. Capital raised from commercial success will be used to find new and useful applications in the market. </span></p> <p><span style="font-family: Times New Roman; font-size: small;"> </span></p> <p style="margin: 0in 0in 0pt;"><span style="color: black;">Further, it is significant to note that never before in the history of humankind and machines has the machine had a capacity to interpret and act on the facial expressions of humans. We believe that this new capacity will continue to find new applications far beyond transportation safety and well into the foreseeable future.</span></p> <p style="margin: 0in 0in 0pt;">&nbsp;</p> <p style="margin: 0in 0in 0pt;">&nbsp;</p> <p><span style="font-family: Times New Roman; font-size: small;"> </span></p><br> <p>            Last Modified: 02/03/2019<br>      Modified by: Dimitris&nbsp;N&nbsp;Metaxas</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The I-Corps project, Real-Time Facial Tracking for Safety, Security and Medical Applications is one of the results of nearly 20 years of research into the facial tracking aspect of Human-Computer Interaction. The technology enables a computer with a single, standard resolution camera to track and quantify head pose and human facial expressions in real time. As an example, the technology can detect how much time a person spends smiling and to what degree, how drowsy a person is by measuring eyelid closure and duration, if they are looking in a specific direction or not, etc.   The purpose of the I-Corps project was to explore the commercial market for this technology and discover what applications would be most immediately useful to the general public.    The technology took on the name "FaceTrak" and shortly after the start of the I-Corp program, began testing the market for possible applications. After initially exploring the possibility of using FaceTrak for the treatment of autism during the 7 week I-Corps program, the effort began to focus more on applications in transportation safety. Specifically, FaceTrak can detect drowsiness in humans by measuring the range and duration of eyelid closure. The portability of the technology makes FaceTrak an ideal solution to observe drivers, pilots and other operators onboard nearly any type of vehicle. With the excellent coursework and real-world environment training of the I-Corps program, the project team was able to lay the groundwork for the start of the FaceTrak company, a startup firm that is actively working to commercialize the technology. With continued hard work and good fortune, the FaceTrak technology will soon be onboard vehicles and actively working to improve transportation safety. Capital raised from commercial success will be used to find new and useful applications in the market.     Further, it is significant to note that never before in the history of humankind and machines has the machine had a capacity to interpret and act on the facial expressions of humans. We believe that this new capacity will continue to find new applications far beyond transportation safety and well into the foreseeable future.              Last Modified: 02/03/2019       Submitted by: Dimitris N Metaxas]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
