<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  Bridging between Tabletop Models and the Earth System</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>11/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>97255.00</AwardTotalIntnAmount>
<AwardAmount>97255</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The three-year project tackles the important problem of the difficulty of conducting hands-on activities for 8th and 9th grade Earth Science classrooms.  The PIs take the approach of using tabletop models as analogs for the phenomena the curriculum is trying to elucidate. The project investigates how students apply insights gained from working with dynamic tabletop modules to understanding and reasoning about processes of the full scale Earth system.&lt;br/&gt;&lt;br/&gt;Working with 300 students and four teachers in New York City schools, the researchers test three instructional strategies in terms of the usefulness and pitfalls of each.  The PIs develop written assessments using evidence-centered design principles that examine students' understanding of model attributes, model/Earth attribute correspondences, model relationships, model/Earth relationship correspondences, and geoscience data/evidence.  &lt;br/&gt;&lt;br/&gt;The PIs collect student demographic data using t-tests and multiple regression analysis.  They also collect student demographic data and qualitative measures to describe how the instructional strategies were enacted across classrooms and to understnd the ways in which teachers should be supported to utilize these strategies effectively.</AbstractNarration>
<MinAmdLetterDate>05/03/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/03/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1338311</AwardID>
<Investigator>
<FirstName>Kim</FirstName>
<LastName>Kastens</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kim A Kastens</PI_FULL_NAME>
<EmailAddress>kastens@ldeo.columbia.edu</EmailAddress>
<PI_PHON>9146712341</PI_PHON>
<NSF_ID>000154890</NSF_ID>
<StartDate>05/03/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Education Development Center</Name>
<CityName>Waltham</CityName>
<ZipCode>024538313</ZipCode>
<PhoneNumber>6176182227</PhoneNumber>
<StreetAddress>43 Foundry Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>076583830</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>EDUCATION DEVELOPMENT CENTER, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>076583830</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Education Development Center]]></Name>
<CityName>Waltham</CityName>
<StateCode>MA</StateCode>
<ZipCode>024538313</ZipCode>
<StreetAddress><![CDATA[43 Foundry Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~97255</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span style="white-space: pre;"> <span style="white-space: pre;"> </span></span>Physical dynamic tabletop models are one form of scientific models that are commonly used in instruction to illustrate concepts and phenomena that students cannot interact with directly.&nbsp; In the Earth Sciences, many of the phenomena under study are too big or slow to fit into a classroom setting, such as global circulation or plate tectonics.&nbsp; In &ldquo;Bridging the Gap Between Tabletop Models and the Earth System&rdquo; we examine how students reason about the relationships between common physical dynamic models used in Earth Science classrooms and full-scale Earth System processes.&nbsp; The goals of this project are to better understand how physical models are used in science classrooms to assist with instruction more generally, and the role they play in helping students learn important science concepts. Building from the literature in reasoning from analogies, we identified three types, or levels, of increasingly sophisticated reasoning that students may use when attempting to understand a physical model as representative of a large-scale Earth phenomena.&nbsp; The first level involves reasoning about the correspondences and non-correspondences between objects, entities, or characteristics of those entities in the models and in the Earth System itself. The second level involves reasoning about the ways that the relative motion of entities in the model, or their configuration in space, correspond or do not correspond to the relative motion or configuration of entities in the Earth System. The third, most sophisticated, level of reasoning involves consideration of the causal mechanisms behind emergent phenomena in the model as corresponding to the same causes or mechanisms that result in emergent phenomena in the Earth System</p> <p><span style="white-space: pre;"> <span style="white-space: pre;"> </span></span>Using this framework, we developed written assessment metrics to measure the sophistication of students&rsquo; reasoning between physical models and full-scale Earth phenomena around three topics that are typically taught using models in middle and high school Earth Science classrooms (moon phases, causes of the seasons, and differential setting in depositional environments).&nbsp; Each assessment included between 20-24 items, in both multiple choice and short response format, which measured students&rsquo; ability to reason about correspondences or non-correspondences between the Earth phenomena and an exemplar tabletop model in the front of the classroom.&nbsp; <span style="white-space: pre;"> </span>Three hundred and fifty seven 8<sup>th</sup> and 9<sup>th</sup> grade Earth Science students from four different schools outside of a large metropolitan area in the Northeast participated in the project over two years by completing one or more of the written assessments.&nbsp; Selected students from each classroom also participated in individual interviews to discuss the thinking behind their responses to a subset of items.&nbsp; Videotaped classroom observations were conducted of teachers&rsquo; lessons on each of the three target topics over the course of two years. Student responses to the assessment items were scored using an elaborated outcome space aligned with the levels of reasoning sophistication and were analyzed using Rasch modeling.&nbsp; Student interviews and classroom observations were coded along several dimensions using an emergent coding scheme and examined for patterns and trends in the data.</p> <p><span style="white-space: pre;"> <span style="white-space: pre;"> </span></span>Based on analysis of the written assessments, student interviews, and classroom observations, we learned a number of different things about how students reason between physical models and full-scale Earth System processes, and how such reasoning is, and could be, supported thro...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Physical dynamic tabletop models are one form of scientific models that are commonly used in instruction to illustrate concepts and phenomena that students cannot interact with directly.  In the Earth Sciences, many of the phenomena under study are too big or slow to fit into a classroom setting, such as global circulation or plate tectonics.  In "Bridging the Gap Between Tabletop Models and the Earth System" we examine how students reason about the relationships between common physical dynamic models used in Earth Science classrooms and full-scale Earth System processes.  The goals of this project are to better understand how physical models are used in science classrooms to assist with instruction more generally, and the role they play in helping students learn important science concepts. Building from the literature in reasoning from analogies, we identified three types, or levels, of increasingly sophisticated reasoning that students may use when attempting to understand a physical model as representative of a large-scale Earth phenomena.  The first level involves reasoning about the correspondences and non-correspondences between objects, entities, or characteristics of those entities in the models and in the Earth System itself. The second level involves reasoning about the ways that the relative motion of entities in the model, or their configuration in space, correspond or do not correspond to the relative motion or configuration of entities in the Earth System. The third, most sophisticated, level of reasoning involves consideration of the causal mechanisms behind emergent phenomena in the model as corresponding to the same causes or mechanisms that result in emergent phenomena in the Earth System    Using this framework, we developed written assessment metrics to measure the sophistication of studentsÆ reasoning between physical models and full-scale Earth phenomena around three topics that are typically taught using models in middle and high school Earth Science classrooms (moon phases, causes of the seasons, and differential setting in depositional environments).  Each assessment included between 20-24 items, in both multiple choice and short response format, which measured studentsÆ ability to reason about correspondences or non-correspondences between the Earth phenomena and an exemplar tabletop model in the front of the classroom.   Three hundred and fifty seven 8th and 9th grade Earth Science students from four different schools outside of a large metropolitan area in the Northeast participated in the project over two years by completing one or more of the written assessments.  Selected students from each classroom also participated in individual interviews to discuss the thinking behind their responses to a subset of items.  Videotaped classroom observations were conducted of teachersÆ lessons on each of the three target topics over the course of two years. Student responses to the assessment items were scored using an elaborated outcome space aligned with the levels of reasoning sophistication and were analyzed using Rasch modeling.  Student interviews and classroom observations were coded along several dimensions using an emergent coding scheme and examined for patterns and trends in the data.    Based on analysis of the written assessments, student interviews, and classroom observations, we learned a number of different things about how students reason between physical models and full-scale Earth System processes, and how such reasoning is, and could be, supported through instruction.  We found evidence that students do indeed reason across all three levels of sophistication around the relationships between the model and the Earth System, and that generally the levels do seem to progress in difficulty (i.e., it is generally easier to reason at a Level 1 than a Level 2, and Level 3 is the most difficult), although the data is not as clean-cut as the hypothesis suggests.  We also found that students have m...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
