<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: RUI: Image Matching in the Wild</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>236087.00</AwardTotalIntnAmount>
<AwardAmount>236087</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to advance stereo vision and optical flow algorithms to work in challenging real-world conditions.  It contributes novel algorithmic approaches, new high-resolution datasets with ground truth, and an update to the Middlebury benchmarks.&lt;br/&gt;&lt;br/&gt;The algorithmic advances include fast matching algorithms that employ radiometric and geometric self-calibration, including smart data terms that establish noise and color models during the matching process, and novel layer-based surface reconstruction algorithms with explicit reasoning about half-occluded regions, reflections, and transparency.  The new datasets reflect current challenges, including high-resolution images of real-world scenes with complex occlusions, specular surfaces and reflections under different illuminations and taken with different cameras.  Undergraduate students are actively involved in all components of this research.&lt;br/&gt;&lt;br/&gt;The project has strong potential impact along several fronts.  The new datasets and benchmarks challenge the community and serve as catalysts for new research.  The algorithmic advances allow harnessing the explosion of images available online, and enable real-world applications such as automated driving, geolocation, and automatic 3D reconstruction of whole cities.  Finally, the project exposes undergraduates at a liberal-arts college in rural Vermont to the world of research, experimentation, and discovery.</AbstractNarration>
<MinAmdLetterDate>08/13/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320715</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Scharstein</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Scharstein</PI_FULL_NAME>
<EmailAddress>schar@middlebury.edu</EmailAddress>
<PI_PHON>8024432438</PI_PHON>
<NSF_ID>000122299</NSF_ID>
<StartDate>08/13/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Middlebury College</Name>
<CityName>MIDDLEBURY</CityName>
<ZipCode>057536000</ZipCode>
<PhoneNumber>8024435000</PhoneNumber>
<StreetAddress>14 OLD CHAPEL ROAD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Vermont</StateName>
<StateCode>VT</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VT00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>020651675</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF MIDDLEBURY COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020651675</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Middlebury College]]></Name>
<CityName>Middlebury</CityName>
<StateCode>VT</StateCode>
<ZipCode>057536000</ZipCode>
<StreetAddress><![CDATA[Dept of Computer Science]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Vermont</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VT00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~236087</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project was to advance stereo vision research by creating new stereo datasets and benchmarks of real-world scenes, and developing novel robust image matching algorithms applicable to images taken in uncontrolled environments. &nbsp;The project was highly successful and has yielded datasets, benchmarks, and algorithms, as well as several publications.<br />The intellectual merits of the project include novel techniques for dataset creation and novel stereo algorithms. &nbsp;Broader impacts include the catalytic effect of the new benchmark on stereo research, the improved applicability of stereo methods for real-world applications benefiting the population at large, and exposing undergraduates at a liberal-arts college in rural Vermont to the world of research.<br />Two major contributions of the project are a new collection of 33 high-resolution stereo datasets, and the Middlebury stereo evaluation version 3.<br />The new datasets were obtained using a portable structured lighting system able to capture real-life static indoor scenes, which was built in collaboration with undergraduate students. &nbsp;The system includes novel techniques for efficient 2D subpixel correspondence search and self-calibration of cameras and projectors. &nbsp;The new datasets have a resolution of up to 6 megapixels and a disparity range of up to 800 disparities. Each dataset is available with "perfect" rectification obtained using a novel calibration method, as well as realistic "imperfect" rectification with vertical y-disparities of up to several pixels. &nbsp;All input images are available with multiple different exposure and lighting settings to allow evaluating the effect of radiometric changes. &nbsp;A paper describing this multi-year effort was co-authored with 5 undergraduates and won the best paper award at the German Conference for Pattern Recognition (GCPR) 2014.<br />The datasets enabled updating the saturated Middlebury two-view stereo benchmark (version 2). &nbsp;The new Middlebury Stereo Evaluation (version 3) consists of a training and a test set with 15 image pairs each, providing a varied set of challenges, including complex scenes, imperfect rectification, and radiometric changes. &nbsp;Numerical scores are reported for 10 disparity accuracy metrics, as well as actual runtimes and runtimes normalized by pixels and disparity hypotheses. &nbsp;All results are displayed online in tables with interactive visualization features. &nbsp;The web interface was implemented by an undergraduate student.<br />In addition to contributing the new datasets and benchmark, the project also led to significant algorithmic advances.<br />Extending earlier work on image-based modeling and rendering of real-world scenes containing reflective and glossy surfaces, the project contributed a new approach that solves this problem in the gradient domain. &nbsp;The novel algorithm is able to handle general scenes without explicitly separating the scene into reflective and transmissive components.<br />Another contribution is local plane sweep (LPS) stereo, a novel stereo algorithm that avoids exhaustive search of the full disparity space using plane hypotheses derived from matched sparse features. &nbsp;Local plane sweeps are performed around each slanted plane to produce out-of-plane parallax estimates. &nbsp;A final global optimization stage assigns each pixel to one of the local hypotheses. &nbsp;The technique achieves significant speedup and performance gains over previous algorithms on high-resolution stereo pairs of up to 19 megapixels.<br />The project also contributed a scalable multi-view stereo method able to reconstruct accurate 3D models from hundreds of high-resolution input images. &nbsp;The method uses local fusion of disparity maps obtained with semi-global matching, which enables the reconstruction of large scenes that do not fit into main memory. &nbsp;The method employs a novel total variation (TV) prior to classify disparities into different error classes, and utilizes these classes in a novel stochastic data fusion method. &nbsp;Experimental results on several challenging large-scale datasets demonstrate improved performance over existing methods both qualitatively and quantitatively.<br />In addition, progress was made on several other stereo algorithms, including an extension to the popular SGM stereo algorithm to utilize surface orientation priors, and a "Mondrian" stereo algorithm that can handle pathological synthetic stereo pairs completely devoid of texture. The latter was done in collaboration with an undergraduate student, and has led to a publication with the student as the first author.<br />The stereo vision research projects conducted as part of this project have had a vital impact on undergraduate computer science education at Middlebury, and have further contributed to the development of human resources in science and engineering. &nbsp;Six undergraduates were funded as research assistants to work on various components of the project. &nbsp;Two of the research assistants joined the PI in attending top research conferences -- important formative experiences for undergraduates considering a research career -- and one of them is presenting his results at ICIP 2017.<br />In summary, the project was highly successful. Its intellectual merit spans dataset creation, a new successful benchmark, and several algorithmic contributions. &nbsp;The project also had significant broader impact along several avenues.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/04/2017<br>      Modified by: Daniel&nbsp;Scharstein</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1320715/1320715_10267107_1504577067805_MiddEval3--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1320715/1320715_10267107_1504577067805_MiddEval3--rgov-800width.jpg" title="Middlebury Stereo Evaluation v.3"><img src="/por/images/Reports/POR/2017/1320715/1320715_10267107_1504577067805_MiddEval3--rgov-66x44.jpg" alt="Middlebury Stereo Evaluation v.3"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A snapshot of the Middlebury Stereo Evaluation v.3, illustrating the interactive plotting and sorting features.</div> <div class="imageCredit">Daniel Scharstein</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Daniel&nbsp;Scharstein</div> <div class="imageTitle">Middlebury Stereo Evaluation v.3</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project was to advance stereo vision research by creating new stereo datasets and benchmarks of real-world scenes, and developing novel robust image matching algorithms applicable to images taken in uncontrolled environments.  The project was highly successful and has yielded datasets, benchmarks, and algorithms, as well as several publications. The intellectual merits of the project include novel techniques for dataset creation and novel stereo algorithms.  Broader impacts include the catalytic effect of the new benchmark on stereo research, the improved applicability of stereo methods for real-world applications benefiting the population at large, and exposing undergraduates at a liberal-arts college in rural Vermont to the world of research. Two major contributions of the project are a new collection of 33 high-resolution stereo datasets, and the Middlebury stereo evaluation version 3. The new datasets were obtained using a portable structured lighting system able to capture real-life static indoor scenes, which was built in collaboration with undergraduate students.  The system includes novel techniques for efficient 2D subpixel correspondence search and self-calibration of cameras and projectors.  The new datasets have a resolution of up to 6 megapixels and a disparity range of up to 800 disparities. Each dataset is available with "perfect" rectification obtained using a novel calibration method, as well as realistic "imperfect" rectification with vertical y-disparities of up to several pixels.  All input images are available with multiple different exposure and lighting settings to allow evaluating the effect of radiometric changes.  A paper describing this multi-year effort was co-authored with 5 undergraduates and won the best paper award at the German Conference for Pattern Recognition (GCPR) 2014. The datasets enabled updating the saturated Middlebury two-view stereo benchmark (version 2).  The new Middlebury Stereo Evaluation (version 3) consists of a training and a test set with 15 image pairs each, providing a varied set of challenges, including complex scenes, imperfect rectification, and radiometric changes.  Numerical scores are reported for 10 disparity accuracy metrics, as well as actual runtimes and runtimes normalized by pixels and disparity hypotheses.  All results are displayed online in tables with interactive visualization features.  The web interface was implemented by an undergraduate student. In addition to contributing the new datasets and benchmark, the project also led to significant algorithmic advances. Extending earlier work on image-based modeling and rendering of real-world scenes containing reflective and glossy surfaces, the project contributed a new approach that solves this problem in the gradient domain.  The novel algorithm is able to handle general scenes without explicitly separating the scene into reflective and transmissive components. Another contribution is local plane sweep (LPS) stereo, a novel stereo algorithm that avoids exhaustive search of the full disparity space using plane hypotheses derived from matched sparse features.  Local plane sweeps are performed around each slanted plane to produce out-of-plane parallax estimates.  A final global optimization stage assigns each pixel to one of the local hypotheses.  The technique achieves significant speedup and performance gains over previous algorithms on high-resolution stereo pairs of up to 19 megapixels. The project also contributed a scalable multi-view stereo method able to reconstruct accurate 3D models from hundreds of high-resolution input images.  The method uses local fusion of disparity maps obtained with semi-global matching, which enables the reconstruction of large scenes that do not fit into main memory.  The method employs a novel total variation (TV) prior to classify disparities into different error classes, and utilizes these classes in a novel stochastic data fusion method.  Experimental results on several challenging large-scale datasets demonstrate improved performance over existing methods both qualitatively and quantitatively. In addition, progress was made on several other stereo algorithms, including an extension to the popular SGM stereo algorithm to utilize surface orientation priors, and a "Mondrian" stereo algorithm that can handle pathological synthetic stereo pairs completely devoid of texture. The latter was done in collaboration with an undergraduate student, and has led to a publication with the student as the first author. The stereo vision research projects conducted as part of this project have had a vital impact on undergraduate computer science education at Middlebury, and have further contributed to the development of human resources in science and engineering.  Six undergraduates were funded as research assistants to work on various components of the project.  Two of the research assistants joined the PI in attending top research conferences -- important formative experiences for undergraduates considering a research career -- and one of them is presenting his results at ICIP 2017. In summary, the project was highly successful. Its intellectual merit spans dataset creation, a new successful benchmark, and several algorithmic contributions.  The project also had significant broader impact along several avenues.             Last Modified: 09/04/2017       Submitted by: Daniel Scharstein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
