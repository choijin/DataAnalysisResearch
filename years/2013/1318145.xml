<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Dynamic Invariants for Video Scenes Understanding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>454999.00</AwardTotalIntnAmount>
<AwardAmount>454999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to use a combination of elements from dynamic vision, dynamical systems theory, optimization and semi-algebraic geometry to develop a computationally tractable, scalable framework for automatic dynamic scene understanding from multiple, potentially incomplete and corrupted data streams.  The long-term vision is to lay the foundations for synthesizing provably robust vision systems, capable of sustained successful operation in complex dynamic scenarios.&lt;br/&gt;&lt;br/&gt;The core of the project   is a unified vision, centered on the use of dynamical invariants as information encapsulators, and emphasizing robustness and computational complexity issues.  In this approach, the observed data is treated as the output of an underlying model, typically a difference inclusion, which has associated certain quantities (for example order, embedding manifold, subspace spanned by its trajectories) that are invariant to coordinate transformations, initial conditions, viewpoint changes, synchronization, etc.  These invariants compactly capture spatio-temporal information from video data and lead to robust, computationally efficient algorithms   for automatic video scene understanding.   For instance, in this context video data can be efficiently segmented by detecting changes in these dynamic invariants or clustered according to a suitable defined distance.   An application domain directly impacted by this research is aware environments for public space safety, where the co-PIs have been provided access to real data and given a venue for real time testing of the algorithms.</AbstractNarration>
<MinAmdLetterDate>08/21/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1318145</AwardID>
<Investigator>
<FirstName>Mario</FirstName>
<LastName>Sznaier</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mario Sznaier</PI_FULL_NAME>
<EmailAddress>msznaier@coe.neu.edu</EmailAddress>
<PI_PHON>6173735364</PI_PHON>
<NSF_ID>000428363</NSF_ID>
<StartDate>08/21/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Octavia</FirstName>
<LastName>Camps</LastName>
<PI_MID_INIT>I</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Octavia I Camps</PI_FULL_NAME>
<EmailAddress>camps@ece.neu.edu</EmailAddress>
<PI_PHON>6173734663</PI_PHON>
<NSF_ID>000429038</NSF_ID>
<StartDate>08/21/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>BOSTON</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 HUNTINGTON AVE.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~454999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br /><span>The recent exponential growth in data collection capabilities has the potential to profoundly impact society, with benefits ranging from safer, self aware environments, to sustainable use of scarce resources. A major impediment to realizing this vision stems from the curse of dimensionality. Simply put, state-of-the art techniques at the time this research was started were ill-equipped to deal with the &ldquo;data deluge&rdquo;. &nbsp;To address this issue, the goal of this research was &nbsp;&nbsp;to develop a comprehensive, computationally tractable framework for addressing a broad class of computer vision problems that entail extracting information very sparsely encoded in noisy, high volume video or image data. At its core is a unified vision, centered on the use of dynamical invariants as information encapsulators, and emphasizing robustness and computational complexity issues.</span><br /><br /><span>This project outcomes include algorithms for fine grain classification, outlier rejection for linear subspace clustering, dynamics-based multi-camera segmentation in unsynchronized videos, person re-identification, multi-camera tracking, gesture recognition, 3d activity recognition, robust estimation of the Fundamental Matrix for stereo systems, and chronological sorting of crowd-sourced images. &nbsp;These are key enablers for endowing vision-based &nbsp;systems with substantially enhanced capabilities to extract information sparsely encoded in extremely large data sets. Such a capability has the potential to significantly benefit&nbsp;</span><span>society. Spatially distributed vision sensors endowed with activity analysis capabilities can prevent crime,&nbsp;</span><span>help optimize resource use in smart buildings, and give early warning of serious medical conditions for&nbsp;</span><span>instance by detecting minute gait alterations preceding a stroke. In addition, the proposed research resulted in significant cross&ndash;fertilization with other branches of engineering and applied mathematics. An example is the connection between high dimensional data analysis (computer vision, machine learning),&nbsp;</span><span>hybrid dynamical systems (systems theory) and rank minimization (optimization, sparse signal recovery).</span><br /><br /><span>The results &nbsp;obtained during this research were disseminated to the &nbsp;community through publications in the major conferences: CVPR, ICCV, &nbsp;ECCV, and CDC and journals: IEEE. Trans. Pattern Analysis and Machine Intelligence, Computer Vision and Image Understanding, IEEE Trans. Circuits and Systems for Video Technology, and IEEE Trans. Automatic Control. &nbsp;In addition, these results were incorporated in undergraduate and graduate course levels taught by the co-PIs, short summer courses, and tutorials at major conferences. IThese results also led to the creation of a new course that specifically addresses the issue of handling large data sets&nbsp;</span><span>with an underlying dynamically sparse structure. Finally, several graduate students from under-represented groups were involved in this project.</span></p><br> <p>            Last Modified: 11/28/2018<br>      Modified by: Octavia&nbsp;I&nbsp;Camps</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The recent exponential growth in data collection capabilities has the potential to profoundly impact society, with benefits ranging from safer, self aware environments, to sustainable use of scarce resources. A major impediment to realizing this vision stems from the curse of dimensionality. Simply put, state-of-the art techniques at the time this research was started were ill-equipped to deal with the "data deluge".  To address this issue, the goal of this research was   to develop a comprehensive, computationally tractable framework for addressing a broad class of computer vision problems that entail extracting information very sparsely encoded in noisy, high volume video or image data. At its core is a unified vision, centered on the use of dynamical invariants as information encapsulators, and emphasizing robustness and computational complexity issues.  This project outcomes include algorithms for fine grain classification, outlier rejection for linear subspace clustering, dynamics-based multi-camera segmentation in unsynchronized videos, person re-identification, multi-camera tracking, gesture recognition, 3d activity recognition, robust estimation of the Fundamental Matrix for stereo systems, and chronological sorting of crowd-sourced images.  These are key enablers for endowing vision-based  systems with substantially enhanced capabilities to extract information sparsely encoded in extremely large data sets. Such a capability has the potential to significantly benefit society. Spatially distributed vision sensors endowed with activity analysis capabilities can prevent crime, help optimize resource use in smart buildings, and give early warning of serious medical conditions for instance by detecting minute gait alterations preceding a stroke. In addition, the proposed research resulted in significant cross&ndash;fertilization with other branches of engineering and applied mathematics. An example is the connection between high dimensional data analysis (computer vision, machine learning), hybrid dynamical systems (systems theory) and rank minimization (optimization, sparse signal recovery).  The results  obtained during this research were disseminated to the  community through publications in the major conferences: CVPR, ICCV,  ECCV, and CDC and journals: IEEE. Trans. Pattern Analysis and Machine Intelligence, Computer Vision and Image Understanding, IEEE Trans. Circuits and Systems for Video Technology, and IEEE Trans. Automatic Control.  In addition, these results were incorporated in undergraduate and graduate course levels taught by the co-PIs, short summer courses, and tutorials at major conferences. IThese results also led to the creation of a new course that specifically addresses the issue of handling large data sets with an underlying dynamically sparse structure. Finally, several graduate students from under-represented groups were involved in this project.       Last Modified: 11/28/2018       Submitted by: Octavia I Camps]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
