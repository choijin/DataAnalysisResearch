<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Leveraging 3D structure estimates for photo collection based geo-localization and semantic indexing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>282521.00</AwardTotalIntnAmount>
<AwardAmount>282521</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project advances the state of the art by utilizing geometric consistency as a mid-level visual similarity cue used to develop a visual index of a geo-located image dataset and use the attained data associations as a means to infer semantic relationship among dataset elements. The characterization of the image content in terms of the geometric and semantic elements observed in scene provides a general framework for both identifying and managing data association in large scale photo collections. The project develops such complementary data abstractions into a single framework by focusing on two main research topics: (1) Determining the geographic location where an image was taken by comparing it against a large database of geo-located urban imagery - accordingly, the challenge of balancing both search completeness and computational tractability is brought to the forefront of research efforts; and&lt;br/&gt;(2) Incorporating geometric structure estimates attained from large photo-collections or ground reconnaissance video/photos as a means to identify and recognize semantically meaningful elements within the reconstructed 3D-environment.&lt;br/&gt;&lt;br/&gt;This project leverages the use geometric consistency as a visual data association primitive in order to introduce the concept of structural and semantic indexing within the development internet scale photo collection analysis systems. Moreover, by combining the complementary data abstraction levels of geometrical structure and semantic context the research team develops more efficient and robust data organization framework with applicability well beyond the studied test application of urban geo-localization.</AbstractNarration>
<MinAmdLetterDate>09/13/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1349074</AwardID>
<Investigator>
<FirstName>Jan-Michael</FirstName>
<LastName>Frahm</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jan-Michael Frahm</PI_FULL_NAME>
<EmailAddress>jmf@cs.unc.edu</EmailAddress>
<PI_PHON>9195906003</PI_PHON>
<NSF_ID>000427356</NSF_ID>
<StartDate>09/13/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Enrique</FirstName>
<LastName>Dunn</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Enrique Dunn</PI_FULL_NAME>
<EmailAddress>edunn@stevens.edu</EmailAddress>
<PI_PHON>9194444333</PI_PHON>
<NSF_ID>000623882</NSF_ID>
<StartDate>09/13/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Chapel Hill]]></Name>
<CityName>Chapel Hill</CityName>
<StateCode>NC</StateCode>
<ZipCode>275993175</ZipCode>
<StreetAddress><![CDATA[201 S Columbia St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>M636</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>170E</Code>
<Text>Interagency Agreements</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~282521</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>We advanced the state of the art in Internet photo collection based 3D modeling, i.e. creating a 3D model and identifying semantic scene elements using just the 2D photo graphs of the scene found on the Internet. Moreover, we leveraged the 3D model and the identified appearance and semantic scene elements to localize newly obtained photographs of the scene. In particular our researched methods utilize geometric consistency as a mid-level visual similarity cue to obtain a visual index of the geo-located images in the dataset and then use the attained data associations as a means to infer semantic relationship among dataset elements. The characterization of the image content in terms of the geometric and semantic elements observed in scene provides a general framework for both identifying and managing data association in large scale photo collections. We developed such complementary data abstractions into a single framework by focusing on two main research topics:</p> <p><br />1. Determining the geographic location where an image was taken by comparing it against a large database of geo-located imagery. Our method balances both the search completeness and computational tractability through novel a data association algorithm achieving scalability through linear computational complexity.</p> <p><br />2. We incorporated the geometric structure estimates attained from large photo-collections or ground reconnaissance video/photos as a means to identify and recognize semantic elements within the reconstructed 3D-environment.</p> <p><br />The proposed research leverages geometric consistency as a visual data association primitive in order to introduce the concept of structural and semantic indexing within the development internet scale photo collection analysis algorithm. Moreover, by combining the complementary data abstraction levels of geometrical structure and semantic context we developed a more efficient and robust data organization framework with applicability well beyond the studied test application of landmark based geo-localization.</p> <p><br />We successfully researched large-scale Structure-from-Motion systems that reduced the major computational effort typically spend on pairwise image matching and geometric verification. Specifically we proposed a new method (called PAIGE) to classify potential scene overlap of image pairs by using its global motion pattern semantic. This improves the effectiveness of discovering connected components in large-scale, unordered Internet image collections. Our method learns to efficiently identify image pairs with scene overlap based on our novel image appearance and topology descriptor without the need to perform exhaustive putative matching and geometric verification.&nbsp;</p> <p><br />Our team researched a novel large-scale, structure-from-motion framework that enables scalable modeling from world scale dataset of tens of millions of unordered Internet images. In particular our method is able to perform modeling on a single PC instead of cloud computing platforms. Our system employs the global topology of the appearance features of each scene's photos to build a scene index. This index enables a highly efficient grouping of Internet photos that leads to highly efficient to a linear complexity connected component discovery, which is a critical element for scalability. The researched system was tested and developed on the first world scale data set of 100 million image crowd-sourced photo collection containing images of users from the entire world.&nbsp;</p> <p><br />Previously the scalable large-scale structure from motion methods often boosted scalability by compromising the level of detail of the reconstructed model due to the delicate tradeoff between overlap detection sensitivity (needed for detailed reconstructions) and the related computational effort. To mitigate this tradeoff we proposed a close feedback loop system t...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ We advanced the state of the art in Internet photo collection based 3D modeling, i.e. creating a 3D model and identifying semantic scene elements using just the 2D photo graphs of the scene found on the Internet. Moreover, we leveraged the 3D model and the identified appearance and semantic scene elements to localize newly obtained photographs of the scene. In particular our researched methods utilize geometric consistency as a mid-level visual similarity cue to obtain a visual index of the geo-located images in the dataset and then use the attained data associations as a means to infer semantic relationship among dataset elements. The characterization of the image content in terms of the geometric and semantic elements observed in scene provides a general framework for both identifying and managing data association in large scale photo collections. We developed such complementary data abstractions into a single framework by focusing on two main research topics:   1. Determining the geographic location where an image was taken by comparing it against a large database of geo-located imagery. Our method balances both the search completeness and computational tractability through novel a data association algorithm achieving scalability through linear computational complexity.   2. We incorporated the geometric structure estimates attained from large photo-collections or ground reconnaissance video/photos as a means to identify and recognize semantic elements within the reconstructed 3D-environment.   The proposed research leverages geometric consistency as a visual data association primitive in order to introduce the concept of structural and semantic indexing within the development internet scale photo collection analysis algorithm. Moreover, by combining the complementary data abstraction levels of geometrical structure and semantic context we developed a more efficient and robust data organization framework with applicability well beyond the studied test application of landmark based geo-localization.   We successfully researched large-scale Structure-from-Motion systems that reduced the major computational effort typically spend on pairwise image matching and geometric verification. Specifically we proposed a new method (called PAIGE) to classify potential scene overlap of image pairs by using its global motion pattern semantic. This improves the effectiveness of discovering connected components in large-scale, unordered Internet image collections. Our method learns to efficiently identify image pairs with scene overlap based on our novel image appearance and topology descriptor without the need to perform exhaustive putative matching and geometric verification.    Our team researched a novel large-scale, structure-from-motion framework that enables scalable modeling from world scale dataset of tens of millions of unordered Internet images. In particular our method is able to perform modeling on a single PC instead of cloud computing platforms. Our system employs the global topology of the appearance features of each scene's photos to build a scene index. This index enables a highly efficient grouping of Internet photos that leads to highly efficient to a linear complexity connected component discovery, which is a critical element for scalability. The researched system was tested and developed on the first world scale data set of 100 million image crowd-sourced photo collection containing images of users from the entire world.    Previously the scalable large-scale structure from motion methods often boosted scalability by compromising the level of detail of the reconstructed model due to the delicate tradeoff between overlap detection sensitivity (needed for detailed reconstructions) and the related computational effort. To mitigate this tradeoff we proposed a close feedback loop system that closely couples reconstruction steps and retrieval efforts. This allows us to preserve scalability and to still recover connectivity e...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
