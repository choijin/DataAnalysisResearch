<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NeTS: Small: Meta-Networking Research: Analysis, Partitioning, and Mapping Tools for Large Experiments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>325785.00</AwardTotalIntnAmount>
<AwardAmount>325785</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Brassil</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project attacks the pressing research problem of scaling and semi-automating large network experiments.  Networking research is technically challenging due to the great scale and heterogeneity of protocols and devices in the Internet that researchers need to experiment with. To address this the project will investigate and tackle the problems of resource limitations and experimental artifacts of the testing platforms and scaling techniques. Work to date has either focused on control plane protocols (e.g., routing simulators), or solely considered the data plane. This project's goal is to conduct experiments that are joint control plane and data plane at a scale not previously possible.  &lt;br/&gt;&lt;br/&gt;The project project includes three complementary efforts to address experimentation scale challenges by designing:&lt;br/&gt;&lt;br/&gt;(1) Experiment Mapping Tools and Taxonomy: The project will design a general framework, taxonomy, and a set of tools to bridge the current gap between testbed users and large-scale testbed experiments that use multiple scaling techniques. The user can supply hints on desired fidelity of different components, and these will be used to determine a high fidelity mapping for the experiment.&lt;br/&gt;(2) Experiment Analysis and Partitioning Tools: The project will design methods to model complex dependencies between components of a large-scale experiment to facilitate planning and mapping. These models may also allow partitioning the large experiment into maximally independent smaller experiments that can be sequentially executed to mimic the large experiment.&lt;br/&gt;(3) Applications to Case Studies: The project will use a range of large experiments as applications, focusing on problematic experiments including (a) experiments to understand the effect of misconfigurations, attacks, and defenses on Internet infrastructure (e.g., scalability of RPKI, effect of worms or DDoS on BGP, BGP policy conflicts), (b) experiments for anomaly detection, and (c) experiments with cloud computing.&lt;br/&gt;&lt;br/&gt;The research will help identify and deploy scalable protocols that will enable the Internet to securely accommodate increased traffic volumes. Impacts of the research include the development and public dissemination of general-purpose experimental tools, large-scale testing techniques, methodologies for the use of testing frameworks, and related graduate-level courseware. The PI will undertake significant outreach efforts to simulation and testbed teams, e.g., DETER/Emulab, GENI, AutoNetkit, ns-3, and to industry. The PI will actively involve undergraduate and graduate students from under-represented minority groups in computer science in the research and educational efforts, and will organize a DIMACS workshop on project topics.</AbstractNarration>
<MinAmdLetterDate>08/20/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1319924</AwardID>
<Investigator>
<FirstName>Sonia</FirstName>
<LastName>Fahmy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sonia Fahmy</PI_FULL_NAME>
<EmailAddress>fahmy@cs.purdue.edu</EmailAddress>
<PI_PHON>7654946183</PI_PHON>
<NSF_ID>000284715</NSF_ID>
<StartDate>08/20/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<StreetAddress2><![CDATA[155 S Grant Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072051394</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PURDUE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072051394</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Purdue University]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479072107</ZipCode>
<StreetAddress><![CDATA[305 N. University St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~325785</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project has advanced the knowledge of the limitations of high-fidelity large-scale Internet experimentation, and has developed new tools to analyze, partition, and map a variety of large computer network experiments onto simulators, testbeds, and their hybrids, with high fidelity. The research has increased our fundamental understanding of today's experimentation systems, tools, and scaling techniques, and the classes of experiments that are appropriate on each system. The tools developed in this project have enabled complex computer network experiments at a scale not previously possible by designing:</p> <p>(1) Experiment Mapping Tools and Taxonomy: This includes a general framework called EasyScale, a mapping algorithm called the Waterfall algorithm, and a set of tools to bridge the current gap between testbed users and large-scale testbed experiments that use multiple scaling techniques. The user can supply hints on desired fidelity of different components, and these are used to determine a high fidelity mapping for the experiment.&nbsp;Multiple scaling techniques, such as virtualization and real-time simulators, can be used for different parts of the input experimental topology in order to balance scalability and fidelity.&nbsp;<br /><br />(2) Experiment Analysis and Partitioning Tools: This includes methods to model dependencies between components of a large-scale experiment to facilitate planning and mapping.&nbsp; An example model and partitioning method is based on traffic flows in an experiment. This is called Flow-based Scenario Partitioning (FSP). FSP&nbsp;allows partitioning a large experiment into maximally independent smaller experiments that can be sequentially executed on a small testbed to mimic the large experiment.<br /><br />(3) Applications to Case Studies:&nbsp; The techniques developed in this project have been evaluated on a range of large network experiments as applications, including security experiments with distributed denial of service attacks, Internet routing experiments, and experiments with data centers.</p> <p>Additionally, this project has produced new programming assignments for undergraduate and graduate courses on computer networks.&nbsp;These programming assignments were shared with a number of faculty members at several academic institutions.</p> <p>The project has made contributions to the development and realistic testing of new network architectures that make the Internet robust to cyber attacks and increase Internet performance. The work not only contributed to the tools available for researchers to test their Internet architectures, but also developed guidance and benchmarks for testing these mechanisms in realistic environments in a reproducible and scalable manner. These are likely to make cyber-infrastructure more trustworthy and resilient, and enable novel applications.</p> <p>The publications and some of the software developed in this project have been disseminated to interested researchers, educators, and the industry, and on the project web page. The results have also been presented at major computer networking conferences and workshops.</p> <p>The project has provided training&nbsp;for several graduate students, and has involved several additional undergraduate and graduate students. These students now have a better grasp of the fields of computer networking and software testing. They have gained an appreciation of the difficulty of testing new computer network designs and mechanisms in a realistic environment. They have also learned about the emerging technologies of Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) which we have used as case studies.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/08/2017<br>      Modified by: Sonia&nbsp;Fahmy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project has advanced the knowledge of the limitations of high-fidelity large-scale Internet experimentation, and has developed new tools to analyze, partition, and map a variety of large computer network experiments onto simulators, testbeds, and their hybrids, with high fidelity. The research has increased our fundamental understanding of today's experimentation systems, tools, and scaling techniques, and the classes of experiments that are appropriate on each system. The tools developed in this project have enabled complex computer network experiments at a scale not previously possible by designing:  (1) Experiment Mapping Tools and Taxonomy: This includes a general framework called EasyScale, a mapping algorithm called the Waterfall algorithm, and a set of tools to bridge the current gap between testbed users and large-scale testbed experiments that use multiple scaling techniques. The user can supply hints on desired fidelity of different components, and these are used to determine a high fidelity mapping for the experiment. Multiple scaling techniques, such as virtualization and real-time simulators, can be used for different parts of the input experimental topology in order to balance scalability and fidelity.   (2) Experiment Analysis and Partitioning Tools: This includes methods to model dependencies between components of a large-scale experiment to facilitate planning and mapping.  An example model and partitioning method is based on traffic flows in an experiment. This is called Flow-based Scenario Partitioning (FSP). FSP allows partitioning a large experiment into maximally independent smaller experiments that can be sequentially executed on a small testbed to mimic the large experiment.  (3) Applications to Case Studies:  The techniques developed in this project have been evaluated on a range of large network experiments as applications, including security experiments with distributed denial of service attacks, Internet routing experiments, and experiments with data centers.  Additionally, this project has produced new programming assignments for undergraduate and graduate courses on computer networks. These programming assignments were shared with a number of faculty members at several academic institutions.  The project has made contributions to the development and realistic testing of new network architectures that make the Internet robust to cyber attacks and increase Internet performance. The work not only contributed to the tools available for researchers to test their Internet architectures, but also developed guidance and benchmarks for testing these mechanisms in realistic environments in a reproducible and scalable manner. These are likely to make cyber-infrastructure more trustworthy and resilient, and enable novel applications.  The publications and some of the software developed in this project have been disseminated to interested researchers, educators, and the industry, and on the project web page. The results have also been presented at major computer networking conferences and workshops.  The project has provided training for several graduate students, and has involved several additional undergraduate and graduate students. These students now have a better grasp of the fields of computer networking and software testing. They have gained an appreciation of the difficulty of testing new computer network designs and mechanisms in a realistic environment. They have also learned about the emerging technologies of Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) which we have used as case studies.          Last Modified: 11/08/2017       Submitted by: Sonia Fahmy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
