<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: From Matrix Computations to Tensor Computations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>347999.00</AwardTotalIntnAmount>
<AwardAmount>347999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Libraries for matrix computations have had a huge impact on computational science since many computations can be cast in terms of linear algebra.  As a result, widely used libraries have been available and in broad use for decades.  More recently, multi-linear computations, also known as tensor computations, have become important.  Application areas include computational chemistry, physics, and large data analysis. Until now, little research has been dedicated towards the development of high quality, high performing libraries for such computations.  This project will make strides towards remedying this.&lt;br/&gt;&lt;br/&gt;This project transfers insights from more than a decade of research and development of dense linear algebra libraries as part of the NSF-sponsored FLAME project to the field of tensor computations.  The goal is to create new abstractions for expressing algorithms and their implementations, to derive new algorithms that can take advantage of symmetry in tensors, and discover how to take advantage of the memory hierarchies of modern processors.  A prototype library will be implemented and made available to the scientific computing community.   Together, this will advance the state-of-the-art in this domain.</AbstractNarration>
<MinAmdLetterDate>08/05/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320112</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>van de Geijn</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert A van de Geijn</PI_FULL_NAME>
<EmailAddress>rvdg@cs.utexas.edu</EmailAddress>
<PI_PHON>5124719720</PI_PHON>
<NSF_ID>000336892</NSF_ID>
<StartDate>08/05/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Field</FirstName>
<LastName>Van Zee</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Field G Van Zee</PI_FULL_NAME>
<EmailAddress>field@cs.utexas.edu</EmailAddress>
<PI_PHON>5124152863</PI_PHON>
<NSF_ID>000637140</NSF_ID>
<StartDate>08/05/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787137726</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>21</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX21</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~347999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Tensor computations have applications in the sciences (for example, computational molecular dynamics) and, more recently, machine learning.&nbsp; A tensor can be thought of as a represention of a multilinear transformation or, more simply, a high dimensional array of data. Since the data sets on which these computations are performed are huge, high performance software libraries are of critical importance both in order to reduce the time required for solving a given problem and to reduce the cost when using some of the fastest computers in the world.&nbsp; The project developed new techniques for implementing such software libraries targeting both individual processors and massively parallel distributed memory supercomputer.&nbsp; The techniques were then used to instantiate high-performance code.</p> <p>The intellectual merrit of the research lies with a new notation for describing computations with large high-dimensional tensors and new open-source software that leverages that notation for implementations targeting distributed memory architectures.&nbsp; This has resulted in a number of publications in top journals, one Ph.D. dissertation, and two undergraduate honors theses.&nbsp; The broader impact lies with the science beyond computer science that it facilitates and, importantly, the training of two undergraduates, both of whom were from traditionally underrepresented groups.&nbsp; These individuals have accepted admission into top Ph.D. programs in computer science.&nbsp;&nbsp;</p><br> <p>            Last Modified: 04/20/2018<br>      Modified by: Robert&nbsp;A&nbsp;Van De Geijn</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Tensor computations have applications in the sciences (for example, computational molecular dynamics) and, more recently, machine learning.  A tensor can be thought of as a represention of a multilinear transformation or, more simply, a high dimensional array of data. Since the data sets on which these computations are performed are huge, high performance software libraries are of critical importance both in order to reduce the time required for solving a given problem and to reduce the cost when using some of the fastest computers in the world.  The project developed new techniques for implementing such software libraries targeting both individual processors and massively parallel distributed memory supercomputer.  The techniques were then used to instantiate high-performance code.  The intellectual merrit of the research lies with a new notation for describing computations with large high-dimensional tensors and new open-source software that leverages that notation for implementations targeting distributed memory architectures.  This has resulted in a number of publications in top journals, one Ph.D. dissertation, and two undergraduate honors theses.  The broader impact lies with the science beyond computer science that it facilitates and, importantly, the training of two undergraduates, both of whom were from traditionally underrepresented groups.  These individuals have accepted admission into top Ph.D. programs in computer science.         Last Modified: 04/20/2018       Submitted by: Robert A Van De Geijn]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
