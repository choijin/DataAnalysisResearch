<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: CDS&amp;E-MSS: Robust Algorithms for Interpolation and Extrapolation in Manifold Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>139907.00</AwardTotalIntnAmount>
<AwardAmount>139907</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927902</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The objective of this proposal is to develop robust algorithms for reconstructing or synthesizing highly structured high-dimensional data based on a low-dimensional representation learned from a training dataset, i.e., the interpolation and extrapolation problems in manifold learning. The project will address the elusive issue of computing a usually not well-defined low-dimensional parametrization in the setting of various interpolation and extrapolation problems for manifold learning, emphasizing the notion of physically meaningful paramterizations. It will develop innovative computational methodology for flexibly learning a low-dimensional parametrization together with other physically important variables in the context of both unsupervised and semi-supervised learning and especially active learning settings, for learning and synthesis of dynamic data, and for manifold extrapolation based on transfer learning. Included in the project is a development of a publicly available software package which will disseminate the research results and promote applications of nonlinear dimension reduction methodology to real-world problems.&lt;br/&gt;&lt;br/&gt;The discoveries from this proposed research are expected to impact a wide range of areas of applications. Computing compact representation of high-dimensional data represents a very challenging statistical learning problem, and manifold learning has become a very active research field aiming at discovering hidden structures from the statistical and geometric regularity inherent in many high-dimensional data. Reconstruction and synthesis of high-dimensional data in the context of interpolation and extrapolation will have significant applications in image and video processing, computer vision, video surveillance for homeland security, computational biology, and scientific visualization. The proposed theoretical tools and computational methods have the promise of significantly expanding the applicability and functionality of existing and new manifold learning methods and thus advancing the state of the art in nonlinear dimension reduction research. The proposed research lies at the interface between applied mathematics, computational science, and machine learning applications and provides an ideal setting for research cross-fertilization and collaboration as well as training of graduate students in interdisciplinary research.</AbstractNarration>
<MinAmdLetterDate>07/14/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/14/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1317424</AwardID>
<Investigator>
<FirstName>Qiang</FirstName>
<LastName>Ye</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qiang Ye</PI_FULL_NAME>
<EmailAddress>qye3@uky.edu</EmailAddress>
<PI_PHON>8592574653</PI_PHON>
<NSF_ID>000482987</NSF_ID>
<StartDate>07/14/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Kentucky Research Foundation</Name>
<CityName>Lexington</CityName>
<ZipCode>405260001</ZipCode>
<PhoneNumber>8592579420</PhoneNumber>
<StreetAddress>109 Kinkead Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>KY06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>939017877</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF KENTUCKY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007400724</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Kentucky Research Foundation]]></Name>
<CityName>Lexington</CityName>
<StateCode>KY</StateCode>
<ZipCode>405260001</ZipCode>
<StreetAddress><![CDATA[500 S. Limestone, 109 Kinkead]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>KY06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramElement>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~139907</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project has produced some significant advances in the theory and algorithms for supervised or unsupervised learning of highly structured data. We have adapted the manifold learning methodology to derive an efficient algorithm for the task of outlier detection for noisy data, which allows more general nonlinear models for the data. We have developed new recurrent neural networks with orthogonal state transition matrices that may significantly improve their capability in learning long term dependency in sequential data. Our network has also substantially reduced complexity in training. On the theoretical front, we have derived a rigorous mathematical analysis of the discrete Hessian EigenMap method for nonlinear dimensionality reduction, which addresses the need to understand how these wonderful machine learning algorithms work.<br /><br />The project has also led to a novel application of recurrent neural networks to biological data and some improved software tools. We have successfully applied long short term memory (LSTM) networks to the state inference problem for RNA secondary structures with highly satisfactory accuracy. We have also derived an inverse-free preconditioned Krylov subspace method for computing singular values of large matrices and developed a black-box implementation called SVDIFP that has been distributed through GitHub. Our code mitigates a difficulty associated with non-square matrices in some existing singular value computation programs.</p><br> <p>            Last Modified: 10/19/2017<br>      Modified by: Qiang&nbsp;Ye</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project has produced some significant advances in the theory and algorithms for supervised or unsupervised learning of highly structured data. We have adapted the manifold learning methodology to derive an efficient algorithm for the task of outlier detection for noisy data, which allows more general nonlinear models for the data. We have developed new recurrent neural networks with orthogonal state transition matrices that may significantly improve their capability in learning long term dependency in sequential data. Our network has also substantially reduced complexity in training. On the theoretical front, we have derived a rigorous mathematical analysis of the discrete Hessian EigenMap method for nonlinear dimensionality reduction, which addresses the need to understand how these wonderful machine learning algorithms work.  The project has also led to a novel application of recurrent neural networks to biological data and some improved software tools. We have successfully applied long short term memory (LSTM) networks to the state inference problem for RNA secondary structures with highly satisfactory accuracy. We have also derived an inverse-free preconditioned Krylov subspace method for computing singular values of large matrices and developed a black-box implementation called SVDIFP that has been distributed through GitHub. Our code mitigates a difficulty associated with non-square matrices in some existing singular value computation programs.       Last Modified: 10/19/2017       Submitted by: Qiang Ye]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
