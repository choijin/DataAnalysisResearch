<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Geometric Measure Theory and Geometric Function Theory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2014</AwardEffectiveDate>
<AwardExpirationDate>05/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>236997.00</AwardTotalIntnAmount>
<AwardAmount>236997</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marian Bocea</SignBlockName>
<PO_EMAI>mbocea@nsf.gov</PO_EMAI>
<PO_PHON>7032922595</PO_PHON>
</ProgramOfficer>
<AbstractNarration>One aspect of modern technology is that it is easy to collect data.  A very challenging task is to sift through a large collection of  data in order to find meaningful information.  One would like to organize the data, or at least part of it, in such a way that it is easy to use.  Imagine the data as being all images on the internet, and the "organization" that you seek is being able to map out which images are those of a specific person of your choosing, subordered according to the activities in which he or she is engaged.  Organizing large amounts of information in a useful way, or sorting through it and finding pieces you care about, are tasks that can be transformed, or related to, mathematical questions.  This proposal attempts to address some of these questions.  Basic questions are mathematical analogues of the following: What kind of structure can I hope to get after organizing the data?  How much of my data can I expect to organize in a useful way? Do answers change if I am willing to "lose" some information in the process? Will I know the amount data lost? And, last but not least, can I, in a practical way, access the organized data or a significant part of it?&lt;br/&gt;&lt;br/&gt;In many applications one is given a large data set represented as a subset of a metric space, such as a high-dimensional Euclidean space, and one seeks to "faithfully" represent a "large" portion of this data set as a subset of a low-dimensional Euclidean space. "Faithfully" means in this context that one can still perform the same data mining tasks on the image of the data portion that one could on the original data set.  This task has thus far received much attention from computer scientists and applied mathematicians using a wide range of approaches. The framework of dimensionality reduction also includes data compression and data approximation. These have applications in many areas of science.  Geometric measure theory and geometric function theory are tools whose use in this matter has not been fully exploited. A key point is that often the given data set has some additional geometric structure, for example, has small Hausdorff dimension (a discrete analogue) or is close to being a union of low-dimensional manifolds. This allows one to use harmonic analysis and geometric measure theory to organize the data.  This project will study mathematical questions motivated by this observation. Two basic questions the project will attempt to answer can be phrased as follows: When is part of a metric measure space composed of Lipschitz images of "standard" pieces and how does one find these pieces? When is a collection of points best described as one-dimensional?</AbstractNarration>
<MinAmdLetterDate>06/12/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/15/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1361473</AwardID>
<Investigator>
<FirstName>Raanan</FirstName>
<LastName>Schul</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Raanan Schul</PI_FULL_NAME>
<EmailAddress>schul@math.sunysb.edu</EmailAddress>
<PI_PHON>6316328265</PI_PHON>
<NSF_ID>000007561</NSF_ID>
<StartDate>06/12/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804878247</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>020657151</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Stony Brook]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>117943366</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1281</Code>
<Text>ANALYSIS PROGRAM</Text>
</ProgramElement>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~157998</FUND_OBLG>
<FUND_OBLG>2017~78999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; min-height: 14.0px} p.p3 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #000000; -webkit-text-stroke: #000000; background-color: #ffffff; min-height: 14.0px} span.s1 {font-kerning: none; color: #000000; background-color: #ffffff; -webkit-text-stroke: 0px #000000} span.s2 {font-kerning: none} --> <p class="p1">&nbsp;</p> <p class="p1">One aspect of modern technology is that it is easy to collect data. A very challenging task is to sift through a large collection of data in order to find meaningful information. One would like to organize the data, or at least part of it, in such a way that it is easy to use. Imagine the data as being all images on the internet, and the "organization" that you seek is being able to map out which images are those of a specific person of your choosing, subordered according to the activities in which he or she is engaged. Organizing large amounts of information in a useful way, or sorting through it and finding pieces you care about, are tasks that can be transformed, or related to, mathematical questions. This project involved work related to these type of questions. <span>&nbsp;</span></p> <p class="p2">&nbsp;</p> <p class="p1">A bit more technically, the data set represented as a subset of a metric space, and one seeks to map it (or part of it) to a low dimensional Euclidean space in a way which preserves some useful properties such as pairwise distances.<span>&nbsp; </span>This naturally relates to a concept called ``rectifiability".<span>&nbsp; </span>While rectifiability is often studied in a non-quantitative way, our work has mostly been done using quantitative and constructive methods.<span>&nbsp; </span>Below we give some detail.</p> <p class="p2">&nbsp;</p> <p class="p1">With <em>Jonas Azzam</em> we wrote a paper titled <em>"An Analyst's Traveling Salesman Theorem for sets of dimension larger than one"</em> we gave a necessary and sufficient quantitative conditions for some sets to be rectifiable.<span>&nbsp; </span>The sets in question were of dimension bigger than 1. An analogues result for dimension 1 had been proven in the 1990&rsquo;s (Jones) and had a tremendous impact.</p> <p class="p2"><span>&nbsp;</span></p> <p class="p1">With <em>Matthew badger</em> we wrote a paper titled <em>"Multiscale analysis of 1-rectifiable measures II: characterizations"</em> where we characterized measures which were 1-rectifiable. The measure we studied were allowed to be non-absolutely-continuous, which is quite novel.<span>&nbsp;</span></p> <p class="p2">&nbsp;</p> <p class="p1">With <em>Guy David</em> we wrote two papers, <em>"The Analyst's traveling salesman theorem in graph inverse limits"</em> and <em>"A sharp necessary condition for rectifiable curves in metric spaces"</em>. Both these papers study 1-rectifiability in metric spaces.<span>&nbsp; </span>the former, in a specific example of a metric space, and the latter in a generic metric space.</p> <p class="p2">&nbsp;</p> <p class="p1">Finally, <em>Silvia Ghinassi</em>, a phD student supported in part by this grant, had studied conditions for higher order rectifiability. i.e. when can sets or measures be parametrized in a smooth way by a low dimensional Euclidean space.<span>&nbsp; </span>Her thesis was titled &ldquo;<span class="s1"><em>Higher order rectifiability via Reifenberg theorems for sets and measures&rdquo;.</em></span></p> <p class="p3"><span class="s2"><em>&nbsp;</em></span></p> <p class="p3"><span class="s2"><em>&nbsp;</em></span></p> <p>&nbsp;</p><br> <p>            Last Modified: 07/01/2019<br>      Modified by: Raanan&nbsp;Schul</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   One aspect of modern technology is that it is easy to collect data. A very challenging task is to sift through a large collection of data in order to find meaningful information. One would like to organize the data, or at least part of it, in such a way that it is easy to use. Imagine the data as being all images on the internet, and the "organization" that you seek is being able to map out which images are those of a specific person of your choosing, subordered according to the activities in which he or she is engaged. Organizing large amounts of information in a useful way, or sorting through it and finding pieces you care about, are tasks that can be transformed, or related to, mathematical questions. This project involved work related to these type of questions.     A bit more technically, the data set represented as a subset of a metric space, and one seeks to map it (or part of it) to a low dimensional Euclidean space in a way which preserves some useful properties such as pairwise distances.  This naturally relates to a concept called ``rectifiability".  While rectifiability is often studied in a non-quantitative way, our work has mostly been done using quantitative and constructive methods.  Below we give some detail.   With Jonas Azzam we wrote a paper titled "An Analyst's Traveling Salesman Theorem for sets of dimension larger than one" we gave a necessary and sufficient quantitative conditions for some sets to be rectifiable.  The sets in question were of dimension bigger than 1. An analogues result for dimension 1 had been proven in the 1990?s (Jones) and had a tremendous impact.   With Matthew badger we wrote a paper titled "Multiscale analysis of 1-rectifiable measures II: characterizations" where we characterized measures which were 1-rectifiable. The measure we studied were allowed to be non-absolutely-continuous, which is quite novel.    With Guy David we wrote two papers, "The Analyst's traveling salesman theorem in graph inverse limits" and "A sharp necessary condition for rectifiable curves in metric spaces". Both these papers study 1-rectifiability in metric spaces.  the former, in a specific example of a metric space, and the latter in a generic metric space.   Finally, Silvia Ghinassi, a phD student supported in part by this grant, had studied conditions for higher order rectifiability. i.e. when can sets or measures be parametrized in a smooth way by a low dimensional Euclidean space.  Her thesis was titled "Higher order rectifiability via Reifenberg theorems for sets and measures".              Last Modified: 07/01/2019       Submitted by: Raanan Schul]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
