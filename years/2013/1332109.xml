<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Nonparametric Structure Learning for Complex Scientific Datasets</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>407185.00</AwardTotalIntnAmount>
<AwardAmount>407185</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The project brings together an interdisciplinary team of researchers from Johns Hopkins University, Carnegie Mellon University, and the University of Chicago to develop methods, theory and algorithms for discovering hidden structure from complex scientific datasets, without making strong a priori assumptions.  The outcomes include practical models and provably correct algorithms that can help scientists to conduct sophisticated data analysis. The application areas include genomics, cognitive neuroscience, climate science, astrophysics, and language processing.&lt;br/&gt;&lt;br/&gt;The project has five aims: (i) Nonparametric structure learning in high dimensions: In a standard structure learning problem, observations of a random vector X are available and the goal is to estimate the structure of the distribution of X.  When the dimension is large, nonparametric structure learning becomes challenging.  The project develops new methods and establishes theoretical guarantees for this problem; (ii)  Nonparametric conditional structure learning: In many applications, it is of interest to estimate the structure of a high-dimensional random vector X conditional on another random vector Z . Nonparametric methods for estimating the structure of X given Z are being developed, building on recent approaches to graph-valued and manifold-valued regression developed by the investigators; (iii) Regularization parameter selection: Most structure learning algorithms have at least one tuning parameter that controls the bias-variance tradeoff. Classical methods for selecting tuning parameters are not suitable for complex nonparametric structure learning problems.  The project explores stability-based approaches for regularization selection; (iv)  Parallel and online nonparametric learning: Handling large-scale data is a bottleneck of many nonparametric methods.  The project develops parallel and online techniques to extend nonparametric learning algorithms to large scale problems;  (v) Minimax theory for nonparametric structure learning problems: Minimax theory characterizes the performance limits for learning algorithms.  Few theoretical results are known for complex, high-dimensional nonparametric structure learning.  The project develops new minimax theory in this setting. The results of this project will be disseminated through publications in scientific journals and major conferences, and free dissemination of software that implements the nonparametric structure learning algorithms resulting from this research.&lt;br/&gt;&lt;br/&gt;The broader impacts of the project include: Creation of powerful data analysis techniques and software to a wide range of scientists and engineers to analyze and understand more complex scientific data;  Increased collaboration and interdisciplinary interactions between researchers at multiple institutions (Johns Hopkins University, Carnegie Mellon University, and the University of Chicago); and Broad dissemination of the results of this research in different scientific communities.   Additional information about the  project can be found at: http://www.cs.jhu.edu/~hanliu/nsf116730.html.</AbstractNarration>
<MinAmdLetterDate>03/14/2013</MinAmdLetterDate>
<MaxAmdLetterDate>03/14/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1332109</AwardID>
<Investigator>
<FirstName>Han</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Han Liu</PI_FULL_NAME>
<EmailAddress>hanliu@northwestern.edu</EmailAddress>
<PI_PHON>4122603224</PI_PHON>
<NSF_ID>000582220</NSF_ID>
<StartDate>03/14/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress><![CDATA[Charlton St. Sherrerd Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~52400</FUND_OBLG>
<FUND_OBLG>2012~354785</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1"><span class="s1">This research created a new field named Nonparametric Sparsity, which exploits novel sparsity-inducing regularization techniques to fit nonparametric graphical models. The supported research has successfully built the fundamental principles and theory of this new field.&nbsp; In particular, the project improved upon current techniques and attacked several important bottlenecks of nonparametric structure learning by developing (i) new models and methods that enable high-dimensional nonparametric structure learning, (ii) new computational techniques that enable scalable nonparametric learning in online and parallel fashion, and (iii) new statistical theory that characterizes the performance and information-theoretic limits of nonparametric structure learning algorithms. The deliverables of this project include practical algorithms that can help scientists to conduct sophisticated data analysis and rigorous theory to justify these methods. The supported research has led to more than 40 journal publications, along with more than 2,600 citations and 8 best paper awards.&nbsp;</span>&nbsp;</p> <p class="p1"><span class="s1">In addition, this research exceeds fundamental theory and directly impacts the society. For example, the PI has applied structured nonparametric nonparametric graphical models to analyze high dimensional genomic data. The results of this study were astounding identified several gene mutations that sharply increase the chances that a child will develop autism. The results were published in Nature and featured in a full length article in the New York Times. To better disseminate research results, the PI has developed and is maintaining 6 high quality statistical software packages. All of these are freely available on CRAN</span></p> <p class="p1">&nbsp;</p><br> <p>            Last Modified: 01/04/2016<br>      Modified by: Han&nbsp;Liu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[This research created a new field named Nonparametric Sparsity, which exploits novel sparsity-inducing regularization techniques to fit nonparametric graphical models. The supported research has successfully built the fundamental principles and theory of this new field.  In particular, the project improved upon current techniques and attacked several important bottlenecks of nonparametric structure learning by developing (i) new models and methods that enable high-dimensional nonparametric structure learning, (ii) new computational techniques that enable scalable nonparametric learning in online and parallel fashion, and (iii) new statistical theory that characterizes the performance and information-theoretic limits of nonparametric structure learning algorithms. The deliverables of this project include practical algorithms that can help scientists to conduct sophisticated data analysis and rigorous theory to justify these methods. The supported research has led to more than 40 journal publications, along with more than 2,600 citations and 8 best paper awards.   In addition, this research exceeds fundamental theory and directly impacts the society. For example, the PI has applied structured nonparametric nonparametric graphical models to analyze high dimensional genomic data. The results of this study were astounding identified several gene mutations that sharply increase the chances that a child will develop autism. The results were published in Nature and featured in a full length article in the New York Times. To better disseminate research results, the PI has developed and is maintaining 6 high quality statistical software packages. All of these are freely available on CRAN         Last Modified: 01/04/2016       Submitted by: Han Liu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
