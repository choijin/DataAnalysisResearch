<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS:DSD:Synthesizing Domain Specific Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>260000.00</AwardTotalIntnAmount>
<AwardAmount>260000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>tao li</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Information technology is now a major catalyst for innovation across all aspects of human endeavor. Hence, it is vital to maintain the exponential performance growth of computing devices that has been the key enabler for information technology advances for more than four decades. In the past, semiconductor technology provided us with increasing transistor densities and decreasing power supplies, allowing us to improve performance without increasing energy consumption. However, the lack of power supply scaling in current and future technologies has made all computing systems energy limited. Improving energy efficiency is a defining challenge and the prerequisite to increasing the capabilities of all computing systems, from smartphones to warehouse-scale data-centers.&lt;br/&gt; &lt;br/&gt;The goal of this project is to enable cost-effective customized computing by bridging the gap between high-level application development and the design of specialized hardware for energy efficient computing. Specialization is the prevailing approach for energy efficient computing, as customized units can eliminate the energy overheads of general-purpose cores. However, the complexity of designing and managing customized hardware is currently limiting the benefits from specialization to high-volume, slowly evolving applications. We will create domain specific synthesis tools that, given an application written in an easy-to-use, domain-specific programming language, will generate domain or application specific hardware: compute units and memory systems. The core of our approach to domain specific synthesis is a combination of domain specific languages to capture high-level application information, domain-specific optimization, parallelism and locality optimization, and hardware generation from parallelism and locality patterns.</AbstractNarration>
<MinAmdLetterDate>09/10/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/10/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1337375</AwardID>
<Investigator>
<FirstName>Oyekunle</FirstName>
<LastName>Olukotun</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Oyekunle A Olukotun</PI_FULL_NAME>
<EmailAddress>kunle@stanford.edu</EmailAddress>
<PI_PHON>6507253713</PI_PHON>
<NSF_ID>000320046</NSF_ID>
<StartDate>09/10/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Christoforos</FirstName>
<LastName>Kozyrakis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christoforos Kozyrakis</PI_FULL_NAME>
<EmailAddress>kozyraki@stanford.edu</EmailAddress>
<PI_PHON>6507253716</PI_PHON>
<NSF_ID>000486618</NSF_ID>
<StartDate>09/10/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943059025</ZipCode>
<StreetAddress><![CDATA[353 Serra Mall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8283</Code>
<Text>Exploiting Parallel&amp;Scalabilty</Text>
</ProgramElement>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~260000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Intellectual Merit</strong></p> <p>In recent years, due to the slowing of Moore's Law and power constraints, the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising as they offer significant performance and power improvements compared to CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software development languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient.</p> <p>Under this project we have developed high-level software environments for generating high-performance FPGA designs. Functional languages with parallel patterns are a good fit for hardware generation because they both provide high-level abstractions for programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages like C++. We have &nbsp;identified two key optimizations that are important for translating parallel patterns into efficient hardware: tiling and metapipelining (hierarchical pipelining). We have developed a general representation of tiled parallel patterns, and rules for automatically tiling patterns and generating metapipelines. We have demonstrated &nbsp;that these optimizations result in speedups up to 40 times on a set of benchmarks from the data analytics domain.</p> <p>&nbsp;</p> <p><strong>Broader Impacts</strong></p> <p>This project has provided for the training and professional development of three graduate students. One of these students is an underrepresented minority.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/11/2015<br>      Modified by: Oyekunle&nbsp;A&nbsp;Olukotun</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit  In recent years, due to the slowing of Moore's Law and power constraints, the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising as they offer significant performance and power improvements compared to CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software development languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient.  Under this project we have developed high-level software environments for generating high-performance FPGA designs. Functional languages with parallel patterns are a good fit for hardware generation because they both provide high-level abstractions for programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages like C++. We have  identified two key optimizations that are important for translating parallel patterns into efficient hardware: tiling and metapipelining (hierarchical pipelining). We have developed a general representation of tiled parallel patterns, and rules for automatically tiling patterns and generating metapipelines. We have demonstrated  that these optimizations result in speedups up to 40 times on a set of benchmarks from the data analytics domain.     Broader Impacts  This project has provided for the training and professional development of three graduate students. One of these students is an underrepresented minority.                      Last Modified: 12/11/2015       Submitted by: Oyekunle A Olukotun]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
