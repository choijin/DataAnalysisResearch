<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SI2-SSI: Collaborative Research: Scalable, Extensible, and Open Framework for Ground and Excited State Properties of Complex Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>2383226.00</AwardTotalIntnAmount>
<AwardAmount>2383226</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Bogdan Mihaila</SignBlockName>
<PO_EMAI>bmihaila@nsf.gov</PO_EMAI>
<PO_PHON>7032928235</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computer simulation plays a central role in helping us understand, predict, and engineer the physical and chemical properties of technological materials systems such as semiconductor devices, photovoltaic systems, chemical reactions and catalytic behavior. Despite significant progress in performing realistic simulations in full microscopic detail, some problems are currently out of reach: two examples are the modeling of electronic devices with multiple functional parts based on new materials such as novel low power computer switches that would revolutionize the Information Technology industry, and the photovoltaic activity of complex interfaces between polymers and inorganic nanostructures that would enhance US energy self-reliance.  The research program of this collaborative software institute aims to create an open and effective scientific software package that can make efficient use of cutting-edge high performance computers (HPC) to solve challenging problems involving the physics and chemistry of materials.  By having such software available, this software initiative will have multiple broad impacts.  First, the community of materials scientists will be able to study next-generation problems in materials physics and chemistry, and computer science advances that enable the software will be demonstrated and made accessible for both communities which will help cross-fertilize further such collaborative efforts.  Second, the capability of simulating and engineering more complex materials systems and technological devices could play a role in helping the US continue is competitive edge in science, technology, and education. Third, through training of young scientists, direct outreach to the broader scientific community through workshops and conferences, and educational programs ranging from secondary to graduate levels, the power, importance, and capabilities of computational modeling, materials science, and computer science methodologies that enable the science will be communicated to a broad audience.  Finally, by enabling the refinement of existing materials systems as well as discovery of new materials systems, the resulting scientific advances can help broadly impact society via technological improvements: in terms of the two examples provided above, (a) the successful design of new electronic device paradigms helps significantly advance the digital revolution by permitting the introduction of smaller, more efficient, and more capable electronic circuits and information processing systems, and (b) successful creation of inexpensive, easy-to-fabricate, and durable photovoltaic materials and devices can lead to cleaner forms of energy production while reducing reliance on fossil fuels.&lt;br/&gt;&lt;br/&gt;The technical goal is to greatly enhance the open software tool OPENATOM to advance discovery in nanoscience and technology. OPENATOM will be delivered as a open, robust and validated software package capable of utilizing HPC architectures efficiently to describe the electronic structure of complex materials systems from first principles.  In terms of describing electronic ground-states, OPENATOM will be enhanced by features such as improved configurational sampling methods, hybrid density functionals, and incorporation of fast super-soft pseudopotential techniques. In addition, the team will incorporate the many-body GW-BSE approach for electronic excitations that permits accurate computation of electronic energy levels, optical absorption and emission, and luminescence.  Ultimately, such an extensible software framework will permit accurate electronic structure computations to employ effectively future HPC platforms with 10,000,000 cores.</AbstractNarration>
<MinAmdLetterDate>09/12/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/10/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1339715</AwardID>
<Investigator>
<FirstName>Laxmikant</FirstName>
<LastName>Kale</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Laxmikant V Kale</PI_FULL_NAME>
<EmailAddress>kale@uiuc.edu</EmailAddress>
<PI_PHON>2172440094</PI_PHON>
<NSF_ID>000123469</NSF_ID>
<StartDate>09/12/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1253</Code>
<Text>OFFICE OF MULTIDISCIPLINARY AC</Text>
</ProgramElement>
<ProgramElement>
<Code>1712</Code>
<Text>DMR SHORT TERM SUPPORT</Text>
</ProgramElement>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramElement>
<Code>7231</Code>
<Text>CYBERINFRASTRUCTURE</Text>
</ProgramElement>
<ProgramElement>
<Code>8004</Code>
<Text>Software Institutes</Text>
</ProgramElement>
<ProgramElement>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7569</Code>
<Text>CYBERINFRASTRUCTURE/SCIENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8009</Code>
<Text>Scientifc Software Integration</Text>
</ProgramReference>
<ProgramReference>
<Code>8084</Code>
<Text>CDS&amp;E</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~1910000</FUND_OBLG>
<FUND_OBLG>2014~473226</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-e764fa20-7fff-5260-4116-3904af4b6dd4"> </span></p> <p dir="ltr"><span>A major goal of computational science and engineering is to predict accurately, at the atomistic level, the electronic properties of complex materials including the statistical averaging over configuration space.&nbsp; In order to meet this challenge, this project seeks to encapsulate novel computational methodologies spanning physics, chemistry, and materials simulation within a common software infrastructure that scales to large supercomputers and that encompasses the latest advances in high performance computing (HPC).</span>&nbsp;</p> <p dir="ltr"><span>We anticipate that rich software infrastructure will accelerate the delivery of solutions to challenging problems in Science and Technology.&nbsp; We targeted two drivers of great current interest, the development of fast, low power, post-CMOS architectures based on novel physics, and  cheap organic solar cells, enabled by novel new software.&nbsp; As the accurate simulation of these materials requires highly intensive computation, our focus was on reducing the time required to run those simulations.  Specifically, we made several important contributions in the development of new methods that reduce computational complexity, without sacrificing necessary accuracy, and the implementation of those methods in highly scalable parallel software.&nbsp;</span></p> <p dir="ltr"><span>The initial contribution was the fine grained parallelization of the Car-Parrinello ab-initio Molecular Dynamics method at the heart of the OpenAtom Software.&nbsp; Over the course of the project that capability was expanded to create a framework for the development of important multi-instance methods (i.e., Path-Integrals, K-points, Parallel Tempering, and Spin Density Functionals). These allow for additional scientific insights to be gained by running carefully selected variations of the target molecular system simultaneously.&nbsp; These results were peer reviewed (</span><a href="http://link.springer.com/chapter/10.1007/978-3-319-41321-1_8"><span>DOI: 10.1007/978-3-319-41321-1_8</span></a><span>) in a paper that specifically studied a Metallo-Organic Framework (MOF) molecular system for hydrogen energy storage, demonstrating unprecedented speed for the path integral simulation of realistically sized MOF systems.</span></p> <p dir="ltr"><span>These fine-grained formulations, when run on large supercomputers, lead to intense communication across processors of a supercomputer, posing challenges on petascale era large parallel machines with varied interconnect topologies. We developed&nbsp;</span>key schemes for automatically detecting network topology and object placement, and incorporated them in the underlying Charm++ runtime system. This pioneering work led to much community research on topology aware mapping, and also led to development of radically different new topologies by supercomputer vendors. &nbsp;</p> <p dir="ltr">To predict the behavior of materials with heavier atoms, ( a feature based on community feedback), we developed a new highly scalable mathematical scheme for the Projector Augmented Wave (PAW) technique, and parallel implementation.&nbsp; We recently developed a reduced order (N^2 Log N) method for PAW and developed several collective communication primitives to allow for the implementation of optimized data transfer patterns endemic to the method.&nbsp; The effort to achieve an efficient scalable parallel implementation has extended beyond the end of the grant period.</p> <p dir="ltr">The next key contribution was the development and implementation of a new formulation of the GW method.&nbsp; The GW method predicts material behavior in presence of electronic excitations, such as the capture of photons in solar cells.&nbsp; Our new implementation of the GW method reduces the overall computation time by reducing the number of Fast Fourier Transformations to a quantity found to be an optimal trade-off of total memory consumed, combined with the amount of data being moved across the supercomputer.&nbsp; &nbsp; More specifically, a detailed analysis was performed, and peer reviewed, (<a href="https://www.sciencedirect.com/science/article/pii/S001046551930178X">DOI 10.1016/j.cpc.2019.05.020</a>) comparing the operation counts for real space methods, vs fourier space methods, for each stage of the GW-BSE algorithm.&nbsp; The minimal path was then implemented in the OpenAtom software and compared to the community standard application (Berkeley-GW) to study performance and convergence.&nbsp; Our published comparisons found that OpenAtom was up to three times faster, for strong scaling performance for simulating a standard silicon benchmark system.  Furthermore, OpenAtom was able to continue efficient strong scaling to twice as many nodes as Berkeley-GW, resulting in an even more favorable overall comparison for OpenAtom, with no loss of accuracy.</p> <p dir="ltr">In the process of developing the highly efficient order N^4 implementation of GW-BSE, the team noted several ways that the computational complexity, and memory requirements, could be reduced.&nbsp; That resulted in the development of a novel N^3 method for the implementation of GW-BSE.  This method,  Complex Time Shredded Propagator Windowing (CTSP-W) was just published (<a href="https://doi.org/10.1103/PhysRevB.101.035139">https://doi.org/10.1103/PhysRevB.101.035139</a>) after peer review.&nbsp; That paper describes the analytical comparison against quartic methods and found that it should result in a two or three order of magnitude complexity improvement for larger molecular systems between 200-300 atoms.&nbsp; The comparison found that other cubic methods had much higher computational complexity than CTSP-W, or had other drawbacks that severely limited how easily they can be integrated into the community standard approaches to GW-BSE. Development of a scalable parallel implementation is in progress.</p> <p dir="ltr"><span>This project has resulted in important improvements for the efficient application of DFT and GW-BSE methods to accelerate the development of new materials and devices.</span></p> <p dir="ltr"><span>Links:</span></p> <p><span>OpenAtom Project, Software, and Documentation, Papers, People&nbsp; </span><a href="https://charm.cs.illinois.edu/OpenAtom/"><span>https://charm.cs.illinois.edu/OpenAtom/</span></a></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/31/2020<br>      Modified by: Laxmikant&nbsp;V&nbsp;Kale</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1339715/1339715_10279094_1583881476465_GW-Si108--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1339715/1339715_10279094_1583881476465_GW-Si108--rgov-800width.jpg" title="GW Si108 Performance"><img src="/por/images/Reports/POR/2020/1339715/1339715_10279094_1583881476465_GW-Si108--rgov-66x44.jpg" alt="GW Si108 Performance"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Faster GW Computation Time for Si108 Benchmark on 1000 Nodes Using OpenAtom</div> <div class="imageCredit">to be determined</div> <div class="imageSubmitted">Laxmikant&nbsp;V&nbsp;Kale</div> <div class="imageTitle">GW Si108 Performance</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   A major goal of computational science and engineering is to predict accurately, at the atomistic level, the electronic properties of complex materials including the statistical averaging over configuration space.  In order to meet this challenge, this project seeks to encapsulate novel computational methodologies spanning physics, chemistry, and materials simulation within a common software infrastructure that scales to large supercomputers and that encompasses the latest advances in high performance computing (HPC).  We anticipate that rich software infrastructure will accelerate the delivery of solutions to challenging problems in Science and Technology.  We targeted two drivers of great current interest, the development of fast, low power, post-CMOS architectures based on novel physics, and  cheap organic solar cells, enabled by novel new software.  As the accurate simulation of these materials requires highly intensive computation, our focus was on reducing the time required to run those simulations.  Specifically, we made several important contributions in the development of new methods that reduce computational complexity, without sacrificing necessary accuracy, and the implementation of those methods in highly scalable parallel software.  The initial contribution was the fine grained parallelization of the Car-Parrinello ab-initio Molecular Dynamics method at the heart of the OpenAtom Software.  Over the course of the project that capability was expanded to create a framework for the development of important multi-instance methods (i.e., Path-Integrals, K-points, Parallel Tempering, and Spin Density Functionals). These allow for additional scientific insights to be gained by running carefully selected variations of the target molecular system simultaneously.  These results were peer reviewed (DOI: 10.1007/978-3-319-41321-1_8) in a paper that specifically studied a Metallo-Organic Framework (MOF) molecular system for hydrogen energy storage, demonstrating unprecedented speed for the path integral simulation of realistically sized MOF systems. These fine-grained formulations, when run on large supercomputers, lead to intense communication across processors of a supercomputer, posing challenges on petascale era large parallel machines with varied interconnect topologies. We developed key schemes for automatically detecting network topology and object placement, and incorporated them in the underlying Charm++ runtime system. This pioneering work led to much community research on topology aware mapping, and also led to development of radically different new topologies by supercomputer vendors.   To predict the behavior of materials with heavier atoms, ( a feature based on community feedback), we developed a new highly scalable mathematical scheme for the Projector Augmented Wave (PAW) technique, and parallel implementation.  We recently developed a reduced order (N^2 Log N) method for PAW and developed several collective communication primitives to allow for the implementation of optimized data transfer patterns endemic to the method.  The effort to achieve an efficient scalable parallel implementation has extended beyond the end of the grant period. The next key contribution was the development and implementation of a new formulation of the GW method.  The GW method predicts material behavior in presence of electronic excitations, such as the capture of photons in solar cells.  Our new implementation of the GW method reduces the overall computation time by reducing the number of Fast Fourier Transformations to a quantity found to be an optimal trade-off of total memory consumed, combined with the amount of data being moved across the supercomputer.    More specifically, a detailed analysis was performed, and peer reviewed, (DOI 10.1016/j.cpc.2019.05.020) comparing the operation counts for real space methods, vs fourier space methods, for each stage of the GW-BSE algorithm.  The minimal path was then implemented in the OpenAtom software and compared to the community standard application (Berkeley-GW) to study performance and convergence.  Our published comparisons found that OpenAtom was up to three times faster, for strong scaling performance for simulating a standard silicon benchmark system.  Furthermore, OpenAtom was able to continue efficient strong scaling to twice as many nodes as Berkeley-GW, resulting in an even more favorable overall comparison for OpenAtom, with no loss of accuracy. In the process of developing the highly efficient order N^4 implementation of GW-BSE, the team noted several ways that the computational complexity, and memory requirements, could be reduced.  That resulted in the development of a novel N^3 method for the implementation of GW-BSE.  This method,  Complex Time Shredded Propagator Windowing (CTSP-W) was just published (https://doi.org/10.1103/PhysRevB.101.035139) after peer review.  That paper describes the analytical comparison against quartic methods and found that it should result in a two or three order of magnitude complexity improvement for larger molecular systems between 200-300 atoms.  The comparison found that other cubic methods had much higher computational complexity than CTSP-W, or had other drawbacks that severely limited how easily they can be integrated into the community standard approaches to GW-BSE. Development of a scalable parallel implementation is in progress. This project has resulted in important improvements for the efficient application of DFT and GW-BSE methods to accelerate the development of new materials and devices. Links:  OpenAtom Project, Software, and Documentation, Papers, People  https://charm.cs.illinois.edu/OpenAtom/             Last Modified: 03/31/2020       Submitted by: Laxmikant V Kale]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
