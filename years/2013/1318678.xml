<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>TWC: Option: Small: Automatic Software Model Repair for Security Policies</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>448789.00</AwardTotalIntnAmount>
<AwardAmount>448789</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Increasing cyber security depends on our ability to guarantee that the system will provide the expected functionality under normal circumstances as well as if the system is perturbed by some random events or security threats. Providing such guarantee is often complicated due to several factors such as changes in system requirements caused by user demands, exposure to a new threat model that was not considered (or not relevant) in the original design, or identifying bugs or vulnerabilities during a system life cycle. The purpose of the project is to develop automated techniques --that provide justifiable confidence about correctness--  to transform an existing software model into a new model that satisfies both the existing functionality and the desired security requirements. &lt;br/&gt; &lt;br/&gt;Developing algorithms that generate models that satisfy existing functionality and new security requirements poses new challenges due to the fact that existing trace-based properties do not suffice for several security properties. A characteristic of trace-based properties is that if a model satisfies a trace-based property and it is restricted by removing some undesired behaviors then the revised model still satisfies that trace-based property. Hence, adding a trace-based property can be achieved by removing behaviors that violate it. Since trace-based properties cannot express several security properties, this project will utilize a new formalism, hyperproperties,  that generalizes trace-based properties and can be used for modeling security requirements. In particular, a hyperproperty consists of a set of trace-based properties and to satisfy that hyperproperty it is required that the repaired program exhibit `all? behaviors in one of these properties.&lt;br/&gt; &lt;br/&gt;To develop algorithms that justifiably provide assurance about models developed by them, this project will first focus on formalizing commonly used security requirements using hyperproperties. It will perform complexity analysis to evaluate the complexity of adding different security properties to an existing model. To mitigate cases where the complexity is high, it will develop heuristics and algorithms that (1) identify whether adding the given hyperproperty can be achieved via adding a related stronger trace-based property, and (2) identify a subset of hyperproperties where adding the given property is more efficient. This work will also result in the development of efficient algorithms and tools that utilize the complexity bottlenecks.  Thus, the results of the proposed project will enhance assurance of software systems by repairing security flaws and vulnerabilities in an automated fashion.</AbstractNarration>
<MinAmdLetterDate>08/19/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1318678</AwardID>
<Investigator>
<FirstName>Sandeep</FirstName>
<LastName>Kulkarni</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sandeep S Kulkarni</PI_FULL_NAME>
<EmailAddress>sandeep@cse.msu.edu</EmailAddress>
<PI_PHON>5173552387</PI_PHON>
<NSF_ID>000275940</NSF_ID>
<StartDate>08/19/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName/>
<StateCode>MI</StateCode>
<ZipCode>488241226</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~448789</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main objective of this project was to enable automated repair of existing software models to satisfy new or enhanced security requirements while preserving existing functionality.</p> <p>In this project, we focused on hypersafety and hyperliveness properties. Regarding hypersafety properties, we classified them in terms of a hypersafety property where k identifies the number of computations that are sufficient to detect violation and l denotes the number of states that are sufficient to detect violation of hypersafety property. We showed that the problem can be solved efficiently if k=1 and l &lt;2. However, the problem is NP-complete if k&gt;1 or (k=1 and l&gt;= 1)</p> <p>Regarding hyperliveness, we focused on average response time. We developed an efficient algorithm to revise an existing stabilizing program to ensure that the average response time is less than the desired threshold. Our work was based on PRISM based probabilistic analysis. One of the challenges in this work was that while it is efficient to eliminate behaviors to reduce the average response time, it is possible that the number of behaviors eliminated could be especially large. We showed that there is a tradeoff between the number of behaviors maintained in the final program and the time required for revision. Specifically, we showed that one of our algorithms is extremely efficient. However, it can cause the removal of 90+% of behaviors from the resulting program. We have shown that it is possible to revise this program so that the extra computational power can be used to increase the percentage of behaviors that are maintained in the final program.</p> <p>In this area, we also pursued the case where instead of adding average response time, t, we focused on adding worst response time t' where t' is greater than t. We find that there is a tradeoff between the value of t'; specifically, choosing t' to be very close to t causes the algorithm to be efficient but results in the removal of a large percentage of behaviors from the final program.</p> <p>We also investigated a new approach, lazy repair, for repairing existing programs. Specifically, in this case, we partitioned the repair problem into two parts: First, ignore the realizability constraints (that must be satisfied to ensure that the repaired solution can be implemented in the actual system). This makes the tasks involved in repair significantly more efficient. Second, only focus on adding those realizability constraints. We find that the overall cost of this approach is lower than a cautious repair approach where we focus on satisfying realizability constraints at all times. We are working on expanding this result for hypersafety and hyperliveness properties.</p> <p>We have also developed repair algorithms that utilized genetic programming. Specifically, in this work, we evaluated how GP can be used to add or remove new behaviors with the aim of reaching a program that satisfies the desired requirements. In this work, we define the fitness function in terms of violations observed with the help of a BDD-based analysis. And, the goal is to develop a program where the number of violations is 0. This analysis formed the basis of our work on adding average response time to an existing program.</p> <p>We introduced a novel notion of auditable restoration to deal with conflicting requirements in a practical system. Auditable Restoration allows a system to operate in two modes, a normal mode and an audited mode. A transition from normal mode to audited mode is triggered by auditable events that are specifically added to the system to deal with conflicting requirements. When such auditable events occur, the system is automatically reset to audited mode. Subsequently, when these events are cleared, a special process can automatically begin a reset operation to restore the system to normal mode. Our work is currently limited by requiring that the legitimate and audited state predicates are captured by conjunctive predicates and auditable events are immediately detectable. One of our ongoing work in this area is to generalize this by removing these constraints.</p> <p>We have also focused on developing algorithms for monitoring distributed applications for identifying latent bugs that can cause security errors subsequently. By latent bugs, we mean a bug that is hidden due to race conditions that are resolved in a manner that is favorable to the user. However, when such bugs exist, they could occur in a subsequent execution and an adversary can attempt to cause these bugs by trying again and again. Currently, our monitors are able to detect violation of given predicate. However, we are working on adding more complex patterns for monitoring.</p> <p>Finally, we intend to make all results from this work publically available. The publications are available from PI's website. If any specific information about the publication is desired, please feel free to contact the PI by email.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/01/2017<br>      Modified by: Sandeep&nbsp;S&nbsp;Kulkarni</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main objective of this project was to enable automated repair of existing software models to satisfy new or enhanced security requirements while preserving existing functionality.  In this project, we focused on hypersafety and hyperliveness properties. Regarding hypersafety properties, we classified them in terms of a hypersafety property where k identifies the number of computations that are sufficient to detect violation and l denotes the number of states that are sufficient to detect violation of hypersafety property. We showed that the problem can be solved efficiently if k=1 and l &lt;2. However, the problem is NP-complete if k&gt;1 or (k=1 and l&gt;= 1)  Regarding hyperliveness, we focused on average response time. We developed an efficient algorithm to revise an existing stabilizing program to ensure that the average response time is less than the desired threshold. Our work was based on PRISM based probabilistic analysis. One of the challenges in this work was that while it is efficient to eliminate behaviors to reduce the average response time, it is possible that the number of behaviors eliminated could be especially large. We showed that there is a tradeoff between the number of behaviors maintained in the final program and the time required for revision. Specifically, we showed that one of our algorithms is extremely efficient. However, it can cause the removal of 90+% of behaviors from the resulting program. We have shown that it is possible to revise this program so that the extra computational power can be used to increase the percentage of behaviors that are maintained in the final program.  In this area, we also pursued the case where instead of adding average response time, t, we focused on adding worst response time t' where t' is greater than t. We find that there is a tradeoff between the value of t'; specifically, choosing t' to be very close to t causes the algorithm to be efficient but results in the removal of a large percentage of behaviors from the final program.  We also investigated a new approach, lazy repair, for repairing existing programs. Specifically, in this case, we partitioned the repair problem into two parts: First, ignore the realizability constraints (that must be satisfied to ensure that the repaired solution can be implemented in the actual system). This makes the tasks involved in repair significantly more efficient. Second, only focus on adding those realizability constraints. We find that the overall cost of this approach is lower than a cautious repair approach where we focus on satisfying realizability constraints at all times. We are working on expanding this result for hypersafety and hyperliveness properties.  We have also developed repair algorithms that utilized genetic programming. Specifically, in this work, we evaluated how GP can be used to add or remove new behaviors with the aim of reaching a program that satisfies the desired requirements. In this work, we define the fitness function in terms of violations observed with the help of a BDD-based analysis. And, the goal is to develop a program where the number of violations is 0. This analysis formed the basis of our work on adding average response time to an existing program.  We introduced a novel notion of auditable restoration to deal with conflicting requirements in a practical system. Auditable Restoration allows a system to operate in two modes, a normal mode and an audited mode. A transition from normal mode to audited mode is triggered by auditable events that are specifically added to the system to deal with conflicting requirements. When such auditable events occur, the system is automatically reset to audited mode. Subsequently, when these events are cleared, a special process can automatically begin a reset operation to restore the system to normal mode. Our work is currently limited by requiring that the legitimate and audited state predicates are captured by conjunctive predicates and auditable events are immediately detectable. One of our ongoing work in this area is to generalize this by removing these constraints.  We have also focused on developing algorithms for monitoring distributed applications for identifying latent bugs that can cause security errors subsequently. By latent bugs, we mean a bug that is hidden due to race conditions that are resolved in a manner that is favorable to the user. However, when such bugs exist, they could occur in a subsequent execution and an adversary can attempt to cause these bugs by trying again and again. Currently, our monitors are able to detect violation of given predicate. However, we are working on adding more complex patterns for monitoring.  Finally, we intend to make all results from this work publically available. The publications are available from PI's website. If any specific information about the publication is desired, please feel free to contact the PI by email.              Last Modified: 11/01/2017       Submitted by: Sandeep S Kulkarni]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
