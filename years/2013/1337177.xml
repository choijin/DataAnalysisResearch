<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>XPS:CLCCA: Optimizing Heterogeneous Platforms for Unstructured Parallelism</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>735055.00</AwardTotalIntnAmount>
<AwardAmount>735055</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Major social and economic change is being driven by the emergence of "big data." In all sectors of the economy businesses are increasingly relying on the ability to extract useful intelligence from massive relational data sets. Emergent applications are characterized by data intensive computation where massive parallelism is increasingly unstructured, hierarchical, workload dependent, and time varying.  At the same time, energy and power considerations are driving computer architecture towards massively parallel heterogeneous organizations such as multithreaded CPUs tightly integrated with bulk synchronous parallel (BSP) architectures such as general-purpose graphics processing units (GPUs). This evolution driven by energy efficiency concerns has had a disruptive impact on modern software stacks challenging our ability to extract the performance necessary to deal with big data. We need to develop computing technologies that can harness the throughput potential of energy efficient heterogeneous architectures for emergent applications processing massive relational data sets.&lt;br/&gt; &lt;br/&gt;Realizing the potential of massively-parallel heterogeneous architectures is inhibited by the unstructured dynamic parallelism exhibited by applications in these domains. This research develops a suite of coordinated algorithm, compiler, and microarchitecture technologies that effectively exploits dynamic parallelism. The suite of techniques enables the effective navigation of the tradeoffs between parallelism, locality, and data movement to realize optimized high performance implementations.  First, the proposed program utilizes the language of sparse linear algebra to formulate algorithms to expose massive unstructured parallelism. Second, this formulation drives new compiler and run-time system optimizations tailored to the computational characteristics of these emergent applications and heterogeneous hardware. Third, at the microarchitecture level we propose new memory hierarchy management techniques tailored to exploiting dynamic parallelism. The integrated solutions (algorithm, compiler/run-time, and microarchitecture) are demonstrated on commodity platforms and delivered in the form of an open source software stack to support and enable community wide research efforts. For U.S. businesses to exploit the new capabilities of heterogeneous architectures and systems for emerging applications, it is essential to both create new technology and employees with the necessary skills to utilize these technologies.  Technology transfer and workforce impact will be promoted through the NSF Industry University Cooperative Research Center on Experimental Research in Computer Systems (CERCS, www.cercs.gatech.edu) at Georgia Tech with members such as Intel, IBM, HP, and AMD as well as application oriented companies such as LogicBlox and Intercontinental Commodity Exchange (ICE) and also Department of Energy National laboratories such as Sandia and Oak Ridge. Similar impacts are expected through the NVIDIA Center of Excellence at Georgia Tech.</AbstractNarration>
<MinAmdLetterDate>09/11/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1337177</AwardID>
<Investigator>
<FirstName>Sudhakar</FirstName>
<LastName>Yalamanchili</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sudhakar Yalamanchili</PI_FULL_NAME>
<EmailAddress>sudha@ece.gatech.edu</EmailAddress>
<PI_PHON>4048942940</PI_PHON>
<NSF_ID>000161439</NSF_ID>
<StartDate>09/11/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Vuduc</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard W Vuduc</PI_FULL_NAME>
<EmailAddress>richie@cc.gatech.edu</EmailAddress>
<PI_PHON>5103017014</PI_PHON>
<NSF_ID>000080331</NSF_ID>
<StartDate>09/11/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hyesoon</FirstName>
<LastName>Kim</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hyesoon Kim</PI_FULL_NAME>
<EmailAddress>hyesoon@cc.gatech.edu</EmailAddress>
<PI_PHON>4043850866</PI_PHON>
<NSF_ID>000084212</NSF_ID>
<StartDate>09/11/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue, NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8283</Code>
<Text>Exploiting Parallel&amp;Scalabilty</Text>
</ProgramElement>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~735055</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Societies are defined by their dependencies - social, economic, governmental, and personal. Data intensive applications focused on relationships across these dependencies are distinct from scientific computations. Further, within the sciences, the processing of relationships represented as graph structures is forming an important subset of scientific computation. The improvement in the performance of relational computations over massive data sets has the potential to change the way we do business or chart scientific discovery in those instances where the limiting factor is the sheer volume and diversity of data, such that the lack of computational throughput for relational computations limits our current ability to aggregate information or discover relationships across the data sets. The information that we extract from such relationships are becoming a central component of the way we operate businesses, pursue research, and manage our day to day lives. The form of these computations (e.g., relational, unstructured, etc.) and massive scale of these data sets introduces new algorithmic, intellectual, and engineering challenges. This research advances new algorithmic and engineering solutions to the problems of the analysis of relationships over massive data sets using advanced, massively parallel architectures. In particular, we address the use of heterogeneous architectures wherein high throughput processors (general purpose graphics processing units (GPGPUs)) are coupled with mainstream homogeneous multicore processors.</p> <p>The major intellectual outcomes of this program are several and focus on new relational data sets structured as graphs &ndash; a dominant data structure in modern relational computation. Graphs are popular data structures for representing social networks, biological networks, transport networks, etc. However, they also create unstructured computations and memory referencing behavior that leads to low performance. First, we performed a comprehensive analysis of these emergent applications to understand their dynamic behaviors in how their computations are structured and how they use memory. The specific behavior is referred to as dynamic parallelism where the magnitude of concurrent computations is time-varying and data dependent. &nbsp;The resulting insights led to the development of a new computational model for executing these applications and modifications to modern high performance GPGPU accelerators to enable their implementation on commodity heterogeneous processors. Second, the presence of massive data sets stresses the memory system. We focused on the implications of massive data sets and the associated applications on the management of the memory system. The unique properties of these applications led to the formulation of new models for managing memory (consistency models) and efficiently utilizing time-varying parallelism over data sets (synchronization models). Third, we addressed the algorithmic challenges presented by new relational data sets structured as graphs This program developed new algorithms for partitioning such structures on modern high performance parallel machines. At its core is a new approach to partitioning streaming graph data structures across hundreds &ndash; thousands of parallel processors, for example machines used in large scale scientific computation. These contributions represent a cross-cutting effort from algorithms, through execution models, to architecture implementations.</p> <p>The engineering contributions of this program translated the preceding intellectual contributions into open source software artifacts to benefit the larger research and development community and enable further developments. These include i) two new application benchmark suites for graph processing and dynamic parallelism, ii) new simulation models for processor architectures that can support dynamic parallelism, and iii) software for partitioning and processing large scale graph data on modern high performance computing machines.</p> <p>Collectively, the preceding intellectual and engineering contributions realize advances in the state of the art and provides scaffolding to continue to build on these controbutions.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/21/2017<br>      Modified by: Sudhakar&nbsp;Yalamanchili</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Societies are defined by their dependencies - social, economic, governmental, and personal. Data intensive applications focused on relationships across these dependencies are distinct from scientific computations. Further, within the sciences, the processing of relationships represented as graph structures is forming an important subset of scientific computation. The improvement in the performance of relational computations over massive data sets has the potential to change the way we do business or chart scientific discovery in those instances where the limiting factor is the sheer volume and diversity of data, such that the lack of computational throughput for relational computations limits our current ability to aggregate information or discover relationships across the data sets. The information that we extract from such relationships are becoming a central component of the way we operate businesses, pursue research, and manage our day to day lives. The form of these computations (e.g., relational, unstructured, etc.) and massive scale of these data sets introduces new algorithmic, intellectual, and engineering challenges. This research advances new algorithmic and engineering solutions to the problems of the analysis of relationships over massive data sets using advanced, massively parallel architectures. In particular, we address the use of heterogeneous architectures wherein high throughput processors (general purpose graphics processing units (GPGPUs)) are coupled with mainstream homogeneous multicore processors.  The major intellectual outcomes of this program are several and focus on new relational data sets structured as graphs &ndash; a dominant data structure in modern relational computation. Graphs are popular data structures for representing social networks, biological networks, transport networks, etc. However, they also create unstructured computations and memory referencing behavior that leads to low performance. First, we performed a comprehensive analysis of these emergent applications to understand their dynamic behaviors in how their computations are structured and how they use memory. The specific behavior is referred to as dynamic parallelism where the magnitude of concurrent computations is time-varying and data dependent.  The resulting insights led to the development of a new computational model for executing these applications and modifications to modern high performance GPGPU accelerators to enable their implementation on commodity heterogeneous processors. Second, the presence of massive data sets stresses the memory system. We focused on the implications of massive data sets and the associated applications on the management of the memory system. The unique properties of these applications led to the formulation of new models for managing memory (consistency models) and efficiently utilizing time-varying parallelism over data sets (synchronization models). Third, we addressed the algorithmic challenges presented by new relational data sets structured as graphs This program developed new algorithms for partitioning such structures on modern high performance parallel machines. At its core is a new approach to partitioning streaming graph data structures across hundreds &ndash; thousands of parallel processors, for example machines used in large scale scientific computation. These contributions represent a cross-cutting effort from algorithms, through execution models, to architecture implementations.  The engineering contributions of this program translated the preceding intellectual contributions into open source software artifacts to benefit the larger research and development community and enable further developments. These include i) two new application benchmark suites for graph processing and dynamic parallelism, ii) new simulation models for processor architectures that can support dynamic parallelism, and iii) software for partitioning and processing large scale graph data on modern high performance computing machines.  Collectively, the preceding intellectual and engineering contributions realize advances in the state of the art and provides scaffolding to continue to build on these controbutions.          Last Modified: 12/21/2017       Submitted by: Sudhakar Yalamanchili]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
