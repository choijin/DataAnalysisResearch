<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: A Multi-State Investigation of Small Group and Mass Public Decision Making on Fiscal and Scientific Controversies through the Citizens' Initiative Review</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2014</AwardEffectiveDate>
<AwardExpirationDate>03/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>116451.00</AwardTotalIntnAmount>
<AwardAmount>122451</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Leland</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>In 2010, the Oregon state government authorized the first Citizens' Initiative Review (CIR), which convened two random samples of twenty-four registered voters for five days of deliberation on a pair of statewide initiatives. At the end of their deliberations, each citizen panel wrote a one-page analysis that went into the official pamphlet sent by the Secretary of State to every registered voter. Starting in 2014, the CIR's organizers are attempting to transform this process into a more cost-effective and scalable means of informing public decision making that extends beyond Oregon. Changes to the CIR's design and issue-focus permit a study on the limits and potential of democratic deliberation, with a focus on scientific controversies.&lt;br/&gt; A multi-method investigation of the 2014 CIR will employ direct observation, transcript analysis, and panelist surveys. Case study analysis of four separate CIR panels will assess the democratic and deliberative quality of lay citizen decision making on scientifically complex issues via streamlined, digital discussion procedures. Additional studies will examine how the wider public incorporates the CIR's information and recommendations into its decision making. A multi-state usability study of the voter pamphlet will provide a more refined picture of how voters use and understand the CIR's one-page analysis. An online survey experiment will incorporate findings from the usability study into an online voter guide to test how proposed alterations to the CIR's design shape the public's trust in the CIR's issue analyses. Finally, a mail survey will test the efficacy of distributing CIR findings via conventional media channels. &lt;br/&gt; Our research will aid civic reformers designing deliberative processes, as well as legislators considering the adoption of the CIR and similar designs. Our collaborative research model also advances the professional development of the numerous graduate students and junior faculty working on this project.</AbstractNarration>
<MinAmdLetterDate>04/08/2014</MinAmdLetterDate>
<MaxAmdLetterDate>10/29/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1357444</AwardID>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Knobloch</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katherine R Knobloch</PI_FULL_NAME>
<EmailAddress>katie.knobloch@colostate.edu</EmailAddress>
<PI_PHON>9704916355</PI_PHON>
<NSF_ID>000650042</NSF_ID>
<StartDate>04/08/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Colorado State University</Name>
<CityName>Fort Collins</CityName>
<ZipCode>805232002</ZipCode>
<PhoneNumber>9704916355</PhoneNumber>
<StreetAddress>601 S Howes St</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>785979618</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COLORADO STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>948905492</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Colorado State University]]></Name>
<CityName>Fort Collins</CityName>
<StateCode>CO</StateCode>
<ZipCode>805232002</ZipCode>
<StreetAddress><![CDATA[601 S Howes Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1321</Code>
<Text>Decision, Risk &amp; Mgmt Sci</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~116451</FUND_OBLG>
<FUND_OBLG>2015~6000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In many states and municipalities across the country, members of the electorate are asked to cast their votes on complex ballot measures. These initiatives and referenda give voters the opportunity to weigh in on legislation ranging from the labeling of genetically modified foods to proposed tax increases to the legalization of recreational marijuana. Too often, however, voters have little information with which to reach their decision and much of that information comes from vested interests. The Citizens&rsquo; Initiative Review (CIR) attempts to bolster voters&rsquo; access to relevant information by assembling a group of 20 citizens, demographically reflective of their state, to review the measure and write a summary of the key information and arguments related to it. This statement either appears in the states voters&rsquo; pamphlet or is distributed through the media so that citizens can use it when casting their own ballots.</p> <p>Our research evaluated the quality and impact of the CIR from 2014 to 2016 as it expanded from Oregon, where it was originally implemented in 2010, to trial runs in Arizona, Colorado, and Massachusetts. &nbsp;Findings indicated that the reviews were highly deliberative, allowing participants to carefully weigh relevant information and produce a well-crafted statement. Moreover, the reviews impacted the wider electorate, often increasing their initiative-specific knowledge and helping voters reach their decisions on ballot measures.</p> <p>Across locations, the panels maintained a high level of deliberation. The 2014 and 2016 reviews replicated the levels of analytic rigor and respectful discussion found in 2010 and 2012 in Oregon, even as the reviews were shortened from five days to three and a half and the number of participants was reduced from 24 to 20. At each of the reviews, participants heard from advocates in favor and in opposition to the measure, and participants engaged in small and large group conversations to distill that information for voters. In 2016, the CIR reintroduced issue-specific experts to the process, and panelists were allowed to ask questions about their specialized knowledge. This change increased the quality of information available to participants and allowed them to better evaluate the information provided by proponents and opponents of the measure.</p> <p>In both 2014 and 2016, the vast majority of panelists reported high levels of satisfaction with the reviews, expressed little difficulty understanding the complex information with which they were presented, and said they had learned enough information about the measure to reach a good decision. Participants spent significant time evaluating the claims provided by advocates and experts and the process allowed participants to identify and ask experts about any questions they had about the measure. In addition, professional facilitation of these conversations fostered an atmosphere of respect amongst participants and encouraged them to focus on identifying information useful to voters. By the end of the week, participants had produced relatively clear statements for the voters that were highly accurate, though some redundancy in the statements and complex language may have detracted from their utility.</p> <p>The reviews also generally achieved their goals of producing a more informed electorate, at least for those who read the statements. Over half of likely Oregon voters were aware of the review, with over two-fifths reporting that they read the statements before casting their ballots. Over half of those who read the Oregon statements said that they were at least somewhat helpful in reaching their decisions and about two-thirds found them at least somewhat informative. Additionally, usability testing indicated that reading the statements may encourage voters to cast their ballots on measures they may have otherwise skipped, but that same research found that voters wanted to know more about the review process in order to place their trust in the statements. Still, a separate survey found voters eager to share new information with others, even if it may be in opposition to their voting preferences.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/05/2017<br>      Modified by: Katherine&nbsp;R&nbsp;Knobloch</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In many states and municipalities across the country, members of the electorate are asked to cast their votes on complex ballot measures. These initiatives and referenda give voters the opportunity to weigh in on legislation ranging from the labeling of genetically modified foods to proposed tax increases to the legalization of recreational marijuana. Too often, however, voters have little information with which to reach their decision and much of that information comes from vested interests. The Citizens? Initiative Review (CIR) attempts to bolster voters? access to relevant information by assembling a group of 20 citizens, demographically reflective of their state, to review the measure and write a summary of the key information and arguments related to it. This statement either appears in the states voters? pamphlet or is distributed through the media so that citizens can use it when casting their own ballots.  Our research evaluated the quality and impact of the CIR from 2014 to 2016 as it expanded from Oregon, where it was originally implemented in 2010, to trial runs in Arizona, Colorado, and Massachusetts.  Findings indicated that the reviews were highly deliberative, allowing participants to carefully weigh relevant information and produce a well-crafted statement. Moreover, the reviews impacted the wider electorate, often increasing their initiative-specific knowledge and helping voters reach their decisions on ballot measures.  Across locations, the panels maintained a high level of deliberation. The 2014 and 2016 reviews replicated the levels of analytic rigor and respectful discussion found in 2010 and 2012 in Oregon, even as the reviews were shortened from five days to three and a half and the number of participants was reduced from 24 to 20. At each of the reviews, participants heard from advocates in favor and in opposition to the measure, and participants engaged in small and large group conversations to distill that information for voters. In 2016, the CIR reintroduced issue-specific experts to the process, and panelists were allowed to ask questions about their specialized knowledge. This change increased the quality of information available to participants and allowed them to better evaluate the information provided by proponents and opponents of the measure.  In both 2014 and 2016, the vast majority of panelists reported high levels of satisfaction with the reviews, expressed little difficulty understanding the complex information with which they were presented, and said they had learned enough information about the measure to reach a good decision. Participants spent significant time evaluating the claims provided by advocates and experts and the process allowed participants to identify and ask experts about any questions they had about the measure. In addition, professional facilitation of these conversations fostered an atmosphere of respect amongst participants and encouraged them to focus on identifying information useful to voters. By the end of the week, participants had produced relatively clear statements for the voters that were highly accurate, though some redundancy in the statements and complex language may have detracted from their utility.  The reviews also generally achieved their goals of producing a more informed electorate, at least for those who read the statements. Over half of likely Oregon voters were aware of the review, with over two-fifths reporting that they read the statements before casting their ballots. Over half of those who read the Oregon statements said that they were at least somewhat helpful in reaching their decisions and about two-thirds found them at least somewhat informative. Additionally, usability testing indicated that reading the statements may encourage voters to cast their ballots on measures they may have otherwise skipped, but that same research found that voters wanted to know more about the review process in order to place their trust in the statements. Still, a separate survey found voters eager to share new information with others, even if it may be in opposition to their voting preferences.           Last Modified: 07/05/2017       Submitted by: Katherine R Knobloch]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
