<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AIR Option 1: Technology Translation:  Development and Evaluation of Field Prototype for Determining Excavator Proximity to Buried Utilities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>03/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>162000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Barbara H. Kenny</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This PFI: AIR Technology Translation project focuses on translating fundamental research findings in Georeferenced Augmented Reality (AR) and Emulated Graphical Monitoring to develop a technology for estimating excavator proximity to invisible buried utilities in real-time while a machine is digging. AR is the superimposition of computer-generated images over a user-view of the real world. Emulated Graphical Monitoring is the concurrent 3D visualization of an engineering process ongoing in the real environment. The translated technology has the following unique features: it can allow excavator operators to persistently see what utilities are buried in a digging machine?s vicinity, thus helping prevent utility strike accidents; it can also allow the monitoring of a working excavator?s proximity to buried assets, thereby enabling real-time knowledge-based excavator control. These features provide exemplary situational awareness, safety, and confidence to excavator operators when compared to the leading competing machine control technologies in this market space that are limited to providing grade control guidance during excavation. The project accomplishes is goals by pursuing an accelerated plan to develop and evaluate a field-deployable prototype of the technology for customer demonstration and evaluation along the path to commercial reality, resulting in a market-ready capability that can allow an excavator operator to be visually aware of buried underground utilities and other assets in the vicinity of a machine, and can offer quantitative feedback of machine distance to vicinal obstructions. The partnership engages DTE Energy Company (Michigan?s largest electricity and gas provider), Miss Dig System (Michigan?s One-Call excavation safety agency), and member companies of the Michigan Infrastructure Transportation Association (MITA) to provide guidance in the excavation safety market space and other commercialization aspects as they pertain to the potential to translate the developed technology along a path that may result in a competitive commercial reality. &lt;br/&gt;&lt;br/&gt;An excavator unintentionally hits a buried utility every 60 seconds in the U.S. causing fatalities, injuries, and property damage that annually cost billions of dollars. It is widely documented that these accidents occur either because excavator operators do not know where utilities are buried, or because they cannot perceive where the utilities are relative to the digging excavator. The potential economic impact of this project is expected to be the transformation of excavator operation from a skill-based activity to a knowledge-based practice, leading to improvements in productivity and safety within the next three years, which will contribute to the U.S. competitiveness in the burgeoning civil infrastructure construction and rehabilitation industry. Such benefits will also accrue in manufacturing, transportation, mining, and ship-building where transition from skill-based to knowledge-based processes is seen to be of value. The societal impact, long term, will be the reductions in construction and underground infrastructure life-cycle costs that will be possible through safe and efficient excavation.</AbstractNarration>
<MinAmdLetterDate>09/06/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/27/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1343124</AwardID>
<Investigator>
<FirstName>Vineet</FirstName>
<LastName>Kamat</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vineet R Kamat</PI_FULL_NAME>
<EmailAddress>vkamat@umich.edu</EmailAddress>
<PI_PHON>7347644325</PI_PHON>
<NSF_ID>000244987</NSF_ID>
<StartDate>09/06/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481092125</ZipCode>
<StreetAddress><![CDATA[2350 Hayward Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8019</Code>
<Text>Accelerating Innovation Rsrch</Text>
</ProgramElement>
<ProgramReference>
<Code>116E</Code>
<Text>RESEARCH EXP FOR UNDERGRADS</Text>
</ProgramReference>
<ProgramReference>
<Code>8019</Code>
<Text>Accelerating Innovation Rsrch</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~150000</FUND_OBLG>
<FUND_OBLG>2014~12000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The pose of an articulated machine includes the position and orientation of not only the machine base (e.g., tracks or wheels), but also each of its major articulated components (e.g., stick and bucket). The ability to automatically estimate this pose is a crucial component of technical innovations aimed at improving both safety and productivity in many construction tasks. A computer vision based solution using a network of cameras and markers was developed in this research to enable such a capability for articulated machines.</p> <p>Firstly, a planar marker is magnetically mounted on the end-effector of interest. Another marker is fixed on the jobsite whose 3D pose is pre-surveyed in a project coordinate frame. Then a cluster of at least two cameras respectively observing and tracking the two markers simultaneously forms a camera-marker network and transfers the end-effector's pose into the desired project frame, based on a pre-calibration of the relative poses between each pair of cameras.</p> <p>Through extensive sets of uncertainty analyses and field experiments, this approach is shown to be able to achieve centimeter level depth tracking accuracy within 10 meters with only two ordinary cameras and a few markers, providing a flexible and cost-efficient alternative to other commercial products that use infrastructure dependent sensors like GPS. A working prototype has been tested on several active construction sites with positive feedback from excavator operators confirming the solution's effectiveness.</p> <p>A vision-based sensor system, comprised of fiducial markers and optical cameras, offers a potential low cost and ubiquitous alternative. However, because markers cannot be placed directly on an excavator&rsquo;s bucket for occlusion and durability reasons, a device is needed to transmit bucket motion and provide information necessary to deduce tooth pose.</p> <p>Several design iterations were developed to address this problem, including a four-bar linkage design, a synchronous belt design, a bucket linkage generalized mapping design, and a cable potentiometer generalized mapping design. Prototypes were fabricated, installed, and tested. Promising experimental results suggest the feasibility of vision-based sensor technology for excavator pose estimation. Marker-based sensors were found to offer a potential solution for the economical localization and pose estimation of articulated construction equipment, especially in environments with limited GPS capabilities.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/17/2016<br>      Modified by: Vineet&nbsp;R&nbsp;Kamat</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1343124/1343124_10275914_1466191546901_Image1--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1343124/1343124_10275914_1466191546901_Image1--rgov-800width.jpg" title="SmartDig"><img src="/por/images/Reports/POR/2016/1343124/1343124_10275914_1466191546901_Image1--rgov-66x44.jpg" alt="SmartDig"></a> <div class="imageCaptionContainer"> <div class="imageCaption">(A) camera cluster and stick marker; (B) benchmark with pre-surveyed pose in the project reference frame; (C) system calibration; (D) working prototype of automatic grade control; (E) comparison to manual grade</div> <div class="imageCredit">Suyang Dong and Vineet Kamat</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Vineet&nbsp;R&nbsp;Kamat</div> <div class="imageTitle">SmartDig</div> </div> </li> </ul> </div> </...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The pose of an articulated machine includes the position and orientation of not only the machine base (e.g., tracks or wheels), but also each of its major articulated components (e.g., stick and bucket). The ability to automatically estimate this pose is a crucial component of technical innovations aimed at improving both safety and productivity in many construction tasks. A computer vision based solution using a network of cameras and markers was developed in this research to enable such a capability for articulated machines.  Firstly, a planar marker is magnetically mounted on the end-effector of interest. Another marker is fixed on the jobsite whose 3D pose is pre-surveyed in a project coordinate frame. Then a cluster of at least two cameras respectively observing and tracking the two markers simultaneously forms a camera-marker network and transfers the end-effector's pose into the desired project frame, based on a pre-calibration of the relative poses between each pair of cameras.  Through extensive sets of uncertainty analyses and field experiments, this approach is shown to be able to achieve centimeter level depth tracking accuracy within 10 meters with only two ordinary cameras and a few markers, providing a flexible and cost-efficient alternative to other commercial products that use infrastructure dependent sensors like GPS. A working prototype has been tested on several active construction sites with positive feedback from excavator operators confirming the solution's effectiveness.  A vision-based sensor system, comprised of fiducial markers and optical cameras, offers a potential low cost and ubiquitous alternative. However, because markers cannot be placed directly on an excavatorÆs bucket for occlusion and durability reasons, a device is needed to transmit bucket motion and provide information necessary to deduce tooth pose.  Several design iterations were developed to address this problem, including a four-bar linkage design, a synchronous belt design, a bucket linkage generalized mapping design, and a cable potentiometer generalized mapping design. Prototypes were fabricated, installed, and tested. Promising experimental results suggest the feasibility of vision-based sensor technology for excavator pose estimation. Marker-based sensors were found to offer a potential solution for the economical localization and pose estimation of articulated construction equipment, especially in environments with limited GPS capabilities.          Last Modified: 06/17/2016       Submitted by: Vineet R Kamat]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
