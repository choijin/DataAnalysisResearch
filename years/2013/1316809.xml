<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Small: Collaborative Research: Don't Read my Face: Tackling the Challenges of Facial Masking in Parkinson's Disease Rehabilitation through Co-Robot Mediators</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>949924.00</AwardTotalIntnAmount>
<AwardAmount>949924</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Miller</SignBlockName>
<PO_EMAI>damiller@nsf.gov</PO_EMAI>
<PO_PHON>7032924914</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The overarching scientific goal of this project is two-fold: (1) to develop a robotic architecture endowed with moral emotional control mechanisms, abstract moral reasoning, and a theory of mind that allow corobots to be sensitive to human affective and ethical demands, and (2) to develop a specific instance of the architecture for a co-robot mediator between people with "facial masking" due to Parkinson's disease (PD) that reduces their ability to signal emotion, pain, personality and intentions to their family caregivers, and health care providers who often misinterpret the lack of emotional expressions as disinterest and an inability to adhere to treatment regimen, resulting in stigmatization. To tackle these problems, the project brings together two roboticists with extensive prior experience in robot ethics and modeling emotions as well as implementing them in integrated autonomous robotic systems. The robotics expertise is combined with that of an expert in early PD rehabilitation and daily social life. The project will build on extensive software, hardware and data set resources, including complex robotic control architectures with ethical control mechanisms, personality and emotion models, and affect and natural language capabilities.&lt;br/&gt;&lt;br/&gt;The general expected outcome of the project is an architecture for co-robots that can be adapted to a great variety of health care scenarios in an effort to enrich and dignify already stressed and stigmatized relationships between humans. The project also includes novel educational efforts such as a course in occupational therapy robotics as well as significant K?12 outreach through the Tufts Centers for STEM Diversity and for Engineering Education and Outreach, as well as various important community and public activities such as presentations on health care robotics to focus and patient groups.</AbstractNarration>
<MinAmdLetterDate>09/02/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/02/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1316809</AwardID>
<Investigator>
<FirstName>Matthias</FirstName>
<LastName>Scheutz</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthias J Scheutz</PI_FULL_NAME>
<EmailAddress>matthias.scheutz@tufts.edu</EmailAddress>
<PI_PHON>6176270453</PI_PHON>
<NSF_ID>000289027</NSF_ID>
<StartDate>09/02/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Linda</FirstName>
<LastName>Tickle-Degnen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Linda Tickle-Degnen</PI_FULL_NAME>
<EmailAddress>linda.tickle_degnen@tufts.edu</EmailAddress>
<PI_PHON>6176273417</PI_PHON>
<NSF_ID>000605380</NSF_ID>
<StartDate>09/02/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Tufts University</Name>
<CityName>Boston</CityName>
<ZipCode>021111817</ZipCode>
<PhoneNumber>6176273696</PhoneNumber>
<StreetAddress>136 Harrison Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073134835</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF TUFTS COLLEGE INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073134835</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Tufts University]]></Name>
<CityName>Medford</CityName>
<StateCode>MA</StateCode>
<ZipCode>021554243</ZipCode>
<StreetAddress><![CDATA[200 Boston Avenue, Suite 2300]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~949924</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project investigated ways for robots to support people with Parkinson's Disease (PD), a neurodegenerative disorder that affects about 1M Americans and leads to a loss of motor control and thus changes in speech, facial expressions, and gait.&nbsp; People with PD find it increasingly difficult to perform simple motor tasks such a sorting their medication (e.g., due to tremors or mild cognitive impairment).&nbsp; "Facial masking", in particular, is an early sign of PD where a person with PD is wrongly viewed as disinterested by interactants based on the immobilized face.&nbsp; Various measurement instruments such as the Parkinson's Disease Questionnaire 39 (PDQ-39) have been developed to assess the health status of a person with PD and the effectiveness of the prescribed treatment.</p> <p>To support people with PD, three different robot applications were developed: a robot interviewer to administer the PDQ-39, a robotic assistant to supervise medication sorting (which can be very complex due to the different medications having constraints on when they need to be taken), and a social mediator robot that can express emotions for the person with PD when their inert face and flat affect wrongly suggest lack of emotional involvement.&nbsp; All three robots were evaluated in different user studies, demonstrating the viability of using robots for those applications, but also showing room for improvements in the future.</p> <p>The robot interviewer performed the same interview task as a human would, asking questions on the PDQ-39 and based on the answers followed up with different prescribed questions, recording all the results.&nbsp; It was evaluated in direct comparison to human interviewers to determine how well the robot was able to perform compared to human interviewers and to what extent people with PD would prefer a human interviewer to the robot interviewer.&nbsp; While overall human interviewers were preferred, people with PD had overall positive impressions of the robot interviewer and were willing to disclose their health-related personal information to the robot.&nbsp; This opens up the opportunity for robots to administer health questionnaires to people with PD without requiring the presence of a health care professional or a visit to a health clinic which is often difficult to schedule and depending on the disease progression can be very burdensome for the person with PD or the caregiver.</p> <p>The robot assistant in the medication sorting task was able to watch a person sort different pills in a medication sorting grid which had to be sorted based on time-of-day and day of the week. The robot was able to determine whether pills were sorted correctly using visual input from its cameras and if a mistake was made, the robot could provide different levels of verbal feedback to the human, from simple suggesting to "look again", to specific feedback regarding the location of the error such as "check the blue pill on Monday morning". The feedback corresponded to the first three of seven levels of support given by occupational therapists.&nbsp; The robot was evaluated with a standard undergraduate population as well as people with PD. The results showed that while the students like the robot and found it helpful, people with PD were less enthusiastic and would have preferred more help from the robot, even though the robot's escalating feedback was intended to explicitly support the autonomy of people with PD.&nbsp; This tradeoff between letting people perform as much of the task autonomously and helping them when they struggle is consequently an important topic for future work.</p> <p>Finally, the third system was built to infer moment-by-moment emotional state of people with PD from the verbal semantics of their utterances alone and to express it either via facial expressions or bodily gestures.&nbsp; Both systems were evaluated in online studies using Amazon Mechanical Turk where subjects viewed videos of the robot mimicking emotional expressions next to an actor portraying a person with PD, producing utterances from a corpus of interviews with people with PD.&nbsp; The overall results showed that subjects found a robot expressing the emotional state of a person with PD more appropriate and commensurate with what the actor said than robots with random gestures and facial expressions.&nbsp; Both systems thus showed promise for future developments where the algorithms will be integrated into a larger support robot mediator system that can serve as a proxy for people with PD in multi-person interactions.</p> <p>Overall, the three robot systems developed in this project show the potential of autonomous social robots to support people with neurodegenerative disorders like Parkinson's Disease in their daily routines.&nbsp; Not only can they contribute to preserving the overall autonomy and ultimately dignity of people with PD, but they can also help reduce the growing health care costs by being an in-home health care assistant that augments healh care services, while aso offloading some of the tasks typically performed by human caregivers to autonomous robots.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/16/2019<br>      Modified by: Matthias&nbsp;J&nbsp;Scheutz</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project investigated ways for robots to support people with Parkinson's Disease (PD), a neurodegenerative disorder that affects about 1M Americans and leads to a loss of motor control and thus changes in speech, facial expressions, and gait.  People with PD find it increasingly difficult to perform simple motor tasks such a sorting their medication (e.g., due to tremors or mild cognitive impairment).  "Facial masking", in particular, is an early sign of PD where a person with PD is wrongly viewed as disinterested by interactants based on the immobilized face.  Various measurement instruments such as the Parkinson's Disease Questionnaire 39 (PDQ-39) have been developed to assess the health status of a person with PD and the effectiveness of the prescribed treatment.  To support people with PD, three different robot applications were developed: a robot interviewer to administer the PDQ-39, a robotic assistant to supervise medication sorting (which can be very complex due to the different medications having constraints on when they need to be taken), and a social mediator robot that can express emotions for the person with PD when their inert face and flat affect wrongly suggest lack of emotional involvement.  All three robots were evaluated in different user studies, demonstrating the viability of using robots for those applications, but also showing room for improvements in the future.  The robot interviewer performed the same interview task as a human would, asking questions on the PDQ-39 and based on the answers followed up with different prescribed questions, recording all the results.  It was evaluated in direct comparison to human interviewers to determine how well the robot was able to perform compared to human interviewers and to what extent people with PD would prefer a human interviewer to the robot interviewer.  While overall human interviewers were preferred, people with PD had overall positive impressions of the robot interviewer and were willing to disclose their health-related personal information to the robot.  This opens up the opportunity for robots to administer health questionnaires to people with PD without requiring the presence of a health care professional or a visit to a health clinic which is often difficult to schedule and depending on the disease progression can be very burdensome for the person with PD or the caregiver.  The robot assistant in the medication sorting task was able to watch a person sort different pills in a medication sorting grid which had to be sorted based on time-of-day and day of the week. The robot was able to determine whether pills were sorted correctly using visual input from its cameras and if a mistake was made, the robot could provide different levels of verbal feedback to the human, from simple suggesting to "look again", to specific feedback regarding the location of the error such as "check the blue pill on Monday morning". The feedback corresponded to the first three of seven levels of support given by occupational therapists.  The robot was evaluated with a standard undergraduate population as well as people with PD. The results showed that while the students like the robot and found it helpful, people with PD were less enthusiastic and would have preferred more help from the robot, even though the robot's escalating feedback was intended to explicitly support the autonomy of people with PD.  This tradeoff between letting people perform as much of the task autonomously and helping them when they struggle is consequently an important topic for future work.  Finally, the third system was built to infer moment-by-moment emotional state of people with PD from the verbal semantics of their utterances alone and to express it either via facial expressions or bodily gestures.  Both systems were evaluated in online studies using Amazon Mechanical Turk where subjects viewed videos of the robot mimicking emotional expressions next to an actor portraying a person with PD, producing utterances from a corpus of interviews with people with PD.  The overall results showed that subjects found a robot expressing the emotional state of a person with PD more appropriate and commensurate with what the actor said than robots with random gestures and facial expressions.  Both systems thus showed promise for future developments where the algorithms will be integrated into a larger support robot mediator system that can serve as a proxy for people with PD in multi-person interactions.  Overall, the three robot systems developed in this project show the potential of autonomous social robots to support people with neurodegenerative disorders like Parkinson's Disease in their daily routines.  Not only can they contribute to preserving the overall autonomy and ultimately dignity of people with PD, but they can also help reduce the growing health care costs by being an in-home health care assistant that augments healh care services, while aso offloading some of the tasks typically performed by human caregivers to autonomous robots.          Last Modified: 12/16/2019       Submitted by: Matthias J Scheutz]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
