<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Medium: Collaborative Research: Force Feedback for Fingertips</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>800000.00</AwardTotalIntnAmount>
<AwardAmount>808000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Surface haptics is the creation of programmable haptic effects on physical surfaces such as touch screens and touch pads.  Unlike traditional force feedback devices that require the operator to grasp an end effector, surface haptic devices must provide feedback directly to the fingertips.  With the dramatic rise of touch screen interfaces in recent years, many approaches to surface haptics have been explored, including vibrotactile, shape morphing, and variable friction.  The PI and his team have pioneered an approach in which the surface generates controlled shear forces on each fingertip. Force Feedback for Fingertips (F3), gives fingertips the opportunity to interact with physics-based virtual environments, much like force feedback devices enable the whole hand to do.  With F3, fingers can interact with virtual objects that have mass, stiffness and damping as well as more complicated dynamics (e.g., collisions, mechanisms, and force fields).  By coordinating haptic effects at multiple fingertips, even more compelling illusions can be generated.&lt;br/&gt;&lt;br/&gt;The technology, underlying science, and application of F3 are, however, still in their infancy.  F3 works by coupling lateral vibrations to some form of rectification.  For example, one approach involves high-frequency lateral vibrations of the surface synchronized with a friction reduction effect, resulting in a slip-push transition at each oscillation.  The friction is modulated by means of electrostatic forces or acoustical stimulation.  Current approaches work at ultrasonic frequencies, but little is known about the mechanical or electrical behavior of fingertips at these frequencies, or how energy transfer from a surface to the finger can be optimized.&lt;br/&gt;&lt;br/&gt;This research will produce new knowledge in three main areas:  the physical underpinnings of F3, device design and interaction design.  First, both tribological and acoustic measurements will be made to elucidate the mechanisms by which shear forces are generated.  A high-bandwidth tribometer and optical imaging system will allow friction to be studied, and a custom-built exciter will allow the propagation of acoustic energy in the fingertip to be studied.  Laser Doppler vibrometry will be used to measure surface wave propagation while magnetic resonance elastography will be used to study shear wave propagation within the subcutaneous tissues.  Fractional calculus and finite element techniques will then be used to build biologically plausible models of fingertip tribology and mechanics that match the data.  Second, a new generation of high-performance F3 devices will be developed.  Armed with good models, it will be possible to design impedance-matched devices so that force production is maximized and energy wastage is minimized.  Additionally, these new devices will provide control over the force vector at each of multiple fingertip locations.  Thirdly, novel multi-finger interactions will be designed.  The key idea is that sophisticated percepts, such as "objects" that can be grasped and that feel as though they are moving relative to the surface, can emerge from properly coordinated fingertip forces due to Gestalt-like grouping principles.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  Historically, the PI and his team have had greatest impact when providing technology to and collaborating with colleagues in human-computer interaction.  Inspired by this, an open source F3 kit will be developed and shared.  In addition, undergraduate and high school students will participate in the research, developing software routines and sample applications for the open source kit.  Finally, the kit will be integrated with two pedagogical innovations already implemented by the investigators: flipped classrooms and portable laboratories.</AbstractNarration>
<MinAmdLetterDate>05/30/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302422</AwardID>
<Investigator>
<FirstName>J. Edward</FirstName>
<LastName>Colgate</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>J. Edward Colgate</PI_FULL_NAME>
<EmailAddress>colgate@northwestern.edu</EmailAddress>
<PI_PHON>8474914264</PI_PHON>
<NSF_ID>000267549</NSF_ID>
<StartDate>05/30/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>Peshkin</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael A Peshkin</PI_FULL_NAME>
<EmailAddress>peshkin@northwestern.edu</EmailAddress>
<PI_PHON>8474914630</PI_PHON>
<NSF_ID>000317165</NSF_ID>
<StartDate>05/30/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602080834</ZipCode>
<StreetAddress><![CDATA[2145 Sheridan Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~250000</FUND_OBLG>
<FUND_OBLG>2014~558000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This research began with a vision for a new type of human-computer interface:&nbsp; very much like a touchscreen, yet having the added ability to control what a person using it actually felt through his or her fingertips.&nbsp; For instance, buttons might feel like they have shape so that a person could touch type, or a person with a vision impairment might be able to read using braille or something similar.&nbsp; On the strength of previous research, our team felt that this could be accomplished by developing &ldquo;active forcing&rdquo; technology.&nbsp; An active forcing interface can apply controlled forces to bare human fingertips in any direction along the surface.&nbsp;</p> <p>How does active forcing control what a person feels?&nbsp; The key is to make the forces dependent on the location and movement of the finger relative to graphical objects on the screen.&nbsp; For instance, to make a button feel like it has an indented shape, the force can be controlled so that it does nothing if the finger is right over the center of the button, but pushes the finger back toward the center if it strays away.&nbsp; The pattern of forces essentially fools the brain into believing that the button has shape.&nbsp; Other patterns of forces can be used to emulate buttons that bulge out of the surface, toggle switches, knobs, pathways (imagine tracing out a path on an image of a map and feeling that path guide the finger), and endless other items that a designer might imagine.</p> <p>Active forcing is accomplished by synchronizing high frequency in-plane vibrations of the touch surface with friction levels.&nbsp; The concept is simple enough:&nbsp; vibrate the touch surface in-plane, and increase the friction against the finger whenever that surface is moving in the desired pushing direction, while decreasing it when the surface moves in other directions.&nbsp; On average, the finger will be pushed in the desired direction.&nbsp; In practice, however, this is a challenging thing to do.&nbsp; It is necessary to modulate the friction very rapidly and over a wide range of magnitudes.&nbsp; This, in turn, requires a deep understanding of the friction modulation mechanics.&nbsp;</p> <p>In this research, a combination of theoretical and experimental studies led to a deep understanding of two different approaches to friction modulation.&nbsp; One approach is based on out-of-plane surface vibrations, which are known to reduce friction.&nbsp; This work showed unequivocally that the finger "bounces" against the vibrating surface, and does not "float" has had been previously thought.&nbsp; The bounces, however, are cushioned by air, which is the key factor that leads to friction reduction.&nbsp; An additional result is that the dynamic properties &ndash; especially damping &ndash; of the fingertip itself, play a key role.</p> <p>The second approach is based on creating an electric field between the fingertip skin and the surface.&nbsp; The electric field causes the skin to be pulled down against the surface, increasing friction.&nbsp; The experimental and theoretical results of this work explain how large the attractive force is and what factors influence it.&nbsp; Additionally, it was found that this force could be turned on and off very rapidly, making it ideal for use in active forcing.</p> <p>Guided by these fundamental results, several active forcing systems were developed over the course of the research, culminating in a version &ndash; the UltraShiver &ndash; that is capable of producing large in-plane forces on the finger with no tactile, visual or audio artifact.&nbsp; In other words, although the touch surface appears not to be moving and is completely silent, it is capable of pushing the finger.&nbsp; This is an important result because it is the foundation upon which the vision described at the outset might practically be built.</p><br> <p>            Last Modified: 08/12/2017<br>      Modified by: James&nbsp;E&nbsp;Colgate</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This research began with a vision for a new type of human-computer interface:  very much like a touchscreen, yet having the added ability to control what a person using it actually felt through his or her fingertips.  For instance, buttons might feel like they have shape so that a person could touch type, or a person with a vision impairment might be able to read using braille or something similar.  On the strength of previous research, our team felt that this could be accomplished by developing "active forcing" technology.  An active forcing interface can apply controlled forces to bare human fingertips in any direction along the surface.   How does active forcing control what a person feels?  The key is to make the forces dependent on the location and movement of the finger relative to graphical objects on the screen.  For instance, to make a button feel like it has an indented shape, the force can be controlled so that it does nothing if the finger is right over the center of the button, but pushes the finger back toward the center if it strays away.  The pattern of forces essentially fools the brain into believing that the button has shape.  Other patterns of forces can be used to emulate buttons that bulge out of the surface, toggle switches, knobs, pathways (imagine tracing out a path on an image of a map and feeling that path guide the finger), and endless other items that a designer might imagine.  Active forcing is accomplished by synchronizing high frequency in-plane vibrations of the touch surface with friction levels.  The concept is simple enough:  vibrate the touch surface in-plane, and increase the friction against the finger whenever that surface is moving in the desired pushing direction, while decreasing it when the surface moves in other directions.  On average, the finger will be pushed in the desired direction.  In practice, however, this is a challenging thing to do.  It is necessary to modulate the friction very rapidly and over a wide range of magnitudes.  This, in turn, requires a deep understanding of the friction modulation mechanics.   In this research, a combination of theoretical and experimental studies led to a deep understanding of two different approaches to friction modulation.  One approach is based on out-of-plane surface vibrations, which are known to reduce friction.  This work showed unequivocally that the finger "bounces" against the vibrating surface, and does not "float" has had been previously thought.  The bounces, however, are cushioned by air, which is the key factor that leads to friction reduction.  An additional result is that the dynamic properties &ndash; especially damping &ndash; of the fingertip itself, play a key role.  The second approach is based on creating an electric field between the fingertip skin and the surface.  The electric field causes the skin to be pulled down against the surface, increasing friction.  The experimental and theoretical results of this work explain how large the attractive force is and what factors influence it.  Additionally, it was found that this force could be turned on and off very rapidly, making it ideal for use in active forcing.  Guided by these fundamental results, several active forcing systems were developed over the course of the research, culminating in a version &ndash; the UltraShiver &ndash; that is capable of producing large in-plane forces on the finger with no tactile, visual or audio artifact.  In other words, although the touch surface appears not to be moving and is completely silent, it is capable of pushing the finger.  This is an important result because it is the foundation upon which the vision described at the outset might practically be built.       Last Modified: 08/12/2017       Submitted by: James E Colgate]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
