<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: When is Phonetic Variation Helpful for Word Learning?</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2014</AwardEffectiveDate>
<AwardExpirationDate>03/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>2305.00</AwardTotalIntnAmount>
<AwardAmount>2305</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When we listen to someone speaking sentences in our language, each word seems as clearly identifiable as a familiar face in a crowd.  But in fact, each time we hear a particular word spoken, it is acoustically different from the last time we heard it spoken.  Different talkers, different rates of speech, and different emotional states all affect the specific acoustic form that a word takes.  Experienced language users have no trouble overcoming this variability in the acoustic manifestation of words, but people who are still learning the language - young children and second language learners - struggle.  Thus, uniquely identifying particular words from a highly variable acoustic signal is a skill that must be mastered through experience for each language learned.  The main goal of this research is to explore one factor that might contribute to that mastery.  A secondary question is how words are represented in the mind so as to allow both rapid identification from the acoustic signal and rapid production.    &lt;br/&gt;&lt;br/&gt;Understanding when input from multiple talkers is helpful for learning new words will address the broader question of how people learn to perceive and produce words, a crucial task in learning a first or second language. Additionally, the way that speech perception and production are related has been a long-standing issue in phonetics as well as in language development. There is usually agreement that the knowledge about how to perceive a word influences knowledge about how to produce that word. However, there is much disagreement as to whether there is a single representation that is used for both perceiving a word and producing a word, or whether there are two different, but related representations. If there is a difference between perception and production in terms of benefit from multiple talkers, we will have evidence for different representations for perception and production, at least when a word is newly learned. A more nuanced understanding of the benefit of multiple talkers may inform methods for second language learning. More broadly, it may also shed light on how language is represented in the human mind.</AbstractNarration>
<MinAmdLetterDate>04/14/2014</MinAmdLetterDate>
<MaxAmdLetterDate>04/14/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1348451</AwardID>
<Investigator>
<FirstName>LouAnn</FirstName>
<LastName>Gerken</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>LouAnn Gerken</PI_FULL_NAME>
<EmailAddress>gerken@email.arizona.edu</EmailAddress>
<PI_PHON>5208918540</PI_PHON>
<NSF_ID>000174989</NSF_ID>
<StartDate>04/14/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Andrea</FirstName>
<LastName>Davis</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrea K Davis</PI_FULL_NAME>
<EmailAddress>davisak@email.arizona.edu</EmailAddress>
<PI_PHON>5206266000</PI_PHON>
<NSF_ID>000648719</NSF_ID>
<StartDate>04/14/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName/>
<StateCode>AZ</StateCode>
<ZipCode>857210001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~2305</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Previous work has found that talker variability benefits learning speech sounds and words. The variation between speakers draws attention to the meaningful acoustic cues in speech sounds and words. For example, the primary acoustic cue distinguishing the word <em>pear</em> from the word <em>bear</em> is a longer voice onset time. However, when speaker A says the word <em>pear</em>, and speaker B says the word <em>pear</em>, many other acoustic cues vary as well, because different people have different voice characteristics. If the listener doesn&rsquo;t know that she should pay attention to voice onset time, she may not be able to recognize that speakers A and B are saying the same word. Learning a word from multiple talkers demonstrates which acoustic cues vary greatly between speakers, and are therefore unreliable for understanding a word, and which acoustic cue or cues vary less, and are therefore the cues that are important for understanding a word.&nbsp;</p> <p>Previously, only learners who had not mastered their language have been found to benefit from talker variabiltiy: namely, infants, children, and second language speakers. These learners are still learning the sound system of a language. Thus, talker variability could be helpful for these learners because it bolsters their incomplete knowledge of a language&rsquo;s speech sound system. Speakers who have mastered a language's sound system, such as native speakers, had not previously been tested. These speakers should not benefit from talker variability when learning new words, in contrast to speakers who have not mastered a language's sound system</p> <p>This project showed that learners without language mastery benefited from talker variability when learning words, while learners with language mastery did not benefit. This result corroborates talker variability bolstering incomplete knowledge of a language&rsquo;s sound system.</p> <p>Additionally, this result has implications for second language learning and teaching. Specifically, it may be important to learn a second language from multiple talkers early on, to speed both vocabulary learning and learning of the second language&rsquo;s sound system.</p><br> <p>            Last Modified: 12/02/2015<br>      Modified by: Andrea&nbsp;K&nbsp;Davis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Previous work has found that talker variability benefits learning speech sounds and words. The variation between speakers draws attention to the meaningful acoustic cues in speech sounds and words. For example, the primary acoustic cue distinguishing the word pear from the word bear is a longer voice onset time. However, when speaker A says the word pear, and speaker B says the word pear, many other acoustic cues vary as well, because different people have different voice characteristics. If the listener doesnÆt know that she should pay attention to voice onset time, she may not be able to recognize that speakers A and B are saying the same word. Learning a word from multiple talkers demonstrates which acoustic cues vary greatly between speakers, and are therefore unreliable for understanding a word, and which acoustic cue or cues vary less, and are therefore the cues that are important for understanding a word.   Previously, only learners who had not mastered their language have been found to benefit from talker variabiltiy: namely, infants, children, and second language speakers. These learners are still learning the sound system of a language. Thus, talker variability could be helpful for these learners because it bolsters their incomplete knowledge of a languageÆs speech sound system. Speakers who have mastered a language's sound system, such as native speakers, had not previously been tested. These speakers should not benefit from talker variability when learning new words, in contrast to speakers who have not mastered a language's sound system  This project showed that learners without language mastery benefited from talker variability when learning words, while learners with language mastery did not benefit. This result corroborates talker variability bolstering incomplete knowledge of a languageÆs sound system.  Additionally, this result has implications for second language learning and teaching. Specifically, it may be important to learn a second language from multiple talkers early on, to speed both vocabulary learning and learning of the second languageÆs sound system.       Last Modified: 12/02/2015       Submitted by: Andrea K Davis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
