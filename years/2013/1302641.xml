<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Medium:  Programmability, Portability, Performance and Energy Efficiency for Heterogeneous Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>899786.00</AwardTotalIntnAmount>
<AwardAmount>899786</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>To maximize energy efficiency, future mobile devices will include a diverse range of hardware, such as large and small general-purpose processor cores, vector units, graphics processing units (GPUs), digital signal processors (DSPs), and semi-custom and custom accelerator cores.  This "heterogeneity" could power a new wave of innovation in mobile computing but is blocked by several fundamental challenges. Some of the biggest challenges are that such heterogeneous systems are highly challenging to program; that it is very difficult for software applications that use the diverse hardware to be portable across different mobile devices; that the memory systems in these devices are inflexible and inefficient; and that the semi-custom and custom accelerators are poorly integrated with the rest of the memory system and the programming environments.&lt;br/&gt;&lt;br/&gt;A key insight behind this project is that a carefully designed hardware abstraction layer --- a "Virtual Instruction Set" --- that abstracts away the differences in parallelism and memory subsystems across the different compute units can provide a framework in which all of the above interrelated problems can be solved extremely effectively. The project is developing a framework called Virtual Instruction Set Computing that uses this approach to address the above challenges. The framework uses just two or three models of parallelism and a uniform, rich model of communication to capture the full spectrum of heterogeneous hardware.  The hardware memory architecture supports specialized memory sub-systems and novel memory optimizations customized for those sub-systems, while compilers partition the memory used by applications to make use of these partitions; together, these specialization techniques will provide an order of magnitude improvement in memory efficiency.  Semi-custom accelerators for the key domain of Machine Learning are driving new programming and memory system design techniques to integrate and use semi-custom accelerators in such systems.  The overall research builds on the widely used LLVM virtual instruction set and compiler infrastructure (previously developed by members of this research team), which are already widely used in industry, enhancing the potential for technology transfer from this work. If this project is successful, it can enable far more powerful mobile phones, tablets, and other such devices, and far more advanced software applications that can make full use of the rich capabilities of these devices.</AbstractNarration>
<MinAmdLetterDate>08/13/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302641</AwardID>
<Investigator>
<FirstName>Sarita</FirstName>
<LastName>Adve</LastName>
<PI_MID_INIT>V</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sarita V Adve</PI_FULL_NAME>
<EmailAddress>sadve@cs.uiuc.edu</EmailAddress>
<PI_PHON>2173338461</PI_PHON>
<NSF_ID>000232935</NSF_ID>
<StartDate>08/13/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vikram</FirstName>
<LastName>Adve</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vikram S Adve</PI_FULL_NAME>
<EmailAddress>vadve@cs.uiuc.edu</EmailAddress>
<PI_PHON>2172442016</PI_PHON>
<NSF_ID>000334755</NSF_ID>
<StartDate>08/13/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robin</FirstName>
<LastName>Rutenbar</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robin A Rutenbar</PI_FULL_NAME>
<EmailAddress>rutenbar@pitt.edu</EmailAddress>
<PI_PHON>4126249019</PI_PHON>
<NSF_ID>000609244</NSF_ID>
<StartDate>08/13/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~899786</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Limitations in chip manufacturing techniques (the so-called "end of&nbsp; Moore's Law") are motivating computer system designers to use&nbsp; increasingly diverse, specialized (or "heterogeneous") compute&nbsp; elements rather than many uniform ones in order to achieve high&nbsp; performance and minimize power consumption. &nbsp;Such designs are&nbsp; becoming commonplace in systems ranging from mobile phones to&nbsp; supercomputers and data centers. &nbsp;Such systems raise major new&nbsp; challenges, including programmability, design complexity of&nbsp; individual compute elements, and communication and memory system&nbsp; challenges.&nbsp;&nbsp;&nbsp;</p> <p>We have developed a number of techinques to simplify programming and&nbsp; hardware design for these systems. &nbsp;First, we have developed an&nbsp; approach called HPVM (Heterogeneous Parallel Virtual Machine) that&nbsp; enables a single, suitably designed application program to be&nbsp; translated and optimized for a heterogeneous system with a diverse&nbsp; range of compute elements, and even for different systems with&nbsp; different combinations of these elements. &nbsp;HPVM is based on a common&nbsp; representation of parallelism that can be mapped down to all the&nbsp; different parallel hardware elements in a system. &nbsp;We have shown&nbsp; that a single HPVM program can be translated and optimized for GPUs,&nbsp; vector hardware, and threads, and are currently targeting&nbsp; reconfigurable hardware (FPGAs) and a novel hardware component for&nbsp; machine learning.</p> <p>Second, we developed a collection of memory system design techniques&nbsp; to address the limitations of heterogeneous memory&nbsp; systems. Traditional heterogeneous systems associate compute units&nbsp; with private memory structures (scratchpads and caches) to access&nbsp; data, which requires the programmer to manage complicated data&nbsp; movement patterns to and from main memory for high performance.&nbsp; This project showed how scratchpads and caches could be made direct&nbsp; parts of the globally accessible memory space, resulting in improved&nbsp; programmability and efficiency. Specifically, (1) we developed&nbsp; Stash, a memory structure that unifies the benefits of caches and&nbsp; scratchpads in a global, coherent address space; (2) we extended the&nbsp; existing DeNovo coherence protocol to heterogeneous systems and&nbsp; showed that this protocol enabled a standard and easy-to-program&nbsp; appraoch called data-race-free (DRF) that is much simpler than a&nbsp; current emerging industry standard; (3) we developed the DRFrlx&nbsp; model, a natural extension of DRF to incorporate the efficiency of&nbsp; relaxed atomics while being far easier to reason about correctly;&nbsp; and (4) we released the HeteroSync benchmark suite for heterogeneous&nbsp; workloads exploiting fine-grained synchronization.</p> <p>Third, we have developed PROMISE, a programmable version of a novel&nbsp; hardware design for machine learning applications, which uses&nbsp; analog-domain instead of digital-domain processing to improve energy&nbsp; efficiency by orders of magnitude. &nbsp;We have developed both a compiler&nbsp; from a high-level language (Julia) to PROMISE, and a new algorithm&nbsp; to trade off accuracy for reduced energy, using hardware-independent&nbsp; information about accuracy tolerance in the application code.</p> <p>Finally, we have developed a memory-rich accelerator design for studying&nbsp; heterogeneous memory systems. &nbsp;We used this approach to create a design&nbsp; for a key audio processing problem called "sound source separation,"&nbsp; which uses a range of memory structures, and prototyped it on an FPGA.&nbsp; The result was the first real-time streaming FPGA implementation of sound&nbsp; source separation, and the design achieves 20x speedup over a software&nbsp; solution, and at very low power.</p> <p>This research has had significant external impact. The work on HPVM has&nbsp; attracted interest from several companies. &nbsp;It is now a key part of a&nbsp; collaboration with Intel on compiling for reconfigurable hardware&nbsp; (FPGAs), and a broad DARPA-funded collaboration with IBM and other&nbsp; Universities on greatly improving the design process for future&nbsp; processors.</p> <p>We have released one artifact, the HeteroSync benchmark suite, in&nbsp; the public domain, and we are in the process of releasing the HPVM&nbsp; Compiler Infrastructure. &nbsp;We have trained seven graduate students,&nbsp; one of whom was also an undergraduate researcher, in compiler and&nbsp; hardware research through the course of this project. &nbsp;One of the&nbsp; graduate students supported in this project, as well as one of the&nbsp; three PIs, are women, and one graduate student is Hispanic. &nbsp;One PhD&nbsp; student won an honorable mention for the SIGARCH/TCCA outstanding&nbsp; dissertation award. &nbsp;He will be joining the Wisconsin faculty.&nbsp; Another will join AMD shortly. &nbsp;The undergraduate is pursuing a PhD.</p><br> <p>            Last Modified: 07/26/2018<br>      Modified by: Vikram&nbsp;S&nbsp;Adve</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532628944079_HPVM--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532628944079_HPVM--rgov-800width.jpg" title="Heterogeneous Parallel Virtual Machine"><img src="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532628944079_HPVM--rgov-66x44.jpg" alt="Heterogeneous Parallel Virtual Machine"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The HPVM representation for heterogeneous parallel systems</div> <div class="imageCredit">Vikram Adve, University of Illinois at Urbana-Champaign</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Vikram&nbsp;S&nbsp;Adve</div> <div class="imageTitle">Heterogeneous Parallel Virtual Machine</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629094298_HPVM_Example--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629094298_HPVM_Example--rgov-800width.jpg" title="HPVM Example"><img src="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629094298_HPVM_Example--rgov-66x44.jpg" alt="HPVM Example"></a> <div class="imageCaptionContainer"> <div class="imageCaption">HPVM dataflow graph for image processing program: edge detection in B&W images</div> <div class="imageCredit">Maria Kotsifakou and Prakalp Srivastava, University of Illinois at Urbana-Champaign</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Vikram&nbsp;S&nbsp;Adve</div> <div class="imageTitle">HPVM Example</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629682726_HPVM_ISA_IR--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629682726_HPVM_ISA_IR--rgov-800width.jpg" title="HPVM-based Virtual Instruction Set and Compiler IR"><img src="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629682726_HPVM_ISA_IR--rgov-66x44.jpg" alt="HPVM-based Virtual Instruction Set and Compiler IR"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Using the HPVM model to define a Virtual ISA for shipping code and a compiler Internal Representation for target-specific optimization and code generation.</div> <div class="imageCredit">Vikram Adve, University of Illinois at Urbana-Champaign</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Vikram&nbsp;S&nbsp;Adve</div> <div class="imageTitle">HPVM-based Virtual Instruction Set and Compiler IR</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629898150_PROMISE--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629898150_PROMISE--rgov-800width.jpg" title="The PROMISE Architecture and Compiler for Analog In-memory Processing"><img src="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532629898150_PROMISE--rgov-66x44.jpg" alt="The PROMISE Architecture and Compiler for Analog In-memory Processing"></a> <div class="imageCaptionContainer"> <div class="imageCaption">An analog-domain deep in-memory hardware design and compiler for machine learning inference that is</div> <div class="imageCredit">Prakalp Srivastava and Mingu Kang, University of Illinois at Urbana-Champaign</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Vikram&nbsp;S&nbsp;Adve</div> <div class="imageTitle">The PROMISE Architecture and Compiler for Analog In-memory Processing</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532630724223_AsyncGibbsAccelMRF--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532630724223_AsyncGibbsAccelMRF--rgov-800width.jpg" title="Asynchronous Gibbs sampling accelerator for Markov Random Field"><img src="/por/images/Reports/POR/2018/1302641/1302641_10266775_1532630724223_AsyncGibbsAccelMRF--rgov-66x44.jpg" alt="Asynchronous Gibbs sampling accelerator for Markov Random Field"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A custom accelerator design and FPGA prototype of the asynchronous Gibbs Sampling  algorithm for statistical machine learning</div> <div class="imageCredit">Glenn Ko, University of Illinois at Urbana-Champaign</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Vikram&nbsp;S&nbsp;Adve</div> <div class="imageTitle">Asynchronous Gibbs sampling accelerator for Markov Random Field</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Limitations in chip manufacturing techniques (the so-called "end of  Moore's Law") are motivating computer system designers to use  increasingly diverse, specialized (or "heterogeneous") compute  elements rather than many uniform ones in order to achieve high  performance and minimize power consumption.  Such designs are  becoming commonplace in systems ranging from mobile phones to  supercomputers and data centers.  Such systems raise major new  challenges, including programmability, design complexity of  individual compute elements, and communication and memory system  challenges.     We have developed a number of techinques to simplify programming and  hardware design for these systems.  First, we have developed an  approach called HPVM (Heterogeneous Parallel Virtual Machine) that  enables a single, suitably designed application program to be  translated and optimized for a heterogeneous system with a diverse  range of compute elements, and even for different systems with  different combinations of these elements.  HPVM is based on a common  representation of parallelism that can be mapped down to all the  different parallel hardware elements in a system.  We have shown  that a single HPVM program can be translated and optimized for GPUs,  vector hardware, and threads, and are currently targeting  reconfigurable hardware (FPGAs) and a novel hardware component for  machine learning.  Second, we developed a collection of memory system design techniques  to address the limitations of heterogeneous memory  systems. Traditional heterogeneous systems associate compute units  with private memory structures (scratchpads and caches) to access  data, which requires the programmer to manage complicated data  movement patterns to and from main memory for high performance.  This project showed how scratchpads and caches could be made direct  parts of the globally accessible memory space, resulting in improved  programmability and efficiency. Specifically, (1) we developed  Stash, a memory structure that unifies the benefits of caches and  scratchpads in a global, coherent address space; (2) we extended the  existing DeNovo coherence protocol to heterogeneous systems and  showed that this protocol enabled a standard and easy-to-program  appraoch called data-race-free (DRF) that is much simpler than a  current emerging industry standard; (3) we developed the DRFrlx  model, a natural extension of DRF to incorporate the efficiency of  relaxed atomics while being far easier to reason about correctly;  and (4) we released the HeteroSync benchmark suite for heterogeneous  workloads exploiting fine-grained synchronization.  Third, we have developed PROMISE, a programmable version of a novel  hardware design for machine learning applications, which uses  analog-domain instead of digital-domain processing to improve energy  efficiency by orders of magnitude.  We have developed both a compiler  from a high-level language (Julia) to PROMISE, and a new algorithm  to trade off accuracy for reduced energy, using hardware-independent  information about accuracy tolerance in the application code.  Finally, we have developed a memory-rich accelerator design for studying  heterogeneous memory systems.  We used this approach to create a design  for a key audio processing problem called "sound source separation,"  which uses a range of memory structures, and prototyped it on an FPGA.  The result was the first real-time streaming FPGA implementation of sound  source separation, and the design achieves 20x speedup over a software  solution, and at very low power.  This research has had significant external impact. The work on HPVM has  attracted interest from several companies.  It is now a key part of a  collaboration with Intel on compiling for reconfigurable hardware  (FPGAs), and a broad DARPA-funded collaboration with IBM and other  Universities on greatly improving the design process for future  processors.  We have released one artifact, the HeteroSync benchmark suite, in  the public domain, and we are in the process of releasing the HPVM  Compiler Infrastructure.  We have trained seven graduate students,  one of whom was also an undergraduate researcher, in compiler and  hardware research through the course of this project.  One of the  graduate students supported in this project, as well as one of the  three PIs, are women, and one graduate student is Hispanic.  One PhD  student won an honorable mention for the SIGARCH/TCCA outstanding  dissertation award.  He will be joining the Wisconsin faculty.  Another will join AMD shortly.  The undergraduate is pursuing a PhD.       Last Modified: 07/26/2018       Submitted by: Vikram S Adve]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
