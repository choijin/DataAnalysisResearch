<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Runtime System Support for Automated Object Recycling</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>365599.00</AwardTotalIntnAmount>
<AwardAmount>381599</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project seeks to improve the performance of a wide verity of memory-constrained object-oriented applications by automatically recycling objects. Large-scale, object-oriented software commonly suffers from systemic performance problems, due to inefficiencies inherent in an object-oriented language as well as commonly-adopted design and implementation principles. These problems are becoming increasingly critical as object-oriented languages are used in systems that typically have small memory space and computation power, such as mobile devices. In such systems, memory inefficiencies inherent in an object-oriented language can lead to severe performance degradation and reduced scalability. Evidence suggests that excessive object creation is a major source of inefficiencies in memory-constrained object-oriented applications.  Object recycling reduces this object creation overhead.  Recycling is achieved by designing and implementing runtime system support that can cache objects upon their creation, detect unreachable objects from the cache, and reuse both instances and data content of dead objects.&lt;br/&gt;&lt;br/&gt;Modern life relies increasingly on memory-constrained systems such as smartphones, tablets, and data-analytical tools. This project provides an immediate performance benefit for such memory-constrained systems, thereby leading to improved quality, usability, and user satisfaction. In addition, the research represents a first step in a new direction for the research community to explore, and may provoke further interests in automating, other important (currently manually-enforced) optimizations. The impact of the research is extended by a strategy of open-source licensing and distribution of the resulting software through the OpenJDK and Android communities. The educational component of this project includes creation of new course materials, recruitment of undergraduate students and students from under-represented groups, and education of local programmers on how to develop highly-efficient memory-constrained applications.</AbstractNarration>
<MinAmdLetterDate>08/21/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/11/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1321179</AwardID>
<Investigator>
<FirstName>Harry</FirstName>
<LastName>Xu</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Harry G Xu</PI_FULL_NAME>
<EmailAddress>harryxu@cs.ucla.edu</EmailAddress>
<PI_PHON>3107947145</PI_PHON>
<NSF_ID>000599637</NSF_ID>
<StartDate>08/21/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926973425</ZipCode>
<StreetAddress><![CDATA[5171 California Avenue, Ste 150]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~365599</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major goals of the project are to improve the performance of a wide verity of memory-constrained object-oriented applications by automatically recycling objects. Large-scale software commonly suffers from systemic performance problems, due to inefficiencies inherent in an object-oriented language as well as commonly-adopted design and implementation principles. These problems are becoming increasingly critical as object-oriented languages are used in systems that typically have small memory space and computation power, such as mobile devices. In such systems, memory inefficiencies inherent in an object-oriented language can lead to severe performance degradation and reduced scalability.&nbsp;</p> <p>Under the support of this grant, we have developed a series of techniques to reduce object creation in various kinds of software systems including non-data-intensive systems as well as data-intensive big data systems. These techniques have led to16 publications in top programming language, software engineering, and systems conferences as well as the release of 5 open-source systems. Here we briefly summarize our research outcome in these two application domains.&nbsp;</p> <p>1. Object Reduction in Non-Data-Intensive Systems</p> <p>Despite the employment of faster CPUs and larger memory systems, the levels of inefficiencies in real-world programs grow surprisingly fast and there is an ever-increasing demand for performance optimization in modern software. We have developed static and dynamic program analysis techniques to reduce object creation in large-scale object-oriented applications. We discuss two particular techniques here.&nbsp;</p> <p>The first technique is called Cachetor [FSE'13] that can pinpoint invariant objects that keep getting created and contain identical values.&nbsp;&nbsp;Cachetor employs a series of novel abstractions that are applied to run-time instruction instances during profiling, yielding significantly improved analysis time and scalability. We have implemented Cachetor in Jikes Research Virtual Machine and evaluated it on a set of 14 large Java applications. Our experimental results suggest that Cachetor is effective in exposing caching opportunities and substantial performance gains can be achieved by modifying a program to cache the reported data.&nbsp;</p> <p>We found that many existing optimization techniques (such as object pooling and pretenuring) require precise identification of object lifetimes. However, it is particularly challenging to obtain object lifetimes both precisely and efficiently: precise profiling techniques such as Merlin introduce several hundred times slowdown even for small programs while efficient approximation techniques often sacrifice precision and produce less useful lifetime information. The second technique is a tunable profiling technique, called Resurrector [OOPSLA'13], that explores the middle ground between high precision and high efficiency to find the precision-efficiency sweetspot for various liveness-based optimization techniques. Our evaluation shows that Resurrector is both more precise and more efficient than the GC-based approximation, and it is orders-of-magnitude faster than Merlin.&nbsp;</p> <p>2. Object Reduction in Data-Intensive Systems</p> <p>Modern computing has entered the era of Big Data. Developing systems that can scale to massive amounts of data without significantly increasing resource amounts is a key challenge faced by both researchers and practitioners. Supported by this grant, our work has focused on leveraging compiler and runtime system techniques to scale many different aspects of Big Data applications. Our research efforts have spanned a variety of computation models including dataflow [SOSP&rsquo;15] and graph models [USENIX ATC&rsquo;15, ATC&rsquo;16, ASPLOS&rsquo;17-b], a variety of execution environments including single-machine disk-based [USENIX ATC&rsquo;15, ATC&rsquo;16, TACO&rsquo;16] and distributed cluster-based environments [SOSP&rsquo;15, ASPLOS&rsquo;17-b, OSDI&rsquo;16, as well as applications written in a variety of languages including managed object-oriented languages<strong> </strong>[ISMM&rsquo;13, SOSP&rsquo;15, USENIX ATC&rsquo;15, ASPLOS&rsquo;15, OSDI&rsquo;16] and unmanaged languages [USENIX ATC&rsquo;16, ASPLOS&rsquo;17-a, ASPLOS&rsquo;17-b].</p> <p>Popular data processing frameworks such as Hadoop, Spark, Naiad, or Hyracks are all developed in managed languages, such as Java, C#, or Scala, primarily due to (1) the fast development cycles enabled by these languages, and (2) their abundance of library suites and community support. However, managed languages come at a cost: memory management in Big Data systems is often prohibitively expensive.&nbsp; For example, our study [ISMM&rsquo;13] shows that garbage collection (GC) accounts for close to 50% of the execution time of these systems, severely damaging system performance. The problem becomes increasingly painful in latency-sensitive distributed cloud applications where long GC pause times on one node can make many/all other nodes wait, potentially delaying the processing of user requests for unacceptably long time. &nbsp;Two primary techniques we developed to tackle the problem are Facade [ASPLOS'15] -- a compiler and runtime system that can (almost) statically bound the number of data objects, and Yak [OSDI'16] -- a JVM-based runtime system that splits a Java heap into a control and a data space and use different memory management techniques to manage their memory.&nbsp;</p> <p>To summarize, at the end of the project, we found that (1) exessive object creation is indeed a major source of performance degradation in various application domains; and (2) through a set of techniques we developed under the support of this grant, we could significantly reduce object numbers while preserving a program's semantics, thereby significantly improving the program's performance and scalability.&nbsp;</p><br> <p>            Last Modified: 11/20/2016<br>      Modified by: Guoqing&nbsp;Xu</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goals of the project are to improve the performance of a wide verity of memory-constrained object-oriented applications by automatically recycling objects. Large-scale software commonly suffers from systemic performance problems, due to inefficiencies inherent in an object-oriented language as well as commonly-adopted design and implementation principles. These problems are becoming increasingly critical as object-oriented languages are used in systems that typically have small memory space and computation power, such as mobile devices. In such systems, memory inefficiencies inherent in an object-oriented language can lead to severe performance degradation and reduced scalability.   Under the support of this grant, we have developed a series of techniques to reduce object creation in various kinds of software systems including non-data-intensive systems as well as data-intensive big data systems. These techniques have led to16 publications in top programming language, software engineering, and systems conferences as well as the release of 5 open-source systems. Here we briefly summarize our research outcome in these two application domains.   1. Object Reduction in Non-Data-Intensive Systems  Despite the employment of faster CPUs and larger memory systems, the levels of inefficiencies in real-world programs grow surprisingly fast and there is an ever-increasing demand for performance optimization in modern software. We have developed static and dynamic program analysis techniques to reduce object creation in large-scale object-oriented applications. We discuss two particular techniques here.   The first technique is called Cachetor [FSE'13] that can pinpoint invariant objects that keep getting created and contain identical values.  Cachetor employs a series of novel abstractions that are applied to run-time instruction instances during profiling, yielding significantly improved analysis time and scalability. We have implemented Cachetor in Jikes Research Virtual Machine and evaluated it on a set of 14 large Java applications. Our experimental results suggest that Cachetor is effective in exposing caching opportunities and substantial performance gains can be achieved by modifying a program to cache the reported data.   We found that many existing optimization techniques (such as object pooling and pretenuring) require precise identification of object lifetimes. However, it is particularly challenging to obtain object lifetimes both precisely and efficiently: precise profiling techniques such as Merlin introduce several hundred times slowdown even for small programs while efficient approximation techniques often sacrifice precision and produce less useful lifetime information. The second technique is a tunable profiling technique, called Resurrector [OOPSLA'13], that explores the middle ground between high precision and high efficiency to find the precision-efficiency sweetspot for various liveness-based optimization techniques. Our evaluation shows that Resurrector is both more precise and more efficient than the GC-based approximation, and it is orders-of-magnitude faster than Merlin.   2. Object Reduction in Data-Intensive Systems  Modern computing has entered the era of Big Data. Developing systems that can scale to massive amounts of data without significantly increasing resource amounts is a key challenge faced by both researchers and practitioners. Supported by this grant, our work has focused on leveraging compiler and runtime system techniques to scale many different aspects of Big Data applications. Our research efforts have spanned a variety of computation models including dataflow [SOSP?15] and graph models [USENIX ATC?15, ATC?16, ASPLOS?17-b], a variety of execution environments including single-machine disk-based [USENIX ATC?15, ATC?16, TACO?16] and distributed cluster-based environments [SOSP?15, ASPLOS?17-b, OSDI?16, as well as applications written in a variety of languages including managed object-oriented languages [ISMM?13, SOSP?15, USENIX ATC?15, ASPLOS?15, OSDI?16] and unmanaged languages [USENIX ATC?16, ASPLOS?17-a, ASPLOS?17-b].  Popular data processing frameworks such as Hadoop, Spark, Naiad, or Hyracks are all developed in managed languages, such as Java, C#, or Scala, primarily due to (1) the fast development cycles enabled by these languages, and (2) their abundance of library suites and community support. However, managed languages come at a cost: memory management in Big Data systems is often prohibitively expensive.  For example, our study [ISMM?13] shows that garbage collection (GC) accounts for close to 50% of the execution time of these systems, severely damaging system performance. The problem becomes increasingly painful in latency-sensitive distributed cloud applications where long GC pause times on one node can make many/all other nodes wait, potentially delaying the processing of user requests for unacceptably long time.  Two primary techniques we developed to tackle the problem are Facade [ASPLOS'15] -- a compiler and runtime system that can (almost) statically bound the number of data objects, and Yak [OSDI'16] -- a JVM-based runtime system that splits a Java heap into a control and a data space and use different memory management techniques to manage their memory.   To summarize, at the end of the project, we found that (1) exessive object creation is indeed a major source of performance degradation in various application domains; and (2) through a set of techniques we developed under the support of this grant, we could significantly reduce object numbers while preserving a program's semantics, thereby significantly improving the program's performance and scalability.        Last Modified: 11/20/2016       Submitted by: Guoqing Xu]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
