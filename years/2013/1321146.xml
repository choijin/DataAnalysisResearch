<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Flexible Turn-Taking for Mixed-Initiative Spoken Dialogue System</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>249999.00</AwardTotalIntnAmount>
<AwardAmount>257999</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to determine how turn-taking in human-human dialogue works, and use this as a basis for developing a flexible model of turn-taking for use in spoken dialogue systems. The first two aims focus on determining whether turn-taking is solely determined by the current speaker or is negotiated by both conversants. The first aim measures how well human subjects, listening to excerpts of speech, can predict whether the current speaker will continue the turn or release it. The second aim analyzes timing lags at turn transitions. Many turn transitions have short lags, which favors a speaker-control model; however this might be an artifact of common speech act sequences, back channels, early onsets, and provisional turns. The third aim, using the findings of the first two aims, is to determine the cues and mechanisms that are used by conversants in taking the turn.&lt;br/&gt;&lt;br/&gt;Better understanding of turn-taking in human-human dialogues is important as it will help in building more efficient and natural spoken dialogue systems, allowing the user and system to better collaborate to solve complex tasks. It should also allow spoken dialogue systems to deal with a broad range of users, from experts to novices: for experts, letting them take the initiative (and the turn), in order to efficiently complete the task, while guiding novices with more directions and examples. Furthermore, understanding human-human turn-taking might have biomedical applications. For example, Autism, which is a disorder that affects social communication, might impact how people engage in turn-taking, and so turn-taking biomarkers might help in diagnosing it.</AbstractNarration>
<MinAmdLetterDate>08/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>04/20/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1321146</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Heeman</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter A Heeman</PI_FULL_NAME>
<EmailAddress>heemanp@ohsu.edu</EmailAddress>
<PI_PHON>5033463755</PI_PHON>
<NSF_ID>000171635</NSF_ID>
<StartDate>08/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Oregon Health &amp; Science University</Name>
<CityName>Portland</CityName>
<ZipCode>972393098</ZipCode>
<PhoneNumber>5034947784</PhoneNumber>
<StreetAddress>3181 S W Sam Jackson Park Rd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code L106OPAM]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>096997515</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OREGON HEALTH &amp; SCIENCE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>096997515</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Oregon Health and Science University]]></Name>
<CityName/>
<StateCode>OR</StateCode>
<ZipCode>972393098</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~104569</FUND_OBLG>
<FUND_OBLG>2014~145430</FUND_OBLG>
<FUND_OBLG>2015~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the grant is to better understand how turn-taking works in human-human conversations: how do people ensure that just one person is typically speaking at a time, with little overlap or lag between speaking turns. &nbsp;In our research, we focused on understanding the amount of control that the current speaker has in determining who will speak next (speaker control model), versus how much this control might be shared with the other conversant (collaborative model). Better understanding how people naturally engage in turn-taking will allow us to build spoken dialogue systems that are more naturally and efficient to use.</p> <p><strong>Perceptual Study</strong></p> <p>The first part of this work examined whether someone listening to an utterance (or sentence) that was part of a recorded conversation can predict who will speak next: whether the current speaker will continue, or there is a switch to the other conversant. &nbsp;If participants are able to correctly guess then this must mean that the current speaker dictates who will speak next, and that the information is coded on the current utterance.</p> <p>We also examined whether there was strong agreement between the participants. &nbsp;Of the 40 utterances, 17 had strong agreement as to who will speak next, at levels well beyond chance and statistical significance. &nbsp;This is consistent with the collaborative model, in which the current speaker might not always indicate who should speak next. &nbsp; Of the 17, 12 were predicted to be continues; however, only 7 actually were. This shows that even when the current speaker signals they want to continue, this can be overruled by the other conversant.</p> <p>The other 5 were predicted to be switches, and all were switches. &nbsp;However, 4 of the 5 were question types. &nbsp;As questions are such an efficient way for the current speaker to signal the other to take the turn, other signals might not be used much. &nbsp;</p> <p><strong>Empirical Study of Turn-Taking Offsets</strong></p> <p>We then examined the distribution of offsets from turn switches (how long it took for the next person to start speaking). &nbsp;Key to this grant was to juxtapose this with the distribution of offsets from turn continues, pauses between turn-taking units of the same speaker. &nbsp;This way, we can start to examine whether turn-taking has a collaborative aspect to it, rather than being dictated by the current speaker. &nbsp;We found that the distribution of turn-taking offsets are quite similar between the two, with the exception that switches have some negative offsets.</p> <p>Past work in analyzing the offsets used silences of at least 200ms to segment speech into units, which can be done automatically. In our work, we had people annotate the speech and segment it at places where it forms a complete thought, as well as where it did not seem rude for the other to start speaking. &nbsp;We also annotated a number of common turn-taking phenomena, including interruptions, dual-starts, where both conversants start talking at the same time, and backchannels. &nbsp;This allowed us to carefully treat these types of occurrences in computing the offsets. &nbsp;With the revised offset durations, we see that many turn-transitionstake longer than previously thought, with 50% of all turn-transitions lasting at least 0.27s, and 25% at least 0.62s.</p> <p>Given the more leisurely pace of offsets found here, it seems likely that, instead of aiming to achieve no gaps and no overlaps, speakers aim to contribute to the dialogue as quickly as they can reasonably do so. &nbsp;In some cases the next speech may come quickly, perhaps because the response is a simple backchannel or the speaker is continuing on. In other cases the speech may take a while, perhaps because it takes longer to think of a contribution that will advance the dialogue.</p> <p><strong>Broader Impacts</strong></p> <p>This work supported a Post-doc, Master's student, and an undergraduate student, teaching them how to conduct research work, and giving them an in-depth understanding of the how turn-taking works. &nbsp;A richer understanding of turn-taking in typical development might allow us to better understand how this aspect of dialogue coordination is affected in Autism, which could lead to better diagnosis and remediation.</p><br> <p>            Last Modified: 12/07/2016<br>      Modified by: Peter&nbsp;A&nbsp;Heeman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the grant is to better understand how turn-taking works in human-human conversations: how do people ensure that just one person is typically speaking at a time, with little overlap or lag between speaking turns.  In our research, we focused on understanding the amount of control that the current speaker has in determining who will speak next (speaker control model), versus how much this control might be shared with the other conversant (collaborative model). Better understanding how people naturally engage in turn-taking will allow us to build spoken dialogue systems that are more naturally and efficient to use.  Perceptual Study  The first part of this work examined whether someone listening to an utterance (or sentence) that was part of a recorded conversation can predict who will speak next: whether the current speaker will continue, or there is a switch to the other conversant.  If participants are able to correctly guess then this must mean that the current speaker dictates who will speak next, and that the information is coded on the current utterance.  We also examined whether there was strong agreement between the participants.  Of the 40 utterances, 17 had strong agreement as to who will speak next, at levels well beyond chance and statistical significance.  This is consistent with the collaborative model, in which the current speaker might not always indicate who should speak next.   Of the 17, 12 were predicted to be continues; however, only 7 actually were. This shows that even when the current speaker signals they want to continue, this can be overruled by the other conversant.  The other 5 were predicted to be switches, and all were switches.  However, 4 of the 5 were question types.  As questions are such an efficient way for the current speaker to signal the other to take the turn, other signals might not be used much.    Empirical Study of Turn-Taking Offsets  We then examined the distribution of offsets from turn switches (how long it took for the next person to start speaking).  Key to this grant was to juxtapose this with the distribution of offsets from turn continues, pauses between turn-taking units of the same speaker.  This way, we can start to examine whether turn-taking has a collaborative aspect to it, rather than being dictated by the current speaker.  We found that the distribution of turn-taking offsets are quite similar between the two, with the exception that switches have some negative offsets.  Past work in analyzing the offsets used silences of at least 200ms to segment speech into units, which can be done automatically. In our work, we had people annotate the speech and segment it at places where it forms a complete thought, as well as where it did not seem rude for the other to start speaking.  We also annotated a number of common turn-taking phenomena, including interruptions, dual-starts, where both conversants start talking at the same time, and backchannels.  This allowed us to carefully treat these types of occurrences in computing the offsets.  With the revised offset durations, we see that many turn-transitionstake longer than previously thought, with 50% of all turn-transitions lasting at least 0.27s, and 25% at least 0.62s.  Given the more leisurely pace of offsets found here, it seems likely that, instead of aiming to achieve no gaps and no overlaps, speakers aim to contribute to the dialogue as quickly as they can reasonably do so.  In some cases the next speech may come quickly, perhaps because the response is a simple backchannel or the speaker is continuing on. In other cases the speech may take a while, perhaps because it takes longer to think of a contribution that will advance the dialogue.  Broader Impacts  This work supported a Post-doc, Master's student, and an undergraduate student, teaching them how to conduct research work, and giving them an in-depth understanding of the how turn-taking works.  A richer understanding of turn-taking in typical development might allow us to better understand how this aspect of dialogue coordination is affected in Autism, which could lead to better diagnosis and remediation.       Last Modified: 12/07/2016       Submitted by: Peter A Heeman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
