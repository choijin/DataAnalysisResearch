<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: 3D Event Reconstruction from Social Cameras</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>216000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This EAGER project explores the use of social cameras to reconstruct and understand social activities in the wild. Social cameras are an emerging phenomenon, producing video captures of social activity from the point of view of members of the social group itself. They are proliferating at an unprecedented rate, as smartphones, camcorders, and recently wearable cameras, become broadly adopted around the world. Users naturally direct social cameras at areas of activity they consider significant, by turning their heads towards them (with wearable cameras) or by pointing their smartphone cameras at them. The core scientific contribution of this work is the joint analysis of both the 3D motion of social cameras (that encodes group attention) and the 3D motion in the scene (that encodes social activity) towards understanding the social interactions in a scene. A number of internal models (such as maximizing rigidity or minimizing effort) for event reconstruction are being investigated to address the ill-posed inverse problems involved.&lt;br/&gt;&lt;br/&gt;This research is establishing a new area of visual analysis by providing the requisite framework for social activity understanding in 3D rather than in 2D. The ability to analyze social videos in 3D space and time provides useful tools for almost any activity that involves social groups working together, such as citizen journalism, search-and-rescue team coordination, or collaborative assembly teams. The project is integrated with education through teaching and student training, and outreaches industry through collaborations.</AbstractNarration>
<MinAmdLetterDate>09/02/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/17/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1353120</AwardID>
<Investigator>
<FirstName>Yaser</FirstName>
<LastName>Sheikh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yaser Sheikh</PI_FULL_NAME>
<EmailAddress>yaser@cs.cmu.edu</EmailAddress>
<PI_PHON>4122681138</PI_PHON>
<NSF_ID>000502497</NSF_ID>
<StartDate>09/02/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~200000</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Intellectual Merit</strong></p> <p>The project outcomes included an exploration both of developing a computational understanding of social behavior from crowd captures in the wild and a more systematic investigation in a controlled laboratory setting with the Panoptic Studio.&nbsp;</p> <p>A major outcome of the research was in predicting gaze direction from social cameras. We build a model based on a the concept of a "Social charge" that effectively predicts the gaze orientation, and therefore the attentive behavior, of individuals in a group.</p> <p class="p3"><span class="s1">In addition, we explored visibility Estimation in large scale 3D reconstruction: we formulated and considered the problem of visibility estimation in large scale dynamic 3D reconstruction from social cameras. This produced the highest resolution 3D reconstruciton of trajectory streams in history.</span></p> <p class="p3"><strong>Broad Impact</strong></p> <p class="p3"><span class="s1">We developed a state-of-the-art pose estimation system based on inference machines that can detection the anatomical landmark of people in social situations. This algorithm runs at over 14Hz when deployed on a GPU.</span></p> <p>Hanbyul Joo, Hyun Soo Park, Yaser Sheikh&nbsp;(2014).&nbsp;<em>MAP Visibility Estimation for Large-Scale Dynamic 3D Reconstruction</em>. IEEE Conference on Computer Vision and Pattern Recognition.&nbsp;Columbus, Ohio.<br />Varun Ramakrishna, Daniel Munoz, Martial Hebert, J. Andrew Bagnell, and Yaser Sheikh&nbsp;(2014).&nbsp;<em>Pose Machines: Articulated Pose Estimation via Inference Machines</em>. European Conference on Computer Vision.&nbsp;Zurich, Switzerland.&nbsp;<br />Hyun Soo Park, Eakta Jain, Yaser Sheikh&nbsp;(2013).&nbsp;<em>Predicting Primary Gaze Behavior using Social Saliency Fields</em>. IEEE International Conference on Computer Vision.&nbsp;Sydney, Australia.&nbsp;</p> <ul class="ul1"> </ul> <p class="p4"><span class="s1">Two PhD student research was supported under this grant and two visiting undergraduates were supported in the CMU Robotics Institute Summer Scholars program.</span></p> <p><strong>Outcomes of the award covering the life of the award</strong></p> <p>This project provided support to explore the foundations of event reconstruction from social cameras---cameras that capture social signals of the group using the cameras.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 02/10/2017<br>      Modified by: Yaser&nbsp;Sheikh</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1353120/1353120_10273732_1486780406931_tmp--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1353120/1353120_10273732_1486780406931_tmp--rgov-800width.jpg" title="Event Reconstruction"><img src="/por/images/Reports/POR/2017/1353120/1353120_10273732_1486780406931_tmp--rgov-66x44.jpg" alt="Event Reconstruction"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Event Reconstruction in the Panoptic Studio</div> <div class="imageCredit">Yaser Sheikh</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Yaser&nbsp;Sheikh</div> <div class="imageTitle">Event Reconstruction</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit  The project outcomes included an exploration both of developing a computational understanding of social behavior from crowd captures in the wild and a more systematic investigation in a controlled laboratory setting with the Panoptic Studio.   A major outcome of the research was in predicting gaze direction from social cameras. We build a model based on a the concept of a "Social charge" that effectively predicts the gaze orientation, and therefore the attentive behavior, of individuals in a group. In addition, we explored visibility Estimation in large scale 3D reconstruction: we formulated and considered the problem of visibility estimation in large scale dynamic 3D reconstruction from social cameras. This produced the highest resolution 3D reconstruciton of trajectory streams in history. Broad Impact We developed a state-of-the-art pose estimation system based on inference machines that can detection the anatomical landmark of people in social situations. This algorithm runs at over 14Hz when deployed on a GPU.  Hanbyul Joo, Hyun Soo Park, Yaser Sheikh (2014). MAP Visibility Estimation for Large-Scale Dynamic 3D Reconstruction. IEEE Conference on Computer Vision and Pattern Recognition. Columbus, Ohio. Varun Ramakrishna, Daniel Munoz, Martial Hebert, J. Andrew Bagnell, and Yaser Sheikh (2014). Pose Machines: Articulated Pose Estimation via Inference Machines. European Conference on Computer Vision. Zurich, Switzerland.  Hyun Soo Park, Eakta Jain, Yaser Sheikh (2013). Predicting Primary Gaze Behavior using Social Saliency Fields. IEEE International Conference on Computer Vision. Sydney, Australia.    Two PhD student research was supported under this grant and two visiting undergraduates were supported in the CMU Robotics Institute Summer Scholars program.  Outcomes of the award covering the life of the award  This project provided support to explore the foundations of event reconstruction from social cameras---cameras that capture social signals of the group using the cameras.           Last Modified: 02/10/2017       Submitted by: Yaser Sheikh]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
