<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Generating and Understanding Narratives for Dynamic Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>02/29/2016</AwardExpirationDate>
<AwardTotalIntnAmount>149857.00</AwardTotalIntnAmount>
<AwardAmount>149857</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hector Munoz-Avila</SignBlockName>
<PO_EMAI>hmunoz@nsf.gov</PO_EMAI>
<PO_PHON>7032924481</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Narrative generation is the process of generating textual descriptions of action in dynamic environments such as movies, sports events and educational programs. On-line narration of a dynamic environment is beneficial in a wide range of contexts, from entertainment to training and education. For example, successfully narrating a video would allow blind and visually-impaired people to follow visual cues that are important to understanding the video.  Key to attaining this goal is the ability to translate natural language into a form that is understandable by computers.  A particular challenge is to do this not for a specifically chosen domain, but in a general way that is suitable for adaptation to  a wide range of natural dynamic environments.  This project explores new directions to tackle these extremely challenging, yet crucial, issues, undertaking exploratory research towards building essential components of a domain-adaptive framework that learns to understand and generate narratives on-line for natural dynamic environments with minimal supervision by human experts.  This research explores methods to generate narratives on-line by learning the natural dynamics of the environment, automatically forming templates, and deciding when and what to mention. &lt;br/&gt;&lt;br/&gt;Many natural language applications are concerned with recognition of paraphrases and semantic understanding. The software and data resulting from this project are potentially useful for semantic analysis in natural language processing, and is being made available for research purposes. This work is designed for significant social impact through a broad range of applications including educational, entertainment, and accessibility.  A narrative generation system could be beneficial to visually-impaired people to better understand videos over the internet. In addition, such a system can help broadcasting companies to report news or sports events with customized commentaries for different users. This project also provides research and collaborative work experience to undergraduate and graduate students including under-represented and minority groups. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1352249</AwardID>
<Investigator>
<FirstName>Hanna</FirstName>
<LastName>Hajishirzi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hanna Hajishirzi</PI_FULL_NAME>
<EmailAddress>hannaneh@uw.edu</EmailAddress>
<PI_PHON>2065434043</PI_PHON>
<NSF_ID>000634179</NSF_ID>
<StartDate>08/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981952500</ZipCode>
<StreetAddress><![CDATA[Box 352500]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~149857</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-af9d58e6-034c-495e-f1cb-b6197dfeb629"> </span></p> <p dir="ltr"><span>Language is given meaning through its correspondence with a world representation. Grounded language acquisition is the problem of interpreting an utterance in the context of a world representation. </span><span>Previous systems that use machine learning techniques for language grounding usually work for formal world representations and controlled domains. If provided with sufficient training data, these approaches achieve high performance for simple controlled domains and rigidly structured language. However, general application of these methods for language grounding in a real-world setting is somewhat limited.</span><span> This exploratory project focused on designing general algorithms </span><span>for grounded language learning in diverse, real-world domains with weak supervision. </span></p> <p dir="ltr"><span>Major research activities and findings: </span><span><span> </span></span><span><span> </span></span></p> <ul> <li dir="ltr"> <p dir="ltr"><span>Multi-Resolution Language Grounding with Weak Supervision: In this work with introduced a new method for the multi-resolution grounding of complex natural language in a detailed world representation. We introduced a machine learning method to decompose the grounding problem into the more tractable subproblems of segmenting the language into fragments and aligning the fragments with the world representation. We also release a new dataset and tool for sport commentary grounding.&nbsp;</span></p> </li> <li dir="ltr"> <p dir="ltr"><span>Grounding Text into Diagrams for solving geometry questions: We build GEOS, the first automated system to solve unaltered SAT geometry questions by combining text understanding and diagram interpretation. In our experiments, GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions. We alo release a new dataset and tool for grounding and solving geometry questions.</span></p> </li> <li dir="ltr"> <p dir="ltr"><span>Grounding Standard Wikipedia to Simple Wikipedia: We study the problem of improving monolingual sentence alignment for text simplification, specifically for text in standard and simple Wikipedia. We introduce a method that improves over past efforts by using a greedy (vs. ordered) search over the document and a word-level semantic similarity score based on Wiktionary (vs. WordNet) that also accounts for structural similarity through syntactic dependencies. We release a new dataset of aligned sentences.&nbsp;</span></p> </li> <li dir="ltr"> <p dir="ltr"><span>Grounding text in dialog systems into knowledge graphs: We describe how a question-answering system can learn about its domain from conversational dialogs. Our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (KG), and uses the graph to solve questions.&nbsp;</span></p> </li> <li dir="ltr"> <p dir="ltr"><span>Grounding Algebra Word Problems into Equations with Weak Supervision: We present a novel approach to learning to solve arithmetic and algebra word problems. Our system analyzes the problem statement to identify the relevant variables and their values and then maps this information into an equation tree using local and global cues. &nbsp;A new dataset and tool has been released for grounding and solving algebra word problems.&nbsp;</span></p> </li> </ul> <p><span>This exploratory project produced a broad set of publically available software tools and datasets in language grounding. &nbsp;Research results were published in 10 peer reviewed publications and multiple popular media releases. The results of this project facilitated industry collaborations. One graduate student and three undergraduate students were supported in this project, one receiving a major research award at UW. Research fi...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Language is given meaning through its correspondence with a world representation. Grounded language acquisition is the problem of interpreting an utterance in the context of a world representation. Previous systems that use machine learning techniques for language grounding usually work for formal world representations and controlled domains. If provided with sufficient training data, these approaches achieve high performance for simple controlled domains and rigidly structured language. However, general application of these methods for language grounding in a real-world setting is somewhat limited. This exploratory project focused on designing general algorithms for grounded language learning in diverse, real-world domains with weak supervision.  Major research activities and findings:      Multi-Resolution Language Grounding with Weak Supervision: In this work with introduced a new method for the multi-resolution grounding of complex natural language in a detailed world representation. We introduced a machine learning method to decompose the grounding problem into the more tractable subproblems of segmenting the language into fragments and aligning the fragments with the world representation. We also release a new dataset and tool for sport commentary grounding.    Grounding Text into Diagrams for solving geometry questions: We build GEOS, the first automated system to solve unaltered SAT geometry questions by combining text understanding and diagram interpretation. In our experiments, GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions. We alo release a new dataset and tool for grounding and solving geometry questions.   Grounding Standard Wikipedia to Simple Wikipedia: We study the problem of improving monolingual sentence alignment for text simplification, specifically for text in standard and simple Wikipedia. We introduce a method that improves over past efforts by using a greedy (vs. ordered) search over the document and a word-level semantic similarity score based on Wiktionary (vs. WordNet) that also accounts for structural similarity through syntactic dependencies. We release a new dataset of aligned sentences.    Grounding text in dialog systems into knowledge graphs: We describe how a question-answering system can learn about its domain from conversational dialogs. Our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (KG), and uses the graph to solve questions.    Grounding Algebra Word Problems into Equations with Weak Supervision: We present a novel approach to learning to solve arithmetic and algebra word problems. Our system analyzes the problem statement to identify the relevant variables and their values and then maps this information into an equation tree using local and global cues.  A new dataset and tool has been released for grounding and solving algebra word problems.     This exploratory project produced a broad set of publically available software tools and datasets in language grounding.  Research results were published in 10 peer reviewed publications and multiple popular media releases. The results of this project facilitated industry collaborations. One graduate student and three undergraduate students were supported in this project, one receiving a major research award at UW. Research findings are used in paper reading and discussion in seminar classes. The project opened up collaborations across three departments of computer science, electrical engineering, and linguistics.              Last Modified: 05/30/2016       Submitted by: Hanna Hajishirzi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
