<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Collaborative Research: Design and Analysis of Novel Compressed Sensing Algorithms via Connections with Coding Theory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/16/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>196560.00</AwardTotalIntnAmount>
<AwardAmount>196560</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Compressed sensing (CS) is a rapidly advancing area of signal processing and statistics that has the potential to radically change the way that analog signals are transformed into digital signals.  The main idea is to acquire a sparse signal from a very small number of measurements using a specialized sampling and reconstruction process.  Since one promising application of CS is medical imaging, improvements in CS systems are also expected to advance real-world healthcare applications.  In this project, the investigators will study the fundamental connection between error-correcting codes (ECC) and CS and leverage recent advances in ECC to design improved CS measurement and reconstruction systems.&lt;br/&gt;&lt;br/&gt;In particular, the connection between linear-programming (LP) decoding of binary linear codes and LP reconstruction will be used to develop a non-asymptotic theory for the design and analysis of CS algorithms and measurement matrices.  The first part of the project will focus on novel relaxations of the CS reconstruction problem that allow non-convex regularization and iterative solution.  The second part of the project will focus on applying the theory of pseudo-codewords, which was originally developed to understand iterative and LP decoding of binary linear codes, to achieve a non-asymptotic analysis of iterative reconstruction algorithms for CS.  The third part of the project will focus on exploiting additional signal structure (i.e., beyond sparsity) that exists in high-contrast imaging applications such as angiograms.</AbstractNarration>
<MinAmdLetterDate>07/18/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1344364</AwardID>
<Investigator>
<FirstName>Georgios-Alex</FirstName>
<LastName>Dimakis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Georgios-Alex Dimakis</PI_FULL_NAME>
<EmailAddress>dimakis@austin.utexas.edu</EmailAddress>
<PI_PHON>5124713068</PI_PHON>
<NSF_ID>000515168</NSF_ID>
<StartDate>07/18/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121532</ZipCode>
<StreetAddress><![CDATA[101 E. 27th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2012~196560</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project investigated the role of sparsity in signal recovery problems. The first step was the discovery of a connection between error-correcting codes and sparse signal recovery (Compressed sensing). This connection led to provable guarantees of sensing matrices using LDPC codes. This allowed us to design the first known deterministic compressed sensing matrices with an optimal number of measurements.</p> <p><br />One part of this project focuses on exploiting sparsity along with additional additional structure (e.g. combinatorial properties.). For this problem we recently introduced a fast algorithm for estimating structural properties of big graphs called 3-profiles. Our algorithm uses the idea of random graph sparsification: Given a large graph we delete randomly many edges to obtain a smaller problem. We then estimate the desired structural properties on the sub-sampled graph and we can extrapolate for the true numbers for the full graph. We developed novel probabilistic bounds to show that this sparsification process is provably accurate. &nbsp;This algorithm has applications in computer security and social network analysis.&nbsp;</p> <p><br />For the problem of recovering unknown combinatorial structures we also obtained novel lower-bounds using information theoretic methods. Specifically we studied the problem of learning the dependency structure of a set of random variables given samples. While there have been recent results for specific graph classes, these involve fairly extensive technical arguments that are specialized to each specific graph class. Our work identified two key graph-structural ingredients thatwe then used to obtain novel sample complexity lower-bounds. Presence of these structural properties makes the graph class hard to learn.&nbsp;</p><br> <p>            Last Modified: 01/26/2016<br>      Modified by: Georgios-Alex&nbsp;Dimakis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project investigated the role of sparsity in signal recovery problems. The first step was the discovery of a connection between error-correcting codes and sparse signal recovery (Compressed sensing). This connection led to provable guarantees of sensing matrices using LDPC codes. This allowed us to design the first known deterministic compressed sensing matrices with an optimal number of measurements.   One part of this project focuses on exploiting sparsity along with additional additional structure (e.g. combinatorial properties.). For this problem we recently introduced a fast algorithm for estimating structural properties of big graphs called 3-profiles. Our algorithm uses the idea of random graph sparsification: Given a large graph we delete randomly many edges to obtain a smaller problem. We then estimate the desired structural properties on the sub-sampled graph and we can extrapolate for the true numbers for the full graph. We developed novel probabilistic bounds to show that this sparsification process is provably accurate.  This algorithm has applications in computer security and social network analysis.    For the problem of recovering unknown combinatorial structures we also obtained novel lower-bounds using information theoretic methods. Specifically we studied the problem of learning the dependency structure of a set of random variables given samples. While there have been recent results for specific graph classes, these involve fairly extensive technical arguments that are specialized to each specific graph class. Our work identified two key graph-structural ingredients thatwe then used to obtain novel sample complexity lower-bounds. Presence of these structural properties makes the graph class hard to learn.        Last Modified: 01/26/2016       Submitted by: Georgios-Alex Dimakis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
