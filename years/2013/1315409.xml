<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  A Multimodal Sensor Platform for Automated Detection and Classification of Pest Insects</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>179999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project proposes to develop a multi-modal sensor platform for robust detection and classification of insect pests for automated monitoring of insect populations.  More specifically, the project will investigate the feasibility of extracting meaningful features of insect pests using a set of low-cost, low-power sensors?namely ultrasound, infrared light and bio-impedance sensors?and develop multi-modal sensor fusion algorithms for robust detection and classification of multiple target insect species against any non-target organisms that may enter the trapping device.  Measurement signals generated by the sensors will be analyzed to determine a set of distinct features that can be computed on an embedded platform for real-time processing.  The critical requirements of employing low-cost, low-power sensors with real-time processing capability make this research unique and challenging.  Different sensor fusion strategies based on these features will be investigated and the performance of each fusion algorithm will be evaluated.  Successful conclusion of Phase I and II of this project will result in fully automated, wireless insect traps capable of providing accurate, real-time populations of multiple pest species.&lt;br/&gt;&lt;br/&gt; The broader impact/commercial potential of this project is that the proposed system could revolutionize pest management practices in agriculture and drastically reduce the amount of pesticide applications.  The proposed system not only eliminates one of the most laborious and dreaded activities of manually inspecting insect traps, but also provides unprecedented access to accurate, real-time insect population information to make more effective pest management decisions.  This leads to reduced, spatially-restricted pesticide applications, better understanding of insect pest behaviors, and enhanced biological control.  The potential market for the proposed technology is quite broad.  In fact, the technology can benefit any industry that requires regular monitoring of insect populations such as tree fruits (e.g., apple, grape, citrus, pear, etc.), row crops (e.g., corn, soy bean, sugar cane, etc.), vegetables, nuts, coffee, ornamental trees, stored food, etc.  Furthermore, the proposed technology could be used for various state and federal pest monitoring programs?such as the Slow the Spread (STS) Project administered by USDA to monitor gypsy moths?that requires placing and managing up to a few hundreds of thousands of pheromone traps annually.</AbstractNarration>
<MinAmdLetterDate>05/31/2013</MinAmdLetterDate>
<MaxAmdLetterDate>12/19/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1315409</AwardID>
<Investigator>
<FirstName>Johnny</FirstName>
<LastName>Park</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Johnny Park</PI_FULL_NAME>
<EmailAddress>johnny.park@spensatech.com</EmailAddress>
<PI_PHON>7655883592</PI_PHON>
<NSF_ID>000564516</NSF_ID>
<StartDate>05/31/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Spensa Technologies Inc.</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479064182</ZipCode>
<PhoneNumber>7655883592</PhoneNumber>
<StreetAddress>1281 Win Hentschel Blvd</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>831480376</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SPENSA TECHNOLOGIES INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>480047506</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Spensa Technologies Inc.]]></Name>
<CityName>West Lafayette</CityName>
<StateCode>IN</StateCode>
<ZipCode>479064182</ZipCode>
<StreetAddress><![CDATA[1281 Win Hentschel Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>1185</Code>
<Text>SENSORY SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~150000</FUND_OBLG>
<FUND_OBLG>2014~29999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This report describes the outcomes and findings of the NSF SBIR Phase IB project "A Multimodal Sensor Platform for Automated Detection and Classification of Pest Insects" carried out between July 1st, 2013 and June 31st, 2014. In this project, we designed a multi-sensor automated insect trap prototype (see Figure 1) and acquired preliminary data from three types of sensors: infrared, ultrasound, and bio-impedance. We carried out a large number of wind tunnel experiments and collected ground truth information to design and test the classification algorithms. Overall, we were able to collect sensor signals corresponding to a total of 1076 detections of five different insect species: codling moth (CM), Oriental fruit moth (OFM), naval orange worm (NOW), obliquebanded leafrollers (OBLR), and green lacewings (GLW). Using this information, we evaluated different classification algorithms and obtained satisfactory results at least with the bio-impedance and the infrared data. We also obtained preliminary results of an approach that combines signals from the bio-impedance and the infrared sensors. In addition, we were also able to reduce the power consumption of the infrared sensors to 10% of its nominal value.</p> <p>We have carried out multiple species classification using the bio-impedance and the infrared sensors. We have investigated several approaches for extracting features from the raw sensor data, and applied a support vector machine based classifier for classification. To our surprise, the classification results only using the bio-impedance or the infrared sensor were very good. Classification results showed over 93% correct rate with less than 5% error rate for the bio-impedance sensor and 88% correct rate with 11% error rate for the infrared sensors. Needless to say, these results far exceeded our expectation. The experimental results strongly validate the hypothesis that multiple insect species can be classified with a high degree of accuracy. We believe we will be able to achieve even more impressive results once we fuse data from all three sensors. We have made preliminary progress in an approach to merge the classification results using a method that computes the probability that a given measurement sample belongs to a certain insect species using the output of the support vector machine classifier. We will also continue to work with ultrasound sensors so that we will be able to assess the usefulness of these sensors with respect to (1) classification accuracy of multiple species; (2) detection accuracy of single species; and (3) overall power efficiency.</p> <p>For the multi-sensor trap to become a viable product, it must be able to operate for prolonged periods of time on a small and inexpensive battery pack. The current prototype was designed with the purpose of acquiring the best signals possible with little consideration to power consumption. Although we made substantial progress towards reducing the overall power consumption of the system, additional work is needed to further reduce the power consumption of the data acquisition circuits without sacrificing the quality of the signals.</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/13/2014<br>      Modified by: Johnny&nbsp;Park</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2014/1315409/1315409_10249280_1410631993016_POR_fig--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/1315409/1315409_10249280_1410631993016_POR_fig--rgov-800width.jpg" title...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This report describes the outcomes and findings of the NSF SBIR Phase IB project "A Multimodal Sensor Platform for Automated Detection and Classification of Pest Insects" carried out between July 1st, 2013 and June 31st, 2014. In this project, we designed a multi-sensor automated insect trap prototype (see Figure 1) and acquired preliminary data from three types of sensors: infrared, ultrasound, and bio-impedance. We carried out a large number of wind tunnel experiments and collected ground truth information to design and test the classification algorithms. Overall, we were able to collect sensor signals corresponding to a total of 1076 detections of five different insect species: codling moth (CM), Oriental fruit moth (OFM), naval orange worm (NOW), obliquebanded leafrollers (OBLR), and green lacewings (GLW). Using this information, we evaluated different classification algorithms and obtained satisfactory results at least with the bio-impedance and the infrared data. We also obtained preliminary results of an approach that combines signals from the bio-impedance and the infrared sensors. In addition, we were also able to reduce the power consumption of the infrared sensors to 10% of its nominal value.  We have carried out multiple species classification using the bio-impedance and the infrared sensors. We have investigated several approaches for extracting features from the raw sensor data, and applied a support vector machine based classifier for classification. To our surprise, the classification results only using the bio-impedance or the infrared sensor were very good. Classification results showed over 93% correct rate with less than 5% error rate for the bio-impedance sensor and 88% correct rate with 11% error rate for the infrared sensors. Needless to say, these results far exceeded our expectation. The experimental results strongly validate the hypothesis that multiple insect species can be classified with a high degree of accuracy. We believe we will be able to achieve even more impressive results once we fuse data from all three sensors. We have made preliminary progress in an approach to merge the classification results using a method that computes the probability that a given measurement sample belongs to a certain insect species using the output of the support vector machine classifier. We will also continue to work with ultrasound sensors so that we will be able to assess the usefulness of these sensors with respect to (1) classification accuracy of multiple species; (2) detection accuracy of single species; and (3) overall power efficiency.  For the multi-sensor trap to become a viable product, it must be able to operate for prolonged periods of time on a small and inexpensive battery pack. The current prototype was designed with the purpose of acquiring the best signals possible with little consideration to power consumption. Although we made substantial progress towards reducing the overall power consumption of the system, additional work is needed to further reduce the power consumption of the data acquisition circuits without sacrificing the quality of the signals.             Last Modified: 09/13/2014       Submitted by: Johnny Park]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
