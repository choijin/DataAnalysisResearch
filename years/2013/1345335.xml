<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Artificial Characterization of Objects Relating to Human Tactile Perception</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2014</AwardEffectiveDate>
<AwardExpirationDate>12/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>149808.00</AwardTotalIntnAmount>
<AwardAmount>175813</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Innovation Research (SBIR) Phase I project aims to develop a robotic instrument to provide quantitative characterization of surface properties that humans can perceive by touch. In contrast to machine vision, which operates on images&lt;br/&gt;captured passively with video cameras, "machine touch" requires physical interaction between the robotic sensors and the object. In fact, tactile signals are affected more by the choice of exploratory movement than by the properties of the object, making selection and control of these movements essential.  Current generations of robots rely on primitive contact sensors that are of little use in enabling more human-like perception, movement, dexterity and reflexes.   Robots equipped with more humanlike tactile perception and intelligent exploratory strategies will be used to characterize and identify common objects with accuracy and speed similar to humans.  They will be able to learn and continuously improve their performance as they interact with objects over time.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project will be the enabling of advanced, autonomous functionality in the next generation of robots.   Robots need to be able to perceive the world and interact with the world more like humans in order to better work alongside us in unstructured environments.   Assistive robots for care of the disabled and the elderly are but one example of how next generation robotics will improve the quality of life for many.    Better understanding of the haptic properties of consumer products will facilitate development of new products that ?feel? better to human users and the development of quality control systems to assure that those products consistently attain those desirable properties during manufacture.  Because these robots employ biomimetic strategies for haptic perception, their performance can be compared to that of humans to provide insights into the perceptual and cognitive strategies employed by the human mind.</AbstractNarration>
<MinAmdLetterDate>11/13/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/23/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1345335</AwardID>
<Investigator>
<FirstName>Jeremy</FirstName>
<LastName>Fishel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeremy Fishel</PI_FULL_NAME>
<EmailAddress>jafishel@csuchico.edu</EmailAddress>
<PI_PHON>5308985320</PI_PHON>
<NSF_ID>000606414</NSF_ID>
<StartDate>11/13/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SynTouch LLC</Name>
<CityName>Montrose</CityName>
<ZipCode>910201516</ZipCode>
<PhoneNumber>3108075786</PhoneNumber>
<StreetAddress>3720 Clifton Place</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>28</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA28</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>827484929</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SYNTOUCH L.L.C.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117367572</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SynTouch]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900076601</ZipCode>
<StreetAddress><![CDATA[2222 South Figueroa St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~175813</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this research was to determine if a human-like tactile sensor (the BioTac) could be used to measure how surfaces feel in a way that relates to how humans describe objects. To accomplish this, a large database of more than 500 different samples from everyday objects was assembled, covering a wide range of tactile properties. Exploratory movements, modeled after the poking and sliding movements humans make, were developed to allow the tactile sensor to explore the objects similar to the way humans do. Using carefully crafted signal processing, it was possible to develop measurements for 15 different tactile properties that humans associate with touch (such as rough/smooth, coarse/fine, soft/hard, warm/cool, etc.). Using these methods, it was found that the developed system was able to characterize and differentiate these surfaces better than humans could.</p> <p>This work represents the first of its kind to develop a human-inspired method for characterizing the way things feel. This brings the world one step closer to developing the first tactile standard to quantify the sense of touch, which has been one of the most elusive of the senses to measure (in contrast to sound and vision, which are easily measured with microphones and video cameras). The human-like BioTac sensor combined with human-like exploratory movements and human-inspired signal processing resulted in a system that was gratifyingly very human-like in its performance. Research in this direction has further advanced our understanding of human touch and its applications in industrial use. Several industrial partners are helping to develop the requirements that would allow this technology to translate to a testing system that would characterize how products feel. This has many applications in advanced product development, sourcing of new raw materials, and quality control.</p> <p>A more comprehensive understanding of the robotic sense of touch and how that relates to the human sense of touch has a much broader impact for developing human-like robots that will need a sense of touch to perform human-like activities. Robots, if they cannot feel, will be just as clumsy as humans when their fingers are numb from the cold. This research is a first step toward understanding how robotic touch can relate to human touch, an essential step to advancing human-like robotics and robotic dexterity.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/08/2015<br>      Modified by: Jeremy&nbsp;Fishel</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2015/1345335/1345335_10285190_1438995923652_Testbed--rgov-214x142.jpg" original="/por/images/Reports/POR/2015/1345335/1345335_10285190_1438995923652_Testbed--rgov-800width.jpg" title="The SynTouch Tactile Analysis System"><img src="/por/images/Reports/POR/2015/1345335/1345335_10285190_1438995923652_Testbed--rgov-66x44.jpg" alt="The SynTouch Tactile Analysis System"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The SynTouch Tactile Analysis system uses the human-like BioTac sensor to move over surfaces to determine how they feel, just like you do with your own fingers.</div> <div class="imageCredit">SynTouch LLC</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jeremy&nbsp;Fishel</div> <div class="imageTitle">The SynTouch Tactile Analysis System</div> </div> </li> <li> <a href="/por/images/Reports/POR/2015/1345335/1345335_10285...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this research was to determine if a human-like tactile sensor (the BioTac) could be used to measure how surfaces feel in a way that relates to how humans describe objects. To accomplish this, a large database of more than 500 different samples from everyday objects was assembled, covering a wide range of tactile properties. Exploratory movements, modeled after the poking and sliding movements humans make, were developed to allow the tactile sensor to explore the objects similar to the way humans do. Using carefully crafted signal processing, it was possible to develop measurements for 15 different tactile properties that humans associate with touch (such as rough/smooth, coarse/fine, soft/hard, warm/cool, etc.). Using these methods, it was found that the developed system was able to characterize and differentiate these surfaces better than humans could.  This work represents the first of its kind to develop a human-inspired method for characterizing the way things feel. This brings the world one step closer to developing the first tactile standard to quantify the sense of touch, which has been one of the most elusive of the senses to measure (in contrast to sound and vision, which are easily measured with microphones and video cameras). The human-like BioTac sensor combined with human-like exploratory movements and human-inspired signal processing resulted in a system that was gratifyingly very human-like in its performance. Research in this direction has further advanced our understanding of human touch and its applications in industrial use. Several industrial partners are helping to develop the requirements that would allow this technology to translate to a testing system that would characterize how products feel. This has many applications in advanced product development, sourcing of new raw materials, and quality control.  A more comprehensive understanding of the robotic sense of touch and how that relates to the human sense of touch has a much broader impact for developing human-like robots that will need a sense of touch to perform human-like activities. Robots, if they cannot feel, will be just as clumsy as humans when their fingers are numb from the cold. This research is a first step toward understanding how robotic touch can relate to human touch, an essential step to advancing human-like robotics and robotic dexterity.          Last Modified: 08/08/2015       Submitted by: Jeremy Fishel]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
