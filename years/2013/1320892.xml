<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Speaker Independent Acoustic-Articulator Inversion for Pronunciation Assessment</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>449643.00</AwardTotalIntnAmount>
<AwardAmount>481643</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>To support an integrated global economy, it is essential that people of all backgrounds be able to function together effectively despite language barriers, and development of Computer Aided Language Learning (CALL) and accent modification tools is a key part of making this possible. In order to support effective learning and provide specific, useful pronunciation feedback to users, systems for pronunciation correction must be able to capture and accurately describe errors in articulation. Accurate acoustic-to-articulator inversion, the estimation of articulatory trajectories from an acoustic signal, has the potential to significantly improve the accuracy and specificity of such feedback to language learners, and enhance methods for in-depth study of both native speaker and second language learner articulatory patterns.&lt;br/&gt;&lt;br/&gt;This research addresses the problem of robust speaker-independent acoustic-to-articulator inversion, which is a challenging problem due to the complexity of articulation patterns and significant inter-speaker differences. To overcome this difficulty, a novel speaker-independent inversion approach called Parallel Reference Speaker Weighting is being developed, which uses parallel acoustic-articulator adaptation to create speaker-specific models for new speakers without kinematic training data, represented in a normalized articulatory working space. The new approach is being evaluated on the Marquette University EMA-MAE Corpus of parallel acoustic / 3-D electromagnetic articulography data including both American English and Mandarin Accented English speakers. &lt;br/&gt;&lt;br/&gt;The primary impact of this work focuses on the improvement of pronunciation assessment and accent modification systems, with potential for contribution to numerous other speech technologies, including speech recognition, speech coding, and audio and video synthesis.</AbstractNarration>
<MinAmdLetterDate>08/08/2013</MinAmdLetterDate>
<MaxAmdLetterDate>12/21/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320892</AwardID>
<Investigator>
<FirstName>Mike</FirstName>
<LastName>Johnson</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mike T Johnson</PI_FULL_NAME>
<EmailAddress>mike.johnson@uky.edu</EmailAddress>
<PI_PHON>8592570717</PI_PHON>
<NSF_ID>000279555</NSF_ID>
<StartDate>08/08/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Berry</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jeffrey Berry</PI_FULL_NAME>
<EmailAddress>jeffrey.berry@marquette.edu</EmailAddress>
<PI_PHON>4142887200</PI_PHON>
<NSF_ID>000572881</NSF_ID>
<StartDate>08/08/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Marquette University</Name>
<CityName>Milwaukee</CityName>
<ZipCode>532011881</ZipCode>
<PhoneNumber>4142887200</PhoneNumber>
<StreetAddress>P.O. Box 1881</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046929621</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MARQUETTE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006439962</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Marquette University]]></Name>
<CityName/>
<StateCode>WI</StateCode>
<ZipCode>532011881</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~151913</FUND_OBLG>
<FUND_OBLG>2014~156585</FUND_OBLG>
<FUND_OBLG>2015~157145</FUND_OBLG>
<FUND_OBLG>2016~8000</FUND_OBLG>
<FUND_OBLG>2017~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>To be competitive in the global economy, it is essential that people of all backgrounds be able to function together effectively despite language barriers, and development of Computer Aided Language Learning (CALL), Computer Aided Pronunciation Training (CAPT), and other accent modification tools is a key part of making this possible. In order to support effective learning and provide specific, useful pronunciation feedback to users, systems for pronunciation correction must be able to capture and accurately describe errors in articulation. Current systems are limited in the specificity of the corrective feedback that is provided, often only providing a "good versus bad" pronunciation match to the target and at best providing only the general category of pronunciation error. Accurate estimates of language learners' articulatory motion has the potential to significantly improve the quality of feedback, as well as enhancing methods for in-depth study of L1 and L2 articulatory patterns as it relates to language learning.</p> <p>With this goal in mind, our project has focused on the problem of robust speaker-independent acoustic-to-articulator inversion, with application to pronunciation assessment. Acoustic-to-articulator inversion, the estimation of articulatory trajectories from an acoustic signal, is a challenging problem due to the complexity of articulation patterns and significant inter-speaker differences, and is even more so when applied to non-native speakers without any kinematic training data. We have addressed this problem through development of a robust normalized working space for articulatory representation and use of a novel speaker-independent inversion approach called Parallel Reference Speaker Weighting (PRSW), which uses parallel acoustic-articulator adaptation to create speaker-specific models for new speakers without any kinematic training data. The approach has been evaluated on an electromagnetic articulography (EMA) dataset of native American English (L1) speakers and native Mandarin Chinese (L2) speakers who speak English as a second language. Results have shown that our PRSW approach is able to produce estimated articulatory trajectories for new unknown speakers that are nearly as accurate as speaker-dependent systems trained on actual speech and articulatory data for a known speaker. Our final system generates articulatory trajectories with a 0.66 correlation to the true trajectory, in contrast to a speaker dependent inversion system that gives outputs with a 0.67 correlation to the true trajectory.</p> <p>The primary scientific contribution of this work has been the extension of current methods for pronunciation analysis to include explicit models of articulatory motion that can be normalized to a speaker-independent reference frame and compared to a normative baseline, without the need for previously collected kinematic data for that speaker.&nbsp; This has already had significant impact on our understanding of differences in L1 and L2 articulatory patterns, especially for Mandarin Accented English, and is expected to enable more comprehensive and effective feedback mechanisms in CALL systems for pronunciation modification.</p> <p>The broader impact of pronunciation assessment in particular lies in its contribution to enabling nonnative speakers of English to more effectively function within American society. Improved outcomes in pronunciation training will bolster the achievement of non-native speakers and facilitate communicative effectiveness. In addition, the new robust methods for speech inversion created through this project have the potential to benefit not only pronunciation assessment but also numerous speech technologies, including speech recognition, coding, and video synthesis.</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/05/2018<br>      Modified by: Mike&nbsp;T&nbsp;Johnson</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1320892/1320892_10265346_1543939693616_MLLR_PRSW_method--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1320892/1320892_10265346_1543939693616_MLLR_PRSW_method--rgov-800width.jpg" title="PRSW Block Diagram"><img src="/por/images/Reports/POR/2018/1320892/1320892_10265346_1543939693616_MLLR_PRSW_method--rgov-66x44.jpg" alt="PRSW Block Diagram"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The MLLR-PRSW system performs articulatory inversion of a new speaker with no kinematic training data and a small amount of acoustic adaptation data. It uses MLLR adaption to create new acoustic models and RSW adaptation to generate weights for the articulatory models from reference speakers.</div> <div class="imageCredit">Narjes Bozorg</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mike&nbsp;T&nbsp;Johnson</div> <div class="imageTitle">PRSW Block Diagram</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1320892/1320892_10265346_1543939859482_MLLR_PRSW_results--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1320892/1320892_10265346_1543939859482_MLLR_PRSW_results--rgov-800width.jpg" title="PRSW results"><img src="/por/images/Reports/POR/2018/1320892/1320892_10265346_1543939859482_MLLR_PRSW_results--rgov-66x44.jpg" alt="PRSW results"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Table of inversion correlation results for both native English speakers and native Mandarin speakers speaking English.  Speaker dependent, PRSW-PRSW, and MLLR-PRSW methods are shown. Final average correlation is 0.66 for MLLR-PRSW method.</div> <div class="imageCredit">Narjes Bozorg</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mike&nbsp;T&nbsp;Johnson</div> <div class="imageTitle">PRSW results</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1320892/1320892_10265346_1544023940257_Vowel_articulation_templates--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1320892/1320892_10265346_1544023940257_Vowel_articulation_templates--rgov-800width.jpg" title="Vowel articulation templates"><img src="/por/images/Reports/POR/2018/1320892/1320892_10265346_1544023940257_Vowel_articulation_templates--rgov-66x44.jpg" alt="Vowel articulation templates"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Confidence ellipses, visualization, and biofeedback plots generated from inversion data, for use with second language pronunciation training</div> <div class="imageCredit">Jeffrey Berry</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mike&nbsp;T&nbsp;Johnson</div> <div class="imageTitle">Vowel articulation templates</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ To be competitive in the global economy, it is essential that people of all backgrounds be able to function together effectively despite language barriers, and development of Computer Aided Language Learning (CALL), Computer Aided Pronunciation Training (CAPT), and other accent modification tools is a key part of making this possible. In order to support effective learning and provide specific, useful pronunciation feedback to users, systems for pronunciation correction must be able to capture and accurately describe errors in articulation. Current systems are limited in the specificity of the corrective feedback that is provided, often only providing a "good versus bad" pronunciation match to the target and at best providing only the general category of pronunciation error. Accurate estimates of language learners' articulatory motion has the potential to significantly improve the quality of feedback, as well as enhancing methods for in-depth study of L1 and L2 articulatory patterns as it relates to language learning.  With this goal in mind, our project has focused on the problem of robust speaker-independent acoustic-to-articulator inversion, with application to pronunciation assessment. Acoustic-to-articulator inversion, the estimation of articulatory trajectories from an acoustic signal, is a challenging problem due to the complexity of articulation patterns and significant inter-speaker differences, and is even more so when applied to non-native speakers without any kinematic training data. We have addressed this problem through development of a robust normalized working space for articulatory representation and use of a novel speaker-independent inversion approach called Parallel Reference Speaker Weighting (PRSW), which uses parallel acoustic-articulator adaptation to create speaker-specific models for new speakers without any kinematic training data. The approach has been evaluated on an electromagnetic articulography (EMA) dataset of native American English (L1) speakers and native Mandarin Chinese (L2) speakers who speak English as a second language. Results have shown that our PRSW approach is able to produce estimated articulatory trajectories for new unknown speakers that are nearly as accurate as speaker-dependent systems trained on actual speech and articulatory data for a known speaker. Our final system generates articulatory trajectories with a 0.66 correlation to the true trajectory, in contrast to a speaker dependent inversion system that gives outputs with a 0.67 correlation to the true trajectory.  The primary scientific contribution of this work has been the extension of current methods for pronunciation analysis to include explicit models of articulatory motion that can be normalized to a speaker-independent reference frame and compared to a normative baseline, without the need for previously collected kinematic data for that speaker.  This has already had significant impact on our understanding of differences in L1 and L2 articulatory patterns, especially for Mandarin Accented English, and is expected to enable more comprehensive and effective feedback mechanisms in CALL systems for pronunciation modification.  The broader impact of pronunciation assessment in particular lies in its contribution to enabling nonnative speakers of English to more effectively function within American society. Improved outcomes in pronunciation training will bolster the achievement of non-native speakers and facilitate communicative effectiveness. In addition, the new robust methods for speech inversion created through this project have the potential to benefit not only pronunciation assessment but also numerous speech technologies, including speech recognition, coding, and video synthesis.          Last Modified: 12/05/2018       Submitted by: Mike T Johnson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
