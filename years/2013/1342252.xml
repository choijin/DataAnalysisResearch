<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RAPID: Social Media: Learning from the Boston Marathon Bombing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>72879.00</AwardTotalIntnAmount>
<AwardAmount>72879</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The April 15, 2013 Boston Marathon Bombing (BMB) is a fresh reminder that societies can be shocked not only by natural disasters such as earthquakes and hurricanes but also by acts of terrorism. The bombing engaged the public in multiple ways, and social media platforms (Twitter, YouTube, Facebook, etc.) enabled the public to become both informed and to some extent involved. Digital traces that can be collected from these sites present a brief window of opportunity for research on how, and to what extent, this involvement emerged. This RAPID project will collect data from social media such as Twitter and other linked sources to address questions about the flow of information about the event across traditional and social media, the propogation and amplification of unsubstantiated information and misinformation, differences between official and popular social media use, self-organization of efforts for assistance or suspect tracking and changes in public sentiment over time. Data from this event may reveal differences in the dynamics of social media use in the wake of terrorist events vs. natural disasters. &lt;br/&gt;&lt;br/&gt;The intellectual merit of the proposed project is that it combines emerging methods and techniques for social media research with recent research on disaster response coordination and planning to develop a conceptual model of the BMB information flows to guide data collection and analysis. Because the Boston Marathon attracted participants from around the world, this bombing has a global dimension that may affect the nature and reach of the social media communications.  &lt;br/&gt;&lt;br/&gt;Broader impacts of the project include educational benefits from students involved in the project and in courses that will be informed by the project findings. The collected data will be made available to other researchers and the principal investigators plan to coordinate their work with others examining this event, thus contributing to the infrastructure for science. The proposal includes funding for dissemination of the results of preliminary analysis of the collected data. Results from analysis may offer an improved guide for research on communication and information flows in crises and disasters (whether natural or human-initiated), thus benefiting society.  &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>05/24/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/24/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1342252</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Mason</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert M Mason</PI_FULL_NAME>
<EmailAddress>rmmason@uw.edu</EmailAddress>
<PI_PHON>2062215623</PI_PHON>
<NSF_ID>000348364</NSF_ID>
<StartDate>05/24/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kate</FirstName>
<LastName>Starbird</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kate Starbird</PI_FULL_NAME>
<EmailAddress>kstarbi@uw.edu</EmailAddress>
<PI_PHON>2065434043</PI_PHON>
<NSF_ID>000636015</NSF_ID>
<StartDate>05/24/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName/>
<StateCode>WA</StateCode>
<ZipCode>981051016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~72879</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In disasters and crises, many people turn to social media platforms and services such as Twitter and Facebook for news and to share their views and knowledge about what can be rapidly changing situations.&nbsp; Information from these sources, including citizens and other observers not in positions of authority, can be useful to first responders and to authorities coordinating help and assistance.&nbsp; Relying on this information, however, can present problems, as some of the information is unverified and can be misleading.</p> <p>This project collected 11 million tweets (very short messages using the Twitter service) immediately after the bombing at the Boston Marathon on April 15, 2013.&nbsp; Our acquisition method had gaps at times, and we later acquired over 20 million tweets from a commercial service for the same time period to assure that we had a complete collection.</p> <p>Many of these tweets were &ldquo;retweets&rdquo; in which the original message was repeatedly forwarded, sometimes with additional comments. Our initial goals were to understand if the tweets could provide reliable information in time to be useful to responders and to civic authorities.&nbsp; We expected some of these messages to be unverified (they would be &ldquo;rumors&rdquo;) and that many of these would prove to be false.&nbsp; We wanted to see if &ldquo;the crowd,&rdquo; which could quickly spread both information and misinformation, would serve to correct misinformation.</p> <p>We examined several rumors and focused our study on the spread of misinformation.&nbsp; Some of the rumors were easily seen as false.&nbsp; For example, someone tweeted that an 8-year old girl running in the marathon had been killed.&nbsp; This tweet was retweeted thousands of times by people who didn&rsquo;t reflect on its obvious inaccuracy (8 year olds don&rsquo;t run in the marathon).&nbsp; Interestingly, when someone added an image of a young girl with a runner&rsquo;s bib that clearly showed she was in a &ldquo;5 K&rdquo; run, rather than sparking a correction, the rumor began to spread even faster,</p> <p>The project yielded several results that have significance both for other researchers and for policy and decision makers&mdash;for those who continue research aimed at understanding the spread of information and rumors and for authorities and crisis responders.&nbsp; One finding verifies the value of collecting contemporaneous social media data, even if it is incomplete.&nbsp; The &ldquo;archived&rdquo; set of data used in the project was missing messages that had been deleted.&nbsp; Using such data for research can give a misleading picture of the speed and reach of misinformation and the processes by which it spreads.</p> <p>Authorities and crisis responders will benefit from our observations that rumors, including false information, can spread rapidly and widely&mdash;they can become &ldquo;viral.&rdquo;&nbsp; In our study, the &ldquo;corrections&rdquo; to false rumors occurred at a much lower rate and were forwarded (retweeted) much less often&mdash;there was not a corresponding viral behavior to the corrections.&nbsp; Moreover, retweets of the false rumor continued even after corrections were posted, and this was true for each instance of misinformation.</p> <p>The project results provide support for the notion that further work is needed to understand the propagation of misinformation in crises so that the full potential of social media can be realized in such situations.&nbsp; Additional work beyond this project is continuing.&nbsp;&nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/17/2015<br>      Modified by: Robert&nbsp;M&nbsp;Mason</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In disasters and crises, many people turn to social media platforms and services such as Twitter and Facebook for news and to share their views and knowledge about what can be rapidly changing situations.  Information from these sources, including citizens and other observers not in positions of authority, can be useful to first responders and to authorities coordinating help and assistance.  Relying on this information, however, can present problems, as some of the information is unverified and can be misleading.  This project collected 11 million tweets (very short messages using the Twitter service) immediately after the bombing at the Boston Marathon on April 15, 2013.  Our acquisition method had gaps at times, and we later acquired over 20 million tweets from a commercial service for the same time period to assure that we had a complete collection.  Many of these tweets were "retweets" in which the original message was repeatedly forwarded, sometimes with additional comments. Our initial goals were to understand if the tweets could provide reliable information in time to be useful to responders and to civic authorities.  We expected some of these messages to be unverified (they would be "rumors") and that many of these would prove to be false.  We wanted to see if "the crowd," which could quickly spread both information and misinformation, would serve to correct misinformation.  We examined several rumors and focused our study on the spread of misinformation.  Some of the rumors were easily seen as false.  For example, someone tweeted that an 8-year old girl running in the marathon had been killed.  This tweet was retweeted thousands of times by people who didnÆt reflect on its obvious inaccuracy (8 year olds donÆt run in the marathon).  Interestingly, when someone added an image of a young girl with a runnerÆs bib that clearly showed she was in a "5 K" run, rather than sparking a correction, the rumor began to spread even faster,  The project yielded several results that have significance both for other researchers and for policy and decision makers&mdash;for those who continue research aimed at understanding the spread of information and rumors and for authorities and crisis responders.  One finding verifies the value of collecting contemporaneous social media data, even if it is incomplete.  The "archived" set of data used in the project was missing messages that had been deleted.  Using such data for research can give a misleading picture of the speed and reach of misinformation and the processes by which it spreads.  Authorities and crisis responders will benefit from our observations that rumors, including false information, can spread rapidly and widely&mdash;they can become "viral."  In our study, the "corrections" to false rumors occurred at a much lower rate and were forwarded (retweeted) much less often&mdash;there was not a corresponding viral behavior to the corrections.  Moreover, retweets of the false rumor continued even after corrections were posted, and this was true for each instance of misinformation.  The project results provide support for the notion that further work is needed to understand the propagation of misinformation in crises so that the full potential of social media can be realized in such situations.  Additional work beyond this project is continuing.             Last Modified: 08/17/2015       Submitted by: Robert M Mason]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
