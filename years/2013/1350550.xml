<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: More than Words: Advancing Prosodic Analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2014</AwardEffectiveDate>
<AwardExpirationDate>02/28/2017</AwardExpirationDate>
<AwardTotalIntnAmount>507568.00</AwardTotalIntnAmount>
<AwardAmount>37741</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Prosody is an essential component of human speech. Whereas the words are "what is said", prosody is "how it is said".  A wealth of information is communicated via prosody including information about a speaker's intent and state (speaking-style and emotion).  To advance the capabilities of machines to understand human speech, this CAREER project develops new representations of prosody and applies them to a variety of spoken language processing tasks:  word recognition, speaking-style recognition, dialog-act classification and speaker identification.  This project employs and advances semi-supervised and unsupervised representation learning techniques to characterize prosody.  This project also investigates prosody across multiple languages.  Speakers of multiple languages contribute speech and annotate some basic prosodic phenomena (phrasing and prominence).  The overarching goal is to identify a compact and universal representation of prosody that will be employed effectively in spoken language processing tasks across languages.  Scientific results, representations and tools for extraction will be made open-source as will the collected, annotated multi-lingual data.&lt;br/&gt;&lt;br/&gt;Speech recognition is being integrated into our lives through mobile devices and spoken dialog systems.  The next great hurdle in the ability to communicate with machines via speech is understanding prosody.  Taking prosody into account will result in machines understanding humans better; conversely, automatically generating adequate prosody to convey intent will allow machines to sound more human.  Both types of improvement are sorely needed as automated conversation agents and robots are starting to become a part of our everyday lives.  Finally, this project implements an innovative and challenging education plan that is well-integrated with its research.  It includes curricula modules on prosodic analysis and representation learning to be widely disseminated.  Moreover, undergraduate students who provide and annotate speech samples for the project will get a hands-on introduction to computer science research, and will be compensated in part with tuition waivers for introductory courses in computer science.</AbstractNarration>
<MinAmdLetterDate>03/04/2014</MinAmdLetterDate>
<MaxAmdLetterDate>02/06/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1350550</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Rosenberg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew Rosenberg</PI_FULL_NAME>
<EmailAddress>Andrew@cs.qc.cuny.edu</EmailAddress>
<PI_PHON>7189975400</PI_PHON>
<NSF_ID>000568222</NSF_ID>
<StartDate>03/04/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>CUNY Queens College</Name>
<CityName>Flushing</CityName>
<ZipCode>113671575</ZipCode>
<PhoneNumber>7189975400</PhoneNumber>
<StreetAddress>65 30 Kissena Blvd</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>619346146</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073268849</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[CUNY Queens College]]></Name>
<CityName>Queens</CityName>
<StateCode>NY</StateCode>
<ZipCode>113671575</ZipCode>
<StreetAddress><![CDATA[65-30 Kissena Blvd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~37740</FUND_OBLG>
<FUND_OBLG>2015~0</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-d3a0f7e7-a79f-b201-c4a9-ddc70ecdc885"> <p dir="ltr"><span>Prosody (or more colloquially &ldquo;intonation&rdquo;) has a broad and significant impact on spoken language. &nbsp;The manner in which words are spoken can impact interpretation in dramatic and subtle ways. Questions are indicated via prosody; consider &ldquo;John likes Mary.&rdquo; vs. &ldquo;John likes Mary?!&rdquo;. &nbsp;Focus is communicated prosodically as well; consider &ldquo;I like GREEN apples (not red ones)&rdquo; vs. &ldquo;I like green APPLES (not green grapes)&rdquo;. &nbsp;The goal of this project was to derive compact, consistent and universal representations of prosody, that can be used in a variety of spoken language processing tasks. &nbsp;</span></p> <p dir="ltr"><span>An important and timely aspect of this project was the application of novel, and rapidly changing deep learning approaches to prosodic analysis. &nbsp;To this end we demonstrated the efficacy of recurrent neural networks (RNNs) to detect and classify prosodic events. &nbsp;This project explored and developed two novel representations of prosodic information -- one clustering legendre polynomial coefficients as a contour representation, and a second using frechet distance as a pairwise measure of contour similarity. &nbsp;This project contributed to the development and maintenance of AuToBI, and open source tool for prosodic annotation.</span></p> <p dir="ltr"><span>This project was cut short, as the PI left academia for industry. This left efforts in collecting new non-native speech data, efforts cross-lingual modeling and representation learning, and applications of prosodic information unrealized. &nbsp;While the work and goals continue in various related forms, the project itself has ended.</span></p> <div><span><br /></span></div> </span></p> <p>&nbsp;</p><br> <p>            Last Modified: 06/14/2017<br>      Modified by: Andrew&nbsp;Rosenberg</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Prosody (or more colloquially "intonation") has a broad and significant impact on spoken language.  The manner in which words are spoken can impact interpretation in dramatic and subtle ways. Questions are indicated via prosody; consider "John likes Mary." vs. "John likes Mary?!".  Focus is communicated prosodically as well; consider "I like GREEN apples (not red ones)" vs. "I like green APPLES (not green grapes)".  The goal of this project was to derive compact, consistent and universal representations of prosody, that can be used in a variety of spoken language processing tasks.   An important and timely aspect of this project was the application of novel, and rapidly changing deep learning approaches to prosodic analysis.  To this end we demonstrated the efficacy of recurrent neural networks (RNNs) to detect and classify prosodic events.  This project explored and developed two novel representations of prosodic information -- one clustering legendre polynomial coefficients as a contour representation, and a second using frechet distance as a pairwise measure of contour similarity.  This project contributed to the development and maintenance of AuToBI, and open source tool for prosodic annotation. This project was cut short, as the PI left academia for industry. This left efforts in collecting new non-native speech data, efforts cross-lingual modeling and representation learning, and applications of prosodic information unrealized.  While the work and goals continue in various related forms, the project itself has ended.             Last Modified: 06/14/2017       Submitted by: Andrew Rosenberg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
