<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: EAGER: Automatically Building Test Collections Using Implicit Relevance Signals from the Web</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>103233.00</AwardTotalIntnAmount>
<AwardAmount>103233</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Helping users find relevant information is undeniably an important problem vital to the functioning of today's information-based societies.  It is therefore no surprise that millions of people worldwide make use of search engine technologies each and every day. Although existing search technologies work well, there is still considerable room for improvement. Search engine innovation is driven by the ability to rapidly, and repeatedly, measure the quality of the results produced by a given system.  This type of measurement typically requires some form of human input. For example, a human expert may be hired to assess the relevance of search results, or the search engine may log user interactions, such as the queries entered and the results clicked. After a sufficiently large amount of data has been collected, it can then be used to accurately measure search engine quality. It can also be used to improve the quality of existing search engines via a process known as "tuning" or "training". However, gathering large amounts of this information typically requires a significant amount of human effort or computational resources. Therefore, sustained innovation is only possible at a very steep cost.&lt;br/&gt;&lt;br/&gt;Techniques for constructing large information retrieval test collections that require no human effort are the primary focus of this research study. Rather than relying on human-curated information, implicit relevance signals from the Web are mined to automatically construct large, reusable test collections for a variety of search tasks, including Web search, news search, and enterprise search.  The observation that the Web contains a large number of implicit relevance signals is the starting point of the research. The simplest example of an implicit relevance signal is the hyperlink, which can be interpreted as a signal acknowledging the relevance of the target page by the source author. The hypothesis that such implicit relevance signals can be effectively mined and aggregated in a completely unsupervised manner to create test collections without any human effort is investigated in this research.  Automatically generated test collections are evaluated in two different ways. First, the test collections are evaluated according to their ability to accurately measure the quality of search systems compared to human-generated test collections. Second, the quality of search engines tuned using the automated test collections are compared against engines tuned using manual test collections.&lt;br/&gt;&lt;br/&gt;The broader impact of this project is derived from automatically constructed test collections that are freely distributed to the broader research community. Advances in search engine technologies are expected as the result of increased availability of training data to systematically evaluate and tune search engines, both in industrial and academic settings. Additional broader impact is expected from the integration of research and education at both the graduate and undergraduate levels and from engaging women and underrepresented students through various outreach programs.</AbstractNarration>
<MinAmdLetterDate>01/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>01/16/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1304939</AwardID>
<Investigator>
<FirstName>Eduard</FirstName>
<LastName>Hovy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Eduard Hovy</PI_FULL_NAME>
<EmailAddress>hovy@cs.cmu.edu</EmailAddress>
<PI_PHON>4122686592</PI_PHON>
<NSF_ID>000624328</NSF_ID>
<StartDate>01/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2011~103233</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Test collections are the primary drivers of progress in Natural Language Processing (NLP) research and development challenges (including information retrieval, machine translation, information extraction, and question answering). They provide a yardstick for assessing the effectiveness of ranking functions and other tasks in an automatic, rapid, and repeatable fashion, and serve as training data for learning to optimize new techniques. However, manual construction of test collections tends to be slow, labor-intensive, and expensive. This project was originally conceived to examine the feasibility of constructing Web-based test collections in a completely unsupervised manner given only a large Web corpus as input.&nbsp; During the course of research, instead of automatically constructing pseudo-test collections, we addressed two core subproblems that impede progress.&nbsp; First, we focused on rapid ranking of alternatives using Random Walks, in order to more effectively filter out poor candidates as seed documents for the next round of test collection construction after the initial retrieval.&nbsp; Second we focused on enhancing existing social networking methods for detecting communities in highly-connected networks, by considering not only connectivity but also topic of relevance for each node.&nbsp; This enables algorithms that construct (pseudo-)test collections to ensure coverage of relevant topics and also to prevent imbalance or overrepresentation of certain groupings compared to others.&nbsp; &nbsp;For both sets of algorithms we adopted relevant methods from Physics and Mathematics and reformulated and implemented them to be relevant to and of use for NLP challenges.&nbsp; We believe this is a valuable contribution especially for people studying web search and related document ranking problems.&nbsp;</p><br> <p>            Last Modified: 10/11/2017<br>      Modified by: Eduard&nbsp;H&nbsp;Hovy</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Test collections are the primary drivers of progress in Natural Language Processing (NLP) research and development challenges (including information retrieval, machine translation, information extraction, and question answering). They provide a yardstick for assessing the effectiveness of ranking functions and other tasks in an automatic, rapid, and repeatable fashion, and serve as training data for learning to optimize new techniques. However, manual construction of test collections tends to be slow, labor-intensive, and expensive. This project was originally conceived to examine the feasibility of constructing Web-based test collections in a completely unsupervised manner given only a large Web corpus as input.  During the course of research, instead of automatically constructing pseudo-test collections, we addressed two core subproblems that impede progress.  First, we focused on rapid ranking of alternatives using Random Walks, in order to more effectively filter out poor candidates as seed documents for the next round of test collection construction after the initial retrieval.  Second we focused on enhancing existing social networking methods for detecting communities in highly-connected networks, by considering not only connectivity but also topic of relevance for each node.  This enables algorithms that construct (pseudo-)test collections to ensure coverage of relevant topics and also to prevent imbalance or overrepresentation of certain groupings compared to others.   For both sets of algorithms we adopted relevant methods from Physics and Mathematics and reformulated and implemented them to be relevant to and of use for NLP challenges.  We believe this is a valuable contribution especially for people studying web search and related document ranking problems.        Last Modified: 10/11/2017       Submitted by: Eduard H Hovy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
