<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: SHF: SMALL: Efficient, Low-Latency Networked Storage</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>From key-value stores to distributed file systems to distributed &lt;br/&gt;databases, networked storage underpins modern Internet services. &lt;br/&gt;Networked storage allows programmers to separate logic and data, enables &lt;br/&gt;high throughput scale out, and takes advantage of increasingly fast &lt;br/&gt;datacenter networks.  However, in the big data era, networked storage &lt;br/&gt;faces a new challenge: The amount of data accessed per user request is &lt;br/&gt;growing rapidly; outpacing processor speeds and DRAM capacity. &lt;br/&gt;Increasingly, user-perceived response times are dominated by the slowest &lt;br/&gt;storage accesses, i.e., the 99th percentile tails.  Networked storage is &lt;br/&gt;notorious for fat tailed response times.&lt;br/&gt;&lt;br/&gt;We are developing networked storage systems that are 1) always fast and 2) &lt;br/&gt;cost efficient.  A key approach is to understand and selectively use &lt;br/&gt;replication for predictability (or cloning).  In this approach, clients &lt;br/&gt;issue redundant storage accesses against independent hardware resources. &lt;br/&gt;The first to respond provides the result.  Replication for predictability &lt;br/&gt;reduces client-perceived variability, leading to always fast response &lt;br/&gt;times.  Our implementations are especially cost effective at scale.  To &lt;br/&gt;lower costs, we study the root causes of slow response times, saving &lt;br/&gt;resources by focusing on common causes.  We also trade quality---e.g., &lt;br/&gt;slightly degraded search engine results--- for lower hardware costs when &lt;br/&gt;appropriate.  For broader impact, the PI will work to transfer the &lt;br/&gt;technology to national and local companies.</AbstractNarration>
<MinAmdLetterDate>07/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/29/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320071</AwardID>
<Investigator>
<FirstName>Christopher</FirstName>
<LastName>Stewart</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christopher Stewart</PI_FULL_NAME>
<EmailAddress>cstewart@cse.ohio-state.edu</EmailAddress>
<PI_PHON>5857197769</PI_PHON>
<NSF_ID>000534897</NSF_ID>
<StartDate>07/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101277</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~400000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Networked storage systems allow computer programs to run on one server even though their data is stored on another. These programs access data by sending messages over the network. In datacenters, the time to send a message between servers has declined as 10GbE and optical switches have become common.&nbsp; It is now faster to use networked storage to access data in main memory stored on another server than to access a local disk.<br />Further, well designed networked stores can scale out, i.e., they can increase throughput by simply adding servers.</p> <p>This research studied networked storage systems for Internet services, i.e., computer programs that receive requests from end users, process data related to the request and return results with fast response time.&nbsp; During the course of this work, the structure of Internet services changed.&nbsp; Older services that performed a 3-5 database accesses per request gave way to modern services that require hundreds or thousands of data lookups per request.&nbsp; Why do modern Internet services access so much data?&nbsp; For starters, modern services that are qualitatively similar to older services have larger datasets now, e.g., consider growth of a search engine index.&nbsp; Second, modern services execute complicated data mining and machine learning operations, e.g., consider a recommendation engine for e-commerce products.&nbsp; Finally, modern services use data that is often noisy and redundant, inflating data accesses required for a dependable result.&nbsp;&nbsp;</p> <p><br /><strong>The intellectual contributions of this research included:</strong></p> <p>+ The paper titled&nbsp;<em>Zoolander: Efficiently Meeting Very Strict, Low-Latency SLOs</em>&nbsp;introduced an analytic model on replication for predictability (a.ka. redundancy).&nbsp; It used a probabilistic approach--- comparable to the famous birthday problem--- to estimate processing time for&nbsp;<em>k</em>&nbsp;networked storage requests.&nbsp; When paired with queuing models, this approach provided accurate predictions on the effects of redundancy on response time.&nbsp; Managing redundancy is now a hot topic in computer systems research.&nbsp; Further, this contribution was accessible.&nbsp; Questions on modeling replication for predictibility have been added to undergraduate and graduate architecture courses.</p> <p>+ The paper titled&nbsp;<em>Obtaining and Managing Answer Quality for Online Data-Intensive Services</em>&nbsp;showed that operating system software can capture and manage answer quality without modifying hosted Internet services.&nbsp; For example, a cloud infrastructure provider can use our techniques to throttle data accesses per query without degrading results.&nbsp; A key result showed that a good implementation in the operating system could achieve throughput comparable to an implementation where the service is modified.&nbsp;&nbsp;</p> <p>&nbsp;+ The paper titled&nbsp;<em>Adaptive Power Profiling for Many-Core HPC Architectures</em>&nbsp;showed that power consumption with 1 active core provides predictive information on power consumptions as active cores are added.&nbsp; A short profile of 1-2% of the workload combined with data on 1-core power usage accurately characterizes power usage.</p> <p>&nbsp;</p> <p><strong>The broader impacts achieved by this research included:</strong></p> <p>+&nbsp; Dr. Jaimie Kelley and Dr. Aniket Chakrabarti worked on this project during their PhD studies.&nbsp; Dr. Kelley's first job is assistant professor at Denison University.&nbsp; Dr. Chakrabarti's first job is applied scientist at Microsoft AI &amp; Research.&nbsp; 4 Masters and Undergraduate theses were derived from project.</p> <p>+&nbsp; Data Management in the Cloud is a new course taught at The Ohio State University.&nbsp; It is required for Data Analytics majors.&nbsp; PI Stewart taught the initial offering and worked with his colleagues to ensure that principles for networked storage systems were included.</p> <p>+&nbsp; We created a 1-hour workshop to showcase our research.&nbsp; The workshop culminated with a demo: A competition between workshop attendees and the OpenEphyra question-answer system with adaptive answer quality.&nbsp; We presented this workshop to over 150 people.&nbsp; Most were 7-8th graders.&nbsp; The workshop helped to motivate Buck-I-Code, a weekend coding workshop for Columbus-area girls.&nbsp; Buck-I-Code is now in its 5th year.</p> <p>+&nbsp; We developed a&nbsp;map-reduce platform based on the open-source BashReduce system that was used by Nationwide Children's Hospital.&nbsp; The platform subsampled genetic data to improve running time, i.e., it traded answer quality for performance.</p><br> <p>            Last Modified: 11/13/2017<br>      Modified by: Christopher&nbsp;Stewart</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Networked storage systems allow computer programs to run on one server even though their data is stored on another. These programs access data by sending messages over the network. In datacenters, the time to send a message between servers has declined as 10GbE and optical switches have become common.  It is now faster to use networked storage to access data in main memory stored on another server than to access a local disk. Further, well designed networked stores can scale out, i.e., they can increase throughput by simply adding servers.  This research studied networked storage systems for Internet services, i.e., computer programs that receive requests from end users, process data related to the request and return results with fast response time.  During the course of this work, the structure of Internet services changed.  Older services that performed a 3-5 database accesses per request gave way to modern services that require hundreds or thousands of data lookups per request.  Why do modern Internet services access so much data?  For starters, modern services that are qualitatively similar to older services have larger datasets now, e.g., consider growth of a search engine index.  Second, modern services execute complicated data mining and machine learning operations, e.g., consider a recommendation engine for e-commerce products.  Finally, modern services use data that is often noisy and redundant, inflating data accesses required for a dependable result.     The intellectual contributions of this research included:  + The paper titled Zoolander: Efficiently Meeting Very Strict, Low-Latency SLOs introduced an analytic model on replication for predictability (a.ka. redundancy).  It used a probabilistic approach--- comparable to the famous birthday problem--- to estimate processing time for k networked storage requests.  When paired with queuing models, this approach provided accurate predictions on the effects of redundancy on response time.  Managing redundancy is now a hot topic in computer systems research.  Further, this contribution was accessible.  Questions on modeling replication for predictibility have been added to undergraduate and graduate architecture courses.  + The paper titled Obtaining and Managing Answer Quality for Online Data-Intensive Services showed that operating system software can capture and manage answer quality without modifying hosted Internet services.  For example, a cloud infrastructure provider can use our techniques to throttle data accesses per query without degrading results.  A key result showed that a good implementation in the operating system could achieve throughput comparable to an implementation where the service is modified.     + The paper titled Adaptive Power Profiling for Many-Core HPC Architectures showed that power consumption with 1 active core provides predictive information on power consumptions as active cores are added.  A short profile of 1-2% of the workload combined with data on 1-core power usage accurately characterizes power usage.     The broader impacts achieved by this research included:  +  Dr. Jaimie Kelley and Dr. Aniket Chakrabarti worked on this project during their PhD studies.  Dr. Kelley's first job is assistant professor at Denison University.  Dr. Chakrabarti's first job is applied scientist at Microsoft AI &amp; Research.  4 Masters and Undergraduate theses were derived from project.  +  Data Management in the Cloud is a new course taught at The Ohio State University.  It is required for Data Analytics majors.  PI Stewart taught the initial offering and worked with his colleagues to ensure that principles for networked storage systems were included.  +  We created a 1-hour workshop to showcase our research.  The workshop culminated with a demo: A competition between workshop attendees and the OpenEphyra question-answer system with adaptive answer quality.  We presented this workshop to over 150 people.  Most were 7-8th graders.  The workshop helped to motivate Buck-I-Code, a weekend coding workshop for Columbus-area girls.  Buck-I-Code is now in its 5th year.  +  We developed a map-reduce platform based on the open-source BashReduce system that was used by Nationwide Children's Hospital.  The platform subsampled genetic data to improve running time, i.e., it traded answer quality for performance.       Last Modified: 11/13/2017       Submitted by: Christopher Stewart]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
