<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Large: Collaborative Research: Fast and Accurate Infrastructure Modeling and Inspection with Low-Flying Robots</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>1988750.00</AwardTotalIntnAmount>
<AwardAmount>2012750</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The goal of this project is to transform the efficiency, fidelity, and safety of current critical infrastructure inspection methods by combining human judgment with machine intelligence through the development of an autonomous robotic inspection assistant. The proposed work utilizes small aerial robots, coupled with three-dimensional imaging and the state-of-the-art in planning, modeling, and analysis to develop safe and efficient, high-precision assessment of structures. The key themes of the proposed work are: (1) rapid infrastructure modeling and analysis of large complex structures via a small autonomous aerial robot with 3D mapping capabilities; (2) immersive inspection and structural assessment to combine shape and appearance into an integrated representation amenable to structural health evaluation by an inspector; and (3) adaptive aerial vehicle motion plans that seek to learn from the experience of human inspectors and facilitate as autonomous inspection assistants. The proposed work is exploring the role of humans in the entire cycle from deployment of flying robots to registering data to the assessment.  This project brings together members of participating communities and is developing curriculum to engage undergraduate and graduate students from robotics and civil engineering in the proposed research.</AbstractNarration>
<MinAmdLetterDate>09/04/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/05/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1328930</AwardID>
<Investigator>
<FirstName>Sanjiv</FirstName>
<LastName>Singh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sanjiv Singh</PI_FULL_NAME>
<EmailAddress>ssingh@cmu.edu</EmailAddress>
<PI_PHON>4122686577</PI_PHON>
<NSF_ID>000418992</NSF_ID>
<StartDate>09/04/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Burcu</FirstName>
<LastName>Akinci</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Burcu Akinci</PI_FULL_NAME>
<EmailAddress>bakinci@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122682959</PI_PHON>
<NSF_ID>000486800</NSF_ID>
<StartDate>09/04/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Huber</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Huber</PI_FULL_NAME>
<EmailAddress>dhuber@cs.cmu.edu</EmailAddress>
<PI_PHON>4122682991</PI_PHON>
<NSF_ID>000357502</NSF_ID>
<StartDate>09/04/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sebastian</FirstName>
<LastName>Scherer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sebastian Scherer</PI_FULL_NAME>
<EmailAddress>basti@andrew.cmu.edu</EmailAddress>
<PI_PHON>4125899581</PI_PHON>
<NSF_ID>000614425</NSF_ID>
<StartDate>09/04/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~639146</FUND_OBLG>
<FUND_OBLG>2014~680451</FUND_OBLG>
<FUND_OBLG>2015~677153</FUND_OBLG>
<FUND_OBLG>2016~8000</FUND_OBLG>
<FUND_OBLG>2017~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of the ARIA project was to transform the efficiency, fidelity, and safety of current critical infrastructure inspection methods by combining human judgment with machine intelligence through the development of an autonomous robotic inspection assistant. A small aerial robot (micro air vehicle, or MAV), coupled with three-dimensional imaging and the state-of-the-art in planning, modeling, and analysis, provides safe and efficient, high-precision assessment of structures. &nbsp;</p> <p><br />The project was comprised of three key objectives: (1) Rapid infrastructure modeling and analysis of large complex structures via a small autonomous aerial robot with 3D mapping capabilities; &nbsp;(2) Immersive inspection and structural assessment to combine shape and appearance into an integrated representation amenable to structural health evaluation by an inspector; and (3) Adaptive aerial vehicle motion plans that seek to learn from the experience of human inspectors and facilitate as autonomous inspection assistants. The first theme is further sub-divided into several components: robust state estimation, mapping, knowledge-based semantic modeling, visual analysis and inspection, and structural modeling and assessment.<br /><br />In the project we are able to demonstrate significant progress in furthering the robot autonomy, GPS-denied state estimation, semantic 3D segmentation, structural analysis, and assesment of structures. Additionally, we engaged with stake holders to educate on the art of possible and gather feedback on requirements. The following types of approaches were developed:<br />- robust plane segmentation algorithms<br />- visual damage inspection methods<br />- 3D point cloud to structure segmentation methods<br />- automatic finite-element meshing methods<br />- immersive inspection visualization and interaction approaches<br />- automatic coverage planning algorithms<br />- localization and mapping algorithms that do not require GPS<br />- disturbance-aware motion planning</p> <p><br />The methods were integrated and tested on a custom robot equipped with a spinning LiDAR scanner and cameras in several experiments on bridges. The largest bridge scanned was the Delaware Memorial bridge. Live demonstrations were performed with several stakeholders and the results of our research were shared annually with an advisory board and during regular open house events.</p> <p><br />The GPS-denied mapping was commercialized into a separate spin-off company (Kaarta Inc.). Several of the algorithms developed in this project have the potential to have a larger impact on the civil and construction industry by making comprehensive 3D modelling accessible in a large set of environments. We have been in conversations with multiple partners on commercializing the products generated in the project. The algorithms developed have advanced the state of the art in terms of flying robots, semantic segmentation, structural modeling, and inspection.</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/05/2018<br>      Modified by: Sebastian&nbsp;Scherer</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of the ARIA project was to transform the efficiency, fidelity, and safety of current critical infrastructure inspection methods by combining human judgment with machine intelligence through the development of an autonomous robotic inspection assistant. A small aerial robot (micro air vehicle, or MAV), coupled with three-dimensional imaging and the state-of-the-art in planning, modeling, and analysis, provides safe and efficient, high-precision assessment of structures.     The project was comprised of three key objectives: (1) Rapid infrastructure modeling and analysis of large complex structures via a small autonomous aerial robot with 3D mapping capabilities;  (2) Immersive inspection and structural assessment to combine shape and appearance into an integrated representation amenable to structural health evaluation by an inspector; and (3) Adaptive aerial vehicle motion plans that seek to learn from the experience of human inspectors and facilitate as autonomous inspection assistants. The first theme is further sub-divided into several components: robust state estimation, mapping, knowledge-based semantic modeling, visual analysis and inspection, and structural modeling and assessment.  In the project we are able to demonstrate significant progress in furthering the robot autonomy, GPS-denied state estimation, semantic 3D segmentation, structural analysis, and assesment of structures. Additionally, we engaged with stake holders to educate on the art of possible and gather feedback on requirements. The following types of approaches were developed: - robust plane segmentation algorithms - visual damage inspection methods - 3D point cloud to structure segmentation methods - automatic finite-element meshing methods - immersive inspection visualization and interaction approaches - automatic coverage planning algorithms - localization and mapping algorithms that do not require GPS - disturbance-aware motion planning   The methods were integrated and tested on a custom robot equipped with a spinning LiDAR scanner and cameras in several experiments on bridges. The largest bridge scanned was the Delaware Memorial bridge. Live demonstrations were performed with several stakeholders and the results of our research were shared annually with an advisory board and during regular open house events.   The GPS-denied mapping was commercialized into a separate spin-off company (Kaarta Inc.). Several of the algorithms developed in this project have the potential to have a larger impact on the civil and construction industry by making comprehensive 3D modelling accessible in a large set of environments. We have been in conversations with multiple partners on commercializing the products generated in the project. The algorithms developed have advanced the state of the art in terms of flying robots, semantic segmentation, structural modeling, and inspection.          Last Modified: 06/05/2018       Submitted by: Sebastian Scherer]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
