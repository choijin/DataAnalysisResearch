<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Workshop on High-Level Programming Models for Parallelism</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2013</AwardEffectiveDate>
<AwardExpirationDate>04/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>81302.00</AwardTotalIntnAmount>
<AwardAmount>81302</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anindya Banerjee</SignBlockName>
<PO_EMAI>abanerje@nsf.gov</PO_EMAI>
<PO_PHON>7032927885</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The past decade has witnessed a sea change in the way that computing systems are designed, programmed, implemented, and evaluated.  The advent of multicore technologies has fundamentally reshaped the long-standing contract between hardware and software - no longer can we simply rely on improvements in clock speeds to have our programs run faster. Instead, the burden for improvements in program performance now falls squarely on software and algorithms. Devising new techniques to efficiently and safely exploit multiple cores is the central question facing language designers, compiler writers, and system architects.&lt;br/&gt;&lt;br/&gt;To help address these challenges, this NSF sponsored workshop will identify future research directions related to High-Level Programming Models for Parallelism, and the transition of such research to industrial practice.  The workshop will bring together researchers from academia, industry, and government research labs working in the area of parallelism, including algorithms, architecture, language design and implementation, and runtime systems. The workshop will identify primary challenges in the field, both foundational and infrastructural, and will address the transition of ideas from research to practice.</AbstractNarration>
<MinAmdLetterDate>04/17/2013</MinAmdLetterDate>
<MaxAmdLetterDate>04/17/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1339507</AwardID>
<Investigator>
<FirstName>Jens</FirstName>
<LastName>Palsberg</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jens Palsberg</PI_FULL_NAME>
<EmailAddress>palsberg@ucla.edu</EmailAddress>
<PI_PHON>3108256320</PI_PHON>
<NSF_ID>000105676</NSF_ID>
<StartDate>04/17/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Suresh</FirstName>
<LastName>Jagannathan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Suresh Jagannathan</PI_FULL_NAME>
<EmailAddress>suresh@cs.purdue.edu</EmailAddress>
<PI_PHON>7654940971</PI_PHON>
<NSF_ID>000181308</NSF_ID>
<StartDate>04/17/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA Computer Science]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951596</ZipCode>
<StreetAddress><![CDATA[420 Westwood Plaza, 4732 BH]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramElement>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~81302</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The past decade has witnessed a sea change in the way computing systems are designed, programmed, implemented, and evaluated. The advent of multi-core technologies has fundamentally reshaped the long-standing contract between hardware and software - no longer can we simply rely on improvements in clock speeds to have our programs run faster. Instead, the burden for improvements in program performance now falls squarely on software and algorithms. Devising new techniques to efficiently and safely exploit multiple cores is the central question facing language designers, compiler writers, and system architects today. The shift to heterogeneous many-core systems, for example GPGPU platforms, and cloud-based services further exacerbate these challenges.</p> <p>As a precursor to addressing these tremendously signicant and important issues, this workshop was organized to (a) reflect on successes and failures in programming language-centric approaches to parallelism, with respect to design, specification, and implementation, (b) identify future research directions with special focus on the role of declarative approaches, performance models, and the opportunity to exploit domain specicity, and (c) explore how proposed solutions can migrate from research to industrial practice. &nbsp;The resulting recommendations broadly advocate for new clean-slate designs that enable deeper integration of concurrency into program abstractions and implementations, the importance of deriving performance characteristics from the specication of concurrency abstractions, embracing formal method approaches to reason about concurrency mechanisms and their implementations, and the development of tools to enable re-engineering of legacy code for migration to new languages and DSLs.</p><br> <p>            Last Modified: 03/02/2015<br>      Modified by: Jens&nbsp;Palsberg</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The past decade has witnessed a sea change in the way computing systems are designed, programmed, implemented, and evaluated. The advent of multi-core technologies has fundamentally reshaped the long-standing contract between hardware and software - no longer can we simply rely on improvements in clock speeds to have our programs run faster. Instead, the burden for improvements in program performance now falls squarely on software and algorithms. Devising new techniques to efficiently and safely exploit multiple cores is the central question facing language designers, compiler writers, and system architects today. The shift to heterogeneous many-core systems, for example GPGPU platforms, and cloud-based services further exacerbate these challenges.  As a precursor to addressing these tremendously signicant and important issues, this workshop was organized to (a) reflect on successes and failures in programming language-centric approaches to parallelism, with respect to design, specification, and implementation, (b) identify future research directions with special focus on the role of declarative approaches, performance models, and the opportunity to exploit domain specicity, and (c) explore how proposed solutions can migrate from research to industrial practice.  The resulting recommendations broadly advocate for new clean-slate designs that enable deeper integration of concurrency into program abstractions and implementations, the importance of deriving performance characteristics from the specication of concurrency abstractions, embracing formal method approaches to reason about concurrency mechanisms and their implementations, and the development of tools to enable re-engineering of legacy code for migration to new languages and DSLs.       Last Modified: 03/02/2015       Submitted by: Jens Palsberg]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
