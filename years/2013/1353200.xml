<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Applying Semantic Paradata to Outcomes-aligned Assessment</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2014</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>768000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Glenn H. Larsen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This SBIR Phase II project will result in a cloud-based web application that uses natural language processing to automatically generate online assessment questions for any digital textual material and to align questions with topics and learning outcomes. These questions will be available for instructors to review, edit and use in online quizzes that students can take on desktops, laptops, tablets or smartphones. The application will grade the quizzes and analyze both individual and aggregate results. Instructors can enhance the analysis by tying errors to common student misconceptions. The application will provide instructors with near real-time updates on student learning and provide students with personalized and immediate feedback. The application will maintain a bank of questions that can be customized to an academic unit or institution and that will grow with use. The question bank and data collected by the system will be mined to improve performance over time.  A beta release will be evaluated at multiple universities during Phase II. &lt;br/&gt;&lt;br/&gt;The broader/commercial impact of this work includes its potential to improve instruction for over 21 million American college and university students. Assessments play critical roles in higher education, but it currently takes considerable instructor time and effort to produce, grade and maintain them.  Using the application developed in this Phase II SBIR, instructors will be able to generate and deliver quizzes quickly enough for ad-hoc in-class use and easily enough to integrate frequent practice and diagnostic tests into daily instruction. This will enable instructors to better evaluate students, keep students engaged, and tailor their instruction to student needs. Students will be able to take more practice tests, which evidence shows helps retain and recall class content, and administrators will obtain more data tied directly to student outcomes.  Expected benefits include increased student success rates and richer data that universities and accreditation agencies can analyze to evaluate and improve programs. In addition, this Phase II SBIR will implement, test and improve techniques for automated question generation and outcomes alignment that can be used in other applications.</AbstractNarration>
<MinAmdLetterDate>04/07/2014</MinAmdLetterDate>
<MaxAmdLetterDate>07/23/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1353200</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Robson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert Robson</PI_FULL_NAME>
<EmailAddress>robby.robson@eduworks.com</EmailAddress>
<PI_PHON>5417530844</PI_PHON>
<NSF_ID>000222362</NSF_ID>
<StartDate>04/07/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Eduworks Corporation</Name>
<CityName>Corvallis</CityName>
<ZipCode>973334899</ZipCode>
<PhoneNumber>5417530844</PhoneNumber>
<StreetAddress>400 SW 4th Street</StreetAddress>
<StreetAddress2><![CDATA[STE 110]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>111494303</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>EDUWORKS CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Eduworks Corporation]]></Name>
<CityName>Corvallis</CityName>
<StateCode>OR</StateCode>
<ZipCode>973334875</ZipCode>
<StreetAddress><![CDATA[136 SW Washington Ave, STE 203]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>8031</Code>
<Text>Education Products</Text>
</ProgramReference>
<ProgramReference>
<Code>8240</Code>
<Text>SBIR/STTR CAP</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~755000</FUND_OBLG>
<FUND_OBLG>2015~13000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This research resulted in a quiz production system, now branded as QuizBench, that can generate assessment questions in seconds and quizzes in minutes, saving instructors, trainers, and publishers hours of authoring time. Whereas existing authoring tools require users to formulate and manually input their own questions and answers, users of this application simply drop learning materials onto a drag-and-drop interface (or point to a file or URL) and optionally add targeted learning outcomes. The application analyzes the materials and uses artificial intelligence (AI) to produce assessment questions which users can then select, edit (if desired), and collate into a quiz. Quizzes can be exported for use in a learning management system or taken online via a link generated by the application. When a student takes the quiz via the link, the application immediately grades the quiz, using a second set of AI and text analysis algorithms to evaluate free-form answers. Frequent feedback of this nature that helps check knowledge and reinforce learning.&nbsp;</p> <p>The QuizBench application can produce candidate questions directly from the input materials, suggest the most relevant questions from a question bank, or do both. Users can store previously generated questions and quizzes and can add their own questions to a quiz or to the application's question bank. This enables users to build up a storehouse of questions and question patterns that the application will retrieve based on the content of input materials or associated learning outcomes and that users can edit to create new variations on existing questions.&nbsp;</p> <p><strong>Intellectual Merit:</strong> QuizBench incorporates multiple technical innovations. These range from specialized data structures and user interface elements to the ability to search for questions by comparing them to the contents of a document or web page. The most significant, however, are new computational linguistics and automated question generation methods.</p> <p>Previously available automated question generation algorithms often produced grammatically incorrect questions and focused on transforming single sentences into quiz questions. The results of these algorithms could not be reliably used in a quiz authoring tool. The methods developed under this SBIR take entire documents into consideration when generating questions and include several other improvements that lead to higher quality questions. The types of questions that QuizBench produces directly from text include multiple choice, fill-in-the-blank, and free-form essay questions. For multiple choice questions, the underlying algorithms also produce viable distractors. This advances the state-of-the-art in automated question generation, and many of the methods developed can be used to automate other processes that involve analyzing, understanding, and transforming text in documents.&nbsp;</p> <p>QuizBench also uses input materials and outcomes to search for well-aligned questions in a question bank. As with automated questions generation, the search algorithms analyze the entire content of input materials. Although automatically generated questions are limited to standard question types, more sophisticated questions (e.g. that involve graphs, diagrams, experiments, or complex mathematical equations) can be stored and retrieved from question banks.&nbsp;</p> <p><strong>Broader Impacts:</strong>&nbsp;QuizBench transforms the quiz authoring process from a do-it-yourself process into a "select and edit" process that is supported by AI. The resulting authoring approach is easier and faster and lowers the barrier to providing students with frequent formative assessments, which is known to improve learning.</p> <p>QuizBench suggests questions that are aligned with instructional content and learning outcomes. This has the potential to improve the overall quality of questions and assessments, and by suggesting ready-made questions, QuizBench encourages authors spend more time thinking about the wording and value of each question. In addition, the question bank feature enables untrained authors to start with vetted or professionally produced questions (if such questions are present in the question bank) and, at the very least, to start with with questions that address relevant topics and outcomes. This, too, has the potential to improve quality.</p> <p>The ability to &nbsp;produce questions related to the contents of a document is a basic capability that can be applied to engage readers in online materials, provide ubiquitous knowledge checks, and improve the efficacy of ad hoc learning experiences.&nbsp;It ties in closely with competency-based education and training, and the underlying algorithms and methods can be applied to adjacent fields such as staffing and workforce development. &nbsp;QuizBench is meant to integrate into multiple authoring and instructional workflows and with standard instructional technologies. As such &nbsp;QuizBench can significantly increase the production and use of quality quiz questions and quizzes in education and training.&nbsp;</p> <p style="text-align: left;">&nbsp;</p><br> <p>            Last Modified: 10/01/2016<br>      Modified by: Robert&nbsp;Robson</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This research resulted in a quiz production system, now branded as QuizBench, that can generate assessment questions in seconds and quizzes in minutes, saving instructors, trainers, and publishers hours of authoring time. Whereas existing authoring tools require users to formulate and manually input their own questions and answers, users of this application simply drop learning materials onto a drag-and-drop interface (or point to a file or URL) and optionally add targeted learning outcomes. The application analyzes the materials and uses artificial intelligence (AI) to produce assessment questions which users can then select, edit (if desired), and collate into a quiz. Quizzes can be exported for use in a learning management system or taken online via a link generated by the application. When a student takes the quiz via the link, the application immediately grades the quiz, using a second set of AI and text analysis algorithms to evaluate free-form answers. Frequent feedback of this nature that helps check knowledge and reinforce learning.   The QuizBench application can produce candidate questions directly from the input materials, suggest the most relevant questions from a question bank, or do both. Users can store previously generated questions and quizzes and can add their own questions to a quiz or to the application's question bank. This enables users to build up a storehouse of questions and question patterns that the application will retrieve based on the content of input materials or associated learning outcomes and that users can edit to create new variations on existing questions.   Intellectual Merit: QuizBench incorporates multiple technical innovations. These range from specialized data structures and user interface elements to the ability to search for questions by comparing them to the contents of a document or web page. The most significant, however, are new computational linguistics and automated question generation methods.  Previously available automated question generation algorithms often produced grammatically incorrect questions and focused on transforming single sentences into quiz questions. The results of these algorithms could not be reliably used in a quiz authoring tool. The methods developed under this SBIR take entire documents into consideration when generating questions and include several other improvements that lead to higher quality questions. The types of questions that QuizBench produces directly from text include multiple choice, fill-in-the-blank, and free-form essay questions. For multiple choice questions, the underlying algorithms also produce viable distractors. This advances the state-of-the-art in automated question generation, and many of the methods developed can be used to automate other processes that involve analyzing, understanding, and transforming text in documents.   QuizBench also uses input materials and outcomes to search for well-aligned questions in a question bank. As with automated questions generation, the search algorithms analyze the entire content of input materials. Although automatically generated questions are limited to standard question types, more sophisticated questions (e.g. that involve graphs, diagrams, experiments, or complex mathematical equations) can be stored and retrieved from question banks.   Broader Impacts: QuizBench transforms the quiz authoring process from a do-it-yourself process into a "select and edit" process that is supported by AI. The resulting authoring approach is easier and faster and lowers the barrier to providing students with frequent formative assessments, which is known to improve learning.  QuizBench suggests questions that are aligned with instructional content and learning outcomes. This has the potential to improve the overall quality of questions and assessments, and by suggesting ready-made questions, QuizBench encourages authors spend more time thinking about the wording and value of each question. In addition, the question bank feature enables untrained authors to start with vetted or professionally produced questions (if such questions are present in the question bank) and, at the very least, to start with with questions that address relevant topics and outcomes. This, too, has the potential to improve quality.  The ability to  produce questions related to the contents of a document is a basic capability that can be applied to engage readers in online materials, provide ubiquitous knowledge checks, and improve the efficacy of ad hoc learning experiences. It ties in closely with competency-based education and training, and the underlying algorithms and methods can be applied to adjacent fields such as staffing and workforce development.  QuizBench is meant to integrate into multiple authoring and instructional workflows and with standard instructional technologies. As such  QuizBench can significantly increase the production and use of quality quiz questions and quizzes in education and training.          Last Modified: 10/01/2016       Submitted by: Robert Robson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
