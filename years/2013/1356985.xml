<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: Interviewer Voice Characteristics and Data Quality</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2014</AwardEffectiveDate>
<AwardExpirationDate>05/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>15998.00</AwardTotalIntnAmount>
<AwardAmount>15998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
<PO_EMAI>ceavey@nsf.gov</PO_EMAI>
<PO_PHON>7032927269</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Telephone interviews frequently contain socially desirable, socially undesirable, and complex questions that tend to produce problems for respondents.  A speaker may be especially likely to change vocal patterns for these types of questions.  These changes may either directly affect data quality or indirectly affect data quality through the listener's perception of the voice.  As telephone surveys continue to be the primary mode of data collection for many large national studies, it is important to understand how interviewer voices affect data quality.  This study will examine whether interviewer voice characteristics affect data quality in socially desirable, undesirable, and complex survey questions.  Interviewer voices are the primary means of communication to respondents in telephone interviews.  If voice characteristics of interviewers affect data quality, those overseeing interviews may be able to select or train interviewers to modify some of their vocal characteristics with the goal of maximizing data quality.  Moreover, results from this research will be useful for selecting interviewers based on voice characteristics for audio computer-assisted self-interviewing (ACASI), telephone audio-CASI (T-ACASI), and interactive voice response (IVR) systems with the goal of minimizing measurement error.  As a Doctoral Dissertation Research Improvement award, support is provided to enable a promising student to establish a strong, independent research career.&lt;br/&gt;&lt;br/&gt;Specifically, this study has three objectives.  The project will evaluate whether a telephone survey interviewer's objective voice characteristics including speech rate, pitch, intonation, and disfluency are associated with a listener's subjective perception of these voice characteristics and their assessment of five subjective interviewer traits (credibility, confidence, reliability, trustworthiness, and easiness to understand).  The project also will examine whether objective voice characteristics of telephone survey interviewers affect data quality in socially desirable, socially undesirable, and complex questions.  Finally, the project will investigate whether subjective perceptions of an interviewer's voice mediate the relationship between objective voice characteristics and data quality.  The study will objectively measure interviewer's voice characteristics by using the Praat computer software program and will use raters to subjectively evaluate voice characteristics (e.g. pitch and speaking rate) and interviewer traits (e.g. credibility, confidence) on seven-point scales.  Hierarchical logistic regression models will be used to examine the association between the objective and subjective voice characteristics and data quality.  Measures of data quality include item nonresponse for all questions, rounding answers (e.g. 5, 10) for complex and neutral questions, and the directional hypothesis of more/less is better for socially undesirable/desirable questions.</AbstractNarration>
<MinAmdLetterDate>06/11/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1356985</AwardID>
<Investigator>
<FirstName>Kristen</FirstName>
<LastName>Olson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kristen Olson</PI_FULL_NAME>
<EmailAddress>kolson5@unl.edu</EmailAddress>
<PI_PHON>4024726057</PI_PHON>
<NSF_ID>000614500</NSF_ID>
<StartDate>06/11/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Nuttirudee</FirstName>
<LastName>Charoenruk</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nuttirudee Charoenruk</PI_FULL_NAME>
<EmailAddress>nuttirudee5685@huskers.unl.edu</EmailAddress>
<PI_PHON>4024723171</PI_PHON>
<NSF_ID>000651080</NSF_ID>
<StartDate>06/11/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Nebraska-Lincoln</Name>
<CityName>Lincoln</CityName>
<ZipCode>685031435</ZipCode>
<PhoneNumber>4024723171</PhoneNumber>
<StreetAddress>151 Prem S. Paul Research Center</StreetAddress>
<StreetAddress2><![CDATA[2200 Vine St]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<StateCode>NE</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NE01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555456995</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BOARD OF REGENTS OF THE UNIVERSITY OF NEBRASKA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068662618</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Nebraska-Lincoln]]></Name>
<CityName/>
<StateCode>NE</StateCode>
<ZipCode>685880324</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NE01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~15998</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>As an aural mode, interviewer voices play an important part in telephone surveys. Interviewer voices have been shown to play an important role in recruitment of sampled persons (e.g., Benki et al., 2011; Van der Vaart et al., 2005), but the effects on how respondents answer questions are virtually unexplored. If interviewer voice characteristics affect data quality, we will be able to select or train interviewers to modify some of their vocal characteristics with the goal of maximizing data quality.</p> <p>Interviewers receive limited training on vocal characteristics, with a general focus on intonation and speech rate. Interviewers are advised to ask questions with proper phrasing and inflection and to speak at an average rate of two words per second (wps) (Cannell et al., 1981; Guenzel et al., 1983). Pitch and disfluencies may affect respondent perception of interviewers (Apple et al. 1979), and then affect their survey reports. As such, in this study, we examined whether interviewer voice characteristics (pitch, intonation, speech rate, and disfluencies) affect data quality in socially desirable, socially undesirable, and complex questions which frequently asked in telephone survey and tend to produce problems for respondents.</p> <p>Data for this study came from the Work and Leisure Today Survey (NSF SES-1132015). We examined the first turn that interviewers read a survey question (n=4,689). Pitch, intonation, speech rate, and disfluencies are both objectively measured by the Praat program and subjectively evaluated by six coders. Additionally, the coders evaluated five interviewer personality traits (expertise, trustworthiness, reliability, confidence, and easiness to understand) from interviewer voices. Data quality indicators used in this study are item nonresponse, rounded answers, the hypothesis of &ldquo;more/less is better&rdquo; in reports on sensitive or socially desirable items, and five respondent behaviors associated with data quality: the respondent 1) interrupts questions with an answer, 2) expresses uncertainty about a question, 3) requests clarification, 4) gives qualified answers, and 5) gives a response that does not meet the question&rsquo;s objective (Tourangeau et al., 2000).</p> <p>Because listeners might perceive interviewer personality traits from interviewer voices and the perception of these interviewer personality traits may affect data quality, we first evaluated how listeners perceive interviewers&rsquo; personality traits from their voices. Second, we examined whether interviewer voice characteristics are associated with data quality. Finally, we investigated whether subjective perceptions of an interviewer&rsquo;s personality traits mediated the relationship between objective acoustic voice characteristics and data quality. Overall, we found that listeners could perceive interviewers&rsquo; personality traits from their voices. Results in this study suggest that more positively viewed interviewers read questions with higher pitched voices, have moderate intonation (around 40 Hz for male and 60-80 Hz for female), read at a speech rate faster than 2 wps (especially for socially undesirable questions and complex questions), and have fewer disfluencies. Reading a question at the typically recommended speech rate of two words per second leads to negative perceptions of interviewer personality traits.</p> <p>We also found that both objective and subjective voice characteristics affect data quality; however, the effects are inconsistent across data quality indicators. Interviewers obtain better data quality when they read questions with moderate intonation and disfluencies. The voice characteristic with the largest effect on data quality is speech rate. Interviewers obtain better data quality when they read neutral questions at a rate of 2 wps, but read socially undesirable questions more quickly. However, effects of pitch on data qualit...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ As an aural mode, interviewer voices play an important part in telephone surveys. Interviewer voices have been shown to play an important role in recruitment of sampled persons (e.g., Benki et al., 2011; Van der Vaart et al., 2005), but the effects on how respondents answer questions are virtually unexplored. If interviewer voice characteristics affect data quality, we will be able to select or train interviewers to modify some of their vocal characteristics with the goal of maximizing data quality.  Interviewers receive limited training on vocal characteristics, with a general focus on intonation and speech rate. Interviewers are advised to ask questions with proper phrasing and inflection and to speak at an average rate of two words per second (wps) (Cannell et al., 1981; Guenzel et al., 1983). Pitch and disfluencies may affect respondent perception of interviewers (Apple et al. 1979), and then affect their survey reports. As such, in this study, we examined whether interviewer voice characteristics (pitch, intonation, speech rate, and disfluencies) affect data quality in socially desirable, socially undesirable, and complex questions which frequently asked in telephone survey and tend to produce problems for respondents.  Data for this study came from the Work and Leisure Today Survey (NSF SES-1132015). We examined the first turn that interviewers read a survey question (n=4,689). Pitch, intonation, speech rate, and disfluencies are both objectively measured by the Praat program and subjectively evaluated by six coders. Additionally, the coders evaluated five interviewer personality traits (expertise, trustworthiness, reliability, confidence, and easiness to understand) from interviewer voices. Data quality indicators used in this study are item nonresponse, rounded answers, the hypothesis of "more/less is better" in reports on sensitive or socially desirable items, and five respondent behaviors associated with data quality: the respondent 1) interrupts questions with an answer, 2) expresses uncertainty about a question, 3) requests clarification, 4) gives qualified answers, and 5) gives a response that does not meet the questionÆs objective (Tourangeau et al., 2000).  Because listeners might perceive interviewer personality traits from interviewer voices and the perception of these interviewer personality traits may affect data quality, we first evaluated how listeners perceive interviewersÆ personality traits from their voices. Second, we examined whether interviewer voice characteristics are associated with data quality. Finally, we investigated whether subjective perceptions of an interviewerÆs personality traits mediated the relationship between objective acoustic voice characteristics and data quality. Overall, we found that listeners could perceive interviewersÆ personality traits from their voices. Results in this study suggest that more positively viewed interviewers read questions with higher pitched voices, have moderate intonation (around 40 Hz for male and 60-80 Hz for female), read at a speech rate faster than 2 wps (especially for socially undesirable questions and complex questions), and have fewer disfluencies. Reading a question at the typically recommended speech rate of two words per second leads to negative perceptions of interviewer personality traits.  We also found that both objective and subjective voice characteristics affect data quality; however, the effects are inconsistent across data quality indicators. Interviewers obtain better data quality when they read questions with moderate intonation and disfluencies. The voice characteristic with the largest effect on data quality is speech rate. Interviewers obtain better data quality when they read neutral questions at a rate of 2 wps, but read socially undesirable questions more quickly. However, effects of pitch on data quality indicators are inconclusive. Results suggest that interviewers should be trained to read questions with moderate intonat...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
