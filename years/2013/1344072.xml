<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SCH: EXP: Collaborative Research: Privacy-Preserving Framework for Publishing Electronic Healthcare Records</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2014</AwardEffectiveDate>
<AwardExpirationDate>12/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>198000.00</AwardTotalIntnAmount>
<AwardAmount>198000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project builds a novel privacy-preserving framework with both new algorithms and software tools to: 1) evaluate the effectiveness of current identifier-suppression techniques for Electronic Healthcare Record (EHR) data; 2) de-identify and anonymize EHR data to protect personal information without significantly reducing the utility of data for secondary data analysis. The proposed techniques eliminate the violation of privacy through re-identification, and facilitate the secondary usage, sharing, publishing and exchange of healthcare data without the risk of breaching protected health information (PHI). This new privacy-preserving framework injects the ICD-9-CM-aware constraint-based privacy-preserving techniques into EHRs to eliminate the threat of identifying an individual in the secondary use of research data. The proposed technique and development can be readily adapted to other types of healthcare databases in order to ensure privacy and prevent re-identification of published data. The project produces groundbreaking algorithms and tools for identifying privacy leakages and protecting personal privacy information in EHRs to improve healthcare data publishing. New privacy-preserving techniques developed in this project lead towards a new type of healthcare science for EHRs. The project also delivers fundamental advancements to engineering by showing how to integrate biomedical domain knowledge with a computationally advanced quantitative framework for preserving the privacy of published EHRs. HIPAA has established protocols and industry standards to protect the confidentiality of PHI. However, our results demonstrate that, even with regard to health data that meets HIPAA requirements, the risk of re-identification is not completely eliminated. By identifying the security vulnerabilities inherent in the HIPAA standards, our research develops a more rigorous security standard that greatly improves privacy protections by applying state-of-the-art algorithms.&lt;br/&gt; &lt;br/&gt;The developed data privacy-preserving framework has significant implications for the future of US healthcare data publishing and related applications. Specifically, the transition from paper records to EHRs has accelerated significantly since the passage of the HITECH Act of 2009. The Act provides monetary incentives for the "meaningful use" of EHRs. As a result, the quality and quantity of healthcare databases has risen sharply, which has renewed the public's fear of a breach of privacy of their medical information. This research work is innovative and crucial not only for facilitating EHR data publishing, but also for enhancing the development and promotion of EHRs. At the educational front, this project facilitates the development of novel educational tools to construct entirely new courses and laboratory classes for healthcare, data privacy, data mining, and a wide range of applications. As a result, it enhances the current instructional methods for teaching data privacy and data mining, and has compelling biomedical and healthcare applications that can facilitate learning of computational algorithms. This project involves both undergraduate and graduate students in the three participating institutions. The PIs make a strong effort to engage minority graduate and undergraduate students in research activities in order to increase their exposure to cutting-edge research.</AbstractNarration>
<MinAmdLetterDate>09/13/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1344072</AwardID>
<Investigator>
<FirstName>Liam</FirstName>
<LastName>O'Neill</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Liam O'Neill</PI_FULL_NAME>
<EmailAddress>Liam.ONeill@unthsc.edu</EmailAddress>
<PI_PHON>8177350337</PI_PHON>
<NSF_ID>000575622</NSF_ID>
<StartDate>09/13/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Texas Health Science Center at Fort Worth</Name>
<CityName>Fort Worth</CityName>
<ZipCode>761072699</ZipCode>
<PhoneNumber>8177355073</PhoneNumber>
<StreetAddress>3500 Camp Bowie Blvd.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>110091808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH TEXAS HEALTH SCIENCE CENTER AT FORT WORTH</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>110091808</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Texas - HSC]]></Name>
<CityName>Fort Worth</CityName>
<StateCode>TX</StateCode>
<ZipCode>761072699</ZipCode>
<StreetAddress><![CDATA[3500 Camp Bowie Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8061</Code>
<Text>SCH Type I:  EXP</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~198000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp; &nbsp; &nbsp;Our research findings are highly relevant to the current debate over health information privacy. Our research calls into question the efficacy of the anonymization framework employed by HIPAA for protecting patient privacy, specifically the "safe harbor" method - which is conceptually simple and ubiquitously&nbsp; employed. This relies on the conventional wisdom that information can be classified as either "personally identifiable" or "not personally identifiable," even as the former category has no mathematical or statistical definition. We demonstrate that health care organizations can achieve a higher degree of protection of patient confidentiality - beyond the minimum standard that is required by HIPAA - by employing more rigorous methods, such as k-anonymity.&nbsp;</p> <p><span style="white-space: pre;"> </span>We also demonstrate how the risk of re-identification can be estimated by determining the "percent uniqueness" for various combinations of diagnosis and procedure codes.&nbsp;<span> </span>We considered various realistic scenarios of how the publication of such data could lead to breaches of patient privacy. To illustrate the vulnerability of such published data, we calculated the&ldquo;population uniqueness&rdquo; for patients undergoing one or more surgical procedures using data from the State of Texas. We showed that, for a patient selected uniformly at random, the probability that an adversary could match this patient&rsquo;s record to a unique record in the state external database was 42.8% (with standard error &lt; 0.1%). Despite the 42.8% being an unacceptably high level of risk, it underestimates the risk for patients from smaller states or provinces. Based on the findings, we proposed an editorial policy for anesthesia journals that greatly reduces the likelihood of a privacy breach, while supporting the goal of transparency of the research process. Our article was published inthe June, 2016, issue of <em>Anesthesia and Analgesia</em>, and Dr. Liam O'Neill was interviewed for the journal's monthly podcast.&nbsp;</p> <p><span>&nbsp;</span><span style="white-space: pre;"> </span>Another interesting finding from our research is that, contrary to the conventional wisdom that most privacy disclosures happen when a user posts her own information, evenintentionally or inadvertently, on social media, we found that users&rsquo; privacy informationare being revealed by not only their own disclosures but also by the activities of their social ties. To understand the degree of such disclosures and their implications for individual privacy, we launched one of the first systematic efforts to understand the commonalities and distinctions between self- vs. co-disclosure, especially pertaining to different types of private information. Specifically, we conducted a data-driven study that builds upon an innovative measurement for quantifying the extent to which others&rsquo; co-disclosurecould lead to actual privacy harm. The results demonstrate the significant harm caused by co-disclosure and illustrate the interesting differences between the identity elements revealed through self- and co-disclosure.<span> </span>For example, we found through an empirical study on Twitter that a user&rsquo;s date of birth indeed more commonly disclosed by his social ties rather than the user himself. For up to 10 percent of users who disclose the least amount of their own information, the amount of information disclosed by their social ties is actually greater than what they disclose about themselves. These results were presented at the 2017 Dewald Roode Workshop on Information Systems Security Research, and will be published in the<em> Proceedings of the 51st Hawaii International Conference on System Sciences</em>.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/31/2018<br>      Modified by: Liam&nbsp;O'neill</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[      Our research findings are highly relevant to the current debate over health information privacy. Our research calls into question the efficacy of the anonymization framework employed by HIPAA for protecting patient privacy, specifically the "safe harbor" method - which is conceptually simple and ubiquitously  employed. This relies on the conventional wisdom that information can be classified as either "personally identifiable" or "not personally identifiable," even as the former category has no mathematical or statistical definition. We demonstrate that health care organizations can achieve a higher degree of protection of patient confidentiality - beyond the minimum standard that is required by HIPAA - by employing more rigorous methods, such as k-anonymity.    We also demonstrate how the risk of re-identification can be estimated by determining the "percent uniqueness" for various combinations of diagnosis and procedure codes.  We considered various realistic scenarios of how the publication of such data could lead to breaches of patient privacy. To illustrate the vulnerability of such published data, we calculated the"population uniqueness" for patients undergoing one or more surgical procedures using data from the State of Texas. We showed that, for a patient selected uniformly at random, the probability that an adversary could match this patient?s record to a unique record in the state external database was 42.8% (with standard error &lt; 0.1%). Despite the 42.8% being an unacceptably high level of risk, it underestimates the risk for patients from smaller states or provinces. Based on the findings, we proposed an editorial policy for anesthesia journals that greatly reduces the likelihood of a privacy breach, while supporting the goal of transparency of the research process. Our article was published inthe June, 2016, issue of Anesthesia and Analgesia, and Dr. Liam O'Neill was interviewed for the journal's monthly podcast.     Another interesting finding from our research is that, contrary to the conventional wisdom that most privacy disclosures happen when a user posts her own information, evenintentionally or inadvertently, on social media, we found that users? privacy informationare being revealed by not only their own disclosures but also by the activities of their social ties. To understand the degree of such disclosures and their implications for individual privacy, we launched one of the first systematic efforts to understand the commonalities and distinctions between self- vs. co-disclosure, especially pertaining to different types of private information. Specifically, we conducted a data-driven study that builds upon an innovative measurement for quantifying the extent to which others? co-disclosurecould lead to actual privacy harm. The results demonstrate the significant harm caused by co-disclosure and illustrate the interesting differences between the identity elements revealed through self- and co-disclosure. For example, we found through an empirical study on Twitter that a user?s date of birth indeed more commonly disclosed by his social ties rather than the user himself. For up to 10 percent of users who disclose the least amount of their own information, the amount of information disclosed by their social ties is actually greater than what they disclose about themselves. These results were presented at the 2017 Dewald Roode Workshop on Information Systems Security Research, and will be published in the Proceedings of the 51st Hawaii International Conference on System Sciences.                Last Modified: 03/31/2018       Submitted by: Liam O'neill]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
