<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS: Synergy: Collaborative Research: Mutually Stabilized Correction in Physical Demonstration</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>699999.00</AwardTotalIntnAmount>
<AwardAmount>699999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Objective: How much a person should be allowed to interact with a controlled machine?  If that machine is safety critical, and if the computer that oversees its operation is essential to its operation and safety, the answer may be that the person should not be allowed to interfere with its operation at all or very little. Moreover, whether the person is a novice or an expert matters.  &lt;br/&gt;&lt;br/&gt;Intellectual Merit: This research algorithmically resolves the tension between the need for safety and the need for performance, something a person may be much more adept at improving than a machine. Using a combination of techniques from numerical methods, systems theory, machine learning, human-machine interfaces, optimal control, and formal verification, this research will develop a computable notion of trust that allows the embedded system to assess the safety of the instruction a person is providing.  The interface for interacting with a machine matters as well; designing motions for safety-critical systems using a keyboard may be unintuitive and lead to unsafe commands because of its limitations, while other interfaces may be more intuitive but threaten the stability of a system because the person does not understand the needs of the system.  Hence, the person needs to develop trust with the machine over a period of time, and the last part of the research will include evaluating a person's performance by verifying the safety of the instructions the person provides.  As the person becomes better at safe operation, she will be given more authority to control the machine while never putting the system in danger.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  The activities will include outreach, development of public-domain software, experimental coursework including two massive online courses, and technology transfer to rehabilitation. Outreach will include exhibits at the Museum of Science and Industry and working with an inner-city high school. The algorithms to be developed will have immediate impact on projects with the Rehabilitation Institute of Chicago, including assistive devices, stroke assessment, and neuromuscular hand control. Providing a foundation for a science of trust has the potential to transform rehabilitation research.</AbstractNarration>
<MinAmdLetterDate>09/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1329891</AwardID>
<Investigator>
<FirstName>Todd</FirstName>
<LastName>Murphey</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Todd D Murphey</PI_FULL_NAME>
<EmailAddress>t-murphey@northwestern.edu</EmailAddress>
<PI_PHON>3034671041</PI_PHON>
<NSF_ID>000485210</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brenna</FirstName>
<LastName>Argall</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brenna Argall</PI_FULL_NAME>
<EmailAddress>brenna.argall@northwestern.edu</EmailAddress>
<PI_PHON>3122381686</PI_PHON>
<NSF_ID>000602007</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<StreetAddress2><![CDATA[Rubloff 7th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>160079455</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHWESTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005436803</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northwestern University]]></Name>
<CityName>Evanston</CityName>
<StateCode>IL</StateCode>
<ZipCode>602080834</ZipCode>
<StreetAddress><![CDATA[2145 Sheridan Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~699999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The project "CPS: Synergy: Collaborative Research: Mutually Stabilized Correction in Physical Demonstration" (Award 1329891) developed human-in-the-loop (HITL) control methodologies that are real-time, reliable, computable, and verifiable. One way to understand the contributions of the work is to think of a device that needs to keep a person safe while accomplishing a goal, like a driverless car or an exoskeleton.&nbsp; In both cases, automation needs to balance the need to accomplish something (going to the store or walking across a room) against the need to be safe (avoid collisions, stay upright and avoiding tripping).&nbsp; Moreover, the person using the device may know more about some aspects of what needs to be accomplished; some roads may be better than others, stepping around someone on the sidewalk may be easier in one direction than the other.&nbsp; Lastly, the person may understand less in other respects; a person may not see oncoming traffic or may not be paying attention.&nbsp; As a result, the human-machine team needs to take into account both capabilities and limitations of both the human and the machine, leading to a capable system that capitalizes on capabilities and mitigates limitations from both partners. The work focused on formalizing the automated assessment of trust, primarily focusing on the degree to which a computer or automation system should trust a human operator, and integrated that trust into the routine operation of the cyber-physical system.&nbsp;</p> <p>The work developed analytical methods that analyze a person's decisions in real-time, allowing automation to determine whether the person should be given flexibility in actions or should be prevented from engaging in potentially high risk activity.&nbsp; The automation makes this assessment at every moment of execution, leading to algorithms that can provide guarantees on performance and safety. The mathematical analysis of these algorithms also provides stability guarantees for a human-machine team if the task is known.&nbsp; For unknown tasks, machine learning techniques were developed to create a dynamic model of the human-machine system that could be checked for safety requirements.&nbsp; &nbsp;</p> <p>Both simulated and physical systems were tested as part of the work.&nbsp; Simulated systems included crane control and a simple landing problem for aerial vehicles.&nbsp; In these settings, it was demonstrated that trust-based relationships between people and machines lead to more reliable and robust executions, with good performance and safe outcomes.&nbsp; Physical interaction experiments demonstrated that people learn from interaction better when automation is only keeping them safe, but is not solving the physical task for them. These tasks are only example applications, and all the software is implemented in a general manner, with most of it already available as open source code.</p> <p>The importance of this work extends beyond cyber-physical systems to the broad question of how people will interact with machines in the future.&nbsp; These human-machine systems, if designed well to incorporate the strengths of both and address weaknesses of both, will be more capable and more productive than either humans or machines by themselves.&nbsp; The work in this grant created the foundation for automating the trade-off of decision authority between people and machines, as they work together to accomplish complex tasks.&nbsp;</p> <p>During the period of the award, important broader impact goals were accomplished.&nbsp; Outreach at the Museum of Science and Industry, Chicago occurred in each year of the award (2014-2018), reaching thousands of students.&nbsp; &nbsp;Moreover, a class at Northwestern University on active learning incorporated some of the results in lectures and in problems in homework and projects. The work was applied at Northwestern's medical school, using physical assistance robots.&nbsp;</p><br> <p>            Last Modified: 12/18/2018<br>      Modified by: Todd&nbsp;D&nbsp;Murphey</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project "CPS: Synergy: Collaborative Research: Mutually Stabilized Correction in Physical Demonstration" (Award 1329891) developed human-in-the-loop (HITL) control methodologies that are real-time, reliable, computable, and verifiable. One way to understand the contributions of the work is to think of a device that needs to keep a person safe while accomplishing a goal, like a driverless car or an exoskeleton.  In both cases, automation needs to balance the need to accomplish something (going to the store or walking across a room) against the need to be safe (avoid collisions, stay upright and avoiding tripping).  Moreover, the person using the device may know more about some aspects of what needs to be accomplished; some roads may be better than others, stepping around someone on the sidewalk may be easier in one direction than the other.  Lastly, the person may understand less in other respects; a person may not see oncoming traffic or may not be paying attention.  As a result, the human-machine team needs to take into account both capabilities and limitations of both the human and the machine, leading to a capable system that capitalizes on capabilities and mitigates limitations from both partners. The work focused on formalizing the automated assessment of trust, primarily focusing on the degree to which a computer or automation system should trust a human operator, and integrated that trust into the routine operation of the cyber-physical system.   The work developed analytical methods that analyze a person's decisions in real-time, allowing automation to determine whether the person should be given flexibility in actions or should be prevented from engaging in potentially high risk activity.  The automation makes this assessment at every moment of execution, leading to algorithms that can provide guarantees on performance and safety. The mathematical analysis of these algorithms also provides stability guarantees for a human-machine team if the task is known.  For unknown tasks, machine learning techniques were developed to create a dynamic model of the human-machine system that could be checked for safety requirements.     Both simulated and physical systems were tested as part of the work.  Simulated systems included crane control and a simple landing problem for aerial vehicles.  In these settings, it was demonstrated that trust-based relationships between people and machines lead to more reliable and robust executions, with good performance and safe outcomes.  Physical interaction experiments demonstrated that people learn from interaction better when automation is only keeping them safe, but is not solving the physical task for them. These tasks are only example applications, and all the software is implemented in a general manner, with most of it already available as open source code.  The importance of this work extends beyond cyber-physical systems to the broad question of how people will interact with machines in the future.  These human-machine systems, if designed well to incorporate the strengths of both and address weaknesses of both, will be more capable and more productive than either humans or machines by themselves.  The work in this grant created the foundation for automating the trade-off of decision authority between people and machines, as they work together to accomplish complex tasks.   During the period of the award, important broader impact goals were accomplished.  Outreach at the Museum of Science and Industry, Chicago occurred in each year of the award (2014-2018), reaching thousands of students.   Moreover, a class at Northwestern University on active learning incorporated some of the results in lectures and in problems in homework and projects. The work was applied at Northwestern's medical school, using physical assistance robots.        Last Modified: 12/18/2018       Submitted by: Todd D Murphey]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
