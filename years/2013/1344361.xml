<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Exploratory Research on Harnessing Human Manipulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>99999.00</AwardTotalIntnAmount>
<AwardAmount>99999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gregory Chirikjian</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project is exploring the use of crowd-sourcing, or citizen science, to produce a large database of analyzed human manipulation video.  Every human is an expert on human manipulation.  Harnessing this expertise has the potential to radically transform our knowledge of manipulation.  A large analyzed video database directly serves several important goals of robotics, including autonomous robotic manipulation and recognition of human behavior.  This new approach is in its earliest stages.  The project goals are to explore the new approach, identify problems, assess the value, refine the vision, and formulate plans.  Activities include development of pilot interfaces, testing different approaches to user training, and developing approaches to the filtering and aggregation of results.  The ultimate impact will be a broader scientific understanding of human manipulation, and a large dataset to support research in robotic manipulation and human behavior recognition.  Results will be disseminated through publication of discoveries related to human manipulation, open access to the database, and open access to the crowd-sourcing interface and related software.</AbstractNarration>
<MinAmdLetterDate>08/15/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/15/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1344361</AwardID>
<Investigator>
<FirstName>Matthew</FirstName>
<LastName>Mason</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew T Mason</PI_FULL_NAME>
<EmailAddress>matt.mason@cs.cmu.edu</EmailAddress>
<PI_PHON>4122688804</PI_PHON>
<NSF_ID>000362470</NSF_ID>
<StartDate>08/15/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Nancy</FirstName>
<LastName>Pollard</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nancy S Pollard</PI_FULL_NAME>
<EmailAddress>nsp@cs.cmu.edu</EmailAddress>
<PI_PHON>4122681479</PI_PHON>
<NSF_ID>000271462</NSF_ID>
<StartDate>08/15/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~99999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br />The long-range goal of the project was to improve our understanding of manipulation, by developing new techniques for analysis of video recordings of human manipulation. &nbsp;Specific goals were:</p> <ul> <li>To learn techniques for crowd-based analysis of human manipulation;</li> <li>To develop superior language and classifications describing human manipulation; and</li> <li>To develop plans for a regular NSF-funded project to follow up with a full-scaledevelopment of a database of human manipulation acts and technology for mapping toautonomous robotic manipulation.</li> </ul> <p>A specific outcome related to Intellectual Merit was the analysis of several videos of human manipulation, classification of manipulation actions, and comparisons with prior taxonomies of manipulation actions. &nbsp;This analysis led to a deeper understanding of the grasping and manipulation actions used in tasks like shopping in a deli. &nbsp;For example when taking a heavy item from a shelf, there may be several stages of behavior required to move the fingers through clutter to a suitable grasp, partially pulling the object out for access to a better grasp, and adjust the grasp to take the object's weight, all before actually lifting the object.</p> <p>A specific outcome related to Broader Impact is the potential transfer of intelligent manipulative actions from humans to robotic systems, with consequences for automation productivity, improving the nation's productivity.<br /><br />Liu, Jia, Fangxiaoyu Feng, Yuzuko C Nakamura, and Nancy S Pollard. &ldquo;A taxonomy of everyday grasps in action.&rdquo; In Humanoid Robots (Humanoids), 2014 14th IEEE-RAS International Conference on, 573&ndash; 580. IEEE, 2014.</p> <p>Liu, Jia, Yuzuko C. Nakamura, and Nancy S. Pollard, &ldquo;Annotating Everyday Grasps in Action,&rdquo; &nbsp;In Jean-Paul Laumond and Naoko Abe (eds.) Dance Notations and Robot Motion, Springer Tracts in Robotics, (in press).</p> <p>Mason, Matthew T, Nancy Pollard, Alberto Rodriguez, and Ryan Kerwin. &ldquo;Harnessing Human Manipulation.&rdquo; In NSF/ARL Workshop on Cloud Robotics: Challenges and Opportunities. 2013.</p><br> <p>            Last Modified: 10/29/2015<br>      Modified by: Matthew&nbsp;T&nbsp;Mason</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The long-range goal of the project was to improve our understanding of manipulation, by developing new techniques for analysis of video recordings of human manipulation.  Specific goals were:  To learn techniques for crowd-based analysis of human manipulation; To develop superior language and classifications describing human manipulation; and To develop plans for a regular NSF-funded project to follow up with a full-scaledevelopment of a database of human manipulation acts and technology for mapping toautonomous robotic manipulation.   A specific outcome related to Intellectual Merit was the analysis of several videos of human manipulation, classification of manipulation actions, and comparisons with prior taxonomies of manipulation actions.  This analysis led to a deeper understanding of the grasping and manipulation actions used in tasks like shopping in a deli.  For example when taking a heavy item from a shelf, there may be several stages of behavior required to move the fingers through clutter to a suitable grasp, partially pulling the object out for access to a better grasp, and adjust the grasp to take the object's weight, all before actually lifting the object.  A specific outcome related to Broader Impact is the potential transfer of intelligent manipulative actions from humans to robotic systems, with consequences for automation productivity, improving the nation's productivity.  Liu, Jia, Fangxiaoyu Feng, Yuzuko C Nakamura, and Nancy S Pollard. "A taxonomy of everyday grasps in action." In Humanoid Robots (Humanoids), 2014 14th IEEE-RAS International Conference on, 573&ndash; 580. IEEE, 2014.  Liu, Jia, Yuzuko C. Nakamura, and Nancy S. Pollard, "Annotating Everyday Grasps in Action,"  In Jean-Paul Laumond and Naoko Abe (eds.) Dance Notations and Robot Motion, Springer Tracts in Robotics, (in press).  Mason, Matthew T, Nancy Pollard, Alberto Rodriguez, and Ryan Kerwin. "Harnessing Human Manipulation." In NSF/ARL Workshop on Cloud Robotics: Challenges and Opportunities. 2013.       Last Modified: 10/29/2015       Submitted by: Matthew T Mason]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
