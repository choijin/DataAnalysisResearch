<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Synthesis of User Interfaces for Collaborative Systems in Uncertain Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>179687.00</AwardTotalIntnAmount>
<AwardAmount>179687</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jordan Berg</SignBlockName>
<PO_EMAI>jberg@nsf.gov</PO_EMAI>
<PO_PHON>7032925365</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The research objective of collaborative project is to synthesize observability and estimation techniques from hybrid control theory to design and validate user-interfaces for expensive, high-risk, and safety-critical collaborative systems (e.g. avionics and biomedical devices). The user interface provides a means for the user to observe the underlying automated system as well as for the user to apply inputs to the system.  This research will develop deterministic and stochastic methods for systems under both normal and abnormal operating conditions. The developed techniques and algorithms will be designed to accommodate environments that have complex information requirements, inevitable uncertainties and measurement errors, and nontrivial continuous dynamics, such as those found in air traffic control and aircraft flight management systems. Specifically, this research addresses the development of 1) observability-based conditions to assess the correctness of information content in user interfaces (modeled as hybrid systems with discrete push-button and continuous joystick-type inputs), 2) mode estimation techniques for fault detection (for operation under abnormal conditions) and a prioritization of display elements, 3) display design via sensor scheduling to determine the optimal combination of information for a given display mode, and 4) abstraction-based conditions for correctness of user-interface design (that assume the user interface is a reduced representation of the actual underlying system under standard and abnormal conditions). &lt;br/&gt;&lt;br/&gt;If successful, the results of this research could help identify human-automation interaction problems (such as automation surprises, inadequate or excessive information contained in the user interface, and mode confusion) in collaborative systems before they are built, tested, deployed, and possibly while they are operating.  The control algorithms and interface design aids developed through this research are generic, and have potential to improve the effectiveness in collaborative systems in a variety of domains.  This research plan will contribute to the formal methods in human computer interaction community, and to the control theory communities focused on the design of decision support aids.  Developed theory, code, and data will be disseminated in a timely manner.  Students will benefit through development of a new, multidisciplinary graduate course in control of collaborative systems, with particular emphasis on avionics and air traffic applications, as well as from mentoring and participation in this research.</AbstractNarration>
<MinAmdLetterDate>08/24/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1335038</AwardID>
<Investigator>
<FirstName>Meeko</FirstName>
<LastName>Oishi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meeko Oishi</PI_FULL_NAME>
<EmailAddress>oishi@unm.edu</EmailAddress>
<PI_PHON>5052770299</PI_PHON>
<NSF_ID>000602298</NSF_ID>
<StartDate>08/24/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of New Mexico</Name>
<CityName>Albuquerque</CityName>
<ZipCode>871310001</ZipCode>
<PhoneNumber>5052774186</PhoneNumber>
<StreetAddress>1700 Lomas Blvd. NE, Suite 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<StateCode>NM</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NM01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>868853094</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NEW MEXICO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>784121725</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of New Mexico]]></Name>
<CityName/>
<StateCode>NM</StateCode>
<ZipCode>871310001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NM01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1632</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramElement>
<ProgramReference>
<Code>030E</Code>
<Text>CONTROL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>031E</Code>
<Text>MECHATRONICS</Text>
</ProgramReference>
<ProgramReference>
<Code>034E</Code>
<Text>Dynamical systems</Text>
</ProgramReference>
<ProgramReference>
<Code>035E</Code>
<Text>NOISE, ACOUSTICS, VIBRATIONS</Text>
</ProgramReference>
<ProgramReference>
<Code>8024</Code>
<Text>Complex Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~179687</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Human interaction with automation is pervasive in complex, safety-critical systems, yet no systematic methodology currently exists for the analysis and design of highly automated systems with a human in the loop.&nbsp; In many domains, controller design and interface design are accomplished separately, with interface design often conducted after controller design (and without the benefit of knowledge of the control algorithms implemented).&nbsp; Such ordering yields systems prone to inconsistencies and design errors.&nbsp; The research objective of this work is to address this problem by developing methods for dynamics-driven synthesis of interfaces, by examining the information content that the human needs in order to effectively interact with the automated system.&nbsp; The educational objective of this work is to help create an educated and trained workforce fluent in modeling and control of human-automation systems.&nbsp; The long-term impact of this work will be improved safety, reliability, and overall performance in human-automation systems, enabled by the use of new methods and tools developed through this work.</p> <p>We developed a modeling framework in which the human is captured as a special type of observer, with additional constraints beyond a control theoretic observer.&nbsp; These constraints account for the human&rsquo;s situational awareness, ability to process external information as well as information about their own applied inputs to the system, and human factors design guidelines which recommend not requiring reliance upon the human&rsquo;s memory of previous events.&nbsp; We capture these restrictions through conditions for unknown input observability and predictability, and characterize the space of states for which, for a given task, it is possible for the human to reconstruct the underlying state, and predict the next state, given information in the user interface.</p> <p>We then analyzed the design problem, that is, the question of how to synthesize information of minimal cardinality, that still enables the user to complete the important reconstruction and prediction steps that are a precursor to situational awareness.&nbsp; We focused on both nominal and off-nominal circumstances, which may vary in the human&rsquo;s accuracy (or existence) of mental models of the automated system&rsquo;s behavior, as well as in the human&rsquo;s predilection to trust the automation.&nbsp; We also focused on circumstances in which the information that the human has access to is corrupted by sensor noise (as well as the noise-free case).&nbsp; We formulated a sensor placement problem, which resulted in an interface design problem that was a constrained combinatorial optimization problem.&nbsp; We showed that the computational complexity is bounded in polynomial time when we can prescribe an upper level of trust that the human will have in the automated system.&nbsp; The human&rsquo;s trust in the automation indirectly dictates how much information should be provided: with more trust, the human delegates more to the automation, and hence needs less information; vice versa when the human has less trust in the automation.&nbsp;</p> <p>Several graduate students were supported in part by this project, at the MSc and PhD levels, including several from underrepresented groups.&nbsp; Their professional development was supported in part through their attendance at conferences to present their research related to this work.&nbsp; Research results were disseminated in a timely manner in refereed venues.</p> <p>The results of this research could help identify human-automation interaction problems (such as automation surprises, inadequate or excessive information contained in the user interface, and mode confusion) in collaborative systems before they are built, tested, deployed, and possibly while they are operating. &nbsp;The control algorithms and interface design aids developed through this research are generic, and have potential to improve the effectiveness in collaborative systems in a variety of domains.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/04/2017<br>      Modified by: Meeko&nbsp;Oishi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Human interaction with automation is pervasive in complex, safety-critical systems, yet no systematic methodology currently exists for the analysis and design of highly automated systems with a human in the loop.  In many domains, controller design and interface design are accomplished separately, with interface design often conducted after controller design (and without the benefit of knowledge of the control algorithms implemented).  Such ordering yields systems prone to inconsistencies and design errors.  The research objective of this work is to address this problem by developing methods for dynamics-driven synthesis of interfaces, by examining the information content that the human needs in order to effectively interact with the automated system.  The educational objective of this work is to help create an educated and trained workforce fluent in modeling and control of human-automation systems.  The long-term impact of this work will be improved safety, reliability, and overall performance in human-automation systems, enabled by the use of new methods and tools developed through this work.  We developed a modeling framework in which the human is captured as a special type of observer, with additional constraints beyond a control theoretic observer.  These constraints account for the human?s situational awareness, ability to process external information as well as information about their own applied inputs to the system, and human factors design guidelines which recommend not requiring reliance upon the human?s memory of previous events.  We capture these restrictions through conditions for unknown input observability and predictability, and characterize the space of states for which, for a given task, it is possible for the human to reconstruct the underlying state, and predict the next state, given information in the user interface.  We then analyzed the design problem, that is, the question of how to synthesize information of minimal cardinality, that still enables the user to complete the important reconstruction and prediction steps that are a precursor to situational awareness.  We focused on both nominal and off-nominal circumstances, which may vary in the human?s accuracy (or existence) of mental models of the automated system?s behavior, as well as in the human?s predilection to trust the automation.  We also focused on circumstances in which the information that the human has access to is corrupted by sensor noise (as well as the noise-free case).  We formulated a sensor placement problem, which resulted in an interface design problem that was a constrained combinatorial optimization problem.  We showed that the computational complexity is bounded in polynomial time when we can prescribe an upper level of trust that the human will have in the automated system.  The human?s trust in the automation indirectly dictates how much information should be provided: with more trust, the human delegates more to the automation, and hence needs less information; vice versa when the human has less trust in the automation.   Several graduate students were supported in part by this project, at the MSc and PhD levels, including several from underrepresented groups.  Their professional development was supported in part through their attendance at conferences to present their research related to this work.  Research results were disseminated in a timely manner in refereed venues.  The results of this research could help identify human-automation interaction problems (such as automation surprises, inadequate or excessive information contained in the user interface, and mode confusion) in collaborative systems before they are built, tested, deployed, and possibly while they are operating.  The control algorithms and interface design aids developed through this research are generic, and have potential to improve the effectiveness in collaborative systems in a variety of domains.           Last Modified: 12/04/2017       Submitted by: Meeko Oishi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
