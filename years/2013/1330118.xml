<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CPS: Synergy: Collaborative Research: Harnessing the Automotive Infoverse</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>461875.00</AwardTotalIntnAmount>
<AwardAmount>466703</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Corman</SignBlockName>
<PO_EMAI>dcorman@nsf.gov</PO_EMAI>
<PO_PHON>7032928754</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Until now, the cyber component of automobiles has consisted of control algorithms and associated software for vehicular subsystems designed to achieve one or more performance, efficiency, reliability, comfort, or safety goals, primarily based on short-term intrinsic vehicle sensor data. However, there exist many extrinsic factors that can affect the degree to which these goals can be achieved. These factors can be determined from: longer-term traces of in-built sensor data that can be abstracted as triplines, socialized versions of these that are shared amongst vehicle users, and online databases. These three sources of information collectively constitute the automotive infoverse.&lt;br/&gt;&lt;br/&gt;This project harnesses this automotive infoverse to achieve these goals through high-confidence vehicle tuning and driver feedback decisions. Specifically, the project develops software called Headlight that permits the rapid development of apps that use the infoverse to achieve one or more goals. Advisory apps can provide feedback to the driver in order to ensure better fuel efficiency, while auto-tuning goals can set car parameters to promote safety. Allowing vehicles and such apps to share vehicle data with others and to use extrinsic information results in novel information processing, assurance, and privacy challenges. The project develops methods, algorithms and models to address these challenges.&lt;br/&gt;&lt;br/&gt;Broader Impact - This project can have significant societal impact by reducing carbon emissions and improving vehicular safety, can spur innovation in tuning methods and encourage researchers to experiment with this class of cyber-physical systems. The active participation of General Motors will strongly facilitate technology transfer. The program has outreach through internships, course material, high school and undergraduate involvement, and through creating an open infrastructure usable by diverse developers.</AbstractNarration>
<MinAmdLetterDate>08/30/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/23/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1330118</AwardID>
<Investigator>
<FirstName>Ramesh</FirstName>
<LastName>Govindan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ramesh Govindan</PI_FULL_NAME>
<EmailAddress>ramesh@usc.edu</EmailAddress>
<PI_PHON>2137404509</PI_PHON>
<NSF_ID>000459031</NSF_ID>
<StartDate>08/30/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Fan</FirstName>
<LastName>Bai</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fan Bai</PI_FULL_NAME>
<EmailAddress>fan.bai@gm.com</EmailAddress>
<PI_PHON/>
<NSF_ID>000502815</NSF_ID>
<StartDate>08/30/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900890001</ZipCode>
<StreetAddress><![CDATA[3720 S. Flower Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7363</Code>
<Text>Networking Technology and Syst</Text>
</ProgramElement>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~458702</FUND_OBLG>
<FUND_OBLG>2015~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Vehicles today have several hundred sensors that are used to monitor vehicular subsystems. Such monitoring can track the health of these subsystems and can also be used to control vehicular behavior. In this project, we explored ways in which these sensors could be used to improve vehicular safety, comfort, and performance. Many of the sensors can be accessed through a diagnostic interface using proprietary protocols, so to conduct our research, we partnered with a major car company to obtain access to these sensors.</p> <p><br />One outcome of our research was a suite of algorithms that are used on-board sensors to improve the positioning of the vehicle. Because GPS can be inaccurate in downtown areas, we developed techniques to use onboard sensors to obtain positioning with enough accuracy to locate the vehicle within a given lane. These techniques combine GPS readings with map information, but also use vehicular sensors to determine whether a vehicle traverses a speed bump, or turns right or left, or comes to stop at a signal, then uses these determinations to learn positional corrections. These positional corrections leverage the wisdom of the crowds: if multiple cars stop at the same light, then the average of their positional readings is likely to be more accurate.</p> <p><br />A second outcome of the research built upon this idea and developed a collection of crowd-sourcing algorithms that use onboard sensors to determine driving behavior or various aspects of the environment. Because vehicles have hundreds of sensors, if drivers would share their sensor readings (in much the same way that drivers today share information on apps like Waze), we hypothesized that we could determine various aspects of the environment such as: stop signs, road curvature, road grade, and pothole positions. We developed sensor processing and aggregation algorithms and demonstrated that these algorithms could reliably detect these environmental features.</p> <p><br />Our most recent outcome explored a novel capability that we call Augmented Vehicular Reality (AVR). Today, and in the foreseeable future, vehicles will have "3D sensors" like LiDAR and stereo cameras. Autonomous vehicles and driver assist systems rely on these sensors. These sensors can perceive depth, but their view is limited by obstacles. AVR enables a vehicle to obtain, using wireless communication, readings from other sensors, so that the vehicle can effectively "see through" obstacles. This capability can greatly increase the safety of autonomous driving, enabling a vehicle to plan its path more effectively. The code for AVR is publicly available.</p> <p><br />Concretely, these outcomes have resulted in two patents, several publications, and we have transitioned code to industry. In addition, project has trained 3 PhD students (of whom one has graduated and another is likely to graduate soon), and an MS student. Two undergraduate students have also participated in the research.</p><br> <p>            Last Modified: 10/10/2019<br>      Modified by: Ramesh&nbsp;Govindan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Vehicles today have several hundred sensors that are used to monitor vehicular subsystems. Such monitoring can track the health of these subsystems and can also be used to control vehicular behavior. In this project, we explored ways in which these sensors could be used to improve vehicular safety, comfort, and performance. Many of the sensors can be accessed through a diagnostic interface using proprietary protocols, so to conduct our research, we partnered with a major car company to obtain access to these sensors.   One outcome of our research was a suite of algorithms that are used on-board sensors to improve the positioning of the vehicle. Because GPS can be inaccurate in downtown areas, we developed techniques to use onboard sensors to obtain positioning with enough accuracy to locate the vehicle within a given lane. These techniques combine GPS readings with map information, but also use vehicular sensors to determine whether a vehicle traverses a speed bump, or turns right or left, or comes to stop at a signal, then uses these determinations to learn positional corrections. These positional corrections leverage the wisdom of the crowds: if multiple cars stop at the same light, then the average of their positional readings is likely to be more accurate.   A second outcome of the research built upon this idea and developed a collection of crowd-sourcing algorithms that use onboard sensors to determine driving behavior or various aspects of the environment. Because vehicles have hundreds of sensors, if drivers would share their sensor readings (in much the same way that drivers today share information on apps like Waze), we hypothesized that we could determine various aspects of the environment such as: stop signs, road curvature, road grade, and pothole positions. We developed sensor processing and aggregation algorithms and demonstrated that these algorithms could reliably detect these environmental features.   Our most recent outcome explored a novel capability that we call Augmented Vehicular Reality (AVR). Today, and in the foreseeable future, vehicles will have "3D sensors" like LiDAR and stereo cameras. Autonomous vehicles and driver assist systems rely on these sensors. These sensors can perceive depth, but their view is limited by obstacles. AVR enables a vehicle to obtain, using wireless communication, readings from other sensors, so that the vehicle can effectively "see through" obstacles. This capability can greatly increase the safety of autonomous driving, enabling a vehicle to plan its path more effectively. The code for AVR is publicly available.   Concretely, these outcomes have resulted in two patents, several publications, and we have transitioned code to industry. In addition, project has trained 3 PhD students (of whom one has graduated and another is likely to graduate soon), and an MS student. Two undergraduate students have also participated in the research.       Last Modified: 10/10/2019       Submitted by: Ramesh Govindan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
