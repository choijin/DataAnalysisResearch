<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>The Activation Approach: A Comprehensive Method and Toolkit for Evaluating the Impact of Science Learning Experiences Across Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>798443.00</AwardTotalIntnAmount>
<AwardAmount>798443</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The project develops evaluation tools around the concept of "science activation" a construct that includes: fascination with science, valuing science, perceived autonomy, competency belief, and engagement in scientific sensemaking. This enables evaluation of  a broader range of outcomes beyond achievement test scores. The project will build on research activities and turn those findings into measures, surveys, and protocols that can be used in both formal and informal settings with 11-15-year old youth.&lt;br/&gt;&lt;br/&gt;The instruments and toolkit developed through the project will help other organizations to collect, analyze and interpret similar data.</AbstractNarration>
<MinAmdLetterDate>09/01/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/01/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1337186</AwardID>
<Investigator>
<FirstName>Rena</FirstName>
<LastName>Dorph</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rena Dorph</PI_FULL_NAME>
<EmailAddress>rdorph@berkeley.edu</EmailAddress>
<PI_PHON>5106424193</PI_PHON>
<NSF_ID>000461915</NSF_ID>
<StartDate>09/01/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ardice</FirstName>
<LastName>Hartry</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ardice Hartry</PI_FULL_NAME>
<EmailAddress>hartry@berkeley.edu</EmailAddress>
<PI_PHON>5106428109</PI_PHON>
<NSF_ID>000610811</NSF_ID>
<StartDate>09/01/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Matthew A.</FirstName>
<LastName>Cannady</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Matthew A. Cannady</PI_FULL_NAME>
<EmailAddress>mcannady@berkeley.edu</EmailAddress>
<PI_PHON>5106426281</PI_PHON>
<NSF_ID>000620916</NSF_ID>
<StartDate>09/01/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947045940</ZipCode>
<StreetAddress><![CDATA[1 Centennial Dr.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7261</Code>
<Text>Project &amp; Program Evaluation</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~798443</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-84d09b32-c0e3-de28-de05-6b6e24d09a2b"> <p dir="ltr"><span>The National Research Council report, </span><span>Monitoring Progress Toward Successful K-12 Education: &nbsp;A Nation Advancing?</span><span> (2013), called for a national indicator system that could be used by policymakers and practitioners to improve STEM education. Throughout this project, our team conducted research on the two Indicators that are focused on adequacy of instructional time and resources for science in grades K-5. Our goal was to understand how best to measure time and resources for science in elementary schools. We conducted a literature review of current and past methods of tracking time spent teaching/learning science during the elementary school day and the range of resources provided/used in order to do this. We interviewed key stakeholders, including practitioners, designers, and developers, to better understand what has been effective in terms of time, scheduling, and substance. Lastly, we convened a group of national experts in the field to provide consensus related to measurement strategy, establishment of benchmarks of adequacy, and to develop recommendations for implementation of measures at national scale. </span></p> <p dir="ltr"><span>For the teacher survey, we found a number of ways to improve survey data collection. First, we show how to provide examples of the unit of measurement. We recommend retaining the &ldquo;total minutes per week&rdquo; but including a minimum range check on this indicator. Second, it is important that the actor or recipient is clear. Because some schools use a science specialist to offer instruction to elementary students, it is important to understand whether the data refer to the number of minutes of science instruction that students receive, or that the teacher responding to the survey offers. If future research intends to correlate minutes of science instruction with student achievement, we need to understand the total number of minutes that students received science instruction. </span></p> <p dir="ltr"><span>Third, our work stressed the importance of understanding that occurs during instructional minutes. Sixty minutes of listening to lecture can have very different outcomes than sixty minutes of engaging in the practices of science. We recommend including an item that asks teachers to characterize the nature of how time is spent during science, and thus the quality of the science instruction and opportunities provided. Fourth, any indicator system needs to obtain a balance between collecting high-quality data that reflects reality and collecting such data at scale. An indicator system provides the opportunity for multiple methods and sources of data, rather than relying on a single survey to obtain all required information. We suggest including a district-based survey focusing on allocated time, and teacher-based activity logs. </span></p> <p dir="ltr"><span>For the principal survey, our findings suggested that two main strategies would improve survey items. First, we suggest limiting the grade levels principals are asked to report about. Because science instructional time can vary widely between kindergarten and 5</span><span>th</span><span> grade, we opted to limit the question to two grade levels: 2</span><span>nd</span><span> and 5</span><span>th</span><span>. For information about opportunities to learn science, we created a single measure for principals about how frequently they had supplemental science activities at their school. Since these are school-wide (or at least school-supported) opportunities, collecting them at the school level seemed most appropriate.</span></p> <p dir="ltr"><span>This exploratory study and its findings provide a foundation for thinking about an accountability system to ensure students receive equitable access to science education. While it is clear that the number of instructional minutes and the opportunities alone do not ensure student learning in science, they provide insight into the priorities of the teachers, administrators, and policy makers, and have the potential to inform policy decisions in the future. The process of this study revealed the need to further refine data collection strategies to ensure high response rates when administering a survey for accountability purposes. The creation of &ldquo;school dashboards&rdquo; could incentivize local participation in the monitoring system. Findings from this study have been reported to the National Center for Education Statistics (NCES), and NCES plans to pilot a time-monitoring item in the current national survey as one way to begin monitoring the indicators on a national scale. </span></p> <p dir="ltr"><span>This work has wide-reaching impacts for science learning experiences in K-5 schools. This set of key indicators demonstrate whether students have access to quality science learning experiences, particularly in terms of adequate time and a full range of experiences. These indicators will help policymakers and other stakeholders improve education because they represent points of greatest leverage. By defining adequate time and opportunities for science instruction and designing measures to monitor what is being offered to students, districts and states can monitor their programs effectively. They will be able to make informed decisions that will improve science learning in every district and every state. More and more students can receive sufficient and high-quality instruction in science, and this, in turn, will increase the number of underrepresented students who pursue science degrees and careers, expand the STEM-capable workforce, and increase science literacy.</span></p> <div><span><br /></span></div> </span></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/15/2017<br>      Modified by: Ardice&nbsp;Hartry</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  The National Research Council report, Monitoring Progress Toward Successful K-12 Education:  A Nation Advancing? (2013), called for a national indicator system that could be used by policymakers and practitioners to improve STEM education. Throughout this project, our team conducted research on the two Indicators that are focused on adequacy of instructional time and resources for science in grades K-5. Our goal was to understand how best to measure time and resources for science in elementary schools. We conducted a literature review of current and past methods of tracking time spent teaching/learning science during the elementary school day and the range of resources provided/used in order to do this. We interviewed key stakeholders, including practitioners, designers, and developers, to better understand what has been effective in terms of time, scheduling, and substance. Lastly, we convened a group of national experts in the field to provide consensus related to measurement strategy, establishment of benchmarks of adequacy, and to develop recommendations for implementation of measures at national scale.  For the teacher survey, we found a number of ways to improve survey data collection. First, we show how to provide examples of the unit of measurement. We recommend retaining the "total minutes per week" but including a minimum range check on this indicator. Second, it is important that the actor or recipient is clear. Because some schools use a science specialist to offer instruction to elementary students, it is important to understand whether the data refer to the number of minutes of science instruction that students receive, or that the teacher responding to the survey offers. If future research intends to correlate minutes of science instruction with student achievement, we need to understand the total number of minutes that students received science instruction.  Third, our work stressed the importance of understanding that occurs during instructional minutes. Sixty minutes of listening to lecture can have very different outcomes than sixty minutes of engaging in the practices of science. We recommend including an item that asks teachers to characterize the nature of how time is spent during science, and thus the quality of the science instruction and opportunities provided. Fourth, any indicator system needs to obtain a balance between collecting high-quality data that reflects reality and collecting such data at scale. An indicator system provides the opportunity for multiple methods and sources of data, rather than relying on a single survey to obtain all required information. We suggest including a district-based survey focusing on allocated time, and teacher-based activity logs.  For the principal survey, our findings suggested that two main strategies would improve survey items. First, we suggest limiting the grade levels principals are asked to report about. Because science instructional time can vary widely between kindergarten and 5th grade, we opted to limit the question to two grade levels: 2nd and 5th. For information about opportunities to learn science, we created a single measure for principals about how frequently they had supplemental science activities at their school. Since these are school-wide (or at least school-supported) opportunities, collecting them at the school level seemed most appropriate. This exploratory study and its findings provide a foundation for thinking about an accountability system to ensure students receive equitable access to science education. While it is clear that the number of instructional minutes and the opportunities alone do not ensure student learning in science, they provide insight into the priorities of the teachers, administrators, and policy makers, and have the potential to inform policy decisions in the future. The process of this study revealed the need to further refine data collection strategies to ensure high response rates when administering a survey for accountability purposes. The creation of "school dashboards" could incentivize local participation in the monitoring system. Findings from this study have been reported to the National Center for Education Statistics (NCES), and NCES plans to pilot a time-monitoring item in the current national survey as one way to begin monitoring the indicators on a national scale.  This work has wide-reaching impacts for science learning experiences in K-5 schools. This set of key indicators demonstrate whether students have access to quality science learning experiences, particularly in terms of adequate time and a full range of experiences. These indicators will help policymakers and other stakeholders improve education because they represent points of greatest leverage. By defining adequate time and opportunities for science instruction and designing measures to monitor what is being offered to students, districts and states can monitor their programs effectively. They will be able to make informed decisions that will improve science learning in every district and every state. More and more students can receive sufficient and high-quality instruction in science, and this, in turn, will increase the number of underrepresented students who pursue science degrees and careers, expand the STEM-capable workforce, and increase science literacy.             Last Modified: 11/15/2017       Submitted by: Ardice Hartry]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
