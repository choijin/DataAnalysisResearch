<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Measuring, Predicting, and Improving Construction Safety by Improving Hazard Signal Detection with Augmented Virtual Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>100400.00</AwardTotalIntnAmount>
<AwardAmount>100400</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cynthia Chen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Each year the construction industry has a disproportionate injury rate compared to other industries. One of the main causes of these injuries is human error, which could be exacerbated by skill deficiency associated with signal detection (defined as the ability of an individual to detect visual stimuli that indicate the existence of a safety hazard). From psychological and engineering standpoints little is known about signal detection or if this skill can be accurately measured, predicted, or improved with emerging technologies. This award supports interdisciplinary research that investigates if signal detection can be reliably improved through exposure to and feedback from an augmented virtual construction environment. Additionally, the research explores if an individual's signal detection skill in a virtual environment can predict their skill in real construction environments. As new knowledge is gained, it will be shared with industry practitioners through presentations to national communities of practice, integrated into multiple levels of civil engineering and psychology curricula, and embedded in the final version of the virtual system that will disseminated broadly for education and safety training.&lt;br/&gt;&lt;br/&gt;The main objective of this research is to test hypotheses that augmented virtual environments can be used to improve signal detection skill by over 30% and that over half of the variability in signal detection skill in field environments can be predicted by one's performance in an augmented virtual system. These hypotheses will be tested using a multiple baseline design that has been adapted from pharmaceutical research to address the dynamic nature of the construction industry. The experimental results will be statistically verified using interrupted time-series regression models. If successful, the adaptation of multiple baseline design and statistical verification would serve as a new approach of experimental research for construction. Additionally, a strong relationship between performance in virtual and field environments would indicate that high-fidelity augmented virtual environments provide a risk-free proxy for measuring signal detection skill, potentially transforming the way that construction safety is studied.</AbstractNarration>
<MinAmdLetterDate>06/23/2014</MinAmdLetterDate>
<MaxAmdLetterDate>06/23/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1363222</AwardID>
<Investigator>
<FirstName>Mani</FirstName>
<LastName>Golparvar-Fard</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mani Golparvar-Fard</PI_FULL_NAME>
<EmailAddress>mgolpar@illinois.edu</EmailAddress>
<PI_PHON>2173005226</PI_PHON>
<NSF_ID>000586985</NSF_ID>
<StartDate>06/23/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207406</ZipCode>
<StreetAddress><![CDATA[1901 South First Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1631</Code>
<Text>CIS-Civil Infrastructure Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>029E</Code>
<Text>INFRASTRUCTURE SYSTEMS MGT</Text>
</ProgramReference>
<ProgramReference>
<Code>036E</Code>
<Text>CIVIL INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>039E</Code>
<Text>STRUCTURAL SYSTEMS</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~100400</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project examined the interplay between hazard recognition, risk perception, risk tolerance, and decision making (i.e., situational awareness) in dynamic construction environments. Through a controlled experiment in a risk-free virtual 3D construction site augmented by reality data, participants were induced into one of three emotional states (positive, neutral, or negative) using video clips. This emotions induction allowed the team to explore the extent to which human emotion influences situational awareness. The results indicate that emotion induction does not have a statistically-significant impact on hazard recognition, which is contrary to the original hypothesis. Further, the results indicate that emptions connected with the dangers of the environment itself do influence situational awareness. The increased understanding of emotions and situational awareness may help to design safety interventions that consider the nuanced impact of emotions on decision making. This is important as construction is one of the most dangerous occupations, accounting for nearly 1,000 fatalities per year in the US. The real- experiments also created actionable feedback on how 2D and 3D reality data can be integrated into virtual reality environments to bridge the gap in conducting user-centered experiments in virtual environments as opposed to real-world settings. The results of the project were published in academic conference and journal papers and were shared with industry practitioners via numerous industry associations and communities of practice.</p><br> <p>            Last Modified: 10/08/2018<br>      Modified by: Mani&nbsp;Golparvar-Fard</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539021974857_pic2--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539021974857_pic2--rgov-800width.jpg" title="Augmented Virtuality environment"><img src="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539021974857_pic2--rgov-66x44.jpg" alt="Augmented Virtuality environment"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Screenshots of the Augmented Virtuality environment</div> <div class="imageCredit">our team</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Augmented Virtuality environment</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539021762034_pic1--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539021762034_pic1--rgov-800width.jpg" title="Model showing associations between key safety dimensions and positive and negative affective experiences"><img src="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539021762034_pic1--rgov-66x44.jpg" alt="Model showing associations between key safety dimensions and positive and negative affective experiences"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Model Showing Associations Between Key Safety Dimensions and Affective Experiences- Pathways from experimental manipulation show the result for affective manipulation coded linearly i.e., comparison between the two treatment groups (negative and positive). The broken lines represent relationship.</div> <div class="imageCredit">our team</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Model showing associations between key safety dimensions and positive and negative affective experiences</div> </div> </li> <li> <a href="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539022047600_pic3--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539022047600_pic3--rgov-800width.jpg" title="Overview of the Experimental Protocol"><img src="/por/images/Reports/POR/2018/1363222/1363222_10312401_1539022047600_pic3--rgov-66x44.jpg" alt="Overview of the Experimental Protocol"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Overview of the Experimental Protocol</div> <div class="imageCredit">Our team</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Mani&nbsp;Golparvar-Fard</div> <div class="imageTitle">Overview of the Experimental Protocol</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project examined the interplay between hazard recognition, risk perception, risk tolerance, and decision making (i.e., situational awareness) in dynamic construction environments. Through a controlled experiment in a risk-free virtual 3D construction site augmented by reality data, participants were induced into one of three emotional states (positive, neutral, or negative) using video clips. This emotions induction allowed the team to explore the extent to which human emotion influences situational awareness. The results indicate that emotion induction does not have a statistically-significant impact on hazard recognition, which is contrary to the original hypothesis. Further, the results indicate that emptions connected with the dangers of the environment itself do influence situational awareness. The increased understanding of emotions and situational awareness may help to design safety interventions that consider the nuanced impact of emotions on decision making. This is important as construction is one of the most dangerous occupations, accounting for nearly 1,000 fatalities per year in the US. The real- experiments also created actionable feedback on how 2D and 3D reality data can be integrated into virtual reality environments to bridge the gap in conducting user-centered experiments in virtual environments as opposed to real-world settings. The results of the project were published in academic conference and journal papers and were shared with industry practitioners via numerous industry associations and communities of practice.       Last Modified: 10/08/2018       Submitted by: Mani Golparvar-Fard]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
