<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Medium: Collaborative Research: New Approaches to Robustness in High-Dimensions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cozzens</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Rapid development of large-scale data collection technology has&lt;br/&gt;ignited research into high-dimensional machine learning.  For&lt;br/&gt;instance, the problem of designing recommender systems, such as those&lt;br/&gt;used by Amazon, Netflix and other on-line companies, involves&lt;br/&gt;analyzing large matrices that describe users' behavior in past&lt;br/&gt;situations.  In sociology, researchers are interested in fitting&lt;br/&gt;networks to large-scale data sets, involving hundreds or thousands of&lt;br/&gt;individuals.  In medical imaging, the goal is to reconstruct&lt;br/&gt;complicated phenomena (e.g., brain images; videos of a beating heart)&lt;br/&gt;based on on a minimal number of incomplete and possibly corrupted&lt;br/&gt;measurements.  Motivated by such applications, the goal of this&lt;br/&gt;research is to develop and analyze models and algorithms for&lt;br/&gt;extracting relevant structure from such high-dimensional data sets in&lt;br/&gt;a robust and scalable fashion.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The research leverages tools from convex optimization, signal&lt;br/&gt;processing, and robust statistics.  It consists of three main thrusts:&lt;br/&gt;(1) Model restrictiveness: Successful methods for high-dimensional&lt;br/&gt;data exploit low-dimensional structure; however, many real-world&lt;br/&gt;problems fall outside the scope of existing models.  This proposal&lt;br/&gt;significantly extends the basic set-up by allowing for multiple&lt;br/&gt;structures, leading to computationally efficient algorithms while&lt;br/&gt;eliminating negative effects of model mismatch.  (2) Non-ideal data:&lt;br/&gt;Missing data are prevalent in real-world problems, and can cause major&lt;br/&gt;breakdowns in standard algorithms for high-dimensional data. The&lt;br/&gt;second thrust devises relaxations and greedy approaches for these&lt;br/&gt;non-convex problems.  (3) Arbitrary Outliers: Gross errors can arise&lt;br/&gt;for various reasons, including fault-prone sensors and manipulative&lt;br/&gt;agents.  The third thrust proposes efficient and randomized algorithms&lt;br/&gt;to address arbitrary outliers.</AbstractNarration>
<MinAmdLetterDate>03/19/2013</MinAmdLetterDate>
<MaxAmdLetterDate>04/16/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302687</AwardID>
<Investigator>
<FirstName>Martin</FirstName>
<LastName>Wainwright</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Martin Wainwright</PI_FULL_NAME>
<EmailAddress>wainwrig@eecs.berkeley.edu</EmailAddress>
<PI_PHON>5106431978</PI_PHON>
<NSF_ID>000060031</NSF_ID>
<StartDate>03/19/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947201770</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramElement>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~189792</FUND_OBLG>
<FUND_OBLG>2015~210208</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><br />This project focused on flexible and robust techniques for modelingand drawing inferences from high-dimensional data sets.&nbsp; One coreproblem is that of ranking from pairwise comparisons, as used in manyapplications, including ordering of on-line search results (Google andYahoo); ranking of cartoons in the New Yorker; and aggregation ofsurvey based (NYC city planning).&nbsp; A second core problem iscrowd-sourcing, where the goal is to aggregate the responses of acollection of ``workers'' so as to obtain reliable answers to a set ofquestions (e.g., in classifying and annotating data sets; insearch-and-rescue operations in digital imagery).</p> <p><br />In this research, we developed flexible models for the pairwiseranking problem based on the notion of strong stochastic transitivity(essentially, formalizing the transitivity of a natural ordering:e.g., if Federer is a superior player to Nadal, then he should be atleast as likely to beat a third player as Nadal).&nbsp; We studied thestructure of the class of SST matrices, and developed computationallyefficient algorithms for both learning the underlying ranking (e.g.,as is done for the ATP ranking of tennis players), and also estimatingthe probabilities of the pairwise comparisons.&nbsp; We also developedrobust models for aggregating data in crowd-sourcing, as is used inthe Amazon Turk system.&nbsp; We developed a generalization of theclassical Dawid-Skene model that is much less sensitive to model mismatch.</p> <p><br />The research was inter-disciplinary in nature, combining methods andtechniques from statistical machine learning, artificial intelligence,high-dimensional statistics, optimization and information theory.&nbsp; Thegrant supported the training of multiple graduate students andpost-doctoral students, who now occupy faculty positions atuniversities across the country (e.g., Carnegie Mellon University,University of Michigan, Cornell University).</p><br> <p>            Last Modified: 01/01/2018<br>      Modified by: Martin&nbsp;Wainwright</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  This project focused on flexible and robust techniques for modelingand drawing inferences from high-dimensional data sets.  One coreproblem is that of ranking from pairwise comparisons, as used in manyapplications, including ordering of on-line search results (Google andYahoo); ranking of cartoons in the New Yorker; and aggregation ofsurvey based (NYC city planning).  A second core problem iscrowd-sourcing, where the goal is to aggregate the responses of acollection of ``workers'' so as to obtain reliable answers to a set ofquestions (e.g., in classifying and annotating data sets; insearch-and-rescue operations in digital imagery).   In this research, we developed flexible models for the pairwiseranking problem based on the notion of strong stochastic transitivity(essentially, formalizing the transitivity of a natural ordering:e.g., if Federer is a superior player to Nadal, then he should be atleast as likely to beat a third player as Nadal).  We studied thestructure of the class of SST matrices, and developed computationallyefficient algorithms for both learning the underlying ranking (e.g.,as is done for the ATP ranking of tennis players), and also estimatingthe probabilities of the pairwise comparisons.  We also developedrobust models for aggregating data in crowd-sourcing, as is used inthe Amazon Turk system.  We developed a generalization of theclassical Dawid-Skene model that is much less sensitive to model mismatch.   The research was inter-disciplinary in nature, combining methods andtechniques from statistical machine learning, artificial intelligence,high-dimensional statistics, optimization and information theory.  Thegrant supported the training of multiple graduate students andpost-doctoral students, who now occupy faculty positions atuniversities across the country (e.g., Carnegie Mellon University,University of Michigan, Cornell University).       Last Modified: 01/01/2018       Submitted by: Martin Wainwright]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
