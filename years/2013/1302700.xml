<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Medium: Collaborative Research: Object and Activity Recognition as the Maximum Weight Subgraph Problem with Mutual Exclusion Constraints</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>It has been widely acknowledged that recognizing objects in images, and human activities in video - the basic problems in computer vision - can be significantly improved by accounting for object (activity) parts, context, and their spatiotemporal relationships. This is because these constraints facilitate resolving ambiguous hypotheses in the face of uncertainty. Since parts and contexts can be efficiently modeled by graphical models (e.g., Conditional Random Field), object and activity recognition are often formulated as probabilistic inference of graphical models. The project develops a new theoretical framework of graphical models that explicitly encodes high-order, spatiotemporal, hierarchical, and contextual interactions among objects (activities) as Quadratic Mutual-Exclusion Constraints (QMCs), for the purposes of object and activity recognition in images and video.&lt;br/&gt;&lt;br/&gt;The key contributions of the project work include: 1) Approaches to view-invariant object and activity recognition; 2) Formulations of learning and inference of graphical models representing objects and human activities, as finding a maximum weight subgraph (MWS) under the QMCs; 3) Polynomial-time algorithms for solving the MWS problem subject to QMCs; and 4) Explicit performance bounds and theoretical guarantees of tightness and convergence of the proposed learning and inference algorithms. &lt;br/&gt;&lt;br/&gt;The project framework encodes hard constraints from the domain of interest that have never been used in prior work, and uses principled, polynomial-time algorithms for learning and inference. The research of this project advances the state of the art in object and activity recognition, and enables new applications including video surveillance, retrieval from large datasets, and perception of mobile robots.</AbstractNarration>
<MinAmdLetterDate>04/26/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/20/2016</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302700</AwardID>
<Investigator>
<FirstName>Sinisa</FirstName>
<LastName>Todorovic</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sinisa Todorovic</PI_FULL_NAME>
<EmailAddress>sinisa@eecs.oregonstate.edu</EmailAddress>
<PI_PHON>5417377268</PI_PHON>
<NSF_ID>000514889</NSF_ID>
<StartDate>04/26/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Oregon State University</Name>
<CityName>Corvallis</CityName>
<ZipCode>973318507</ZipCode>
<PhoneNumber>5417374933</PhoneNumber>
<StreetAddress>OREGON STATE UNIVERSITY</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OR04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>053599908</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OREGON STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053599908</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Oregon State University]]></Name>
<CityName>Corvallis</CityName>
<StateCode>OR</StateCode>
<ZipCode>973315501</ZipCode>
<StreetAddress><![CDATA[1148 Kelley Engineering Center]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OR04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~112450</FUND_OBLG>
<FUND_OBLG>2014~140363</FUND_OBLG>
<FUND_OBLG>2015~147114</FUND_OBLG>
<FUND_OBLG>2016~100073</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The project has advanced object and activity recognition in images and videos by reducing uncertainty with Quadratic Mutual-Exclusion Constraints (QMCs) about object and activity classes, which are learned directly from training data. Visual recognition has been cast as the problem of<span style="font-size: 12px;">&nbsp;finding a maximum weight subgraph (MWS) subject to QMCs, and new, polynomial-time algorithms have been developed for solving this constrained problem. Explicit performance bounds and theoretical guarantees of tightness and convergence of the proposed learning and inference algorithms have been derived. New directions have been explored by integrating QMCs with recent deep learning approaches for weakly supervised semantic segmentation of images, fine-graine object detection in images, and estimating boundary flow (i.e., motions of object boundaries) in videos. Since accounting for QMCs, in general, increases computational complexity, as a trade off for improving accuracy of recognition, the project has also studied&nbsp;<span>improving performance under a limited time budget.&nbsp;</span>The project has produced: 15 publications presented in high-impact journals and at top vision conferences, open-source software, and served as a research material for three successfully defended </span><span style="font-size: 12px;">PhD Theses, &nbsp;a number of MS theses. It has also provided training of four undergraduate REU students (among those two minority) at Oregon State University and Temple University.</span></p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/02/2019<br>      Modified by: Sinisa&nbsp;Todorovic</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project has advanced object and activity recognition in images and videos by reducing uncertainty with Quadratic Mutual-Exclusion Constraints (QMCs) about object and activity classes, which are learned directly from training data. Visual recognition has been cast as the problem of finding a maximum weight subgraph (MWS) subject to QMCs, and new, polynomial-time algorithms have been developed for solving this constrained problem. Explicit performance bounds and theoretical guarantees of tightness and convergence of the proposed learning and inference algorithms have been derived. New directions have been explored by integrating QMCs with recent deep learning approaches for weakly supervised semantic segmentation of images, fine-graine object detection in images, and estimating boundary flow (i.e., motions of object boundaries) in videos. Since accounting for QMCs, in general, increases computational complexity, as a trade off for improving accuracy of recognition, the project has also studied improving performance under a limited time budget. The project has produced: 15 publications presented in high-impact journals and at top vision conferences, open-source software, and served as a research material for three successfully defended PhD Theses,  a number of MS theses. It has also provided training of four undergraduate REU students (among those two minority) at Oregon State University and Temple University.                      Last Modified: 03/02/2019       Submitted by: Sinisa Todorovic]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
