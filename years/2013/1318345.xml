<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EXP: RUI: Exploring Spatial-Temporal Anchored Collaboration in Asynchronous Learning Experiences</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>448698.00</AwardTotalIntnAmount>
<AwardAmount>448698</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>John Cherniavsky</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The researchers on this project are developing and studying a web-based multi-media platform that will allow special-temporal annotations intended for collaboration in post-secondary courses. The use of digital web-hosted media is becoming increasingly commonplace and important in postsecondary educational environments. Instructors routinely post large collections of images, audio clips, and videos for student use. As instructors continue to adopt innovative pedagogies using these multi-media materials, the need to deliver multimedia content online, outside of the typical class setting, becomes even more important. Hybrid, distance learning, and massive open online courses place additional demands on the delivery of digitally-mediated content.&lt;br/&gt;&lt;br/&gt;Current hosting solutions for the large amount of educational media lack tools to foster rich collaborative discourse and social learning. Student-to-student interactions that would be trivial in face-to-face settings are not easily reproduced in online environments. In part this is due to the lack of support for spatial-temporal collaboration within media playback systems. In order to address these limitations, this project explores the implementation of novel techniques to support spatial-temporal collaboration over a variety of web-hosted media including video, audio, and still images. The researchers will design, deploy, and evaluate TrACE - the Transformative Anchored Collaboration Environment.&lt;br/&gt;&lt;br/&gt;The broader impact of the project lies in the potential transformation of how educational content is addressed in asynchronous environments - in particular massive open online courses (MOOCs). MOOCs have the promise of transforming undergraduate education making it available to traditionally underrepresented populations.</AbstractNarration>
<MinAmdLetterDate>09/06/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1318345</AwardID>
<Investigator>
<FirstName>Larissa</FirstName>
<LastName>Schroeder</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Larissa Schroeder</PI_FULL_NAME>
<EmailAddress>schroeder@hartford.edu</EmailAddress>
<PI_PHON>8607684083</PI_PHON>
<NSF_ID>000620557</NSF_ID>
<StartDate>09/06/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Dorn</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian Dorn</PI_FULL_NAME>
<EmailAddress>bdorn@unomaha.edu</EmailAddress>
<PI_PHON>4025544905</PI_PHON>
<NSF_ID>000634344</NSF_ID>
<StartDate>09/06/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Ball</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin A Ball</PI_FULL_NAME>
<EmailAddress>keball@hartford.edu</EmailAddress>
<PI_PHON>8607685806</PI_PHON>
<NSF_ID>000634391</NSF_ID>
<StartDate>09/06/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Nebraska at Omaha</Name>
<CityName>Omaha</CityName>
<ZipCode>681820210</ZipCode>
<PhoneNumber>4025542286</PhoneNumber>
<StreetAddress>6001 Dodge Street</StreetAddress>
<StreetAddress2><![CDATA[EAB 203]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<StateCode>NE</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NE02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>190827162</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NEBRASKA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068662618</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Nebraska at Omaha]]></Name>
<CityName>Omaha</CityName>
<StateCode>NE</StateCode>
<ZipCode>681820210</ZipCode>
<StreetAddress><![CDATA[6001 Dodge Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Nebraska</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NE02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7511</Code>
<Text>TUES-Type 2 Project</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8841</Code>
<Text>Exploration Projects</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~448698</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-fa7a9316-7fff-e1e8-8b96-ef5a57174a5d"> </span></p> <p dir="ltr"><span>Streaming video content from the Web continues to play an increasingly important role in the delivery of formal and informal educational content in the information age. &nbsp;However, many of the systems we encounter that host these videos are not designed with the specific goal of learning in mind.  The primary aim of this project was to explore innovative ways for students and instructors to interact with web-based video content as part of blended and online course experiences. &nbsp;The core innovation created opportunities for interaction and collaboration through student and teacher-created anchor points embedded within instructional videos.  As part of this grant, we designed and built the TrACE system to evaluate how such features were adopted by teachers and shaped course practices in higher education settings. &nbsp;TrACE enabled a wide range of interactive anchor types not available in commercial video-streaming platforms, including free-from questions and discussion, bookmarking, audience polling, prompted and structured reflection points, and quiz features.</span></p> <p dir="ltr"><span>TrACE was deployed in dozens of undergraduate, graduate, and continuing education courses at multiple universities during the grant period, and it was used by thousands of learners in that time. &nbsp;With each semester, we iteratively improved the TrACE system through an iterative design-based research process guided by feedback from actual classroom instructors and their students.  We found that the nature of video content plays a major role in shaping interaction, with narrated lecture-style videos engendering short question-response patterns and limited student-to-student interaction but case-analysis videos fostering longer debate-style discussion threads. &nbsp;We found that providing flexibly configurable public and private discussion features that could be tailored to specific classes was a key element in supporting teachers' formative assessment practices.  We also observed that enabling students to make individual choices about whether to post content anonymously to their peers was important for encouraging overall participation.</span></p> <p dir="ltr"><span> </span></p> <p dir="ltr"><span>Because TrACE enabled fine-grained logging of student interactions with video content, this project also explored how to construct analytics tools to help teachers better understand their students' work in the system. &nbsp;We discovered that teachers universally desire more data about their students, but that they often lack the time to explore detailed reports during the academic term, limiting their ability to make data-driven decisions in real time. &nbsp;To alleviate this difficulty, we designed and tested a set of expectation-driven analytic tools which let teachers describe what they hope their students do with a video in a natural way.  These expectations were automatically used to generate reports for teachers and award completion badges for students. &nbsp;Use of the expectation-driven analytics was markedly higher among instructors compared to traditional user activity tables and graphs, and they became integrated into several formal course participation policies.</span></p> <p dir="ltr"><span>&nbsp;</span>This project directly impacted thousands of students studying in STEM disciplines (e.g., Computer Science, Mathematics, Rehabilitation Science, etc.) through the courses where TrACE was used, and insights about the opportunities and challenges gleaned from these courses may continue to shape how video is integrated in future learning environments. &nbsp;Further, the project also supported the training of future researchers in STEM by contributing to the successful completion of 1 doctoral dissertation and 3 master's theses, and by enabling 11 undergraduate students to gain valuable first-hand experience with human-centered computing and learning sciences research.</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/04/2019<br>      Modified by: Brian&nbsp;Dorn</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1318345/1318345_10275806_1546610074590_trace--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1318345/1318345_10275806_1546610074590_trace--rgov-800width.jpg" title="TrACE User Interface"><img src="/por/images/Reports/POR/2019/1318345/1318345_10275806_1546610074590_trace--rgov-66x44.jpg" alt="TrACE User Interface"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Video playback interface within TrACE with annotation features visible.</div> <div class="imageCredit">Brian Dorn</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Brian&nbsp;Dorn</div> <div class="imageTitle">TrACE User Interface</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1318345/1318345_10275806_1546610306604_expect--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1318345/1318345_10275806_1546610306604_expect--rgov-800width.jpg" title="Expectation-Driven Analytics Tools"><img src="/por/images/Reports/POR/2019/1318345/1318345_10275806_1546610306604_expect--rgov-66x44.jpg" alt="Expectation-Driven Analytics Tools"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Authoring tool for expectation-driving analytics (top) and sample resulting class report for a specific video (bottom)</div> <div class="imageCredit">Brian Dorn</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Brian&nbsp;Dorn</div> <div class="imageTitle">Expectation-Driven Analytics Tools</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Streaming video content from the Web continues to play an increasingly important role in the delivery of formal and informal educational content in the information age.  However, many of the systems we encounter that host these videos are not designed with the specific goal of learning in mind.  The primary aim of this project was to explore innovative ways for students and instructors to interact with web-based video content as part of blended and online course experiences.  The core innovation created opportunities for interaction and collaboration through student and teacher-created anchor points embedded within instructional videos.  As part of this grant, we designed and built the TrACE system to evaluate how such features were adopted by teachers and shaped course practices in higher education settings.  TrACE enabled a wide range of interactive anchor types not available in commercial video-streaming platforms, including free-from questions and discussion, bookmarking, audience polling, prompted and structured reflection points, and quiz features. TrACE was deployed in dozens of undergraduate, graduate, and continuing education courses at multiple universities during the grant period, and it was used by thousands of learners in that time.  With each semester, we iteratively improved the TrACE system through an iterative design-based research process guided by feedback from actual classroom instructors and their students.  We found that the nature of video content plays a major role in shaping interaction, with narrated lecture-style videos engendering short question-response patterns and limited student-to-student interaction but case-analysis videos fostering longer debate-style discussion threads.  We found that providing flexibly configurable public and private discussion features that could be tailored to specific classes was a key element in supporting teachers' formative assessment practices.  We also observed that enabling students to make individual choices about whether to post content anonymously to their peers was important for encouraging overall participation.   Because TrACE enabled fine-grained logging of student interactions with video content, this project also explored how to construct analytics tools to help teachers better understand their students' work in the system.  We discovered that teachers universally desire more data about their students, but that they often lack the time to explore detailed reports during the academic term, limiting their ability to make data-driven decisions in real time.  To alleviate this difficulty, we designed and tested a set of expectation-driven analytic tools which let teachers describe what they hope their students do with a video in a natural way.  These expectations were automatically used to generate reports for teachers and award completion badges for students.  Use of the expectation-driven analytics was markedly higher among instructors compared to traditional user activity tables and graphs, and they became integrated into several formal course participation policies.  This project directly impacted thousands of students studying in STEM disciplines (e.g., Computer Science, Mathematics, Rehabilitation Science, etc.) through the courses where TrACE was used, and insights about the opportunities and challenges gleaned from these courses may continue to shape how video is integrated in future learning environments.  Further, the project also supported the training of future researchers in STEM by contributing to the successful completion of 1 doctoral dissertation and 3 master's theses, and by enabling 11 undergraduate students to gain valuable first-hand experience with human-centered computing and learning sciences research.          Last Modified: 01/04/2019       Submitted by: Brian Dorn]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
