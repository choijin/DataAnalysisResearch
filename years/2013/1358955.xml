<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Neural Mechanisms for Perceptual Decision Making in Humans</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2014</AwardEffectiveDate>
<AwardExpirationDate>12/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>530898.00</AwardTotalIntnAmount>
<AwardAmount>530898</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kurt Thoroughman</SignBlockName>
<PO_EMAI>kthoroug@nsf.gov</PO_EMAI>
<PO_PHON>7032920000</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In daily life, humans are constantly faced with decisions about what they see, hear or feel - decisions that, though simple, are critical to acting in accordance with their goals. For example, when driving, how close one's car is to the car in front must be continuously monitored so that the appropriate action - stepping on the break - can be performed in a timely manner. Despite the simplicity of such decisions, our actions are highly variable because many factors influence the decision process in the brain, for example, (1) how much we know in terms of when to expect a relevant event, (2) whether it is more important to act rapidly or to take longer in order to be more accurate, (3) in what location we expect a relevant sensory event to occur, and (4) how much practice we have had in making a given type of decision. There is currently very little empirical knowledge on these factors because the decision process itself is very difficult to measure noninvasively in humans. With support from the National Science Foundation, Dr. Simon Kelly of the City College of New York (CCNY), along with collaborator Dr Redmond O'Connell of Trinity College Dublin, will measure electrical activity from specific regions of the human brain using electroencephalography (EEG) and mathematical algorithms for source separation while participants perform decision making tasks that rely on each of the four aforementioned factors. Crucially, a new paradigm design and signal analysis framework and algorithms will be used which provides the unprecedented ability to measure distinct neural elements of the decision process, namely, 1) the representation of the sensory information itself, 2) the accumulation of that information over time, and 3) the planning of action in accordance with the emerging decision. The findings, taken together, will shed light on some of the most enigmatic aspects of how humans perceive and behave in their sensory environments.&lt;br/&gt;&lt;br/&gt;A vast array of neurological and psychiatric disorders are associated with deficits in speed and/or accuracy on laboratory tasks in which they make responses to sensations according to task instructions. The advances made in the current project will open the unprecedented possibility to parse such deficits on the neural systems level, and establish the specific stage of processing and nature of computations that are impaired. This has great potential impact on diagnosis and treatment in mental health. All data and code from this project will be made available online for anyone aspiring to gain further insights from the data, or generate new data using these paradigms. The project entails close collaboration between biomedical engineers and psychologists, and stands to promote such interdisciplinary synergy more generally in the neuroscience community. All experiments lend themselves to student participation and highly valuable learning experiences, which will be strongly encouraged. Early-stage researchers at the postdoctoral, doctoral and undergraduate level will be trained as a part of this project. The demographic make-up of the research team at CCNY strongly counters the prevailing representation in science and engineering, with 8 of the total 11 lab members belonging to under-represented groups in STEM disciplines. All members will gain research training and experience, as well as cross-cultural exposure through the international collaboration with Trinity College.</AbstractNarration>
<MinAmdLetterDate>05/06/2014</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1358955</AwardID>
<Investigator>
<FirstName>Simon</FirstName>
<LastName>Kelly</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Simon Kelly</PI_FULL_NAME>
<EmailAddress>skelly2@ccny.cuny.edu</EmailAddress>
<PI_PHON>2126508626</PI_PHON>
<NSF_ID>000626671</NSF_ID>
<StartDate>05/06/2014</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Redmond</FirstName>
<LastName>O'Connell</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Redmond O'Connell</PI_FULL_NAME>
<EmailAddress>reoconne@tcd.ie</EmailAddress>
<PI_PHON/>
<NSF_ID>000626724</NSF_ID>
<StartDate>05/06/2014</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>CUNY City College</Name>
<CityName>New York</CityName>
<ZipCode>100319101</ZipCode>
<PhoneNumber>2126505418</PhoneNumber>
<StreetAddress>Convent Ave at 138th St</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>603503991</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073268849</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[CUNY City College]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100319101</ZipCode>
<StreetAddress><![CDATA[Convent Ave at 138th St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~356664</FUND_OBLG>
<FUND_OBLG>2015~174234</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><!--   @page { margin: 0.79in }   p { margin-bottom: 0.1in; line-height: 120% } --> <p><span style="color: #0000ff;"><span style="font-family: Arial;"><span style="font-size: x-small;"><span>Perceptual decisions involve the translation of sensory information - e.g. what we see or hear - into appropriate actions. We perform countless translations like this every day yet we don&rsquo;t fully understand how even the simplest of these are accomplished by the brain. The goal of this research project was to gain new insights into how humans make perceptual decisions from event-related potentials (ERPs) recorded on the scalp surface while people make decisions. We capitalized on a new experimental design that enables us to trace the dynamics of the brain&rsquo;s 3 main information processing stages in parallel: 1) the representation of sensory &ldquo;evidence,&rdquo; 2) the accumulation of this evidence over time, and 3) the preparation of a movement used to act upon the decision. We addressed 4 major outstanding questions and amassed an array of significant findings:</span></span></span></span></p> <p><br /><br /></p> <p><span style="color: #0000ff;"><span style="font-family: Arial;"><span style="font-size: x-small;"><span>1) How are decisions formed in continuous monitoring conditions? This is the situation faced in many common scenarios such as driving a car. To examine this we designed a new visual stimulus that provides reliable measures of the brain&rsquo;s representation of how bright the stimulus is, and asked subjects to detect decreases or increases in intensity. We found that even spontaneous variations in the brain&rsquo;s sensory representation during periods where the stimulus itself is physically not changing had a significant impact on the neural signals reflecting decision formation. In a spin-off study we also found that tiny eye movements known to occur while fixating on a stimulus significantly &ldquo;trip-up&rdquo; decision formation by disturbing all processing stages from sensory to motor. </span></span></span></span></p> <p><br /><br /></p> <p><span style="color: #0000ff;"><span style="font-family: Arial;"><span style="font-size: x-small;"><span>2) When we have advance knowledge of what form a stimulus is likely to take or how long we will have to respond to it, we can adjust our mechanisms of decision formation to ensure that we respond in the best way possible. How does the brain do this? In this aim, we first examined adjustments for speed pressure using a novel paradigm allowing simultaneous recording of sensory encoding, evidence accumulation, motor preparation and even muscle activation, and found that speed pressure induced a change at every level but not all of the same nature. Whereas &ldquo;urgency&rdquo; signals that grow with elapsed time are added to motor preparation signals causing them to &ldquo;hurry&rdquo; towards an action-triggering threshold at the expense of choice accuracy, there is a boost to sensory representations that partially counteracts this accuracy cost. In another study we developed a new computational model of the decision process and its adjustment for such task demands based on these findings and demonstrated its superiority in accounting for decision signals and behavior compared to standard models. </span></span></span></span></p> <p><br /><br /></p> <p><span style="color: #0000ff;"><span style="font-family: Arial;"><span style="font-size: x-small;"><span>3) How is it that attending to a source of evidence leads to faster and more accurate decisions? Here we examined a situation where there are two sources from which relevant information can intermittently and unpredictably arise, and found that the successful, timely detection of such relevant information relies on a &ldquo;target selection&rdquo; signal that occurs shortly after the transition to coherent evidence and predicts the rate at which evidence is accumulated toward a threshold. We also established that this signal equates to an ERP component known as the &ldquo;N2pc&rdquo; which for decades has been linked to the orienting of attention in space, and our paradigm enabled us to gain new insights into its function.</span></span></span></span></p> <p><br /><br /></p> <p><span style="color: #0000ff;"><span style="font-family: Arial;"><span style="font-size: x-small;"><span>4) As we know from sports, we get better at sensory-guided actions the more we practice. But what are the changes underlying these improvements in the brain? Using our new paradigm we established that initial improvements in response speed come about due to a boost in the sensory representation of the evidence, and later improvements in accuracy come about due to increases in the decision bound. The data for this aim also revealed a novel and interesting effect whereby, due to randomness in the timing of the relevant but subtle change in the stimulus, subjects did not know exactly when the evidence would start displaying, and dealt with this by beginning to accumulate sensory information in advance of any evidence, highlighting a novel strategy in decision making under temporal uncertainty. </span></span></span></span></p> <p><br /><br /></p> <p><span style="color: #0000ff;"><span style="font-family: Arial;"><span style="font-size: x-small;"><span>Based on a recent paradigm innovation, this NSF-funded research covered much new territory taking together the core findings, the follow-ups to unexpected findings, the further use of the same tasks, and the neurally-informed modeling approach seeded by the work. We have published 9 papers acknowledging support from the grant and 5 more are to appear soon. The work promotes novel ways to use ERPs to study well-defined mechanisms underlying cognitive operations and provides new tasks and dependent measures for insightful clinical investigations.</span></span></span></span></p> <p><br /><br /><br /></p> <p>&nbsp;</p><br> <p>            Last Modified: 04/30/2019<br>      Modified by: Simon&nbsp;Kelly</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Perceptual decisions involve the translation of sensory information - e.g. what we see or hear - into appropriate actions. We perform countless translations like this every day yet we don?t fully understand how even the simplest of these are accomplished by the brain. The goal of this research project was to gain new insights into how humans make perceptual decisions from event-related potentials (ERPs) recorded on the scalp surface while people make decisions. We capitalized on a new experimental design that enables us to trace the dynamics of the brain?s 3 main information processing stages in parallel: 1) the representation of sensory "evidence," 2) the accumulation of this evidence over time, and 3) the preparation of a movement used to act upon the decision. We addressed 4 major outstanding questions and amassed an array of significant findings:      1) How are decisions formed in continuous monitoring conditions? This is the situation faced in many common scenarios such as driving a car. To examine this we designed a new visual stimulus that provides reliable measures of the brain?s representation of how bright the stimulus is, and asked subjects to detect decreases or increases in intensity. We found that even spontaneous variations in the brain?s sensory representation during periods where the stimulus itself is physically not changing had a significant impact on the neural signals reflecting decision formation. In a spin-off study we also found that tiny eye movements known to occur while fixating on a stimulus significantly "trip-up" decision formation by disturbing all processing stages from sensory to motor.       2) When we have advance knowledge of what form a stimulus is likely to take or how long we will have to respond to it, we can adjust our mechanisms of decision formation to ensure that we respond in the best way possible. How does the brain do this? In this aim, we first examined adjustments for speed pressure using a novel paradigm allowing simultaneous recording of sensory encoding, evidence accumulation, motor preparation and even muscle activation, and found that speed pressure induced a change at every level but not all of the same nature. Whereas "urgency" signals that grow with elapsed time are added to motor preparation signals causing them to "hurry" towards an action-triggering threshold at the expense of choice accuracy, there is a boost to sensory representations that partially counteracts this accuracy cost. In another study we developed a new computational model of the decision process and its adjustment for such task demands based on these findings and demonstrated its superiority in accounting for decision signals and behavior compared to standard models.       3) How is it that attending to a source of evidence leads to faster and more accurate decisions? Here we examined a situation where there are two sources from which relevant information can intermittently and unpredictably arise, and found that the successful, timely detection of such relevant information relies on a "target selection" signal that occurs shortly after the transition to coherent evidence and predicts the rate at which evidence is accumulated toward a threshold. We also established that this signal equates to an ERP component known as the "N2pc" which for decades has been linked to the orienting of attention in space, and our paradigm enabled us to gain new insights into its function.      4) As we know from sports, we get better at sensory-guided actions the more we practice. But what are the changes underlying these improvements in the brain? Using our new paradigm we established that initial improvements in response speed come about due to a boost in the sensory representation of the evidence, and later improvements in accuracy come about due to increases in the decision bound. The data for this aim also revealed a novel and interesting effect whereby, due to randomness in the timing of the relevant but subtle change in the stimulus, subjects did not know exactly when the evidence would start displaying, and dealt with this by beginning to accumulate sensory information in advance of any evidence, highlighting a novel strategy in decision making under temporal uncertainty.       Based on a recent paradigm innovation, this NSF-funded research covered much new territory taking together the core findings, the follow-ups to unexpected findings, the further use of the same tasks, and the neurally-informed modeling approach seeded by the work. We have published 9 papers acknowledging support from the grant and 5 more are to appear soon. The work promotes novel ways to use ERPs to study well-defined mechanisms underlying cognitive operations and provides new tasks and dependent measures for insightful clinical investigations.               Last Modified: 04/30/2019       Submitted by: Simon Kelly]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
