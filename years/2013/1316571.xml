<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Investigating Simulations of Teaching Practice: Assessing Readiness to Teach Elementary Mathematics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2016</AwardExpirationDate>
<AwardTotalIntnAmount>449829.00</AwardTotalIntnAmount>
<AwardAmount>449829</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Finbarr Sloane</SignBlockName>
<PO_EMAI>fsloane@nsf.gov</PO_EMAI>
<PO_PHON>7032928465</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Abstract&lt;br/&gt;&lt;br/&gt;The PI argues cogently that assessment of pre-service teacher preparedness to teach is based on a flawed model.  The goal then is to use a simulation model from other professional arenas: the training of doctors, nurses, etc., to offer new insights and control for the many variables that come to play when conducting evaluations in practice. These might include classroom context, the difficulty of the mathematics being deployed, etc.  To do this the PI will develop three assessments that vary in the simulation scenario. In the context of developing and validating these assessments, the PI will examine:&lt;br/&gt;&lt;br/&gt;1. What do we learn about the nature of pre-service teachers skills at eliciting and interpreting students thinking and their mathematical knowledge for teaching (MKT) in use through assessments that simulate teaching practice? How does their performance correspond with eliciting and interpreting students mathematical thinking in classroom contexts?&lt;br/&gt;2. How does the nature of pre-service teachers skills at eliciting and interpreting students thinking and mathematical knowledge vary in relation to different simulation scenarios? Are some simulation scenarios easier than other simulation scenarios?&lt;br/&gt;3. What are the challenges of designing alternative versions of a particular simulation assessment?</AbstractNarration>
<MinAmdLetterDate>09/18/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/18/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1316571</AwardID>
<Investigator>
<FirstName>Hyman</FirstName>
<LastName>Bass</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hyman Bass</PI_FULL_NAME>
<EmailAddress>hybass@umich.edu</EmailAddress>
<PI_PHON>7346154043</PI_PHON>
<NSF_ID>000458143</NSF_ID>
<StartDate>09/18/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Deborah</FirstName>
<LastName>Ball</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Deborah L Ball</PI_FULL_NAME>
<EmailAddress>dball@umich.edu</EmailAddress>
<PI_PHON>3136473713</PI_PHON>
<NSF_ID>000091275</NSF_ID>
<StartDate>09/18/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Tim</FirstName>
<LastName>Boerst</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tim Boerst</PI_FULL_NAME>
<EmailAddress>tboerst@umich.edu</EmailAddress>
<PI_PHON>7346159048</PI_PHON>
<NSF_ID>000540122</NSF_ID>
<StartDate>09/18/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Meghan</FirstName>
<LastName>Shaughnessy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Meghan Shaughnessy</PI_FULL_NAME>
<EmailAddress>mshaugh@bu.edu</EmailAddress>
<PI_PHON>5102958824</PI_PHON>
<NSF_ID>000635758</NSF_ID>
<StartDate>09/18/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073133571</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073133571</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan Ann Arbor]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091271</ZipCode>
<StreetAddress><![CDATA[3003 S. State St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7645</Code>
<Text>Discovery Research K-12</Text>
</ProgramElement>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~449829</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="MsoNormal"><span style="font-size: 10.0pt; font-family: Arial;">Ensuring that beginning teachers are &ldquo;classroom-ready&rdquo; requires assessments that efficiently and validly evaluate proficiency in teaching. This project explored simulations as a way to assess teaching practice, which could provide an important complement, or alternative, to directly assessing teaching practice in classrooms. This form of assessment has the potential to provide a way to avoid onerous expense, logistics, and other difficulties of assessments happening in classrooms and builds on <span style="color: black;">the use of simulations in professional training in many other fields, such as nursing, dentistry, and law.</span></span></p> <p class="MsoNormal"><span style="font-size: 10.0pt; font-family: Arial; color: black;">We developed and investigated simulation assessments focused on the knowledge and skill preservice teachers demonstrate as they engage in teaching practices. In the simulation, preservice teachers interact with a person following a mathematical learner profile specifying a student&rsquo;s process, understanding, and way of engaging with respect to a specific mathematical problem. The simulations focused specifically on one particularly important area of mathematics, number and operations, and the teaching practices of eliciting children&rsquo;s thinking and interpreting children&rsquo;s mathematical thinking. Different simulations were designed by varying three important characteristics of a student&rsquo;s mathematical thinking within number and operation: the mathematical strategy (standard, alternative, or invented); the nature of mathematical understanding (conceptual, procedural, or mixed); and the outcome of the student&rsquo;s mathematical work (correct answer or incorrect answer</span><span style="font-size: 10.0pt; font-family: Arial;">). Each simulation went through a development process involving iterative cycles of use with preservice teachers at different points in their teacher education program, careful study of the preservice teacher performances that were elicited, and revision of the simulation to address shortcomings of content, enactment, and interpretation. Once a simulation was in its final form, training materials were developed to support the use of the assessment.</span></p> <p class="MsoNormal"><span style="font-family: Arial; font-size: 10pt;">Our research focused on what could be learned about preservice teachers&rsquo; skills with eliciting and interpreting students&rsquo; thinking, and their mathematical knowledge for teaching in use, through assessments that simulate teaching practice. Once facet of this research focused on the correspondence of a preservice teachers&rsquo; performance in a simulation and performance in a classroom context. Many of the same components of the practice of eliciting student thinking were visible in both contexts. When these components were not visible in both contexts it was often the case that the variability of the classroom context did not present the preservice teachers with the opportunity to demonstrate their skills in eliciting thinking (such as when students would elaborate their thinking about a problem in response to a single question from the preservice teacher).</span><span style="mso-spacerun: yes;">&nbsp;</span><span style="font-family: Arial; font-size: 10pt;">Another facet of this research focused on how preservice teachers&rsquo; performances varied across simulations with different characteristics. Some combinations of characteristics, such as a combination of the student&rsquo;s use of an alternative strategy, understanding of the strategy, and a correct solution, evoked robust eliciting and interpretation responses from preservice teachers. Some combinations of characteristics created assessments that proved to be &ldquo;easier&rdquo; or &ldquo;more difficult&rdquo; than other combinations. An additional facet of this research focused on learning about the nature of preservice teachers&rsquo; skill with eliciting and interpreting students&rsquo; thinking as shown through simulations at different points in their development. We learned that preservice teachers in one university-based teacher education program are less likely to ask about the student&rsquo;s understanding of a strategy than to ask about the procedural steps in a student&rsquo;s strategy. Further, we learned that it was possible to see difference in performances that signaled mathematical knowledge for teaching such as skill in posing a follow-up problem that would present the same conditions as the original problem.</span></p> <p class="MsoNormal"><span style="font-family: Arial; font-size: 10pt;">Through this exploratory project we have contributed substantially to the field in several respects. First, building on work in other practice-centered professional fields, we were able to develop and use simulation assessments to learn about the teaching skill and mathematical knowledge of preservice teachers. Second, the development of the simulations and associated scoring tools provide examples of what Grossman and colleagues (2008) have called &ldquo;decompositions of practice&rdquo; that are essential for supporting preservice teachers&rsquo; learning of complex professional practices. Third, and related, as teacher education moves to focus more squarely on teaching practice, our work provides an important tool, namely a means of assessing skills with key teaching practices at different points within a teacher education program.</span></p><br> <p>            Last Modified: 12/20/2016<br>      Modified by: Tim&nbsp;Boerst</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Ensuring that beginning teachers are "classroom-ready" requires assessments that efficiently and validly evaluate proficiency in teaching. This project explored simulations as a way to assess teaching practice, which could provide an important complement, or alternative, to directly assessing teaching practice in classrooms. This form of assessment has the potential to provide a way to avoid onerous expense, logistics, and other difficulties of assessments happening in classrooms and builds on the use of simulations in professional training in many other fields, such as nursing, dentistry, and law. We developed and investigated simulation assessments focused on the knowledge and skill preservice teachers demonstrate as they engage in teaching practices. In the simulation, preservice teachers interact with a person following a mathematical learner profile specifying a student?s process, understanding, and way of engaging with respect to a specific mathematical problem. The simulations focused specifically on one particularly important area of mathematics, number and operations, and the teaching practices of eliciting children?s thinking and interpreting children?s mathematical thinking. Different simulations were designed by varying three important characteristics of a student?s mathematical thinking within number and operation: the mathematical strategy (standard, alternative, or invented); the nature of mathematical understanding (conceptual, procedural, or mixed); and the outcome of the student?s mathematical work (correct answer or incorrect answer). Each simulation went through a development process involving iterative cycles of use with preservice teachers at different points in their teacher education program, careful study of the preservice teacher performances that were elicited, and revision of the simulation to address shortcomings of content, enactment, and interpretation. Once a simulation was in its final form, training materials were developed to support the use of the assessment. Our research focused on what could be learned about preservice teachers? skills with eliciting and interpreting students? thinking, and their mathematical knowledge for teaching in use, through assessments that simulate teaching practice. Once facet of this research focused on the correspondence of a preservice teachers? performance in a simulation and performance in a classroom context. Many of the same components of the practice of eliciting student thinking were visible in both contexts. When these components were not visible in both contexts it was often the case that the variability of the classroom context did not present the preservice teachers with the opportunity to demonstrate their skills in eliciting thinking (such as when students would elaborate their thinking about a problem in response to a single question from the preservice teacher). Another facet of this research focused on how preservice teachers? performances varied across simulations with different characteristics. Some combinations of characteristics, such as a combination of the student?s use of an alternative strategy, understanding of the strategy, and a correct solution, evoked robust eliciting and interpretation responses from preservice teachers. Some combinations of characteristics created assessments that proved to be "easier" or "more difficult" than other combinations. An additional facet of this research focused on learning about the nature of preservice teachers? skill with eliciting and interpreting students? thinking as shown through simulations at different points in their development. We learned that preservice teachers in one university-based teacher education program are less likely to ask about the student?s understanding of a strategy than to ask about the procedural steps in a student?s strategy. Further, we learned that it was possible to see difference in performances that signaled mathematical knowledge for teaching such as skill in posing a follow-up problem that would present the same conditions as the original problem. Through this exploratory project we have contributed substantially to the field in several respects. First, building on work in other practice-centered professional fields, we were able to develop and use simulation assessments to learn about the teaching skill and mathematical knowledge of preservice teachers. Second, the development of the simulations and associated scoring tools provide examples of what Grossman and colleagues (2008) have called "decompositions of practice" that are essential for supporting preservice teachers? learning of complex professional practices. Third, and related, as teacher education moves to focus more squarely on teaching practice, our work provides an important tool, namely a means of assessing skills with key teaching practices at different points within a teacher education program.       Last Modified: 12/20/2016       Submitted by: Tim Boerst]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
