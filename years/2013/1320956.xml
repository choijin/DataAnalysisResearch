<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Open Vision - Tools for Open Set Computer Vision and Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>12/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>449894.00</AwardTotalIntnAmount>
<AwardAmount>449894</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When humans "recognize" things one of answers can always be "unknown" or "that's new."  Existing vision and machine learning research has made great progress but have done so in a closed set paradigm - which explicitly minimizes risk/errors over what is known.  As a computer vision system is moved toward real problems, it must face up to an open world. This project develops technologies for a new fundamental theory of "open vision" and corresponding set of tools that are explicitly designed to address open set recognition. At the heart of this research are three key concepts: 1) extending classical learning theory to include the risks of labeling open/unknown spaces, and then building classifiers that balance empirical risk, smoothness and open space risk; 2) meta-recognition - bringing a statistically-grounded probabilistic interpretation to classifiers, improving their ability to produce "confidence" in their answers; 3) operational adaptation - developing new approaches to address, at operation/run time, missing data or new data incorporating both open set and meta-recognition technologies. The work is also developing new approaches for open set evaluation, addressing problems in face recognition and visual object recognition as well as adapting classical machine learning datasets.&lt;br/&gt;&lt;br/&gt;The open vision paradigm is embodied in open source tools that provide  performance at or significantly advancing the state of the art  while providing greater protection form unknown unknowns.   Since most science is exploring the unknown, providing easy to use open source learning/recognition tools design for both known and unknown data, the project have broad impact to many different applications.</AbstractNarration>
<MinAmdLetterDate>08/21/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320956</AwardID>
<Investigator>
<FirstName>Terrance</FirstName>
<LastName>Boult</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Terrance E Boult</PI_FULL_NAME>
<EmailAddress>tboult@vast.uccs.edu</EmailAddress>
<PI_PHON>7192553510</PI_PHON>
<NSF_ID>000212325</NSF_ID>
<StartDate>08/21/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Colorado at Colorado Springs</Name>
<CityName>Colorado Springs</CityName>
<ZipCode>809183733</ZipCode>
<PhoneNumber>7192553153</PhoneNumber>
<StreetAddress>1420, Austin Bluffs Parkway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CO05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>186192829</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF COLORADO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007431505</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Univ. of Colorado Colorado Springs]]></Name>
<CityName>Colorado Springs</CityName>
<StateCode>CO</StateCode>
<ZipCode>809183733</ZipCode>
<StreetAddress><![CDATA[1420 Austin Bluffs Parkway, Camp]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CO05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~449894</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Traditional machine learning, both statistical and deep network-based, assume all inputs would fall into one of the training classes.&nbsp; In real systems, it is almost always possible for something unexpected to show up.&nbsp; While traditional systems would choose one of the known classes, an open-set recognition system would be able to label the unknown inputs as unknown.&nbsp; For example, one would probably want an autonomous car to stop when an unknown object was in front of it.&nbsp; Unfortunately, one cannot train a system with all possible unknown objects; there will always be unknown unknowns not seed during training.&nbsp;</p> <p><br />The Intellectual merit of the OpenVision project was formalizing the concept of open set recognition problems where the system must learn to label as unknown inputs that were not seen in training and should have bounded error for the space of unknown objects.&nbsp; The effort develop new approaches to machine learning and vision systems that formally bound the potential error from unknown inputs, developing extensions for traditional SVM-based and deep-network approaches to the problem.&nbsp; &nbsp;It was the first research to show how deep networks could formally have bounded error in "rejecting" unknown inputs.&nbsp; The OpenVision effort pioneered the use of statistical extreme value theory in vision, and our novel extreme value machine used it to develop a new way of looking at "margins" in machine learning, see the associated figure.&nbsp; In that figure, we show 2D features for examples from four classes and the associated extreme value response. The EVM models can easily reject the unknown "?" instances and naturally vary their confidence based on data density.&nbsp; &nbsp; &nbsp;The effort released the developed algorithms as open-source so everyone can benefit from them, and hundreds of other researchers have downloaded/used the code produce base.&nbsp;&nbsp;</p> <p><br />Regarding broader impact, the open vision project applied these new algorithms to a range of problems from tracking/counting endangered species, to the recognition of tattoos, analysis to extract facial attributes from images.&nbsp; The project delivered operational systems/code to government agencies.&nbsp; The effort also developed tutorials, workshops, and challenges including releasing new datasets to help other researchers evaluate open set algorithms, with hundreds of other research groups downloading that data.&nbsp; &nbsp;The OpenVision project supported both graduate students and undergraduate students including with multiple students from under-represented populations not just getting involved in the research, but publishing papers and going on for their Ph.D.&nbsp;<br /><br /><br /></p><br> <p>            Last Modified: 04/04/2018<br>      Modified by: Terrance&nbsp;E&nbsp;Boult</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2018/1320956/1320956_10269554_1522849624034_ScreenShot2018-04-04at7.43.55AM--rgov-214x142.jpg" original="/por/images/Reports/POR/2018/1320956/1320956_10269554_1522849624034_ScreenShot2018-04-04at7.43.55AM--rgov-800width.jpg" title="Extreme Value Machine (EVM) with incremental class"><img src="/por/images/Reports/POR/2018/1320956/1320956_10269554_1522849624034_ScreenShot2018-04-04at7.43.55AM--rgov-66x44.jpg" alt="Extreme Value Machine (EVM) with incremental class"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Example from the Extreme Value Machine (EVM) trained on four 2D classes: dots, diamonds, squares, and stars can reject the unknown "?" inputs. New data such as the "+" class can be added, and the EVM adapts, e.g., note the changes in class A's models.</div> <div class="imageCredit">T. Boult</div> <div class="imagePermisssions">Creative Commons</div> <div class="imageSubmitted">Terrance&nbsp;E&nbsp;Boult</div> <div class="imageTitle">Extreme Value Machine (EVM) with incremental class</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Traditional machine learning, both statistical and deep network-based, assume all inputs would fall into one of the training classes.  In real systems, it is almost always possible for something unexpected to show up.  While traditional systems would choose one of the known classes, an open-set recognition system would be able to label the unknown inputs as unknown.  For example, one would probably want an autonomous car to stop when an unknown object was in front of it.  Unfortunately, one cannot train a system with all possible unknown objects; there will always be unknown unknowns not seed during training.    The Intellectual merit of the OpenVision project was formalizing the concept of open set recognition problems where the system must learn to label as unknown inputs that were not seen in training and should have bounded error for the space of unknown objects.  The effort develop new approaches to machine learning and vision systems that formally bound the potential error from unknown inputs, developing extensions for traditional SVM-based and deep-network approaches to the problem.   It was the first research to show how deep networks could formally have bounded error in "rejecting" unknown inputs.  The OpenVision effort pioneered the use of statistical extreme value theory in vision, and our novel extreme value machine used it to develop a new way of looking at "margins" in machine learning, see the associated figure.  In that figure, we show 2D features for examples from four classes and the associated extreme value response. The EVM models can easily reject the unknown "?" instances and naturally vary their confidence based on data density.     The effort released the developed algorithms as open-source so everyone can benefit from them, and hundreds of other researchers have downloaded/used the code produce base.     Regarding broader impact, the open vision project applied these new algorithms to a range of problems from tracking/counting endangered species, to the recognition of tattoos, analysis to extract facial attributes from images.  The project delivered operational systems/code to government agencies.  The effort also developed tutorials, workshops, and challenges including releasing new datasets to help other researchers evaluate open set algorithms, with hundreds of other research groups downloading that data.   The OpenVision project supported both graduate students and undergraduate students including with multiple students from under-represented populations not just getting involved in the research, but publishing papers and going on for their Ph.D.           Last Modified: 04/04/2018       Submitted by: Terrance E Boult]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
