<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Closing the Loop: Inducing High-Precision Grammars for Generating Disambiguating Paraphrases</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>11/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>299982.00</AwardTotalIntnAmount>
<AwardAmount>307982</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project investigates trainable methods of paraphrasing natural language sentences to effectively disambiguate their meaning, using precise, bidirectional grammars induced from corpora to "close the loop"' between parsing and generation.  The approach generalizes previous work on probabilistically avoiding ambiguity in natural language generation to a broad coverage setting, disambiguating only as necessary in order to better balance clarity and readability. Generating disambiguating paraphrases in a broad coverage setting makes it possible to explore ways of adapting parsers to new domains using crowd-sourced judgments of meaning similarity.  Accordingly, the project explores methods of (1) inducing OpenCCG grammars from the dependency output of parsers such as the C&amp;C parser, (2) generating paraphrases with OpenCCG that explicitly aim to avoid likely distractor interpretations, (3) collecting meaning similarity judgments between the original sentence and paraphrases of its most likely interpretations, and (4) retraining the parser using the collected judgments. To evaluate the approach while also conducting outreach, the project involves data collection and experimentation at Ohio State's language research pod at the COSI science museum, in addition to the use of Amazon's Mechanical Turk.&lt;br/&gt;&lt;br/&gt;By closing the loop between interpretation and generation, the project  promises to dramatically enhance the prospects for using crowd-sourcing to adapt natural language processing tools to new domains.  The project will also enable international collaborations with the University of Sydney, and help to educate the public about language science and technology, providing an inspirational example of science in action to the children who attend COSI.</AbstractNarration>
<MinAmdLetterDate>08/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>11/07/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1319318</AwardID>
<Investigator>
<FirstName>Michael</FirstName>
<LastName>White</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Michael White</PI_FULL_NAME>
<EmailAddress>mwhite@ling.ohio-state.edu</EmailAddress>
<PI_PHON>6142929974</PI_PHON>
<NSF_ID>000069401</NSF_ID>
<StartDate>08/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~299982</FUND_OBLG>
<FUND_OBLG>2014~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Crowdsourcing today plays an increasingly important role in collecting data to develop language technology components.&nbsp; However, the need to collect data with linguistic annotations continues to be an obstacle to cost effective data acquisition.&nbsp; In this project, we demonstrated important steps towards overcoming this obstacle by developing methods for using automatically generated disambiguating paraphrases to support crowdsourcing annotations of sentences with structural ambiguity.&nbsp; The main idea is illustrated in Figure 1.&nbsp; The system takes as input English sentences and runs them through an automatic parser.&nbsp; If the parser finds that a sentence has two likely interpretations, indicating a structural ambiguity, it generates a paraphrase corresponding to each interpretation (using a surface realizer) in a way that is intended to clarify the ambiguity.&nbsp; Note that while the interpretations resulting from parsing are represented in a way that requires linguistic training to understand, the generated paraphrases are in English.&nbsp; As such, it becomes possible to simply ask a crowdworker (on a platform such as Amazon Mechanical Turk, or AMT) which paraphrase is closer in meaning to the original sentence.&nbsp; Depending on which paraphrase is selected, the corresponding interpretation will then be added to the dataset as the right meaning of the sentence.&nbsp; (The figure labels the dataset as silver as it may be noisier than gold data annotated by linguistically trained annotators.)&nbsp; This dataset can then be used to retrain the parser, which can be expected to be especially helpful when the parser is to be used on language outside the domain of its original training data.</p> <p>Through a series of papers, the project initially demonstrated for the first time that parsers can be used to help avoid confusing ambiguities when generating text with modern statistically trained realizers.&nbsp; Then, the project augmented this approach with several additional strategies to effectively generated disambiguating paraphrases for the most frequently observed kinds of structural ambiguity.&nbsp; To demonstrate success, the project showed that the method illustrated in Figure 1 reliably reproduced expert judgments and that the resulting crowdsourced data could be used to improve parsing accuracy.&nbsp; Subsequently, researchers at the University of Washington were inspired in part by the project to crowdsource annotations in a similar spirit, using automatically generated clarification questions rather than disambiguating paraphrases per se.&nbsp; While these clarification questions tend to be simpler, they cannot address the whole range of structural ambiguities tackled by the project, suggesting that the methods could be usefully combined as part of a larger-scale effort to continually improve language technology components via conversational interaction.</p> <p>The project additionally supported initial experiments with a new grammar formalism, Dynamic Continuized Combinatory Categorial Grammar, that brings together theoretical advances in the treatment of quantified phrases in natural language with more computationally attractive approaches, yielding a framework for pursing the clarification of quantificational ambiguities in future work.</p> <p>Turning to broader impacts, the project supported the training of one undergraduate and five graduate students, including two female students who remain underrepresented in the field.&nbsp; Notably, the project also supported the development of Madly Ambiguous (http://madlyambiguous.osu.edu/), a demonstration and game for teaching the basics of structural (and other forms of linguistic) ambiguity.&nbsp; In Madly Ambiguous, the spunky Mr. Computer Head (Figure 2) narrates as users read about structural ambiguity&#894; after that, users face off against Mr. Computer Head in a game where they try to complete an ambiguous sentence (Figure 3) in a way that makes Mr. Computer Head guess the incorrect interpretation. After finishing a round of the game by informing Mr. Computer Head whether he came up with the correct interpretation (Figure 4), users may read more about how Mr. Computer Head and systems like him are trained to deal with tasks of ambiguity (Figure 2).&nbsp; Ultimately, users learn not only about structural ambiguity, but also a little bit about natural language processing tasks and their difficulty.</p> <p>Madly Ambiguous was initially developed for use at COSI, the Columbus science museum, but was subsequently adapted to support undergraduate teaching.&nbsp; Following a demonstration paper at the North American chapter of the Association for Computational Linguistics conference and an article in The Atlantic, it has been used with success at universities around the country and the world.</p><br> <p>            Last Modified: 03/01/2019<br>      Modified by: Michael&nbsp;White</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485703258_fig1-domainadapt--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485703258_fig1-domainadapt--rgov-800width.jpg" title="Figure 1"><img src="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485703258_fig1-domainadapt--rgov-66x44.jpg" alt="Figure 1"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Using automatically generated paraphrases to crowdsource data for adapting parsers to new domains (see text)</div> <div class="imageCredit">Michael White</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Michael&nbsp;White</div> <div class="imageTitle">Figure 1</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485836011_fig2-explanation--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485836011_fig2-explanation--rgov-800width.jpg" title="Figure 2"><img src="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485836011_fig2-explanation--rgov-66x44.jpg" alt="Figure 2"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The spunky Mr. Computer Head is the host of Madly Ambiguous, teaching users of all ages about structural ambiguity and why it is so difficult for computers</div> <div class="imageCredit">Ajda Gokcen</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Michael&nbsp;White</div> <div class="imageTitle">Figure 2</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485942164_fig3-answer--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485942164_fig3-answer--rgov-800width.jpg" title="Figure 3"><img src="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485942164_fig3-answer--rgov-66x44.jpg" alt="Figure 3"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Users challenge Mr. Computer Head to guess the intended interpretation of their completion of an ambiguous sentence</div> <div class="imageCredit">Ajda Gokcen and Michael White</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Michael&nbsp;White</div> <div class="imageTitle">Figure 3</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485999466_fig4-check--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485999466_fig4-check--rgov-800width.jpg" title="Figure 4"><img src="/por/images/Reports/POR/2019/1319318/1319318_10268137_1551485999466_fig4-check--rgov-66x44.jpg" alt="Figure 4"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Users complete a round of the game by informing Mr. Computer Head whether he came up with the intended interpretation</div> <div class="imageCredit">Ajda Gokcen</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Michael&nbsp;White</div> <div class="imageTitle">Figure 4</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Crowdsourcing today plays an increasingly important role in collecting data to develop language technology components.  However, the need to collect data with linguistic annotations continues to be an obstacle to cost effective data acquisition.  In this project, we demonstrated important steps towards overcoming this obstacle by developing methods for using automatically generated disambiguating paraphrases to support crowdsourcing annotations of sentences with structural ambiguity.  The main idea is illustrated in Figure 1.  The system takes as input English sentences and runs them through an automatic parser.  If the parser finds that a sentence has two likely interpretations, indicating a structural ambiguity, it generates a paraphrase corresponding to each interpretation (using a surface realizer) in a way that is intended to clarify the ambiguity.  Note that while the interpretations resulting from parsing are represented in a way that requires linguistic training to understand, the generated paraphrases are in English.  As such, it becomes possible to simply ask a crowdworker (on a platform such as Amazon Mechanical Turk, or AMT) which paraphrase is closer in meaning to the original sentence.  Depending on which paraphrase is selected, the corresponding interpretation will then be added to the dataset as the right meaning of the sentence.  (The figure labels the dataset as silver as it may be noisier than gold data annotated by linguistically trained annotators.)  This dataset can then be used to retrain the parser, which can be expected to be especially helpful when the parser is to be used on language outside the domain of its original training data.  Through a series of papers, the project initially demonstrated for the first time that parsers can be used to help avoid confusing ambiguities when generating text with modern statistically trained realizers.  Then, the project augmented this approach with several additional strategies to effectively generated disambiguating paraphrases for the most frequently observed kinds of structural ambiguity.  To demonstrate success, the project showed that the method illustrated in Figure 1 reliably reproduced expert judgments and that the resulting crowdsourced data could be used to improve parsing accuracy.  Subsequently, researchers at the University of Washington were inspired in part by the project to crowdsource annotations in a similar spirit, using automatically generated clarification questions rather than disambiguating paraphrases per se.  While these clarification questions tend to be simpler, they cannot address the whole range of structural ambiguities tackled by the project, suggesting that the methods could be usefully combined as part of a larger-scale effort to continually improve language technology components via conversational interaction.  The project additionally supported initial experiments with a new grammar formalism, Dynamic Continuized Combinatory Categorial Grammar, that brings together theoretical advances in the treatment of quantified phrases in natural language with more computationally attractive approaches, yielding a framework for pursing the clarification of quantificational ambiguities in future work.  Turning to broader impacts, the project supported the training of one undergraduate and five graduate students, including two female students who remain underrepresented in the field.  Notably, the project also supported the development of Madly Ambiguous (http://madlyambiguous.osu.edu/), a demonstration and game for teaching the basics of structural (and other forms of linguistic) ambiguity.  In Madly Ambiguous, the spunky Mr. Computer Head (Figure 2) narrates as users read about structural ambiguity&#894; after that, users face off against Mr. Computer Head in a game where they try to complete an ambiguous sentence (Figure 3) in a way that makes Mr. Computer Head guess the incorrect interpretation. After finishing a round of the game by informing Mr. Computer Head whether he came up with the correct interpretation (Figure 4), users may read more about how Mr. Computer Head and systems like him are trained to deal with tasks of ambiguity (Figure 2).  Ultimately, users learn not only about structural ambiguity, but also a little bit about natural language processing tasks and their difficulty.  Madly Ambiguous was initially developed for use at COSI, the Columbus science museum, but was subsequently adapted to support undergraduate teaching.  Following a demonstration paper at the North American chapter of the Association for Computational Linguistics conference and an article in The Atlantic, it has been used with success at universities around the country and the world.       Last Modified: 03/01/2019       Submitted by: Michael White]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
