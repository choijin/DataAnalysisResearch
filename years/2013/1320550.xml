<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:   Optimal Monte Carlo Estimation via Randomized Multilevel Methods</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>209993.00</AwardTotalIntnAmount>
<AwardAmount>209993</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research project will investigate a comprehensive set of tools to enable efficient and unbiased Monte Carlo methods in a wide range of settings such as: steady-state computations and stochastic differential equations (SDEs). The PIs extend the applicability and power of a recently introduced technique called multilevel Monte Carlo (MLMC), which has rapidly grown in popularity and has shown to be highly successful, particularly in the context of numerical solutions to SDEs. The PIs strategy rests on two basic ingredients. First, they abstract the main ideas of MLMC. This abstraction makes it clear that MLMC can be applied to many problem settings (beyond the SDE context), for example in problems such as: estimating steady-state expectations of Markov random fields, and solving distributional fixed point equations. Second, the PIs introduce a simple, yet powerful, extra randomization step. This randomization step will permit to not only completely delete the bias, which so far is present in every single application of the multilevel method, but it will also permit to more easily optimize parameters (often user-defined) that arise in classical multilevel applications. At the core of our abstraction of the MLMC method lies the construction of a suitable sequence of strong (almost sure) approximations under some metric. The freedom that is implicit in constructing such approximations yields a rich research program that touches upon many of the elements of modern probability, including random matrices, Markov random fields, mean field fixed point equations and Lyapunov stability.&lt;br/&gt;    &lt;br/&gt;    The PIs will investigate a methodology that enables high-performance computing in the context of simulation of stochastic systems. The PIs methodology will substantially extend a recently developed approach, called Multilevel Monte Carlo (MLMC), which has typically been applied only to compute numerical solutions of stochastic differential equations (SDEs). More generally, this research project addresses a wide range of problems that lie at the center of modern scientific computing, beyond the important setting of SDEs which arise in virtually all areas of modeling in engineering and science. For example, the PIs will generalize the MLMC approach to accurately perform so-called steady-state simulation for Markov chains indexed by trees. These computational problems arise very often in statistical inference applications, ranging from imaging to classification problems. The PIs research also improves upon the classical MLMC technique by optimizing its design and allowing the study of, for example, steady-state analysis of SDEs (i.e. combining traditional areas of study with new methodological applications). The PIs will in particular apply these optimized computational techniques to solve problems in service and manufacturing engineering. The PIs plan to develop a new jointly designed course, on the topic of this proposal, and the course material will be made available online to increase the dissemination and the potential applicability of the project's findings. The PIs will attempt to recruit high-quality personnel from under-represented groups and will disseminate the scientific output of the research via open access sites, in addition to the standard vehicles such as conferences and journal publications.</AbstractNarration>
<MinAmdLetterDate>07/23/2013</MinAmdLetterDate>
<MaxAmdLetterDate>07/31/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320550</AwardID>
<Investigator>
<FirstName>Jose</FirstName>
<LastName>Blanchet</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jose Blanchet</PI_FULL_NAME>
<EmailAddress>jose.blanchet@stanford.edu</EmailAddress>
<PI_PHON>9177140326</PI_PHON>
<NSF_ID>000489034</NSF_ID>
<StartDate>07/23/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>100276902</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~69234</FUND_OBLG>
<FUND_OBLG>2014~70009</FUND_OBLG>
<FUND_OBLG>2015~70750</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The general goal of this project is to&nbsp;investigate a new computational technique, called "Randomized Multilevel Monte Carlo" (RMLMC), which allows&nbsp;producing unbiased estimators with optimal rate of convergence. The research combines a wide range of advanced tools in probability to obtain algorithms which overcome difficulties which have been unsolved for many years. For example, the PIs deploy the theory of rough paths (which lies at the core of contemporary stochastic analysis), in combination with RMLMC to obtain the first procedure with simulates exactly and without any bias realizations of multidimensional stochastic differential equations. Prior to PIs research, only one-dimensional exact samplers existed, the first of which was produced in 2004. So, it took more than a dozen years&nbsp;and the tools developed in this research to understand how to exactly encode, in a computer, a multidimensional differential equation driven by white noise. Because these processes arise in a wide range of scientific and engineering applications, this proposal can potentially impact various areas of science and engineering in future years.&nbsp; &nbsp;</p> <p>As another example that exposes the&nbsp;novel range of techniques investigated and developed in this proposal is the construction of estimators for so-called multivariate extreme value distributions (also known as max-stable distributions). These are used to model spatial extremes in high dimensions. It turns out that these distributions are challenging to work with both numerically and analytically. So, finding exact and efficient estimators is crucial if one wishes to produce an accurate numerical prediction of extreme events (such as heat waves or floods) in many locations. One of the outcomes of this proposal is the development of algorithms for the&nbsp;exact sampling of multivariate extreme value distributions with optimal rate of convergence.&nbsp;</p> <p>Two pictures are included in this project outcome report. The first one is a realization of a multidimensional reflected Brownian motion (a process of great importance in modeling queueing systems). The second corresponds to the density of a two-dimensional extreme value distribution with a non-trivial dependence amont the coordinates. The remarkable feature in the first picture is that every point in time is random. So, in principle, it is impossible to fully encode the full random path in a computer without incurring in some sort of bias. However, the picture produced is calibrated to be indistinguishable from the perception of a human vision with absolute certainty. The second picture is just the two-dimensional projection of a high dimensional extreme value distribution created with our algorithm.</p> <p>Another outcome which is important to emphasize from this project is the development of a technique to provide unbiased estimators for solutions of stochastic optimization problems. This is particularly interesting in Big Data applications in which a statistical model is fitted in the presence of massive data sets. Often, one uses a small universe (a random subsample) from the original massive data set and fits the model for the subsample. After averaging many subsamples one obtains an estimate of the statistical model, which represents the information on the whole universe (but with random noise from the sampling procedure). Although reasonable, this approach, unfortunately, is biased because the statistical method will overfit on every sample systematically. So, this systematic effect, applied to every subsample, is not removed after averaging. The research of this proposal develops a method which completely removes the systematic bias, therefore allowing to fit statistical models to&nbsp;arbitrarily large data sets using easy parallelization. In simple words, the proposal introduces a subsampling procedure which does not suffer from systemic biases, therefore producing parameter estimates which can be averaged to produce an estimate which is equivalent to optimizing over the whole universe of the data.&nbsp;</p><br> <p>            Last Modified: 10/28/2017<br>      Modified by: Jose&nbsp;Blanchet</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1320550/1320550_10260553_1509233238322_poster--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1320550/1320550_10260553_1509233238322_poster--rgov-800width.jpg" title="Strong simulation of Reflected Brownian Motion"><img src="/por/images/Reports/POR/2017/1320550/1320550_10260553_1509233238322_poster--rgov-66x44.jpg" alt="Strong simulation of Reflected Brownian Motion"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Picture generated with an algorithm with confines the bias of a continuous random path to a level which is imperceptible to human vision.</div> <div class="imageCredit">Based on Volume 27, Number 1 (2017), 275-336.</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jose&nbsp;Blanchet</div> <div class="imageTitle">Strong simulation of Reflected Brownian Motion</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1320550/1320550_10260553_1509233530296_plot_newEstimator_std--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1320550/1320550_10260553_1509233530296_plot_newEstimator_std--rgov-800width.jpg" title="Density of Multivariate Extreme Distribution"><img src="/por/images/Reports/POR/2017/1320550/1320550_10260553_1509233530296_plot_newEstimator_std--rgov-66x44.jpg" alt="Density of Multivariate Extreme Distribution"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This is the output of an unbiased Monte Carlo estimator of a multivariate extreme vale distribution. Showing only a two dimensional projection. The estimator has basically the optimal rate of convergence (square root in sample size) given any dimension.</div> <div class="imageCredit">Based on Zhipeng Liu's implementation.</div> <div class="imagePermisssions">Royalty-free (unrestricted use)</div> <div class="imageSubmitted">Jose&nbsp;Blanchet</div> <div class="imageTitle">Density of Multivariate Extreme Distribution</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The general goal of this project is to investigate a new computational technique, called "Randomized Multilevel Monte Carlo" (RMLMC), which allows producing unbiased estimators with optimal rate of convergence. The research combines a wide range of advanced tools in probability to obtain algorithms which overcome difficulties which have been unsolved for many years. For example, the PIs deploy the theory of rough paths (which lies at the core of contemporary stochastic analysis), in combination with RMLMC to obtain the first procedure with simulates exactly and without any bias realizations of multidimensional stochastic differential equations. Prior to PIs research, only one-dimensional exact samplers existed, the first of which was produced in 2004. So, it took more than a dozen years and the tools developed in this research to understand how to exactly encode, in a computer, a multidimensional differential equation driven by white noise. Because these processes arise in a wide range of scientific and engineering applications, this proposal can potentially impact various areas of science and engineering in future years.     As another example that exposes the novel range of techniques investigated and developed in this proposal is the construction of estimators for so-called multivariate extreme value distributions (also known as max-stable distributions). These are used to model spatial extremes in high dimensions. It turns out that these distributions are challenging to work with both numerically and analytically. So, finding exact and efficient estimators is crucial if one wishes to produce an accurate numerical prediction of extreme events (such as heat waves or floods) in many locations. One of the outcomes of this proposal is the development of algorithms for the exact sampling of multivariate extreme value distributions with optimal rate of convergence.   Two pictures are included in this project outcome report. The first one is a realization of a multidimensional reflected Brownian motion (a process of great importance in modeling queueing systems). The second corresponds to the density of a two-dimensional extreme value distribution with a non-trivial dependence amont the coordinates. The remarkable feature in the first picture is that every point in time is random. So, in principle, it is impossible to fully encode the full random path in a computer without incurring in some sort of bias. However, the picture produced is calibrated to be indistinguishable from the perception of a human vision with absolute certainty. The second picture is just the two-dimensional projection of a high dimensional extreme value distribution created with our algorithm.  Another outcome which is important to emphasize from this project is the development of a technique to provide unbiased estimators for solutions of stochastic optimization problems. This is particularly interesting in Big Data applications in which a statistical model is fitted in the presence of massive data sets. Often, one uses a small universe (a random subsample) from the original massive data set and fits the model for the subsample. After averaging many subsamples one obtains an estimate of the statistical model, which represents the information on the whole universe (but with random noise from the sampling procedure). Although reasonable, this approach, unfortunately, is biased because the statistical method will overfit on every sample systematically. So, this systematic effect, applied to every subsample, is not removed after averaging. The research of this proposal develops a method which completely removes the systematic bias, therefore allowing to fit statistical models to arbitrarily large data sets using easy parallelization. In simple words, the proposal introduces a subsampling procedure which does not suffer from systemic biases, therefore producing parameter estimates which can be averaged to produce an estimate which is equivalent to optimizing over the whole universe of the data.        Last Modified: 10/28/2017       Submitted by: Jose Blanchet]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
