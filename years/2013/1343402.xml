<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AIR Option 1: Technology Translation:  Automated Targeted Destination Recognition for the Blind with Motion Deblurring</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>02/28/2017</AwardExpirationDate>
<AwardTotalIntnAmount>149997.00</AwardTotalIntnAmount>
<AwardAmount>161997</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Barbara H. Kenny</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This PFI: AIR Technology Translation project focuses on translating the research advances in computer vision technologies to fill the gap between research and the real needs in assistive technology for blind people. The goal of this project is to explore solutions for the challenges of designing wearable camera-based wayfinding assistants for blind persons from fundamental research to produce a portable proof-of-concept prototype to help blind users recognize targeted destinations from complex environments. The project accomplishes this goal by 1) developing robust motion deblurring methods to handle the irregular motions of blind users who are wearing the camera and 2) recognizing targeted destinations based on the requests of blind users for wayfinding and navigation. The proof-of-concept prototype system will be developed with visual information captured via a wearable camera on sunglasses/hat and a portable computer (mini laptop or cell phone) for data analysis, while the speech/sound outputs will be provided to a blind user via a Bluetooth earpiece. The performance of the newly developed algorithms and the proof-of-concept prototype will be evaluated by blind subjects.&lt;br/&gt;The partnership engages different areas of expertise including university research, industry real system design and development, and blind user study from organizations for the blind and visually handicapped to provide solutions for the most challenging problems (motion blur and query-based targeted destination recognition) in the design of wearable camera-based wayfinding and navigation aids for blind users. The interdisciplinary areas of expertise pertain to the potential to translate the computer vision based assistive technology along a path that may result in a competitive commercial reality. This will lead to new revolutionary design concepts of cost-effective and portable camera-based assistive devices to help visually impaired people in achieving functional mobility comparable to people with normal vision. The potential economic impact is expected to be $120 million in the next 10 years, which will contribute to the U.S. competitiveness in developing technology for blind wayfinding and navigation.   This research has a direct impact to benefit the visually impaired, improve their inclusion and integration into society, and enhance their future employment opportunities, success in the workplace, independent living, and economic and social self-sufficiency.</AbstractNarration>
<MinAmdLetterDate>09/10/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/27/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1343402</AwardID>
<Investigator>
<FirstName>YingLi</FirstName>
<LastName>Tian</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>YingLi Tian</PI_FULL_NAME>
<EmailAddress>ytian@ccny.cuny.edu</EmailAddress>
<PI_PHON>2126507046</PI_PHON>
<NSF_ID>000517490</NSF_ID>
<StartDate>09/10/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>CUNY City College</Name>
<CityName>New York</CityName>
<ZipCode>100319101</ZipCode>
<PhoneNumber>2126505418</PhoneNumber>
<StreetAddress>Convent Ave at 138th St</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>603503991</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073268849</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[CUNY City College]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100319101</ZipCode>
<StreetAddress><![CDATA[Convent Ave at 138th St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8019</Code>
<Text>Accelerating Innovation Rsrch</Text>
</ProgramElement>
<ProgramReference>
<Code>116E</Code>
<Text>RESEARCH EXP FOR UNDERGRADS</Text>
</ProgramReference>
<ProgramReference>
<Code>8019</Code>
<Text>Accelerating Innovation Rsrch</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~149997</FUND_OBLG>
<FUND_OBLG>2014~12000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The goal of this project is to explore solutions for challenges of designing wearable camera-based wayfinding assistants for blind persons from fundamental research to produce a practical and portable prototype to help blind users recognize targeted destinations such as a bathroom, a subway station, or a grocery store, based on text and signage recognition from complex environments. In particular, our research and development will focus on: 1) Developing robust motion deblurring methods to handle the irregular motions of blind users who are wearing the camera. 2) Recognizing targeted destinations based on the requests of blind users for wayfinding and navigation.</p> <p>With the support of this project, we have developed a prototype system of indoor navigation and wayfinding system based on Google Tango device and some new methods for designing wearable camera-based wayfinding assistants for blind persons. In particular, we have developed methods to remove motion blur, select high quality images, scene text understanding, path planning, obstacle avoidance, etc. This research provided solutions for the most challenging problems in wearable camera-based wayfinding and navigation for blind users: motion blur and query-based targeted destination recognition. This led to new design concepts of cost-effective and portable revolutionary camera-based assist devices to help visually impaired people in achieving mobility functions comparable to people with normal vision. &nbsp;This effort has bridged the gaps between research advances in Computer Vision technologies and real needs in assistive technology for blind people. The technologies developed for this project can be further extended to many other applications such as image retrieval, video surveillance, robot navigation, etc. We have published a total of 29 papers in conferences and journals supported in part by this project. There are 5 more papers under review and 3 more papers under preparation.</p> <p>With the support of this project and the REU program, a total of 6 PhD students, 1 masters student, 5 undergraduate students (2 of them are minority students) participated the project. Students have gained interdisciplinary knowledge and unique research experience in video processing and data mining technologies, real problem solving skills, as well as theoretical model development. The research experiences have prepared them for graduate study and careers in industry. The research findings are integrated in PI&rsquo;s course of &ldquo;Digital Image and Video Processing&rdquo; for both undergraduate and graduate students.</p><br> <p>            Last Modified: 03/24/2017<br>      Modified by: YingLi&nbsp;Tian</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The goal of this project is to explore solutions for challenges of designing wearable camera-based wayfinding assistants for blind persons from fundamental research to produce a practical and portable prototype to help blind users recognize targeted destinations such as a bathroom, a subway station, or a grocery store, based on text and signage recognition from complex environments. In particular, our research and development will focus on: 1) Developing robust motion deblurring methods to handle the irregular motions of blind users who are wearing the camera. 2) Recognizing targeted destinations based on the requests of blind users for wayfinding and navigation.  With the support of this project, we have developed a prototype system of indoor navigation and wayfinding system based on Google Tango device and some new methods for designing wearable camera-based wayfinding assistants for blind persons. In particular, we have developed methods to remove motion blur, select high quality images, scene text understanding, path planning, obstacle avoidance, etc. This research provided solutions for the most challenging problems in wearable camera-based wayfinding and navigation for blind users: motion blur and query-based targeted destination recognition. This led to new design concepts of cost-effective and portable revolutionary camera-based assist devices to help visually impaired people in achieving mobility functions comparable to people with normal vision.  This effort has bridged the gaps between research advances in Computer Vision technologies and real needs in assistive technology for blind people. The technologies developed for this project can be further extended to many other applications such as image retrieval, video surveillance, robot navigation, etc. We have published a total of 29 papers in conferences and journals supported in part by this project. There are 5 more papers under review and 3 more papers under preparation.  With the support of this project and the REU program, a total of 6 PhD students, 1 masters student, 5 undergraduate students (2 of them are minority students) participated the project. Students have gained interdisciplinary knowledge and unique research experience in video processing and data mining technologies, real problem solving skills, as well as theoretical model development. The research experiences have prepared them for graduate study and careers in industry. The research findings are integrated in PI?s course of "Digital Image and Video Processing" for both undergraduate and graduate students.       Last Modified: 03/24/2017       Submitted by: YingLi Tian]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
