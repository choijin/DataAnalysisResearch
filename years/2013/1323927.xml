<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Gaze Durations in Infancy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>303381.00</AwardTotalIntnAmount>
<AwardAmount>303381</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>david moore</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>When infants look at someone's face or at an object, they are learning about the world. But neither parents nor scientists know how long an infant will look at a given face or object. This study tests the hypothesis that the durations of an infant's previous looks at a target predict the duration of the next look at the target. This is called the temporal dependency hypothesis. It suggests that infants regulate their own behavior to learn from their environment early in life. The temporal dependency hypothesis will be evaluated in a multi-ethnic group of infants from the Southeastern United States. During several visits in the first year of life, individual infant looks will be measured as infants interact with their mothers, and watch videos of people and objects. During each of these activities, individual infants may have a preferred level of temporal dependency that indicates how strongly their past looks predict their next looks. Greater temporal dependency is believed to reflect greater self-regulation. The project will assess whether greater temporal dependency predicts higher levels of communication and self-regulation at a year and a half of age.&lt;br/&gt;&lt;br/&gt;The project unites research on social and cognitive development to understand the behavioral bases of visual exploration. It tests a hypothesis that may characterize other behaviors relevant to children's learning such as reaction times. Results will inform understanding of developmental disorders such as autism, and the development of new technologies such as robots with realistic and effective looking behaviors. To maximize this impact, project resources such as digital recordings of infant behavior will be shared with other researchers.</AbstractNarration>
<MinAmdLetterDate>09/03/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/03/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1323927</AwardID>
<Investigator>
<FirstName>Lorraine</FirstName>
<LastName>Bahrick</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lorraine E Bahrick</PI_FULL_NAME>
<EmailAddress>bahrick@fiu.edu</EmailAddress>
<PI_PHON>3053483988</PI_PHON>
<NSF_ID>000270784</NSF_ID>
<StartDate>09/03/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Messinger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Messinger</PI_FULL_NAME>
<EmailAddress>dmessinger@miami.edu</EmailAddress>
<PI_PHON>3052848443</PI_PHON>
<NSF_ID>000125299</NSF_ID>
<StartDate>09/03/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Miami</Name>
<CityName>CORAL GABLES</CityName>
<ZipCode>331462926</ZipCode>
<PhoneNumber>3052843924</PhoneNumber>
<StreetAddress>1320 S. Dixie Highway Suite 650</StreetAddress>
<StreetAddress2><![CDATA[Suite 100-A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>625174149</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MIAMI</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004146619</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Miami]]></Name>
<CityName>Coral Gables</CityName>
<StateCode>FL</StateCode>
<ZipCode>331463315</ZipCode>
<StreetAddress><![CDATA[5665 Ponce de Leon Blvd.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~303381</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Intellectual Merit</strong></p> <p>A central question in developmental science is the ability to predict an infant&rsquo;s next behavior. This project tested the temporal dependency hypothesis: the duration of one infant look at an object will predict the duration of the next look. We focused on infant looking because infants explore the environment visually, and looking behavior is used to infer what infants perceive and how they process what they see.</p> <p>Among human infants at different ages, and among monkey infants, the duration of one look predicted the duration of the next. First, among 3-month-olds watching a video-recorded social display, one look duration predicted the next even after accounting for the overall tendency of look durations to decline over time (habituation). This means that longer looks tended to be followed by longer looks (and shorter by shorter) over time. One look continued to predict the next even when the social display was removed (from one trial to the next). Moreover, trial duration (the aggregated looking during a presentation of a display) predicted subsequent trial durations. Similar patterns were seen in a separate dataset of 6-month-old human infants. In fact, we also confirmed that one look duration predicted the next among 48 human-reared macaque infants observed at 2.5 weeks, 3 months, and 5 months of age using eye-tracking technology. This means that at various timescales, even in the face of interruptions, infants of various ages and species maintain short-term stability in their visual exploration of the environment. As a whole, then, there was robust support for the temporal dependency hypothesis, providing quantitative evidence for the impact of past behavior on future behavior.</p> <p>Having confirmed the temporal dependency hypothesis, we asked about the development of temporal dependency among infants looking at non-social sequences of moving objects. When sequences were shorter (simpler), 4-month-olds did not show temporal dependency but 6-month-olds did. When sequences were longer (more complex) 6- and 8-month-olds did not show temporal dependency but 10-month-olds did. This suggests that temporal dependency develops as a product of infant engagement with the visual environment. It may be, in fact, that temporal dependency indexes an infant&rsquo;s understanding of the stimuli they are watching.</p> <p>Might temporal dependency also occur in real-world interactions?<strong> </strong>We found temporal dependency among six-month-olds interacting with their mothers. The duration of one infant look at parent&rsquo;s face predicted the next both during actual interaction and in a &ldquo;still-face&rdquo; period when parent stops interacting with the infant. Temporal dependency, then, appears to reflect infant structuring of their own look durations, whether or not the parent is responding to the looks. We also investigated the temporal dependency of looks away from the parent&rsquo;s face (anything else in the environment). During the still-face period, temporal dependency was weaker than in interaction. Paradoxically, this suggests that parental interactive behavior enhances the stability of infant gazes away from the parent&rsquo;s face, potentially indexing a decrease in an infant&rsquo;s ability to self-regulate.</p> <p>Having documented the development and cross-situation (and species) stability of temporal dependency&mdash;the ability to predict future behavior durations&mdash;we turned to the temporal dynamics of infant and mother smiling in face-to-face interactions. Inverse optimal control models indicated that by 4 months of age, both mothers and infants time their smiles to elicit specific interactive states with the partner. Mothers attempt to maximize the time spent in mutual smiling with the infant. Infants attempt to maximize time in which the mother is smiling but the infant is not. To validate this finding, we transferred the infant pattern of behavior to a child-robot that automatically perceived and produced smiles while interacting with adults. The infant behavior pattern was successful at maximizing adult-only smile time. Thus infants not only structure their own behavior in time, but interact with their mothers in a fashion that elicits specific patterns of behavior, suggesting a sophisticated early use of timing in social interactions</p> <p><strong>Broader Impacts</strong></p> <p>Through this project, investigators with different areas of expertise bridged a historical divide between research on social (Messinger) and perceptual development (Bahrick). Substantively, the finding that infants structure their own behavior may facilitate the design of more realistic software and hardware (robotic) simulations of real-time looking. The temporal dependency phenomenon may also have broader impacts to social problems. For example, low-income preschoolers show temporal dependency in the timing of their responses to questions assessing science knowledge.</p> <p>Finally, the current project has produced a cohort of young scientists: a) two Ph.D. developmental psychologist postdocs (Whitney Mattson, U Michigan, and Devon Gangi, UC Davis); b) training for two graduate students: one Hispanic (Katherine Martin) and one not (Emily Prince, awarded an NSF Graduate Research Fellowship); and c) two research assistants (Ming Ma, pursuing a masters in electrical and computer engineering at Cornell, and Katherine Zambrana pursuing a psychology Ph.D. at Florida International University).</p><br> <p>            Last Modified: 11/30/2016<br>      Modified by: Daniel&nbsp;Messinger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Intellectual Merit  A central question in developmental science is the ability to predict an infant?s next behavior. This project tested the temporal dependency hypothesis: the duration of one infant look at an object will predict the duration of the next look. We focused on infant looking because infants explore the environment visually, and looking behavior is used to infer what infants perceive and how they process what they see.  Among human infants at different ages, and among monkey infants, the duration of one look predicted the duration of the next. First, among 3-month-olds watching a video-recorded social display, one look duration predicted the next even after accounting for the overall tendency of look durations to decline over time (habituation). This means that longer looks tended to be followed by longer looks (and shorter by shorter) over time. One look continued to predict the next even when the social display was removed (from one trial to the next). Moreover, trial duration (the aggregated looking during a presentation of a display) predicted subsequent trial durations. Similar patterns were seen in a separate dataset of 6-month-old human infants. In fact, we also confirmed that one look duration predicted the next among 48 human-reared macaque infants observed at 2.5 weeks, 3 months, and 5 months of age using eye-tracking technology. This means that at various timescales, even in the face of interruptions, infants of various ages and species maintain short-term stability in their visual exploration of the environment. As a whole, then, there was robust support for the temporal dependency hypothesis, providing quantitative evidence for the impact of past behavior on future behavior.  Having confirmed the temporal dependency hypothesis, we asked about the development of temporal dependency among infants looking at non-social sequences of moving objects. When sequences were shorter (simpler), 4-month-olds did not show temporal dependency but 6-month-olds did. When sequences were longer (more complex) 6- and 8-month-olds did not show temporal dependency but 10-month-olds did. This suggests that temporal dependency develops as a product of infant engagement with the visual environment. It may be, in fact, that temporal dependency indexes an infant?s understanding of the stimuli they are watching.  Might temporal dependency also occur in real-world interactions? We found temporal dependency among six-month-olds interacting with their mothers. The duration of one infant look at parent?s face predicted the next both during actual interaction and in a "still-face" period when parent stops interacting with the infant. Temporal dependency, then, appears to reflect infant structuring of their own look durations, whether or not the parent is responding to the looks. We also investigated the temporal dependency of looks away from the parent?s face (anything else in the environment). During the still-face period, temporal dependency was weaker than in interaction. Paradoxically, this suggests that parental interactive behavior enhances the stability of infant gazes away from the parent?s face, potentially indexing a decrease in an infant?s ability to self-regulate.  Having documented the development and cross-situation (and species) stability of temporal dependency&mdash;the ability to predict future behavior durations&mdash;we turned to the temporal dynamics of infant and mother smiling in face-to-face interactions. Inverse optimal control models indicated that by 4 months of age, both mothers and infants time their smiles to elicit specific interactive states with the partner. Mothers attempt to maximize the time spent in mutual smiling with the infant. Infants attempt to maximize time in which the mother is smiling but the infant is not. To validate this finding, we transferred the infant pattern of behavior to a child-robot that automatically perceived and produced smiles while interacting with adults. The infant behavior pattern was successful at maximizing adult-only smile time. Thus infants not only structure their own behavior in time, but interact with their mothers in a fashion that elicits specific patterns of behavior, suggesting a sophisticated early use of timing in social interactions  Broader Impacts  Through this project, investigators with different areas of expertise bridged a historical divide between research on social (Messinger) and perceptual development (Bahrick). Substantively, the finding that infants structure their own behavior may facilitate the design of more realistic software and hardware (robotic) simulations of real-time looking. The temporal dependency phenomenon may also have broader impacts to social problems. For example, low-income preschoolers show temporal dependency in the timing of their responses to questions assessing science knowledge.  Finally, the current project has produced a cohort of young scientists: a) two Ph.D. developmental psychologist postdocs (Whitney Mattson, U Michigan, and Devon Gangi, UC Davis); b) training for two graduate students: one Hispanic (Katherine Martin) and one not (Emily Prince, awarded an NSF Graduate Research Fellowship); and c) two research assistants (Ming Ma, pursuing a masters in electrical and computer engineering at Cornell, and Katherine Zambrana pursuing a psychology Ph.D. at Florida International University).       Last Modified: 11/30/2016       Submitted by: Daniel Messinger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
