<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Bayesian Thinking on Your Feet---Embedding Generative Models in Reinforcement Learning for Sequentially Revealed Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>D.  Langendoen</SignBlockName>
<PO_EMAI>dlangend@nsf.gov</PO_EMAI>
<PO_PHON>7032925088</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Machine learning algorithms cannot "think on their feet".  When applied in practice, most approaches developed using traditional machine learning techniques wait for an entire input to arrive before they are able to provide an answer or react.  While sufficient for some tasks, this is inappropriate for a large class of problems that require more immediate or incremental responses.  This project develops new algorithms to address machine learning problems that require an algorithm to "think on its feet".  These algorithms combine guesses about what input is likely appear in the future with actions that the algorithm should take now to provide useful, effective output in a timely fashion.&lt;br/&gt;&lt;br/&gt;One application of these new methods is simultaneous translation.  This is the problem of taking problem of "observing" a sentence one word at a time in a foreign language, such as German, and providing a real-time running translation in a target language (like English).  This is particularly difficult for language pairs that have significant syntactic divergences, such as object-verb order differences between foreign languages like German or Japanese (verb final) and target languages like English (verb medial).  Like human simultaneous translators, machine learning algorithms must learn to predict the words that will appear at the end of a sentence.  The project facilitates this prediction using a framework that combined word prediction and machine translation system.&lt;br/&gt;&lt;br/&gt;The project also uses the newly developed  algorithms in academic settings to provide significant outreach to high school students and undergraduates, particularly in underrepresented communities.</AbstractNarration>
<MinAmdLetterDate>07/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/25/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1320538</AwardID>
<Investigator>
<FirstName>Hal</FirstName>
<LastName>Daume</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME>III</PI_SUFX_NAME>
<PI_FULL_NAME>Hal Daume</PI_FULL_NAME>
<EmailAddress>hal@umiacs.umd.edu</EmailAddress>
<PI_PHON>8015567863</PI_PHON>
<NSF_ID>000445461</NSF_ID>
<StartDate>07/29/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jordan</FirstName>
<LastName>Boyd-Graber</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jordan L Boyd-Graber</PI_FULL_NAME>
<EmailAddress>jbg@umiacs.umd.edu</EmailAddress>
<PI_PHON>3014057414</PI_PHON>
<NSF_ID>000566281</NSF_ID>
<StartDate>07/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland, College Park</Name>
<CityName>College Park</CityName>
<ZipCode>207425141</ZipCode>
<PhoneNumber>3014056269</PhoneNumber>
<StreetAddress>3112 LEE BLDG 7809 Regents Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>790934285</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND, COLLEGE PARK</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, College Park]]></Name>
<CityName>College Park</CityName>
<StateCode>MD</StateCode>
<ZipCode>207425141</ZipCode>
<StreetAddress><![CDATA[3112 LEE BLDG 7809 Regents Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~154399</FUND_OBLG>
<FUND_OBLG>2014~162651</FUND_OBLG>
<FUND_OBLG>2015~182950</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p id="docs-internal-guid-0de1ebb5-6e41-b286-c8fd-154115787555" style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">&nbsp;&nbsp;&nbsp; </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">Understanding language is not a process that happens one sentence at a time; instead, we process words one at a time. &nbsp;However, most existing systems for translating sentences or answering questions only work on complete sentences. &nbsp;This project helps create systems that can process sentences one word at a time rather than with complete sentences.</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">&nbsp;&nbsp;&nbsp; </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">This is harder than you might expect. &nbsp;For instance, take the task of translating Japanese or German into English. &nbsp;In these languages, the verb comes at the very end of the sentence. &nbsp;However, in English, the sentence is in the middle of the sentence. &nbsp;To successfully translate into English before the Japanese sentence is complete, a translator must guess the verb or somehow avoid mentioning the verb. &nbsp;Our project has helped understand both how humans do this (through the analysis of interpreters) and build the first statistical approaches for computers to do word-by-word translation.</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">&nbsp;&nbsp;&nbsp; </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">To build computerized word-by-word translation systems, we have to predict what the final verb will be or to rearrange English sentences to look more like the word order of Japanese sentences. &nbsp;For example, we can say &ldquo;the e-mail of the secretary&rdquo; rather than &ldquo;the secretary&rsquo;s e-mail&rdquo;. &nbsp;In addition, we can also predict what the verb of the Japanese sentence will be to speed up our translations into English. &nbsp;</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">&nbsp;&nbsp;&nbsp; </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">We also built systems that can answer English questions in a similar way (that is, word by word) for a trivia game called quiz bowl. &nbsp;In quiz bowl, participants must interrupt questions as soon as they know the answer (unlike, for example, Jeopardy, where you can only answer after a complete question). &nbsp;This is a popular game played in hundreds of high schools and colleges around the country. &nbsp;In adapting the game so that computers can answer (and interrupt) questions, we built new techniques that are fast, accurate, and can predict when the computer actually knows the answer. &nbsp;Because this is a multiplayer game, we have also built techniques for systems to understand what opponents know (for example, be more aggressive on chemistry questions if the opponent is good at that subject and be cautious on history if the opponent is bad), which requires new modeling techniques in reinforcement learning.</span></p> <p>&nbsp;</p> <p style="line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;" dir="ltr"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">&nbsp;&nbsp;&nbsp; </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">Both of these tasks have a similar structure: you get text one word at a time and you must make a decision (e.g., answer the question or predict the verb) after each word. &nbsp;The similarity of the tasks allows us to share many of the underlying techniques for solving the problems (making predictions from text, estimating how confident our predictions are). &nbsp;We built the first systems that use statistical techniques that can solve these problems, showcasing the challenge of dealing with text word by word.</span></p> <p><br /><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">&nbsp;&nbsp;&nbsp; </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">In addition to solving these technical challenges, the quiz bowl task makes for an exciting opportunity to showcase machine learning and natural language processing to the general public. &nbsp;Each year, we </span><span style="font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">test these systems in live demonstrations: we had our quiz bowl system play against Ken Jennings (it won) and a team of quiz bowl masters (it lost badly in 2016 but squeaked out a win in 2017). &nbsp;These events are well attended (hundreds at each event) and help </span><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: #ffffff; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;">laypeople (high school students and their families) understand what AI is capable of and (more importantly) what it is not capable of. &nbsp;Students are able to understand that our systems can match text but still struggles about reasoning abstractly or even solving simple math problems, which shows the importance of continued research in this area.</span></p><br> <p>            Last Modified: 10/30/2017<br>      Modified by: Jordan&nbsp;L&nbsp;Boyd-Graber</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    Understanding language is not a process that happens one sentence at a time; instead, we process words one at a time.  However, most existing systems for translating sentences or answering questions only work on complete sentences.  This project helps create systems that can process sentences one word at a time rather than with complete sentences.        This is harder than you might expect.  For instance, take the task of translating Japanese or German into English.  In these languages, the verb comes at the very end of the sentence.  However, in English, the sentence is in the middle of the sentence.  To successfully translate into English before the Japanese sentence is complete, a translator must guess the verb or somehow avoid mentioning the verb.  Our project has helped understand both how humans do this (through the analysis of interpreters) and build the first statistical approaches for computers to do word-by-word translation.        To build computerized word-by-word translation systems, we have to predict what the final verb will be or to rearrange English sentences to look more like the word order of Japanese sentences.  For example, we can say "the e-mail of the secretary" rather than "the secretary?s e-mail".  In addition, we can also predict what the verb of the Japanese sentence will be to speed up our translations into English.          We also built systems that can answer English questions in a similar way (that is, word by word) for a trivia game called quiz bowl.  In quiz bowl, participants must interrupt questions as soon as they know the answer (unlike, for example, Jeopardy, where you can only answer after a complete question).  This is a popular game played in hundreds of high schools and colleges around the country.  In adapting the game so that computers can answer (and interrupt) questions, we built new techniques that are fast, accurate, and can predict when the computer actually knows the answer.  Because this is a multiplayer game, we have also built techniques for systems to understand what opponents know (for example, be more aggressive on chemistry questions if the opponent is good at that subject and be cautious on history if the opponent is bad), which requires new modeling techniques in reinforcement learning.        Both of these tasks have a similar structure: you get text one word at a time and you must make a decision (e.g., answer the question or predict the verb) after each word.  The similarity of the tasks allows us to share many of the underlying techniques for solving the problems (making predictions from text, estimating how confident our predictions are).  We built the first systems that use statistical techniques that can solve these problems, showcasing the challenge of dealing with text word by word.       In addition to solving these technical challenges, the quiz bowl task makes for an exciting opportunity to showcase machine learning and natural language processing to the general public.  Each year, we test these systems in live demonstrations: we had our quiz bowl system play against Ken Jennings (it won) and a team of quiz bowl masters (it lost badly in 2016 but squeaked out a win in 2017).  These events are well attended (hundreds at each event) and help laypeople (high school students and their families) understand what AI is capable of and (more importantly) what it is not capable of.  Students are able to understand that our systems can match text but still struggles about reasoning abstractly or even solving simple math problems, which shows the importance of continued research in this area.       Last Modified: 10/30/2017       Submitted by: Jordan L Boyd-Graber]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
