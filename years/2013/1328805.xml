<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Large: Collaborative Research: Human-robot Coordinated Manipulation and Transportation of Large Objects</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>700000.00</AwardTotalIntnAmount>
<AwardAmount>708000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Motivated by the complementary abilities of humans and humanoids, the objective of this proposal is to develop the science and technology necessary for realizing human-robot cooperative object manipulation and transportation. The key concepts that this research seeks to promote are adaptability to human activity under minimal communication, and robustness to variability and uncertainty in the environment, achieved through a layered representation and deliberate processing of the available information. Moreover, this project aims to make maximum use of a minimal set of sensors to plan and control the actions of the robot, while ensuring safe and efficient cooperative transportation.  The embodiment of this research is a humanoid co-worker that bears most of the load, when helping a person to carry an object, without requiring excessive communication, or prior training on the part of the human.&lt;br/&gt;&lt;br/&gt;By introducing concrete methods for human-robot physical collaboration in semi-structured environments, this project enables a unique synergy between robots and humans that has the potential to increase productivity, and reduce accidents and injuries. In doing so, it also promotes the advancement of new practical applications of robots in construction, manufacturing, logistics, and home services. By developing open-source, portable algorithms for humanoid robots and mobile manipulators, this effort results in cost and time savings for researchers, developers, educators, and end-users in robotics. Finally, through an aggressive educational and community outreach plan, and by actively engaging K-12 students in an exciting RoboTech Fellows program, this project seeks to increase diversity and attract underrepresented groups to STEM.</AbstractNarration>
<MinAmdLetterDate>09/25/2013</MinAmdLetterDate>
<MaxAmdLetterDate>05/26/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1328805</AwardID>
<Investigator>
<FirstName>R. Vijay</FirstName>
<LastName>Kumar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>R. Vijay Kumar</PI_FULL_NAME>
<EmailAddress>Kumar@seas.upenn.edu</EmailAddress>
<PI_PHON>2158983630</PI_PHON>
<NSF_ID>000280506</NSF_ID>
<StartDate>09/25/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Lee</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel D Lee</PI_FULL_NAME>
<EmailAddress>ddl46@cornell.edu</EmailAddress>
<PI_PHON>6463709862</PI_PHON>
<NSF_ID>000322679</NSF_ID>
<StartDate>09/25/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Kuchenbecker</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katherine J Kuchenbecker</PI_FULL_NAME>
<EmailAddress>kuchenbe@seas.upenn.edu</EmailAddress>
<PI_PHON>2155732786</PI_PHON>
<NSF_ID>000465871</NSF_ID>
<StartDate>01/04/2016</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<StreetAddress2><![CDATA[3451 Walnut St, 5th Flr Franklin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042250712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042250712</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pennsylvania]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191046389</ZipCode>
<StreetAddress><![CDATA[3330 Walnut Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7298</Code>
<Text>COLLABORATIVE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>7925</Code>
<Text>LARGE PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~700000</FUND_OBLG>
<FUND_OBLG>2017~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>(a)&nbsp;We developed novel search-based&nbsp;planning techniques         leveraging motion-primitives for a system of a human and&nbsp;robot         carrying an object.&nbsp;Motion primitives capture the intrinsic         dynamics of&nbsp;the system while the search of the resulting lattice         graph allows the system to&nbsp;prune&nbsp;out edges and notes that may         result in unsafe states.<br /> <br /> (b)&nbsp;We synthesized algorithms that&nbsp;enabled a robot to predict         human motion intent based on optical and force&nbsp;sensors. A pose         estimate of the&nbsp;human agent and an estimate of wrenches         exerted&nbsp;by the human allows the system to infer human intent in         cooperative manipulation.<br /> <br /> (c)&nbsp;We studied the dynamics of&nbsp;liquid-filled containers and         derived first-principle models of pouring from&nbsp;containers. These         models predict the&nbsp;flow rate from containers based on         their&nbsp;cross section and the pouring angle, and suggest         model-based approaches to&nbsp;design controllers for&nbsp;robot pouring         from one container to another.<br /> <br /> (d)&nbsp;We developed deep learning&nbsp;algorithms that allow robots to         learn how to pour precisely from containers&nbsp;with unknown         geometry to another&nbsp;container. This is a significant step         since&nbsp;robots cannot be expected to have prior knowledge about         every container it&nbsp;might have to use.<br /> <br /> These&nbsp;results have applications to human-robot collaboration in         a wide range of tasks,&nbsp;and more specifically to applications in         lab&nbsp;automation for biotech and drug&nbsp;discovery labs.<br /> <br />The&nbsp;project also provided all or part support for the education of 5 PhD     students and 4 Undergraduate students.</p><br> <p>            Last Modified: 02/03/2020<br>      Modified by: R. Vijay&nbsp;Kumar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ (a) We developed novel search-based planning techniques         leveraging motion-primitives for a system of a human and robot         carrying an object. Motion primitives capture the intrinsic         dynamics of the system while the search of the resulting lattice         graph allows the system to prune out edges and notes that may         result in unsafe states.    (b) We synthesized algorithms that enabled a robot to predict         human motion intent based on optical and force sensors. A pose         estimate of the human agent and an estimate of wrenches         exerted by the human allows the system to infer human intent in         cooperative manipulation.    (c) We studied the dynamics of liquid-filled containers and         derived first-principle models of pouring from containers. These         models predict the flow rate from containers based on         their cross section and the pouring angle, and suggest         model-based approaches to design controllers for robot pouring         from one container to another.    (d) We developed deep learning algorithms that allow robots to         learn how to pour precisely from containers with unknown         geometry to another container. This is a significant step         since robots cannot be expected to have prior knowledge about         every container it might have to use.    These results have applications to human-robot collaboration in         a wide range of tasks, and more specifically to applications in         lab automation for biotech and drug discovery labs.   The project also provided all or part support for the education of 5 PhD     students and 4 Undergraduate students.       Last Modified: 02/03/2020       Submitted by: R. Vijay Kumar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
