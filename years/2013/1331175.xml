<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BSF: 2012251: Algorithmic Game Theory meets Computational Learning Theory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>32939.00</AwardTotalIntnAmount>
<AwardAmount>32939</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tracy Kimbrel</SignBlockName>
<PO_EMAI>tkimbrel@nsf.gov</PO_EMAI>
<PO_PHON>7032927924</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is funded as part of the United States-Israel Collaboration in Computer Science (USICCS) program.  Through this program, NSF and the United States - Israel Binational Science Foundation (BSF) jointly support collaborations among US-based researchers and Israel-based researchers.&lt;br/&gt;&lt;br/&gt;The goal of this project is to use ideas and techniques developed in the field of Computational Learning Theory to produce algorithms that can aid users or firms in solving certain economic decision-making problems.  Computational Learning Theory studies how one can automatically learn good prediction rules from data, as well as questions such as how much data is intrinsically needed in order to learn rules of a given complexity.  In economic decision-making, one often has some amount of data (or recent experience) and must extrapolate from this a course of action for the future.  This project aims to bring these two areas together in order to produce improved economic decision-making tools.&lt;br/&gt;&lt;br/&gt;This project focuses specifically on three challenging problems for which ideas from Computational Learning Theory appear to be especially promising.  The first concerns the decision of how many of each of a given suite of products to produce when customers are arriving over time and have disjunctive needs, and the production costs for each product obey economies of scale.  The goal in this setting is from a small amount of initial observation to be able to commit to a near-optimal plan for how much of each product to produce, to satisfy future customers at the least possible total cost.  The second concerns the problems of market segmentation when the potential customers have known attributes but the relation of these attributes to their preferences is not known up front.  Finally, the last concerns the problem of inferring a model for bidders in an auction when only the outcome information of the auction is observable.  These problems all involve challenging inference tasks for which tools from Computational Learning Theory appear to be well suited.</AbstractNarration>
<MinAmdLetterDate>09/11/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1331175</AwardID>
<Investigator>
<FirstName>Avrim</FirstName>
<LastName>Blum</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Avrim Blum</PI_FULL_NAME>
<EmailAddress>avrim@ttic.edu</EmailAddress>
<PI_PHON>7738341740</PI_PHON>
<NSF_ID>000445508</NSF_ID>
<StartDate>09/11/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>2878</Code>
<Text>Special Projects - CCF</Text>
</ProgramElement>
<ProgramReference>
<Code>2878</Code>
<Text>SPECIAL PROJECTS - CCF</Text>
</ProgramReference>
<ProgramReference>
<Code>7796</Code>
<Text>ALGORITHMIC FOUNDATIONS</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~32939</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project addressed several fundamental questions at the intersection of Computer Science, Economics, and Machine Learning.&nbsp;</p> <p>One main direction involved algorithms for determining how much to produce of products that obey economies of scale when you do not initially know what demand will be and customers arrive online over time and have disjunctive needs.&nbsp; &nbsp;For example, some customers might be happy with any of products A or B or C, others might be happy with only A or B, and yet others might be happy only with product A.&nbsp; In this case, to take advantage of economies of scale, one should produce only product A (rather than, say, equal numbers of A, B, and C).&nbsp; More generally, the algorithmic challenge is to determine what to produce if we do not know up front what customers' needs are and instead only learn them as they arrive over time.&nbsp;&nbsp;</p> <p>A second main direction involved designing algorithms that observe the results of an allocation process (e.g., observing which computational resources are allocated to different jobs in a cloud computing system, or observing which tasks workers get assigned to in a company) and then can use those observations to reverse-engineer the procedure used to determine the allocation. These algorithms could be useful for helping to verify whether an allocation process indeed satisfies some claimed property.&nbsp; Closely related to this, we also developed algorithms for inferring a model for bidders in an auction when only the outcome information of the auction (who won and how much they paid) is observable.</p> <p>A third main direction involved analysis of improved methods for learning via crowdsourcing.&nbsp; The high-level idea is that crowdsourcing is used to gather labeled training data that is fed into a learning algorithm.&nbsp; However, crowdsourced labels can be noisy.&nbsp; Even worse, some regions of the input space may just be harder to label correctly than others, so this noise may not be uniform.&nbsp; One approach to dealing with this is to use voting across many labelers to reduce or eliminate the noise coming from individual mistakes.&nbsp; However, this means that a substantial amount of redundant labeling work is being performed.&nbsp; In this work, we developed new approaches that interleave the learning and labeling process in order to substantially reduce this labeling overhead.</p> <p>Finally, the last main direction involved analysis of equilibria and processes for reaching equilibria in markets where goods can have different quality levels, and producers can adjust the quality level of their products based on how much money they put into production.&nbsp; &nbsp;We examine the question of under what conditions the price of a product will be a good signal of its quality, and prove general theorems about the structure of equilibria in such markets.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/29/2018<br>      Modified by: Avrim&nbsp;Blum</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project addressed several fundamental questions at the intersection of Computer Science, Economics, and Machine Learning.   One main direction involved algorithms for determining how much to produce of products that obey economies of scale when you do not initially know what demand will be and customers arrive online over time and have disjunctive needs.   For example, some customers might be happy with any of products A or B or C, others might be happy with only A or B, and yet others might be happy only with product A.  In this case, to take advantage of economies of scale, one should produce only product A (rather than, say, equal numbers of A, B, and C).  More generally, the algorithmic challenge is to determine what to produce if we do not know up front what customers' needs are and instead only learn them as they arrive over time.    A second main direction involved designing algorithms that observe the results of an allocation process (e.g., observing which computational resources are allocated to different jobs in a cloud computing system, or observing which tasks workers get assigned to in a company) and then can use those observations to reverse-engineer the procedure used to determine the allocation. These algorithms could be useful for helping to verify whether an allocation process indeed satisfies some claimed property.  Closely related to this, we also developed algorithms for inferring a model for bidders in an auction when only the outcome information of the auction (who won and how much they paid) is observable.  A third main direction involved analysis of improved methods for learning via crowdsourcing.  The high-level idea is that crowdsourcing is used to gather labeled training data that is fed into a learning algorithm.  However, crowdsourced labels can be noisy.  Even worse, some regions of the input space may just be harder to label correctly than others, so this noise may not be uniform.  One approach to dealing with this is to use voting across many labelers to reduce or eliminate the noise coming from individual mistakes.  However, this means that a substantial amount of redundant labeling work is being performed.  In this work, we developed new approaches that interleave the learning and labeling process in order to substantially reduce this labeling overhead.  Finally, the last main direction involved analysis of equilibria and processes for reaching equilibria in markets where goods can have different quality levels, and producers can adjust the quality level of their products based on how much money they put into production.   We examine the question of under what conditions the price of a product will be a good signal of its quality, and prove general theorems about the structure of equilibria in such markets.          Last Modified: 11/29/2018       Submitted by: Avrim Blum]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
