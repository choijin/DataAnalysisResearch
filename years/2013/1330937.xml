<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Workshop: How the Brain Accommodates Variability in Linguistic Representations; July, 2013 - University of Michigan</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2013</AwardEffectiveDate>
<AwardExpirationDate>12/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>11903.00</AwardTotalIntnAmount>
<AwardAmount>11903</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When we listen, we rapidly and reliably decode speakers' intentions and we mostly do so independently of whom were are talking to. Yet, anyone who has interacted with an automated speech recognition system (e.g., while booking a flight) is painfully aware that speech recognition is a computationally hard problem: although we hardly ever become aware of it, the physical signal corresponding to, for example, one speaker's "b" can be identical to another speaker's "p", making it hard for computers to distinguish between them. How then does the human brain accomplish this task with such apparent ease? &lt;br/&gt;&lt;br/&gt;This NSF funded workshop brings together researchers from computer sciences, linguistics, and the cognitive sciences to discuss and investigate how the brain achieves robust language understanding despite variability. The invited speakers are internationally-known experts. Representatives from both industry and academia will present on the state of the art in automated speech recognition, implicit learning during language understanding, and the neural systems underlying speech perception. The workshop will take place in conjunction with the 2013 Linguistic Society of America's Summer Institute--the largest international linguistics summer school--and will thereby provide training to a large number of young language researchers.</AbstractNarration>
<MinAmdLetterDate>06/19/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/19/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1330937</AwardID>
<Investigator>
<FirstName>Victor</FirstName>
<LastName>Ferreira</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Victor S Ferreira</PI_FULL_NAME>
<EmailAddress>vferreira@ucsd.edu</EmailAddress>
<PI_PHON>8585346303</PI_PHON>
<NSF_ID>000296485</NSF_ID>
<StartDate>06/19/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>T. Florian</FirstName>
<LastName>Jaeger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>T. Florian Jaeger</PI_FULL_NAME>
<EmailAddress>fjaeger@bcs.rochester.edu</EmailAddress>
<PI_PHON>5852763611</PI_PHON>
<NSF_ID>000497304</NSF_ID>
<StartDate>06/19/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Rochester</Name>
<CityName>Rochester</CityName>
<ZipCode>146270140</ZipCode>
<PhoneNumber>5852754031</PhoneNumber>
<StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041294109</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ROCHESTER</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041294109</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Michigan]]></Name>
<CityName>Ann Arbor</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091220</ZipCode>
<StreetAddress><![CDATA[440 Lorch Hall, 611 Tappan Stree]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~11903</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">In order to understand each other, listeners must decode the linguistic signal, in order to infer our intended messages. This process is necessarily noisy: no two instances of a sound category (e.g. a /p/) are exactly alike in terms of the physical signal that corresponds to them. To further complicate communication, speakers differ in the way they realize the same sounds, concepts, and propositions. The challenges posed to comprehension by variability are perhaps most obvious at the level of speech perception. For example, the acoustic distributions corresponding to one speaker&rsquo;s /p/, can be physically more similar to the acoustic distributions of another speaker&rsquo;s /b/ than the acoustic distributions of that speaker&rsquo;s /p/. That is, not only is the linguistic signal intrinsically noisy, resulting in distributions of acoustic features corresponding to linguistic categories, but these distributions also vary depending on the speaker. This lack of invariance makes language understanding a challenging computational problem.</p> <p class="p1">Understanding how the human brain overcomes this problem can help to develop better speech technology (such as automatic speech recognition, background noise-suppression while using cell phone, etc.). It can also help to develop a better understanding of certain types of problems that cause trouble with understanding others.</p> <p class="p1">We organized and conducted a workshop that brought together researchers working on the on this problem from linguistic, psycholinguistics, and computational perspectives. Over 120 students, post-docs, and faculty, including academics and representative of related industries, attended the workshop at the 2013 Linguistic Society of America Summer Institute (the largest gathering of language researchers in the world).</p> <p class="p1">The workshop facilitated new interdisciplinary collaboration, including potential collaborations (still in the planning stages) between industry and academia.</p><br> <p>            Last Modified: 01/06/2015<br>      Modified by: T. Florian&nbsp;Jaeger</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[In order to understand each other, listeners must decode the linguistic signal, in order to infer our intended messages. This process is necessarily noisy: no two instances of a sound category (e.g. a /p/) are exactly alike in terms of the physical signal that corresponds to them. To further complicate communication, speakers differ in the way they realize the same sounds, concepts, and propositions. The challenges posed to comprehension by variability are perhaps most obvious at the level of speech perception. For example, the acoustic distributions corresponding to one speakerÆs /p/, can be physically more similar to the acoustic distributions of another speakerÆs /b/ than the acoustic distributions of that speakerÆs /p/. That is, not only is the linguistic signal intrinsically noisy, resulting in distributions of acoustic features corresponding to linguistic categories, but these distributions also vary depending on the speaker. This lack of invariance makes language understanding a challenging computational problem. Understanding how the human brain overcomes this problem can help to develop better speech technology (such as automatic speech recognition, background noise-suppression while using cell phone, etc.). It can also help to develop a better understanding of certain types of problems that cause trouble with understanding others. We organized and conducted a workshop that brought together researchers working on the on this problem from linguistic, psycholinguistics, and computational perspectives. Over 120 students, post-docs, and faculty, including academics and representative of related industries, attended the workshop at the 2013 Linguistic Society of America Summer Institute (the largest gathering of language researchers in the world). The workshop facilitated new interdisciplinary collaboration, including potential collaborations (still in the planning stages) between industry and academia.       Last Modified: 01/06/2015       Submitted by: T. Florian Jaeger]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
