<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Extending and Automating Dynamic Specialization of Database Management Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>496830.00</AwardTotalIntnAmount>
<AwardAmount>496830</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Database management systems (DBMSs) are ubiquitous in industry and their performance and functionality are crucially important in commercial IT infrastructure. There has been a lot of work on improving the performance of these critical systems.  This project adopts a complementary and orthogonal approach to substantially increasing the performance of DBMSs.  This is done by exploiting runtime information about the DBMS to specialize the DBMS code on the fly in order to eliminate as much unnecessary work as possible.  This dynamic code optimization, which we term "micro-specialization", is highly aggressive and goes well beyond what can be achieved using existing compiler optimization technology. This focus on runtime code optimization is also very different from most of the current research on DBMS performance improvement.  The project investigates algorithms for automatic identification of code sequences where micro-specialization may profitably be applied; algorithms that can micro-specialize such identified target code sequences; and techniques for ensuring the correctness of the resulting code.  Preliminary studies on disparate DBMSes suggest that micro-specialization offers significant performance improvements when applied to mature, high-performance DBMSs and to industry-standard benchmarks, and that there are rich opportunities for other substantial performance gains, with minimal impact on the DBMS architecture.&lt;br/&gt;&lt;br/&gt;Broader impacts of this project include increased efficiency of the IT infrastructure used by a wide variety of companies, leading to improved overall productivity.  Graduate and undergraduate students are involved in all aspects of the research activities as an integral part of the project. The PIs have an established track record of integrating research activities into the undergraduate curriculum and involving undergraduates, including women and members of underrepresented minorities, in research; this project continues this tradition.&lt;br/&gt;&lt;br/&gt;For further information see the web site at http://www.cs.arizona.edu/projects/microspecialization/ .</AbstractNarration>
<MinAmdLetterDate>08/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1318343</AwardID>
<Investigator>
<FirstName>Saumya</FirstName>
<LastName>Debray</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Saumya K Debray</PI_FULL_NAME>
<EmailAddress>debray@cs.arizona.edu</EmailAddress>
<PI_PHON>5206214527</PI_PHON>
<NSF_ID>000120753</NSF_ID>
<StartDate>08/29/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Snodgrass</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard T Snodgrass</PI_FULL_NAME>
<EmailAddress>rts@cs.arizona.edu</EmailAddress>
<PI_PHON>5206216370</PI_PHON>
<NSF_ID>000378635</NSF_ID>
<StartDate>08/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName/>
<StateCode>AZ</StateCode>
<ZipCode>857210077</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~496830</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong id="docs-internal-guid-ea540b67-7fff-0a05-23d9-058f33ce2ef5" style="font-weight: normal;"> </strong></p> <p style="line-height: 1.2; margin-top: 8pt; margin-bottom: 8pt;" dir="ltr"><strong id="docs-internal-guid-ea540b67-7fff-0a05-23d9-058f33ce2ef5" style="font-weight: normal;"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">The funded research extends our previously-developed technology of micro-specialization, which identifies runtime invariants and dynamically generates specialized version(s) of extant database management system (DBMS) code to yield significant performance improvement when used on traditional<br />DBMSes.&nbsp; <em>Generalized microspecialization</em>, developed in the funded research, introduces four new classes of generalized invariants that in concert enable a much wider variety of optimizations, including many that would not be possible in the original formulation of microspecialization. We aso extended the<br />process of microspecialization to work well with emerging features of modern DBMSes, specifically (a) columnar store, (b) operator-at-a-time query evaluation, and (c) query compilation. We applied this new process to MonetDB, which includes all of these features, demonstrating that generalized microspecialization is able to obtain significant performance improvement on this already highly optimized state-of-the-art DBMS and thus is complementary to these recent architectural advances. <br /><br />We also investigated the impact <strong id="docs-internal-guid-ea540b67-7fff-0a05-23d9-058f33ce2ef5" style="font-weight: normal;"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">on the instruction cache </span></strong>of large amounts of code generation by aggressive micro-specialization. Microspecialization removes machine code by exploiting the runtime invariants, thus reducing instruction cache pressure. This benefit may be reduced in the presence of multiple specializations of the same original DBMS routine simultaneously executing, for different versions of the same DBMS routine invoked by operators within a query plan or for different versions invoked by other<br />query plans executing at the same time. We showed that micro-specialization could increase the cache pressure on both the level-1 instruction cache and the level-2 cache, which is more complex to model and deal with because this cache is usually shared between code and data. We developed several novel<br />run-time code placement algorithms that place dynamically-generated run-time code wisely. We demonstrated that these approaches minimize I-cache pressure for workloads that utilize as many as 1000 dynamically-generated functions.&nbsp; <br /><br />Across the wide spectrum of available DBMS performance amplification strategies, the methodology developed in this research is the least intrusive, is fine-grained, is incremental, and is complementary to other approaches. Thus, generalized microspecialization is a lightweight approach that can potentially improve the performance of any DBMS, including those that have already benefited from other, more heavyweight approaches.<br /><br />During this research, we also began an experimental effort to engage undergraduate students in the research project, focusing in particular on students from under-represented groups. Our prior experience in working with undergraduates suggests that it is especially beneficial to engage students early in their college careers and offer them an interesting and rewarding research path as they progress through the computer science program; a<br />practical problem is that, early in their careers, they usually do not have the technical background to perform useful research. To address this concern, we focused on two aproaches.<br /><br />We ran an experimental program [May-Aug 2017] to identify and engage a cohort of freshmen students during their second programming course and invited them to learn the relevant material (C programming, Unix environment, x86 assembly) through a guided, collaborative, self-paced learning process. As students progressed through this learning process and attained<br />appropriate levels of technical expertise, they were gradually introduced to research and absorbed into the research group.<br /><br />We also constructed a mentoring pipeline whereby more experienced undergraduates would guide and mentor the less experienced students. The interaction with, and mentoring by, undergraduates only a little older than them made the process less intimidating for the students just starting out.<br /><br />It is too early (and the number of students involved too small) to say definitively whether this represents a successful strategy for broadening research participation by early research engagement of undergraduates, in particular those from under-represented groups. We did notice that the students participating in this experiment seem to have picked up much of the needed technical background in a collaborative learning setting and without<br />undue pressure or stress. We will continue to work with this cohort to ntegrate them into our research group and start them working on real research problems.</span></strong></p> <p style="line-height: 1.2; margin-top: 8pt; margin-bottom: 8pt;" dir="ltr"><strong style="font-weight: normal;"><span style="font-size: 10.5pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br /></span></strong></p><br> <p>            Last Modified: 11/01/2018<br>      Modified by: Richard&nbsp;T&nbsp;Snodgrass</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The funded research extends our previously-developed technology of micro-specialization, which identifies runtime invariants and dynamically generates specialized version(s) of extant database management system (DBMS) code to yield significant performance improvement when used on traditional DBMSes.  Generalized microspecialization, developed in the funded research, introduces four new classes of generalized invariants that in concert enable a much wider variety of optimizations, including many that would not be possible in the original formulation of microspecialization. We aso extended the process of microspecialization to work well with emerging features of modern DBMSes, specifically (a) columnar store, (b) operator-at-a-time query evaluation, and (c) query compilation. We applied this new process to MonetDB, which includes all of these features, demonstrating that generalized microspecialization is able to obtain significant performance improvement on this already highly optimized state-of-the-art DBMS and thus is complementary to these recent architectural advances.   We also investigated the impact on the instruction cache of large amounts of code generation by aggressive micro-specialization. Microspecialization removes machine code by exploiting the runtime invariants, thus reducing instruction cache pressure. This benefit may be reduced in the presence of multiple specializations of the same original DBMS routine simultaneously executing, for different versions of the same DBMS routine invoked by operators within a query plan or for different versions invoked by other query plans executing at the same time. We showed that micro-specialization could increase the cache pressure on both the level-1 instruction cache and the level-2 cache, which is more complex to model and deal with because this cache is usually shared between code and data. We developed several novel run-time code placement algorithms that place dynamically-generated run-time code wisely. We demonstrated that these approaches minimize I-cache pressure for workloads that utilize as many as 1000 dynamically-generated functions.    Across the wide spectrum of available DBMS performance amplification strategies, the methodology developed in this research is the least intrusive, is fine-grained, is incremental, and is complementary to other approaches. Thus, generalized microspecialization is a lightweight approach that can potentially improve the performance of any DBMS, including those that have already benefited from other, more heavyweight approaches.  During this research, we also began an experimental effort to engage undergraduate students in the research project, focusing in particular on students from under-represented groups. Our prior experience in working with undergraduates suggests that it is especially beneficial to engage students early in their college careers and offer them an interesting and rewarding research path as they progress through the computer science program; a practical problem is that, early in their careers, they usually do not have the technical background to perform useful research. To address this concern, we focused on two aproaches.  We ran an experimental program [May-Aug 2017] to identify and engage a cohort of freshmen students during their second programming course and invited them to learn the relevant material (C programming, Unix environment, x86 assembly) through a guided, collaborative, self-paced learning process. As students progressed through this learning process and attained appropriate levels of technical expertise, they were gradually introduced to research and absorbed into the research group.  We also constructed a mentoring pipeline whereby more experienced undergraduates would guide and mentor the less experienced students. The interaction with, and mentoring by, undergraduates only a little older than them made the process less intimidating for the students just starting out.  It is too early (and the number of students involved too small) to say definitively whether this represents a successful strategy for broadening research participation by early research engagement of undergraduates, in particular those from under-represented groups. We did notice that the students participating in this experiment seem to have picked up much of the needed technical background in a collaborative learning setting and without undue pressure or stress. We will continue to work with this cohort to ntegrate them into our research group and start them working on real research problems.         Last Modified: 11/01/2018       Submitted by: Richard T Snodgrass]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
