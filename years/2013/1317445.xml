<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: Small: Collaborative Research: Adaptive Motion Planning and Decision-Making for Human-Robot Collaboration in Manufacturing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>319728.00</AwardTotalIntnAmount>
<AwardAmount>319728</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project addresses manufacturing tasks that cannot be fully automated because of either the limitations of current algorithms or prohibitive cost and set-up time. Such tasks generally require workers to collaborate in close proximity and adapt to each other's decisions and motions. This project explores accomplishing these tasks through human-robot collaboration. Recent hardware developments in robotics have made human-robot collaboration physically possible, but robots still require new algorithms to ensure safety, efficiency, and fluency when working with people. Creating such algorithms is difficult because there can be high uncertainty in what a person is going to do and how they are going to do it. This project explores the integration of reasoning about how a person moves and how he or she makes decisions into a robot motion planning and decision-making framework. The research centers on the development of new algorithmic frameworks for modeling, simulating, and planning for human-robot collaboration, which requires advances in robot training, task modeling, human motion understanding, high-dimensional motion planning with uncertainty, and metrics to assess human-robot joint action. The results of this project have the potential to signi&amp;#64257;cantly improve American competitiveness in manufacturing; especially for small-batch manufacturing and burst production, where the cost and set-up time of fully-autonomous solutions is prohibitive. The work will be disseminated in research papers and integrated into curricula. The project is guided by an advisory board from the manufacturing industry, which provides another avenue for dissemination.</AbstractNarration>
<MinAmdLetterDate>09/06/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1317445</AwardID>
<Investigator>
<FirstName>Julie</FirstName>
<LastName>Shah</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Julie Shah</PI_FULL_NAME>
<EmailAddress>arnoldj@mit.edu</EmailAddress>
<PI_PHON>6173244879</PI_PHON>
<NSF_ID>000611096</NSF_ID>
<StartDate>09/06/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394301</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~319728</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="rtejustify">Once a team has developed a plan for working together, the members must coordinate while executing the plan. However, it is challenging for a machine to monitor a human's real-time progress through a plan. The ability to accurately predict human motion is imperative for any human-robot interaction application in which the human and robot interact in close proximity to one another. Prior activity recognition approaches are designed and tuned for specific motions or tasks. No existing single technique provides accurate predictions over short and long time horizons, in most scenarios. The robot must predict detailed space-time trajectories of human actions for short and long timescales (&lt;1s to 10-20s) to react appropriately.&nbsp;Robots also need to make quick adjustments to their plans based on continually updating predictions of human actions.</p> <p class="rtejustify">Although a variety of human motion prediction approaches have already been developed, they are often designed for specific types of tasks or motions, and thus do not generalize well. Furthermore, it is not always obvious which of these methods is appropriate for a given task, making human motion prediction difficult to implement in practice. We addressed this problem by developing a multiple-predictor system (MPS) for human motion prediction. In our approach, the system learns directly from task data in order to determine the most favorable parameters for each implemented prediction method and which combination of these predictors to use. Our implementation consists of three complementary methods: velocity-based position projection, time series classification, and sequence prediction. We describe the process of forming the MPS and our evaluation of its performance against the individual methods in terms of accuracy of predictions of human position over a range of look-ahead time values. We report that our method leads to a reduction in mean error of 18.5%, 28.9%, and 37.3% when compared with the three individual methods, respectively.</p> <p class="rtejustify">We utilized the MPS to develop a human-aware robotic system with single-axis mobility that incorporates both predictions of human motion and planning in time to execute efficient and safe motions during automotive final assembly. We evaluated our system in simulation against three alternative methods, including a baseline approach emulating the behavior of standard safety systems in factories today. We also assessed the system within a factory test environment. Through both live demonstration and results from simulated experiments, we found that our approach produces statistically significant improvements in quantitative measures of safety and fluency of interaction.</p><br> <p>            Last Modified: 07/20/2018<br>      Modified by: Julie&nbsp;Shah</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Once a team has developed a plan for working together, the members must coordinate while executing the plan. However, it is challenging for a machine to monitor a human's real-time progress through a plan. The ability to accurately predict human motion is imperative for any human-robot interaction application in which the human and robot interact in close proximity to one another. Prior activity recognition approaches are designed and tuned for specific motions or tasks. No existing single technique provides accurate predictions over short and long time horizons, in most scenarios. The robot must predict detailed space-time trajectories of human actions for short and long timescales (&lt;1s to 10-20s) to react appropriately. Robots also need to make quick adjustments to their plans based on continually updating predictions of human actions. Although a variety of human motion prediction approaches have already been developed, they are often designed for specific types of tasks or motions, and thus do not generalize well. Furthermore, it is not always obvious which of these methods is appropriate for a given task, making human motion prediction difficult to implement in practice. We addressed this problem by developing a multiple-predictor system (MPS) for human motion prediction. In our approach, the system learns directly from task data in order to determine the most favorable parameters for each implemented prediction method and which combination of these predictors to use. Our implementation consists of three complementary methods: velocity-based position projection, time series classification, and sequence prediction. We describe the process of forming the MPS and our evaluation of its performance against the individual methods in terms of accuracy of predictions of human position over a range of look-ahead time values. We report that our method leads to a reduction in mean error of 18.5%, 28.9%, and 37.3% when compared with the three individual methods, respectively. We utilized the MPS to develop a human-aware robotic system with single-axis mobility that incorporates both predictions of human motion and planning in time to execute efficient and safe motions during automotive final assembly. We evaluated our system in simulation against three alternative methods, including a baseline approach emulating the behavior of standard safety systems in factories today. We also assessed the system within a factory test environment. Through both live demonstration and results from simulated experiments, we found that our approach produces statistically significant improvements in quantitative measures of safety and fluency of interaction.       Last Modified: 07/20/2018       Submitted by: Julie Shah]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
