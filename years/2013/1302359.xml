<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Medium: Collaborative Research: The Commutativity Rule for Scalable System Software</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>After decades of reliable improvement, processor speeds have&lt;br/&gt;flattened; for the foreseeable future, computers will add processing&lt;br/&gt;power by adding more processors, rather than faster ones. This is a&lt;br/&gt;tremendous challenge for software designers. It's far too easy for&lt;br/&gt;software using multiple processors to burn up a growing fraction of&lt;br/&gt;available processing power on coordination overheads like locking,&lt;br/&gt;rather than actual work. That is, it's far too easy for software to&lt;br/&gt;not scale: to get slower as processors are added. And an important&lt;br/&gt;reason for this is simply that scalability is poorly understood. Some&lt;br/&gt;programs don't scale because they're badly written, but others don't&lt;br/&gt;scale because their goals are fundamentally impossible to accomplish&lt;br/&gt;in a scalable way. Programmers lack effective tools for high-level&lt;br/&gt;reasoning about software scalability limitations, and thus waste&lt;br/&gt;effort on both impossible and uninteresting tasks.&lt;br/&gt;&lt;br/&gt;We will produce the first well-grounded and formal reasoning procedure&lt;br/&gt;for scalability that is flexible enough to apply to an entire&lt;br/&gt;operating system. Our scalability rule links commutativity and&lt;br/&gt;scalability. We characterize software interfaces as more or less&lt;br/&gt;inherently scalable depending on the contexts in which those&lt;br/&gt;interfaces commute: the more commutative an interface (that is, the&lt;br/&gt;more often the order of its function calls doesn't matter), the more&lt;br/&gt;scalable an implementation can be. We prove that a scalable&lt;br/&gt;implementation exists for any commutative context. This idea can&lt;br/&gt;already guide software designers in developing easily-scalable&lt;br/&gt;interfaces, but we will also provide a set of automated tools for&lt;br/&gt;measuring interface commutativity and for finding implementation&lt;br/&gt;scalability bottlenecks, and evaluate our ideas in a highly-scalable&lt;br/&gt;operating system. The resulting tools and ideas could make scalable&lt;br/&gt;software far easier to design and program, and thus help software&lt;br/&gt;designers provide the software performance on which so much of our&lt;br/&gt;economy depends.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/09/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/09/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302359</AwardID>
<Investigator>
<FirstName>Edward</FirstName>
<LastName>Kohler</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edward Kohler</PI_FULL_NAME>
<EmailAddress>kohler@seas.harvard.edu</EmailAddress>
<PI_PHON>6174962630</PI_PHON>
<NSF_ID>000099226</NSF_ID>
<StartDate>09/09/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021382933</ZipCode>
<StreetAddress><![CDATA[29 Oxford St, MD327]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~300000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>After decades of reliable improvement, processor speeds have flattened; for the foreseeable future, computers will add processing power by adding more processors, rather than faster ones. Yet much software using multiple processors spends more time on coordination overheads than actual work! In the worst case, software gets slower as processors are added -- either because the software is badly written, or because its goals are fundamentally impossible to accomplish in a scalable way.</p> <p>The key to fixing this problem is understanding it. What kinds of software can be made to scale -- to run faster as more processors are added? Can scalability opportunities be identified independent of a specific piece of possibly-buggy code?</p> <p>This project answers this question with the Scalable Commutativity Rule: "Whenever interface operations commute, they can be implemented in a way that scales (on hardware like today's computers)." The interface governs how the software should behave, independent of its code. We say the interface commutes when a handful of operations can execute independent of order -- that is, when later operations can't tell what order actually occurred. Commutativity is easy to think about, but hard to precisely define. We developed a novel form of commutativity, SIM commutativity, that lets the rule apply even to the most complex software. We were able to show that given this novel form of commutativity, the rule is actually a law, true in a strict formal sense.</p> <p>Precise reasoning about commutativity helps software designers understand the limits of software performance. It also helps software designers find new opportunities for speed. For instance, reasoning about commutativity helped us design new database-like software systems, for both multi-core processors and multi-machine systems, that can process transactions at greatly increased rates. These systems perform better at scale precisely because they explicitly take advantage of commutativity, whereas some previous systems' designs ignored the commutativity present in their problem definitions, and thus failed in some cases to scale.</p> <p>&nbsp;</p><br> <p>            Last Modified: 09/25/2018<br>      Modified by: Edward&nbsp;Kohler</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ After decades of reliable improvement, processor speeds have flattened; for the foreseeable future, computers will add processing power by adding more processors, rather than faster ones. Yet much software using multiple processors spends more time on coordination overheads than actual work! In the worst case, software gets slower as processors are added -- either because the software is badly written, or because its goals are fundamentally impossible to accomplish in a scalable way.  The key to fixing this problem is understanding it. What kinds of software can be made to scale -- to run faster as more processors are added? Can scalability opportunities be identified independent of a specific piece of possibly-buggy code?  This project answers this question with the Scalable Commutativity Rule: "Whenever interface operations commute, they can be implemented in a way that scales (on hardware like today's computers)." The interface governs how the software should behave, independent of its code. We say the interface commutes when a handful of operations can execute independent of order -- that is, when later operations can't tell what order actually occurred. Commutativity is easy to think about, but hard to precisely define. We developed a novel form of commutativity, SIM commutativity, that lets the rule apply even to the most complex software. We were able to show that given this novel form of commutativity, the rule is actually a law, true in a strict formal sense.  Precise reasoning about commutativity helps software designers understand the limits of software performance. It also helps software designers find new opportunities for speed. For instance, reasoning about commutativity helped us design new database-like software systems, for both multi-core processors and multi-machine systems, that can process transactions at greatly increased rates. These systems perform better at scale precisely because they explicitly take advantage of commutativity, whereas some previous systems' designs ignored the commutativity present in their problem definitions, and thus failed in some cases to scale.          Last Modified: 09/25/2018       Submitted by: Edward Kohler]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
