<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CCF:AF:EAGER Algorithmic Paradigms for Computation on MapReduce</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>100000.00</AwardTotalIntnAmount>
<AwardAmount>100000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rahul Shah</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Rapid advances in sensing technologies, as well as the ubiquity of online social and information networks, have led to unprecedented increase in the size and quantity of data sets that need to be stored and processed. Researchers are only beginning to grapple with the scale of data that modern systems generate. This provides a unique opportunity to design and implement algorithms at a scale that wasn't witnessed before, leading to unique challenges. The focus of this project is on designing algorithms for (arguably) the dominant computing paradigm for big data, MapReduce, and its variants. Despite its broad adoption across industries, there is very little work on developing theoretical models for these systems, or developing algorithms for natural optimization problems that arise in big-data applications. &lt;br/&gt;&lt;br/&gt;This project seeks to develop a strong theoretical understanding of large-scale data processing and a principled approach to algorithm design in these settings. The key challenge with MapReduce-type platforms is that they incorporate and modify aspects from several computing paradigms, such as streaming and parallel computing, which leads to significant challenges in modeling such systems and in developing algorithm design principles that apply across platforms. The principal investigator (PI) first seeks to define complexity measures for MapReduce algorithms. The PI next aims to find connections to and differentiate from more classical and widely studied models such as the Parallel Random Access Machine (PRAM), streaming computation, and I/O-efficient computation models, seeking to discover common algorithm design principles and computational limitations in this process. Via this process, the PI will develop efficient algorithms for classes of graph theoretic and statistical optimization problems that arise in big-data settings, and will also develop a suite of practical implementations for these.  The problems considered in this proposal are of fundamental nature, as evinced by their long and historic roots in theoretical computer science, parallel computation, and databases.   Computational science will benefit from this research.   Other broader impacts include graduate and undergraduate training in research and education.</AbstractNarration>
<MinAmdLetterDate>08/19/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1348696</AwardID>
<Investigator>
<FirstName>Kameshwar</FirstName>
<LastName>Munagala</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kameshwar Munagala</PI_FULL_NAME>
<EmailAddress>kamesh@cs.duke.edu</EmailAddress>
<PI_PHON>9196843030</PI_PHON>
<NSF_ID>000487108</NSF_ID>
<StartDate>08/19/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<StateCode>NC</StateCode>
<ZipCode>277080129</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>The major goals of this project are to model distrubuted cluster computing platforms such as MapReduce, Spark, etc at various levels: At the level of optimizing the execution of a single task (parallel computing), and at the level of optimizing the performance of different tasks running simultaenously on a cluster.&nbsp;</span></p> <p><span><strong>Intellectual Merit.</strong> This project has led to improved parallel algorithms for the basic graph theoretic problems of computing the densest subgraph as well as computing maximum matchings when the graph is bipartite. Applications include detecting communities in social networks as well as allocating advertisements to keywords in the context of search engines. This project has also led to the development of improved scheduling algorithms for tasks in a cluster, studying their fairness properties, as well as new techniques for their theoretical analysis. Finally, it has led to the study of fairness and efficiency of resource allocation in a computing cluster when the resources in question are shared by multiple tenants. This work is in collaboration with database researchers and has been open sourced.</span></p> <p><strong>Broader Impact. </strong>This project has led to the training of two graduate students and one undergraduate student. Much of this work is in collaboration with researchers in computer systems, architecture, and databases. This has led to the open sourcing of some code, and to some continuing implementation of the scheduling concepts developed, with the hope of open sourcing in the near future. The project on fairness in shared resource settings has morphed into an active research direction on vote aggregation in participatory budgeting, where the goal is to decide how to allocate a city's budget among competing public projects. This is in collaboration with researchers who are building and deploying such a system for public use.&nbsp;</p><br> <p>            Last Modified: 11/23/2015<br>      Modified by: Kameshwar&nbsp;Munagala</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goals of this project are to model distrubuted cluster computing platforms such as MapReduce, Spark, etc at various levels: At the level of optimizing the execution of a single task (parallel computing), and at the level of optimizing the performance of different tasks running simultaenously on a cluster.   Intellectual Merit. This project has led to improved parallel algorithms for the basic graph theoretic problems of computing the densest subgraph as well as computing maximum matchings when the graph is bipartite. Applications include detecting communities in social networks as well as allocating advertisements to keywords in the context of search engines. This project has also led to the development of improved scheduling algorithms for tasks in a cluster, studying their fairness properties, as well as new techniques for their theoretical analysis. Finally, it has led to the study of fairness and efficiency of resource allocation in a computing cluster when the resources in question are shared by multiple tenants. This work is in collaboration with database researchers and has been open sourced.  Broader Impact. This project has led to the training of two graduate students and one undergraduate student. Much of this work is in collaboration with researchers in computer systems, architecture, and databases. This has led to the open sourcing of some code, and to some continuing implementation of the scheduling concepts developed, with the hope of open sourcing in the near future. The project on fairness in shared resource settings has morphed into an active research direction on vote aggregation in participatory budgeting, where the goal is to decide how to allocate a city's budget among competing public projects. This is in collaboration with researchers who are building and deploying such a system for public use.        Last Modified: 11/23/2015       Submitted by: Kameshwar Munagala]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
