<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Large Deviation Methods for the Analysis and Design of Accelerated Monte Carlo Schemes</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>550000.00</AwardTotalIntnAmount>
<AwardAmount>550000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yong Zeng</SignBlockName>
<PO_EMAI>yzeng@nsf.gov</PO_EMAI>
<PO_PHON>7032927902</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The main focus of the research program is the use of large deviation ideas for the design and analysis of accelerated Monte Carlo methods.  In addition, the underlying large deviation theory will be developed where needed.  The PIs will emphasize two classes of problems, which are (i) accelerating the convergence of an empirical measure to a target stationary distribution and (ii) the estimation of the probability of a single rare event.  In prior work the PIs have initiated use of the large deviation rate for the empirical measure of a Markov process as a tool for algorithm analysis.  By considering suitable limits of the already effective parallel tempering algorithm, they developed a new algorithm called infinite swapping, as well as computationally tractable variants called partial infinite swapping.  The research program involves further theoretical development of the algorithm and the associated large deviation tools, as well as applications to challenging problems from materials science.  With regard to the estimation of the probability of a rare event, the PIs will continue to develop an approach based on large deviations and subsolutions to an associated Hamilton-Jacobi-Bellman equation for the design and analysis of importance sampling and certain types of branching algorithms.  The primary applications focus of the research program is the study of nanoscale materials.  Because their basic physical and chemical properties can differ significantly from those of their bulk counterparts, such materials are of substantial practical and theoretical interest.  Understanding how these basic properties are determined by the atomic-level details involved, an essential element in realizing the ultimate design potential of these systems, involves overcoming a number of rare event challenges. &lt;br/&gt;&lt;br/&gt;Monte Carlo algorithms are one of the most flexible and useful numerical tools in the applied sciences and engineering.  They are used to solve a broad range of problems, such as determining thermodynamic properties in models from chemistry and material science, evaluating equilibrium properties in large scale networks, and in problems of classification and estimation in Bayesian statistics.  However, with many Monte Carlo algorithms, rare events play a dominant role in determining the quality and hence usefulness of the resulting numerical approximation.  An important example is the approximation of integrals via Markov chain Monte Carlo.  These applications are very challenging when the distribution has pockets of significant probability and transitions between these pockets are rare.  Another example is estimation of the probability of a single rare event, such as unexpectedly large payouts in insurance claims or the transition between metastable wells in a model from chemical physics.  The PIs will develop and apply methods from large deviation theory, which is the branch of probability that analyzes and characterizes rare events, to the problem of efficient algorithm design.  They will apply these algorithms to problems of materials science.</AbstractNarration>
<MinAmdLetterDate>08/05/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/05/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1317199</AwardID>
<Investigator>
<FirstName>Jimmie</FirstName>
<LastName>Doll</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jimmie D Doll</PI_FULL_NAME>
<EmailAddress>jimmie_doll@brown.edu</EmailAddress>
<PI_PHON>4018633443</PI_PHON>
<NSF_ID>000400080</NSF_ID>
<StartDate>08/05/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Dupuis</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Paul G Dupuis</PI_FULL_NAME>
<EmailAddress>dupuis@cfm.brown.edu</EmailAddress>
<PI_PHON>4018633238</PI_PHON>
<NSF_ID>000110853</NSF_ID>
<StartDate>08/05/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129093</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Projects]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1253</Code>
<Text>OFFICE OF MULTIDISCIPLINARY AC</Text>
</ProgramElement>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~550000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Monte Carlo methods are among the most valuable, general purpose numerical tools currently available. They are used throughout the sciences and engineering, where in each case crucial information can be obtained by accurately computing certain integrals with respect to a (typically complicated) probability distribution. However, for this class of numerical methods, effectively dealing with what is called the "rare event sampling problem" is a particular challenge.</p> <p>In the usual approach to the approximation of the integral we interpret the probability measure as the stationary or invariant distribution of some Markov process. The most straightforward approach is to simulate the process and use the empirical measure of the simulated trajectory to approximate the true invariant distribution. In this case, if convergence to equilibrium depends on the occurrence of a large number of relatively rare events [such as the visits between isolated regions of high probability under the target measure], then the trajectory must be simulated for an extraordinarily long time before a good approximation is obtained.</p> <p>One of the most successful accelerated methods to overcome this difficulty is known as replica exchange or parallel tempering, which uses a collection of interacting simulations with different probabilistic behaviors to overcome this problem. However, a challenge in using these methods is that they are hard to analyze mathematically, and so extracting optimal performance from the methods is difficult. In prior work we introduced the use of ideas from the theory of large deviations, which is the part of probability that studies rare events, for the design and analysis of parallel tempering methods.&nbsp; Our analysis led to an optimized version of parallel tempering, which we call &ldquo;infinite swapping&rdquo;, that is obtained as the frequency of exchange attempts tends to infinity. The main focus of this project was the analysis and further mathematical and algorithmic development of infinite swapping.</p> <p>Among the accomplishments of the project, the following are notable:</p> <ul> <li>One of the great challenges in the use of Monte Carlo methods is understanding when a sufficient number of visits between regions of high probability have occurred so that the numerical approximation is accurate.&nbsp; Indeed, the rare event sampling issue can suggest that effective sampling has occurred when in fact the approximations are far from accurate. Using a property that is generic to tempering methods generally and which is easy to monitor during simulation, we developed a criterion which could be shown mathematically to be a prerequisite for convergence of the Monte Carlo approximation, and thus provides a convenient generic probe of sampling performance. </li> </ul> <ul> <li>Another class of difficult numerical integration problems occur when calculating generalized averages.&nbsp; These are complex valued integrals that might arise, for example, in a quantum calculation, and feature highly oscillatory integrands. &nbsp;Using a technique called stationary phase Monte Carlo, one can reduce the nature of the highly oscillatory integrand, but at the expense of introducing a rare event sampling problem.&nbsp; However, by combining techniques from thermodynamic integration with the infinite swapping algorithm, we are able to overcome this difficulty.</li> </ul> <ul> <li>In the usual framework of parallel tempering and infinite swapping, a temperature parameter distinguishes the statistical properties of the interacting simulations.&nbsp; A key issue then is how to select the temperatures to produce the most accurate numerical approximation, usually with an emphasis on greatest accuracy at the lowest temperature.&nbsp; Using large deviation methods, we were able in certain circumstances to explicitly solve the problem of optimal temperature selection as the lowest temperature tends to zero (which is also when the sampling problem becomes most challenging). </li> </ul> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/05/2017<br>      Modified by: Paul&nbsp;G&nbsp;Dupuis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Monte Carlo methods are among the most valuable, general purpose numerical tools currently available. They are used throughout the sciences and engineering, where in each case crucial information can be obtained by accurately computing certain integrals with respect to a (typically complicated) probability distribution. However, for this class of numerical methods, effectively dealing with what is called the "rare event sampling problem" is a particular challenge.  In the usual approach to the approximation of the integral we interpret the probability measure as the stationary or invariant distribution of some Markov process. The most straightforward approach is to simulate the process and use the empirical measure of the simulated trajectory to approximate the true invariant distribution. In this case, if convergence to equilibrium depends on the occurrence of a large number of relatively rare events [such as the visits between isolated regions of high probability under the target measure], then the trajectory must be simulated for an extraordinarily long time before a good approximation is obtained.  One of the most successful accelerated methods to overcome this difficulty is known as replica exchange or parallel tempering, which uses a collection of interacting simulations with different probabilistic behaviors to overcome this problem. However, a challenge in using these methods is that they are hard to analyze mathematically, and so extracting optimal performance from the methods is difficult. In prior work we introduced the use of ideas from the theory of large deviations, which is the part of probability that studies rare events, for the design and analysis of parallel tempering methods.  Our analysis led to an optimized version of parallel tempering, which we call "infinite swapping", that is obtained as the frequency of exchange attempts tends to infinity. The main focus of this project was the analysis and further mathematical and algorithmic development of infinite swapping.  Among the accomplishments of the project, the following are notable:  One of the great challenges in the use of Monte Carlo methods is understanding when a sufficient number of visits between regions of high probability have occurred so that the numerical approximation is accurate.  Indeed, the rare event sampling issue can suggest that effective sampling has occurred when in fact the approximations are far from accurate. Using a property that is generic to tempering methods generally and which is easy to monitor during simulation, we developed a criterion which could be shown mathematically to be a prerequisite for convergence of the Monte Carlo approximation, and thus provides a convenient generic probe of sampling performance.    Another class of difficult numerical integration problems occur when calculating generalized averages.  These are complex valued integrals that might arise, for example, in a quantum calculation, and feature highly oscillatory integrands.  Using a technique called stationary phase Monte Carlo, one can reduce the nature of the highly oscillatory integrand, but at the expense of introducing a rare event sampling problem.  However, by combining techniques from thermodynamic integration with the infinite swapping algorithm, we are able to overcome this difficulty.   In the usual framework of parallel tempering and infinite swapping, a temperature parameter distinguishes the statistical properties of the interacting simulations.  A key issue then is how to select the temperatures to produce the most accurate numerical approximation, usually with an emphasis on greatest accuracy at the lowest temperature.  Using large deviation methods, we were able in certain circumstances to explicitly solve the problem of optimal temperature selection as the lowest temperature tends to zero (which is also when the sampling problem becomes most challenging).               Last Modified: 12/05/2017       Submitted by: Paul G Dupuis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
