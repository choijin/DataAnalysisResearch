<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CI-ADDO-NEW: OCCAM: Open Curation for Computer Architecture Modeling</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>543042</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The computer architecture research community has created a rich and diverse collection of simulators, emulators, and benchmarks. Each individual research group has its own preferred tools, perhaps built on top of an existing or custom infrastructure. These artifacts are used in experiments to evaluate design trade-offs and to analyze implications to performance, energy, reliability, and other metrics. &lt;br/&gt;&lt;br/&gt;Unfortunately, the ways in which these tools are used for evaluation often hinder the application of the scientific method. The barrier to entry for using various artifacts (i.e., simulation tools and benchmarks) is usually high, when these artifacts are made available.  Experiments are rarely open, nor easily repeatable by other researchers, leading to inaccurate comparisons.  Moreover, it is difficult for a single group to explore all variations due to state-space explosion.&lt;br/&gt;&lt;br/&gt;To demonstrate that these problems can be addressed to improve computer architecture evaluation, this pilot project takes the first steps to develop an open-access repository that permits sharing artifacts and experimental results among a broad group of stakeholders in computer architecture.  The project builds and engages an active community of users, establishes governance and access policies, and determines the requirements for software services of the repository. This initial prototype provides the community an opportunity to supply feedback and suggestions to evolve the prototype and refine its policies.&lt;br/&gt;&lt;br/&gt;The project shows that significant collective effort can be saved by sharing simulators and experiments for accountable and repeatable experimentation as part of the scientific method. It avoids the burden of re-implementing and re-creating tools, experiments, data sets, benchmarks, etc. This savings in effort and more sound and complete evaluation can then be directed on innovating new architectural techniques for better computer systems.</AbstractNarration>
<MinAmdLetterDate>08/26/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/14/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1305220</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Mosse'</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Mosse'</PI_FULL_NAME>
<EmailAddress>mosse@cs.pitt.edu</EmailAddress>
<PI_PHON>4126248923</PI_PHON>
<NSF_ID>000229674</NSF_ID>
<StartDate>08/26/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Bruce</FirstName>
<LastName>Childers</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bruce Childers</PI_FULL_NAME>
<EmailAddress>childers@cs.pitt.edu</EmailAddress>
<PI_PHON>4126248421</PI_PHON>
<NSF_ID>000245880</NSF_ID>
<StartDate>08/26/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alex</FirstName>
<LastName>Jones</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alex Jones</PI_FULL_NAME>
<EmailAddress>akjones@engr.pitt.edu</EmailAddress>
<PI_PHON>4126249666</PI_PHON>
<NSF_ID>000239841</NSF_ID>
<StartDate>08/26/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152132303</ZipCode>
<StreetAddress><![CDATA[123 University Club]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>N587</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>O222</Code>
<Text/>
</ProgramElement>
<ProgramElement>
<Code>P228</Code>
<Text/>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>8237</Code>
<Text>CISE Interagency Agreements</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~200000</FUND_OBLG>
<FUND_OBLG>2014~100451</FUND_OBLG>
<FUND_OBLG>2015~98385</FUND_OBLG>
<FUND_OBLG>2016~144206</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Computer architecture researchers have created a rich and diverse collection of simulators, emulators, and benchmarks. Different research groups have their own preferred tools, perhaps built on top of an existing or custom infrastructure, which are used in experiments to evaluate design trade-offs and to analyze implications to performance, energy, reliability, and other metrics.&nbsp;<br /> <br /> The ways in which these tools are used for evaluation can hinder experimental study. The barrier to entry for using various artifacts (i.e., simulation tools and benchmarks) is usually high. Experiments may not be open, nor easily repeatable by other researchers, leading to incomplete comparisons. Moreover, it can be difficult for a single research group to explore all variations due to state-space explosion.<br /> <br /> To demonstrate that these challanges can be addressed, this pilot project took the first step toward developing a software system, OCCAM, to instantiate an open-access data, code, and experiment repository. With the OCCAM software, a repository can be established to share artifacts and experimental results among computer architecture researchers. The project developed and evaluated approaches for the prototype OCCAM software. It created a demonstrator of the software, with several simulators and tools in different test cases. Using these materials, the project engaged the research community to (1) determine data, code, and experiment requirements; (2) design and test the most promising technical approaches for the requirements; and (3) examine community processes to support a repository. The OCCAM software, which resulted from this project, can be used as a foundation to institute a production system and repository of simulators, tools, experiments, and results.</p> <p>Using the OCCAM software, collective effort can be saved by sharing simulators and experiments for accountable and repeatable experimentation as part of the scientific method. The prototype software demonstrated how an interactive, workflow-oriented system can be used to reduce the burden of re-implementing and re-creating tools, experiments, data sets, benchmarks, etc. This savings in effort can then be directed on innovating and further comparing new architectural techniques to design better computer systems.</p><br> <p>            Last Modified: 01/21/2019<br>      Modified by: Bruce&nbsp;Childers</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Computer architecture researchers have created a rich and diverse collection of simulators, emulators, and benchmarks. Different research groups have their own preferred tools, perhaps built on top of an existing or custom infrastructure, which are used in experiments to evaluate design trade-offs and to analyze implications to performance, energy, reliability, and other metrics.     The ways in which these tools are used for evaluation can hinder experimental study. The barrier to entry for using various artifacts (i.e., simulation tools and benchmarks) is usually high. Experiments may not be open, nor easily repeatable by other researchers, leading to incomplete comparisons. Moreover, it can be difficult for a single research group to explore all variations due to state-space explosion.    To demonstrate that these challanges can be addressed, this pilot project took the first step toward developing a software system, OCCAM, to instantiate an open-access data, code, and experiment repository. With the OCCAM software, a repository can be established to share artifacts and experimental results among computer architecture researchers. The project developed and evaluated approaches for the prototype OCCAM software. It created a demonstrator of the software, with several simulators and tools in different test cases. Using these materials, the project engaged the research community to (1) determine data, code, and experiment requirements; (2) design and test the most promising technical approaches for the requirements; and (3) examine community processes to support a repository. The OCCAM software, which resulted from this project, can be used as a foundation to institute a production system and repository of simulators, tools, experiments, and results.  Using the OCCAM software, collective effort can be saved by sharing simulators and experiments for accountable and repeatable experimentation as part of the scientific method. The prototype software demonstrated how an interactive, workflow-oriented system can be used to reduce the burden of re-implementing and re-creating tools, experiments, data sets, benchmarks, etc. This savings in effort can then be directed on innovating and further comparing new architectural techniques to design better computer systems.       Last Modified: 01/21/2019       Submitted by: Bruce Childers]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
