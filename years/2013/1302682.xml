<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Medium: Bridging the Software/Hardware Gap Towards Efficient, Heterogeneous, and Predictable Datacenters</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>750000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>tao li</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Much of today's computational capability is housed in massive cloud computing infrastructures sometimes known as "Warehouse Scale Computers."  This transition has given rise to a new class of emerging applications that run on hundreds of thousands of powerful cores, and access petabytes or exabytes of storage; these applications include web search, media streaming, big data analysis, etc. This centralization of the world's computing means that inefficiencies in those systems are magnified to a high degree -- in other words, if we can improve the efficiency of those systems, we measurably improve the efficiency (improve performance, reduce energy drain) of the world's computing infrastructure. This research addresses several sources of inefficiency, including increasingly inaccurate assumptions of hardware homogeneity, unpredictable interference between applications, and poor models of low-level resource sharing. &lt;br/&gt;&lt;br/&gt;This research addresses these inefficiencies by (1) creating a heterogeneity-aware execution framework for cloud platforms that not only accounts for the heterogeneous capabilities of the hardware that are expected to increase over time, but intentionally employs heterogeneity (at multiple levels) to improve efficiency in running diverse workloads; (2) creating a holistic runtime system for shared resource management that accounts for resource sharing at all levels, including low-level sharing on CMPs and multithreaded cores, allowing threads to be more aggressively co-scheduled; and (3) creating new precise prediction models for performance and quality of service that can drive more intelligent scheduling decisions.</AbstractNarration>
<MinAmdLetterDate>07/31/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302682</AwardID>
<Investigator>
<FirstName>Dean</FirstName>
<LastName>Tullsen</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dean M Tullsen</PI_FULL_NAME>
<EmailAddress>tullsen@cs.ucsd.edu</EmailAddress>
<PI_PHON>8585346181</PI_PHON>
<NSF_ID>000461702</NSF_ID>
<StartDate>07/31/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lingjia</FirstName>
<LastName>Tang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lingjia Tang</PI_FULL_NAME>
<EmailAddress>lingjia@umich.edu</EmailAddress>
<PI_PHON>4344092501</PI_PHON>
<NSF_ID>000628990</NSF_ID>
<StartDate>07/31/2013</StartDate>
<EndDate>09/11/2015</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jason</FirstName>
<LastName>Mars</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jason Mars</PI_FULL_NAME>
<EmailAddress>profmars@umich.edu</EmailAddress>
<PI_PHON>7347633229</PI_PHON>
<NSF_ID>000629579</NSF_ID>
<StartDate>07/31/2013</StartDate>
<EndDate>09/11/2015</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-San Diego</Name>
<CityName>La Jolla</CityName>
<ZipCode>920930934</ZipCode>
<PhoneNumber>8585344896</PhoneNumber>
<StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
<StreetAddress2><![CDATA[9500 Gilman Drive, 0934]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA49</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804355790</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SAN DIEGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCSD]]></Name>
<CityName>La Jolla</CityName>
<StateCode>CA</StateCode>
<ZipCode>920930404</ZipCode>
<StreetAddress><![CDATA[Dept of Computer Science and Eng]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>49</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA49</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~750000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Datacenters currently sponsor a dominant portion of the world&rsquo;s business and personal computational capability, and consume a significant fraction of the world&rsquo;s energy.&nbsp; Computational efficiency in these datacenters is critical to advancing our ability to solve key problems, and yet do so with reduced impact on our environment.</p> <p>This research addressed many challenges to datacenter efficiency. &nbsp;These include.</p> <p>Datacenters must co-locate diverse jobs, and doing so is inherently efficient.&nbsp; But this raises key challenges.&nbsp; This work demonstrated the ability to precisely estimate performance implications of application interference (both same-processor interference and same core, via SMT, interference), precise power accounting of interference.</p> <p>This research demonstrated the performance and security advantages of heterogeneous architectures that employ cores that run distinct instruction set architectures.&nbsp; It demonstrated that the cost of cross-ISA migration could be reduced by several orders of magnitude compared to prior solutions.&nbsp; Next it showed that such an architecture provides significant efficiency advantages, with as much as 21% performance gain and 23% energy gains over the best possible single-ISA heterogeneous design.</p> <p>Additionally, this work demonstrates significant security advantages of multi-ISA heterogeneous architectures.&nbsp; Such an architecture can address a wide array of security attacks, which fall under the broad label of Return-Oriented Programming, by frequently (in face of a possible attack) switching between cores with distinct ISAs.&nbsp; In this way, we can execute traditional code seamlessly, but make it nearly impossible for code that exploits unintentional control to execute intended or useful computation.</p> <p>This research further extended the heterogeneous-ISA compilation and runtime infrastructure to work on a real IBM datacenter across diverse machines.</p> <p>This research introduces DjiNN, an open infrastructure for DNN as a service in WSCs, and Tonic Suite, a suite of 7 end-to-end applications that span image, speech, and language processing.&nbsp; It used DjiNN to design a high throughput DNN system based on massive GPU server designs and provide insights as to the varying characteristics across applications.&nbsp; This improves DNN throughput by over 120x for all but one application (40x for Facial Recognition) on an NVIDIA K40 GPU.</p> <p>This project &nbsp;proposes the use of phase change materials (PCMs) to temporarily store the heat generated by the servers of a datacenter during peak load. The ability to store heat allows the system to shape the thermal behavior of the datacenter, releasing the heat only when it is advantageous to do so. This work presents and validates a methodology to study the impact of PCM on a datacenter. PCM can reduce the necessary cooling system size by up to 12% without impacting peak throughput, or increase the number of servers by up to 14.6% without increasing the cooling load.</p> <p>Sirius is an open end-to-end IPA web-service application that accepts queries in the form of voice and images, and responds with natural language. This workload is used to investigate the implications of four points in the design space of future accelerator-based server architectures spanning traditional CPUs, GPUs, manycore throughput co-processors, and FPGAs. Results show that GPU and FPGA accelerated servers improve the query latency on average by 10x and 16x, and reduce the TCO of datacenters by 2.6x and 1.4x, respectively.</p> <p>Adrenaline is an approach to leverage finer granularity, 10&rsquo;s of nanoseconds, voltage boosting to effectively rein in the tail latency. First, emerging finer granularity voltage/frequency boosting is an enabling mechanism for intelligent allocation of the power budget to precisely boost only the queries that contribute to the tail latency; and second, per-query characteristics can be used to design indicators for proactively pinpointing these queries, triggering boosting accordingly. This achieves up to a 2.50x tail latency improvement for Memcached and up to a 3.03x for Web Search.</p> <p>This work shows that directly adopting heterogeneous multicores without re-designing the software stack leads to significant QoS violations. Octopus-Man is a novel QoS-aware task management solution that dynamically maps latency-sensitive tasks to the least power-hungry processing resources that are sufficient to meet the QoS requirements. Octopus-Man improves energy efficiency by up to 41% (CPU power) and up to 15% (system power) over an all-brawny WSC.</p> <p>This project also sought to identify the underlying causes for QoS violation in accelerator-outfitted servers. Experiments show that queuing delay for the compute resources and PCI-e bandwidth contention for data transfer are the main two factors that contribute to the long tails of user-facing applications. Baymax is a runtime system that orchestrates the execution of compute tasks from different applications and mitigates PCI-e bandwidth contention to deliver the required QoS.</p> <p>Broader Impacts:&nbsp; This research provided training, exposure, and industry internship opportunities, for a large, diverse group of graduate students from both Universities.&nbsp; This project significantly advances the ability to provide cloud-based computation at reduced energy cost.&nbsp; Due to the high worldwide demand for datacenter-based power, any reduction in energy consumption will have noticeable effect on world energy resources and environmental impacts.</p> <p>&nbsp;</p><br> <p>            Last Modified: 02/20/2017<br>      Modified by: Dean&nbsp;M&nbsp;Tullsen</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Datacenters currently sponsor a dominant portion of the world?s business and personal computational capability, and consume a significant fraction of the world?s energy.  Computational efficiency in these datacenters is critical to advancing our ability to solve key problems, and yet do so with reduced impact on our environment.  This research addressed many challenges to datacenter efficiency.  These include.  Datacenters must co-locate diverse jobs, and doing so is inherently efficient.  But this raises key challenges.  This work demonstrated the ability to precisely estimate performance implications of application interference (both same-processor interference and same core, via SMT, interference), precise power accounting of interference.  This research demonstrated the performance and security advantages of heterogeneous architectures that employ cores that run distinct instruction set architectures.  It demonstrated that the cost of cross-ISA migration could be reduced by several orders of magnitude compared to prior solutions.  Next it showed that such an architecture provides significant efficiency advantages, with as much as 21% performance gain and 23% energy gains over the best possible single-ISA heterogeneous design.  Additionally, this work demonstrates significant security advantages of multi-ISA heterogeneous architectures.  Such an architecture can address a wide array of security attacks, which fall under the broad label of Return-Oriented Programming, by frequently (in face of a possible attack) switching between cores with distinct ISAs.  In this way, we can execute traditional code seamlessly, but make it nearly impossible for code that exploits unintentional control to execute intended or useful computation.  This research further extended the heterogeneous-ISA compilation and runtime infrastructure to work on a real IBM datacenter across diverse machines.  This research introduces DjiNN, an open infrastructure for DNN as a service in WSCs, and Tonic Suite, a suite of 7 end-to-end applications that span image, speech, and language processing.  It used DjiNN to design a high throughput DNN system based on massive GPU server designs and provide insights as to the varying characteristics across applications.  This improves DNN throughput by over 120x for all but one application (40x for Facial Recognition) on an NVIDIA K40 GPU.  This project  proposes the use of phase change materials (PCMs) to temporarily store the heat generated by the servers of a datacenter during peak load. The ability to store heat allows the system to shape the thermal behavior of the datacenter, releasing the heat only when it is advantageous to do so. This work presents and validates a methodology to study the impact of PCM on a datacenter. PCM can reduce the necessary cooling system size by up to 12% without impacting peak throughput, or increase the number of servers by up to 14.6% without increasing the cooling load.  Sirius is an open end-to-end IPA web-service application that accepts queries in the form of voice and images, and responds with natural language. This workload is used to investigate the implications of four points in the design space of future accelerator-based server architectures spanning traditional CPUs, GPUs, manycore throughput co-processors, and FPGAs. Results show that GPU and FPGA accelerated servers improve the query latency on average by 10x and 16x, and reduce the TCO of datacenters by 2.6x and 1.4x, respectively.  Adrenaline is an approach to leverage finer granularity, 10?s of nanoseconds, voltage boosting to effectively rein in the tail latency. First, emerging finer granularity voltage/frequency boosting is an enabling mechanism for intelligent allocation of the power budget to precisely boost only the queries that contribute to the tail latency; and second, per-query characteristics can be used to design indicators for proactively pinpointing these queries, triggering boosting accordingly. This achieves up to a 2.50x tail latency improvement for Memcached and up to a 3.03x for Web Search.  This work shows that directly adopting heterogeneous multicores without re-designing the software stack leads to significant QoS violations. Octopus-Man is a novel QoS-aware task management solution that dynamically maps latency-sensitive tasks to the least power-hungry processing resources that are sufficient to meet the QoS requirements. Octopus-Man improves energy efficiency by up to 41% (CPU power) and up to 15% (system power) over an all-brawny WSC.  This project also sought to identify the underlying causes for QoS violation in accelerator-outfitted servers. Experiments show that queuing delay for the compute resources and PCI-e bandwidth contention for data transfer are the main two factors that contribute to the long tails of user-facing applications. Baymax is a runtime system that orchestrates the execution of compute tasks from different applications and mitigates PCI-e bandwidth contention to deliver the required QoS.  Broader Impacts:  This research provided training, exposure, and industry internship opportunities, for a large, diverse group of graduate students from both Universities.  This project significantly advances the ability to provide cloud-based computation at reduced energy cost.  Due to the high worldwide demand for datacenter-based power, any reduction in energy consumption will have noticeable effect on world energy resources and environmental impacts.          Last Modified: 02/20/2017       Submitted by: Dean M Tullsen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
