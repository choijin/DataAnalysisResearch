<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Enhancing Comparative Assessment for Chemistry with or without Standardized Testing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>386417.00</AwardTotalIntnAmount>
<AwardAmount>386417</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11040200</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DUE</Abbreviation>
<LongName>Division Of Undergraduate Education</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dawn Rickey</SignBlockName>
<PO_EMAI>drickey@nsf.gov</PO_EMAI>
<PO_PHON>7032924674</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In response to an increasing need for faculty members and departments to perform more thorough assessments of student learning, this project is conducting research on and developing tools to perform assessments of student learning in undergraduate chemistry courses.  The overarching goal of the project is to provide chemistry instructors access to data warehouses of student performance on chemistry test items that can be queried to compare the performance of their students to the performance of the entire population in the database.  This work is leveraging long-standing capacity in comparative assessment within chemistry education, as provided through norm-referenced examinations produced by the American Chemical Society Examinations Institute, with software developers, whose expertise led to the creation of the Online Web-based Learning (OWL) system used by 200,000 students of chemistry.&lt;br/&gt;&lt;br/&gt;Intellectual Merit: Conducting psychometric research and developing semi-automated methods for instructors to align test items to a content criterion template are facilitating significant progress in both chemistry education and psychometrics.  Specific project activities include producing an anchoring concepts content map (ACCM) for the entire undergraduate chemistry curriculum, creating a portal that allows chemistry instructors to connect and dynamically align their own test items to the ACCM and establishing a mechanism for instructors to compare the performances of their own students on their locally-written test items with national data sets of student performance.   Developing the requisite software tools advances understanding in several key areas, such as architecture for test item meta tags, efficiency of test data warehousing, user-friendly query tools for assessment development and effectual data organization and visualization in assessment outcomes reports for users.&lt;br/&gt;&lt;br/&gt;Broader Impacts: This work is developing practical tools for chemistry instructors from all institution types to improve their marshaling of evidence with regard to student learning in chemistry.  As the database of student performance on assessments grows, data will permit for more complete and meaningful comparisons of the efficacy of curricular and pedagogical reforms.  Outcomes from this project can be used to inform science education research across all disciplines.</AbstractNarration>
<MinAmdLetterDate>09/03/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/03/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1323469</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Hart</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David M Hart</PI_FULL_NAME>
<EmailAddress>dhart@cs.umass.edu</EmailAddress>
<PI_PHON>4135453278</PI_PHON>
<NSF_ID>000241318</NSF_ID>
<StartDate>09/03/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stephen</FirstName>
<LastName>Battisti</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stephen M Battisti</PI_FULL_NAME>
<EmailAddress>battisti@cs.umass.edu</EmailAddress>
<PI_PHON>4135450698</PI_PHON>
<NSF_ID>000066291</NSF_ID>
<StartDate>09/03/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>April</FirstName>
<LastName>Zenisky</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>April Zenisky</PI_FULL_NAME>
<EmailAddress>azenisky@educ.umass.edu</EmailAddress>
<PI_PHON>4135453610</PI_PHON>
<NSF_ID>000585657</NSF_ID>
<StartDate>09/03/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Massachusetts Amherst</Name>
<CityName>Hadley</CityName>
<ZipCode>010359450</ZipCode>
<PhoneNumber>4135450698</PhoneNumber>
<StreetAddress>Research Administration Building</StreetAddress>
<StreetAddress2><![CDATA[100 Venture Way, Suite 201]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>153926712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MASSACHUSETTS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>079520631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Massachusetts Amherst]]></Name>
<CityName>Amherst</CityName>
<StateCode>MA</StateCode>
<ZipCode>010039264</ZipCode>
<StreetAddress><![CDATA[70 Butterfield Terrace]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1536</Code>
<Text>S-STEM-Schlr Sci Tech Eng&amp;Math</Text>
</ProgramElement>
<ProgramElement>
<Code>7511</Code>
<Text>TUES-Type 2 Project</Text>
</ProgramElement>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0413</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>13XX</Code>
<Name>H-1B FUND, EHR, NSF</Name>
<APP_SYMB_ID>045176</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~386417</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project&rsquo;s primary goal is to improve assessment in undergraduate chemistry education.&nbsp; It&rsquo;s a collaborative project between researchers at the University of Massachusetts at Amherst and researchers at Iowa State University affiliated with the American Chemical Society&rsquo;s Examinations Institute (ACS-EI) and is designed to increase the use of the Anchoring Chemistry Concept Maps (ACCM) being developed for many of the chemistry sub-disciplinary areas covered by ACS Exams: general chemistry, organic chemistry, inorganic chemistry, physical chemistry, analytical chemistry and biochemistry.&nbsp; The ACCM is a hierarchical organization of chemistry concepts to which exam items can be aligned to support <em>criterion-based</em> score reporting, which is far more diagnostic than assigning a single score to a test outcome.&nbsp; From criterion-based reporting instructors can see which conceptual areas of the curriculum students are doing well in and where there are problems.&nbsp; Online ACS Exams already report their results using this method.&nbsp;</p> <p>In this project we have developed a software system called QMAP that lets general chemistry instructors who do <em>not</em> use ACS exams take advantage of the criterion-based reporting enabled by the ACCM.&nbsp; Instructors upload their own exam questions into QMAP and the system helps them align each question with the general chemistry ACCM.&nbsp; Once aligned, the instructor can see how well students did on those items compared to students from across the country who took ACS exams with similar items.&nbsp; QMAP uses advanced information retrieval techniques to match instructor-submitted test items to the appropriate concepts in the concept map.&nbsp; The user interface allows the instructor to enter an exam item and then displays the closest five matching concepts, from which the instructor can pick the most suitable.&nbsp; In testing, QMAP was able to suggest the most suitable matching concept as the top recommendation over 80% of the time. Next steps for the QMAP project include opening it up to the general chemistry instructor community for wide-spread use, improving the user interface in consultation with human factors experts, and expanding its use to the other chemistry sub-disciplines covered by the ACCM.&nbsp;&nbsp;</p> <p>QMAP holds great promise for opening up the recently developed diagnostic capabilities enabled by the ACCM to a wider community of instructors besides those who use ACS Exams.&nbsp; This has the potential to advance evidence-based approaches to the evaluation of chemistry curricula and instruction if widely adopted.&nbsp; In the case of general chemistry, a foundational course in most STEM majors, this can have a ripple effect in other disciplines.&nbsp; When expanded to the other ACCM chemistry sub-disciplines it will allow instructors throughout the chemistry majors sequence to effectively assess their students&rsquo; progress.&nbsp;</p> <p>With respect to the educational assessment portion of the project, UMass researchers helped Exams Institute staff mock up and try out report formats with end users (chemistry instructors) in multiple workshops.&nbsp;The feedback received indicated that end users liked the reports prepared by the research team, but they also desired a high degree of flexibility in terms of being able to manipulate or rearrange the data with respect to individual or institutional priorities. This is significant because it reinforces the differences between institutions and how individual users look at data, and suggests that future report development and reporting activities should seek further user guidance about the process of assessment data use to build data tools that provide users with the tools to mine the data given their needs, within broader categories of use and aggregation (individual student, class, class section, department/division, etc.).</p> <p>The research on reporting carried out through this grant provided key insight into user behavior and data use in the higher education context, which is a critically understudied educational data use setting. This finding has helped us refine our approach to report development with respect to diversifying user groups and reporting purposes.&nbsp; This project has engaged educators from a wide range of institutions to participate in workshops and other meetings to provide feedback on the reporting system, and in the process, these meetings have provided those participants with a venue for critical reflection on educational practice with respect to data use in their higher education classrooms.&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/10/2018<br>      Modified by: David&nbsp;M&nbsp;Hart</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project?s primary goal is to improve assessment in undergraduate chemistry education.  It?s a collaborative project between researchers at the University of Massachusetts at Amherst and researchers at Iowa State University affiliated with the American Chemical Society?s Examinations Institute (ACS-EI) and is designed to increase the use of the Anchoring Chemistry Concept Maps (ACCM) being developed for many of the chemistry sub-disciplinary areas covered by ACS Exams: general chemistry, organic chemistry, inorganic chemistry, physical chemistry, analytical chemistry and biochemistry.  The ACCM is a hierarchical organization of chemistry concepts to which exam items can be aligned to support criterion-based score reporting, which is far more diagnostic than assigning a single score to a test outcome.  From criterion-based reporting instructors can see which conceptual areas of the curriculum students are doing well in and where there are problems.  Online ACS Exams already report their results using this method.   In this project we have developed a software system called QMAP that lets general chemistry instructors who do not use ACS exams take advantage of the criterion-based reporting enabled by the ACCM.  Instructors upload their own exam questions into QMAP and the system helps them align each question with the general chemistry ACCM.  Once aligned, the instructor can see how well students did on those items compared to students from across the country who took ACS exams with similar items.  QMAP uses advanced information retrieval techniques to match instructor-submitted test items to the appropriate concepts in the concept map.  The user interface allows the instructor to enter an exam item and then displays the closest five matching concepts, from which the instructor can pick the most suitable.  In testing, QMAP was able to suggest the most suitable matching concept as the top recommendation over 80% of the time. Next steps for the QMAP project include opening it up to the general chemistry instructor community for wide-spread use, improving the user interface in consultation with human factors experts, and expanding its use to the other chemistry sub-disciplines covered by the ACCM.    QMAP holds great promise for opening up the recently developed diagnostic capabilities enabled by the ACCM to a wider community of instructors besides those who use ACS Exams.  This has the potential to advance evidence-based approaches to the evaluation of chemistry curricula and instruction if widely adopted.  In the case of general chemistry, a foundational course in most STEM majors, this can have a ripple effect in other disciplines.  When expanded to the other ACCM chemistry sub-disciplines it will allow instructors throughout the chemistry majors sequence to effectively assess their students? progress.   With respect to the educational assessment portion of the project, UMass researchers helped Exams Institute staff mock up and try out report formats with end users (chemistry instructors) in multiple workshops. The feedback received indicated that end users liked the reports prepared by the research team, but they also desired a high degree of flexibility in terms of being able to manipulate or rearrange the data with respect to individual or institutional priorities. This is significant because it reinforces the differences between institutions and how individual users look at data, and suggests that future report development and reporting activities should seek further user guidance about the process of assessment data use to build data tools that provide users with the tools to mine the data given their needs, within broader categories of use and aggregation (individual student, class, class section, department/division, etc.).  The research on reporting carried out through this grant provided key insight into user behavior and data use in the higher education context, which is a critically understudied educational data use setting. This finding has helped us refine our approach to report development with respect to diversifying user groups and reporting purposes.  This project has engaged educators from a wide range of institutions to participate in workshops and other meetings to provide feedback on the reporting system, and in the process, these meetings have provided those participants with a venue for critical reflection on educational practice with respect to data use in their higher education classrooms.              Last Modified: 01/10/2018       Submitted by: David M Hart]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
