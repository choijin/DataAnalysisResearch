<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Visual Cortex on Silicon</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>600000.00</AwardTotalIntnAmount>
<AwardAmount>680000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The human vision system understands and interprets complex scenes for a wide range of visual tasks in real-time while consuming less than 20 Watts of power. This Expeditions-in-Computing project explores holistic design of machine vision systems that have the potential to approach and eventually exceed the capabilities of human vision systems. This will enable the next generation of machine vision systems to not only record images but also understand visual content. Such smart machine vision systems will have a multi-faceted impact on society, including visual aids for visually impaired persons, driver assistance for reducing automotive accidents, and augmented reality for enhanced shopping, travel, and safety. The transformative nature of the research will inspire and train a new generation of students in inter-disciplinary work that spans neuroscience, computing and engineering discipline.&lt;br/&gt;&lt;br/&gt;While several machine vision systems today can each successfully perform one or a few human tasks ? such as detecting human faces in point-and-shoot cameras ? they are still limited in their ability to perform a wide range of visual tasks, to operate in complex, cluttered environments, and to provide reasoning for their decisions.  In contrast, the mammalian visual cortex excels in a broad variety of goal-oriented cognitive tasks, and is at least three orders of magnitude more energy efficient than customized state-of-the-art machine vision systems. The proposed research envisions a holistic design of a machine vision system that will approach the cognitive abilities of the human cortex, by developing a comprehensive solution consisting of vision algorithms, hardware design, human-machine interfaces, and information storage. The project aims to understand the fundamental mechanisms used in the visual cortex to enable the design of new vision algorithms and hardware fabrics that can improve power, speed, flexibility, and recognition accuracies relative to existing machine vision systems. Towards this goal, the project proposes an ambitious inter-disciplinary research agenda that will (i) understand goal-directed visual attention mechanisms in the brain to design task-driven vision algorithms; (ii) develop vision theory and algorithms that scale in performance with increasing complexity of a scene; (iii) integrate complementary approaches in biological and machine vision techniques; (iv) develop a new-genre of computing architectures inspired by advances in both the understanding of the visual cortex and the emergence of electronic devices; and (v) design human-computer interfaces that will effectively assist end-users while preserving privacy and maximizing utility. These advances will allow us to replace current-day cameras with cognitive visual systems that more intelligently analyze and understand complex scenes, and dynamically interact with users.&lt;br/&gt;&lt;br/&gt;Machine vision systems that understand and interact with their environment in ways similar to humans will enable new transformative applications. The project will develop experimental platforms to: (1) assist visually impaired people; (2) enhance driver attention; and (3) augment reality to provide enhanced experience for retail shopping or a vacation visit, and enhanced safety for critical public infrastructure. This project will result in education and research artifacts that will be disseminated widely through a web portal and via online lecture delivery. The resulting artifacts and prototypes will enhance successful ongoing outreach programs to under-represented minorities and the general public, such as museum exhibits, science fairs, and a summer camp aimed at K-12 students. It will also spur similar new outreach efforts at other partner locations. The project will help identify and develop course material and projects directed at instilling interest in computing fields for students in four-year colleges. Partnerships with two Hispanic serving institutes, industry, national labs and international projects are also planned.</AbstractNarration>
<MinAmdLetterDate>09/17/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1317470</AwardID>
<Investigator>
<FirstName>H.-S. Philip</FirstName>
<LastName>Wong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>H.-S. Philip Wong</PI_FULL_NAME>
<EmailAddress>hspwong@stanford.edu</EmailAddress>
<PI_PHON>6507250982</PI_PHON>
<NSF_ID>000168006</NSF_ID>
<StartDate>09/17/2013</StartDate>
<EndDate>08/24/2018</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Subhasish</FirstName>
<LastName>Mitra</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Subhasish Mitra</PI_FULL_NAME>
<EmailAddress>subh@stanford.edu</EmailAddress>
<PI_PHON>6507241915</PI_PHON>
<NSF_ID>000069199</NSF_ID>
<StartDate>08/24/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009214214</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LELAND STANFORD JUNIOR UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009214214</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stanford University]]></Name>
<CityName>Stanford</CityName>
<StateCode>CA</StateCode>
<ZipCode>943052004</ZipCode>
<StreetAddress><![CDATA[420 Via Palou]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7723</Code>
<Text>Expeditions in Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7723</Code>
<Text>EXPERIMENTAL EXPEDITIONS</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~240000</FUND_OBLG>
<FUND_OBLG>2014~120000</FUND_OBLG>
<FUND_OBLG>2015~240000</FUND_OBLG>
<FUND_OBLG>2017~80000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="WordSection1"> <p>Demand for more energy-efficient artificial intelligent systems has driven the design for AI domain-specific accelerators. However, data transfer between separate compute and memory units becomes the main energy-efficiency bottleneck for today?s AI hardware systems, limiting scalability for the ever-demanding AI tasks. This collaborative effort from Stanford and UCSD aims to overcome the challenge by utilizing novel Compute-In-Memory (CIM) architecture to eliminate the data transfer and implement such architecture using emerging non-volatile memory (NVM) technologies ensuring future scalability towards larger, more complex AI models.</p> <p>The interdisciplinary nature of the project requires us to understand and innovate across the full-stack of the AI system, and perform cross-layer optimization to fully exploit the benefits of NVM based CIM architecture. We started by identifying key requirements of the AI hardware ? energy-efficiency and reconfigurability. We performed an architectural analysis to understand the bottlenecks impeding the requirements, and co-designed the algorithm, architecture, and circuit to overcome the limitations. Meanwhile, to understand device non-idealities that hamper hardware implementation, we fabricated and characterized various NVM devices including RRAM, PCM and CBRAM, and experimentally demonstrated AI inference and training on the fabricated array. Finally, combining our knowledge from architecture-level to device-level, we designed and tested the first fully-integrated CMOS-RRAM CIM hardware that simultaneously offers state-of-the-art energy-efficiency and reconfigurability, achieving our initial project goal.</p> <p>Our architectural analysis revealed four key challenges for realizing high energy-efficiency and reconfigurability. (1) High bit-precision used by AI models demand high-precision data converters (ADCs, DACs) that dominate area and energy consumption. (2) when the memory array is large, low array utilization results in low energy-efficiency. (3) conventional current-mode sensing used for CIM keeps memory array activated during sensing, consuming large energy. (4) conventional CIM architecture has fixed dataflow direction. Implementing reconfigurable dataflow required by different AI models lead to latency, energy, and area overheads.</p> <p>To address the first two challenges, we co-designed the algorithm with architecture utilizing the intrinsic redundancy of neural network models. We studied trained-quantization and structured-pruning techniques tailored for NVM-CIM hardware to mitigate high-precision DACs/ADCs and array size requirements. Our resulting architecture design, "ERNIE", achieved 25-680 TOPS/W energy efficiency and 2.2-42 TOPS/mm^2 throughput in 28nm technology with little-to-no loss of neural network inference accuracy - orders of magnitude better than previously-reported designs with resistive memory. The ERNIE architecture outperformed digital implementation of the same algorithm by ~8x.</p> </div> <p>To improve sensing efficiency, we designed a novel voltage-mode sensing scheme that achieves 3.6? improvement in energy-efficiency compared to the conventional current-mode sensing by eliminating the static current-flow, and&nbsp; avoids the nonlinearity issue that prevents conventional voltage-mode sensing from sensing multi-bit outputs. Additionally, we experimentally studied two neural network weight mapping schemes under the voltage-mode sensing and compared their performance under various scenarios (VLSI 2020, Paper TM2.2).</p> <p>The reconfigurability of dataflow direction is realized through our novel architecture design ? Transposable Neurosynaptic Core (TNC). We first presented the TNC architecture at the 2020 International Solid-State Circuits Conference (ISSCC, Paper 33.1). Instead of arranging the sensing circuits on the peripheral of NVM array as in most conventional CIM architecture, the TNC interleave the sensing circuits and NVM array within the same area. The matrix-vector-multiplication dataflow direction (forward, backward, or recurrent) can be dynamically reconfigured within a TNC without needing additional hardware on the peripheral, realizing reconfigurability without sacrificing efficiency.</p> <p>We fabricated and characterized various NVM devices using Stanford?s nano-fabrication facility and through external collaborations with IBM and Tsinghua University (China). We studied 3D integration of the NVMs and the CMOS, and characterized NVM devices and arrays for their capability to be applied for in-memory inference and training. Using the fabricated memory array, we experimentally demonstrated the inference and training of a 45-synapse Restricted Boltzmann Machine (RBM) realized with 90 PCM elements. Measured energy consumption is 6.1 nJ per epoch, ~150 times lower than conventional processor-memory systems.</p> <p>Architectural innovations and experimental studies laid the foundation for successful hardware implementation. We demonstrated the first fully-integrated CMOS-RRAM CIM hardware that simultaneously delivers the record energy-efficiency of 74TMACS/W among RRAM-based CIM hardware and offers intrinsic data reconfigurability to support various neural network architectures such as Multi-layer Perceptron, Convolutional Neural Network, Recurrent Neural Network and Restricted Boltzmann Machine (RBM) (2020 ISSCC conference). We taped-out two chips using 130nm CMOS process with monolithically-integrated HfOx RRAMs. The first chip contains a single Transposable Neurosynaptic Core with 65K RRAM weights and 256 CMOS neurons; the second chip contains 48 cores with 3M RRAMs and 12K neurons. We developed a comprehensive set of hardware and software tools allowing easy implementation of AI models on our chips. We successfully demonstrated image recovery, image classification, and voice recognition applications on our hardware. The real-time image recovery using RBM was presented at the 2020 ISSCC demo sessions and the 2020 VLSI conferences: &nbsp;<a href="https://youtu.be/b7ITxmfaLBk">https://youtu.be/b7ITxmfaLBk</a>. This hardware is an important milestone towards future energy-efficient, flexible, and scalable AI fabrics.</p><br> <p>            Last Modified: 07/14/2020<br>      Modified by: Subhasish&nbsp;Mitra</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594663059967_single_core--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594663059967_single_core--rgov-800width.jpg" title="Single Core"><img src="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594663059967_single_core--rgov-66x44.jpg" alt="Single Core"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Test Chip Micrograph and Testing Board</div> <div class="imageCredit">Wan, Weier; et al. ISSCC 2020</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Subhasish&nbsp;Mitra</div> <div class="imageTitle">Single Core</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594660765563_application_demo--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594660765563_application_demo--rgov-800width.jpg" title="Application demo"><img src="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594660765563_application_demo--rgov-66x44.jpg" alt="Application demo"></a> <div class="imageCaptionContainer"> <div class="imageCaption">MNIST image recovery using Restricted Boltzmann Machine</div> <div class="imageCredit">Wan, Weier et al., ISSCC 2020, VLSI 2020</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Subhasish&nbsp;Mitra</div> <div class="imageTitle">Application demo</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594662807467_energy_efficiency--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594662807467_energy_efficiency--rgov-800width.jpg" title="Energy Efficiency"><img src="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594662807467_energy_efficiency--rgov-66x44.jpg" alt="Energy Efficiency"></a> <div class="imageCaptionContainer"> <div class="imageCaption">RRAM Compute-in-memory chips energy efficiency comparison</div> <div class="imageCredit">Wan, Weier; et al. ISSCC 2020</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Subhasish&nbsp;Mitra</div> <div class="imageTitle">Energy Efficiency</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594663250082_TNC--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594663250082_TNC--rgov-800width.jpg" title="TNC"><img src="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594663250082_TNC--rgov-66x44.jpg" alt="TNC"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Transposable Neurosynaptic Core</div> <div class="imageCredit">Wan, Weier; et al. ISSCC 2020</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Subhasish&nbsp;Mitra</div> <div class="imageTitle">TNC</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594743913770_48core_api--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594743913770_48core_api--rgov-800width.jpg" title="48core API"><img src="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594743913770_48core_api--rgov-66x44.jpg" alt="48core API"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Multi-Core Chip with Software API</div> <div class="imageCredit">Wan, Weier</div> <div class="imagePermisssions">Royalty-free (restricted use - cannot be shared)</div> <div class="imageSubmitted">Subhasish&nbsp;Mitra</div> <div class="imageTitle">48core API</div> </div> </li> <li> <a href="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594744019750_device_characterization--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594744019750_device_characterization--rgov-800width.jpg" title="Device Characterization"><img src="/por/images/Reports/POR/2020/1317470/1317470_10281068_1594744019750_device_characterization--rgov-66x44.jpg" alt="Device Characterization"></a> <div class="imageCaptionContainer"> <div class="imageCaption">RRAM conductance relaxation; Device-to-device and cycle-to-cycle variation of gradual conductance modulation</div> <div class="imageCredit">Wan, Weier</div> <div class="imagePermisssions">Royalty-free (restricted use - cannot be shared)</div> <div class="imageSubmitted">Subhasish&nbsp;Mitra</div> <div class="imageTitle">Device Characterization</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[  Demand for more energy-efficient artificial intelligent systems has driven the design for AI domain-specific accelerators. However, data transfer between separate compute and memory units becomes the main energy-efficiency bottleneck for today?s AI hardware systems, limiting scalability for the ever-demanding AI tasks. This collaborative effort from Stanford and UCSD aims to overcome the challenge by utilizing novel Compute-In-Memory (CIM) architecture to eliminate the data transfer and implement such architecture using emerging non-volatile memory (NVM) technologies ensuring future scalability towards larger, more complex AI models.  The interdisciplinary nature of the project requires us to understand and innovate across the full-stack of the AI system, and perform cross-layer optimization to fully exploit the benefits of NVM based CIM architecture. We started by identifying key requirements of the AI hardware ? energy-efficiency and reconfigurability. We performed an architectural analysis to understand the bottlenecks impeding the requirements, and co-designed the algorithm, architecture, and circuit to overcome the limitations. Meanwhile, to understand device non-idealities that hamper hardware implementation, we fabricated and characterized various NVM devices including RRAM, PCM and CBRAM, and experimentally demonstrated AI inference and training on the fabricated array. Finally, combining our knowledge from architecture-level to device-level, we designed and tested the first fully-integrated CMOS-RRAM CIM hardware that simultaneously offers state-of-the-art energy-efficiency and reconfigurability, achieving our initial project goal.  Our architectural analysis revealed four key challenges for realizing high energy-efficiency and reconfigurability. (1) High bit-precision used by AI models demand high-precision data converters (ADCs, DACs) that dominate area and energy consumption. (2) when the memory array is large, low array utilization results in low energy-efficiency. (3) conventional current-mode sensing used for CIM keeps memory array activated during sensing, consuming large energy. (4) conventional CIM architecture has fixed dataflow direction. Implementing reconfigurable dataflow required by different AI models lead to latency, energy, and area overheads.  To address the first two challenges, we co-designed the algorithm with architecture utilizing the intrinsic redundancy of neural network models. We studied trained-quantization and structured-pruning techniques tailored for NVM-CIM hardware to mitigate high-precision DACs/ADCs and array size requirements. Our resulting architecture design, "ERNIE", achieved 25-680 TOPS/W energy efficiency and 2.2-42 TOPS/mm^2 throughput in 28nm technology with little-to-no loss of neural network inference accuracy - orders of magnitude better than previously-reported designs with resistive memory. The ERNIE architecture outperformed digital implementation of the same algorithm by ~8x.   To improve sensing efficiency, we designed a novel voltage-mode sensing scheme that achieves 3.6? improvement in energy-efficiency compared to the conventional current-mode sensing by eliminating the static current-flow, and  avoids the nonlinearity issue that prevents conventional voltage-mode sensing from sensing multi-bit outputs. Additionally, we experimentally studied two neural network weight mapping schemes under the voltage-mode sensing and compared their performance under various scenarios (VLSI 2020, Paper TM2.2).  The reconfigurability of dataflow direction is realized through our novel architecture design ? Transposable Neurosynaptic Core (TNC). We first presented the TNC architecture at the 2020 International Solid-State Circuits Conference (ISSCC, Paper 33.1). Instead of arranging the sensing circuits on the peripheral of NVM array as in most conventional CIM architecture, the TNC interleave the sensing circuits and NVM array within the same area. The matrix-vector-multiplication dataflow direction (forward, backward, or recurrent) can be dynamically reconfigured within a TNC without needing additional hardware on the peripheral, realizing reconfigurability without sacrificing efficiency.  We fabricated and characterized various NVM devices using Stanford?s nano-fabrication facility and through external collaborations with IBM and Tsinghua University (China). We studied 3D integration of the NVMs and the CMOS, and characterized NVM devices and arrays for their capability to be applied for in-memory inference and training. Using the fabricated memory array, we experimentally demonstrated the inference and training of a 45-synapse Restricted Boltzmann Machine (RBM) realized with 90 PCM elements. Measured energy consumption is 6.1 nJ per epoch, ~150 times lower than conventional processor-memory systems.  Architectural innovations and experimental studies laid the foundation for successful hardware implementation. We demonstrated the first fully-integrated CMOS-RRAM CIM hardware that simultaneously delivers the record energy-efficiency of 74TMACS/W among RRAM-based CIM hardware and offers intrinsic data reconfigurability to support various neural network architectures such as Multi-layer Perceptron, Convolutional Neural Network, Recurrent Neural Network and Restricted Boltzmann Machine (RBM) (2020 ISSCC conference). We taped-out two chips using 130nm CMOS process with monolithically-integrated HfOx RRAMs. The first chip contains a single Transposable Neurosynaptic Core with 65K RRAM weights and 256 CMOS neurons; the second chip contains 48 cores with 3M RRAMs and 12K neurons. We developed a comprehensive set of hardware and software tools allowing easy implementation of AI models on our chips. We successfully demonstrated image recovery, image classification, and voice recognition applications on our hardware. The real-time image recovery using RBM was presented at the 2020 ISSCC demo sessions and the 2020 VLSI conferences:  https://youtu.be/b7ITxmfaLBk. This hardware is an important milestone towards future energy-efficient, flexible, and scalable AI fabrics.       Last Modified: 07/14/2020       Submitted by: Subhasish Mitra]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
