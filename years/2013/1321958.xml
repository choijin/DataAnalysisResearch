<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>DC: Small: Collaborative Research: DARE: Declarative and Scalable Recovery</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
<AwardExpirationDate>08/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>235663.00</AwardTotalIntnAmount>
<AwardAmount>235663</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Hong Jiang</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>One dominant characteristic of today's large-scale computing systems&lt;br/&gt;is the prevalence of large storage clusters.  Storage clusters at the&lt;br/&gt;scale of hundreds or thousands of commodity machines are&lt;br/&gt;increasingly being deployed. At companies like Amazon, Google, Yahoo,&lt;br/&gt;and others, thousands of nodes are managed as a single system.&lt;br/&gt;&lt;br/&gt;As large clusters have brought many benefits, they also bring a new&lt;br/&gt;challenge: a growing number and frequency of failures that must be&lt;br/&gt;managed. Bits, sectors, disks, machines, racks, and many other&lt;br/&gt;components fail.  With millions of servers and hundreds of data&lt;br/&gt;centers, there are millions of opportunities for these components to&lt;br/&gt;fail. Failing to deal with failures will directly impact the&lt;br/&gt;reliability and availability of data and jobs.&lt;br/&gt;&lt;br/&gt;Unfortunately, we still hear data-loss stories even recently. For&lt;br/&gt;example, in March 2009, Facebook lost millions of photos due to&lt;br/&gt;simultaneous disk failures that "should" rarely happen at the same&lt;br/&gt;time (but it happened); in July 2009, a large bank was fined a record&lt;br/&gt;total of 3 millions pounds after losing data on thousands of its&lt;br/&gt;customers; more recently, in October 2009, T-Mobile Sidekick, which&lt;br/&gt;uses Microsoft's cloud service, also lost its customer data.  These&lt;br/&gt;incidents have shown that existing large-scale storage systems are&lt;br/&gt;still fragile to failures.&lt;br/&gt;&lt;br/&gt;To address the challenges of large-scale recovery, the goal of this&lt;br/&gt;project is to: (1) seek the fundamental problems of recovery in&lt;br/&gt;today's scalable world of computing, (2) improve the reliability,&lt;br/&gt;performance, and scalability of existing large-scale recovery, and (3)&lt;br/&gt;explore formally grounded languages to empower rigorous specification&lt;br/&gt;of recovery properties and behaviors.  Our vision is to build systems&lt;br/&gt;that "DARE to fail": systems that deliberately fail themselves,&lt;br/&gt;exercise recovery routinely, and enable easy and correct deployment of&lt;br/&gt;new recovery policies.&lt;br/&gt;&lt;br/&gt;For more information, please visit this website:&lt;br/&gt;http://boom.cs.berkeley.edu/dare/</AbstractNarration>
<MinAmdLetterDate>04/09/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/13/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1321958</AwardID>
<Investigator>
<FirstName>Haryadi</FirstName>
<LastName>Gunawi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Haryadi Gunawi</PI_FULL_NAME>
<EmailAddress>haryadi@cs.uchicago.edu</EmailAddress>
<PI_PHON>7737025772</PI_PHON>
<NSF_ID>000626546</NSF_ID>
<StartDate>04/09/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606375418</ZipCode>
<StreetAddress><![CDATA[1100 E 58th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7793</Code>
<Text>DATA-INTENSIVE COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>7943</Code>
<Text>PROGRAMMING LANGUAGES</Text>
</ProgramReference>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2010~235663</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p><br />The DARE project advances cloud recovery testing techniques and thus improve the dependability of cloud systems.&nbsp; The DARE project produces several outcomes. <br /><br />With FATE (Failure Testing Service) and DESTINI (Declarative Testing Specifications), recovery is systematically tested in the face of multiple failures and correct recovery is specified clearly, concisely, and precisely.&nbsp; FATE and DESTINI can explore over 40,000 failure scenarios including multiple failures in a single system and easily express tens of recovery specifications. <br /><br />With PreFail (a programmable failure-injection tool), which advances FATE, testers can write a wide range of policies to prune down the large space of multiple failures and spend 10X&sbquo;&Auml;&igrave;200X less time than exhaustive testing. <br /><br />With HARDFS, cloud storage such as HDFS can recovery from fail-silent (non fail-stop) behaviors that result from memory corruption and software bugs.&nbsp; HARDFS employs a new approach: selective and lightweight versioning (SLEEVE).&nbsp; HARDFS recovers orders of magnitude faster than full reboot by using micro-recovery. <br /><br />With SAMC (Semantic-Aware Model Checking), the scalability of distributed systems model checkers are significantly improved.&nbsp; With simple semantic information of the target cloud system, SAMC can alleviate redundant reorderings of messages, crashes, and reboots during state exploration process.&nbsp; SAMC can can find deep distributed system bugs one to two orders of magnitude faster compared to state-of-the-art distributed system model checkers. <br /><br />Finally, with CBS (Cloud Bug Study), the largest bug study for cloud systems to date, new unique problems such as scalability bugs, data consistency bugs, and many others specific to cloud systems are analyzed and provided to the cloud dependability research community. <br /><br /><br />Broader Impact: The DARE project places significant value on technology transfer; the outcomes of the project have led to direct industrial impact.&nbsp; For example, approaches from DARE cloud testing frameworks have been adopted by several industries that deploy cloud clusters.&nbsp; In addition, predictability is a key to success of multi-billion dollar computing, and DARE results address important concerns raised in building sustainable computing such as failure detection, isolation, diagnosis, and prediction.&nbsp; Finally, users from many areas (science, healthcare, business, education, military, and government) are increasingly use large-scale storage and computing services, and the outcomes of DARE project improve the reliability and availability of these services. <br /><br /><br /></p> <p>.</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/21/2014<br>      Modified by: Haryadi&nbsp;Gunawi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[     The DARE project advances cloud recovery testing techniques and thus improve the dependability of cloud systems.  The DARE project produces several outcomes.   With FATE (Failure Testing Service) and DESTINI (Declarative Testing Specifications), recovery is systematically tested in the face of multiple failures and correct recovery is specified clearly, concisely, and precisely.  FATE and DESTINI can explore over 40,000 failure scenarios including multiple failures in a single system and easily express tens of recovery specifications.   With PreFail (a programmable failure-injection tool), which advances FATE, testers can write a wide range of policies to prune down the large space of multiple failures and spend 10X&sbquo;&Auml;&igrave;200X less time than exhaustive testing.   With HARDFS, cloud storage such as HDFS can recovery from fail-silent (non fail-stop) behaviors that result from memory corruption and software bugs.  HARDFS employs a new approach: selective and lightweight versioning (SLEEVE).  HARDFS recovers orders of magnitude faster than full reboot by using micro-recovery.   With SAMC (Semantic-Aware Model Checking), the scalability of distributed systems model checkers are significantly improved.  With simple semantic information of the target cloud system, SAMC can alleviate redundant reorderings of messages, crashes, and reboots during state exploration process.  SAMC can can find deep distributed system bugs one to two orders of magnitude faster compared to state-of-the-art distributed system model checkers.   Finally, with CBS (Cloud Bug Study), the largest bug study for cloud systems to date, new unique problems such as scalability bugs, data consistency bugs, and many others specific to cloud systems are analyzed and provided to the cloud dependability research community.    Broader Impact: The DARE project places significant value on technology transfer; the outcomes of the project have led to direct industrial impact.  For example, approaches from DARE cloud testing frameworks have been adopted by several industries that deploy cloud clusters.  In addition, predictability is a key to success of multi-billion dollar computing, and DARE results address important concerns raised in building sustainable computing such as failure detection, isolation, diagnosis, and prediction.  Finally, users from many areas (science, healthcare, business, education, military, and government) are increasingly use large-scale storage and computing services, and the outcomes of DARE project improve the reliability and availability of these services.      .          Last Modified: 11/21/2014       Submitted by: Haryadi Gunawi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
