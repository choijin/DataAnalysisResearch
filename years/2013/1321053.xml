<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Deep Learning: Theory, Algorithms, and Applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2013</AwardEffectiveDate>
<AwardExpirationDate>07/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>449999.00</AwardTotalIntnAmount>
<AwardAmount>457999</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Weng-keen Wong</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The ability to learn is essential to the survival and robustness of biological systems. There is also growing evidence that learning is essential to build robust artificial intelligent systems and solve complex problems in many application domains.  However, solutions to complex problems ranging from recognizing faces to understanding speech, cannot be implemented in a single step.  Instead they require multiple processing stages, for instance to extract increasingly more abstract and refined features from an input image.  &lt;br/&gt;&lt;br/&gt;Thus computers and brains are both faced with the problem of deep learning --- how to simultaneously optimize the parameters of a hierarchy of processing stages in order to solve complex tasks and display intelligent behavior. In the past few years there has been remarkable progress in computer science to address the deep learning problem, and deep learning methods now claim state-of-the-art performance in several application areas.  The next generation of machine learning methods holds the promise to not only approach human performance in tasks previously impossible for computers, but also to exceed it.  However, our theoretical understanding of deep learning remains limited and there are several important areas where deep learning has not yet been applied systematically. This project addresses these challenges and opportunities by furthering formal understanding of the theory and algorithms behind deep learning, and by applying deep learning methods to new problems in the life sciences.  Because deep learning can be used in almost any domain, the results have the potential for broadly impacting science, engineering, and technology across multiple areas.  &lt;br/&gt;&lt;br/&gt;The project has educational and outreach components, ranging from courses to virtual 3D world interactions, for undergraduate and graduate students at UCI, as well as talented students from local high schools, and underrepresented minority students from local colleges. Scientific results, data, and software resulting from the project will be disseminated in scientific journals and over the web.&lt;br/&gt;&lt;br/&gt;The project has three main thrusts: theory, algorithms, and applications. From a theoretical standpoint, the project develops better mathematical understanding of deep architectures, including stacks of autoencoder networks, and their properties.  These theoretical results will inform the design of deep-learning architectures.  From an algorithmic standpoint, the project investigates, formally and through simulations, several deep learning algorithms, including the dropout algorithm and the PI's deep targets algorithm.  From an application standpoint, the project uses the new theoretical and algorithmic knowledge in application to the life sciences, for instance for protein structure prediction, and in predicting chemical reactions.  Advancing the state-of-the-art for any one of these thrusts will have a significant impact in computer science, artificial intelligence, statistical machine learning, and the corresponding application field.</AbstractNarration>
<MinAmdLetterDate>08/06/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/16/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1321053</AwardID>
<Investigator>
<FirstName>Pierre</FirstName>
<LastName>Baldi</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pierre F Baldi</PI_FULL_NAME>
<EmailAddress>pfbaldi@ics.uci.edu</EmailAddress>
<PI_PHON>9498245809</PI_PHON>
<NSF_ID>000440884</NSF_ID>
<StartDate>08/06/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Irvine</Name>
<CityName>Irvine</CityName>
<ZipCode>926977600</ZipCode>
<PhoneNumber>9498247295</PhoneNumber>
<StreetAddress>160 Aldrich Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA45</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>046705849</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, IRVINE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Irvine]]></Name>
<CityName>Irvine</CityName>
<StateCode>CA</StateCode>
<ZipCode>926173067</ZipCode>
<StreetAddress><![CDATA[4038 Bren Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>45</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA45</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~149827</FUND_OBLG>
<FUND_OBLG>2014~308172</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Deep learning, essentially a form of machine learning that uses big data to train large neural networks inspired by biology, is at the center of Artificial Intelligence today.&nbsp; In recent years, deep learning methods have led to breakthroughs in multiple ares of engineering ranging from computer vision, to speech recognition, to natural language processing. Deep learning systems are currently used by billions of people who benefit from&nbsp; them implicitely through the use of, for instance&nbsp; cell phones and web search engines.&nbsp;</p> <p>This effort has had two major outcomes. First, it has improved our theoretical understanding of deep learning by providing&nbsp; a mathematical theory of dropout, an important form of randomization that is often used in combination with deep learning. A follow up has been a development of a theory of local learning, as a generalization of the concept of Hebbian learning, often paraphrased as "neuron that fire together, wire together".</p> <p>Second, this effort has developed successful applications of deep learning in the natural sciences, in particular in physics and biology. In physics, deep learning methods have been developped&nbsp; to process the astronomical amount of data produced by particle colliders in high-energy physics and improve our ability to detect exotic particles, such as the Higgs boson. Detecting such exotic particles is essential for our understanding of the most fundamental nature of the universe, the nature of dark matter, and so forth.</p> <p>In biology, deep learning methods have been developed to accurately predict protein structural features, such as protein secondary structure, and to analyze high-throughput data related to circadian rhythms to accurately identify&nbsp; transcripts and other molecular species whose concentration oscillate&nbsp; along the night-day cycle. Circadian rhythms are fundamenbtal for biology: they dateback to the origin of life, are found in virtually every species and every cell, and they coordinate homeostasis, metabolism, and many other functions. Thus knowing which molecules oscillate in a circadian manner is very important.</p> <p>This effort has trained several doctoral students and the results, data, and programs have been disseminated broadly through journal publications, workshops, conference presentations, and other venues, such as web portals where they can be freely downloaded by the entire scientific community. The methods developed are already being used by and benefit other natural scientists. Finally,&nbsp; because machine learning methods are so broadly used, progress in our fundamental understanding of deep learning methods&nbsp; is likely to have broad repercussions and benefits in science, engineering, and society.</p><br> <p>            Last Modified: 08/08/2016<br>      Modified by: Pierre&nbsp;F&nbsp;Baldi</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Deep learning, essentially a form of machine learning that uses big data to train large neural networks inspired by biology, is at the center of Artificial Intelligence today.  In recent years, deep learning methods have led to breakthroughs in multiple ares of engineering ranging from computer vision, to speech recognition, to natural language processing. Deep learning systems are currently used by billions of people who benefit from  them implicitely through the use of, for instance  cell phones and web search engines.   This effort has had two major outcomes. First, it has improved our theoretical understanding of deep learning by providing  a mathematical theory of dropout, an important form of randomization that is often used in combination with deep learning. A follow up has been a development of a theory of local learning, as a generalization of the concept of Hebbian learning, often paraphrased as "neuron that fire together, wire together".  Second, this effort has developed successful applications of deep learning in the natural sciences, in particular in physics and biology. In physics, deep learning methods have been developped  to process the astronomical amount of data produced by particle colliders in high-energy physics and improve our ability to detect exotic particles, such as the Higgs boson. Detecting such exotic particles is essential for our understanding of the most fundamental nature of the universe, the nature of dark matter, and so forth.  In biology, deep learning methods have been developed to accurately predict protein structural features, such as protein secondary structure, and to analyze high-throughput data related to circadian rhythms to accurately identify  transcripts and other molecular species whose concentration oscillate  along the night-day cycle. Circadian rhythms are fundamenbtal for biology: they dateback to the origin of life, are found in virtually every species and every cell, and they coordinate homeostasis, metabolism, and many other functions. Thus knowing which molecules oscillate in a circadian manner is very important.  This effort has trained several doctoral students and the results, data, and programs have been disseminated broadly through journal publications, workshops, conference presentations, and other venues, such as web portals where they can be freely downloaded by the entire scientific community. The methods developed are already being used by and benefit other natural scientists. Finally,  because machine learning methods are so broadly used, progress in our fundamental understanding of deep learning methods  is likely to have broad repercussions and benefits in science, engineering, and society.       Last Modified: 08/08/2016       Submitted by: Pierre F Baldi]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
