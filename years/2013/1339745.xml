<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SI2-SSI: Collaborative: The XScala Project: A Community Repository for Model-Driven Design and Tuning of Data-Intensive Applications for Extreme-Scale Accelerator-Based Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>1188710.00</AwardTotalIntnAmount>
<AwardAmount>1188710</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alan Sussman</SignBlockName>
<PO_EMAI>alasussm@nsf.gov</PO_EMAI>
<PO_PHON>7032927563</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The increasing gap between processor and memory performance -- referred to as the memory wall -- has led high-performance computing vendors to design and incorporate new accelerators into their next-generation systems. Representative accelerators include recon&amp;#64257;gurable hardware such as FPGAs, heterogeneous processors such as CPU+GPU processors, highly multicore and multithreaded processors, and manycore co-processors and general-purpose graphics processing units, among others. These accelerators contain myriad innovative architectural features, including explicit control of data motion, large-scale SIMD/vector processing, and multithreaded stream processing. Such features provide abundant opportunities for developers to achieve high-performance for applications that were previously deemed hard to optimize. This project aims to develop tools that will assist developers in using hardware accelerators (co-processors) productively and effectively.&lt;br/&gt; &lt;br/&gt;This project's specific technical focus is on data-intensive kernels including large dictionary string matching, dynamic programming, graph theory, and sparse matrix computations that arise in the domains of biology, network security, and the social sciences. The project is developing XScala, a software framework for designing efficient accelerator kernels. The framework contains a variety of design time and run-time performance optimization tools. The project concentrates on data-intensive kernels, bound by data movement. It proposes optimization techniques including (a) enhancing and exploiting maximal concurrency to hide data movement; (b) algorithmic reorganization to improve spatial and/or temporal locality; (c) data structure transformations to improve locality or reduce the size of the data (compressed structures); and (d) prefetching, among others. The project is also developing a public software repository and forum, called the XBazaar, for community-developed accelerator kernels. This project includes workshops, tutorials, and the PIs class and summer projects as various means by which to increase community involvement. The broader impacts include productive use of emerging classes of accelerator-augmented computer systems; creation of an open and accessible community repository, the XBazaar, for distributing accelerator-tuned computational kernels, software, and models; training of graduate and undergraduate students; and dissemination through publications, presentations at scientific meetings, lectures, workshops, and tutorials. The framework itself will be released as open-source code and as precompiled binaries for several common platforms, through the XBazaar, as an initial step toward building a community around accelerator kernels.</AbstractNarration>
<MinAmdLetterDate>09/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1339745</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Bader</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David A Bader</PI_FULL_NAME>
<EmailAddress>bader@njit.edu</EmailAddress>
<PI_PHON>9735962654</PI_PHON>
<NSF_ID>000206826</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Vuduc</LastName>
<PI_MID_INIT>W</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Richard W Vuduc</PI_FULL_NAME>
<EmailAddress>richie@cc.gatech.edu</EmailAddress>
<PI_PHON>5103017014</PI_PHON>
<NSF_ID>000080331</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Edward</FirstName>
<LastName>Riedy</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Edward J Riedy</PI_FULL_NAME>
<EmailAddress>jason.riedy@cc.gatech.edu</EmailAddress>
<PI_PHON>4048944819</PI_PHON>
<NSF_ID>000596559</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Ave NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7231</Code>
<Text>CYBERINFRASTRUCTURE</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>8009</Code>
<Text>Scientifc Software Integration</Text>
</ProgramReference>
<ProgramReference>
<Code>9145</Code>
<Text>SPECIAL PROGRAMS-RESERVE</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~1188710</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>This project aims to&nbsp;</span><span>develop software tools and techniques that assist developers in using hardware accelerators</span><span>&nbsp;(co-processors) productively and effectively. "Accelerators" refers to the wide variety of existing and emerging computational processors and co-processors, including advanced multicore CPUs, GPUs, FPGAs, and many-core co-processors. The motivating applications come from the domains of biology, network security, and the social sciences. This project&rsquo;s specific technical focus is on data-intensive kernels including large dictionary string matching, dynamic programming, graph theory, sparse matrix computations, and machine learning. In these contexts, "data-intensive" refers to the property of data movement being the main bottleneck.</span></p> <p><span>Specifically, the proposed research has the following&nbsp;</span><span>objectives</span><span>:</span></p> <ol> <li> <p><span>Develop a model-driven parallelism exploration and optimization framework</span><span>, which would allow semi-automatic design-time optimizations and run-time adaptations for efficient usage of general-purpose processors and accelerators.</span></p> </li> <li> <p><span>Develop an annotated task-level representation for kernels</span><span>&nbsp;whereby designs with different optimizations for the same task will be evaluated and scheduled at run time. Significantly, we envision annotations expressing the inherent data locality requirements and parameterized performance models, which may be manually specified or automatically inferred; these annotated designs will be used by the run-time system to compose optimized kernels in face of dynamically changing execution environments.</span></p> </li> <li> <p><span>Demonstrations on several data-intensive and sparse computation kernels</span><span>. These demonstrations will include representative compact applications in four areas: string pattern matching (used in network security), dynamic programming (computational biology), sparse graph problems (analyzing complex social and biological networks), and sparse matrix computations (scientific computing).</span></p> </li> </ol> <p><span>Deployment of this work on real platforms and applications, as well as dissemination to real end-user programmers.</span><span>&nbsp;Tuned and openly available kernels permit productive use of current architectures, and models of upcoming architectures permits productive tuning for each new architecture.&nbsp;</span></p> <p>The following is a list of the major software products supported at least in part by the XScala project. Note that all products are open-source projects.</p> <dl class="clearing"><dd> <div class="tinyMCEContent"><dl><dd> <ul> <li>STINGER:&nbsp;The STINGER package supports streaming graph analytics through in-memory parallel computation.&nbsp; STINGER forms the basis for a fundamentally new model of computation on streaming graph data developed during this perion.</li> <li> <p><span>&nbsp;</span><span>cuSTINGER</span><span>: We developed cuSTINGER, which provides GPU acceleration via CUDA. cuSTINGER has been released as a separate, standalone package. cuSTINGER was used to develop novel graph structure counting algorithms on NVIDIA GPUs.<br /></span></p> </li> <li><span><strong>NNPACK</strong>: NNPACK provides fast primitives for convolutional layers in neural network inference computations. Significant updates during this period include improved ARM/ARM64 support and better integration with higher-level frameworks, including PyTorch, Caffe2, and MXNet. A portion of this work is now being "spun-off" as an FPGA-accelerated development effort.</span></li> </ul> </dd></dl></div> </dd></dl> <p>&nbsp;</p><br> <p>            Last Modified: 10/01/2018<br>      Modified by: David&nbsp;A&nbsp;Bader</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project aims to develop software tools and techniques that assist developers in using hardware accelerators (co-processors) productively and effectively. "Accelerators" refers to the wide variety of existing and emerging computational processors and co-processors, including advanced multicore CPUs, GPUs, FPGAs, and many-core co-processors. The motivating applications come from the domains of biology, network security, and the social sciences. This project?s specific technical focus is on data-intensive kernels including large dictionary string matching, dynamic programming, graph theory, sparse matrix computations, and machine learning. In these contexts, "data-intensive" refers to the property of data movement being the main bottleneck.  Specifically, the proposed research has the following objectives:    Develop a model-driven parallelism exploration and optimization framework, which would allow semi-automatic design-time optimizations and run-time adaptations for efficient usage of general-purpose processors and accelerators.    Develop an annotated task-level representation for kernels whereby designs with different optimizations for the same task will be evaluated and scheduled at run time. Significantly, we envision annotations expressing the inherent data locality requirements and parameterized performance models, which may be manually specified or automatically inferred; these annotated designs will be used by the run-time system to compose optimized kernels in face of dynamically changing execution environments.    Demonstrations on several data-intensive and sparse computation kernels. These demonstrations will include representative compact applications in four areas: string pattern matching (used in network security), dynamic programming (computational biology), sparse graph problems (analyzing complex social and biological networks), and sparse matrix computations (scientific computing).    Deployment of this work on real platforms and applications, as well as dissemination to real end-user programmers. Tuned and openly available kernels permit productive use of current architectures, and models of upcoming architectures permits productive tuning for each new architecture.   The following is a list of the major software products supported at least in part by the XScala project. Note that all products are open-source projects.    STINGER: The STINGER package supports streaming graph analytics through in-memory parallel computation.  STINGER forms the basis for a fundamentally new model of computation on streaming graph data developed during this perion.    cuSTINGER: We developed cuSTINGER, which provides GPU acceleration via CUDA. cuSTINGER has been released as a separate, standalone package. cuSTINGER was used to develop novel graph structure counting algorithms on NVIDIA GPUs.   NNPACK: NNPACK provides fast primitives for convolutional layers in neural network inference computations. Significant updates during this period include improved ARM/ARM64 support and better integration with higher-level frameworks, including PyTorch, Caffe2, and MXNet. A portion of this work is now being "spun-off" as an FPGA-accelerated development effort.             Last Modified: 10/01/2018       Submitted by: David A Bader]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
