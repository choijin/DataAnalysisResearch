<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Using Crowdsourced Virtual Students to Create Intelligent Tutors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>163830.00</AwardTotalIntnAmount>
<AwardAmount>163830</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project will develop and evaluate the potential of a new human-computer system that bridges the roles of virtual student and virtual teacher to allow humans and computers to take turns teaching and learning from each other. The key insight is that reading comprehension activities (e.g., vocabulary building, summarizing, question generation, concept mapping) closely parallel the knowledge engineering required to create virtual teachers for intelligent tutoring systems (ITSs). The system links these activities so that when students read online, they engage a virtual student in educational tasks that both improve their reading comprehension and simultaneously contribute to the creation of ITSs for future students. An important aspect of the proposed research is to find the optimum balance between student learning (which benefits the individual) and the creation of ITS knowledge representations (which benefits many). Specific research objectives are: (1) to develop a baseline platform (called BrainTrust) such that students can create ITS knowledge representations by teaching a virtual student; (2) to study the relationship between the student's ability, the virtual student's ability, the student's learning outcomes, and the quality of knowledge representations produced. A distinctive characteristic of the proposed research is the study of these questions in ecologically valid conditions, as students engage in authentic study, while also participating in randomized experiments.&lt;br/&gt;&lt;br/&gt;The research may lead to the development of systems that improve reading comprehension, which may have broad benefits given the centrality of reading comprehension to all learning. In particular, problems with reading comprehension have been linked to first-year college student dropout that disproportionately affects African-American students. The research will also enhance infrastructure for research and education through the development and dissemination of the BrainTrust platform, a next-generation computing infrastructure to rapidly create and deploy ITSs tailored to specific needs. If this exploratory project demonstrates that the dual outcomes of human learning and high-quality knowledge representations can be achieved, it will open a new area of research that brings teaching these virtual students full circle with learning from their derived intelligent tutoring systems.</AbstractNarration>
<MinAmdLetterDate>08/26/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1352207</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Olney</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew M Olney</PI_FULL_NAME>
<EmailAddress>aolney@memphis.edu</EmailAddress>
<PI_PHON>9016785032</PI_PHON>
<NSF_ID>000349405</NSF_ID>
<StartDate>08/26/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Memphis</Name>
<CityName>Memphis</CityName>
<ZipCode>381523370</ZipCode>
<PhoneNumber>9016783251</PhoneNumber>
<StreetAddress>Administration 315</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<StateCode>TN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>055688857</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MEMPHIS, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>878135631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Memphis]]></Name>
<CityName>Memphis</CityName>
<StateCode>TN</StateCode>
<ZipCode>381523370</ZipCode>
<StreetAddress><![CDATA[365 Innovation Drive, Rm. 436]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~163830</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This research project investigated a new human-computer system that will ultimately allow humans and computers to take turns teaching and learning from each other. This research addresses one of the biggest challenges in the field of educational technology: knowledge engineering. Decades of research have produced computer tutors that are as effective as human tutors, but they have not been widely adopted because they are extremely expensive to produce -- largely due to knowledge engineering.</p> <p>This research project approached the knowledge engineering problem from a different perspective. Instead of finding experts in artificial intelligence to do our knowledge engineering, what if we could get a crowd of ordinary people to do it for us? To explore this idea, we created a system called BrainTrust. In BrainTrust, humans teach a virtual student while they read a textbook. As the human teaches and corrects the virtual student, they are doing knowledge engineering. &nbsp;That knowledge engineering is captured by the system to be recycled to other human users. The idea is that eventually each piece of knowledge will be scrutinized and changed by users until everyone agrees it is OK. At that point, it could be used in a computer tutor.</p> <p>We want the human user to learn while teaching the virtual student. That way both the human user and society benefit from the created knowledge. In this research project, we investigated the various factors that influence learning and knowledge engineering quality. The overall goal of the project was to see if there was a combination of factors that optimized both learning and knowledge engineering quality such that any human user could have equally good outcomes.</p> <p>To pursue this goal we created a web-based version of BrainTrust and conducted two experiments. The first experiment used college students who participated for credit, and the second experiment used workers from Amazon Mechanical Turk who participated for money. In both experiments we gave surveys measuring intrinsic motivation and reading ability, a pre-test, BrainTrust, and a post-test. Participants experienced three versions of BrainTrust: a text-only condition with no virtual student, a virtual student condition that made a few mistakes, and a virtual student condition that never made mistakes. Our hypothesis was that some participants might learn more by teaching a virtual student that made mistakes and that other participants would learn more working with a virtual student that never made mistakes.</p> <p>Our experiments did not support this hypothesis. Instead we found that the most important factors were high levels of intrinsic motivation and strong reading ability. Even though participants revised more knowledge when teaching the virtual student who made mistakes, teaching had very little influence on learning. In fact, participants did best when they did not have to correct the virtual student at all. These results suggest strong guidelines on how knowledge engineering should be crowdsourced if we want participants to learn while doing it.</p> <p>The future of this research lies in deploying it &ldquo;in the wild&rdquo; so that students can use it on their own textbooks. That is perhaps the best way to enhance intrinsic motivation. At scale it will also be possible to study the knowledge engineering process over time and optimize it.</p><br> <p>            Last Modified: 12/01/2015<br>      Modified by: Andrew&nbsp;M&nbsp;Olney</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This research project investigated a new human-computer system that will ultimately allow humans and computers to take turns teaching and learning from each other. This research addresses one of the biggest challenges in the field of educational technology: knowledge engineering. Decades of research have produced computer tutors that are as effective as human tutors, but they have not been widely adopted because they are extremely expensive to produce -- largely due to knowledge engineering.  This research project approached the knowledge engineering problem from a different perspective. Instead of finding experts in artificial intelligence to do our knowledge engineering, what if we could get a crowd of ordinary people to do it for us? To explore this idea, we created a system called BrainTrust. In BrainTrust, humans teach a virtual student while they read a textbook. As the human teaches and corrects the virtual student, they are doing knowledge engineering.  That knowledge engineering is captured by the system to be recycled to other human users. The idea is that eventually each piece of knowledge will be scrutinized and changed by users until everyone agrees it is OK. At that point, it could be used in a computer tutor.  We want the human user to learn while teaching the virtual student. That way both the human user and society benefit from the created knowledge. In this research project, we investigated the various factors that influence learning and knowledge engineering quality. The overall goal of the project was to see if there was a combination of factors that optimized both learning and knowledge engineering quality such that any human user could have equally good outcomes.  To pursue this goal we created a web-based version of BrainTrust and conducted two experiments. The first experiment used college students who participated for credit, and the second experiment used workers from Amazon Mechanical Turk who participated for money. In both experiments we gave surveys measuring intrinsic motivation and reading ability, a pre-test, BrainTrust, and a post-test. Participants experienced three versions of BrainTrust: a text-only condition with no virtual student, a virtual student condition that made a few mistakes, and a virtual student condition that never made mistakes. Our hypothesis was that some participants might learn more by teaching a virtual student that made mistakes and that other participants would learn more working with a virtual student that never made mistakes.  Our experiments did not support this hypothesis. Instead we found that the most important factors were high levels of intrinsic motivation and strong reading ability. Even though participants revised more knowledge when teaching the virtual student who made mistakes, teaching had very little influence on learning. In fact, participants did best when they did not have to correct the virtual student at all. These results suggest strong guidelines on how knowledge engineering should be crowdsourced if we want participants to learn while doing it.  The future of this research lies in deploying it "in the wild" so that students can use it on their own textbooks. That is perhaps the best way to enhance intrinsic motivation. At scale it will also be possible to study the knowledge engineering process over time and optimize it.       Last Modified: 12/01/2015       Submitted by: Andrew M Olney]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
