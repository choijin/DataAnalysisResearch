<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Extracting Valuable Information Automatically from Objects with Surface Impressions via Photographs and Interactive Digital Surrogates</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>905399</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The innovation, CUNAT (CUNeiform Automated Translator) attacks significant problems in a discipline wedded to conservative manual methods. Ancient Mesopotamian legal treatises, Egyptian medical records, and Roman political accounts--telling us exactly what happened in the words of the very people whose actions formed our history - languish untranslated, because there are too many of them, translation takes too long, and there are too few linguistic experts. "Cuneiform text genres include everything...from mathematical and grammatical exercises, beer recipes, international treaties, musical scores, legal codes, religious rituals, sales receipts, and astronomical tables....[M]useums...have acquired approximately 400,000 tablets, with thousands being unearthed every year.... [S]cholars continue to make unique and valuable contributions to the study of history, law, religion, linguistics, mathematics, and science" (Digital Hammurabi Project). CUNAT will allow anyone to create 3D models of artifacts and extract meaning from their impressions more effectively and quickly than existing tools. Phase II innovations include: extending the limits of image-based feature detection through unique algorithms based on 3D models automatically generated from photographs; isolating meaningful characters from noise across an array of surface shapes; classifying the characters of many dialects based on geometric characteristics; and performing automatic translation using graph-based algorithms and rules engines rather than traditional word-by-word methods.&lt;br/&gt;&lt;br/&gt;The broader/commercial impact of our innovation are new learning and analysis methods: a high-school student enters an art museum and sees an object with triangular-shaped surface incisions; the label reads "cuneiform tablet, 864BCE, Nimrud;" curious, the student aims a smartphone camera at the object and clicks; the images are uploaded into the project?s software app, which generates an interactive 3D model and an English translation of the inscription. The student may become the first person to have read the text and discover previously unknown astronomical knowledge detailed by the ancient scribe. Their software gives this research power and excitement of discovery to everyone, every institution, anywhere, anytime, because neither expensive special equipment nor complex calibration or lighting are necessary to produce results with unprecedented efficiency and accuracy. The innovations will address critical needs across the field of archaeology and produce a commercially viable product with applications to problems in museum exhibition, numismatics, and digital art history. In addition, accurate processes will be widely applicable, including forensics, paleontology, auto mechanics, personalized 3D printing, and carpentry. Beyond the insight into the past that will inevitably accrue, economic and technological advantages will motivate commercial adoption within and beyond our target market.</AbstractNarration>
<MinAmdLetterDate>08/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2015</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1330139</AwardID>
<Investigator>
<FirstName>Donald</FirstName>
<LastName>Sanders</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Donald H Sanders</PI_FULL_NAME>
<EmailAddress>dsanders@learningsites.com</EmailAddress>
<PI_PHON>4134582828</PI_PHON>
<NSF_ID>000607996</NSF_ID>
<StartDate>08/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Learning Sites, Inc.</Name>
<CityName>Williamstown</CityName>
<ZipCode>012672232</ZipCode>
<PhoneNumber>4134582828</PhoneNumber>
<StreetAddress>151 Bridges Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>944990548</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>LEARNING SITES INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Learning Sites, Inc.]]></Name>
<CityName>Williamstown</CityName>
<StateCode>MA</StateCode>
<ZipCode>012672232</ZipCode>
<StreetAddress><![CDATA[151 Bridges Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>169E</Code>
<Text>SBIR Tech Enhan Partner (TECP)</Text>
</ProgramReference>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>7744</Code>
<Text>RAHSS</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8039</Code>
<Text>Information, Communication &amp; Computing</Text>
</ProgramReference>
<ProgramReference>
<Code>8043</Code>
<Text>System Design and Simulation</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~750000</FUND_OBLG>
<FUND_OBLG>2015~155399</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The major goal of our NSF grants was to develop a smartphone app to (among&nbsp; other things) automatically translate ancient languages that too few people around the world can currently read.&nbsp; There are literally many hundreds of thousands of ancient texts (especially written in Mesopotamian cuneiform and Egyptian hieratic scripts) that languish untranslated because there are too few experts, the material is too widely scattered, and too many more are being uncovered every year.&nbsp; Our app would then allow anyone (from students to scholars to the general public) to use their smartphone to gain access to these now-hidden, but crucial historical documents. <br /><br />Cuneiform was the script for the earliest writing and lasted over 3000 years across dozens of ancient languages and dialects. Hieratic script was the handwritten equivalent of the pictorial hieroglyphic and used for everyday correspondence. Texts written in those scripts cover such subjects as astronomical observations, medical treatises and cures, political treaties, economic transactions, letters home from soldiers stationed far away, and legal pronouncements; that is, the very same material we write about today and that give us detailed insight into the past.&nbsp; Imagine walking into a museum and seeing an object covered with a bunch of odd triangular-shaped surface incisions.&nbsp; The gallery label simply says "cuneiform tablet, Nimrud, 980 BCE." Curious, you aim a smartphone camera at the object and click a few times around the tablet.&nbsp; The images are uploaded into our app that then automatically generates an interactive virtual reality 3D model of the object (which you can view in the app) and an English translation of the inscription.&nbsp; You may become the first person ever to have read that text and perhaps discover some previously unknown tidbit about history that could change the way we understand ancient cultures !&nbsp; Our CUNAT (CUNeiform Automated Translator) app offers this research power and excitement of discovery to anyone, anywhere, anytime, because neither special equipment nor complex calibration or lighting are necessary to produce results with unprecedented efficiency and accuracy. <br /><br />In order to complete the task of developing an app that could read and understand both cuneiform script (which meant dealing with incised markings across irregular 3D surfaces), and hieratic script (which meant dealing with many different types of handwriting styles across curved pottery fragments), we had to work with some advanced computer techniques, such as: programming a process to automatically stitch together many smartphone photographs into a virtual reality 3D model which could be viewed interactively directly on the phone; programming the app to understand the nuances of ancient grammars, which are very different from modern language structures; building an application that could find and identify individual hieratic signs from among dozens of very different scribal hands; and including a massive database of information gleaned from the translated texts that could then be searched from both the Web and from inside the app, making the newly discovered names, dates, commodities, and events available to anyone.<br /><br />We anticipate that our mobile app translator will have a huge impact on the study of the distant past.&nbsp; Historians, archaeologists, teachers, and others should spend their time doing what they are trained to do--learn about the past and interpret the ancient writings to gain new insight into our collective histories.&nbsp; These people should not have to spend their time laboriously finding and then translating one text at a time.&nbsp; Our product will change all that and thus radically change the nature of scholarship. Further, the app will level the playing field when it comes to acquiring the knowledge of the ancients that will help inform our present in the fields of astronomy, mathematics, medicine, political theory, accounting, architecture, economics, religious rituals, and more.&nbsp; We democratize access to that information, normally the purview of the few, because in the future, anyone with a handheld device camera will be able to translate ancient languages.&nbsp; <br /><br />Down the road, we foresee the app being indispensable in crime scene forensics, numismatics, paleontology, digital art history, and related fields in which inscribed or impressed data require quick and accurate interpretation. Further, the app's ability to quickly generate interactive 3D computer models from photographs will be a sought-after tool for 3D printing, on-site object repair, the DIY crowd, for auto mechanics, furniture builders, and related activities where digitally capturing physical objects for replication, repair, or distant communication are key to success.<br /><br />The new insight into the past that will inevitably result from use of our product will help improve public education, social attitudes, decision-making practices, and perhaps even policies as a result of the influx of new information about how past cultures and individuals tackled the very same issues we deal with today (such as, regarding international treaties, laws and public policy, societal norms, and civic affairs).<br /><br />Available at the Android app store very soon.</p><br> <p>            Last Modified: 10/05/2016<br>      Modified by: Donald&nbsp;H&nbsp;Sanders</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670705382_CUNAT01--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670705382_CUNAT01--rgov-800width.jpg" title="CUNAT app pix01"><img src="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670705382_CUNAT01--rgov-66x44.jpg" alt="CUNAT app pix01"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Three screen grabs: (left) basic login screen; (middle) typical object catalogue screen; (right) detail of the 3D model viewer in the CUNAT part of the app</div> <div class="imageCredit">Learning Sites, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Donald&nbsp;H&nbsp;Sanders</div> <div class="imageTitle">CUNAT app pix01</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670848541_CUNAT02--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670848541_CUNAT02--rgov-800width.jpg" title="CUNAT app pix02"><img src="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670848541_CUNAT02--rgov-66x44.jpg" alt="CUNAT app pix02"></a> <div class="imageCaptionContainer"> <div class="imageCaption">the translation process tabs in the CUNAT part of the app: (left) transcription of the cuneiform signs; (next) options if a sign is ambiguous; (next) the linguistic syntax; (right) part of the translation</div> <div class="imageCredit">Learning Sites, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Donald&nbsp;H&nbsp;Sanders</div> <div class="imageTitle">CUNAT app pix02</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670997266_HIEARAT01--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670997266_HIEARAT01--rgov-800width.jpg" title="CUNAT app pix03"><img src="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475670997266_HIEARAT01--rgov-66x44.jpg" alt="CUNAT app pix03"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Screen grabs from HIERAT, the hieratic addition to the app: (left) HIERAT log in; (center) image tab; (right) transcription of the signs (with Moeller/Gardiner numbers turned off)</div> <div class="imageCredit">Learning Sites, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Donald&nbsp;H&nbsp;Sanders</div> <div class="imageTitle">CUNAT app pix03</div> </div> </li> <li> <a href="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475671104911_HIEARAT02--rgov-214x142.jpg" original="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475671104911_HIEARAT02--rgov-800width.jpg" title="CUNAT app pix04"><img src="/por/images/Reports/POR/2016/1330139/1330139_10272100_1475671104911_HIEARAT02--rgov-66x44.jpg" alt="CUNAT app pix04"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Screen grabs from the HIERAT portion of the app: (left) the hieroglyphic equivalents of the hieratic signs; (center) same screen with the phonetic designations turned on; (right) part of the English translation</div> <div class="imageCredit">Learning Sites, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Donald&nbsp;H&nbsp;Sanders</div> <div class="imageTitle">CUNAT app pix04</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The major goal of our NSF grants was to develop a smartphone app to (among  other things) automatically translate ancient languages that too few people around the world can currently read.  There are literally many hundreds of thousands of ancient texts (especially written in Mesopotamian cuneiform and Egyptian hieratic scripts) that languish untranslated because there are too few experts, the material is too widely scattered, and too many more are being uncovered every year.  Our app would then allow anyone (from students to scholars to the general public) to use their smartphone to gain access to these now-hidden, but crucial historical documents.   Cuneiform was the script for the earliest writing and lasted over 3000 years across dozens of ancient languages and dialects. Hieratic script was the handwritten equivalent of the pictorial hieroglyphic and used for everyday correspondence. Texts written in those scripts cover such subjects as astronomical observations, medical treatises and cures, political treaties, economic transactions, letters home from soldiers stationed far away, and legal pronouncements; that is, the very same material we write about today and that give us detailed insight into the past.  Imagine walking into a museum and seeing an object covered with a bunch of odd triangular-shaped surface incisions.  The gallery label simply says "cuneiform tablet, Nimrud, 980 BCE." Curious, you aim a smartphone camera at the object and click a few times around the tablet.  The images are uploaded into our app that then automatically generates an interactive virtual reality 3D model of the object (which you can view in the app) and an English translation of the inscription.  You may become the first person ever to have read that text and perhaps discover some previously unknown tidbit about history that could change the way we understand ancient cultures !  Our CUNAT (CUNeiform Automated Translator) app offers this research power and excitement of discovery to anyone, anywhere, anytime, because neither special equipment nor complex calibration or lighting are necessary to produce results with unprecedented efficiency and accuracy.   In order to complete the task of developing an app that could read and understand both cuneiform script (which meant dealing with incised markings across irregular 3D surfaces), and hieratic script (which meant dealing with many different types of handwriting styles across curved pottery fragments), we had to work with some advanced computer techniques, such as: programming a process to automatically stitch together many smartphone photographs into a virtual reality 3D model which could be viewed interactively directly on the phone; programming the app to understand the nuances of ancient grammars, which are very different from modern language structures; building an application that could find and identify individual hieratic signs from among dozens of very different scribal hands; and including a massive database of information gleaned from the translated texts that could then be searched from both the Web and from inside the app, making the newly discovered names, dates, commodities, and events available to anyone.  We anticipate that our mobile app translator will have a huge impact on the study of the distant past.  Historians, archaeologists, teachers, and others should spend their time doing what they are trained to do--learn about the past and interpret the ancient writings to gain new insight into our collective histories.  These people should not have to spend their time laboriously finding and then translating one text at a time.  Our product will change all that and thus radically change the nature of scholarship. Further, the app will level the playing field when it comes to acquiring the knowledge of the ancients that will help inform our present in the fields of astronomy, mathematics, medicine, political theory, accounting, architecture, economics, religious rituals, and more.  We democratize access to that information, normally the purview of the few, because in the future, anyone with a handheld device camera will be able to translate ancient languages.    Down the road, we foresee the app being indispensable in crime scene forensics, numismatics, paleontology, digital art history, and related fields in which inscribed or impressed data require quick and accurate interpretation. Further, the app's ability to quickly generate interactive 3D computer models from photographs will be a sought-after tool for 3D printing, on-site object repair, the DIY crowd, for auto mechanics, furniture builders, and related activities where digitally capturing physical objects for replication, repair, or distant communication are key to success.  The new insight into the past that will inevitably result from use of our product will help improve public education, social attitudes, decision-making practices, and perhaps even policies as a result of the influx of new information about how past cultures and individuals tackled the very same issues we deal with today (such as, regarding international treaties, laws and public policy, societal norms, and civic affairs).  Available at the Android app store very soon.       Last Modified: 10/05/2016       Submitted by: Donald H Sanders]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
