<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research:  Randomization Inference for Contemporary Problems in Statistics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2013</AwardEffectiveDate>
<AwardExpirationDate>08/31/2016</AwardExpirationDate>
<AwardTotalIntnAmount>120000.00</AwardTotalIntnAmount>
<AwardAmount>120000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The investigators continue the development of new methodology and the accompanying mathematical theory for problems in multiple testing and inference, driven by the many burgeoning applications in the information age.  Further motivation for valid methods stems from exploratory analysis of large data sets, where the process of "data snooping" (or "data mining") often leads to challenges of multiple testing and simultaneous inference.  In such problems, the statistician is faced with the challenge of accounting for all possible errors resulting from a complex analysis of the data, so that any resulting inferences or conclusions can reliably be viewed as "real" rather than spurious findings or artifacts of the data.  It is safe to say that the mathematical justification of sound statistical methods is not keeping pace with the demand for valid new tools.  In particular, the investigators develop randomization tests as  inferential methods for semi-parametric and nonparametric models that do not rely on unverifiable assumptions.  To a great extent, resampling methods, such as the bootstrap and subsampling, are successful in many problems, at least in an asymptotic sense, but for many problems they are unsatisfactory.  Examples of such problems in contemporary statistics include "high" dimensional problems, where the "curse of dimensionality" may cause resampling methods to break down, and "non-regular" problems, where a lack of convergence of the approximation that is not at least locally uniform in the underlying data generating process may cause resampling methods to break down.   Some specific problems addressed include Tobit regression and linear regression with weak instruments.  Moreover, resampling methods do not enjoy exact finite-sample validity, which is perhaps the main reason permutation and rank tests are so commonly used in many fields, such as medical studies.  The investigators apply randomization tests to many new problems that statisticians face, despite issues of high dimensionality, simultaneous inference, unknown dependence structures, non-Gaussianity, etc.  An exciting feature of the approach is that, properly constructed, randomization tests enjoy good robustness properties in situations where the assumptions guaranteeing finite-sample validity may fail.  Mathematical theory is developed as well as feasible computational constructs.&lt;br/&gt;&lt;br/&gt;Useful statistical methodology is the key tool to analyzing any study or scientific experiment.  Recently, the demand for efficient and reliable confirmatory statistical methods has grown rapidly, driven by problems arising in the analysis of DNA microarray biotechnology, econometrics, finance, educational evaluation, global warming, and astronomy, as well as many others.  In general, the philosophical approach is to develop practical methods that have both robustness of validity and robustness of efficiency so that they may be applied in increasingly complex situations as the scope of modern data analysis continues to grow.  The broader impact of this work is potentially quite large because the resulting inferential tools can be applied to such diverse fields as genetics, bioengineering, image processing and neuroimaging, clinical trials, education, astronomy, finance and econometrics. The results will be widely disseminated, and public software of new statistical tools made accessible whenever possible. The many thriving fields of applications demand new statistical methods, creating challenging and exciting opportunities for young scholars under the direction of the investigators.</AbstractNarration>
<MinAmdLetterDate>08/29/2013</MinAmdLetterDate>
<MaxAmdLetterDate>08/29/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1308260</AwardID>
<Investigator>
<FirstName>Azeem</FirstName>
<LastName>Shaikh</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Azeem M Shaikh</PI_FULL_NAME>
<EmailAddress>amshaikh@uchicago.edu</EmailAddress>
<PI_PHON>7737023621</PI_PHON>
<NSF_ID>000257165</NSF_ID>
<StartDate>08/29/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372612</ZipCode>
<PhoneNumber>7737028669</PhoneNumber>
<StreetAddress>6054 South Drexel Avenue</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005421136</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CHICAGO, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005421136</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Chicago]]></Name>
<CityName>Chicago</CityName>
<StateCode>IL</StateCode>
<ZipCode>606375418</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~120000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed several new and innovative methods for the analysis of different types of data. &nbsp;First, it devleoped new methods for the analysis of "clustered data." &nbsp;Clustered data are quite common in economics -- e.g., units of observations may be villages, states, schools, etc. &nbsp;When there are comparatively few clusters, conventional methods for inference in these settings break down. &nbsp;We developed both new methods for analyzing these types of data structures, as well as new results about existing methods that were heretofore unknown. &nbsp;Second, we developed new results about inference in randomized controlled trials (RCTs). &nbsp;It is common in RCTs to assign units to treatment and control so as to "balance" baseline covariates -- like gender -- across the two groups. &nbsp;For instance, we would not want to have a situation where all boys ended up in the treatment group and all girls ended up in the control group. &nbsp;This common practice induces dependence in treatment status that invalidates the assumptions that underlie standard appraoches to inference in these settings. &nbsp;We develop new results about these standard approaches, showing how to correct them when they go awry. &nbsp;Third, we considered multiple testing problems in experiments. &nbsp;Multiple testing problems arise naturally in the analysis of experiments due to multiple outcomes, subgroups or treatments of interest. Methods for controlling false positive despite the large number of resulting hypotheses were provided and also applied to differente experimental data sets. &nbsp;It is worth emphasizing that failure to account for multiple testing in these settings is related to the widely acknowledged "replicability crisis" in the sciences. &nbsp;Seperately, several new results concerning (partial) identification were derived, &nbsp; Finally, two distinct areas of econmetrics -- inference for partially identified models and shape restrictions -- were surveyed.</p><br> <p>            Last Modified: 06/08/2018<br>      Modified by: Azeem&nbsp;M&nbsp;Shaikh</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed several new and innovative methods for the analysis of different types of data.  First, it devleoped new methods for the analysis of "clustered data."  Clustered data are quite common in economics -- e.g., units of observations may be villages, states, schools, etc.  When there are comparatively few clusters, conventional methods for inference in these settings break down.  We developed both new methods for analyzing these types of data structures, as well as new results about existing methods that were heretofore unknown.  Second, we developed new results about inference in randomized controlled trials (RCTs).  It is common in RCTs to assign units to treatment and control so as to "balance" baseline covariates -- like gender -- across the two groups.  For instance, we would not want to have a situation where all boys ended up in the treatment group and all girls ended up in the control group.  This common practice induces dependence in treatment status that invalidates the assumptions that underlie standard appraoches to inference in these settings.  We develop new results about these standard approaches, showing how to correct them when they go awry.  Third, we considered multiple testing problems in experiments.  Multiple testing problems arise naturally in the analysis of experiments due to multiple outcomes, subgroups or treatments of interest. Methods for controlling false positive despite the large number of resulting hypotheses were provided and also applied to differente experimental data sets.  It is worth emphasizing that failure to account for multiple testing in these settings is related to the widely acknowledged "replicability crisis" in the sciences.  Seperately, several new results concerning (partial) identification were derived,   Finally, two distinct areas of econmetrics -- inference for partially identified models and shape restrictions -- were surveyed.       Last Modified: 06/08/2018       Submitted by: Azeem M Shaikh]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
