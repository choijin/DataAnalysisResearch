<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI Collaborative: Development of iRehab, an Intelligent Closed-Loop Instrument for Adaptive Rehabilitation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>799890.00</AwardTotalIntnAmount>
<AwardAmount>879890</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita Rodriguez</SignBlockName>
<PO_EMAI>rrodrigu@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Proposal #: 13-38118  Collaborative  Proposal #: 13-37866&lt;br/&gt;PI(s):  Makedon, Fillia S    PI(s):  Betke, Margrit&lt;br/&gt;Athitsos, Vassilis; Gatchel, Robert J; Huang, Heng; Romero-Ortega, Mario I&lt;br/&gt;Institution:      University of Texas-Arlington              INstitution:     Boston Univeristy    &lt;br/&gt;Title:  MRI/Dev :Collab Dev. of iRehab, an Intelligent Closed-loop Instrument for Adaptive Rehabilitation&lt;br/&gt;Project Proposed:&lt;br/&gt;This project, developing of an instrument referred to as iRehab, aims to enable personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, and/or psychosocial symptoms. The instrument, a modular rehabilitation device, in its simplest form consists of a computer, a camera, and adaptive software for assessment and training of cognitive functions. In its final, most complex form, the instrument will integrate data from a 4-degree-of-freedom robotic-arm with gimbals and torque sensing, a Kinect sensor, multiple cameras, an eye-tracking device, a touch screen, a microphone, and an fNIRS brain imaging sensor. &lt;br/&gt;The instrument will be developed in two phases. In the first phase, the investigators develop a Barrett robot arm. In the second phase, the instrument will extend to a Kinect sensor, multiple cameras, an eye-tracking device, and related low-cost components, along with the assessment software for assessing motor function and cognitive, emotional, and personality functioning. &lt;br/&gt;iRehab consists integrates multidisciplinary methodologies and sensors to assess and assist the cognitive and physical rehabilitation of persons affected by various impairments. This work highly interdisciplinary work follows a cyber-physical approach. It provides new research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. This work advances research in human brain activity mapping, personalized medicine, and big data.&lt;br/&gt;Broader Impacts:  &lt;br/&gt;The proposed instrument exhibits potential for large broader impact as it directly contributes to future healthcare and human wellbeing improving accessibility to affordable rehabilitation for a broad range of patients. The instrument is likely to accelerate the recovery of a large spectrum of injuries and diseases including those causing motor, neurological, and cognitive disorders. An education plan includes course development, internships, workshops and tutorials, and an on-line resource center. In addition to many educational impacts, impact will be felt on the fundamental research in the areas addressed.</AbstractNarration>
<MinAmdLetterDate>09/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>04/26/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1338118</AwardID>
<Investigator>
<FirstName>Fillia</FirstName>
<LastName>Makedon</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fillia S Makedon</PI_FULL_NAME>
<EmailAddress>makedon@cse.uta.edu</EmailAddress>
<PI_PHON>8172723605</PI_PHON>
<NSF_ID>000191699</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Heng</FirstName>
<LastName>Huang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Heng Huang</PI_FULL_NAME>
<EmailAddress>heng.huang@pitt.edu</EmailAddress>
<PI_PHON>4123834421</PI_PHON>
<NSF_ID>000086248</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vassilis</FirstName>
<LastName>Athitsos</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vassilis Athitsos</PI_FULL_NAME>
<EmailAddress>athitsos@uta.edu</EmailAddress>
<PI_PHON>8172722105</PI_PHON>
<NSF_ID>000308836</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mario</FirstName>
<LastName>Romero-Ortega</LastName>
<PI_MID_INIT>I</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mario I Romero-Ortega</PI_FULL_NAME>
<EmailAddress>mromero@uta.edu</EmailAddress>
<PI_PHON>8172725018</PI_PHON>
<NSF_ID>000525709</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Gatchel</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert J Gatchel</PI_FULL_NAME>
<EmailAddress>gatchel@uta.edu</EmailAddress>
<PI_PHON>8172722541</PI_PHON>
<NSF_ID>000603449</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Arlington</Name>
<CityName>Arlington</CityName>
<ZipCode>760190145</ZipCode>
<PhoneNumber>8172722105</PhoneNumber>
<StreetAddress>701 S Nedderman Dr, Box 19145</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>064234610</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT ARLINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Arlington]]></Name>
<CityName>Arlington</CityName>
<StateCode>TX</StateCode>
<ZipCode>760190001</ZipCode>
<StreetAddress><![CDATA[500 UTA Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~799890</FUND_OBLG>
<FUND_OBLG>2014~16000</FUND_OBLG>
<FUND_OBLG>2015~16000</FUND_OBLG>
<FUND_OBLG>2016~16000</FUND_OBLG>
<FUND_OBLG>2017~16000</FUND_OBLG>
<FUND_OBLG>2018~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Motivation and objectives: </strong>Physical and neurological disorders span a wide spectrum, from acute to mild and are manifested through different physical disabilities. In this project, the focus is on designing an adaptive, easy-to-use intelligent instrument that supports personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, or demonstrate psychosocial symptoms. We call this instrument <strong>iRehab</strong>. The instrument integrates rehabilitation modules, i.e., sensors, software, and effectors.&nbsp; It enables monitoring and analysis of the user&rsquo;s rehabilitation activity and performance with the aim to provide effective personalization and guidance through the rehabilitation process. The instrument then generates recommendations to the therapist as to the intensity, length, and difficulty of the rehabilitation regimen. The <strong>goals of this project</strong> were to (a) build an intelligent closed-loop instrument for adaptive rehabilitation that can monitor, collect and analyze different types of user activity data; (b) measure cognitive and physical ability of the user while performing a task-driven rehabilitation session and adapt the difficulty or intensity of the task accordingly; (c) perform analysis on the collected sensor data to enable personalization of the rehabilitation and generate recommendations to the therapist.</p> <p>&nbsp;</p> <p><strong>Summary of Activities: </strong>During the period of the grant, special therapy activities were designed (including games) in order to assess and monitor rehabilitation compliance and performance through a common front end and thus allow the therapist and the user to choose the appropriate type of activity to follow. Data logging of the game performance was automated and algorithms were designed to enable multimodal data fusion and sensor data analysis in order to determine whether a user is ready for the next exercise level or needs a different type of stimulus. Real time monitoring facilities were developed to enable exercise adaptation and personalization regarding the user&rsquo;s motor, mental and psychological state. The development of iRehab took into consideration computational as well as practical considerations: (a) accurate assessment of behavior during rehabilitation, as prescribed by the therapist; (b) cost and ease of use, (c) the types of rehabilitation equipment available (ranging from simple to advanced), and (d) the goals of the therapy, as defined by the therapist (e.g., improve motor ability of left upper limb). Different types of rehabilitation equipment were used, including a robotic arm device that generates detailed and exact torque sensing output at any instance of movement. The robotic device enabled refinement and validation of the analysis of motion tracking data in combination with other multisensory data collected. The robotic arm was instructed to move along a trajectory in 3D space, and the user, while wearing a brain-imaging sensor, was able to experience the motion trajectory.</p> <p><strong>&nbsp;</strong></p> <p><strong>Project Outcomes and Findings: </strong>The main project outcome is an evidence-based framework that collects and analyzes patient multisensory data while a person is engaged in a specific rehabilitation activity. Different metrics were designed to determine the person&rsquo;s ability to perform and respond to the tasks given. Findings include the development of specific tasks or stimuli to assess motor and mental ability, promote user engagement and analyze and visualize a person&rsquo;s response and performance in order to further refine and personalize treatment.&nbsp; The focus was on the upper limbs that model traditional physical therapy exercises. Different types of incentives were integrated to promote user engagement. Interfaces were developed to analyze and visualize the user&rsquo;s performance data. Machine learning algorithms were applied to analyze the fused multisensory data. Virtual reality tools were used to visualize the process and provide immersive exercise experience. Interactive user interfaces were designed to enable the therapist to control and guide the therapy.&nbsp;</p> <p><strong>&nbsp;</strong></p> <p><strong>Intellectual Merit: </strong>The project led to the development of advanced motion analysis algorithms and the development of new types of multi-sensing game-driven data collection and analysis methods with broad impact on a variety of neurological disorders, facilitating the diagnosis and treatment.&nbsp; The project provided new interdisciplinary research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. It advanced research in personalized physical therapy and big data and led to new insights in the use of robot-based rehabilitation, fusion of disparate sensor data (robotic, vision, neuroimaging).&nbsp; The project also opened the way for advancements in building prosthetic devices and other assistive technologies to improve the quality of life in a fundamental way.</p> <p><strong>&nbsp;</strong></p> <p><strong>Broader Impacts: </strong>The project developed software and hardware to enhance individual sensory and cognitive capabilities, improve the remote monitoring and rehabilitation therapy delivery, and provide for personalized computer and robot enabled rehabilitation.<strong> </strong>The project also developed assessment and intervention methods for different types of chronic disorders, including neurological disorders that can help reduce healthcare costs and improve the quality of therapy practices. &nbsp;The project also offered new insights into building adaptive rehabilitation systems that can accelerate the success of therapy of a large spectrum of injuries and diseases causing motor, neurological and cognitive disorders.</p> <p class="normal">&nbsp;</p> <p class="normal">&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/02/2018<br>      Modified by: Fillia&nbsp;S&nbsp;Makedon</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Motivation and objectives: Physical and neurological disorders span a wide spectrum, from acute to mild and are manifested through different physical disabilities. In this project, the focus is on designing an adaptive, easy-to-use intelligent instrument that supports personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, or demonstrate psychosocial symptoms. We call this instrument iRehab. The instrument integrates rehabilitation modules, i.e., sensors, software, and effectors.  It enables monitoring and analysis of the user?s rehabilitation activity and performance with the aim to provide effective personalization and guidance through the rehabilitation process. The instrument then generates recommendations to the therapist as to the intensity, length, and difficulty of the rehabilitation regimen. The goals of this project were to (a) build an intelligent closed-loop instrument for adaptive rehabilitation that can monitor, collect and analyze different types of user activity data; (b) measure cognitive and physical ability of the user while performing a task-driven rehabilitation session and adapt the difficulty or intensity of the task accordingly; (c) perform analysis on the collected sensor data to enable personalization of the rehabilitation and generate recommendations to the therapist.     Summary of Activities: During the period of the grant, special therapy activities were designed (including games) in order to assess and monitor rehabilitation compliance and performance through a common front end and thus allow the therapist and the user to choose the appropriate type of activity to follow. Data logging of the game performance was automated and algorithms were designed to enable multimodal data fusion and sensor data analysis in order to determine whether a user is ready for the next exercise level or needs a different type of stimulus. Real time monitoring facilities were developed to enable exercise adaptation and personalization regarding the user?s motor, mental and psychological state. The development of iRehab took into consideration computational as well as practical considerations: (a) accurate assessment of behavior during rehabilitation, as prescribed by the therapist; (b) cost and ease of use, (c) the types of rehabilitation equipment available (ranging from simple to advanced), and (d) the goals of the therapy, as defined by the therapist (e.g., improve motor ability of left upper limb). Different types of rehabilitation equipment were used, including a robotic arm device that generates detailed and exact torque sensing output at any instance of movement. The robotic device enabled refinement and validation of the analysis of motion tracking data in combination with other multisensory data collected. The robotic arm was instructed to move along a trajectory in 3D space, and the user, while wearing a brain-imaging sensor, was able to experience the motion trajectory.     Project Outcomes and Findings: The main project outcome is an evidence-based framework that collects and analyzes patient multisensory data while a person is engaged in a specific rehabilitation activity. Different metrics were designed to determine the person?s ability to perform and respond to the tasks given. Findings include the development of specific tasks or stimuli to assess motor and mental ability, promote user engagement and analyze and visualize a person?s response and performance in order to further refine and personalize treatment.  The focus was on the upper limbs that model traditional physical therapy exercises. Different types of incentives were integrated to promote user engagement. Interfaces were developed to analyze and visualize the user?s performance data. Machine learning algorithms were applied to analyze the fused multisensory data. Virtual reality tools were used to visualize the process and provide immersive exercise experience. Interactive user interfaces were designed to enable the therapist to control and guide the therapy.      Intellectual Merit: The project led to the development of advanced motion analysis algorithms and the development of new types of multi-sensing game-driven data collection and analysis methods with broad impact on a variety of neurological disorders, facilitating the diagnosis and treatment.  The project provided new interdisciplinary research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. It advanced research in personalized physical therapy and big data and led to new insights in the use of robot-based rehabilitation, fusion of disparate sensor data (robotic, vision, neuroimaging).  The project also opened the way for advancements in building prosthetic devices and other assistive technologies to improve the quality of life in a fundamental way.     Broader Impacts: The project developed software and hardware to enhance individual sensory and cognitive capabilities, improve the remote monitoring and rehabilitation therapy delivery, and provide for personalized computer and robot enabled rehabilitation. The project also developed assessment and intervention methods for different types of chronic disorders, including neurological disorders that can help reduce healthcare costs and improve the quality of therapy practices.  The project also offered new insights into building adaptive rehabilitation systems that can accelerate the success of therapy of a large spectrum of injuries and diseases causing motor, neurological and cognitive disorders.              Last Modified: 11/02/2018       Submitted by: Fillia S Makedon]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
