<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MRI Collaborative: Development of iRehab, an Intelligent Closed-Loop Instrument for Adaptive Rehabilitation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2013</AwardEffectiveDate>
<AwardExpirationDate>09/30/2017</AwardExpirationDate>
<AwardTotalIntnAmount>200109.00</AwardTotalIntnAmount>
<AwardAmount>200109</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rita Rodriguez</SignBlockName>
<PO_EMAI>rrodrigu@nsf.gov</PO_EMAI>
<PO_PHON>7032928950</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Proposal #: 13-38118 Collaborative                            Proposal #: 13-37866 &lt;br/&gt;PI(s): Makedon, Fillia S collaboration with                   PI(s): Betke, Margrit &lt;br/&gt;Athitsos, Vassilis; Gatchel, Robert J; Huang, Heng; Romero-Ortega, Mario I &lt;br/&gt;Institution: University of Texas-Arlington collaboration with Institution: Boston Univeristy &lt;br/&gt;Title: MRI/Dev :Collab Dev. of iRehab, an Intelligent Closed-loop Instrument for Adaptive Rehabilitation &lt;br/&gt;Project Proposed: &lt;br/&gt;This project, developing of an instrument referred to as iRehab, aims to enable personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, cognitive impairments, and/or psychosocial symptoms. The instrument, a modular rehabilitation device, in its simplest form consists of a computer, a camera, and adaptive software for assessment and training of cognitive functions. In its final, most complex form, the instrument will integrate data from a 4-degree-of-freedom robotic-arm with gimbals and torque sensing, a Kinect sensor, multiple cameras, an eye-tracking device, a touch screen, a microphone, and an fNIRS brain imaging sensor. &lt;br/&gt;The instrument will be developed in two phases. In the first phase, the investigators develop a Barrett robot arm. In the second phase, the instrument will extend to a Kinect sensor, multiple cameras, an eye-tracking device, and related low-cost components, along with the assessment software for assessing motor function and cognitive, emotional, and personality functioning. &lt;br/&gt;iRehab consists integrates multidisciplinary methodologies and sensors to assess and assist the cognitive and physical rehabilitation of persons affected by various impairments. This work highly interdisciplinary work follows a cyber-physical approach. It provides new research opportunities across the fields of human-centered computing, computer vision, assistive technology, robotics, machine learning, and neuroimaging. This work advances research in human brain activity mapping, personalized medicine, and big data. &lt;br/&gt;Broader Impacts: &lt;br/&gt;The proposed instrument exhibits potential for large broader impact as it directly contributes to future healthcare and human wellbeing improving accessibility to affordable rehabilitation for a broad range of patients. The instrument is likely to accelerate the recovery of a large spectrum of injuries and diseases including those causing motor, neurological, and cognitive disorders. An education plan includes course development, internships, workshops and tutorials, and an on-line resource center. In addition to many educational impacts, impact will be felt on the fundamental research in the areas addressed.</AbstractNarration>
<MinAmdLetterDate>09/16/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/16/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1337866</AwardID>
<Investigator>
<FirstName>Margrit</FirstName>
<LastName>Betke</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Margrit Betke</PI_FULL_NAME>
<EmailAddress>betke@cs.bu.edu</EmailAddress>
<PI_PHON>6173536412</PI_PHON>
<NSF_ID>000096058</NSF_ID>
<StartDate>09/16/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[CS Dept, Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022151300</ZipCode>
<StreetAddress><![CDATA[111 Cummington Mall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramReference>
<Code>1189</Code>
<Text>MAJOR RESEARCH INSTRUMENTATION</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~200109</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The project built iRehab, a modular, adaptive, easy-to-use intelligent instrument that supports the personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, or cognitive impairments. iRehab uses the Proficio robotic arm with accurate torque sensing output.&nbsp; The robotic arm can be instructed to move along a trajectory in 3D space, and the user, while holding onto the robot's hand, experiences this motion trajectory. The research team paired the robotic arm with a Kinect sensor and an Oculus Rift virtual reality headset (see image).&nbsp; Experiments showed that the Kinect interface can monitor upper-body exercises with an appropriate level of accuracy. The result was obtained by comparing the trajectories measured with the Kinect interface to the ground-truth trajectories obtained with the Proficio robotic arm. The margin of error depended on the relative position between the Kinect and the Proficio and the direction of the exercise motion. &nbsp;</p> <p>The team developed the DyAd approach (short for "Dynamic Adjustment" approach), which recommends adjusted rehabilitation exercise configurations based on a person's performance. The system can compare the performed movement trajectory with a desired trajectory and measure differences. Based on these differences, the system can make adjustments, for example, in the difficulty level of the exercise.</p> <p>For users with severe motion disabilities, who cannot use the traditional keyboard and mouse to access a computer, iRehab provides a novel interaction mechanism that uses a virtual keyboard.&nbsp; The mechanism is called EyeSwipe and requires a gaze detection device to be connected with iRehab.&nbsp; EyeSwipe is a dwell-time-free gaze-typing method. With EyeSwipe, the user gaze-types the first and last characters of a word using the novel selection strategy &ldquo;reverse crossing.&rdquo; To gaze-type the characters in the middle of the word, the user only needs to glance at the vicinity of the respective keys.</p> <p>The project supported the professional preparation of numerous researchers, doctoral, masters, and undergraduate students.&nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 12/23/2017<br>      Modified by: Margrit&nbsp;Betke</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1337866/1337866_10280530_1514067544106_Betke-outcomes-iRehab--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1337866/1337866_10280530_1514067544106_Betke-outcomes-iRehab--rgov-800width.jpg" title="iRehab"><img src="/por/images/Reports/POR/2017/1337866/1337866_10280530_1514067544106_Betke-outcomes-iRehab--rgov-66x44.jpg" alt="iRehab"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The iRehab instrument: A Proficio robotic arm, a Kinect senor, and an Oculus Rift virtual reality headset are used during physical exercise.</div> <div class="imageCredit">Boston University</div> <div class="imagePermisssions">Copyright owner is an institution with an existing agreement allowing use by NSF</div> <div class="imageSubmitted">Margrit&nbsp;Betke</div> <div class="imageTitle">iRehab</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The project built iRehab, a modular, adaptive, easy-to-use intelligent instrument that supports the personalized rehabilitation therapy for individuals suffering from brain injury, motor disabilities, or cognitive impairments. iRehab uses the Proficio robotic arm with accurate torque sensing output.  The robotic arm can be instructed to move along a trajectory in 3D space, and the user, while holding onto the robot's hand, experiences this motion trajectory. The research team paired the robotic arm with a Kinect sensor and an Oculus Rift virtual reality headset (see image).  Experiments showed that the Kinect interface can monitor upper-body exercises with an appropriate level of accuracy. The result was obtained by comparing the trajectories measured with the Kinect interface to the ground-truth trajectories obtained with the Proficio robotic arm. The margin of error depended on the relative position between the Kinect and the Proficio and the direction of the exercise motion.    The team developed the DyAd approach (short for "Dynamic Adjustment" approach), which recommends adjusted rehabilitation exercise configurations based on a person's performance. The system can compare the performed movement trajectory with a desired trajectory and measure differences. Based on these differences, the system can make adjustments, for example, in the difficulty level of the exercise.  For users with severe motion disabilities, who cannot use the traditional keyboard and mouse to access a computer, iRehab provides a novel interaction mechanism that uses a virtual keyboard.  The mechanism is called EyeSwipe and requires a gaze detection device to be connected with iRehab.  EyeSwipe is a dwell-time-free gaze-typing method. With EyeSwipe, the user gaze-types the first and last characters of a word using the novel selection strategy "reverse crossing." To gaze-type the characters in the middle of the word, the user only needs to glance at the vicinity of the respective keys.  The project supported the professional preparation of numerous researchers, doctoral, masters, and undergraduate students.            Last Modified: 12/23/2017       Submitted by: Margrit Betke]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
