<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Using Neuroscience to Optimize Video Thumbnail Selection</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2013</AwardEffectiveDate>
<AwardExpirationDate>12/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>150000.00</AwardTotalIntnAmount>
<AwardAmount>150000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Glenn H. Larsen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>The innovation of this neuroscience project will be used to build a proprietary model of how the human brain generates preference from the perception of visual information. This model will serve as the basis for a web-based software product that can automatically select the most visually appealing frame from an online video to be used as the thumbnail representing the video. Using neuroscience to predict the visual appeal of a thumbnail allows for automated identification of more engaging thumbnails that will increase click-through rates and, as a result, video views. This is critically important for publishers because the thumbnail is the direct point of contact between publishers, advertisers, and users, meaning that billion dollar revenue streams pass through this tiny image. By introducing state-of-the-art neurotechnology to online video thumbnail selection, the proposed innovation offers a scientific way to increase clicks rates, video views, and, as a result, revenue streams.&lt;br/&gt;&lt;br/&gt;The broader/commercial impact of the proposed innovation stems from the generality of the core technology, which is predicting human preference for visual information using neuroscience. Once developed, this automated video thumbnail selection method will revolutionize online video, and can easily be extended to optimize image selection for any online media. For example, static online display advertisements such as banner ads, thumbnails for products on e-commerce websites, consumer package design, product design, User Interface (UX) Design for mobile devices, and application icons. Together these commercial sectors generate trillions of dollars in revenue every year, creating an exceptionally large market for the technology. Through Neon's technology, the way in which Internet users interact with and select visual information will be transformed.</AbstractNarration>
<MinAmdLetterDate>06/17/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/17/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1315058</AwardID>
<Investigator>
<FirstName>Sophie</FirstName>
<LastName>Lebrecht</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sophie Lebrecht</PI_FULL_NAME>
<EmailAddress>lebrecht@neon-lab.com</EmailAddress>
<PI_PHON>4129449262</PI_PHON>
<NSF_ID>000622022</NSF_ID>
<StartDate>06/17/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Neon Labs</Name>
<CityName>San Francisco</CityName>
<ZipCode>941070000</ZipCode>
<PhoneNumber>4129449262</PhoneNumber>
<StreetAddress>27 South Park Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>14</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA14</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078811187</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEON LABS, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Neon Labs]]></Name>
<CityName>Moffett Field</CityName>
<StateCode>CA</StateCode>
<ZipCode>940350398</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8039</Code>
<Text>Information, Communication &amp; Computing</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~150000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1"><span class="s1">During Phase I of our Small Business Innovation Research award, we were successful in building a market-ready product called Neon for Video. The product allows customers to input a video and view top-ranked frames from the video that can be published as the thumbnail representing the video online. The thumbnail selections are powered by a proprietary computational model that extracts the most visually appealing frames, or frames with positive affective valence, from a given video based on how the human brain generates preference from the perception of visual information.&nbsp;</span></p> <p class="p1"><span class="s1">In order to validate the effectiveness of Neon&rsquo;s thumbnail extraction model, we conducted a large-scale test on the online video platform YouTube. Experimental results concluded that Neon thumbnails generated 20-150% more video views than the default thumbnail selected by YouTube. We conducted additional research and work that led to the successful development and validation of Neon for Video. This work included: conducting behavioral experiments to measure the affective valence perception of 16,200 scene images, which were frames automatically extracted from a wide-ranging selection of videos; developing a computational model that leverages the experimental data associated with the images used in the behavioral experiments, which is capable of making real-time valence predictions for novel images; building a set of APIs that allow customers to input videos and generate thumbnails; and forming a commercial partnership and building a technical integration with Brightcove, one of the leaders in online video hosting, which allows Neon to access the raw video file, necessary for Neon to process the video and select the thumbnails. By using this method to select images to represent online video content, video publishers are able to automatically find the images in their video content that will cause potential video viewers to engage with their content.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 03/31/2014<br>      Modified by: Sophie&nbsp;Lebrecht</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[During Phase I of our Small Business Innovation Research award, we were successful in building a market-ready product called Neon for Video. The product allows customers to input a video and view top-ranked frames from the video that can be published as the thumbnail representing the video online. The thumbnail selections are powered by a proprietary computational model that extracts the most visually appealing frames, or frames with positive affective valence, from a given video based on how the human brain generates preference from the perception of visual information.  In order to validate the effectiveness of NeonÃ†s thumbnail extraction model, we conducted a large-scale test on the online video platform YouTube. Experimental results concluded that Neon thumbnails generated 20-150% more video views than the default thumbnail selected by YouTube. We conducted additional research and work that led to the successful development and validation of Neon for Video. This work included: conducting behavioral experiments to measure the affective valence perception of 16,200 scene images, which were frames automatically extracted from a wide-ranging selection of videos; developing a computational model that leverages the experimental data associated with the images used in the behavioral experiments, which is capable of making real-time valence predictions for novel images; building a set of APIs that allow customers to input videos and generate thumbnails; and forming a commercial partnership and building a technical integration with Brightcove, one of the leaders in online video hosting, which allows Neon to access the raw video file, necessary for Neon to process the video and select the thumbnails. By using this method to select images to represent online video content, video publishers are able to automatically find the images in their video content that will cause potential video viewers to engage with their content.          Last Modified: 03/31/2014       Submitted by: Sophie Lebrecht]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
