<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: New Representations of Probability Distributions to Improve Machine Learning --- A Unified Kernel Embedding Framework for Distributions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2014</AwardEffectiveDate>
<AwardExpirationDate>04/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>499721.00</AwardTotalIntnAmount>
<AwardAmount>499721</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Computational intelligence touches our lives daily.  Web searches, weather prediction, detecting financial fraud, medicine and education benefit from this ubiquitous technology.  Problems in computational intelligence such as image classification and predicting properties of new materials produce copious amounts of high-dimensional, complex data.  Many algorithms in computational intelligence rely on probability distributions, and such data can carry unusual distributions that challenge traditional methods of modeling.  (For example, they are typically not textbook distributions such as the Gaussian.)  In some applications, the data input to the algorithms are themselves probability distributions.  Existing techniques are cannot both capture unusual distributions and scale to millions of data points without stalling the computation.  There is a pressing need for a flexible, efficient framework for representing, learning, and reasoning about datasets arising from these problems.&lt;br/&gt;&lt;br/&gt;This project will address these challenges by developing a novel and unified framework to represent and model, learn, and use probability distributions in computational intelligence.  To evaluate the utility of the new techniques, the project will test them on difficult real-world problems in computer image analysis, materials science, and flow cytometry (a biotechnology technique used for cell counting, cell sorting, and protein engineering).&lt;br/&gt;&lt;br/&gt;The project, an NSF CAREER award, will integrate the research results with several education intiatives.  New curricula will be designed for both undergraduate and graduate students, with empahsis on students from under-represented groups.  A new online course will be created to make the results accessible to massive online masters students.  Finally, advanced high school math teachers will be engaged to design problems related to the reserach for use in a math competition for advanced high school students.&lt;br/&gt;&lt;br/&gt;This project will (1) create a novel and unified nonparametric kernel framework for distributional data and distributions with fine-grained statistical properties, and (2) develop principled and scalable algorithms for nonparametric analysis of big data. The unified kernel embedding framework will advance large scale nonparametric data analysis significantly, and play an important synergistic role in bridging together traditionally separate research areas in data analysis, including kernel methods, graphical models, optimization, nonparametric Bayesian methods, functional analysis and tensor data analysis. In addition to advances in algorithmic methods, the applications to large-scale image classification, flow cytometry, and materials property prediction have the potential for transformative impact on society.</AbstractNarration>
<MinAmdLetterDate>05/07/2014</MinAmdLetterDate>
<MaxAmdLetterDate>04/12/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1350983</AwardID>
<Investigator>
<FirstName>Haesun</FirstName>
<LastName>Park</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Haesun Park</PI_FULL_NAME>
<EmailAddress>hpark@cc.gatech.edu</EmailAddress>
<PI_PHON>4043852170</PI_PHON>
<NSF_ID>000163876</NSF_ID>
<StartDate>04/12/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Le</FirstName>
<LastName>Song</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Le Song</PI_FULL_NAME>
<EmailAddress>lsong@cc.gatech.edu</EmailAddress>
<PI_PHON>4048585702</PI_PHON>
<NSF_ID>000601175</NSF_ID>
<StartDate>05/07/2014</StartDate>
<EndDate>04/12/2021</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Ave. NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~89322</FUND_OBLG>
<FUND_OBLG>2015~99069</FUND_OBLG>
<FUND_OBLG>2016~102371</FUND_OBLG>
<FUND_OBLG>2017~144527</FUND_OBLG>
<FUND_OBLG>2018~64432</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Data arising from many real world problems ranging from image classification, to flow cytometry data analysis, to materials property prediction, contain very rich and complex structures, such as translation invariance, permutation invariance and non-Gaussian distributions. There is a pressing need for a flexible and unified framework for representing, learning, and reasoning about datasets from these problems in an efficient manner.</p> <p>&nbsp;</p> <p>The embedding framework developed in this project represents probability distributions and structured data as elements in a vector space, such that comparisons and manipulations of distributions and probabilistic reasoning, can be carried out via vector space operations, such as inner products, distances, projections, linear transformations and spectral analysis. This new view will allow many existing data analysis algorithms, such as support vector machines (SVM), one-class SVM, k-means clustering, ridge regression, principal component analysis, to generalize directly to structured and distributional data.</p> <p>&nbsp;</p> <p>The framework has broadened and enhanced the benefits of machine learning techniques to its users. The developed embedding framework has also played an important synergistic role in bridging together traditionally separate research areas in data analysis, including kernel methods, graphical models, optimization, nonparametric Bayesian methods, functional analysis and tensor data analysis.</p> <p>&nbsp;</p> <p>Besides advances in methodologies, the focus on large-scale image classification and materials property prediction, have transformative impact in the society. In response to the growing demand for machine learning in diverse applications, the novel learning framework has been introduced into the curriculum at Georgia Tech, to train both graduate and students from under-presented groups in the foundations, engineering, and applications of machine learning.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/12/2021<br>      Modified by: Haesun&nbsp;Park</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Data arising from many real world problems ranging from image classification, to flow cytometry data analysis, to materials property prediction, contain very rich and complex structures, such as translation invariance, permutation invariance and non-Gaussian distributions. There is a pressing need for a flexible and unified framework for representing, learning, and reasoning about datasets from these problems in an efficient manner.     The embedding framework developed in this project represents probability distributions and structured data as elements in a vector space, such that comparisons and manipulations of distributions and probabilistic reasoning, can be carried out via vector space operations, such as inner products, distances, projections, linear transformations and spectral analysis. This new view will allow many existing data analysis algorithms, such as support vector machines (SVM), one-class SVM, k-means clustering, ridge regression, principal component analysis, to generalize directly to structured and distributional data.     The framework has broadened and enhanced the benefits of machine learning techniques to its users. The developed embedding framework has also played an important synergistic role in bridging together traditionally separate research areas in data analysis, including kernel methods, graphical models, optimization, nonparametric Bayesian methods, functional analysis and tensor data analysis.     Besides advances in methodologies, the focus on large-scale image classification and materials property prediction, have transformative impact in the society. In response to the growing demand for machine learning in diverse applications, the novel learning framework has been introduced into the curriculum at Georgia Tech, to train both graduate and students from under-presented groups in the foundations, engineering, and applications of machine learning.          Last Modified: 07/12/2021       Submitted by: Haesun Park]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
