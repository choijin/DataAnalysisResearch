<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: MicSynth: Enhancing and Reconstructing Sound Scenes from Crowdsourced Recordings</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
<AwardExpirationDate>06/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>There is no doubt that we live in an environment that is massively recorded by multiple people at any point in time. Although we have the technology to combine such information in the visual space (e.g., with PhotoSynth), there is currently no good way to combine audio streams from multiple recordings of the same event. This projects fills that gap by developing new techniques in spectral decompositions and landmark-based localization methods to support taking large amounts of low-level audio recordings of the same event and resynthesize them as one high-quality version, eliminating the artifacts and noise of each individual recording while taking advantage of their strong points.&lt;br/&gt;&lt;br/&gt;This project aims to introduce new computational tools to combine uncurated recordings at a large scale, and produce information that no single recording can provide. Combining all available information and producing objective representations will enable effective sifting through data from massively recorded events (e.g., social unrest, natural disasters, historical moments) and focus on the needed information. The resulting tools will support creation of high-quality recordings from historical events that might not otherwise be well documented, by using the power of the crowds. The project web site (http://www.cs.illinois.edu/~paris/crowdmic) will provide access to the research results, including a service that allows the consolidation from user-submitted recordings, publication and source code in order to to stimulate activity in this field. Research results will also be incorporated in the development of classes on social and crowdsourcing aspects of audio and signal processing.</AbstractNarration>
<MinAmdLetterDate>09/05/2013</MinAmdLetterDate>
<MaxAmdLetterDate>09/05/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1319708</AwardID>
<Investigator>
<FirstName>Paris</FirstName>
<LastName>Smaragdis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Paris Smaragdis</PI_FULL_NAME>
<EmailAddress>paris@illinois.edu</EmailAddress>
<PI_PHON>2172656893</PI_PHON>
<NSF_ID>000573387</NSF_ID>
<StartDate>09/05/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>618207473</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~500000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span>Today most events of note are being massively recorded by citizens, and these recordings are openly shared in social media. That data often requires painstaking manual effort to piece together. In this project we developed computational solutions to consolidating large numbers of crowdsourced recordings into a single coherent entity.</span></p> <p><span>In terms of intellectual merit, we have developed novel computational approaches that allow us to efficiently process thousands of recordings simultaneously and subsequently discover how they are related to each other. This task was computationally prohibitive in the past, requiring supercomputing-grade resources. Through our work we have shown that the same goal, with increased accuracy, can be achieved more efficiently on consumer-grade equipment. Our algorithms replace costly mathematical operations with hashing approximations that are not only computationally more efficient, but also more robust to real-world complications. In doing so we have shown a number of examples of how to take traditional signal processing primitives and redo them so that they can now tractably operate on big data scales.</span></p> <p><span>In terms of broader impact, we have developed tools that can be used by anyone who deals with massively recorded data, whether that is a private citizen or a large organization. The basic principles of our work are already in use by large social media corporations consolidating user generated content, and media production software that expands our creative horizons. Moving forward we see such technology as being a valuable tool for national security applications (e.g. analyzing user-generated recordings from disaster incidents), as well as serving as the backbone for our future work on large sensing grids (e.g. city-wide acoustic monitoring). As we increasingly see larger amounts of raw recordings being generated and shared, we see our work serving as a starting point to revising how we process signals at such scales and how to get value out of them.</span></p><br> <p>            Last Modified: 07/27/2018<br>      Modified by: Paris&nbsp;Smaragdis</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Today most events of note are being massively recorded by citizens, and these recordings are openly shared in social media. That data often requires painstaking manual effort to piece together. In this project we developed computational solutions to consolidating large numbers of crowdsourced recordings into a single coherent entity.  In terms of intellectual merit, we have developed novel computational approaches that allow us to efficiently process thousands of recordings simultaneously and subsequently discover how they are related to each other. This task was computationally prohibitive in the past, requiring supercomputing-grade resources. Through our work we have shown that the same goal, with increased accuracy, can be achieved more efficiently on consumer-grade equipment. Our algorithms replace costly mathematical operations with hashing approximations that are not only computationally more efficient, but also more robust to real-world complications. In doing so we have shown a number of examples of how to take traditional signal processing primitives and redo them so that they can now tractably operate on big data scales.  In terms of broader impact, we have developed tools that can be used by anyone who deals with massively recorded data, whether that is a private citizen or a large organization. The basic principles of our work are already in use by large social media corporations consolidating user generated content, and media production software that expands our creative horizons. Moving forward we see such technology as being a valuable tool for national security applications (e.g. analyzing user-generated recordings from disaster incidents), as well as serving as the backbone for our future work on large sensing grids (e.g. city-wide acoustic monitoring). As we increasingly see larger amounts of raw recordings being generated and shared, we see our work serving as a starting point to revising how we process signals at such scales and how to get value out of them.       Last Modified: 07/27/2018       Submitted by: Paris Smaragdis]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
