<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CGV: Medium: Collaborative Research: Developing conceptual models for navigation, marking, and inspection in the context of 3D image segmentation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2013</AwardEffectiveDate>
<AwardExpirationDate>05/31/2017</AwardExpirationDate>
<AwardTotalIntnAmount>232680.00</AwardTotalIntnAmount>
<AwardAmount>232680</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>3D image segmentation is an important and ubiquitous task in image-oriented scientific disciplines, particularly biomedicine, where images provide the basis for biological discovery.  While imaging techniques reveal spatial content and activities within an entire subject, ultimately biologists are interested in specific anatomical structures (e.g., organs, tissues, cells, etc.).  Delineation of the structures of interest within a given set of images is therefore a typical first-step in the data-to-knowledge pipeline, with both the efficiency and accuracy of segmentation critically affecting how the data is utilized in research and clinical practice.  Creating accurate segmentations, particularly for 3D biomedical images, is a non-trivial task that calls for cooperation between humans and computers.  While human experts, with their superior visual perception skills and vast knowledge and experience acquired from years of training, ultimately decide what constitutes an accurate segmentation, they lack the objectivity or efficiency of computational algorithms.  On the other hand, without expert guidance, segmentation algorithms easily fail in the presence of the noise and ambiguity that are inevitable in biomedical images.  In this research the PIs will investigate 3D image segmentation as a human-computer interaction paradigm to better understand the human factors that are involved in the current segmentation process, with the goal of making the process more efficient, accurate and repeatable.  The team's hypothesis is that the segmentation process could be significantly improved through a deeper understanding of how people perform low-level perception and cognition tasks in the context of 3D segmentation (e.g., visual cues, delineation of structures by marks, and local accuracy or quality criteria), and how domain experts wish to specify high-level segmentation constraints (e.g., connectivity, topology, and shape).  To test this hypothesis the PIs will analyze the segmentation process by domain experts that span a reasonable subspace of the actual segmentors and segmentation tasks in biology and clinical practice, to define a conceptual framework that captures the low-level perception and cognitive elements of segmentation as well as the higher-level information related to navigation, marking, and inspection.  Building upon and instantiating the framework, the team will work with experts to develop a prototype segmentation tool that explores novel interaction and visualization paradigms as well as their supporting algorithms.  The prototype tool will be used to both verify the conceptual framework and to create a more effective practical solution to segmentation.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  By formulating and studying segmentation as a human perception and cognitive task, this work represents a major departure from existing research on either segmentation algorithms or tools.  The resulting conceptual framework will serve as a bridge between the two communities, leading both to better designs for current and future segmentation tools and the framing of new problems for segmentation algorithms.  For end users, the working prototype will support a more effective segmentation experience that is powered by the underlying conceptual framework.  Furthermore, formalizing the kinds of perceptual cues and conceptual models users have when approaching the segmentation problem will serve as a useful test case for understanding the more general question of how perception and cognition interact when they are re-mapped to solve a problem they were never designed for.  To disseminate the findings of this research, the PIs will release their working prototype as an open-source project, which can then serve as a shared communication platform between algorithm developers, tool developers, and end users.</AbstractNarration>
<MinAmdLetterDate>06/12/2013</MinAmdLetterDate>
<MaxAmdLetterDate>06/12/2013</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1302200</AwardID>
<Investigator>
<FirstName>Tao</FirstName>
<LastName>Ju</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tao Ju</PI_FULL_NAME>
<EmailAddress>taoju@cse.wustl.edu</EmailAddress>
<PI_PHON>3149356648</PI_PHON>
<NSF_ID>000492331</NSF_ID>
<StartDate>06/12/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Washington University</Name>
<CityName>Saint Louis</CityName>
<ZipCode>631304862</ZipCode>
<PhoneNumber>3147474134</PhoneNumber>
<StreetAddress>CAMPUS BOX 1054</StreetAddress>
<StreetAddress2><![CDATA[1 Brookings Drive]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>068552207</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WASHINGTON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068552207</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Washington University]]></Name>
<CityName>St. Louis</CityName>
<StateCode>MO</StateCode>
<ZipCode>631304899</ZipCode>
<StreetAddress><![CDATA[One Brookings Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0113</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2013~232680</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-b95d7969-a134-f06a-dcc2-6d126f85e584"> </span></p> <p dir="ltr"><span>The advance of imaging techniques in the past few decades has made a fundamental impact on biomedicine. With novel use of light, sound, and radiation, imaging allows us to see &ldquo;through&rdquo; the subject, whether living or post-mortem, at an ever increasing depth and resolution. Combined with radioactive, chemical or physical markers, the images can highlight biological activities that are otherwise invisible to our eyes. Today, imaging has become a central tool in both scientific research and clinical practices.</span></p> <p dir="ltr"><span>Imaging produces spatial data which, in its raw form, consists of nothing more than colored pixels or voxels. This information needs to be processed in order to reveal useful knowledge about the physiology, morphology, and mechanics of the imaged subject. The data-to-knowledge pipeline usually starts with the delineation of the anatomical structure of interest (e.g., an organ, a tissue, a cell, or a collection of these), a process commonly known as segmentation. Segmentation is not only meaningful from a biological perspective (as biological properties tend to differ between different structures), but is also critical for a wide range of qualitative and quantitative interrogation processes that are commonly found in practical&nbsp;</span>applications.</p> <p dir="ltr"><span>In this collaborative project between researchers at Washington University in St. Louis, Oregon State University and University of North Texas (formerly University of California-San Diego), the team has developed a conceptual framework that captures both the low-level perception and cognitive elements of segmentation as well as the higher-level information related to workflow, inspection, and repeatability. Furthermore, building upon this frame-work, the team has developed novel tools, protocols and algorithms that improve both the manual and the semi-automatic segmentation and review process in terms of efficiency, quality, and repeatability. &nbsp;Some of the notable outcomes are:</span></p> <p dir="ltr"><span>- We have documented the segmentation process for four separate use cases: environmental engineering (carbon sequestration), 3D cell structures (retinal cell connectivity, breast cancer, neurodegeneration), cardiac development, and nasal and lung airways (rabbits, humans, and mice).</span></p> <p dir="ltr"><span>- We have developed an ontology describing the segmentation process from sample preparation to downstream application use. This ontology is hierarchical and captures both the low-level tasks (e.g., perception of boundaries) through high-level tasks (knowledge of the structure being segmented).</span></p> <p dir="ltr"><span>- We have developed novel methods for semi-automatic surface reconstruction incorporating high-level tasks, guided by knowledge of the structure being segmented. We consider three types of knowledge: the shape of the structure (in the form of existing pre-segmented templates), previously drawn contours used to segment the structure, and the topology of the structure (in the form of the number of topological handles, or genus).</span></p> <p dir="ltr"><span>The outcome of our project benefits both the segmentation research community and the users of segmentation tools in several ways. First, our developed conceptual framework can serve as a bridge between the two communities, potentially leading both to better designs for current and future segmentation interfaces and the phrasing of new problems in the automatic segmentation research community. Second, our working prototype will support end-to-end segmentation and incorporate any developed interaction paradigms.</span></p> <p dir="ltr"><span>The research results have been disseminated through research papers as well as the open-source software prototype, VolumeViewer. The project has provided training for four graduate students and a handful of undergraduate students across the three institutions, eight of which are female and/or underrepresented minorities. </span></p> <p><br /><br /><br /><br /></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/02/2017<br>      Modified by: Tao&nbsp;Ju</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501651215002_seg-5--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501651215002_seg-5--rgov-800width.jpg" title="VolumeViewer software"><img src="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501651215002_seg-5--rgov-66x44.jpg" alt="VolumeViewer software"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This is the user interface of VolumeViewer. Area 1 is the main window, 2 is the 3D volume localization, 3 is the protocol instructions, and 4 is the navigation path visualization.</div> <div class="imageCredit">Michelle Holloway [ISVC'15]</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tao&nbsp;Ju</div> <div class="imageTitle">VolumeViewer software</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501650151558_seg-3--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501650151558_seg-3--rgov-800width.jpg" title="Topology-constrained reconstruction from cross-sections"><img src="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501650151558_seg-3--rgov-66x44.jpg" alt="Topology-constrained reconstruction from cross-sections"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Given anatomical boundaries delineated by experts  (left), previous reconstruction algorithms create topological errors such as tunnels (middle left, middle right), whereas our algorithm allows the user to control the genus of the surface (right).</div> <div class="imageCredit">Tao Ju [Siggraph'15]</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tao&nbsp;Ju</div> <div class="imageTitle">Topology-constrained reconstruction from cross-sections</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501650803936_seg-4--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501650803936_seg-4--rgov-800width.jpg" title="Template-based surface reconstruction from cross-sections"><img src="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501650803936_seg-4--rgov-66x44.jpg" alt="Template-based surface reconstruction from cross-sections"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Given a template shape of the anatomical structure (left) and another set of contours drawn by the experts (middle), our algorithm deforms the template to fit the new contours (right).</div> <div class="imageCredit">Tao Ju [C&G 16]</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tao&nbsp;Ju</div> <div class="imageTitle">Template-based surface reconstruction from cross-sections</div> </div> </li> <li> <a href="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501649708405_seg-2--rgov-214x142.jpg" original="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501649708405_seg-2--rgov-800width.jpg" title="Topology-constrained reconstruction of multi-labelled domains from cross-sections"><img src="/por/images/Reports/POR/2017/1302200/1302200_10251444_1501649708405_seg-2--rgov-66x44.jpg" alt="Topology-constrained reconstruction of multi-labelled domains from cross-sections"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Given a stack of multi-labelled cross-sections (left) and a set of topological constraints on the number and genus of surfaces bounding each label (middle top), our algorithm reconstructs a multi-labelled model meeting those constraints (middle, right).</div> <div class="imageCredit">Tao Ju [Siggraph'17]</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Tao&nbsp;Ju</div> <div class="imageTitle">Topology-constrained reconstruction of multi-labelled domains from cross-sections</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The advance of imaging techniques in the past few decades has made a fundamental impact on biomedicine. With novel use of light, sound, and radiation, imaging allows us to see "through" the subject, whether living or post-mortem, at an ever increasing depth and resolution. Combined with radioactive, chemical or physical markers, the images can highlight biological activities that are otherwise invisible to our eyes. Today, imaging has become a central tool in both scientific research and clinical practices. Imaging produces spatial data which, in its raw form, consists of nothing more than colored pixels or voxels. This information needs to be processed in order to reveal useful knowledge about the physiology, morphology, and mechanics of the imaged subject. The data-to-knowledge pipeline usually starts with the delineation of the anatomical structure of interest (e.g., an organ, a tissue, a cell, or a collection of these), a process commonly known as segmentation. Segmentation is not only meaningful from a biological perspective (as biological properties tend to differ between different structures), but is also critical for a wide range of qualitative and quantitative interrogation processes that are commonly found in practical applications. In this collaborative project between researchers at Washington University in St. Louis, Oregon State University and University of North Texas (formerly University of California-San Diego), the team has developed a conceptual framework that captures both the low-level perception and cognitive elements of segmentation as well as the higher-level information related to workflow, inspection, and repeatability. Furthermore, building upon this frame-work, the team has developed novel tools, protocols and algorithms that improve both the manual and the semi-automatic segmentation and review process in terms of efficiency, quality, and repeatability.  Some of the notable outcomes are: - We have documented the segmentation process for four separate use cases: environmental engineering (carbon sequestration), 3D cell structures (retinal cell connectivity, breast cancer, neurodegeneration), cardiac development, and nasal and lung airways (rabbits, humans, and mice). - We have developed an ontology describing the segmentation process from sample preparation to downstream application use. This ontology is hierarchical and captures both the low-level tasks (e.g., perception of boundaries) through high-level tasks (knowledge of the structure being segmented). - We have developed novel methods for semi-automatic surface reconstruction incorporating high-level tasks, guided by knowledge of the structure being segmented. We consider three types of knowledge: the shape of the structure (in the form of existing pre-segmented templates), previously drawn contours used to segment the structure, and the topology of the structure (in the form of the number of topological handles, or genus). The outcome of our project benefits both the segmentation research community and the users of segmentation tools in several ways. First, our developed conceptual framework can serve as a bridge between the two communities, potentially leading both to better designs for current and future segmentation interfaces and the phrasing of new problems in the automatic segmentation research community. Second, our working prototype will support end-to-end segmentation and incorporate any developed interaction paradigms. The research results have been disseminated through research papers as well as the open-source software prototype, VolumeViewer. The project has provided training for four graduate students and a handful of undergraduate students across the three institutions, eight of which are female and/or underrepresented minorities.                    Last Modified: 08/02/2017       Submitted by: Tao Ju]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
