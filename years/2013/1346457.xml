<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>STTR Phase I:  Rapid and Efficient Scene Modeling for Law Enforcement and Disaster Response</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2014</AwardEffectiveDate>
<AwardExpirationDate>06/30/2015</AwardExpirationDate>
<AwardTotalIntnAmount>224850.00</AwardTotalIntnAmount>
<AwardAmount>254800</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Small Business Technology Transfer Research (STTR) Phase I project will produce technology capable of constructing three-dimensional (3D) models of scenes accurately, rapidly, and at low cost. The technology leverages recent developments in computer vision and enhances them for operation under varying ambient conditions while increasing speed of model construction, thus enabling practical applications. Key system design requirements identified include: 1) ability to produce complete and accurate high fidelity models quickly; 2) robustness to varying ambient conditions; 3) ease of use by a non-specialist without extensive training; and 4) low cost. The proposed research objectives include: improvements to state-of-the-art algorithms for robust and efficient 3D modeling from images; the development of an approach for dense 3D reconstruction using different sensor modalities; the development of a sensor view point planning algorithm; the creation of techniques for the identification of missing model data; and the development of a system for merging data from different sources into a coherent 3D model of the environment. The work plan includes a thorough assessment of the system?s ability to reconstruct a scene accurately and completely, as well as the benefit of reconstructing scenes using sensors deployed by low-cost vehicles. &lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project will be the widespread use of 3D modeling for scene documentation. Systems currently available for this application are expensive, slow, bulky, and their use requires special training. The technology resulting from this work will enable the production and commercialization of systems that are faster, more affordable, and easier to use by non-experts, thereby simplifying their adoption by a larger number of law enforcers, prosecutors, insurers, and other government agencies. In the transportation domain, for example, a speedy scene reconstruction is essential to restore the flow of traffic when accidents happen. On busy highways, traffic backup can grow at a rate of up to a mile per minute of delay in clearing the accident site. This currently limits the complete documentation of accidents to only those cases where fatalities occur. The technology proposed will allow the documentation of larger number of incidents. Additionally, a great reduction in the time and complexity involved in determining the cause of accidents is expected. The potential long-term benefits of this reduction include a more rapid evolution of regulation and policy to deal with chronic causes of traffic accidents, which will expedite the implementation of road safety mechanisms.</AbstractNarration>
<MinAmdLetterDate>12/11/2013</MinAmdLetterDate>
<MaxAmdLetterDate>12/17/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1346457</AwardID>
<Investigator>
<FirstName>Sanjiv</FirstName>
<LastName>Singh</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sanjiv Singh</PI_FULL_NAME>
<EmailAddress>ssingh@cmu.edu</EmailAddress>
<PI_PHON>4122686577</PI_PHON>
<NSF_ID>000418992</NSF_ID>
<StartDate>12/11/2013</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Luis Ernesto</FirstName>
<LastName>Navarro-Serment</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Luis Ernesto Navarro-Serment</PI_FULL_NAME>
<EmailAddress>lenscmu@ri.cmu.edu</EmailAddress>
<PI_PHON>4122689527</PI_PHON>
<NSF_ID>000647293</NSF_ID>
<StartDate>12/11/2013</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Near Earth Autonomy, Inc.</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152082517</ZipCode>
<PhoneNumber>4125136110</PhoneNumber>
<StreetAddress>150 N Lexington St.</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>078391304</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEAR EARTH AUTONOMY, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Near Earth Autonomy]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152131856</ZipCode>
<StreetAddress><![CDATA[5001 Baum Blvd. Suite 750]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1505</Code>
<Text>STTR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>1505</Code>
<Text>STTR PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>163E</Code>
<Text>SBIR Phase IB</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~224850</FUND_OBLG>
<FUND_OBLG>2015~29950</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Various industries have a need for tools that create photorealistic, three-dimensional (3D) models of real world scenes. Architects and engineers use such models to create as-built plans and for maintenance purposes; mining and construction companies use them to calculate how much soil must be moved to reach a vein or build a highway; police and fire investigators use them for forensics purposes; and insurance companies, for processing claims. These are but a few examples of the utility of such tools. Existing alternatives are expensive to own and slow to operate. Furthermore, existing workflows involve data collection followed by off-site post-processing to build the model. Only then do users determine whether sufficient data has been collected or whether it is necessary to revisit the site, which is often costly or sometimes impossible.</p> <p>In this project, Near Earth Autonomy developed a fast, low-cost, accurate scene modeling system to meet the needs of the industries listed above and others. The system can be hand-carried or mounted on vehicles, including ground-based or aerial, manned or unmanned. During data collection the system builds the model in real-time and presents it to the operator, allowing him to validate the data live before leaving the site. The system includes state-of-the-art software created by Near Earth to combine range data from a laser rangefinder, images from a camera, and inertial data from an inertial measurement unit to create self-consistent 3D models. Two prototype scene modeling systems were built and used to map large regions and multi-story buildings, with the accuracy necessary for use in construction and building maintenance.</p> <p>Based on potential customer and end-user feedback collected during the course of the project, Near Earth Autonomy identified the key technical and market developments needed for a commercial product: model photorealism and accuracy and ease of use and deployment. A third-generation prototype addressing these needs will be designed and built as the project progresses.</p><br> <p>            Last Modified: 09/03/2015<br>      Modified by: Sanjiv&nbsp;Singh</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Various industries have a need for tools that create photorealistic, three-dimensional (3D) models of real world scenes. Architects and engineers use such models to create as-built plans and for maintenance purposes; mining and construction companies use them to calculate how much soil must be moved to reach a vein or build a highway; police and fire investigators use them for forensics purposes; and insurance companies, for processing claims. These are but a few examples of the utility of such tools. Existing alternatives are expensive to own and slow to operate. Furthermore, existing workflows involve data collection followed by off-site post-processing to build the model. Only then do users determine whether sufficient data has been collected or whether it is necessary to revisit the site, which is often costly or sometimes impossible.  In this project, Near Earth Autonomy developed a fast, low-cost, accurate scene modeling system to meet the needs of the industries listed above and others. The system can be hand-carried or mounted on vehicles, including ground-based or aerial, manned or unmanned. During data collection the system builds the model in real-time and presents it to the operator, allowing him to validate the data live before leaving the site. The system includes state-of-the-art software created by Near Earth to combine range data from a laser rangefinder, images from a camera, and inertial data from an inertial measurement unit to create self-consistent 3D models. Two prototype scene modeling systems were built and used to map large regions and multi-story buildings, with the accuracy necessary for use in construction and building maintenance.  Based on potential customer and end-user feedback collected during the course of the project, Near Earth Autonomy identified the key technical and market developments needed for a commercial product: model photorealism and accuracy and ease of use and deployment. A third-generation prototype addressing these needs will be designed and built as the project progresses.       Last Modified: 09/03/2015       Submitted by: Sanjiv Singh]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
