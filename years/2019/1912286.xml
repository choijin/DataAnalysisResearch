<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRCNS Research Proposal: Understanding Cortical Networks Related to Speech Using Deep Learning on ECOG Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>832574.00</AwardTotalIntnAmount>
<AwardAmount>848574</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Despite significant advances in neural science, the dynamics by which neural activity propagates across cortex while we think of a word and produce it remains poorly understood. This proposal will develop novel, data-driven approaches for understanding functions and interactions of various brain regions by leveraging rare neural recordings obtained with electrocorticography (ECoG) sensors while neurosurgical patients participate in tasks involving language perception, semantic access and word production.  This project will produce a set of validated novel computational tools for estimating neural representations and their dynamics as well as elucidate the cortical networks subserving perception, semantic access, and production of speech. Although these tools will be developed for ECoG data, the proposed frameworks are applicable to other neural data modalities including fMRI and EEG, and thus have broad applications in neuroscience. The ability to robustly translate between speech and its neural representations is vital to the development of speech prosthetics, which would allow patients with degenerative conditions (Amyotrophic Lateral Sclerosis) or neurological damage (locked-in syndrome) to drive a speech synthesizer via control from intact cortical structures. The network connectivity tools could shed light on the propagation dynamics of epileptic seizures as well as on how cortical communication, when impaired, gives rise to language aphasias and disconnection syndromes. Furthermore, the decoding and network connectivity tools could help develop novel language mapping approaches for brain surgery without the associated risks of electrical stimulation mapping.&lt;br/&gt;&lt;br/&gt;The project consists of three core thrusts: developing neural decoders for language processing, developing directed connectivity models, and experimental validation. The neural decoders will be based on deep-learning architectures able to learn a transformation between neural signals and the speech heard by the patient, the speech produced by the patient, or the semantic concept represented by the stimulus word. The connectivity models will generalize and coalesce current approaches for estimating the task-dependent, time-varying directed connectivity between cortical regions. Lastly, these findings will be experimentally validated via clinical electrical stimulation data and cortico-cortico evoked potential (CCEP) stimulation experiments. Current modeling approaches of ECoG data have mostly focused on variants of linear models and on speech acoustics. This project will harness the potential of highly non-linear and deep networks for modeling neural responses to both speech acoustics and access to semantics. Additionally, tools for inferring direct connectivity and interactions among neural regions will provide a detailed characterization of the network dynamics, which is largely overlooked by most ECoG decoding studies.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/31/2019</MinAmdLetterDate>
<MaxAmdLetterDate>04/09/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1912286</AwardID>
<Investigator>
<FirstName>Yao</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yao Wang</PI_FULL_NAME>
<EmailAddress>yw523@nyu.edu</EmailAddress>
<PI_PHON>6469973469</PI_PHON>
<NSF_ID>000467592</NSF_ID>
<StartDate>08/31/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Adeen</FirstName>
<LastName>Flinker</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adeen Flinker</PI_FULL_NAME>
<EmailAddress>Adeen.Flinker@nyumc.org</EmailAddress>
<PI_PHON/>
<NSF_ID>000770084</NSF_ID>
<StartDate>08/31/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<CountyName>NEW YORK</CountyName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName>Brooklyn</CityName>
<CountyName>KINGS</CountyName>
<StateCode>NY</StateCode>
<ZipCode>112013848</ZipCode>
<StreetAddress><![CDATA[2 Metrotech Center]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7327</Code>
<Text>CRCNS-Computation Neuroscience</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramElement>
<Code>7564</Code>
<Text>CCSS-Comms Circuits &amp; Sens Sys</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7327</Code>
<Text>CRCNS</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~832574</FUND_OBLG>
<FUND_OBLG>2020~16000</FUND_OBLG>
</Award>
</rootTag>
