<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Large Workspace Haptic Interaction for Mixed Reality Locomotion Interfaces</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>499998.00</AwardTotalIntnAmount>
<AwardAmount>531998</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
<PO_EMAI>bprabhak@nsf.gov</PO_EMAI>
<PO_PHON>7032924847</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Walking to a door, turning the door knob, and turning the door to get into a room is a natural motion for us. How do we study this motion in a mixed/virtual reality (VR) environment? The goal of this research is to develop a better understanding of how people interact with important objects from daily living, and then use this knowledge to design a VR system and a set of haptic devices, enabling people to experience these interactions in a simulated environment. Studies with human subjects will be used to establish a library of the objects, describing how the objects should physically respond to user interaction. Based on these studies, a set of haptic devices will be designed to simulate interactions with real-world objects (such as a door knob), i.e., the haptic devices will behave like robots offering force feedback when users operate them. The proposed VR system provides 3D stereo images of the objects by projecting on the walls and floor of the virtual environment, a treadmill with a harness and tethers to simulate walking, and the haptic devices to simulate the interactions with the real-world objects. Users can walk up to these objects in the virtual world, grasp handles or knobs on the end of the haptic devices that are merged with their graphical representation, and then operate the objects as they continue to walk through the virtual world.  Some activities will be combined for two-handed operation. The haptic devices and the VR system will allow the user to interact with objects over a large area near the treadmill.  Human subject studies will evaluate the effectiveness of the system to imitate the different objects and to improve the user's sense of being in the environment.  These activities lay a foundation for using VR for training first responders, providing therapists with new tools for treating health problems such as Parkinson's Disease or stroke, and for creating new entertainment technology. This research project contributes newly designed haptic devices, VR models, and control algorithms comprising a large workspace haptic environment. &lt;br/&gt;&lt;br/&gt;To accomplish the above objectives, this project will target the design, control, and integration of a large workspace haptic devices with VR locomotion interfaces, such as the TreadPort that allow users to navigate different environments with varied terrain and environmental conditions. The research will investigate practical activities where large workspace haptic interaction is important. Examples of such activities include pushing a cart; carrying and or pulling a suitcase or briefcase; opening, closing, and walking through a door; operating a wheelbarrow; and using a cane. A library of models combining kinematics, statics, and dynamics will be constructed and validated by human subject studies on physical mockups. The results of these human subject studies will then be used to design the haptic interfaces, focusing on providing a range of motion and haptic feedback to realistically render tasks using the hands and arms. The proposed haptic interface consists of large planar manipulators oriented in the horizontal plane near hand level, providing gross motion while avoiding problems with gravity compensation. Specialized hand end-effector interfaces would allow the user's hands to interact with physical interfaces and provide more dexterous motion. Mobile bases will allow the planar manipulators to reposition to accommodate user motion and large workspace haptic display. Given the large workspace nature of this problem, new algorithms will be developed for planning the motion of a haptic device for effectively displaying these features, and for correlating this motion to control the effective impedance exhibited by the haptic device to create stable and realistic physical human interaction with the virtual world. Research will also address coordination and control of the manipulators, treadmill, and torso feedback systems to provide manipulation of the simulated features displayed in the virtual world. Human subject studies will evaluate both the effectiveness of the system to realistically display large scale haptic interactions as well as the immersion quality. These study results will provide a basis for others striving to apply such research in the development of new therapies. The library of physical interactions and challenging scenarios created by this research will provide tools for researchers developing therapies related to aging and degenerative diseases, such as Parkinson's Disease; demonstrate new tools for training; and illustrate potential activities in entertainment.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/31/2019</MinAmdLetterDate>
<MaxAmdLetterDate>05/10/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1911194</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Hollerbach</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John M Hollerbach</PI_FULL_NAME>
<EmailAddress>jmh@cs.utah.edu</EmailAddress>
<PI_PHON>8015856978</PI_PHON>
<NSF_ID>000326004</NSF_ID>
<StartDate>08/31/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Minor</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark Minor</PI_FULL_NAME>
<EmailAddress>mark.minor@utah.edu</EmailAddress>
<PI_PHON>8015877771</PI_PHON>
<NSF_ID>000328014</NSF_ID>
<StartDate>08/31/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<CountyName/>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<StreetAddress2><![CDATA[Second Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>UT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009095365</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF UTAH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009095365</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Utah]]></Name>
<CityName/>
<CountyName/>
<StateCode>UT</StateCode>
<ZipCode>841128930</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>UT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~499998</FUND_OBLG>
<FUND_OBLG>2020~16000</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
</Award>
</rootTag>
