<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Perspective-taking in Conversation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>386349.00</AwardTotalIntnAmount>
<AwardAmount>386349</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Current theories of language use assume that by sharing ideas in conversation, people develop shared knowledge. This assumption, however, is largely untested and there is good reason to think that it is wrong. The investigator's preliminary studies asked a basic question with fundamental implications:  Do speakers and listeners each walk away from a conversation with the same idea about what was said? The answer is no. Speakers are much more likely to remember what was said than the person who was listening. The proposed work takes as a starting point these asymmetries in memory for conversations in order to generate novel predictions regarding the interplay between memory and language use in conversation. Anticipated findings will provide insight into when conversational partners are likely to have similar memories for what was said, and when their memories are likely to differ. The resulting discoveries could change basic recommendations for how to engage in a successful conversation, both in high stakes settings (business negotiations, dispute mediation, first dates), but also in day-to-day life. The findings may also guide expectations about what humans are likely to remember based on conversations with devices such as "Alexa," in turn providing insights for device design and human-technology interactions. Potential implications for pedagogy include recommendations for improving communication in teacher-student interactions and in group projects. &lt;br/&gt;&lt;br/&gt;This proposal develops and tests the predictions of a theoretical view of shared conversational knowledge that offers a radical departure from current views and makes competing predictions. A series of 10 experiments tests the hypothesis that following conversation, partners will retain predictably different memories of the conversation. As a result, despite their shared experience of conversing, partners will have a different perspective on what was said, influencing future decisions and interactions in predictable ways. The work will also provide insights into mechanisms of language processing in ecologically valid settings. Broader impacts include  opportunities for graduate students, undergraduate students, and high school students to conduct independent research projects. Special efforts are made to recruit students from under-represented groups. All de-identified data generated by this research will be made publicly available on the internet. In sum, the work has the potential to advance understanding of psychological and linguistic processes, advance computer dialog systems, and offer insights into pedagogical research.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/25/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/25/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1921492</AwardID>
<Investigator>
<FirstName>Sarah</FirstName>
<LastName>Brown-Schmidt</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sarah Brown-Schmidt</PI_FULL_NAME>
<EmailAddress>sarahbrownschmidt@gmail.com</EmailAddress>
<PI_PHON>6153434476</PI_PHON>
<NSF_ID>000554827</NSF_ID>
<StartDate>07/25/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Vanderbilt University</Name>
<CityName>Nashville</CityName>
<ZipCode>372350002</ZipCode>
<PhoneNumber>6153222631</PhoneNumber>
<StreetAddress>Sponsored Programs Administratio</StreetAddress>
<StreetAddress2><![CDATA[PMB 407749 2301 Vanderbilt Place]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<StateCode>TN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>965717143</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VANDERBILT UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004413456</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Vanderbilt University]]></Name>
<CityName>Nashville</CityName>
<StateCode>TN</StateCode>
<ZipCode>372032417</ZipCode>
<StreetAddress><![CDATA[110 21st Avenue South, Suite 800]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Tennessee</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>081Y</Code>
<Text>NSF 2026 Fund</Text>
</ProgramElement>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~386349</FUND_OBLG>
</Award>
</rootTag>
