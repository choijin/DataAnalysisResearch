<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: INT: A New Paradigm for Geometric Reasoning through Structure from Category</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>473699.00</AwardTotalIntnAmount>
<AwardAmount>473699</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The task of a robot determining the 3D shape and pose of an object is critical to the advancement of generally deployed collaborative robotics. Current artificial intelligence (AI) still struggles with such tasks. Until now the problem of inferring an object's 3D pose and shape (i.e., geometric reasoning) through AI has largely been treated as a 3D supervised learning problem. That is, the AI is given 2D images with corresponding 3D labels to learn. These 3D labels are costly and error prone to obtain at a large scale, acting as an intrinsic barrier to the advancement of geometric reasoning within robotics. In this project, the research team advocates a new paradigm for geometric reasoning that requires no 3D supervision - using a mathematical framework called "structure from category". Success will result in autonomous systems such as vehicles, robots, and drones with dramatically enhanced perception and planning abilities to navigate their way in 3D world. &lt;br/&gt;&lt;br/&gt;Deep neural networks (DNNs) - the heart of most AI systems in robotics - are currently used like black boxes. It is hard to instill them explicitly with real-world knowledge; instead they learn implicitly through labelled examples. This becomes a problem when such examples are not available in abundance. This research aims to shift this paradigm for AI from an opaque black-box to a transparent "glass-box", to facilitate the principled inclusion of explicit constraints and priors such as geometry. In this project, the research team has a novel way around this impasse, by reinterpreting the nonlinearities within a DNN as hierarchical sparsity constraints. Using this approach, the research team advocates for a method of inferring 3D shape and pose solely from 2D labels, dramatically improving the ability of modern DNNs to perform effective geometric reasoning at scale across large amounts of data.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/30/2019</MinAmdLetterDate>
<MaxAmdLetterDate>12/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1925281</AwardID>
<Investigator>
<FirstName>Simon</FirstName>
<LastName>Lucey</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Simon M Lucey</PI_FULL_NAME>
<EmailAddress>slucey@cs.cmu.edu</EmailAddress>
<PI_PHON>4122682889</PI_PHON>
<NSF_ID>000217779</NSF_ID>
<StartDate>08/30/2019</StartDate>
<EndDate>12/14/2020</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Laszlo</FirstName>
<LastName>Jeni</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Laszlo A Jeni</PI_FULL_NAME>
<EmailAddress>laszlojeni@cmu.edu</EmailAddress>
<PI_PHON>4122684461</PI_PHON>
<NSF_ID>000831563</NSF_ID>
<StartDate>12/14/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~473699</FUND_OBLG>
</Award>
</rootTag>
