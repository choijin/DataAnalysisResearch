<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Learning Language in Simulation for Real Robot Interaction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>12/01/2019</AwardEffectiveDate>
<AwardExpirationDate>11/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>219516.00</AwardTotalIntnAmount>
<AwardAmount>219516</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>While robots are rapidly becoming more capable and ubiquitous, their&lt;br/&gt;utility is still severely limited by the inability of regular users to&lt;br/&gt;customize their behaviors. This EArly Grant for Exploratory Research (EAGER) &lt;br/&gt;will explore how examples of language, gaze, and other communications can be collected from a&lt;br/&gt;virtual interaction with a robot in order to learn how robots can&lt;br/&gt;interact better with end users. Current robots' difficulty of use and&lt;br/&gt;inflexibility are major factors preventing them from being more&lt;br/&gt;broadly available to populations that might benefit, such as&lt;br/&gt;aging-in-place seniors. One promising solution is to let users control&lt;br/&gt;and teach robots with natural language, an intuitive and comfortable&lt;br/&gt;mechanism. This has led to active research in the area of grounded&lt;br/&gt;language acquisition: learning language that refers to and is informed&lt;br/&gt;by the physical world. Given the complexity of robotic systems, there&lt;br/&gt;is growing interest in approaches that take advantage of the latest in&lt;br/&gt;virtual reality technology, which can lower the barrier of entry to&lt;br/&gt;this research.&lt;br/&gt;&lt;br/&gt;This EAGER project develops infrastructure that will lay the necessary&lt;br/&gt;groundwork for applying simulation-to-reality approaches to natural&lt;br/&gt;language interactions with robots. This project aims to bootstrap&lt;br/&gt;robots' learning to understand language, using a combination of data&lt;br/&gt;collected in a high-fidelity virtual reality environment with&lt;br/&gt;simulated robots and real-world testing on physical robots. A person&lt;br/&gt;will interact with simulated robots in virtual reality, and his or her&lt;br/&gt;actions and language will be recorded. By integrating with existing&lt;br/&gt;robotics technology, this project will model the connection between&lt;br/&gt;the language people use and the robot's perceptions and actions.&lt;br/&gt;Natural language descriptions of what is happening in simulation will&lt;br/&gt;be obtained and used to train a joint model of language and simulated&lt;br/&gt;percepts as a way to learn grounded language. The effectiveness of the&lt;br/&gt;framework and algorithms will be measured on automatic&lt;br/&gt;prediction/generation tasks and transferability of learned models to a&lt;br/&gt;real, physical robot. This work will serve as a proof of concept for&lt;br/&gt;the value of combining robotics simulation with human interaction, as&lt;br/&gt;well as providing interested researchers with resources to bootstrap&lt;br/&gt;their own work.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/15/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/15/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1940931</AwardID>
<Investigator>
<FirstName>Donald</FirstName>
<LastName>Engel</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Donald Engel</PI_FULL_NAME>
<EmailAddress>donengel@umbc.edu</EmailAddress>
<PI_PHON>4104552837</PI_PHON>
<NSF_ID>000668900</NSF_ID>
<StartDate>08/15/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Cynthia</FirstName>
<LastName>Matuszek</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Cynthia Matuszek</PI_FULL_NAME>
<EmailAddress>cmat@umbc.edu</EmailAddress>
<PI_PHON>5125774025</PI_PHON>
<NSF_ID>000690099</NSF_ID>
<StartDate>08/15/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Francis</FirstName>
<LastName>Ferraro</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Francis Ferraro</PI_FULL_NAME>
<EmailAddress>ferraro@umbc.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000763127</NSF_ID>
<StartDate>08/15/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maryland Baltimore County</Name>
<CityName>Baltimore</CityName>
<ZipCode>212500002</ZipCode>
<PhoneNumber>4104553140</PhoneNumber>
<StreetAddress>1000 Hilltop Circle</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>061364808</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MARYLAND BALTIMORE COUNTY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>003256088</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Maryland, Baltimore County]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212500002</ZipCode>
<StreetAddress><![CDATA[1000 Hilltop Circle]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~219516</FUND_OBLG>
</Award>
</rootTag>
