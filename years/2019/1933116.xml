<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RAPID: Influence on Beliefs in Non-Scientific Theories</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>38250.00</AwardTotalIntnAmount>
<AwardAmount>38250</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Brian Humes</SignBlockName>
<PO_EMAI>bhumes@nsf.gov</PO_EMAI>
<PO_PHON>7032927284</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Contrary to the popular negative depictions, public endorsement of non-scientific theories are not solely the domain of extremists and paranoids. A large proportion of the public will admit to believing in at least one matter that most in the scientific community disparage. To an outside observer, a particular theory may seem irrational, but that does not preclude its potential to be socially or politically consequential. As a result, it is vital to understand where these attitudes come from in order to develop strategies to minimize their spread. A problem researchers face, however, is that many non-scientific views have already become politicized before surveys assessing respondents' beliefs in them are fielded. Moreover, it is impossible for researchers to anticipate the rare situations in which elites unambiguously endorse a "theory" that most scientists would not endorse. As such, it is difficult to disentangle the causal effects of elite cues, partisanship, and the like. The current research will re-interview a set of survey respondents (previously interviewed in 2017) and a set of new respondents to gauge how their attitudes about a theory not supported by scientists has changed in the last two years (before and after the non-scientific perspective became promoted by elites). This research will enable the PIs to test over time changes in support for a non-scientific views. Given the importance and prominence, along with the disruption, possibly caused by public acceptance of non-scientific views, the knowledge gained in this research will enable efforts to mitigate the effects of non-scientific views. &lt;br/&gt;&lt;br/&gt;In this proposal, we empirically test how an individual's support of a non-scientific view changes over time. We will re-interview a set of previously interviewed survey respondents to leverage changes since 2017. Additionally, we will survey a set of new respondents and randomize the information about the view they receive. The combination of these designs will enable us to test several theoretically motivated hypotheses about how the intersection of a person's predispositions and the information environment create support for non-scientific views and how these views may become politicized.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/26/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/26/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1933116</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Peterson</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David A Peterson</PI_FULL_NAME>
<EmailAddress>daveamp@iastate.edu</EmailAddress>
<PI_PHON>5155096345</PI_PHON>
<NSF_ID>000429671</NSF_ID>
<StartDate>08/26/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Joanne</FirstName>
<LastName>Miller</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joanne M Miller</PI_FULL_NAME>
<EmailAddress>jomiller@udel.edu</EmailAddress>
<PI_PHON>3028311463</PI_PHON>
<NSF_ID>000158122</NSF_ID>
<StartDate>08/26/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Iowa State University</Name>
<CityName>AMES</CityName>
<ZipCode>500112207</ZipCode>
<PhoneNumber>5152945225</PhoneNumber>
<StreetAddress>1138 Pearson</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<StateCode>IA</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IA04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>005309844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>IOWA STATE UNIVERSITY OF SCIENCE AND TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>005309844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Iowa State University]]></Name>
<CityName/>
<StateCode>IA</StateCode>
<ZipCode>500112011</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Iowa</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IA04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1371</Code>
<Text>Political Science</Text>
</ProgramElement>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~38250</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In this research, we were interested in studying whether political leaders&rsquo; endorsement of misinformation leads people in the general public to be more likely to&nbsp; believe the misinformation. We were also interested in studying whether people will &ldquo;un-believe&rdquo; misinformation if a political leader who originally endorsed the misinformation later makes statements that contradict the misinformation. In an age when social media gives political leaders direct, unmediated, access to the public, and information of all types can spread like wildfire, it is important to understand the causes of belief <em>and</em> disbelief in misinformation. We studied these questions using two statements. In April, 2019, a statement was made that: &ldquo;they say that the noise from wind turbines causes cancer,&rdquo; perpetuating misinformation about the health effects of wind turbines. Also in April, the following statement countering misinformation that vaccines cause autism was made that &ldquo;the measles vaccine is so important.&rdquo; We conducted two studies to assess the impact of these two statements on individuals&rsquo; beliefs that wind turbines cause cancer and that vaccines are dangerous.</p> <p>In the first study (conducted in August, 2019), we re-contacted adults who were asked about their belief that wind turbines cause cancer in 2017 &ndash; long before the wind turbine statement. We reminded them of the statement about wind turbines causing cancer, and we asked them a series of questions about wind turbines, including whether they believed that wind turbines cause cancer. We compared their wind turbine attitudes in 2017 to their wind turbine attitudes in 2019, and found that wind turbine attitudes did not change as a result of the wind turbine statement. However, we suspected that this result was partly due to the fact that we were only able to re-contact a small number of people who completed the original 2017 survey.</p> <p>To further explore the impact of statements endorsing (and disavowing) misinformation, we conducted a second survey of a representative sample of U.S. adults in September, 2019. In this study, we randomly assigned 1/3 of the survey participants to read the wind turbine statement (&ldquo;they say that the noise from wind turbines causes cancer&rdquo;). We randomly assigned another 1/3 of the survey participants to read the vaccine statement (&ldquo;the measles vaccine is so important&rdquo;). And we randomly assigned the last 1/3 of the participants to read neither statement. Next, we assessed their attitudes about the safety of wind turbines and about the safety of vaccines. We also measured their partisanship. We were interested in whether the statements would affect Republicans&rsquo; and Democrats&rsquo; attitudes differently. &nbsp;Republicans who read the statement that perpetuated misinformation about wind turbines were <em>more</em> likely to believe the misinformation that wind turbines cause cancer than Republicans who did not read the wind turbines statement. In contrast, Republicans who read the statement that the measles vaccine is important were <em>less</em> likely to believe that vaccines are dangerous than Republicans who did not read the statement. Democrats&rsquo; wind turbine attitudes did not differ depending on whether they read the wind turbine statement or not (indicating that the statement did not impact their beliefs about wind turbines). Unexpectedly, Democrats who read the pro-vaccine statement were <em>more</em> likely to believe that vaccines were dangerous than those who did not read his statement, but this finding did not replicate in another study we conducted, so we suspect it is a statistical anomaly.</p> <p>The most important finding from this research that has implications for the study of belief in misinformation is that the effect of a statement perpetuating misinformation had a bigger effect on Republicans&rsquo; <em>belief</em> in misinformation than a statement correcting misinformation had on their <em>disbelief</em> in misinformation. In other words, it is easier to &ldquo;turn on&rdquo; misinformation than it is to &ldquo;turn off&rdquo; misinformation. We suspect that this asymmetry would also appear for Democrats in response to a statements perpetuating/disavowing misinformation that Democrats are more likely to believe to begin with, but we did not have the ability to test that hypothesis. These findings have broader impacts for our understanding of how difficult it is to correct misinformation once it is out there, and suggest that future research should focus more on how to inoculate people from believing misinformation in the first place.</p><br> <p>            Last Modified: 01/04/2021<br>      Modified by: Joanne&nbsp;M&nbsp;Miller</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In this research, we were interested in studying whether political leaders’ endorsement of misinformation leads people in the general public to be more likely to  believe the misinformation. We were also interested in studying whether people will "un-believe" misinformation if a political leader who originally endorsed the misinformation later makes statements that contradict the misinformation. In an age when social media gives political leaders direct, unmediated, access to the public, and information of all types can spread like wildfire, it is important to understand the causes of belief and disbelief in misinformation. We studied these questions using two statements. In April, 2019, a statement was made that: "they say that the noise from wind turbines causes cancer," perpetuating misinformation about the health effects of wind turbines. Also in April, the following statement countering misinformation that vaccines cause autism was made that "the measles vaccine is so important." We conducted two studies to assess the impact of these two statements on individuals’ beliefs that wind turbines cause cancer and that vaccines are dangerous.  In the first study (conducted in August, 2019), we re-contacted adults who were asked about their belief that wind turbines cause cancer in 2017 &ndash; long before the wind turbine statement. We reminded them of the statement about wind turbines causing cancer, and we asked them a series of questions about wind turbines, including whether they believed that wind turbines cause cancer. We compared their wind turbine attitudes in 2017 to their wind turbine attitudes in 2019, and found that wind turbine attitudes did not change as a result of the wind turbine statement. However, we suspected that this result was partly due to the fact that we were only able to re-contact a small number of people who completed the original 2017 survey.  To further explore the impact of statements endorsing (and disavowing) misinformation, we conducted a second survey of a representative sample of U.S. adults in September, 2019. In this study, we randomly assigned 1/3 of the survey participants to read the wind turbine statement ("they say that the noise from wind turbines causes cancer"). We randomly assigned another 1/3 of the survey participants to read the vaccine statement ("the measles vaccine is so important"). And we randomly assigned the last 1/3 of the participants to read neither statement. Next, we assessed their attitudes about the safety of wind turbines and about the safety of vaccines. We also measured their partisanship. We were interested in whether the statements would affect Republicans’ and Democrats’ attitudes differently.  Republicans who read the statement that perpetuated misinformation about wind turbines were more likely to believe the misinformation that wind turbines cause cancer than Republicans who did not read the wind turbines statement. In contrast, Republicans who read the statement that the measles vaccine is important were less likely to believe that vaccines are dangerous than Republicans who did not read the statement. Democrats’ wind turbine attitudes did not differ depending on whether they read the wind turbine statement or not (indicating that the statement did not impact their beliefs about wind turbines). Unexpectedly, Democrats who read the pro-vaccine statement were more likely to believe that vaccines were dangerous than those who did not read his statement, but this finding did not replicate in another study we conducted, so we suspect it is a statistical anomaly.  The most important finding from this research that has implications for the study of belief in misinformation is that the effect of a statement perpetuating misinformation had a bigger effect on Republicans’ belief in misinformation than a statement correcting misinformation had on their disbelief in misinformation. In other words, it is easier to "turn on" misinformation than it is to "turn off" misinformation. We suspect that this asymmetry would also appear for Democrats in response to a statements perpetuating/disavowing misinformation that Democrats are more likely to believe to begin with, but we did not have the ability to test that hypothesis. These findings have broader impacts for our understanding of how difficult it is to correct misinformation once it is out there, and suggest that future research should focus more on how to inoculate people from believing misinformation in the first place.       Last Modified: 01/04/2021       Submitted by: Joanne M Miller]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
