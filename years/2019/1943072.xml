<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Toward Proactive Assistive Robotics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2020</AwardEffectiveDate>
<AwardExpirationDate>03/31/2025</AwardExpirationDate>
<AwardTotalIntnAmount>549780.00</AwardTotalIntnAmount>
<AwardAmount>193588</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Assistive robots have the potential to increase human efficiency and quality of life in many ways, such as enabling people with severe motor impairments to independently complete activities of daily living (ADLs). However, most robots designed for assistive human-robot interaction (HRI) are reactive, either providing "always on" assistance or responding only to explicit requests, rather than proactively taking initiative to help with their partner's goal. The next major advance in HRI will involve robots that are able to proactively anticipate and respond to people's needs, just as an experienced caregiver does. To do this, robots must observe and reason about potentially subtle cues of context and human behavior. For example, what someone is looking at can reveal their next action or indicate that they need help with a task. This project investigates how human behavior and context reveal task-relevant mental states, and then develops assistive robots that provide support to people in a variety of everyday situations. In the process of doing the research, this project will also make an educational impact by developing HRI courses and texts that use assistive robotics as an example of effective HRI.&lt;br/&gt;&lt;br/&gt;This project will first investigate how human eye gaze can reveal when and how people need assistance in activities of daily living like food preparation and eating. Assistance algorithms will then be developed that monitor eye gaze and proactively respond with robot actions. These algorithms will be evaluated in studies with users who have upper motor impairments and could benefit from the new technology. To these ends, the project contributes: (1) Computational models that use a human's eye gaze and task context to predict task-relevant human mental states such as the target of the current action, the next action to be selected, and whether someone is having difficulty with the task; (2) algorithms that apply mental state models to enable proactive robot assistance in co-manipulation, providing the right type of assistance at the right time; (3) an evaluation of proactive robot assistance algorithms in real-world contexts with users who have motor impairments; (4) a novel ontology of robot assistance types, starting with initial definitions of first- and second-order assistance and expanding outward through literature surveys and interviews; and (5) an extension of shared autonomy algorithms from single-step tasks to multi-step tasks, with a particular focus on ADLs.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/01/2020</MinAmdLetterDate>
<MaxAmdLetterDate>05/18/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1943072</AwardID>
<Investigator>
<FirstName>Henny</FirstName>
<LastName>Admoni</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Henny Admoni</PI_FULL_NAME>
<EmailAddress>hadmoni@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122689527</PI_PHON>
<NSF_ID>000754294</NSF_ID>
<StartDate>04/01/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~69530</FUND_OBLG>
<FUND_OBLG>2021~124058</FUND_OBLG>
</Award>
</rootTag>
