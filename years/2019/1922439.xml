<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NCS-FO:  The Neural Basis of Human Spatial Navigation in Large-Scale Virtual Spaces with Vestibular Input</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/30/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>504390.00</AwardTotalIntnAmount>
<AwardAmount>504390</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
<PO_EMAI>kwhang@nsf.gov</PO_EMAI>
<PO_PHON>7032925149</PO_PHON>
</ProgramOfficer>
<AbstractNarration>How do people learn large-scale spaces, like new towns and cities that they visit, as they navigate? Addressing this question poses surprising obstacles, such as the difficulty in optimizing large-scale spaces for experimental testing and controlling for pre-existing knowledge. Desktop virtual reality offers one possible way to address this question, although such testing offers an incomplete rendition of the full-body, immersive experience that is real-world navigation. Researchers will develop a 2-D treadmill coupled with a head-mounted display to allow free ambulation of large-scale virtual spaces. Successful development of this device has important societal applications. For example, pre-training with enriched body-based cues has the potential to increase knowledge transfer to real world environments, which could be helpful for training individuals such as first-responders and navigation in wilderness environments. Also, the device and proposed experiments will provide a completely novel understanding of the neural basis of human spatial navigation with body-based cues, fundamental to accurately modeling spatial cognition and understanding why we often get lost when we visit new cities.&lt;br/&gt;&lt;br/&gt;Almost all theories of the neural basis of spatial navigation, largely developed in freely navigating rodents, assume the critical importance of importance of body-based cues to this code. Yet the vast majority of studies in humans involve navigation in desktop virtual reality. The novel device that will be developed will permit 2-D locomotion-based VR navigation, allowing a full range of body/head rotations and ambulation. The experiments will determine 1) the contributions of body-based input to human spatial navigation and how navigation in VR with body-based can enhance subsequent knowledge of real world environments 2) how the brain codes spatial distance by employing simultaneous EEG recordings 3) how the brain codes the relative directions of landmarks in the environment by modeling the underlying multidimensional brain networks using high-resolution functional magnetic imaging (fMRI). The outcomes from these experiments will be important to testing models of spatial navigation and advancing our understanding of the extent to which we employ visual vs. body-based cues to represent spatial environments, currently an issue of significant debate in the field.</AbstractNarration>
<MinAmdLetterDate>02/06/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/06/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1922439</AwardID>
<Investigator>
<FirstName>Arne</FirstName>
<LastName>Ekstrom</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arne Ekstrom</PI_FULL_NAME>
<EmailAddress>adekstrom@email.arizona.edu</EmailAddress>
<PI_PHON>5206214594</PI_PHON>
<NSF_ID>000628782</NSF_ID>
<StartDate>02/06/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Arizona</Name>
<CityName>Tucson</CityName>
<ZipCode>857194824</ZipCode>
<PhoneNumber>5206266000</PhoneNumber>
<StreetAddress>888 N Euclid Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>806345617</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ARIZONA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072459266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Arizona]]></Name>
<CityName>Tucson</CityName>
<StateCode>AZ</StateCode>
<ZipCode>857194824</ZipCode>
<StreetAddress><![CDATA[888 N Euclid Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>8551</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0416</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~504389</FUND_OBLG>
</Award>
</rootTag>
