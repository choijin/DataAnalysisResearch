<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Appearance Modeling by Synthesis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>499931.00</AwardTotalIntnAmount>
<AwardAmount>499931</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Appearance modeling aims to create digital representations of materials, ranging from imaginary materials drawn by artists to reproductions of physical materials.  To date, the most successful methods for creating realistic digital materials have been data-driven, where data captured from a physical material sample is used to reconstruct a digital representation. Most prior work assumes that the measurements fully constrain the reconstruction process.  This project will explore a new paradigm that views appearance modeling as a constrained synthesis process instead of a reconstruction / interpolation process.  This change in paradigm requires a rethinking of fundamental appearance modeling assumptions.  First, constrained synthesis produces a distribution of possible solutions rather than a single most likely solution as in classic appearance modeling methods. This creates opportunities for users to participate in the appearance modeling process (for example, by selecting the "best"' solution according to subjective or artistic criteria).  Furthermore, instead of building up a solution with additional appearance measurements, constrained synthesis reduces the solution distribution with each additional measurement; that is to say, it promotes a subtractive approach to appearance modeling.  A constrained synthesis approach to appearance modeling also offers an elegant and scalable solution to reproducing a material's appearance from insufficient or incomplete data. This research builds on methods from computer vision and machine learning, and has the potential to advance the state-of-the-art in both fields. More broadly, the reconstruction and synthesis methods developed will be applicable to fields that model high dimensional data and for which it is difficult to obtain samples.  The results from the proposed research activities will be incorporated in new and existing courses, recruitment activities at the graduate and undergraduate level, and outreach activities promoting STEM to minorities.&lt;br/&gt;&lt;br/&gt;This project will advance constrained synthesis as a new paradigm for appearance modeling through three research thrusts that explore generative adversarial networks (GANs) for: (1) unconstrained material generators, (2) constrained material generators, and (3) empowering users to author new material generators.  In each of these research thrusts, the concept of a (potentially non-linear) projection that provides a mapping from the high dimensional target distribution to one or more lower-dimensional source distributions plays a central role.  Associating a discriminator with each projection yields novel GAN architectures that decouple the spaces of the training data, conditions, and the target distribution.  Building on the concept of projections and the resulting decoupling of distribution spaces, each of the three research thrusts endeavors to contribute to a different subfield in appearance modeling: (1) synthesizing novel instances of spatially varying materials, (2) reconstructing a material from a variable number of observations or from incomplete measurements, and (3) designing novel material generators by restricting the output of a general material generator based on user preferences.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/03/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/09/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1909028</AwardID>
<Investigator>
<FirstName>Pieter</FirstName>
<LastName>Peers</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pieter Peers</PI_FULL_NAME>
<EmailAddress>ppeers@cs.wm.edu</EmailAddress>
<PI_PHON>7572213466</PI_PHON>
<NSF_ID>000554726</NSF_ID>
<StartDate>09/03/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>College of William and Mary</Name>
<CityName>Williamsburg</CityName>
<ZipCode>231878795</ZipCode>
<PhoneNumber>7572213966</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 8795]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>074762238</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COLLEGE OF WILLIAM &amp; MARY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>074762238</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[College of William and Mary]]></Name>
<CityName/>
<StateCode>VA</StateCode>
<ZipCode>231878795</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~127470</FUND_OBLG>
<FUND_OBLG>2020~372461</FUND_OBLG>
</Award>
</rootTag>
