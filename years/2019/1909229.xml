<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: TICE - Telematic Immersive Classroom Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2020</AwardEffectiveDate>
<AwardExpirationDate>03/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Since their inception, telecommunication systems have targeted the exchange between exactly two people. This holds true for the telegraph, the telephone, and typical video conference systems. Meetings for larger groups of people are usually conducted using the same personal interfaces â€“ take, for example, a telephone conference call. This practice contrasts with a traditional group meeting, for example, or a classroom scenario. In the latter, students and teachers can communicate with each other while having an awareness of the spatial location of each participant and the ability to identify each speaker easily. The goal of this project is to develop technology that enables two distant classrooms to be joined by telecommunication devices without the need for personal communication interfaces. An electronically adjustable microphone array will be designed that can virtually focus on an active speaker. This way, echoes that would otherwise occur in a collaborative telecommunication scenario with loudspeakers will be avoided. The system will be designed such that the sounds of a speaker will emanate from the position at which they are seen on a live video feed. Project outcomes are expected to have broad impact by providing new educational opportunities for classroom students by virtually connecting them to other classrooms for collaborative learning experiences.  &lt;br/&gt; &lt;br/&gt;This project will develop a spatially correct, long-distance audio connection between collaborative spaces, for example two classrooms with groups of people at each site. The missing link needed to enable such remote collaboration is an audio tracking system that can follow all participants on both sides of the connection. The approach will use two 16-channel spherical microphones as the main audio tracking devices. The key idea is that each spherical microphone will receive continuous information from additional body-worn microphones, which is utilized to ensure echo-free bidirectional communication. The body-worn microphone signals will inform the tracking system who among the participants is speaking at a given time interval and in a given frequency range. The spherical microphone is then used to track each sound source during the time intervals that the source is active and in those frequency bands that are not disturbed by other sources. Using machine-learning tools, including Bayesian methods, Kalman filters, and Deep Neural Networks, the tracking system will implement a joint bottom-up/top-down architecture. Two existing sites are equipped with immersive loudspeaker systems, each of which will enable accurate local reproduction of spatialized audio from the remote site. These sites are also equipped with collaborative virtual reality systems with immersive video capabilities, and they will serve as laboratories for this project, enabling a system to transmit bidirectional audio/video streams with spatially congruent audio/video images. As an extensions of the project, the audio-tracking system will be paired with an existing 6-camera tracking system that is mounted on the laboratory ceiling and technologies will be developed to replace the body-worn microphones with virtual microphones using the beam-forming capabilities of a spherical microphone array.  In another extension, visual gestures of participants will be considered to further facilitate the telematic experience. An important component of this research will be the development of an affordable and deployable version of the collaborative virtual reality system that can be easily used in schools, for example as a ceiling-mounted system hosted in a school's gymnasium.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/01/2020</MinAmdLetterDate>
<MaxAmdLetterDate>04/01/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1909229</AwardID>
<Investigator>
<FirstName>Jonas</FirstName>
<LastName>Braasch</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jonas Braasch</PI_FULL_NAME>
<EmailAddress>braasj@rpi.edu</EmailAddress>
<PI_PHON>5182763864</PI_PHON>
<NSF_ID>000186127</NSF_ID>
<StartDate>04/01/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<CountyName/>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002430742</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RENSSELAER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002430742</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rensselaer Polytechnic Institute]]></Name>
<CityName/>
<CountyName/>
<StateCode>NY</StateCode>
<ZipCode>121103522</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~500000</FUND_OBLG>
</Award>
</rootTag>
