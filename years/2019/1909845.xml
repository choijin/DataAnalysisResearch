<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Manipulating Text in Screenless Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>499876.00</AwardTotalIntnAmount>
<AwardAmount>499876</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Keyboards on mobile devices display characters visually, and in so doing they present challenges for people who are blind as well as for all users in situations where it is inconvenient or unsafe to hold a phone in order to communicate. Existing approaches to mobile accessibility for eyes-free text entry do not fully solve this problem, because they remain screen-centric; manipulating text generally requires interacting with visual keypads that at most read aloud keys upon touching. A major unsolved challenge is how to manipulate text aurally and silently, in a way that unbinds users from a visual display. The goal of this project is to expand our understanding of text interaction from a screen-centric paradigm to screenless, aural environments. To this end, the work will establish and evaluate principles for aural text manipulation that do not rely on a reference screen but rather operate entirely over the auditory channel. This research is significant because it is expected to contribute novel strategies to augment the ability of over seven million blind people in the United States to perform text-entry by circumventing direct interaction with screen-based devices. By breaking free from the constraints of mobile visual displays, project outcomes will have broader applicability to support aural text manipulation for sighted users in situations where it is inconvenient or unsafe to stay glued to the screen while typing, or where text manipulation needs to be discreet, silent, and concealed from view. The project will directly engage people who are blind and visually impaired from three partner organizations in Indiana as well as students at Indiana University from underrepresented groups to co-create and evaluate new options to interact with text while bypassing the screen.&lt;br/&gt;&lt;br/&gt;The project will pursue two technical thrusts. The first thrust will identify strategies for the auditory arrangement of the character set that operate over time rather than within the visual-spatial constraints of the screen. The conceptual advances will be designed to work with current and future wearable input devices (hand/finger gestures supported by armband or smart rings) and will inform the foundation for a new class of auditory keyboards untethered to a visual display. The second thrust will focus on conducting iterative and comparative evaluation studies with sighted and blind participants on system prototypes of auditory keyboards, in order to examine how people can aurally manipulate text in screenless contexts.  By exploring and validating novel principles to re-imagine the concept of keyboard in the aural modality, the project will contribute to shifting the way people think about accessible typing in eyes-free scenarios and will play a fundamental role in the understanding of how people respond to screenless environments for text manipulation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/14/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/14/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1909845</AwardID>
<Investigator>
<FirstName>Davide</FirstName>
<LastName>Bolchini</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Davide Bolchini</PI_FULL_NAME>
<EmailAddress>dbolchin@iupui.edu</EmailAddress>
<PI_PHON>3172785144</PI_PHON>
<NSF_ID>000511635</NSF_ID>
<StartDate>08/14/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University Purdue Univ]]></Name>
<CityName>Indianapolis</CityName>
<StateCode>IN</StateCode>
<ZipCode>462023103</ZipCode>
<StreetAddress><![CDATA[535 W Michigan St., IT 475]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~499876</FUND_OBLG>
</Award>
</rootTag>
