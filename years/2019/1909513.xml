<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Collaborative Research: RUI: Scalable Decentralized Planning in Open Multiagent Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>205888.00</AwardTotalIntnAmount>
<AwardAmount>205888</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Roger Mailler</SignBlockName>
<PO_EMAI>rmailler@nsf.gov</PO_EMAI>
<PO_PHON>7032927982</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Automated planning is about finding a sequence of actions that is anticipated to successfully complete the task at hand or maximize earned rewards. Planning becomes difficult when the outcomes of actions are uncertain. It is further complicated in the presence of other agents whose actions also affect the environment and reward outcomes. While both these challenges have received much attention from researchers, real-world contexts often exhibit another property -- that of agent and task openness. Agent openness comes about when agents exit the environment, resume, or new agents enter, and task openness occurs when the tasks that agents must complete change with new tasks appearing and some disappearing.  Such openness complicates the planning process as agents now need to optimally consider, for example, the possibilities of existing teammates leaving the environment or a successfully rewarding task disappearing from the environment.  The research is systematically generalizing automated planning to consider these new and practical challenges while still keeping the methods computationally feasible. This research involves investigators at Oberlin College (a primarily undergraduate institution), Universities of Nebraska and Georgia collaborating closely to develop methods for planning in open multi-agent systems and demonstrating them in domains such as wildfire suppression, dynamic ridesharing, and others that exhibit openness. The principal investigators are using the outcomes of this research to inform their classroom instructions, and artificial intelligence camps for elementary and middle school students are planned at Oberlin.&lt;br/&gt;&lt;br/&gt;The technical approach involves gaining a fundamental understanding of the impact of agent and task openness on the environment, and utilizing this understanding to develop and learn stochastic models that represent the openness. These models are being used to build new algorithms for tractable agent-level planning in such contexts. The methods will exploit system-level properties such as agent anonymity and statistical population sampling that allows modeling large populations from small samples, which has been successful in the social sciences to make the approaches scalable to many agents. This research is advancing our understanding of how intelligent agents should perform scalable, decentralized planning in complex environments, and developing a framework--with empirical results and insights--that could lead to more robust intelligence for personal assistant agents for human-agent interactions, robots, and autonomous vehicles, where the agents reason about challenging environmental dynamics as the actors and their tasks change over time.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/19/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1909513</AwardID>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Eck</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam D Eck</PI_FULL_NAME>
<EmailAddress>aeck@oberlin.edu</EmailAddress>
<PI_PHON>4407758095</PI_PHON>
<NSF_ID>000790463</NSF_ID>
<StartDate>07/19/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Oberlin College</Name>
<CityName>Oberlin</CityName>
<ZipCode>440741090</ZipCode>
<PhoneNumber>4407758461</PhoneNumber>
<StreetAddress>70 N. Professor Street</StreetAddress>
<StreetAddress2><![CDATA[Room 100]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>068911908</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OBERLIN COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068911908</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Oberlin College]]></Name>
<CityName>Oberlin</CityName>
<StateCode>OH</StateCode>
<ZipCode>440741094</ZipCode>
<StreetAddress><![CDATA[10 N Professor Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~205888</FUND_OBLG>
</Award>
</rootTag>
