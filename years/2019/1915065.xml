<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SCH: INT: Collaborative Research: Detection, Assessment and Rehabilitation of Stroke-Induced Visual Neglect Using Augmented Reality (AR) and Electroencephalography (EEG)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>394163.00</AwardTotalIntnAmount>
<AwardAmount>394163</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
<PO_EMAI>wnilsen@nsf.gov</PO_EMAI>
<PO_PHON>7032922568</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Unilateral spatial neglect is a perceptual disorder that is one of the most common consequences of right-side brain damage after stroke, occurring in 29% of the 15 million people who sustain stroke worldwide. Patients with neglect demonstrate inattention to objects or events on the side that is opposite to the damaged part of the brain. They often miss food on one side of the plate, missing words on one side of the page, bumping into the left door jamb, getting confused by moving objects, and being fearful of walking in crowded places. The current gold standard for detecting and rehabilitating neglect lacks generalizability to dynamic tasks and contexts encountered during activities of daily living (ADL). The investigators in this project will develop a brain-computer interface (BCI) system that will be implemented in augmented reality (AR) environment for detection, assessment and rehabilitation of unilateral neglect during ADL.  More specifically, the system will in real-time monitor the brain activity recorded through electroencephalography (EEG) for the detection and assessment of visually neglected extra-personal space. Moreover, the system will also include haptic, auditory and visual stimulation while the users are engaged in real-world tasks conducted during rehabilitation for reducing neglect-related disabilities. It is also anticipated that the novel scientific discoveries and engineering enhancements of this project will have effects on the current practice on BCIs: (i) enabling design and implementation of such systems in more naturalistic environments providing more immersive experiences; and (ii) expansion of the use of BCIs in the design of intervention and rehabilitation techniques for other neurological disorders. This project will promote STEM education and provide rigorous training and variety of hands-on experiences to researchers from K-12 to graduate level.&lt;br/&gt;&lt;br/&gt;The research objective of this project is to introduce a prototype for stroke-induced neglect detection, assessment, and rehabilitation system, featuring: (i) seamless integration of EEG and AR in the design of visually evoked EEG-based BCIs to operate during activities of daily living; (ii) accurate and continuous EEG event related potential detection for neglect assessment and mapping through Bayesian inference models; (iii) information theoretic optimum design of neglect intervention focusing on activities of daily living; and (iv) multimodal real-time feedback for rehabilitation of neglect related disabilities during intervention. Unlike the common computerized neglect assessment methods, EEG will not require any physical responses from the patient. Also, the use of EEG permits automation, making it an ideal method to guide a personalized and automated neglect intervention. It is known that one common element among the existing interventions that have shown promise for reducing neglect is multimodal stimulation to the neglected side of the body or environment. Timely feedback to the user when neglect is detected during the continuous EEG monitoring will enable this stimulation. Finally, used in conjunction with AR headset and skill-based training during acute inpatient rehabilitation, the planned system will provide the opportunity to deliver high-intensity repetitive stimulation with progression during meaningful everyday activities. The outcomes of this project will be disseminated to the scientific community through technical reports,  journal publications and conference presentations. All software developed through this project will be publicly available through archival repositories.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/30/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/30/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1915065</AwardID>
<Investigator>
<FirstName>Sarah</FirstName>
<LastName>Ostadabbas</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Sarah Ostadabbas</PI_FULL_NAME>
<EmailAddress>ostadabbas@ece.neu.edu</EmailAddress>
<PI_PHON>6173734992</PI_PHON>
<NSF_ID>000704085</NSF_ID>
<StartDate>07/30/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramElement>
<ProgramReference>
<Code>8018</Code>
<Text>Smart and Connected Health</Text>
</ProgramReference>
<ProgramReference>
<Code>8062</Code>
<Text>SCH Type II: INT</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~394163</FUND_OBLG>
</Award>
</rootTag>
