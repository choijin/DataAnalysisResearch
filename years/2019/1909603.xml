<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Towards Abstractive Summarization That Preserves the Original Meaning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>498829.00</AwardTotalIntnAmount>
<AwardAmount>498829</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Information floods people's daily lives, and it is overwhelming. Summarization systems that identify salient pieces of information and present it concisely can help. The single most important characteristic a text summary must possess to make it usable in real-world scenarios is its reliability. A summary is reliable if its content can be trusted to remain accurate to the original. While deep neural architectures have demonstrated success in abstractive summarization, studies reveal that system-generated abstracts can contain inaccurate factual details or hallucinated content that change the meaning of the original texts. An abstractive summarization system seeks to transform lengthy source texts to a succinct summary using natural language generation capabilities; the summary can contain new words and phrases that are unseen in the source input. With greater flexibility of lexical choices comes increased demand for reliability---summaries must keep the meaning of the original intact. Without emphasizing summary reliability, system outputs can render useless at best, and misleading and detrimental at worst. Thus, there exists a pressing need, and this project aims to develop robust text summarizers whose outputs can preserve the meaning of the original. This project will have major impact on science and technology as well as the development of society. The knowledge acquired in this project can be extended to help build robust language generation capabilities that are crucial for machine translation. This project will fund both undergraduate and graduate students where undergraduate students are teamed up with graduate students to gain hands-on experiences and promote mentorship.&lt;br/&gt;&lt;br/&gt;This project aims to build robust abstractive summarization systems whose summaries can remain true to the original texts by harnessing the power of deep neural models and linguistic structure prediction. Given that major relations of a summary (e.g., who did what to whom) are often the same or similar to those of the source text, the project focuses on developing methods that learn to promote summaries that preserve important source relations and discourage summaries that contain erroneous relations, thus preventing a summary from dramatically changing the meaning of the original text. The research objective includes the following. (a) Developing an abstractive, sentence-to-sentence summarizer that jointly performs generation of summary sentences and parsing sentence structures. (b) Developing a many-to-one sentence summarizer that explicitly models coreference relationships between mentions observed in the source text. Drawing upon recent developments in deep neural architectures, these efforts are expected to improve a neural abstractive multi-document summarizer to help it properly encode the source texts and decode the summary sequence. (c) Devising a novel, semi-automatic evaluation scheme leveraging question-answering to assess to what extent system summaries preserve the meaning of the original texts.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/22/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1909603</AwardID>
<Investigator>
<FirstName>Fei</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fei Liu</PI_FULL_NAME>
<EmailAddress>Fei.Liu@ucf.edu</EmailAddress>
<PI_PHON>4078233183</PI_PHON>
<NSF_ID>000701523</NSF_ID>
<StartDate>07/22/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>The University of Central Florida Board of Trustees</Name>
<CityName>Orlando</CityName>
<ZipCode>328168005</ZipCode>
<PhoneNumber>4078230387</PhoneNumber>
<StreetAddress>4000 CNTRL FLORIDA BLVD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>150805653</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Central Florida]]></Name>
<CityName>Orlando</CityName>
<StateCode>FL</StateCode>
<ZipCode>328168005</ZipCode>
<StreetAddress><![CDATA[4000 Central Florida Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~498829</FUND_OBLG>
</Award>
</rootTag>
