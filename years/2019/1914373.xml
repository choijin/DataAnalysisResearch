<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Blockchain-Enabled Machine Learning on Confidential Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2019</AwardEffectiveDate>
<AwardExpirationDate>12/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>224634.00</AwardTotalIntnAmount>
<AwardAmount>224634</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anna Brady-Estevez</SignBlockName>
<PO_EMAI>abrady@nsf.gov</PO_EMAI>
<PO_PHON>7032927077</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) project includes advances in scientific understanding and substantial societal and commercial impacts. In an era with seemingly endless data breaches, the project offers a way of applying the power of machine learning while never disclosing sensitive raw data. Decentralized computation can increase the scale of models that may be trained, which will allow the use of deep learning on more complicated problems across a range of fields. Additionally, allowing confidential data to be used will allow more rapid research advances in fields with sensitive data, such as biomedicine. Furthermore, decentralized computation offers the promise of lower cost than existing computational infrastructures such as cloud providers. This greater, and more democratic, power will push the boundaries of the state-of-the-art and also enable more people to leverage large-scale machine learning.&lt;br/&gt;&lt;br/&gt;This SBIR Phase I project proposes to advance knowledge in the area of coordinating decentralized secure machine learning with a blockchain in a manner that maintains data confidentiality and ensures verifiability. The R&amp;D will also advance understanding and practicality of zero knowledge computational verification and homomorphic neural networks. While deep neural networks have yielded astounding results in recent years, there has been limited progress towards achieving a practical solution to training models in a decentralized context while both maintaining data confidentiality and ensuring verifiability. This is the key challenge and it is anticipated that this project will yield a solution. The proposed approach involves defining a protocol for training amongst untrusted parties that is mediated by a decentralized ledger and involves the use of homomorphic encryption and a computational verification technique.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/21/2019</MinAmdLetterDate>
<MaxAmdLetterDate>06/21/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1914373</AwardID>
<Investigator>
<FirstName>Guha</FirstName>
<LastName>Jayachandran</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Guha Jayachandran</PI_FULL_NAME>
<EmailAddress>info@onai.com</EmailAddress>
<PI_PHON>6504298622</PI_PHON>
<NSF_ID>000740909</NSF_ID>
<StartDate>06/21/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Onu Technology, Inc.</Name>
<CityName>San Jose</CityName>
<ZipCode>951294582</ZipCode>
<PhoneNumber>6504298622</PhoneNumber>
<StreetAddress>7291 Coronado Dr., Suite 5</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>079763837</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ONU TECHNOLOGY, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Onu Technology, Inc.]]></Name>
<CityName>San Jose</CityName>
<StateCode>CA</StateCode>
<ZipCode>951293624</ZipCode>
<StreetAddress><![CDATA[7280 Blue Hill Dr., Suite 10]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>8030</Code>
<Text>Chemical Technology</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~224634</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-ce21f877-7fff-7d63-9fff-556ed20fc0a8"> </span></p> <p dir="ltr"><span>We achieved the aims set out for Phase I, related to performing machine learning in a manner that does not expose sensitive data. Machine learning allows models to be trained on data such that those models can then be used to make predictions about other inputs. A particular machine learning technique, deep learning, has proven revolutionary over the past several years in its capabilities. But in many problem domains, the data involved may be sensitive.</span></p> <p dir="ltr"><span>The various techniques investigated and/or developed in this project enable an entity to train a model on encrypted data provided by another party, without needing to be able to decrypt or read the encrypted data; enable multiple parties to jointly train a model without exposing any sensitive data to each other; and allow a model to be evaluated on encrypted input without needing to decrypt that input. We tested and benchmarked all of these scenarios during Phase I.&nbsp;</span></p> <p dir="ltr"><span>The project also entailed enabling a method that can allow participants and third parties mediated by a blockchain to verify that training was faithfully performed, even without being able to view the input data. For example, a company can send encrypted training data to a provider of computation to train a model. The provider cannot read the data but is able to train a model. Only the original data owner can decrypt and utilize the model but anyone can verify the training was properly performed.</span></p> <p dir="ltr"><span>These types of techniques enable a world where the power of deep learning can be harnessed with reliable safeguards for maintaining the confidentiality of sensitive data and ensuring verifiability. Both these aspects--confidentiality and verifiability--are required for performing machine learning on sensitive data in a decentralized or many-party context.&nbsp;</span></p> <p dir="ltr"><span>Accomplishing this vision will increase the safety of data associated with all of us. Better allowing proprietary or confidential data to be used will allow more rapid research advances in fields with sensitive data, such as biomedicine. Furthermore, decentralized computation can increase the scale of models that may be trained, which will allow the use of deep learning on more complicated problems across a range of fields.</span></p><br> <p>            Last Modified: 02/19/2020<br>      Modified by: Guha&nbsp;Jayachandran</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   We achieved the aims set out for Phase I, related to performing machine learning in a manner that does not expose sensitive data. Machine learning allows models to be trained on data such that those models can then be used to make predictions about other inputs. A particular machine learning technique, deep learning, has proven revolutionary over the past several years in its capabilities. But in many problem domains, the data involved may be sensitive. The various techniques investigated and/or developed in this project enable an entity to train a model on encrypted data provided by another party, without needing to be able to decrypt or read the encrypted data; enable multiple parties to jointly train a model without exposing any sensitive data to each other; and allow a model to be evaluated on encrypted input without needing to decrypt that input. We tested and benchmarked all of these scenarios during Phase I.  The project also entailed enabling a method that can allow participants and third parties mediated by a blockchain to verify that training was faithfully performed, even without being able to view the input data. For example, a company can send encrypted training data to a provider of computation to train a model. The provider cannot read the data but is able to train a model. Only the original data owner can decrypt and utilize the model but anyone can verify the training was properly performed. These types of techniques enable a world where the power of deep learning can be harnessed with reliable safeguards for maintaining the confidentiality of sensitive data and ensuring verifiability. Both these aspects--confidentiality and verifiability--are required for performing machine learning on sensitive data in a decentralized or many-party context.  Accomplishing this vision will increase the safety of data associated with all of us. Better allowing proprietary or confidential data to be used will allow more rapid research advances in fields with sensitive data, such as biomedicine. Furthermore, decentralized computation can increase the scale of models that may be trained, which will allow the use of deep learning on more complicated problems across a range of fields.       Last Modified: 02/19/2020       Submitted by: Guha Jayachandran]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
