<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Medium: A Bi-directional Neural Interface for Bionic Prosthetic Legs</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2020</AwardEffectiveDate>
<AwardExpirationDate>05/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>1119855.00</AwardTotalIntnAmount>
<AwardAmount>1126803</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When individuals lose a lower limb, they rely on a prosthesis to restore their basic mobility in daily living.  But most modern robotic prosthetic legs operate autonomously, without direct communication with the user, which limits the functionality and versatility of these assistive devices.  This project will develop a novel bi-directional neural-machine interface that enables individuals with lower limb amputations to operate and sense their prosthetic leg intuitively and naturally.  Project outcomes will have profound societal impact by improving the mobility and stability, balance confidence, and overall quality of life for the large community of individuals with lower limb amputation, while alleviating phantom pain.  In the longer term, the technology created by this research may lead to a paradigm shift in the commercial development of medical assistive devices other than prostheses.  In addition, undergraduate and graduate students in neural and rehabilitation engineering will be trained as members of the research team, and K-12 students from underrepresented groups will be engaged through educational and outreach activities.&lt;br/&gt;&lt;br/&gt;This research will develop a novel non-invasive and bi-directional neural-machine interface (NMI) for a bionic prosthetic ankle that enables seamless integration of robotic prostheses and their users for improved mobility and stability.  The project will encompass three main thrusts: investigation of high-density transcutaneous nerve stimulation and new encoding algorithms for evoking the illusion of sensation in an amputated foot (a sensory interface); development of novel EMG decoding algorithms based on machine learning and neurophysiological modeling approaches for continuous neural control of a prosthetic ankle (a motor interface); and design and fabrication of a bidirectional NMI that combines both of the aforementioned sensory and motor interfaces to achieve embodied integration of a prosthetic ankle within the user.  The NMI prototype will be validated on individuals with transtibial amputations when performing various activities common in daily living.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/04/2020</MinAmdLetterDate>
<MaxAmdLetterDate>04/26/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1954587</AwardID>
<Investigator>
<FirstName>He</FirstName>
<LastName>Huang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>He Huang</PI_FULL_NAME>
<EmailAddress>hhuang11@ncsu.edu</EmailAddress>
<PI_PHON>9195155218</PI_PHON>
<NSF_ID>000522896</NSF_ID>
<StartDate>06/04/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Xiaogang</FirstName>
<LastName>Hu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaogang Hu</PI_FULL_NAME>
<EmailAddress>xiaogang@unc.edu</EmailAddress>
<PI_PHON>9199660696</PI_PHON>
<NSF_ID>000718699</NSF_ID>
<StartDate>06/04/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957115</ZipCode>
<StreetAddress><![CDATA[EBIII 4402D, CB 7115]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~1119855</FUND_OBLG>
<FUND_OBLG>2021~6948</FUND_OBLG>
</Award>
</rootTag>
