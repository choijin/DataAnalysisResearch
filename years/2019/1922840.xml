<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: Collaborative Research: Sparse and Low Rank Methods for Imbalanced and Heterogeneous Data</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>06/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>59956.00</AwardTotalIntnAmount>
<AwardAmount>59956</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In recent years, sparse and low-rank modeling techniques have emerged as powerful tools for efficiently processing visual data in non-traditional ways. A particular area of promise for these theories is visual recognition, where object detection and image classification approaches need to be able to deal with the highly diverse appearance of real-world objects. However, existing visual recognition methods generally succeed only in the presence of sufficient amounts of homogeneous and balanced training data that are well matched to the actual test conditions. In practice, when the data are heterogeneous and imbalanced, the performance of existing methods can be much worse than expected.&lt;br/&gt;&lt;br/&gt;This project will develop a comprehensive framework for real-world visual recognition based on novel sparse and low-rank modeling techniques, which will be able to deal with imbalanced, heterogeneous and multi-modal data. Imbalanced data will be handled using convex optimization techniques that automatically divide a dataset into common and rare patterns, and select a small set of representatives for the common patterns that are then combined with the rare patterns to form a balanced dataset. Heterogeneous and multi-modal data will be handled using non-convex optimization techniques that learn a latent representation from multiple domains or modalities. Classification and clustering algorithms can be applied to the latent representation. Applications of these methods include image and video-based object recognition, activity recognition, video summarization, and surveillance.</AbstractNarration>
<MinAmdLetterDate>02/12/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/12/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1922840</AwardID>
<Investigator>
<FirstName>Vishal</FirstName>
<LastName>Patel</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vishal M Patel</PI_FULL_NAME>
<EmailAddress>vpatel36@jhu.edu</EmailAddress>
<PI_PHON>7045023775</PI_PHON>
<NSF_ID>000675164</NSF_ID>
<StartDate>02/12/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182686</ZipCode>
<StreetAddress><![CDATA[1101 E 33St Suite B001]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~59956</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In recent years, sparse and low-rank modeling techniques have emerged as powerful tools for efficiently processing visual data in non-traditional ways. A particular area of promise for these theories is visual recognition, where object detection and image classification approaches need to be able to deal with the highly diverse appearance of real-world objects. However, existing visual recognition methods generally succeed only in the presence of sufficient amounts of homogeneous and balanced training data that are well matched to the actual test conditions. In practice, when the data are heterogeneous and imbalanced, the performance of existing methods can be much worse than expected.<br /><br />In this project, we developed various sparse and low-rank representation-based methods for unsupervised and supervised classification.&nbsp; Methods for multi-modal subspace clustering, domain adaptive subspace clustering, and multi-modal classification were developed.&nbsp; Applications in image classification, object recognition, and image clustering were presented.&nbsp; Various deep convolution neural network-based methods were also developed.&nbsp; These methods which are based on an encoder-decoder architecture with a shared fully-connected layer, find an explicit nonlinear mapping for data, while simultaneously obtaining sparse codes that can be used for classification and clustering.<br /><br />We organized workshops and gave tutorials at conferences on topics related to this project.&nbsp; All publications and implementation code have been made publicly available to the research community.</p><br> <p>            Last Modified: 08/12/2020<br>      Modified by: Vishal&nbsp;M&nbsp;Patel</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In recent years, sparse and low-rank modeling techniques have emerged as powerful tools for efficiently processing visual data in non-traditional ways. A particular area of promise for these theories is visual recognition, where object detection and image classification approaches need to be able to deal with the highly diverse appearance of real-world objects. However, existing visual recognition methods generally succeed only in the presence of sufficient amounts of homogeneous and balanced training data that are well matched to the actual test conditions. In practice, when the data are heterogeneous and imbalanced, the performance of existing methods can be much worse than expected.  In this project, we developed various sparse and low-rank representation-based methods for unsupervised and supervised classification.  Methods for multi-modal subspace clustering, domain adaptive subspace clustering, and multi-modal classification were developed.  Applications in image classification, object recognition, and image clustering were presented.  Various deep convolution neural network-based methods were also developed.  These methods which are based on an encoder-decoder architecture with a shared fully-connected layer, find an explicit nonlinear mapping for data, while simultaneously obtaining sparse codes that can be used for classification and clustering.  We organized workshops and gave tutorials at conferences on topics related to this project.  All publications and implementation code have been made publicly available to the research community.       Last Modified: 08/12/2020       Submitted by: Vishal M Patel]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
