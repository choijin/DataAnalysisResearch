<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>US-German Data Sharing Proposal: CRCNS Data Sharing: REvealing SPONtaneous Speech Processes in Electrocorticography (RESPONSE)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>388060.00</AwardTotalIntnAmount>
<AwardAmount>388060</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Fritz</SignBlockName>
<PO_EMAI>jfritz@nsf.gov</PO_EMAI>
<PO_PHON>7032927923</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The uniquely human capability to produce speech enables swift communication of abstract and substantive information. Currently, nearly two million people in the United States, and far more worldwide, suffer from significant speech production deficits as a result of severe neuromuscular impairments due to injury or disease. In extreme cases, individuals may be unable to speak at all. These individuals would greatly benefit from a device that could alleviate speech deficits and enable them to communicate more naturally and effectively. This project will explore aspects of decoding a user's intended speech directly from the electrical activity of the brain and converting it to synthesized speech that could be played through a loudspeaker in real-time to emulate natural speaking from thought. In particular, this project will uniquely focus on decoding continuous, spontaneous speech processes to achieve more natural and practical communication device for the severely disabled.&lt;br/&gt;&lt;br/&gt;The complex dynamics of brain activity and the fundamental processing units of continuous speech production and perception are largely unknown, and such dynamics make it challenging to investigate these speech processes with traditional neuroimaging techniques. Electrocorticography (ECoG) measures electrical activity directly from the brain surface and covers an area large enough to provide insights about widespread networks for speech production and understanding, while simultaneously providing localized information for decoding nuanced aspects of the underlying speech processes. Thus, ECoG is instrumental and unparalleled for investigating the detailed spatiotemporal dynamics of speech. The research team's prior work has shown for the first time the detailed spatiotemporal progression of brain activity during prompted continuous speech, and that the team's Brain-to-text system can model phonemes and decode words. However, in pursuit of the ultimate objective of developing a natural speech neuroprosthetic for the severely disabled, research must move beyond studying prompted and isolated aspects of speech. This project will extend the research team's prior experiments to investigate the neural processes of spontaneous and imagined speech production. In conjunction with in-depth analysis of the recorded neural signals, the researchers will apply customized ECoG-based automatic speech recognition (ASR) techniques to facilitate the analysis of the large amount of phones occurring in continuous speech. Ultimately, the project aims to define fundamental units of continuous speech production and understanding, illustrate functional differences between these units, and demonstrate that representations of spontaneous speech can be synthesized directly from the neural recordings. A companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF)</AbstractNarration>
<MinAmdLetterDate>01/30/2019</MinAmdLetterDate>
<MaxAmdLetterDate>01/30/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1902395</AwardID>
<Investigator>
<FirstName>Dean</FirstName>
<LastName>Krusienski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dean Krusienski</PI_FULL_NAME>
<EmailAddress>djkrusienski@vcu.edu</EmailAddress>
<PI_PHON>8048271890</PI_PHON>
<NSF_ID>000500739</NSF_ID>
<StartDate>01/30/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Commonwealth University</Name>
<CityName>RICHMOND</CityName>
<CountyName>**RICHMOND</CountyName>
<ZipCode>232980568</ZipCode>
<PhoneNumber>8048286772</PhoneNumber>
<StreetAddress>P.O. Box 980568</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>105300446</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VIRGINIA COMMONWEALTH UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>105300446</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Virginia Commonwealth University]]></Name>
<CityName/>
<CountyName>**RICHMOND</CountyName>
<StateCode>VA</StateCode>
<ZipCode>232980568</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7327</Code>
<Text>CRCNS-Computation Neuroscience</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7327</Code>
<Text>CRCNS</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~388058</FUND_OBLG>
</Award>
</rootTag>
