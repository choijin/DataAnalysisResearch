<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: FND: Optoacoustic Material and Structure Pretouch Sensing at Robot Fingertip</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2020</AwardEffectiveDate>
<AwardExpirationDate>12/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>750000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Erion Plaku</SignBlockName>
<PO_EMAI>eplaku@nsf.gov</PO_EMAI>
<PO_PHON>7032928695</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When robots move from factory floors to a wider service market, it is imperative to enable robots to grasp objects with no prior knowledge. Contactless detection of object: material type; shape; and close-to-surface interior structure, can provide vital information such as friction coefficient and applicable grasping force for planning for successful grasps. Unfortunately, no existing sensors can achieve this. Imaging and ranging devices such as cameras or lidars can neither see through surface nor distinguish material type. Tactile sensing requires physical contacts between the robot finger and the object surface which may risk damaging the object or changing the position of the object. Either case may lead to a grasping failure.  Microelectromechanical systems and robot perception experts will develop systems and algorithms to create a new type of miniature fingertip-mounted sensor that can detect and map object material type, shape, and close-to-surface interior structure without physical contact. The project will benefit a wide range of robotic applications that require grasping and manipulation such as manufacturing, service robots, search &amp; rescue, etc.&lt;br/&gt;&lt;br/&gt;Building on the working principle of optoacoustic effect which refers to the formation of acoustic waves following light absorption in a solid material, investigators propose to send modulated laser pulse signals to probe material type and structure based on the acoustic spectrum, time-of-flight, and intensity analyses of the received ultrasound signals. The proposed sensor will be enabled by new and efficient material recognition and surface/interior structure mapping algorithms so that the recommended grasping points and force range will be available before robot fingers are closed. The integrated new research and educational effort is named as the Optoacoustic Material And Structure Sensor (OMASS) project which focuses three main tasks, 1) Development of OMASS devices: an iterative study on design, fabrication, packaging, calibration, testing, and device control, 2)  Pretouch perception algorithms to enable the core functions of OMASS devices: material type recognition, surface shape &amp; interior structure mapping, and grasping point planning, and 3) Building a material database with raw signals and signatures for common household items. The OMASS project will share development and educational efforts via journal and conference publications, seminars, research experience for undergraduates and teachers, open-house activities, and the Internet to scientists, students, underrepresented groups, and the public worldwide. The OMASS project will demonstrate the state-of-the-art robotics to the public. The research team will distribute hardware designs, source codes (e.g. ROS stacks), application programming interfaces, experimental data, and documentation via the project website so that other groups can learn from the project team's experience.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/22/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/22/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1925037</AwardID>
<Investigator>
<FirstName>Jun</FirstName>
<LastName>Zou</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jun Zou</PI_FULL_NAME>
<EmailAddress>junzou@tamu.edu</EmailAddress>
<PI_PHON>9798621640</PI_PHON>
<NSF_ID>000299557</NSF_ID>
<StartDate>08/22/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dezhen</FirstName>
<LastName>Song</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dezhen Song</PI_FULL_NAME>
<EmailAddress>dzsong@cs.tamu.edu</EmailAddress>
<PI_PHON>9798621696</PI_PHON>
<NSF_ID>000354064</NSF_ID>
<StartDate>08/22/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M Engineering Experiment Station</Name>
<CityName>College Station</CityName>
<ZipCode>778454645</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Pkwy S</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>847205572</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A&amp;M ENGINEERING EXPERIMENT STATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042915991</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M Engineering Experiment Station]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433112</ZipCode>
<StreetAddress><![CDATA[HRBB 311B, CSE Department, TAMU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~750000</FUND_OBLG>
</Award>
</rootTag>
