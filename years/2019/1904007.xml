<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Cortical Motion Coding and Gaze Control in Natural Vision</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>652023.00</AwardTotalIntnAmount>
<AwardAmount>652023</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08090200</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>IOS</Abbreviation>
<LongName>Division Of Integrative Organismal Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sridhar Raghavachari</SignBlockName>
<PO_EMAI>sraghava@nsf.gov</PO_EMAI>
<PO_PHON>7032924845</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The human eye sends information to the brain at an estimated rate of approximately 10 megabits per second, roughly the speed of an ethernet connection. Processing such a large bandwidth stream of visual information on behaviorally relevant time scales requires the brain to extract and represent information from visual signals efficiently, i.e. represent the most information for the least cost in time, hardware and energy. In essence, the brain needs to compress the visual stream in much the same way that software compresses the digital representation of a movie. This coding enhancement might arise because the brain has evolved coding strategies that specifically account for the fact that because of both object and eye movements, the visual input to the eye may be correlated in space and time. As a result, the visual signals to the brain from the eye and retina may be quite predictable. One of the primary questions in current sensory-motor systems research is to what extent the brain utilizes prediction to compensate for the fact that it takes a finite amount of time to process information even though the visual scene might change in the interim. This proposal focuses on neural representation of visual motion and gaze behavior for natural motion videos and uses a novel video game environment to simplify the analysis of gaze. The project will also create a publicly available database of natural gaze recordings, analyze the statistics of natural retinal image motion, characterize the representation of naturally correlated motion stimuli in cortical neurons, and to articulate the strategy underlying gaze control. This database will benefit neuroscience, computer vision, media design, and other fields.&lt;br/&gt;&lt;br/&gt;The experimental approach combines cortical physiology in non-human primates with high-resolution eye movement recording in both humans and monkeys. The PI proposes to use high-resolution videos of natural moving scenes as visual stimuli while recording neural activity in motion-sensitive visual cortex.  By carefully degrading the movies to make them increasingly less natural and measuring the impact on neural responses, the experiments will determine what features of the moving visual scene are represented most precisely.  A second set of experiments will study the interactions between the visual scene and eye movements. The PI will develop an innovative Pong-like video game that actively engages the viewers and creates a common viewing purpose (scoring points) while simplifying the identification of the target of interest to aid analysis, thereby controlling the cognitive state of the viewer. The interdisciplinary nature of the work will provide training opportunities for undergraduate and graduate students crossing over from mathematics and physics to neurobiology, and for students with a biology background to gain skills in computational analysis.</AbstractNarration>
<MinAmdLetterDate>02/07/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/22/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1904007</AwardID>
<Investigator>
<FirstName>Leslie</FirstName>
<LastName>Osborne</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Leslie C Osborne</PI_FULL_NAME>
<EmailAddress>leslie.osborne@duke.edu</EmailAddress>
<PI_PHON>5105935108</PI_PHON>
<NSF_ID>000549752</NSF_ID>
<StartDate>02/07/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<CountyName>DURHAM</CountyName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2>Erwin Square</StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<CountyName>DURHAM</CountyName>
<StateCode>NC</StateCode>
<ZipCode>277054010</ZipCode>
<StreetAddress><![CDATA[2200 W. Main Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7246</Code>
<Text>PHYSICS OF LIVING SYSTEMS</Text>
</ProgramElement>
<ProgramElement>
<Code>7713</Code>
<Text>Activation</Text>
</ProgramElement>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~102022</FUND_OBLG>
<FUND_OBLG>2017~200000</FUND_OBLG>
<FUND_OBLG>2018~247513</FUND_OBLG>
<FUND_OBLG>2019~102487</FUND_OBLG>
</Award>
</rootTag>
