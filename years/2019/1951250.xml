<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>STTR Phase II:  TerraSentia: Ultra-compact, Autonomous, Teachable Under-canopy Phenotyping Robot for Plant Breeders and Crop Scientists</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/15/2020</AwardEffectiveDate>
<AwardExpirationDate>03/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>832000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anna Brady-Estevez</SignBlockName>
<PO_EMAI>abrady@nsf.gov</PO_EMAI>
<PO_PHON>7032927077</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact of this Small Business Technology Transfer (STTR) Phase II project include improving food security, while at the same time enhancing the economic viability and environmental sustainability of large-scale production agriculture. In order to improve crop varieties, agricultural production, and sustainability of farming, there is an urgent need for better technologies to acquire under-canopy plant trait and health data. Examples of high-value under-canopy data include emergence, stem width, corn ear height, plant life-cycle events like flowering and fruiting, and symptoms of pathogens, diseases, and nutrient deficiency. Because these data cannot be obtained by aerial imaging, under-canopy data collection has dramatically greater actionability and value compared to aerial data. However no cost-effective, scalable ways of collecting this data are currently available. In fact, the state of the art is manual data collection by crop scientists (and their students or interns), agronomists, crop-scouts or farmers - an extremely labor intensive, and therefore expensive way of collecting this highly valuable data. Our work will greatly enhance the availability of under-canopy data from field crops, benefiting crop scientists and agricultural product development professionals as well as enable large scale field monitoring and management in production agriculture.  The commercial value of the field data for crop breeding is in excess of $50 Million/year for breeding major row-crops in the US.&lt;br/&gt;&lt;br/&gt;This STTR Phase II project proposes to establish autonomous data collection under-canopy from field crops using a low-cost ground robot. The proposed work will enhance the ability to collect data autonomously in full-scale crop-breeding fields throughout the season and enable on-site data analytics for remote sites with limited connectivity. Long-term field adaptive autonomy will be achieved through implementation of multiple low-cost sensors. Robot's real-time control algorithms will be developed to adapt camera perspective and robot path in order to obtain the highest quality information from the complex and dynamic under-canopy field environments. Finally, the research will develop hardware specific edge-compute versions of the analytics algorithms to enable on-site data analysis. These innovations will together enable global deployment of the system for effective data collection and phenotyping.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>08/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1951250</AwardID>
<Investigator>
<FirstName>Chinmay</FirstName>
<LastName>Soman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chinmay Soman</PI_FULL_NAME>
<EmailAddress>chinmay@earthsense.co</EmailAddress>
<PI_PHON>2174024767</PI_PHON>
<NSF_ID>000736751</NSF_ID>
<StartDate>04/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>EarthSense, Inc.</Name>
<CityName>Champaign</CityName>
<ZipCode>618207460</ZipCode>
<PhoneNumber>2174024767</PhoneNumber>
<StreetAddress>60 Hazelwood Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080358600</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>EARTHSENSE, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[EarthSense, Inc.]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207460</ZipCode>
<StreetAddress><![CDATA[60 Hazelwood Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1591</Code>
<Text>STTR Phase II</Text>
</ProgramElement>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>8030</Code>
<Text>Chemical Technology</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<ProgramReference>
<Code>8240</Code>
<Text>SBIR/STTR CAP</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~816000</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
</Award>
</rootTag>
