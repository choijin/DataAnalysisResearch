<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Enhancing EEG-based Emotion Estimation  with Transfer Learning, Priming, and Virtual Reality</AwardTitle>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>499973.00</AwardTotalIntnAmount>
<AwardAmount>499973</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Emotions influence the decisions we make every day. However, emotions are difficult to measure. Surveys, the traditional method of emotion measurement, take significant time and cause interruptions. Further, people do not always know their own emotions -- think of the times when a person has shouted, "I'm not shouting!"  Direct emotion-measuring systems, based on sensors worn on the body or head, have shown promise but are not yet ready to compete with surveys. This project includes several new techniques designed to increase the reliability and performance of these systems.  The project will lay the groundwork for wearable devices that can be used outside the laboratory, in environments as varied as classrooms and theme parks. From there, this research could lead to the development of human-computer systems which adjust in real-time to maintain a person's interest. Such systems would be valuable for all levels of education, as well as entertainment and other fields.  During the project, women and members of underrepresented minorities will participate, both as researchers and as research participants. &lt;br/&gt;&lt;br/&gt;This project is one of the first to combine emotion-estimating Brain-Computer Interfaces (BCIs) with three methods: transfer learning, emotion priming, and virtual reality. Transfer learning is expected to help BCI systems detect real emotions rather than setting-specific brain responses. Transfer learning techniques will be applied to data from different emotion elicitation paradigms to study how well training data from standard methods can be expected to work in new environments. An alternative training technique from psychology called "emotion priming" will be used, and the effects on transfer learning will be studied. Emotion priming is expected to increase the accuracy of emotion elicitation, increasing the quality of training data and thus system performance. Virtual reality will be used to manipulate the participants' arousal states through a larger range than is possible through pictures and videos, in order to generate more transferable results. Together, these investigations are expected to dramatically improve the performance and, critically, the cross-task reliability of these systems. Because the study of emotion impacts nearly every field of human study, the development of a system for real-time measurement of valid emotions has the potential to advance cross-disciplinary transformation. Overall, these tests will fill a knowledge gap in the scientific literature, and inform how future general-purpose emotion estimation systems are trained. In addition, the project will provide shared data that may lead to even greater advancements in the BCI field when used by future researchers.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/03/2019</MinAmdLetterDate>
<MaxAmdLetterDate>09/03/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1910526</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Thompson</LastName>
<EmailAddress>Davet@ksu.edu</EmailAddress>
<StartDate>09/03/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Kansas State University</Name>
<CityName>Manhattan</CityName>
<ZipCode>665061100</ZipCode>
<PhoneNumber>7855326804</PhoneNumber>
<StreetAddress>2 FAIRCHILD HALL</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Kansas</StateName>
<StateCode>KS</StateCode>
</Institution>
<ProgramElement>
<Code>081Y</Code>
<Text>NSF 2026 Fund</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramElement>
<Code>8624</Code>
<Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<ProgramReference>
<Code>8091</Code>
<Text>BRAIN Initiative Res Support</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
</Award>
</rootTag>
