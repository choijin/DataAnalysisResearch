<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Understanding visual reasoning for visual communication</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2025</AwardExpirationDate>
<AwardTotalIntnAmount>558702.00</AwardTotalIntnAmount>
<AwardAmount>329507</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Hout</SignBlockName>
<PO_EMAI>mhout@nsf.gov</PO_EMAI>
<PO_PHON>7032922163</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to advance the understanding of visual reasoning for visual communication. Visual reasoning enables people to translate visual input to abstract concepts. For example, to interpret which counties will receive more snowfall using a weather map, it is necessary to figure out which colors on the weather map indicate which amounts of snowfall. People have expectations about how visual features should map to concepts in visualizations, and it is harder for them to interpret visualizations that violate those expectations, even if mappings are clearly labeled. However, the nature of those expectations and their role in visual reasoning is not well-understood, so the design of information visualizations is often unprincipled and ad-hoc. With a better understanding of how visual reasoning works, it will be possible to design visualizations that fit its strengths and optimize visual communication. The investigators will address this problem by studying how people infer meaning from color in visualizations. This research can be translated to producing online tools for designing visualizations, which will improve STEM education and increase public literacy and engagement with science and technology. The education plan will use visual communication to make science more accessible and engaging through virtual reality (VR) and accompanying hands-on experiences with color and visualization, for both college undergraduates and middle-school students. The investigators will also support broadening participation of females in STEM through mentoring among the PI, graduate student, undergraduate intern, and middle school girls. &lt;br/&gt;&lt;br/&gt;The proposed research will address fundamental questions about how visual reasoning enables visual communication. In Objective 1, the investigators will study how people learn to associate perceptual features with novel concepts through environmental statistics. They will also examine how learned associations extend beyond perceptual input due to categorical structure in cognitive representations. In Objective 2, the team will study how to automatically estimate color–concept associations from image statistics. They will construct and evaluate new models that incorporate predictors based on visual input and cognitive representations of color categories. In the process of constructing these models, the team will develop new methods for quantifying graded category membership in a continuous space. By modeling human judgments, there is potential to develop new insights into how those judgments are made. In Objective 3, the team will investigate how people use color–concept associations to interpret visualizations, in a process called assignment inference. Assignment inference enables people to infer optimal mappings between colors and concepts in visualizations, but little is known about how this process works. It is proposed that it can be understood using accumulator models typically used in decision making research, which will forge new connections between the fields of decision making and information visualization. The results will increase knowledge of how people integrate information from multiple, conflicting sources and provide new knowledge about how to optimally design semantically interpretable visualizations.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/19/2020</MinAmdLetterDate>
<MaxAmdLetterDate>02/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1945303</AwardID>
<Investigator>
<FirstName>Karen</FirstName>
<LastName>Schloss</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Karen B Schloss</PI_FULL_NAME>
<EmailAddress>kschloss@wisc.edu</EmailAddress>
<PI_PHON>6083164495</PI_PHON>
<NSF_ID>000782869</NSF_ID>
<StartDate>02/19/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Wisconsin-Madison</Name>
<CityName>MADISON</CityName>
<ZipCode>537151218</ZipCode>
<PhoneNumber>6082623822</PhoneNumber>
<StreetAddress>21 North Park Street</StreetAddress>
<StreetAddress2><![CDATA[Suite 6401]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<StateCode>WI</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WI02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>161202122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WISCONSIN SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041188822</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Wisconsin-Madison]]></Name>
<CityName>Madison</CityName>
<StateCode>WI</StateCode>
<ZipCode>537151218</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Wisconsin</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WI02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~329507</FUND_OBLG>
</Award>
</rootTag>
