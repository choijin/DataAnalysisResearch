<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research In DRMS:  Reinforcement Learning and Attention in Decision Making</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2020</AwardEffectiveDate>
<AwardExpirationDate>02/28/2022</AwardExpirationDate>
<AwardTotalIntnAmount>40219.00</AwardTotalIntnAmount>
<AwardAmount>40219</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Claudia Gonzalez-Vallejo</SignBlockName>
<PO_EMAI>clagonza@nsf.gov</PO_EMAI>
<PO_PHON>7032927836</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Decision makers often consider information from a variety of sources, but since processing information is effortful not all information is always taken into account. This project investigates the contributions of two major sources of information to decision-making: any available information on the reward that an action will produce, and the history of rewards obtained from taking this action in the past. The extent to which decision makers rely on either of these sources of information is fundamental to understanding commonly observed choice patterns that economize on learning: Present information is often (at least partially) ignored and substituted for by relying on prior experience. Recent advances in economics model this trade-off, but do not typically provide an account of prior experience. Neuroscience and artificial intelligence, however, provide an account of learning from prior experience which is relevant to the formation of habits, for instance. This project aims to combine neuroscientific and economic accounts in one coherent theoretical framework, and to quantify experimentally the extent to which decisions rely on present information and prior experience, respectively. Such a measurement is crucial for understanding the circumstances under which a decision maker reassesses a recurring decision and breaks a habit. It will suggest policies that help incentivize decision makers to make deliberate decisions rather than following persistent habits. This is of great importance given the central role habits play in anxiety disorders, addiction, and arguably also in consumption decisions. &lt;br/&gt;&lt;br/&gt;The relative contributions of present information and prior experience are assessed in an experiment that is firmly rooted in the economic theory of rational inattention as well as computational models of reinforcement learning from cognitive neuroscience. The experiment combines observed choice behavior with a measurement of neural activity, in order to establish whether the latter is correlated with probabilistic beliefs. The rationale is that dopaminergic activity in the midbrain is – consistent with reinforcement learning theory – believed to encode a reward prediction error, which can be observed in the striatum using functional magnetic resonance imaging. If this neural measurement can be validated as a proxy for probabilistic beliefs, it could be leveraged for inference on unobservable beliefs. This provides further evidence on the extent to which subjects’ decisions rely on present information and prior experience, depending on the characteristics of these two sources of information.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/07/2020</MinAmdLetterDate>
<MaxAmdLetterDate>02/07/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1948752</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Caplin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew Caplin</PI_FULL_NAME>
<EmailAddress>andrew.caplin@nyu.edu</EmailAddress>
<PI_PHON>2129988950</PI_PHON>
<NSF_ID>000112656</NSF_ID>
<StartDate>02/07/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stefan</FirstName>
<LastName>Bucher</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stefan F Bucher</PI_FULL_NAME>
<EmailAddress>sfb311@nyu.edu</EmailAddress>
<PI_PHON>9178548705</PI_PHON>
<NSF_ID>000807323</NSF_ID>
<StartDate>02/07/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<CountyName>NEW YORK</CountyName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041968306</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NEW YORK UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041968306</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[New York University]]></Name>
<CityName/>
<CountyName>NEW YORK</CountyName>
<StateCode>NY</StateCode>
<ZipCode>100121019</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1321</Code>
<Text>Decision, Risk &amp; Mgmt Sci</Text>
</ProgramElement>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~40219</FUND_OBLG>
</Award>
</rootTag>
