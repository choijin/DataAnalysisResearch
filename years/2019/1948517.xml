<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CHS: RUI: Gaze Sharing to Support Remote Collaboration</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>105572.00</AwardTotalIntnAmount>
<AwardAmount>121572</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
<PO_EMAI>bprabhak@nsf.gov</PO_EMAI>
<PO_PHON>7032924847</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Remote collaboration is becoming a common practice in virtually all employment sectors as it enables flexibility, accommodates different lifestyles, combines resources, and reduces expenses. Despite its numerous advantages and the many technological advancements to support it, there remain numerous challenges. Remote collaborators struggle to maintain shared awareness, mutual understanding, and coordination, leading to frustration and time and monetary loss. Recently, dual eye tracking technology has been explored as a novel way of enhancing remote synchronous collaboration. Through gaze sharing, the process where two collaborators can see each other's point of gaze visualized on their individual screens in real time, remote collaborators in diverse settings have seen improvements in the quality and outcome of their interactions. This project will explore previously overlooked dimensions of remote collaboration and how it is affected by gaze sharing. In particular, it will investigate the communication channel that is used in conjunction with gaze sharing and will explore how gaze awareness affects multi-party groups that go beyond the traditionally studied pairs. This project will be a first step toward understanding how contextual gaze sharing can intelligently support remote collaboration in realistic scenarios that include multiple collaborators.&lt;br/&gt;&lt;br/&gt;Research on real-time gaze sharing has shown that it is a promising way to alleviate some of the limitations of lack of collocation by increasing shared awareness. However, prior gaze sharing studies have not considered the medium of communication and have only studied its effect on communication during audio calls. With the prevalence of text-based communication, it is important to systematically examine the combined effect of the communication medium and shared gaze on collaboration. The first phase of this project will explore gaze sharing as an additional signal to instant messaging and will contrast it to audio-based communication. Using existing communication theories, it will examine the joint effect of gaze sharing and primary channel of communication on collaboration through metrics that include gaze overlap, efficiency, effectiveness, and cognitive workload. The second phase of this project will focus on the group size of remote teams. Gaze sharing has been shown to be particularly effective in studies that include pairs, but it is unclear whether these positive effects would persist in multi-party groups. This project will explore the effect of gaze sharing on multiple collaborators through the development and release of a free and open-source writing platform that will allow multi-party gaze sharing. A user study on writing with groups of varying sizes will follow to uncover whether visualizing multiple gaze locations will be detrimental rather than beneficial to the quality of the collaboration and its outcome. The findings of this project will offer recommendations for future technologies that support multi-party collaborations through the use of different communication media and gaze sharing.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>05/27/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1948517</AwardID>
<Investigator>
<FirstName>Alexandra</FirstName>
<LastName>Papoutsaki</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alexandra Papoutsaki</PI_FULL_NAME>
<EmailAddress>apaa2017@pomona.edu</EmailAddress>
<PI_PHON>9096070969</PI_PHON>
<NSF_ID>000786713</NSF_ID>
<StartDate>04/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Pomona College</Name>
<CityName>Claremont</CityName>
<ZipCode>917114434</ZipCode>
<PhoneNumber>9096218328</PhoneNumber>
<StreetAddress>Alexander Hall</StreetAddress>
<StreetAddress2><![CDATA[550 N. College Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>075293357</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>POMONA COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>075293357</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Pomona College]]></Name>
<CityName>Claremont</CityName>
<StateCode>CA</StateCode>
<ZipCode>917114434</ZipCode>
<StreetAddress><![CDATA[550 North College]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~121572</FUND_OBLG>
</Award>
</rootTag>
