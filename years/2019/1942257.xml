<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Advancing Digital Drawing by Analysis and Modeling of Design Intent</AwardTitle>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>129929.00</AwardTotalIntnAmount>
<AwardAmount>129929</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Drawing is an incomparable aid to visual thinking and discovery, employed by designers, artists, scientists, engineers, and technologists alike. While computing has advanced the manipulation of text, photography, and music in profound ways, drawing has remained largely unchanged in the digital age. This exploratory research will involve a series of studies aimed at understanding the process of drawing at a basic level, with an eye to advancing drawing as a graphical medium on the computer. Project outcomes will have a direct impact on the role of computing in supporting graphical ideation and communication across a wide range of disciplines, from design to engineering to manufacturing to education, by providing fundamental insights into the drawing process. &lt;br/&gt;&lt;br/&gt;In this project machine learning methods will be applied to crowd-sourced drawing tasks across a series of studies to generate new understanding of the process and semantics of drawing, with the ultimate goal of elevating drawing on computers so that it is much more than an attempt to emulate classic art media but instead provides indispensable new capabilities that make drawing, as a form of visual communication, both more expressive and more efficient.  To this end, this work will consider questions such as the following.  What are the strokes that designers draw, and how do these strokes relate to the scene or concept that is depicted? How can the strokes drawn be characterized and quantified?  How does the drawing process vary among individual designers and the scenes they depict? Is it possible to characterize the difference between a quick sketch and a finished illustration? Can models of the drawing process be inferred, and if so can such models be used for understanding and capturing a designer's intent? Can a model for qualitative shape (that is, shape that evolves with the drawing process) be developed?&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/16/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1942257</AwardID>
<Investigator>
<FirstName>Julie</FirstName>
<LastName>Dorsey</LastName>
<EmailAddress>dorsey@cs.yale.edu</EmailAddress>
<StartDate>08/16/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>New Haven</CityName>
<ZipCode>065208327</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>Office of Sponsored Projects</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
</Award>
</rootTag>
