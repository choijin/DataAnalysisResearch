<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: Small: ESTRELLA: Exploiting Structure in Tensors for Representation, Estimation, and Limits of Learning Algorithms</AwardTitle>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>499976.00</AwardTotalIntnAmount>
<AwardAmount>499976</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Scott Acton</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Tensors are multidimensional mathematical objects that generalize vectors (one dimensional) and matrices (two dimensional) to higher dimensions. Tensors, which can be written as multiway arrays, are ubiquitous in applications involving complex-structured data. The data themselves may be tensor-valued in some applications: for example, a grayscale video is a three-dimensional tensor with two spatial dimensions (horizontal and vertical) and one temporal dimension. Tensors can also be used in other applications to represent higher-order correlations between statistical variables; as an example, correlations among all triplets of variables correspond to a three-dimensional tensor. Although tensors have been used for decades in a variety of disciplines, statistical and signal processing methods using structured models for tensor data are less mature than their vector and matrix counterparts. This has immediate consequences for data science practitioners: they lack a theoretical framework for choosing a good model when working with tensor data. This project pursues a comprehensive theory for tensor data by focusing on a family of structured statistical models in which the number of parameters can be controlled in a principled manner. In particular, the project reaps the benefits of structured modeling of tensor data by quantifying the number of data samples needed to obtain a given parametrized structured tensor model and developing efficient algorithms for estimating the associated parameters. In the process, the project seeks also to simplify the measurement, storage, and statistical modeling of tensor-structured data. The outcomes of this project should impact many areas in which tensor data are being used, such as medical imaging, climate science, machine learning, computer vision, text and speech processing, and radar systems. Because of the wide-ranging uses of tensor data, this project also facilitates interactions between multiple research communities from statistics, engineering, and basic sciences.&lt;br/&gt;&lt;br/&gt;The project draws on the tight connection between tensor decompositions and structured matrix models in order to formulate the estimation of structured tensor models as nonconvex optimization problems over highly structured spaces of matrices. The work focuses on developing a fundamental understanding of structured models for tensor data along three research tracks: understanding the geometry of the resulting nonconvex problems, developing computationally efficient algorithms for solving the optimization problems, and quantifying the number of samples required to estimate the parameters within the structured model in a minimax sense. The first track develops a mathematical understanding of the nonconvex optimization problems that arise when using structured models for tensor data. These will inform the design strategies for effectively identifying a good structured model that fits the data. The second track entails the design of numerical methods and algorithms that implement these strategies to efficiently find models that best describe the tensor-valued data. The third and final track characterizes the fundamental limits of the proposed models and their relationship to the metrics of representation, reconstruction, and prediction errors.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/16/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/16/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1910110</AwardID>
<Investigator>
<FirstName>Waheed</FirstName>
<LastName>Bajwa</LastName>
<EmailAddress>waheed.bajwa@rutgers.edu</EmailAddress>
<StartDate>07/16/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Anand</FirstName>
<LastName>Sarwate</LastName>
<EmailAddress>anand.sarwate@rutgers.edu</EmailAddress>
<StartDate>07/16/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
</Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7936</Code>
<Text>SIGNAL PROCESSING</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
</Appropriation>
</Award>
</rootTag>
