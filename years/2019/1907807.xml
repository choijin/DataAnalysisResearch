<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: A data-driven computational model of dyadic rapport: Learning and transforming nonverbal behavior in shared virtual environments.</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Social interaction is a complex and highly demanding task -- it can unfold in a harmonious and effortless way, yet sometimes also fail catastrophically. A critical determinant of success is whether or not the partners are able to establish rapport. Rapport impacts all communication contexts, from initial contact formation to private conflict resolution and business negotiations. While humans are sensitive to flaws in rapport, they frequently fail to identify the reasons or take counter measures. This project is motivated by the idea that new media technologies, such as social virtual reality (VR), can augment people's social-cognitive capacities in this regard and improve our communication skills in daily life interactions.  In relevant respects, machine capabilities can be superior to, and less biased than, human social perception. On the one hand, interactions taking place in VR allow the system to register behavioral details affecting rapport (such as movement, eye gaze, and facial expressions). Moreover, mobile sensor technologies can be seamlessly integrated into VR devices, such as headsets or controllers to measure the neurophysiological correlates of emotional, motivational, and attentional attunement. On the other hand computational power now allows us to run highly complex machine learning algorithms on standard personal computers. This project will leverage VR capture technologies, mobile neurophysiological sensing and deep learning methods to develop a bio-behavioral model of rapport. Based on this the project will develop and evaluate tools to monitor rapport in ongoing interactions and administer feedback to enable corrective actions that improve rapport. &lt;br/&gt;&lt;br/&gt;The investigators will meet the two objectives. First, they will accumulate an annotated interaction database consisting of 150 dyads (pairs of subjects in conversation) performing three different interaction tasks, with an overall duration of 30 minutes. The database will include speech, movement, gaze, EEG measures of concurrent brain activity, and cardiovascular measures. The interaction protocols will be annotated for rapport by groups of observers, and the subjects themselves will evaluate interaction quality and outcomes. Second, they will develop and validate machine learning algorithms that identify bio-behavioral rapport signatures in the annotated multichannel database, and predict perceived rapport and physiological responses from nonverbal behavior. This development will lead to a bio-behavioral model of rapport, which provides the basis for social AI components, capable of monitoring and facilitating rapport in ongoing avatar interactions. Long term goals are to integrate these tools in communication media beyond social VR or in real life interactions, depending on more advanced, portable and unobtrusive sensing devices.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/09/2019</MinAmdLetterDate>
<MaxAmdLetterDate>09/09/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1907807</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Reimers</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark Reimers</PI_FULL_NAME>
<EmailAddress>reimersm@msu.edu</EmailAddress>
<PI_PHON>5173538947</PI_PHON>
<NSF_ID>000521394</NSF_ID>
<StartDate>09/09/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gary</FirstName>
<LastName>Bente</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gary M Bente</PI_FULL_NAME>
<EmailAddress>gabente@msu.edu</EmailAddress>
<PI_PHON>5173559734</PI_PHON>
<NSF_ID>000678750</NSF_ID>
<StartDate>09/09/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vishnu</FirstName>
<LastName>Boddeti</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vishnu Boddeti</PI_FULL_NAME>
<EmailAddress>vishnu@msu.edu</EmailAddress>
<PI_PHON>5174320609</PI_PHON>
<NSF_ID>000711404</NSF_ID>
<StartDate>09/09/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ralf</FirstName>
<LastName>Schmaelzle</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ralf Schmaelzle</PI_FULL_NAME>
<EmailAddress>schmaelz@msu.edu</EmailAddress>
<PI_PHON>5173536629</PI_PHON>
<NSF_ID>000762186</NSF_ID>
<StartDate>09/09/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Michigan State University</Name>
<CityName>East Lansing</CityName>
<ZipCode>488242600</ZipCode>
<PhoneNumber>5173555040</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[426 Administration Bldg, Rm2]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>193247145</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MICHIGAN STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>053343976</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Michigan State University]]></Name>
<CityName>East Lansing</CityName>
<StateCode>MI</StateCode>
<ZipCode>488246402</ZipCode>
<StreetAddress><![CDATA[404 Wilson Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~300000</FUND_OBLG>
</Award>
</rootTag>
