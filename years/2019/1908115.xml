<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Understanding the Percept of Soft Objects for Designing Naturalistic Touch Displays</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>508000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
<PO_EMAI>bprabhak@nsf.gov</PO_EMAI>
<PO_PHON>7032924847</PO_PHON>
</ProgramOfficer>
<AbstractNarration>How can we replicate the sensation of touching a "soft" object such as a plum (fruit), or another's hand, or tissue during surgery? This is the central research question addressed in this project. How we feel an object's "compliance", that is, its rigidity or softness, is an important piece of information needed for building high fidelity touch interfaces. In addition to applications in entertainment and personal productivity, such interfaces could enable surgeons to distinguish gallbladder and prostate tissue and ducts from fat and bone, small children to feel a parent's hand, and consumers to inspect and compare products, clothing, and work pieces. This project seeks to understand how the touch interface provided by a finger pad must deform in space and time to adequately convey a natural sense of compliance. Proper control of the skin's deformation will inform the design of touch-enabled displays that feel natural and are mechanically efficient, rapidly configurable, and responsive. &lt;br/&gt;&lt;br/&gt;This project explores the connection between time-dependent cues at the finger pad surface and the percept of compliance, or softness. The central hypothesis is that time-dependent cues, or information in the rate of change of skin deformation over a spatial field, govern the encoding of compliance. With that information, this project aims to reproduce these skin deformation cues with a dynamic display. Three research tasks are planned for achieving these objectives: (i) Human discrimination tasks with natural objects such as fruits and tissues: here, an ink-based procedure will characterize contact area, force, and displacement relationships. (ii) Generation of skin deformation cues and digit kinematics: for this, engineered, elastic stimuli will replicate natural interactions yet remove per stimulus variability. Novel human subjects paradigms, imaging equipment, and data analysis algorithms will be developed to characterize continuous skin deformation and stretch in 3D. The relative importance of spatiotemporal cues will be analyzed using multi-dimensional scaling. (iii) Reproducing key softness percepts: A soft, transparent, multi-chamber hydraulic actuator will be designed using finite element analysis to produce dynamic, on-the-fly control of skin deformation. Overall, this project seeks to abstract cutaneous cues that underlie the percept of compliance, akin to vision, where color is wavelength in physics space but hue, saturation, and brightness in psychological space.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/15/2019</MinAmdLetterDate>
<MaxAmdLetterDate>04/09/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1908115</AwardID>
<Investigator>
<FirstName>Gregory</FirstName>
<LastName>Gerling</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gregory J Gerling</PI_FULL_NAME>
<EmailAddress>gregory-gerling@virginia.edu</EmailAddress>
<PI_PHON>4349240533</PI_PHON>
<NSF_ID>000389538</NSF_ID>
<StartDate>08/15/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>065391526</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RECTOR &amp; VISITORS OF THE UNIVERSITY OF VIRGINIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>065391526</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Virginia Main Campus]]></Name>
<CityName>Charlottesville</CityName>
<StateCode>VA</StateCode>
<ZipCode>229044747</ZipCode>
<StreetAddress><![CDATA[151 Engineer's Way]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~500000</FUND_OBLG>
<FUND_OBLG>2020~8000</FUND_OBLG>
</Award>
</rootTag>
