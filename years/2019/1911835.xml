<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Cognitive mechanisms underlying the spread of conventions in communities</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2019</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>138000.00</AwardTotalIntnAmount>
<AwardAmount>138000</AwardAmount>
<AwardInstrument>
<Value>Fellowship Award</Value>
</AwardInstrument>
<Organization>
<Code>04010000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SMA</Abbreviation>
<LongName>SBE Off Of Multidisciplinary Activities</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Josie S. Welkom</SignBlockName>
<PO_EMAI>jwelkom@nsf.gov</PO_EMAI>
<PO_PHON>7032927376</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award was provided as part of NSF's Social, Behavioral and Economic Sciences Postdoctoral Research Fellowships (SPRF) program. The goal of the SPRF program is to prepare promising, early career doctoral-level scientists for scientific careers in academia, industry or private sector, and government. SPRF awards involve two years of training under the sponsorship of established scientists and encourage Postdoctoral Fellows to perform independent research. NSF seeks to promote the participation of scientists from all segments of the scientific community, including those from underrepresented groups, in its research programs and activities; the postdoctoral period is an important level of professional development in attaining this goal. Each Postdoctoral Fellow must address important scientific questions that advance their respective disciplinary fields. Under the sponsorship of Thomas Griffiths and Adele Goldberg at Princeton University, this postdoctoral fellowship award supports an early career scientist investigating how linguistic conventions spread through communities. To successfully communicate using language, speakers must share consistent conventions about the meanings of words. As modern communication media has revealed, however, these linguistic conventions are often in flux: novel meanings rapidly spread across social networks and become widely adopted. At the same time, speakers across different sub-communities may vary substantially in which conventions they find meaningful (e.g. the acronyms filling scientific journals). &lt;br/&gt;&lt;br/&gt;This project investigates the adaptive cognitive mechanisms that allow speakers to navigate this complex landscape of meaning, and how these mechanisms may in turn explain how conventions spread within and across communities. The proposed model of how social expectations are represented and generalized lays the groundwork for applying formal models to calibrate interventions on social norms and conventions more broadly. These interventions hold promise as solutions to large-scale social problems ranging from public health concerns like smoking cigarettes to participation in collective actions like voting. Additionally, this work could contribute to understanding how linguistic conventions vary across ethnic or SES-based communities. Using a series of large-scale behavioral studies of referential communication on social networks and state-of-the-art computational cognitive models of language use, the proposed work tests a novel hypothesis about how speakers rationally update and deploy their mental representations of linguistic conventions in different contexts. This hypothesis is made formally precise in a hierarchical Bayesian model and rigorously compared against previous models using new behavioral data. First, the project will examine the mechanisms of generalization supporting the spread of new linguistic conventions within a community. Second, the project will investigate how speakers learn and flexibly switch between different sets of conventions in different communities. Third, the hierarchical model will be extended using a deep neural network architecture to produce finer-grained predictions about natural language descriptions, thus enabling further theory development. This project uses ideas from computational cognitive science to make new connections between two interdisciplinary traditions (psycholinguistics and cultural evolution) that deepen our understanding of how large groups of people coordinate their beliefs to better understand one another.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/30/2019</MinAmdLetterDate>
<MaxAmdLetterDate>06/30/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1911835</AwardID>
<Investigator>
<FirstName>Adele</FirstName>
<LastName>Goldberg</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adele E Goldberg</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>6092588772</PI_PHON>
<NSF_ID>000221424</NSF_ID>
<StartDate>06/30/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Thomas</FirstName>
<LastName>Griffiths</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Thomas L Griffiths</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>6176422701</PI_PHON>
<NSF_ID>000488584</NSF_ID>
<StartDate>06/30/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Hawkins</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert Hawkins</PI_FULL_NAME>
<EmailAddress/>
<PI_PHON>2175496923</PI_PHON>
<NSF_ID>000789462</NSF_ID>
<StartDate>06/30/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Hawkins, Robert</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber/>
<StreetAddress/>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM/>
<ORG_LGL_BUS_NAME/>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>040Y</Code>
<Text>(SPRF-FR) SBE Postdoctoral Res</Text>
</ProgramElement>
<ProgramReference>
<Code>7137</Code>
<Text>POSTDOCTORAL FELLOWSHIPS</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~138000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">Drop into any conversation between friends and you&rsquo;ll be wading in a stream of shorthand, lingo, slang, names, and inside jokes &mdash; many of which may be meaningful to them alone. One of the most remarkable aspects of language use is that we are able to keep all these meanings straight: we have a pretty good idea of&nbsp;<em>who</em>&nbsp;will understand&nbsp;<em>what</em>. It is safe to expect nearly all English speakers, even total strangers, to have a (roughly) similar concept in mind when I say the word "dog." However, only a much smaller community of enthusiasts is likely to understand a reference to "Norwich Terriers," and the set of people I expect to understand the name&nbsp;"Toby"&nbsp;is even smaller, limited primarily to family members and close friends.</p> <p class="p1">In this project, we asked how our knowledge of language becomes so deeply intertwined with our knowledge of our social world. Using a mathematical model called a hierarchical Bayesian network, we were able to isolate the limitations of previous models to their assumptions about how new conventions are&nbsp;<em>generalized to new partners</em>. We introduce a&nbsp;<em>partial-pooling</em>&nbsp;model that resolves these limitations through a more sophisticated cognitive model of generalization. Specifically, our model represents expectations about linguistic meaning at different levels of social structure: some conventions are shared at the level of specific partners (e.g. inside jokes and shorthand that is only transparent to those who were present in a previous conversation), some are shared at the level of specific communities (e.g. technical jargon that is largely unknown outside a scientific sub-field), and some are shared nearly universally within the broader language community. In other words, the spread of linguistic conventions must be grounded in well-validated cognitive models of linguistic generalization, guided by structured social knowledge.&nbsp;</p> <p class="p1">Our findings are organized into three specific Objectives.</p> <p class="p1">First, we implemented complete-pooling models, no-pooling models, and partial-pooling models using a special programming language for probabilistic models and ran a series of simulations on small networks of interacting agents&nbsp;to compare each model's predictions against one another. We then used state-of-the-art software to write a large-scale web experiment that enabled precisely the same experimental design to be conducted with large groups of&nbsp;<em>human</em>&nbsp;participants communicating in real time. Two key behavioral signatures distinguished our proposed model from alternatives: (i) "jumps," or discontinuities when switching from the end of an extended interaction with one partner to the beginning of an interaction with the next partner, and (ii) "drops," or steady increases in the willingness to extend a convention formed with previous partners to interactions with new partners, leading the network to converge as a whole. Only the partial-pooling model was able to account for both of these patterns in the empirical data.</p> <p class="p1">Second, having established a central role for hierarchical social knowledge in linguistic convention formation, we asked how our initial two-layer hierarchy of individuals and populations may need to be enriched with further levels of social structure. Motivated by the ubiquity of code-switching --&nbsp;the ability to retrieve and use different conventions with different partners -- we hypothesized that new linguistic conventions may not be generalized to the full population but only to relevant<em>&nbsp;social groups</em>&nbsp;or&nbsp;<em>communities</em>. We tested this hypothesis in another large-scale web experiment, where we found that conventions formed within a community were generalized to novel in-group members but not to out-group members. The spread of conventions may therefore be sensitive not only to partner identity but also to perceived or inferred social group identity.</p> <p class="p1">Finally, we confronted the long-standing&nbsp;<em>scalability&nbsp;gap</em>&nbsp;between the mechanisms of human convention formation and those proposed by existing theories. Whatever cognitive mechanisms humans are using to adapt to one another are somehow&nbsp;<em>tractable</em>&nbsp;across the vast vocabulary of natural language and the vast world&nbsp;of concepts that we regularly communicate about, while existing models are largely intractable outside toy domains. To address this gap, we developed a new algorithm, inspired by our probabilistic model, to equip state-of-the-art neural language models with the ability to form new conventions with human partners. We deployed our model in&nbsp;real-time interactions with human partners over the web; unlike static models, our adaptive model was able to coordinate with its partner and communicate more effectively over time.</p> <p class="p1">Taken together, our findings in this project provide a novel computational basis for the complex&nbsp;interplay between individual social cognition and emergent collective behavior, yielding new connections between traditional domains of psycholinguistics, social psychology, natural language processing, and cultural evolution.</p> <p class="p1">&nbsp;</p><br> <p>            Last Modified: 08/10/2021<br>      Modified by: Robert&nbsp;Hawkins</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555682643_CleanShot2021-08-09at17.31.03@2x--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555682643_CleanShot2021-08-09at17.31.03@2x--rgov-800width.jpg" title="different layers of analysis"><img src="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555682643_CleanShot2021-08-09at17.31.03@2x--rgov-66x44.jpg" alt="different layers of analysis"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Conventions are emergent properties of groups, but each person only has the opportunity to talk with a relatively small group of partners. The aim of this project is to evaluate a computational theory of how individual minds are able to generalize conventions at different levels of social structure.</div> <div class="imageCredit">Robert D Hawkins</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Robert&nbsp;Hawkins</div> <div class="imageTitle">different layers of analysis</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555447118_CleanShot2021-08-09at17.28.14@2x--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555447118_CleanShot2021-08-09at17.28.14@2x--rgov-800width.jpg" title="schematic of adaptive view"><img src="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555447118_CleanShot2021-08-09at17.28.14@2x--rgov-66x44.jpg" alt="schematic of adaptive view"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Under an adaptive view of meaning in language, we initially use our 'best guess' about what words will make sense to a new partner, and adjust our beliefs based on feedback from their behavior. As both partners update their beliefs, they are able to dynamically coordinate on new conventions.</div> <div class="imageCredit">Robert D Hawkins</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Robert&nbsp;Hawkins</div> <div class="imageTitle">schematic of adaptive view</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555898548_CleanShot2021-08-09at17.36.55@2x--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555898548_CleanShot2021-08-09at17.36.55@2x--rgov-800width.jpg" title="model comparison results"><img src="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628555898548_CleanShot2021-08-09at17.36.55@2x--rgov-66x44.jpg" alt="model comparison results"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Our partial pooling model best fits the empirical data for (A) speaker reduction, and (B) network convergence across three partners. Vertical lines mark boundaries where new partners were introduced, and the thin grey line represents beliefs about a novel partner at each point in time.</div> <div class="imageCredit">Robert D Hawkins</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Robert&nbsp;Hawkins</div> <div class="imageTitle">model comparison results</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628556150310_CleanShot2021-08-09at17.40.36@2x--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628556150310_CleanShot2021-08-09at17.40.36@2x--rgov-800width.jpg" title="extending model to multi communities"><img src="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628556150310_CleanShot2021-08-09at17.40.36@2x--rgov-66x44.jpg" alt="extending model to multi communities"></a> <div class="imageCaptionContainer"> <div class="imageCaption">In Objective (2) we extend our hierarchical model of conventionformation to represent not only partner-specific common ground but also the latent structure of social communities for which language may vary (e.g. 'parents' vs. 'co-workers' vs. 'baseball fans')</div> <div class="imageCredit">Robert D Hawkins</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Robert&nbsp;Hawkins</div> <div class="imageTitle">extending model to multi communities</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628572411534_CleanShot2021-08-09at22.08.48@2x--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628572411534_CleanShot2021-08-09at22.08.48@2x--rgov-800width.jpg" title="continual adaptation for neural language models"><img src="/por/images/Reports/POR/2021/1911835/1911835_10616197_1628572411534_CleanShot2021-08-09at22.08.48@2x--rgov-66x44.jpg" alt="continual adaptation for neural language models"></a> <div class="imageCaptionContainer"> <div class="imageCaption">We propose a tractable algorithm that scales up convention formation to unconstrained natural language. The basic idea is to take a small number of local gradient steps after each observation of a partner's behavior (e.g. naming a picture), gradually approximating language model they are using.</div> <div class="imageCredit">Robert D Hawkins</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Robert&nbsp;Hawkins</div> <div class="imageTitle">continual adaptation for neural language models</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Drop into any conversation between friends and you’ll be wading in a stream of shorthand, lingo, slang, names, and inside jokes &mdash; many of which may be meaningful to them alone. One of the most remarkable aspects of language use is that we are able to keep all these meanings straight: we have a pretty good idea of who will understand what. It is safe to expect nearly all English speakers, even total strangers, to have a (roughly) similar concept in mind when I say the word "dog." However, only a much smaller community of enthusiasts is likely to understand a reference to "Norwich Terriers," and the set of people I expect to understand the name "Toby" is even smaller, limited primarily to family members and close friends. In this project, we asked how our knowledge of language becomes so deeply intertwined with our knowledge of our social world. Using a mathematical model called a hierarchical Bayesian network, we were able to isolate the limitations of previous models to their assumptions about how new conventions are generalized to new partners. We introduce a partial-pooling model that resolves these limitations through a more sophisticated cognitive model of generalization. Specifically, our model represents expectations about linguistic meaning at different levels of social structure: some conventions are shared at the level of specific partners (e.g. inside jokes and shorthand that is only transparent to those who were present in a previous conversation), some are shared at the level of specific communities (e.g. technical jargon that is largely unknown outside a scientific sub-field), and some are shared nearly universally within the broader language community. In other words, the spread of linguistic conventions must be grounded in well-validated cognitive models of linguistic generalization, guided by structured social knowledge.  Our findings are organized into three specific Objectives. First, we implemented complete-pooling models, no-pooling models, and partial-pooling models using a special programming language for probabilistic models and ran a series of simulations on small networks of interacting agents to compare each model's predictions against one another. We then used state-of-the-art software to write a large-scale web experiment that enabled precisely the same experimental design to be conducted with large groups of human participants communicating in real time. Two key behavioral signatures distinguished our proposed model from alternatives: (i) "jumps," or discontinuities when switching from the end of an extended interaction with one partner to the beginning of an interaction with the next partner, and (ii) "drops," or steady increases in the willingness to extend a convention formed with previous partners to interactions with new partners, leading the network to converge as a whole. Only the partial-pooling model was able to account for both of these patterns in the empirical data. Second, having established a central role for hierarchical social knowledge in linguistic convention formation, we asked how our initial two-layer hierarchy of individuals and populations may need to be enriched with further levels of social structure. Motivated by the ubiquity of code-switching -- the ability to retrieve and use different conventions with different partners -- we hypothesized that new linguistic conventions may not be generalized to the full population but only to relevant social groups or communities. We tested this hypothesis in another large-scale web experiment, where we found that conventions formed within a community were generalized to novel in-group members but not to out-group members. The spread of conventions may therefore be sensitive not only to partner identity but also to perceived or inferred social group identity. Finally, we confronted the long-standing scalability gap between the mechanisms of human convention formation and those proposed by existing theories. Whatever cognitive mechanisms humans are using to adapt to one another are somehow tractable across the vast vocabulary of natural language and the vast world of concepts that we regularly communicate about, while existing models are largely intractable outside toy domains. To address this gap, we developed a new algorithm, inspired by our probabilistic model, to equip state-of-the-art neural language models with the ability to form new conventions with human partners. We deployed our model in real-time interactions with human partners over the web; unlike static models, our adaptive model was able to coordinate with its partner and communicate more effectively over time. Taken together, our findings in this project provide a novel computational basis for the complex interplay between individual social cognition and emergent collective behavior, yielding new connections between traditional domains of psycholinguistics, social psychology, natural language processing, and cultural evolution.         Last Modified: 08/10/2021       Submitted by: Robert Hawkins]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
