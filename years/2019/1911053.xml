<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Strong-Story Narrative Planning for Authoring Proactive Intelligent Virtual Environments</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>493256.00</AwardTotalIntnAmount>
<AwardAmount>493256</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
<PO_EMAI>wbainbri@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Interactive virtual worlds have a wide variety of applications, including military training simulations, classroom tutoring systems, therapeutic recreation of events, and entertainment. These worlds invite the user to take on the role of one character while the world and its cast of virtual characters are controlled by the system. Together, the user and the system create an interactive story narrative. To be meaningful and keep the user engaged, the user must be free to act and see the results of their choices, but designing all the branches of an interactive narrative by hand quickly becomes too much work for a human designer. Artificial intelligence can mitigate this problem by creating the narrative automatically as the user makes choices. This project will address several of the technical limitations that are currently preventing scientists from creating realistic, adaptive virtual environments. One key limitation is that algorithms for exploring the space of possible narratives and choosing the best one are currently too slow to be practical, especially in the face of the unpredictable choices that human beings make. Another is that it's hard for the people who design virtual environments to make sure the narratives have the right structure and teach the right information. This project will develop and test technologies that address these limitations in the context of a virtual reality training simulation that helps police officers learn how and when to use force when dealing with the communities they serve. Virtual reality training provides a safe, affordable, repeatable way to provide realistic and memorable training for dangerous situations. The artificial intelligence techniques developed for this project will make sure the training simulation is realistic and provides effective teaching no matter what choices the user makes.&lt;br/&gt;&lt;br/&gt;Most previous approaches for using AI to control virtual environments have focused on creating realistic individual virtual humans. A world full of realistic characters can be realistic, but there is no way for the designer to impose pedagogic or aesthetic structure on the narrative, limiting their usefulness for training. This project will extend previous research on narrative planning algorithms to produce a centralized narrative planner that reasons far into the future about the user, the world, and all of its virtual characters to achieve the same level of narrative structure and quality created by hand-authored experiences, the realistic character behavior of the previously mentioned unstructured environments, and the user agency of open world environments where the player can take any action at any time. Narrative planners anticipate millions of possible futures and are constrained by models of how humans behave according to their beliefs and intentions. Planning a narrative far in advance is computationally expensive, but it can be done at a human level or better by employing non-Markovian heuristic search that accounts for narrative structure to explore only promising partial stories. These same algorithms and models can then be used to help the designers of virtual environments understand what is possible, impossible, likely, and unlikely in the virtual worlds they create. The same models of belief and intention used to model realistic virtual humans can be used to anticipate and understand the human user, and when the user acts unexpectedly, the planner's ability to anticipate millions of possibilities can adapt the narrative automatically to compensate. These algorithms will be validated through a number of computational experiments and finally by measuring their effectiveness in an adaptive virtual reality police training simulation used by real police officers.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/16/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/16/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1911053</AwardID>
<Investigator>
<FirstName>Stephen</FirstName>
<LastName>Ware</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stephen G Ware</PI_FULL_NAME>
<EmailAddress>sgware@cs.uky.edu</EmailAddress>
<PI_PHON>8595622615</PI_PHON>
<NSF_ID>000678546</NSF_ID>
<StartDate>08/16/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Kentucky Research Foundation</Name>
<CityName>Lexington</CityName>
<CountyName>FAYETTE</CountyName>
<ZipCode>405260001</ZipCode>
<PhoneNumber>8592579420</PhoneNumber>
<StreetAddress>109 Kinkead Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>KY06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>939017877</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF KENTUCKY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007400724</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name>University of Kentucky</Name>
<CityName>Lexington</CityName>
<CountyName>FAYETTE</CountyName>
<StateCode>KY</StateCode>
<ZipCode>405260001</ZipCode>
<StreetAddress>109 Kinkhead Hall</StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>KY06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~493256</FUND_OBLG>
</Award>
</rootTag>
