<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Adaptive Sonification to Improve Balance during Everyday Mobility</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2025</AwardExpirationDate>
<AwardTotalIntnAmount>822200.00</AwardTotalIntnAmount>
<AwardAmount>822200</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Scheidt</SignBlockName>
<PO_EMAI>rscheidt@nsf.gov</PO_EMAI>
<PO_PHON>7032922477</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Faculty Early Career Development (CAREER) grant will use machine learning and wearable technology to identify balance and gait deficits in fall-prone older adults and to deliver personalized auditory biofeedback ("sonified biofeedback") designed to improve dynamic balance while walking. Turning has been linked to recurrent falls in older adults because it imposes mechanical conflict between balancing and changing direction. Falls in older adults frequently lead to injury and sometimes death. By some accounts, turning-while-walking can comprise up to 50 percent of steps taken in any given day. Retraining balance strategies used during turning-while-walking has potential to reduce fall risk. This project will identify relationships between person-specific balance strategies used during turning and other factors including physiological and cognitive capabilities - such as strength and capacity for spatial reasoning - as well as environmental factors such as the presence or absence of obstacles. This information will be used to design personalized auditory biofeedback tuned to convey information about movement kinematics and foot forces in a way that facilitates dynamic balance during walking. An initial set of experiments will test human perception and motor responses to sonified biofeedback of dynamic balance information. Additional experiments will test the ability of fall-prone older adults to use personalized biofeedback to improve dynamic balance during turns. This project advances the national health by developing a machine learning approach to the diagnosis of balance deficits in older adults as well as a novel sonified biofeedback approach to improving dynamic balance in that population. The project includes an education and outreach plan, including an innovative “Artist in Residence” program, that will expose underrepresented groups to cutting edge engineering and scientific research in a way that is engaging for engineers and young artists alike. &lt;br/&gt;&lt;br/&gt;This project tests the hypothesis that interactive sonified biofeedback can improve balance strategies used by fall-risk older adults during turning-while-walking. This project has three research objectives. In the first, the PI will conduct human subjects experiments to characterize person-specific relationships between dynamic balance strategies used during turns, physiological and cognitive capabilities, and environmental factors. Participants will walk and turn within the controlled setting of the research lab and outdoors while wearing technology that can sense and transmit movement kinematics and ground reaction forces in real-time. For the second objective, the PI will establish how sonification can be used to train specific balance strategies and the extent to which those strategies can be retained and used without dependency on concurrent biofeedback.  Working in conjunction with a sound designer, the PI will develop soundscapes that sonify balance metrics during unconstrained body movements, evaluate their ability to modulate measures of stability in real-time during repeated training sessions, and test their ability to elicit long-lasting behavioral change. In the third objective, the PI will test the ability of machine learning models to diagnose person-specific balance deficits during turns compared to clinician diagnoses, and to design personalized biofeedback soundscapes that can mitigate clinician-diagnosed balance deficits.  Here, the PI will use Factored Conditional Restricted Boltzman Machines to generate person-specific, turn-type specific, and deficit-specific models that will be able to generate personalized sonified biofeedback to improve balance during turns. This project will advance fundamental understanding of an intelligent machine can communicate intent or otherwise shape the behavior of its human user through physical interaction.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/31/2020</MinAmdLetterDate>
<MaxAmdLetterDate>01/31/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1944207</AwardID>
<Investigator>
<FirstName>Antonia</FirstName>
<LastName>Zaferiou</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Antonia Zaferiou</PI_FULL_NAME>
<EmailAddress>azaferio@stevens.edu</EmailAddress>
<PI_PHON>2012163662</PI_PHON>
<NSF_ID>000806052</NSF_ID>
<StartDate>01/31/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stevens Institute of Technology</Name>
<CityName>HOBOKEN</CityName>
<ZipCode>070305991</ZipCode>
<PhoneNumber>2012168762</PhoneNumber>
<StreetAddress>CASTLE POINT ON HUDSON</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>064271570</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>STEVENS INSTITUTE OF TECHNOLOGY (INC)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>064271570</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Stevens Institute of Technology]]></Name>
<CityName>Hoboken</CityName>
<StateCode>NJ</StateCode>
<ZipCode>070305991</ZipCode>
<StreetAddress><![CDATA[Castle Point on Hudson]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>058Y</Code>
<Text>M3X - Mind, Machine, and Motor</Text>
</ProgramElement>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramReference>
<Code>070E</Code>
<Text>INTEG OF HUMAN &amp; COGNITIVE</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7632</Code>
<Text>HUMAN-ROBOT INTERACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~822200</FUND_OBLG>
</Award>
</rootTag>
