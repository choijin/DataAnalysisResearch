<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: RI: AF: Medium: Exchanging Knowledge Beyond Data Between Human and Machine Learner</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>498930.00</AwardTotalIntnAmount>
<AwardAmount>498930</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent advances in deep learning have made dramatic progress in solving basic perceptual tasks such as speech recognition and object detection. To pave the way for the many human-centered applications that these advances might enable, in healthcare for instance, it is important to move beyond classification problems: to think of machine learning systems as producing not just category predictions, but also the reasons for them. Moreover, these patterns of reasoning need to be comprehensible to humans. To enable this, this project will focus on the exchange of knowledge between humans and machine learning systems and how such exchange of knowledge beyond data can lead to better predictions that are also human-interpretable. The project will result in technological advances that will have the potential to significantly impact the usability of machine learning in human-facing applications.&lt;br/&gt;&lt;br/&gt;The technical aims of this project are developed along two broad themes. The first addresses the question, "How can we involve human feedback in the machine learning process to create succinct models that are interpretable and generate predictions that are explainable?" By enabling humans to provide rich feedback in the form of rules-of-thumb as relational knowledge, the project aims to derive succinct interpretable machine learning models that are amenable to simple explanations that are more compatible with the causal world-view of humans. To enhance the interpretability of machine learning, the project will further explore how human feedback based on relational knowledge can be leveraged to reduce the size of data sets required to train accurate models. The second addresses the question, "How can we encode and exploit relational information in deriving interpretable and explainable models for reasoning?" The project will explore the encoding of relational knowledge in both vector spaces and logical models and further investigate how relational knowledge can be used for analogical reasoning, semantic understanding, and relational queries.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/15/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1956441</AwardID>
<Investigator>
<FirstName>Hongjing</FirstName>
<LastName>Lu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Hongjing Lu</PI_FULL_NAME>
<EmailAddress>hongjing@ucla.edu</EmailAddress>
<PI_PHON>3102062587</PI_PHON>
<NSF_ID>000498799</NSF_ID>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Guy</FirstName>
<LastName>Van den Broeck</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Guy Van den Broeck</PI_FULL_NAME>
<EmailAddress>guyvdb@cs.ucla.edu</EmailAddress>
<PI_PHON>3107940102</PI_PHON>
<NSF_ID>000711612</NSF_ID>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UCLA, Computer Science Dept.]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951596</ZipCode>
<StreetAddress><![CDATA[404 Westwood Plaza, 368 Engr VI.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~498930</FUND_OBLG>
</Award>
</rootTag>
