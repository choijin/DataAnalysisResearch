<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Exploring Rationale behind Visual Understanding: Combining Attention and Reasoning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>285029.00</AwardTotalIntnAmount>
<AwardAmount>285029</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent progress in deep learning has resulted in models that show significant performance gains in computer vision tasks. This project aims to bridge the current gap between the increasing performance in intelligent systems and the lack of understanding in the complex task-solving process. With the overarching goal of understanding and modeling the process, this project studies two intertwined mechanisms heavily involved in task-solving -- attention and reasoning -- and develops a sound framework to integrate the two. It will serve as a critical step forward to untangling the process of solving a visual task and alleviating the black-box problem in machine learning. The research will build attention and reasoning capabilities into machines, thus empowering applications in a broad spectrum of artificial intelligence tasks including medical diagnosis and treatment, robotics, and education. The principal investigator will organize workshops and seminars, and make project results publicly available. The project also aims at integrated research and education with a focus on increased diversity, through K-12 outreach activities, student mentoring, and curriculum development.&lt;br/&gt;&lt;br/&gt;This project focuses on both dataset and model development, as well as enabling new methods for network visualization, interpretation, and diagnosis. More specifically, the project develops: (1) a new dataset with human eye movements and textual explanations, to understand critical factors that contribute to task performance; (2) a framework where models devised in the framework make a first step to demonstrate the process of task-solving by showing attention and reasoning capabilities; and (3) a novel layer-wise network diagnosis method considering both performance and interpretability of each network layer. Addressing these questions will not only boost model performance but open the black-box of the decision-making process of a visual task as well as the structure of the deep neural networks.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/22/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1908711</AwardID>
<Investigator>
<FirstName>Qi</FirstName>
<LastName>Zhao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qi Zhao</PI_FULL_NAME>
<EmailAddress>qzhao@umn.edu</EmailAddress>
<PI_PHON>6126245599</PI_PHON>
<NSF_ID>000753440</NSF_ID>
<StartDate>07/22/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Minnesota-Twin Cities</Name>
<CityName>Minneapolis</CityName>
<ZipCode>554552070</ZipCode>
<PhoneNumber>6126245599</PhoneNumber>
<StreetAddress>200 OAK ST SE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<StateCode>MN</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MN05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>555917996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MINNESOTA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>117178941</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Minnesota-Twin Cities]]></Name>
<CityName>Minneapolis</CityName>
<StateCode>MN</StateCode>
<ZipCode>554550169</ZipCode>
<StreetAddress><![CDATA[4-192, 200 Union Street SE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Minnesota</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MN05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~285029</FUND_OBLG>
</Award>
</rootTag>
