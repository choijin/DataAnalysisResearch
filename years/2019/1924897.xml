<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: FND: Consistent distributed visual-inertial estimation and perception for cooperative unmanned aerial vehicles</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>380049.00</AwardTotalIntnAmount>
<AwardAmount>380049</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Erion Plaku</SignBlockName>
<PO_EMAI>eplaku@nsf.gov</PO_EMAI>
<PO_PHON>7032928695</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is in response to the emerging demand for ubiquitous deployment of autonomous robots in real-world applications. In particular, thanks to their small size, agile maneuverability, and low-altitude flight ability even in complex environments, unmanned aerial vehicles (UAVs) have witnessed significant progress over the last decade. The ubiquitous availability of small and inexpensive UAVs that are equipped with sensing, processing, and communication capabilities, will make it possible to deploy them in teams that can collaborate to accomplish missions more efficiently and robustly than a single vehicle. Assisted by technological advances in sensing, computing, communication, and hardware design and manufacturing, in the coming years, cooperative UAVs will become valuable tools in critical applications ranging from environmental monitoring and emergency response to precision agriculture. However, when developing cooperative UAV systems, many challenges remain, among which, one of the biggest is the stringent resource limitations (such as limited computation power, communication bandwidth, and energy) that UAVs are faced with. Performing cooperative estimation and perception under resource constraints, incurs many challenges that must be addressed during the UAV operations as well as during the design of UAV systems. &lt;br/&gt;&lt;br/&gt;In this project, the investigators will design scalable, robust and distributed state estimation and 3D perception for cooperative UAVs using visual and inertial measurements under computation and communication constraints, thus providing 3D scene understanding and spatial cognition to support intelligent decision making. To this end, resource-adaptive consistent visual-inertial estimation will be formulated as constrained optimization to optimally utilize available resources. Leveraging deep learning/AI techniques, the project team will design deep neural networks to power visual-inertial 3D perception in order to semantically and spatially understand environments. To achieve optimal performance for given resources or determine cost-effective system design for desired performance, the project team will develop formal tools for characterization and co-design of UAV hardware and software systems. By technologically enabling ubiquitous deployment of UAVs, the results of this project will foster innovative applications in robotics such as aerial transportation during humanitarian aid and disaster relief, thus boosting economic development. Moreover, this project will promote hands-on learning in undergraduate education in mechanical engineering and enrich graduate curriculum in robotics, as well as create opportunities for students to perform meaningful research.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/04/2019</MinAmdLetterDate>
<MaxAmdLetterDate>09/04/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1924897</AwardID>
<Investigator>
<FirstName>Guoquan</FirstName>
<LastName>Huang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Guoquan Huang</PI_FULL_NAME>
<EmailAddress>ghuang@udel.edu</EmailAddress>
<PI_PHON>3028318796</PI_PHON>
<NSF_ID>000677461</NSF_ID>
<StartDate>09/04/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Delaware</Name>
<CityName>Newark</CityName>
<ZipCode>197160099</ZipCode>
<PhoneNumber>3028312136</PhoneNumber>
<StreetAddress>210 Hullihen Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<StateCode>DE</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DE00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>059007500</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF DELAWARE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>059007500</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Delaware]]></Name>
<CityName>Newark</CityName>
<StateCode>DE</StateCode>
<ZipCode>197162553</ZipCode>
<StreetAddress><![CDATA[210 Hullihen Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DE00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~380049</FUND_OBLG>
</Award>
</rootTag>
