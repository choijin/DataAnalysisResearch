<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RAPID: A Smart and Mobile Sensor Fusion Framework for Earthquake Hazard Reduction, Situational Assessment, and Relief Efforts</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>98516.00</AwardTotalIntnAmount>
<AwardAmount>98516</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Corman</SignBlockName>
<PO_EMAI>dcorman@nsf.gov</PO_EMAI>
<PO_PHON>7032928754</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Natural disasters including earthquakes, tsunamis, hurricanes and anthropogenic disasters, such as wildfires, are dynamic situations requiring constant monitoring as numerous hazards are constantly emerging that hinder humanitarian efforts and create deadly conditions for rescue workers and victims. Most disaster area assessment, and search and rescue efforts, rely heavily on visual imagery captured from cell phones, aerial video and other forms of media. Currently, real-time assessment for disasters depends entirely on the human operator's ability to visually identify the subject of interest in the video, or images captured. Further, damaged buildings and roadways, debris, smoke, fire, and environmental conditions such as rain complicate the human observer's ability to monitor situations for detecting victims and hazards. It is essential that rescuers can assess hazardous conditions before risking their lives and be armed with smart technologies that enable them to respond to dynamic situations.   The recent events in Southern California (earthquakes) and Louisiana (Hurricane Barry) provide perishable data that will enable maturation of the proposed research activities.  This plus the integration within the Smart Mobile Disaster Data Collection unit for response provides further justification of the RAPID award mechanism. &lt;br/&gt;&lt;br/&gt;The researchers will create a Smart Mobile Disaster Data Collection and Assessment tool for detecting and mapping out situational hazards using intelligent data fused information collected from multiple sensor technologies. Furthermore, this project aims to create a first-of-its-kind public database of collected imagery and media from disasters to help researchers and agencies share information or to assist in developing best practices and collaborative strategies. This project will also enable better visualization of disparate sources of data, thus making it conducive for human operator to detect hazards and victims. This research will also enhance safety and security applications across a wide range of areas including firefighting, disaster relief, and search-and-rescue. The approach of seamlessly utilizing and visualizing sensor information in a situational map to guide responders' actions and enhance their efficiency reduces the risk factor for responders.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/27/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/27/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1942053</AwardID>
<Investigator>
<FirstName>Karen</FirstName>
<LastName>Panetta</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Karen A Panetta</PI_FULL_NAME>
<EmailAddress>Karen@eecs.tufts.edu</EmailAddress>
<PI_PHON>6176275976</PI_PHON>
<NSF_ID>000094986</NSF_ID>
<StartDate>08/27/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Tufts University</Name>
<CityName>Boston</CityName>
<CountyName/>
<ZipCode>021111817</ZipCode>
<PhoneNumber>6176273696</PhoneNumber>
<StreetAddress>136 Harrison Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073134835</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF TUFTS COLLEGE INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073134835</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Tufts University]]></Name>
<CityName>Medford</CityName>
<CountyName/>
<StateCode>MA</StateCode>
<ZipCode>021555530</ZipCode>
<StreetAddress><![CDATA[200 College Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7918</Code>
<Text>CPS-Cyber-Physical Systems</Text>
</ProgramElement>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<ProgramReference>
<Code>7918</Code>
<Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~98516</FUND_OBLG>
</Award>
</rootTag>
