<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Performance-Guided Synthesis of Virtual Environments for Personalized Training</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2025</AwardExpirationDate>
<AwardTotalIntnAmount>533321.00</AwardTotalIntnAmount>
<AwardAmount>231210</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
<PO_EMAI>bprabhak@nsf.gov</PO_EMAI>
<PO_PHON>7032924847</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Virtual Reality (VR) promises to provide a compelling, effective, and convenient means for training and reskilling the workforce. The objective of this project is to devise a computational design framework for guiding the synthesis of personalized virtual training environments for human performance. Designers and general users can intuitively apply this framework for synthesizing a variety of immersive and engaging VR training scenarios in a fully automatic, fast, scalable, and low-cost manner. As a showcase of the proposed framework, the project will demonstrate how to synthesize personalized virtual training environments for workforce training, such as safety inspection training for employees, workplace supervisors, and safety inspectors. This research project offers a novel interdisciplinary perspective for generating personalized VR training content by bringing together expertise and insights from human-computer interaction, virtual reality, computer graphics, machine learning, and optimization, as well as domain expertise in instructional design, safety, emergency management, and engineering. Designers and general users can use this framework to synthesize personalized VR training content for a variety of scenarios such as rehabilitation, safety training, disaster response training, as well as workforce training for different domains such as manufacturing, construction, logistics, transportation, retail management, and public safety.&lt;br/&gt;&lt;br/&gt;To achieve the project’s objectives, the researchers will address the following research question: (1) How to track human performance under virtual scenarios? A VR station will be set up which is capable of tracking multimodal body data such as gaze, body pose, hand movement, and the locomotion of a trainee in performing tasks in a virtual workplace. Based on such tracked data, machine learning models are trained to analyze and characterize the trainee’s skill levels. (2) How to synthesize virtual environments for personalized training? Optimization approaches will be formulated for synthesizing realistic and highly immersive virtual environments for adaptively training the trainee considering his/her skill levels, preferences, and personal training goals. (3) How to evaluate VR training effects? The investigator will evaluate the effectiveness of the synthesized VR training experiences by comparing with alternative training approaches quantitatively in terms of performance gain and knowledge retention; and qualitatively by obtaining domain experts’ and participants’ feedback about the effectiveness, enjoyment, and engagement of the training experience. To facilitate easy deployment and widespread adoption of personalized VR training, the investigator will publicly disseminate the software tools and toolkits devised through project websites, workshops, and research papers. In addition, the investigator will disseminate the research by (1) setting up an open-access VR station at the George Mason University’s Makerspace where faculty, students, and staff from various disciplines can conveniently experience personalized VR training; (2) organizing interdisciplinary VR training workshops and demo days to disseminate the VR training research findings, to showcase the VR training demos to the public, and to stimulate the research and adoption of VR training in different disciplines; (3) broadening the participation of first-generation underrepresented undergraduate students in computing and VR training research via a series of focused mentoring activities organized in collaboration with the Louis Stokes Alliance for Minority Participation program at the university.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/28/2020</MinAmdLetterDate>
<MaxAmdLetterDate>05/02/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1942531</AwardID>
<Investigator>
<FirstName>Lap Fai</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lap Fai Yu</PI_FULL_NAME>
<EmailAddress>craigyu@gmu.edu</EmailAddress>
<PI_PHON>7039934813</PI_PHON>
<NSF_ID>000701257</NSF_ID>
<StartDate>02/28/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>George Mason University</Name>
<CityName>FAIRFAX</CityName>
<ZipCode>220304422</ZipCode>
<PhoneNumber>7039932295</PhoneNumber>
<StreetAddress>4400 UNIVERSITY DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA11</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>077817450</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGE MASON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>077817450</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[George Mason University]]></Name>
<CityName>Fairfax</CityName>
<StateCode>VA</StateCode>
<ZipCode>220304422</ZipCode>
<StreetAddress><![CDATA[4400 University Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>11</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA11</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~115788</FUND_OBLG>
<FUND_OBLG>2021~115422</FUND_OBLG>
</Award>
</rootTag>
