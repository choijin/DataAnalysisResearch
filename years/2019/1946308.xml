<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>COMPCOG: Intuitive Physics without Intuition or Physics: Leveraging Deep Neural Networks to Model Human Physical Reasoning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>553779.00</AwardTotalIntnAmount>
<AwardAmount>553779</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Hout</SignBlockName>
<PO_EMAI>mhout@nsf.gov</PO_EMAI>
<PO_PHON>7032922163</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broad purpose of the proposed research is to leverage recent advances in artificial intelligence (AI) and deep learning to gain insight into the inner workings of human cognition. While the nature of human perception and cognition can only be inferred from behavior, deep neural networks that emulate human behavior offer a unique opportunity to scrutinize the inner workings of the system and potentially understand how and why the system works the way it does (and, thus how and why the human system works the way it does). While cognitive science has always employed formal computational models, for the first time the cognitive abilities of artificial agents has begun to rival or exceed those of humans in several domains, providing the opportunity to formally understand complex human behavior using these models. Specifically, in the proposed research the investigators will use deep neural network models to better understand intuitive physical reasoning — our ability to understand the behavior of objects in our environment. For example, at a glance, people can judge whether a stack of plates is about to fall, or whether it’s stable. This type of intuitive physical reasoning is a fundamental aspect of human cognition which underlies our everyday reasoning about objects in the world, but likely also supports formal education in the physical sciences (e.g., learning Newtonian physics). Thus, the general purpose of the proposed research is to leverage recent advances in deep learning to develop a rich basic level understanding of human intuitive physical reasoning, which ultimately has the potential to impact formal STEM education.&lt;br/&gt;&lt;br/&gt;In the proposed work, the investigators will combine tools from cognitive science (ideal observer analyses), with tools from artificial intelligence (deep, convolutional neural networks), to test a novel psychological theory (intuitive physical reasoning as extrapolation in shape space) to gain insight into a core aspect of human cognition (intuitive physical reasoning). This work involves testing human participants to obtain human performance benchmarks on a variety of intuitive physical judgments, then training deep neural network models to perform the same tasks, in some cases constrained to behave as ideal observers (systems that perform the optimal computation to perform the task). By examining similarities and differences between humans and these deep neural network models, and scrutinizing the inner workings of models that perform the task with human-level accuracy, the investigators will develop neural network based models of human intuitive physical reasoning. As such, this work presents an interdisciplinary integration between cognitive science and artificial intelligence, with the potential to impact basic cognitive theory and its applications to formal STEM education, and to increase the synergy between the fields of machine vision, artificial intelligence, and autonomous agents that aim to emulate human intelligence.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/23/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/23/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1946308</AwardID>
<Investigator>
<FirstName>George</FirstName>
<LastName>Alvarez</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>George A Alvarez</PI_FULL_NAME>
<EmailAddress>alvarez@wjh.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000506197</NSF_ID>
<StartDate>07/23/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<CountyName/>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>Cambridge</CityName>
<CountyName/>
<StateCode>MA</StateCode>
<ZipCode>021382044</ZipCode>
<StreetAddress><![CDATA[33 Kirkland St. Rm 760]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~553779</FUND_OBLG>
</Award>
</rootTag>
