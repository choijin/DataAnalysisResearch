<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps: Device for the Visually Impaired Designed to Improve Mobility</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2019</AwardEffectiveDate>
<AwardExpirationDate>11/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ruth Shuman</SignBlockName>
<PO_EMAI>rshuman@nsf.gov</PO_EMAI>
<PO_PHON>7032922160</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this I-Corps project is significant from both economic and societal standpoints.  There are 8 million people in the US who are Visually Impaired (VI).  A large percent of adults with VI are unemployed. This platform helps to address these challenges by allowing VI individuals to be physically and socially mobile. The platform reads characters and identifies objects and communicates this information to the user. When the VI user needs immediate help, the system can stream a video feed to friends or family members to provide immediate support.  This platform creates value through reducing the demands placed on VI caregivers.  It is also expected to reduce insurance premiums by minimizing accidents.&lt;br/&gt;&lt;br/&gt;This I-Corps project combines AI (Artificial Intelligence) and community based peer-to-peer support. This technology uses well tested AI features such as character and object recognition. By eliminating the high end features of AI, both uncertainty and costs are reduced. The other technology, the peer-to-peer support system, typically uses either paid or unpaid helpers.  For peer-to-peer support, this system includes helpers identified by the users. By blending proven features of two technologies and allowing the users to use their own helpers, this system represents a new innovative and customized technology. The Visually Impaired (VI) population can potentially use the platform with ease and comfort.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/04/2019</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1933412</AwardID>
<Investigator>
<FirstName>KAMAL</FirstName>
<LastName>SARKAR</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>KAMAL SARKAR</PI_FULL_NAME>
<EmailAddress>kamal.sarkar@utrgv.edu</EmailAddress>
<PI_PHON>9566652682</PI_PHON>
<NSF_ID>000347090</NSF_ID>
<StartDate>06/04/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>John</FirstName>
<LastName>Sargent</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John Sargent</PI_FULL_NAME>
<EmailAddress>john.sargent@utrgv.edu</EmailAddress>
<PI_PHON>9566658760</PI_PHON>
<NSF_ID>000726555</NSF_ID>
<StartDate>06/04/2019</StartDate>
<EndDate>06/29/2020</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>The University of Texas Rio Grande Valley</Name>
<CityName>Edinburg</CityName>
<ZipCode>785392909</ZipCode>
<PhoneNumber>9566652889</PhoneNumber>
<StreetAddress>1201 West University Dr</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>15</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX15</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>069444511</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS RIO GRANDE VALLEY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The University of Texas Rio Grande Valley]]></Name>
<CityName>Edinburg</CityName>
<StateCode>TX</StateCode>
<ZipCode>785392909</ZipCode>
<StreetAddress><![CDATA[1201 W. University Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>15</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX15</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~50000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>In the US alone, there are close to 8 million people who are "legally" blind, defined with a visual acuity of 20/200 or less. For our convenience, we call them as Blinds and Persons with Visual Impairment (BPVI). They are mostly dependent on their family members making these members unproductive. Most of them also collect Supplemental Security Income (SSI) of about $1,000 a month. IF technology can be used to make these people productive, this very demography can add hundreds of billions of dollars to the&nbsp;economy, rather than collecting as much from the society. The net impact can be close to half-a-trillion dollars.</p> <p>This project combines various established technologies of AI (Artificial Intelligence) into a reliable economic product to improve "vision" of these BPVI demography.</p> <p>Many of these BPVI populations work&nbsp;<em>in a</em> variety<em> of</em>&nbsp;fields and works as teachers,&nbsp;para-legal, nurses, musicians,&nbsp;performer, etc. to name a few. However, most of them are directly or indirectly discouraged to go to colleges and go for STEM education, in particular, that typically can lead to high-paying jobs. The unemployment rate among the BPVI adults is a staggering 70%! Close to 30% of them live below the poverty level.&nbsp;</p> <p>With the help of the NSF I Corps [TM] program we have developed a prototype for this demography called VMobi [TM]. This will help a BPVI person to navigate an unfamiliar territory using a modified White Cane, cameras, earbuds, batteries, and a front pack that houses all the electronics we call eBox. All the communications are done wirelessly using a smartphone, earbuds, and built-in microphone. Simply put, cameras capture images digitally in an imaginary moving box (6'X6'X10') in front of the user. All identifiable images are wirelessly communicated to the user discreetly via the earbud. This is done by matching the camera images with&nbsp;a pre-selected set of images stored in the device.&nbsp;This helps the user, in addition to the White Cane, to navigate even in an unfamiliar terrain. This is mostly done by established technologies like object/image/character recognitions.</p> <p>VMobi [TM] has another critical feature that allows the user to directly communicate with his/her helper of choice using real-time video streaming with a push of a button in the White Cane.&nbsp; These technologies are also well-established due to Peer-to-Peer communications used get a taxi ride and/or now-famous Zoom meetings on-the-go.</p> <p>The key features of VMobi [TM] are use of well-established technologies at an affordable price. Given the economic condition of the demography, the target retail price is under a thousand dollars. The price was established using face-to-face interviews with close to one hundred BPVI people or their support system in homes and/or public institutions like government agencies or blind schools. While there is no product in the market that offers all these features, even the price tags of those commercially available products with significantly lower features are many folds of the proposed price.</p> <p>VMobi [TM] will allow the user to navigate thru a campus, mall, neighborhood, as examples. It will further allow them to read street signs or restaurant or store names. It can be used to read a menu in a restaurant or a label (including expiration date) in a grocery store. In case of an emergency, (s)he can call his/her close relative/friend/caregiver to help out in an emergency situation by simply pushing a button on his/her White Cane. This feature will allow the user to share his/her surrounding using real-time video streaming. This will enable the helper to bring the user to safety as and when needed. This feature can also be used either to call for emergency (911) or simply talking to a friend using the cell phone.</p> <p>These features will allow a student user to navigate in the campus to find a building or a classroom fast. Someone else can use it to find a new restaurant or store. This can further be used to socialize with each other and build new social networks or keeping one competitive in the professional field.</p> <p>VMobi [TM] is a Platform Technology. It can be used in many other applications like military, defense, and Homeland Security. It can also be used for geriatric care. This technology is being developed with the help of blind users over the years by the researchers of the University of Texas, Rio Grande Valley.</p> <p>&nbsp;</p><br> <p>            Last Modified: 03/29/2021<br>      Modified by: Kamal&nbsp;Sarkar</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1933412/1933412_10609089_1616892987658_InitialPrototypeforVMobi--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1933412/1933412_10609089_1616892987658_InitialPrototypeforVMobi--rgov-800width.jpg" title="Initial Prototype for VMobi TM"><img src="/por/images/Reports/POR/2021/1933412/1933412_10609089_1616892987658_InitialPrototypeforVMobi--rgov-66x44.jpg" alt="Initial Prototype for VMobi TM"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Initial Prototype Showing Proposed Features of VMobi TM</div> <div class="imageCredit">University of Texas, Rio Grande Valley</div> <div class="imageSubmitted">Kamal&nbsp;Sarkar</div> <div class="imageTitle">Initial Prototype for VMobi TM</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1933412/1933412_10609089_1616893567970_OverviewofVMobiTMTechnology--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1933412/1933412_10609089_1616893567970_OverviewofVMobiTMTechnology--rgov-800width.jpg" title="Overview of VMobi TM Technology"><img src="/por/images/Reports/POR/2021/1933412/1933412_10609089_1616893567970_OverviewofVMobiTMTechnology--rgov-66x44.jpg" alt="Overview of VMobi TM Technology"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Overview of VMobi TM Technology Showing Critical eatures Connected Wirelessly</div> <div class="imageCredit">University of Texas, Rio Grande Valley</div> <div class="imagePermisssions">Royalty-free (restricted use - cannot be shared)</div> <div class="imageSubmitted">Kamal&nbsp;Sarkar</div> <div class="imageTitle">Overview of VMobi TM Technology</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ In the US alone, there are close to 8 million people who are "legally" blind, defined with a visual acuity of 20/200 or less. For our convenience, we call them as Blinds and Persons with Visual Impairment (BPVI). They are mostly dependent on their family members making these members unproductive. Most of them also collect Supplemental Security Income (SSI) of about $1,000 a month. IF technology can be used to make these people productive, this very demography can add hundreds of billions of dollars to the economy, rather than collecting as much from the society. The net impact can be close to half-a-trillion dollars.  This project combines various established technologies of AI (Artificial Intelligence) into a reliable economic product to improve "vision" of these BPVI demography.  Many of these BPVI populations work in a variety of fields and works as teachers, para-legal, nurses, musicians, performer, etc. to name a few. However, most of them are directly or indirectly discouraged to go to colleges and go for STEM education, in particular, that typically can lead to high-paying jobs. The unemployment rate among the BPVI adults is a staggering 70%! Close to 30% of them live below the poverty level.   With the help of the NSF I Corps [TM] program we have developed a prototype for this demography called VMobi [TM]. This will help a BPVI person to navigate an unfamiliar territory using a modified White Cane, cameras, earbuds, batteries, and a front pack that houses all the electronics we call eBox. All the communications are done wirelessly using a smartphone, earbuds, and built-in microphone. Simply put, cameras capture images digitally in an imaginary moving box (6'X6'X10') in front of the user. All identifiable images are wirelessly communicated to the user discreetly via the earbud. This is done by matching the camera images with a pre-selected set of images stored in the device. This helps the user, in addition to the White Cane, to navigate even in an unfamiliar terrain. This is mostly done by established technologies like object/image/character recognitions.  VMobi [TM] has another critical feature that allows the user to directly communicate with his/her helper of choice using real-time video streaming with a push of a button in the White Cane.  These technologies are also well-established due to Peer-to-Peer communications used get a taxi ride and/or now-famous Zoom meetings on-the-go.  The key features of VMobi [TM] are use of well-established technologies at an affordable price. Given the economic condition of the demography, the target retail price is under a thousand dollars. The price was established using face-to-face interviews with close to one hundred BPVI people or their support system in homes and/or public institutions like government agencies or blind schools. While there is no product in the market that offers all these features, even the price tags of those commercially available products with significantly lower features are many folds of the proposed price.  VMobi [TM] will allow the user to navigate thru a campus, mall, neighborhood, as examples. It will further allow them to read street signs or restaurant or store names. It can be used to read a menu in a restaurant or a label (including expiration date) in a grocery store. In case of an emergency, (s)he can call his/her close relative/friend/caregiver to help out in an emergency situation by simply pushing a button on his/her White Cane. This feature will allow the user to share his/her surrounding using real-time video streaming. This will enable the helper to bring the user to safety as and when needed. This feature can also be used either to call for emergency (911) or simply talking to a friend using the cell phone.  These features will allow a student user to navigate in the campus to find a building or a classroom fast. Someone else can use it to find a new restaurant or store. This can further be used to socialize with each other and build new social networks or keeping one competitive in the professional field.  VMobi [TM] is a Platform Technology. It can be used in many other applications like military, defense, and Homeland Security. It can also be used for geriatric care. This technology is being developed with the help of blind users over the years by the researchers of the University of Texas, Rio Grande Valley.          Last Modified: 03/29/2021       Submitted by: Kamal Sarkar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
