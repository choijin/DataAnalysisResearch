<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI:Small: Neural Architecture Search with Deep Compositional Grammatical Structures</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>448637.00</AwardTotalIntnAmount>
<AwardAmount>464637</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Artificial Intelligence (AI) technologies have recently shown great values in a wide range of applications such as self-driving cars, smart speaker, machine translation, robot autonomy and medical diagnosis. Computer vision (automatic analysis of images and videos) and natural language processing (automatic analysis of text) are two key pillars of AI. Deep learning artificial neural networks are the "brain" of many state-of-the-art AI systems in these two domains. However, much of the neural architectures are still hand-crafted to tailor to individual tasks in each domain, whereas learning in the human brains seems to be more task- and domain-agnostic. This project presents a principled framework to automatically learn neural architectures that are smaller, faster and better for both computer vision and natural language processing tasks. More specifically, the project explores methods of searching for neural architecture based on structural rules that compose smaller units to make bigger units, similar to how grammars in natural languages guides the way sentences are formed. This approach eliminates the efforts of manually engineering neural architectures. The success of this project will significantly advance AI systems in computer vision and natural language processing, thus moving forward other practical applications of AI technologies as well. This project will also integrate educational components by making significant connections with an interdisciplinary set of students and researchers in the Digital Humanities, and preparing demos to engage the K-12 and undergraduate communities.&lt;br/&gt;&lt;br/&gt;The project proposes three main tasks. The first is to unfold the space of neural architectures with deep compositional grammatical architectures; this allows for learning rich features of deep neural networks in a principled way. The second is to develop grammar-guided neural architecture search. The goal is to search smaller, faster and better deep compositional grammatical architectures by integrating differentiable search and reinforcement learning search in the unfolded space. The third task is to evaluate the proposed work applications. The searched architectures will be used as new feature backbones for existing state-of-the-art deep learning based systems commonly used in computer vision and NLP. The key innovations of this project include: a novel method of grammar-guided network architecture design and search for deep learning, and a unified feature backbone enabling effective and efficient feature exploration and exploitation in computer vision and NLP.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/01/2019</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1909644</AwardID>
<Investigator>
<FirstName>Tianfu</FirstName>
<LastName>Wu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Tianfu Wu</PI_FULL_NAME>
<EmailAddress>tianfu_wu@ncsu.edu</EmailAddress>
<PI_PHON>9195154361</PI_PHON>
<NSF_ID>000738028</NSF_ID>
<StartDate>08/01/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>North Carolina State University</Name>
<CityName>Raleigh</CityName>
<ZipCode>276957514</ZipCode>
<PhoneNumber>9195152444</PhoneNumber>
<StreetAddress>2601 Wolf Village Way</StreetAddress>
<StreetAddress2><![CDATA[Admin. III, STE 240]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042092122</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTH CAROLINA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[North Carolina State University]]></Name>
<CityName>Raleigh</CityName>
<StateCode>NC</StateCode>
<ZipCode>276957911</ZipCode>
<StreetAddress><![CDATA[2701 Sullivan Drive, NC State]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~448637</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
</Award>
</rootTag>
