<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Neural predictors of individual differences in speech perception</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2020</AwardEffectiveDate>
<AwardExpirationDate>03/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>646962.00</AwardTotalIntnAmount>
<AwardAmount>646962</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Fritz</SignBlockName>
<PO_EMAI>jfritz@nsf.gov</PO_EMAI>
<PO_PHON>7032927923</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Speech perception maps sounds into meaning. During development, sound differences important to meaning become more perceptually salient than those that are unimportant. Surprisingly, adults show wide variability in the ability to perceive differences between sounds that belong to the same speech category. Despite considerable evidence for this variability, studies of the neurobiology and behavior of speech perception rarely take this perceptual diversity into account. This project will tackle these questions. In a diverse group of young adults, the brain systems involved in speech perception will be studied, from the brainstem to the cortex. Specifically, this project will test the theory that variation in neural encoding predict individual differences in speech perception and comprehension. These studies may indicate novel solutions for hearing in noisy environments or for treatments for disabling disorders. Through public outreach, this project will promote the neuroscience of speech perception, and foster awareness of the importance of speech perception in education and for the workforce. &lt;br/&gt;&lt;br/&gt;Speech perception maps a complex set of sounds to a limited number of phonetic categories. Categorical perception enables the listener to cope with acoustic variability in speech, by heightening sensitivity to acoustic differences across category boundaries, and lessening sensitivity within categories. Individuals show sizeable differences in “categoricity,” the degree of sensitivity to acoustic variability within a speech sound category. Despite considerable evidence of individual differences (IDs) in categoricity, little is known of how IDs relate to the neural processing stream or to other behavioral measures of speech and language. The current project tests the hypothesis that IDs in speech perception arise from IDs in the neural processing stream, from brainstem to cortex. The project studies the neural processing of younger adults (n=100) at early levels of the auditory pathway, measured using the auditory brainstem response (ABR); and at cortical levels, measured using fMRI. The tasks include behavioral measures of factors that may drive individual differences in sound and speech representation, such as musical skill and measures of reading ability. The combination of ABR, fMRI, and behavior will link IDs in speech processing to neural precision in sound encoding in the brainstem and neural specificity for phonetic responses in cortex. It will also elucidate how IDs in perception and neural encoding explain IDs in well-established speech and language metrics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/13/2020</MinAmdLetterDate>
<MaxAmdLetterDate>03/13/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1947883</AwardID>
<Investigator>
<FirstName>Erika</FirstName>
<LastName>Skoe</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Erika Skoe</PI_FULL_NAME>
<EmailAddress>erika.skoe@uconn.edu</EmailAddress>
<PI_PHON>8604863685</PI_PHON>
<NSF_ID>000658506</NSF_ID>
<StartDate>03/13/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Emily</FirstName>
<LastName>Myers</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Emily Myers</PI_FULL_NAME>
<EmailAddress>emily.myers@uconn.edu</EmailAddress>
<PI_PHON>8604862630</PI_PHON>
<NSF_ID>000688586</NSF_ID>
<StartDate>03/13/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Connecticut</Name>
<CityName>Storrs</CityName>
<CountyName>TOLLAND</CountyName>
<ZipCode>062691133</ZipCode>
<PhoneNumber>8604863622</PhoneNumber>
<StreetAddress>438 Whitney Road Ext.</StreetAddress>
<StreetAddress2><![CDATA[Unit 1133]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>614209054</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CONNECTICUT</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004534830</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Connecticut]]></Name>
<CityName>Storrs</CityName>
<CountyName>TOLLAND</CountyName>
<StateCode>CT</StateCode>
<ZipCode>062691085</ZipCode>
<StreetAddress><![CDATA[2 Alethia Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<ProgramReference>
<Code>8089</Code>
<Text>Understanding the Brain/Cognitive Scienc</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~646962</FUND_OBLG>
</Award>
</rootTag>
