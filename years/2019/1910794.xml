<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: TIDES: Trustworthy Interactive DEcision-making Using Symbolic Planning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2019</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>418170.00</AwardTotalIntnAmount>
<AwardAmount>418170</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Roger Mailler</SignBlockName>
<PO_EMAI>rmailler@nsf.gov</PO_EMAI>
<PO_PHON>7032927982</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Innovations in autonomy continue to produce systems that perceive, learn, decide, and act on their own. Many companies are now building self-driving vehicles and medical robots, and the development of advanced autonomous systems is already a billion-dollar industry. These new technologies offer oversight, advanced automation, and autonomous instruments, and they are adaptable to changing situations, knowledge, and constraints. However, introducing new technologies into our technical and social infrastructures has profound implications, and thus requires establishing confidence in their behavior to avoid potential harm. The effectiveness and broader acceptability of autonomous smart systems therefore rely on the ability of these systems to explain their decisions. Building trust in artificial intelligence (AI) systems is a critical requirement in human-robot interaction, and essential for realizing the full spectrum of societal and industrial benefits from AI. &lt;br/&gt; &lt;br/&gt;This proposal identifies two critical factors for establishing the trustworthiness of autonomous systems: explainability and risk-awareness. The proposed research will provide new algorithms and guidance to enable real-world applications, opening trustworthy reinforcement-learning techniques to a wide variety of practical applications such as control, robotics, e-commerce, and medical treatment. Overall, this research will produce, first, an explainable and data-efficient hierarchical sequential decision-making framework based on symbolic planning and hierarchical reinforcement learning; second, an explainable policy-search framework that can learn explainable policies via integrating inductive logic programming and reinforcement learning; and third, improved approaches to risk-sensitive policy search that are easy to use (for example, without the burden of tuning multi-timescale stepsizes). The theoretical contribution of this research is to significantly improve data-driven policy search in interactive sequential decision-making systems by developing a theory of trust that facilitates and informs smart interactive learning processes.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/05/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/22/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1910794</AwardID>
<Investigator>
<FirstName>Levent</FirstName>
<LastName>Yilmaz</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Levent Yilmaz</PI_FULL_NAME>
<EmailAddress>yilmaz@auburn.edu</EmailAddress>
<PI_PHON>3348446343</PI_PHON>
<NSF_ID>000242144</NSF_ID>
<StartDate>08/05/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Bo</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bo Liu</PI_FULL_NAME>
<EmailAddress>boliu@auburn.edu</EmailAddress>
<PI_PHON>3348446348</PI_PHON>
<NSF_ID>000727926</NSF_ID>
<StartDate>08/05/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Auburn University</Name>
<CityName>Auburn</CityName>
<ZipCode>368320001</ZipCode>
<PhoneNumber>3348444438</PhoneNumber>
<StreetAddress>VPRED, Research &amp; Innovation Ctr</StreetAddress>
<StreetAddress2><![CDATA[540 Devall Drive, Suite 200]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<StateCode>AL</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AL03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066470972</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AUBURN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>066470972</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Auburn University]]></Name>
<CityName/>
<StateCode>AL</StateCode>
<ZipCode>368490001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Alabama</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AL03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~126525</FUND_OBLG>
<FUND_OBLG>2020~291645</FUND_OBLG>
</Award>
</rootTag>
