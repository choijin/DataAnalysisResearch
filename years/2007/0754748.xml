<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>IDBR: Automated Image Analysis for Discovering Motion Behavior in Video</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2008</AwardEffectiveDate>
<AwardExpirationDate>05/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>440341.00</AwardTotalIntnAmount>
<AwardAmount>463591</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08080200</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DBI</Abbreviation>
<LongName>Div Of Biological Infrastructure</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joyce Fernandes</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>A grant has been awarded to Dr. Shin at the University of North Carolina at Charlotte to develop a tool for discovering interesting motion behavior of biological activities.  This often requires a painstaking observation of many biological entities moving in complex patterns.  Such type of analysis is applicable in a wide range of biological systems from the cellular level (natural killer T cells, NKT) to the population level (honeybees).  However, the complexity of the behavior and the shear amount of data makes a manual approach impractical.  The proposed instrument/tool will comprehensively and automatically search for the occurrences of a biological activity in a large dataset with minimal manual involvement.&lt;br/&gt;&lt;br/&gt;The method involves three steps: (1) automated video analysis of biological entities' motion, (2) semi-automated searching for a specific motion behavior, and (3) testing the hypothesis using the tool.  First, a scientist selects one instance of interesting motion.  Then, the tool searches for video clips that contain similar motion.  The scientist then examines and validates the search results.  If the search needs improvement, the scientist selects the good results and provides them to the tool.  Once the user is confident with the search results, the tool will be used for testing a specific hypothesis related to the motion. To demonstrate the applicability of the method on a wide range of problems, hypotheses involving events of two different biological entities of honey bee communication and natural killer T cell sentry behavior will be tested.  The ability to develop an approach to identifying, quantifying and then searching for instances of such events that is applicable to two very different scales of biological activity (immune cells and honeybees) would suggest the potential for application to a wide variety of problems involving complex motion behaviors.&lt;br/&gt;&lt;br/&gt;The proposed project will help support mentoring of undergraduate students. The students will participate in the REU (research experience for undergraduates) through the REU site within the Department of Computer Science.  The Biology Department has approximately 1000 undergraduate majors and continues to offer extensive opportunities for undergraduate research including an undergraduate honors program widely considered to be one of the best in the University. In addition, UNC Charlotte holds the distinction of the largest minority enrollment of any of the non-historically black campuses of the UNC system. This is partly due to the urban location of the University, but also to the effectiveness of the University?s programs for increasing the diversity of student body.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>05/27/2008</MinAmdLetterDate>
<MaxAmdLetterDate>03/18/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0754748</AwardID>
<Investigator>
<FirstName>Stanley</FirstName>
<LastName>Schneider</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Stanley S Schneider</PI_FULL_NAME>
<EmailAddress>sschnedr@uncc.edu</EmailAddress>
<PI_PHON>7046878527</PI_PHON>
<NSF_ID>000377147</NSF_ID>
<StartDate>05/27/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Clemens</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark G Clemens</PI_FULL_NAME>
<EmailAddress>mgclemens@email.uncc.edu</EmailAddress>
<PI_PHON>7046872315</PI_PHON>
<NSF_ID>000395390</NSF_ID>
<StartDate>05/27/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Min</FirstName>
<LastName>Shin</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Min C Shin</PI_FULL_NAME>
<EmailAddress>mcshin@uncc.edu</EmailAddress>
<PI_PHON>7046878578</PI_PHON>
<NSF_ID>000482909</NSF_ID>
<StartDate>05/27/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Charlotte</Name>
<CityName>CHARLOTTE</CityName>
<ZipCode>282230001</ZipCode>
<PhoneNumber>7046871888</PhoneNumber>
<StreetAddress>9201 University City Boulevard</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>066300096</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Charlotte]]></Name>
<CityName>CHARLOTTE</CityName>
<StateCode>NC</StateCode>
<ZipCode>282230001</ZipCode>
<StreetAddress><![CDATA[9201 University City Boulevard]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1108</Code>
<Text>INSTRUMENTAT &amp; INSTRUMENT DEVP</Text>
</ProgramElement>
<ProgramReference>
<Code>1108</Code>
<Text>INSTRUMENTAT &amp; INSTRUMENT DEVP</Text>
</ProgramReference>
<ProgramReference>
<Code>9152</Code>
<Text>EDUCATION PROGRAM EVALUATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9184</Code>
<Text>BIOTECHNOLOGY - INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>BIOT</Code>
<Text>BIOTECHNOLOGY</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~158357</FUND_OBLG>
<FUND_OBLG>2009~162874</FUND_OBLG>
<FUND_OBLG>2010~142360</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong id="internal-source-marker_0.35607300139963627"><strong id="internal-source-marker_0.35607300139963627"><span><strong id="internal-source-marker_0.35607300139963627"><span><strong id="internal-source-marker_0.35607300139963627"><span>Traditional method of analyzing the biological motion is tedious and time-consuming. &nbsp;Often, biologists would be required to manually annotate and quantify the motion patterns of important objects such as immune cells and social insects. &nbsp;&nbsp;However, such method is often the biggest limiting factor to the advancement of biological research as the manual approach greatly limits amount of data that can be analyzed. &nbsp;Manually searching through a large collection of complex motion pattern is simply not feasible. &nbsp;In this project, we have developed new methods for (1) automatically tracking biological objects in video and (2) interactively learning and searching for motion patterns in biological dataset. &nbsp;&nbsp;Our methods allow more reliable, automated tracking of cells and honeybees. &nbsp;Our tool provides an improvement in video searching by learning more quickly with a smaller number of motion examples. &nbsp;Our method has been used for studying how the white cells respond to the presence of trauma by automatically mining through a large collection of video analyzing more than 1 million observations of cells in video. &nbsp;Our tool has been extended for tracking honeybees and ants. &nbsp;The tool is currently being used by other biologists in US. &nbsp;This project has also provided valuable educational experience for 4 Ph.D. students and 5 undergrad college students.</span></strong></span></strong></span></strong></strong></p><br> <p>            Last Modified: 08/30/2012<br>      Modified by: Min&nbsp;C&nbsp;Shin</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2012/0754748/0754748_10024572_1346355067349_Ranking-results--rgov-214x142.jpg" original="/por/images/Reports/POR/2012/0754748/0754748_10024572_1346355067349_Ranking-results--rgov-800width.jpg" title="Searching for biological motion patterns"><img src="/por/images/Reports/POR/2012/0754748/0754748_10024572_1346355067349_Ranking-results--rgov-66x44.jpg" alt="Searching for biological motion patterns"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Top five returned results by each method for a query trajectory. The numbers by each image represent the expert-provided relevance label from 1 (highly irrelevant) to 5 (highly relevant).</div> <div class="imageCredit">T. Fasciano</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Min&nbsp;C&nbsp;Shin</div> <div class="imageTitle">Searching for biological motion patterns</div> </div> </li> <li> <a href="/por/images/Reports/POR/2012/0754748/0754748_10024572_1346354939176_wbc--rgov-214x142.jpg" original="/por/images/Reports/POR/2012/0754748/0754748_10024572_1346354939176_wbc--rgov-800width.jpg" title="Tracking Colliding Cells"><img src="/por/images/Reports/POR/2012/0754748/0754748_10024572_1346354939176_wbc--rgov-66x44.jpg" alt="Tracking Colliding Cells"></a> <div class="imageCaptionContainer"> <div class="imageCaption">A sample visual comparison of tracking colliding cells. The left is an image of rolling leukocytes in a blood vessel from an intravital microscopy video. Region A, where a collision takes place, has been enlarged on the right. Cells have been outlined b...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Traditional method of analyzing the biological motion is tedious and time-consuming.  Often, biologists would be required to manually annotate and quantify the motion patterns of important objects such as immune cells and social insects.   However, such method is often the biggest limiting factor to the advancement of biological research as the manual approach greatly limits amount of data that can be analyzed.  Manually searching through a large collection of complex motion pattern is simply not feasible.  In this project, we have developed new methods for (1) automatically tracking biological objects in video and (2) interactively learning and searching for motion patterns in biological dataset.   Our methods allow more reliable, automated tracking of cells and honeybees.  Our tool provides an improvement in video searching by learning more quickly with a smaller number of motion examples.  Our method has been used for studying how the white cells respond to the presence of trauma by automatically mining through a large collection of video analyzing more than 1 million observations of cells in video.  Our tool has been extended for tracking honeybees and ants.  The tool is currently being used by other biologists in US.  This project has also provided valuable educational experience for 4 Ph.D. students and 5 undergrad college students.       Last Modified: 08/30/2012       Submitted by: Min C Shin]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
