<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Cross-Task Learning for Natural Language Processing</AwardTitle>
<AwardEffectiveDate>08/15/2007</AwardEffectiveDate>
<AwardExpirationDate>07/31/2011</AwardExpirationDate>
<AwardAmount>377067</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana D. Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project considers the problem of simultaneously solving multiple&lt;br/&gt;component-level natural language processing problems.  Such&lt;br/&gt;component-level tasks are necessary as building blocks for large-scale&lt;br/&gt;applications (eg., automatic document summarization, machine&lt;br/&gt;translation, etc.), but are typically solved independently.  These&lt;br/&gt;independent solutions ignore the natural connections that relate the&lt;br/&gt;output of one problem to the output of the other.  This research&lt;br/&gt;explores the ability to exploit such output correspondences to aid&lt;br/&gt;machine learning algorithms, termed "Cross-Task Learning."  These&lt;br/&gt;output correspondences provide strong prior information about the&lt;br/&gt;relationship between the desired outputs of multiple problems.  This&lt;br/&gt;prior knowledge can potentially serve to improve task-level&lt;br/&gt;performance, even when large amounts of training data are unavailable.&lt;br/&gt;The research exploits such prior knowledge using a k-best methodology&lt;br/&gt;so as to maximize the applicability of these techniques.  It also&lt;br/&gt;develops new techniques for semi-supervised learning based on the idea&lt;br/&gt;of output correspondences in order to capitalize on the vast amounts&lt;br/&gt;of unannotated data that are available. In addition, the proposed techniques&lt;br/&gt;are analyzed in the context of computational learning theory. The outcome &lt;br/&gt;will be a set of techniques for learning across multiple natural language processing&lt;br/&gt;tasks.  This technology will be empirically evaluated in the context&lt;br/&gt;of low-level tasks such as shallow parsing and named entity&lt;br/&gt;recognition, as well as the high-level tasks of discourse analysis and&lt;br/&gt;automatic document summarization.  &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/16/2007</MinAmdLetterDate>
<MaxAmdLetterDate>06/09/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0712764</AwardID>
<Investigator>
<FirstName>Hal</FirstName>
<LastName>Daume</LastName>
<EmailAddress>hal@umiacs.umd.edu</EmailAddress>
<StartDate>08/16/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Utah</Name>
<CityName>SALT LAKE CITY</CityName>
<ZipCode>841128930</ZipCode>
<PhoneNumber>8015816903</PhoneNumber>
<StreetAddress>75 S 2000 E</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
