<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>HCC: Interactive and Enriched Haptic Graphical Representations for People who are Blind and Visually Impaired</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2007</AwardEffectiveDate>
<AwardExpirationDate>08/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>332685.00</AwardTotalIntnAmount>
<AwardAmount>397382</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Graphical representations often comprise an integral part of highly interactive interfaces to enhance human insight and creativity.  The benefits of such interfaces are for the most part denied, however, to individuals who are blind or visually impaired, who are as a consequence are placed at a significant disadvantage with respect to learning throughout their lives.  For young children, graphical representations in books are often critical for developing a vocabulary, as many objects cannot easily be obtained or safely handled physically.  Later on, examination and interpretation of graphical information such as experimental time series data, mathematical waveforms and geographical diagrams are crucial for obtaining insight in these areas and a sign of creativity. Currently, the most frequent method of representing 2D graphical information so as to make it accessible to individuals who are blind or visually impaired is through static raised-line drawings, but this method is very poor at relaying information in unconstrained tasks such as those mentioned above.  In this project the PI adopts a novel alternative haptics-based approach to address the challenge of developing more suitable interactive methods and appropriate representations that enhance understanding of unfamiliar information (whether patterns, groups of items, or individual items) and improve the user's ability to make discoveries or propose explanations.  She will develop highly interactive graphics technology that allows the user to actively and separately control both the magnification and simplification of a graphic during its examination.  This will allow the user to customize and vary as needed the trade-off between the two main limitations of haptic processing: the need to serially integrate information, and poor tactile spatial resolution.  The enriched representations will use texture or vibration as a way to encode the separation of a graphic into objects and object parts, and to describe the 3D orientation of parts, which are two of the most difficult aspects of interpretation.  The project will be conducted with input and feedback from members of the target user community, and validated experimentally.&lt;br/&gt;&lt;br/&gt;Broader Impacts:  This research will help move knowledge about human haptic processing from theory to practice.   As the focus is on developing enabling technologies for higher level thinking skills, the project will empower individuals who are blind or visually impaired (and ultimately all users) with new tools to make more significant contributions to society.  Thus, the work will in particular contribute to the effort of preventing individuals from the target community being left further behind as information technology advances forward, and will enable them to enjoy a better income and quality of life.</AbstractNarration>
<MinAmdLetterDate>09/12/2007</MinAmdLetterDate>
<MaxAmdLetterDate>04/06/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0712936</AwardID>
<Investigator>
<FirstName>Dianne</FirstName>
<LastName>Pawluk</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Dianne Pawluk</PI_FULL_NAME>
<EmailAddress>dtpawluk@vcu.edu</EmailAddress>
<PI_PHON>8048289491</PI_PHON>
<NSF_ID>000090237</NSF_ID>
<StartDate>09/12/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Virginia Commonwealth University</Name>
<CityName>RICHMOND</CityName>
<ZipCode>232980568</ZipCode>
<PhoneNumber>8048286772</PhoneNumber>
<StreetAddress>P.O. Box 980568</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>105300446</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>VIRGINIA COMMONWEALTH UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>105300446</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Virginia Commonwealth University]]></Name>
<CityName>RICHMOND</CityName>
<StateCode>VA</StateCode>
<ZipCode>232980568</ZipCode>
<StreetAddress><![CDATA[P.O. Box 980568]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7218</Code>
<Text>RET SUPP-Res Exp for Tchr Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~112931</FUND_OBLG>
<FUND_OBLG>2008~127125</FUND_OBLG>
<FUND_OBLG>2009~134833</FUND_OBLG>
<FUND_OBLG>2010~6493</FUND_OBLG>
<FUND_OBLG>2011~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><strong>Interactive and Enriched Haptic Graphical Representations for People who are Blind or Visually Impaired</strong></p> <p>The main goal of this work was to significantly improve the conveying of graphical information to individuals who are blind or visually impaired through the haptic sense by taking into account the fundamental nature of the haptic system.&nbsp; The haptic sense consists of touch, as well as the sense of position of the joints and forces exerted by the muscles.&nbsp; The haptic sense is very different in how it processes information from the visual sense, with differing resulting strengths and weaknesses.&nbsp; This creates significant problems when users try to interpret tactile diagrams.&nbsp; The general idea of this work is to improve the representations of diagrams to facilitate their interpretation and to allow diagrams to be felt interactively through a computer, facilitating the ease of accessing diagram information.&nbsp; One of the ideas of this work was to develop methods of presenting information about pictures and diagrams that take advantage of one of the haptic system&rsquo;s strength: namely the effectiveness of processing material properties such as texture.&nbsp; The other idea was to try and address the limitations of haptic processing for diagram information.&nbsp; Unfortunately, some of vision&rsquo;s strengths, for which diagrams are designed, are actually haptic&rsquo;s weaknesses: touch is approximately 10x worse than vision in perceiving details, and it cannot view the diagram all at once, but only piece by piece as the fingers scan across it.</p> <p>For the first of these ideas, our primary motivation was based on psychological evidence that individuals are able to process material information, such as texture, across multiple fingers at once in a search task.&nbsp; However, geometric information, such as the raised lines typically created for tactile diagrams, is processed in sequence, one finger at a time.&nbsp; We hypothesized if we could use texture information to encode information to help in the understanding of a diagram, such as difficult to determine information as what lines belonged to which parts of objects and what is the orientation of each part, we could improve performance.&nbsp; We then developed a computer interface device, with one tactile feedback channel per finger, to portray this information from a computer: this format was chosen as it allows for easy display of a diagram versus having to create it physically or using specialized equipment which is costly, slow and cumbersome.&nbsp; We found, through experimentation, that even for one finger, using texture to relay information in a diagram improved performance by a factor of two.&nbsp; Performance using multiple fingers improved even further, increasing by a factor of three.&nbsp; In contrast, using the traditional line diagrams did not improve performance at all with three fingers.</p> <p>For the second of these ideas, addressing haptic&rsquo;s weaknesses, what is typically done is that a professional diagram maker, either through a software program or manually, removes details from the visual diagram.&nbsp; In addition, they almost always remove information not relevant for the specified task at hand.&nbsp; There are two problems with this: 1) if the user asks new questions, new diagrams need to be made, and 2) it greatly limits incidental learning by not allowing users to explore all the information.&nbsp; To address this problem, we examined ways of accessing details without providing information overload.&nbsp; One method was to use a software zooming function, as exists for visual diagrams on computers.&nbsp; However, because haptics processes information very differently than vision, using typical visual techniques can be slow (because the fingers have to scan the diagram serially, it can take much longer to realize that a new zoom lev...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Interactive and Enriched Haptic Graphical Representations for People who are Blind or Visually Impaired  The main goal of this work was to significantly improve the conveying of graphical information to individuals who are blind or visually impaired through the haptic sense by taking into account the fundamental nature of the haptic system.  The haptic sense consists of touch, as well as the sense of position of the joints and forces exerted by the muscles.  The haptic sense is very different in how it processes information from the visual sense, with differing resulting strengths and weaknesses.  This creates significant problems when users try to interpret tactile diagrams.  The general idea of this work is to improve the representations of diagrams to facilitate their interpretation and to allow diagrams to be felt interactively through a computer, facilitating the ease of accessing diagram information.  One of the ideas of this work was to develop methods of presenting information about pictures and diagrams that take advantage of one of the haptic systemÆs strength: namely the effectiveness of processing material properties such as texture.  The other idea was to try and address the limitations of haptic processing for diagram information.  Unfortunately, some of visionÆs strengths, for which diagrams are designed, are actually hapticÆs weaknesses: touch is approximately 10x worse than vision in perceiving details, and it cannot view the diagram all at once, but only piece by piece as the fingers scan across it.  For the first of these ideas, our primary motivation was based on psychological evidence that individuals are able to process material information, such as texture, across multiple fingers at once in a search task.  However, geometric information, such as the raised lines typically created for tactile diagrams, is processed in sequence, one finger at a time.  We hypothesized if we could use texture information to encode information to help in the understanding of a diagram, such as difficult to determine information as what lines belonged to which parts of objects and what is the orientation of each part, we could improve performance.  We then developed a computer interface device, with one tactile feedback channel per finger, to portray this information from a computer: this format was chosen as it allows for easy display of a diagram versus having to create it physically or using specialized equipment which is costly, slow and cumbersome.  We found, through experimentation, that even for one finger, using texture to relay information in a diagram improved performance by a factor of two.  Performance using multiple fingers improved even further, increasing by a factor of three.  In contrast, using the traditional line diagrams did not improve performance at all with three fingers.  For the second of these ideas, addressing hapticÆs weaknesses, what is typically done is that a professional diagram maker, either through a software program or manually, removes details from the visual diagram.  In addition, they almost always remove information not relevant for the specified task at hand.  There are two problems with this: 1) if the user asks new questions, new diagrams need to be made, and 2) it greatly limits incidental learning by not allowing users to explore all the information.  To address this problem, we examined ways of accessing details without providing information overload.  One method was to use a software zooming function, as exists for visual diagrams on computers.  However, because haptics processes information very differently than vision, using typical visual techniques can be slow (because the fingers have to scan the diagram serially, it can take much longer to realize that a new zoom level does not provide new information) and error prone (users may not figure out that objects may be clipped).  We developed an algorithm that examines the local context of the area of the diagram when zooming and...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
