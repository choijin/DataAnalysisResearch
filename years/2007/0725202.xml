<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: SoD-TEAM: Designing Tests for Evolving Software Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2008</AwardEffectiveDate>
<AwardExpirationDate>12/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>342000.00</AwardTotalIntnAmount>
<AwardAmount>442551</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>0725202&lt;br/&gt;Orso, Alessandro&lt;br/&gt;GA Tech Research Corp&lt;br/&gt;&lt;br/&gt;0725190&lt;br/&gt;Tao Xie&lt;br/&gt;North Corolina State University&lt;br/&gt;&lt;br/&gt;SOD: Team:  Designing Tests for Evolving Software Systems&lt;br/&gt;&lt;br/&gt;Software artifacts continue to evolve throughout their (often long) lifetime, and maintaining them is one of the most expensive activities in software development. A considerable percentage of maintenance costs are due to regression testing, which consists of retesting the software after it is modified and is a crucial part of maintenance.  Previous research on regression testing has mostly focused on the efficiency of this activity, while little emphasis has been placed on assessing and improving regression-testing effectiveness. The goal of&lt;br/&gt;this project is to fill this gap through the definition of techniques for (1) determining the adequacy of a test suite with respect to a set of software changes, and (2) providing automated support for designing and developing test cases that target inadequately-exercised changes. To achieve this goal, the research will perform three main tasks: define techniques that combine dependence- and state-related information to generate regression-test requirements for changed software; define techniques based on static and dynamic analysis for developing test cases that satisfy the identified requirements; and evaluate the techniques defined in the project through rigorous experiments and industrial case studies.  This research directly addresses the stated goals of this program by targeting the development of techniques that can improve the processes of&lt;br/&gt;constructing and modifying software-intensive systems.</AbstractNarration>
<MinAmdLetterDate>09/14/2007</MinAmdLetterDate>
<MaxAmdLetterDate>11/05/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0725202</AwardID>
<Investigator>
<FirstName>Mary</FirstName>
<LastName>Harrold</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mary J Harrold</PI_FULL_NAME>
<EmailAddress>harrold@cc.gatech.edu</EmailAddress>
<PI_PHON>4043850612</PI_PHON>
<NSF_ID>000248827</NSF_ID>
<StartDate>09/14/2007</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Alessandro</FirstName>
<LastName>Orso</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Alessandro Orso</PI_FULL_NAME>
<EmailAddress>orso@cc.gatech.edu</EmailAddress>
<PI_PHON>4043852066</PI_PHON>
<NSF_ID>000489660</NSF_ID>
<StartDate>09/14/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 NORTH AVE NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>1640</Code>
<Text>Information Technology Researc</Text>
</ProgramElement>
<ProgramElement>
<Code>7298</Code>
<Text>International Research Collab</Text>
</ProgramElement>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramElement>
<Code>7652</Code>
<Text>SCIENCE OF DESIGN</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramElement>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramElement>
<ProgramReference>
<Code>5914</Code>
<Text>WESTERN EUROPE, OTHER</Text>
</ProgramReference>
<ProgramReference>
<Code>5979</Code>
<Text>Europe and Eurasia</Text>
</ProgramReference>
<ProgramReference>
<Code>7652</Code>
<Text>SCIENCE OF DESIGN</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~342000</FUND_OBLG>
<FUND_OBLG>2010~68086</FUND_OBLG>
<FUND_OBLG>2011~32465</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Software artifacts continue to evolve throughout their (often long) lifetime, and maintaining them is one of the most expensive activities in software development. A considerable percentage of maintenance costs are due to regression testing, which consists of retesting the software after it has been modified and is a crucial part of maintenance. Previous research on regression testing has mostly focused on reducing the cost of this activity, while little emphasis has been placed on assessing and improving regression testing effectiveness. In this project, we filled this gap through the definition of techniques for determining the adequacy of a test suite with respect to a set of software changes and providing automated support for designing and developing test cases that target inadequately exercised changes in the code.</p> <p>To achieve this goal, this research defined novel techniques for (1) identifying which parts of a software system need to be retested after the software has been modified and (2) automatically generating tests that exercise these parts of the code. We evaluated the effectiveness and usefulness of our techinques through rigorous&nbsp;experiments and industrial case studies.</p> <p>As a specific example, we quickly summarize one of the techniques that we developed within this project called behavioral regression testing (BERT), whose overview is provided in the image attached to this report. BERT operates behind the scenes and, as developers modify their code, (1) transparently identifies behavioral differences between the old and new versions of the program, (2) tests such differences, and (3) immediately notifies the developers of possible problems with the changes they introduced. In this way, developers can look at the reported problems while the changes are still fresh in their mind, decide which of the problems reported are actual issues, and suitably react. In our evaluation of BERT on real-world software, our technique was able to identify real problems that could have otherwise been overlooked by the developers and result in software failures on user machines.&nbsp;</p> <p>Overall, this research has provided novel contributions in the principal disciplines of the project and had broader impact in the research community, where some of the papers that describe the research have received awards and have been cited a large number of times. The research also had impact in industry, through several collaborations with various companies, visits and student internships, and invited talks. Through these activities, we performed technology transfer and fostered the adoption of regression testing techniques developed in academia in industrial contexts.</p> <div class="page" title="Page 15"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>More generally, our work on regression testing of today's complex software systems can benefit all those disciplines that rely on such systems (e.g., geoscience, biological science, finance, and healthcare, just to cite a few) and thus ultimately benefit all segments of society that rely on, and benefit from, these disciplines.</span></p> </div> </div> </div> </div><br> <p>            Last Modified: 05/20/2014<br>      Modified by: Alessandro&nbsp;Orso</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2014/0725202/0725202_10023315_1400627221674_bert-overview--rgov-214x142.jpg" original="/por/images/Reports/POR/2014/0725202/0725202_10023315_1400627221674_bert...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Software artifacts continue to evolve throughout their (often long) lifetime, and maintaining them is one of the most expensive activities in software development. A considerable percentage of maintenance costs are due to regression testing, which consists of retesting the software after it has been modified and is a crucial part of maintenance. Previous research on regression testing has mostly focused on reducing the cost of this activity, while little emphasis has been placed on assessing and improving regression testing effectiveness. In this project, we filled this gap through the definition of techniques for determining the adequacy of a test suite with respect to a set of software changes and providing automated support for designing and developing test cases that target inadequately exercised changes in the code.  To achieve this goal, this research defined novel techniques for (1) identifying which parts of a software system need to be retested after the software has been modified and (2) automatically generating tests that exercise these parts of the code. We evaluated the effectiveness and usefulness of our techinques through rigorous experiments and industrial case studies.  As a specific example, we quickly summarize one of the techniques that we developed within this project called behavioral regression testing (BERT), whose overview is provided in the image attached to this report. BERT operates behind the scenes and, as developers modify their code, (1) transparently identifies behavioral differences between the old and new versions of the program, (2) tests such differences, and (3) immediately notifies the developers of possible problems with the changes they introduced. In this way, developers can look at the reported problems while the changes are still fresh in their mind, decide which of the problems reported are actual issues, and suitably react. In our evaluation of BERT on real-world software, our technique was able to identify real problems that could have otherwise been overlooked by the developers and result in software failures on user machines.   Overall, this research has provided novel contributions in the principal disciplines of the project and had broader impact in the research community, where some of the papers that describe the research have received awards and have been cited a large number of times. The research also had impact in industry, through several collaborations with various companies, visits and student internships, and invited talks. Through these activities, we performed technology transfer and fostered the adoption of regression testing techniques developed in academia in industrial contexts.      More generally, our work on regression testing of today's complex software systems can benefit all those disciplines that rely on such systems (e.g., geoscience, biological science, finance, and healthcare, just to cite a few) and thus ultimately benefit all segments of society that rely on, and benefit from, these disciplines.           Last Modified: 05/20/2014       Submitted by: Alessandro Orso]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
