<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Large Scale Object Recognition and  Ground Truth Representation Using Stochastic Image Grammar</AwardTitle>
<AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
<AwardExpirationDate>08/31/2011</AwardExpirationDate>
<AwardAmount>459674</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>PI: Song-Chun Zhu&lt;br/&gt;Institution: University of California - Los Angeles&lt;br/&gt;&lt;br/&gt;Title: Large Scale Object Recognition and Ground Truth Representation Using Stochastic Image Grammar&lt;br/&gt;&lt;br/&gt;The proposed project is aimed at three objectives, (1) studying a common representational framework for learning and modeling  hundreds of object categories, especially to account for the large intra-category variations; (2) constructing a large ground truth database with a minimum of one million  objects annotated semi-automatically for learning and testing;  and (3) building a robust large scale object recognition and image parsing system.  The core to this proposal is a stochastic context sensitive image grammar for effective visual knowledge representation and robust Bayesian inference.  The proposed stochastic image grammar combines the reconfigurability of stochastic context free grammar (SCFG) with the contextual constraints of graphical&lt;br/&gt;(MRF) models. This stochastic grammar model has strong  compositional power for representing large intra-class structural variations and recursive structures for scalable computing, and can be learned from a relatively small sample set. To make the large scale modeling and learning framework practical,  the PI has been constructing a large scale ground truth database in collaboration with the Lotus Hill Institute (LHI) in China.&lt;br/&gt;     The current database contains over 500,000 images manually parsed hierarchically using a semi-automatic vision system, in 240 object categories and 20 scene categories. All the data are represented uniformly in a large And-Or graph structure for learning and testing. We propose to continue collecting and annotating up to 1,000,000 images and construct a series of benchmarks during this project period.&lt;br/&gt;&lt;br/&gt;The proposal develops core techniques for large scale object recognition which can be used as the foundation for building a wide range of applications in commercial and defense industry, such as intelligence image search, security and surveillance, autonomous vehicle, and assisting the blind and visually impaired. The ground truth database shall be the world largest in its detailed parsing and annotation.&lt;br/&gt;A selected portion of this large dataset will be publicized for learning and benchmark evaluation.&lt;br/&gt;It is expected to have a significant impact in the vision community, and it may also help researchers studying human perception in cognitive science by providing more realistic stimuli and natural image statistics.&lt;br/&gt;&lt;br/&gt;  Progress of this project will be reported through the following webpage&lt;br/&gt;&lt;br/&gt;http://civs.stat.ucla.edu/Category_Recognition&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/28/2007</MinAmdLetterDate>
<MaxAmdLetterDate>06/19/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0713652</AwardID>
<Investigator>
<FirstName>Yingnian</FirstName>
<LastName>Wu</LastName>
<EmailAddress>ywu@stat.ucla.edu</EmailAddress>
<StartDate>08/28/2007</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Song-Chun</FirstName>
<LastName>Zhu</LastName>
<EmailAddress>sczhu@stat.ucla.edu</EmailAddress>
<StartDate>08/28/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
