<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: IDBR:  VoxNet--A Deployable Bioacoustic Sensor Network</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2008</AwardEffectiveDate>
<AwardExpirationDate>02/29/2012</AwardExpirationDate>
<AwardTotalIntnAmount>422571.00</AwardTotalIntnAmount>
<AwardAmount>452465</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08080200</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DBI</Abbreviation>
<LongName>Div Of Biological Infrastructure</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joyce Fernandes</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This award supports a collaborative effort between the PIs and investigators at the University of Arizona and Massachusetts Institute of Technology to design and develop instrumentation for wildlife biologists to inventory animals by detecting, recording, and analyzing their sounds.  The system will also allow for field biologists to ask questions about the temporal and spatial dynamics of acoustic communication.  Many species produce sounds, and by identifying and localizing them, we can census biodiversity and study the natural dynamics of communication.  Typically, these will be vocal sounds, such as bird song, or mammal or frog calls, but in theory, the equipment and algorithms can be used for other sorts of sounds (such as the stridulations of cricket wings). To do so, we must build robust hardware and easy to use software that field biologists can and will use.  While there has been the development of ?proof-of-concept? tools and algorithms for many of the components of a usable system, there is no reliable, robust, and easy-to-use system that will permit field biologists to easily census acoustic animals.  To do so, a platform called VoxNet will be developed.  VoxNet is an integrated software and hardware package which will be a quantum leap forward beyond existing technology in for main areas:  software, near-real time event recognition, energy efficiency, and a much longer communication range. &lt;br/&gt;&lt;br/&gt;VoxNet will be a new, highly integrated, deployable acoustic sensor node with a lower unit cost, and lower energy cost than any existing system.  VoxNet will include a highly optimized system software and driver to reduce energy costs through duty cycling. In addition, new 2D/3D algorithms to localize the source of the sound will be developed. These new algorithms will run in near-real-time on a distributed network of VoxNet nodes, enabling users to detect and identify vocalizing animals while in the field. A powerful and easy-to-use software environment based on the WaveScope programming model and the XStream distributed stream processing system (technology partially developed under NSF support at MIT) will be developed.  Finally, the system will be tested in the field to both census birds and identify individually alarm calling marmots.  &lt;br/&gt;&lt;br/&gt;The development of tools for field biologists to use will create new ways to census biodiversity, and ask here-to-for impossible or difficult-to-ask questions about the spatial and temporal dynamics of vocal displays. When deployed, we expect these tools to generate novel and important discoveries. The dissemination of these tools will enhance research productivity in behavior, ecology and evolutionary biology.  And, these tools will create novel ways to census, conserve, and manage biodiversity. The process of developing these tools will create integrative educational opportunities for undergraduates and graduate students.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/20/2008</MinAmdLetterDate>
<MaxAmdLetterDate>03/21/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0754247</AwardID>
<Investigator>
<FirstName>Kung</FirstName>
<LastName>Yao</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kung Yao</PI_FULL_NAME>
<EmailAddress>yao@ee.ucla.edu</EmailAddress>
<PI_PHON>3102064304</PI_PHON>
<NSF_ID>000201422</NSF_ID>
<StartDate>03/20/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Charles</FirstName>
<LastName>Taylor</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Charles E Taylor</PI_FULL_NAME>
<EmailAddress>Taylor@biology.ucla.edu</EmailAddress>
<PI_PHON>3108256850</PI_PHON>
<NSF_ID>000335850</NSF_ID>
<StartDate>03/20/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Blumstein</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel T Blumstein</PI_FULL_NAME>
<EmailAddress>marmots@ucla.edu</EmailAddress>
<PI_PHON>3102674746</PI_PHON>
<NSF_ID>000207243</NSF_ID>
<StartDate>03/20/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Los Angeles</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900951406</ZipCode>
<PhoneNumber>3107940102</PhoneNumber>
<StreetAddress>10889 Wilshire Boulevard</StreetAddress>
<StreetAddress2><![CDATA[Suite 700]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA33</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>092530369</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, LOS ANGELES</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Los Angeles]]></Name>
<CityName>LOS ANGELES</CityName>
<StateCode>CA</StateCode>
<ZipCode>900951406</ZipCode>
<StreetAddress><![CDATA[10889 Wilshire Boulevard]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>33</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA33</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1108</Code>
<Text>INSTRUMENTAT &amp; INSTRUMENT DEVP</Text>
</ProgramElement>
<ProgramElement>
<Code>7226</Code>
<Text>HUMAN RESOURCES</Text>
</ProgramElement>
<ProgramReference>
<Code>1108</Code>
<Text>INSTRUMENTAT &amp; INSTRUMENT DEVP</Text>
</ProgramReference>
<ProgramReference>
<Code>9104</Code>
<Text>ENVIRONMENTAL BIOTECHNOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>BIOT</Code>
<Text>BIOTECHNOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~181452</FUND_OBLG>
<FUND_OBLG>2009~123884</FUND_OBLG>
<FUND_OBLG>2010~137129</FUND_OBLG>
<FUND_OBLG>2011~10000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The overall goal of the project is was build tools for wildlife biologists to inventory animals by detecting, recording, and analyzing their sounds and for field biologists to ask questions about the temporal and spatial dynamics of acoustic communication.&nbsp; Many species produce sounds, and by identifying and localizing them, we can census biodiversity and study the natural dynamics of communication.&nbsp; Typically, these will be vocal sounds, such as bird song, or mammal or frog calls, but in theory, the equipment and algorithms can be used for other sorts of sounds (such as the stridulations of cricket wings).</p> <p>&nbsp;</p> <p>The grant supported the construction of new, robust hardware and relatively easy to use software that field biologists are now using.&nbsp; Our platform, called VoxNet, is an integrated software and hardware package which is a quantum leap forward beyond existing technology in for main areas:&nbsp; software, near-real time event recognition, energy efficiency, and a much longer communication range. VoxNet nodes are highly integrated, deployable acoustic sensor nodes with a lower unit cost, and lower energy cost than previous existing systems.&nbsp; VoxNet includes a highly optimized system software and driver to reduce energy costs through duty cycling. &nbsp;In addition, we developed new algorithms to identify and localize vocalizing animals, including in three dimensions.</p> <p>&nbsp;</p> <p>The development of these tools for field biologists to use will create new ways to census biodiversity, and ask here-to-for impossible or difficult-to-ask questions about the spatial and temporal dynamics of vocal displays. We expect these tools to generate novel and important discoveries. We are freely sharing both software code and hardware schematics with the research community so as to enhance research productivity in behavior, ecology and evolutionary biology.&nbsp; We hope that these tools will create novel ways to census, conserve, and manage biodiversity. The process of developing these tools has created integrative educational opportunities for undergraduates, graduate students, and postdoctoral fellows. And, we have begun to share the bird song recordings used to develop these algorithms with the broader research community.</p> <p class="IDBR-bullet">&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/20/2012<br>      Modified by: Daniel&nbsp;T&nbsp;Blumstein</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The overall goal of the project is was build tools for wildlife biologists to inventory animals by detecting, recording, and analyzing their sounds and for field biologists to ask questions about the temporal and spatial dynamics of acoustic communication.  Many species produce sounds, and by identifying and localizing them, we can census biodiversity and study the natural dynamics of communication.  Typically, these will be vocal sounds, such as bird song, or mammal or frog calls, but in theory, the equipment and algorithms can be used for other sorts of sounds (such as the stridulations of cricket wings).     The grant supported the construction of new, robust hardware and relatively easy to use software that field biologists are now using.  Our platform, called VoxNet, is an integrated software and hardware package which is a quantum leap forward beyond existing technology in for main areas:  software, near-real time event recognition, energy efficiency, and a much longer communication range. VoxNet nodes are highly integrated, deployable acoustic sensor nodes with a lower unit cost, and lower energy cost than previous existing systems.  VoxNet includes a highly optimized system software and driver to reduce energy costs through duty cycling.  In addition, we developed new algorithms to identify and localize vocalizing animals, including in three dimensions.     The development of these tools for field biologists to use will create new ways to census biodiversity, and ask here-to-for impossible or difficult-to-ask questions about the spatial and temporal dynamics of vocal displays. We expect these tools to generate novel and important discoveries. We are freely sharing both software code and hardware schematics with the research community so as to enhance research productivity in behavior, ecology and evolutionary biology.  We hope that these tools will create novel ways to census, conserve, and manage biodiversity. The process of developing these tools has created integrative educational opportunities for undergraduates, graduate students, and postdoctoral fellows. And, we have begun to share the bird song recordings used to develop these algorithms with the broader research community.               Last Modified: 04/20/2012       Submitted by: Daniel T Blumstein]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
