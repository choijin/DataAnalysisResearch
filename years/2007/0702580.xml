<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Images with Normals: Acquisition, Analysis, and Depiction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
<AwardExpirationDate>08/31/2011</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>308000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Rosenblum</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Rusinkiewicz&lt;br/&gt;Princeton University&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Abstract:&lt;br/&gt;&lt;br/&gt;The development of computer-based methods for stylized depiction of 3D models promises to help scientists and engineers produce clear and compelling illustrations and visualizations.  However, despite steady progress on making 3D acquisition inexpensive and practical, obtaining complete 3D models of complex objects remains challenging.  This project investigates the creation of illustrations from a data type lying between simple 2D images and full 3D models:  images with a surface normal stored at each pixel.  These ``RGBN images'' have the potential of becoming a widely-used data type because of the ease, flexibility, and quality with which they may be acquired, and because they contain enough information to permit many analysis and depiction tasks.  That is, they combine an acquisition process only mildly more complex than that for digital photographs with the power and flexibility of tools originally developed for full 3D models.  Methods for RGBN shape analysis and nonphotorealistic rendering will allow for exploration and communication of surface shape and detail in domains such as medical and technical illustration, art history, and forensic analysis.&lt;br/&gt;&lt;br/&gt;This project encompasses a comprehensive investigation of the RGBN image data type, with the aim of developing a practical pipeline for acquiring images with normals and generating stylized depictions.  On the acquisition side, the project is developing hardware/software acquisition systems for robustly acquiring RGBN images in contexts ranging from millimeter-scale objects through cityscapes, and including both static and moving objects. Next, the project includes a mathematical analysis of methods for signal processing on RGBN images, including scale-space analysis and derivative estimation.  These signal processing techniques are used to develop methods for depicting shape and color, including shading, line drawing with suggestive contours and crease lines, exaggerated shading, and enhancement of depth discontinuities.  Finally, RGBN analysis and processing algorithms such as texture analysis/synthesis, inpainting, and similarity-based search are being developed.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>06/06/2007</MinAmdLetterDate>
<MaxAmdLetterDate>05/11/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0702580</AwardID>
<Investigator>
<FirstName>Szymon</FirstName>
<LastName>Rusinkiewicz</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Szymon M Rusinkiewicz</PI_FULL_NAME>
<EmailAddress>smr@princeton.edu</EmailAddress>
<PI_PHON>6092587479</PI_PHON>
<NSF_ID>000379377</NSF_ID>
<StartDate>06/06/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Princeton University</Name>
<CityName>Princeton</CityName>
<ZipCode>085442020</ZipCode>
<PhoneNumber>6092583090</PhoneNumber>
<StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 36]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002484665</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF PRINCETON UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002484665</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Princeton University]]></Name>
<CityName>Princeton</CityName>
<StateCode>NJ</StateCode>
<ZipCode>085442020</ZipCode>
<StreetAddress><![CDATA[Off. of Research &amp; Proj. Adm]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramElement>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramElement>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0107</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~107404</FUND_OBLG>
<FUND_OBLG>2008~192596</FUND_OBLG>
<FUND_OBLG>2010~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The development of computer-based methods for stylized depiction promises to help scientists and engineers produce clear and unambiguous illustrations, diagrams, and visualizations.&nbsp; Tools for shape analysis and nonphotorealistic rendering allow for exploration and communication of surface shape and detail in domains such as medical and technical illustration, art history, and forensic analysis.<br /><br />This project investigated the creation of illustrations from a type of data lying between simple 2D images and full 3D models:&nbsp; images with a surface orientation ("normal") stored at each pixel (or "RGBN images", combining RGB color with a normal at each pixel).&nbsp; These have the potential of becoming a widely-used data type because of the ease, flexibility, and quality with which they may be acquired, and because they contain enough information to permit many analysis and depiction tasks.&nbsp; That is, they combine an acquisition process only mildly more complex than that for digital photographs with the power and flexibility of tools similar to those originally developed for full 3D models.<br /><br />In 2007-2008, we began by investigating inexpensive capture methods for RGBN images and multi-light image collections.&nbsp; These consist of high-quality cameras (digital SLR), and either hand-held flash or ambient illumination.&nbsp; In addition, as part of a project to document and reconstruct 3500-year-old frescoes excavated at the Akrotiri site in Santorini, Greece, we investigated the use of conventional flat-bed scanners for capturing high-quality RGBN images of nearly-flat objects.<br /><br />We also investigated adaptations of traditional signal processing techniques (e.g., bilateral filtering, curvature estimation, scale-space decomposition, segmentation) to RGBN images.&nbsp; These can, in turn, be used to adapt a variety of known non-photorealistic rendering (NPR) methods to these datasets.&nbsp; In particular, we have shown how to perform the analogues of toon shading, line drawing, curvature shading, and exaggerated shading with this datatype.<br /><br />In 2009, we extended our methods to perform high-speed, multi-view capture of RGBN images of human performances, utilizing a novel lighting dome (at USC ICT) to perform the capture.&nbsp; We investigated an approach to obtaining a complete surface model by matching and integrating the (possibly inaccurate) normal maps observed from different directions.&nbsp; The result was dynamic 3D geometry of moving surfaces at unprecedented speeds and accuracies.<br /><br />In 2010, we extended these methods to an even larger class of applications, investigating the use of RGBN images to perform shape matching on fragmented frescoes (obtained from both Akrotiri and sites in Belgium and the Netherlands).&nbsp; We developed new classes of local surface feature descriptors used for shape matching, and showed that descriptors based on surface normals are more discriminative than those based on color, while remaining more practical than those based on full 3D models.<br /><br />Finally, we have also investigated an methods for "reversing" the ideas of RGBN imaging, to manufacture surfaces with given surface shape.&nbsp; The methods range from a technique investigated in 2007 for automatically producing bas-relief sculpture, to techniques published in 2009 and 2010 that explore manufacturing shiny and translucent surfaces.</p><br> <p>            Last Modified: 03/24/2012<br>      Modified by: Szymon&nbsp;M&nbsp;Rusinkiewicz</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div c...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The development of computer-based methods for stylized depiction promises to help scientists and engineers produce clear and unambiguous illustrations, diagrams, and visualizations.  Tools for shape analysis and nonphotorealistic rendering allow for exploration and communication of surface shape and detail in domains such as medical and technical illustration, art history, and forensic analysis.  This project investigated the creation of illustrations from a type of data lying between simple 2D images and full 3D models:  images with a surface orientation ("normal") stored at each pixel (or "RGBN images", combining RGB color with a normal at each pixel).  These have the potential of becoming a widely-used data type because of the ease, flexibility, and quality with which they may be acquired, and because they contain enough information to permit many analysis and depiction tasks.  That is, they combine an acquisition process only mildly more complex than that for digital photographs with the power and flexibility of tools similar to those originally developed for full 3D models.  In 2007-2008, we began by investigating inexpensive capture methods for RGBN images and multi-light image collections.  These consist of high-quality cameras (digital SLR), and either hand-held flash or ambient illumination.  In addition, as part of a project to document and reconstruct 3500-year-old frescoes excavated at the Akrotiri site in Santorini, Greece, we investigated the use of conventional flat-bed scanners for capturing high-quality RGBN images of nearly-flat objects.  We also investigated adaptations of traditional signal processing techniques (e.g., bilateral filtering, curvature estimation, scale-space decomposition, segmentation) to RGBN images.  These can, in turn, be used to adapt a variety of known non-photorealistic rendering (NPR) methods to these datasets.  In particular, we have shown how to perform the analogues of toon shading, line drawing, curvature shading, and exaggerated shading with this datatype.  In 2009, we extended our methods to perform high-speed, multi-view capture of RGBN images of human performances, utilizing a novel lighting dome (at USC ICT) to perform the capture.  We investigated an approach to obtaining a complete surface model by matching and integrating the (possibly inaccurate) normal maps observed from different directions.  The result was dynamic 3D geometry of moving surfaces at unprecedented speeds and accuracies.  In 2010, we extended these methods to an even larger class of applications, investigating the use of RGBN images to perform shape matching on fragmented frescoes (obtained from both Akrotiri and sites in Belgium and the Netherlands).  We developed new classes of local surface feature descriptors used for shape matching, and showed that descriptors based on surface normals are more discriminative than those based on color, while remaining more practical than those based on full 3D models.  Finally, we have also investigated an methods for "reversing" the ideas of RGBN imaging, to manufacture surfaces with given surface shape.  The methods range from a technique investigated in 2007 for automatically producing bas-relief sculpture, to techniques published in 2009 and 2010 that explore manufacturing shiny and translucent surfaces.       Last Modified: 03/24/2012       Submitted by: Szymon M Rusinkiewicz]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
