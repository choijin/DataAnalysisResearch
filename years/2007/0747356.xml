<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Scalable Image Search and Recognition: Learning to Efficiently Leverage Incomplete Information</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2008</AwardEffectiveDate>
<AwardExpirationDate>05/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>509050</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Abstract&lt;br/&gt;&lt;br/&gt;Title: Scalable Image Search and Recognition: Learning to Efficiently Leverage Incomplete Information&lt;br/&gt;PI: Kristen Grauman&lt;br/&gt;Institution: The University of Texas at Austin&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;As it becomes increasingly feasible to capture, transmit, and store image and video content on a large scale, the need for machine vision algorithms capable of interpreting it is undeniable. The opportunities appear vast, but progress towards large-scale visual recognition hinges on the development of computationally efficient methods that can effectively leverage minimal supervision. The proposed research considers how informative but incomplete cues can contribute to the learning process, with the goal of enabling large volumes of visual data to be efficiently organized and queried, and a greater number of visual categories to be recognized.&lt;br/&gt;&lt;br/&gt;This project intends to advance the scale of the recognition problem by using fragments of supervision, even when they are inexact or dynamic. The PI and her team will develop methods to allow very large image databases to be searched according to distance functions inferred from sparse similarity constraints. They will consider visual category learning scenarios where the system itself actively requests only the most useful information, and integrates ambiguous cues from external modalities such as text. As knowledge about an image collection evolves over time, so must the associated search structure. The PI will investigate ways to adapt image indexing techniques according to dynamic constraints. The proposed technical plan calls for a combination of ideas from vision, learning, and algorithms. Scalable recognition and image search will affect the extent to which visual data can be accessed and mined, making this work relevant to other scientific disciplines where images capture vital information but currently lack proper tools for large-scale analysis. The project also entails complementary educational and outreach activities aimed at engaging students in research, furthering communication across related areas, and encouraging young students to consider studying computer science or engineering.&lt;br/&gt;&lt;br/&gt;Updates will be available from: http://www.cs.utexas.edu/¡­grauman/&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/11/2008</MinAmdLetterDate>
<MaxAmdLetterDate>03/30/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0747356</AwardID>
<Investigator>
<FirstName>Kristen</FirstName>
<LastName>Grauman</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kristen L Grauman</PI_FULL_NAME>
<EmailAddress>grauman@cs.utexas.edu</EmailAddress>
<PI_PHON>5124719521</PI_PHON>
<NSF_ID>000282504</NSF_ID>
<StartDate>04/11/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787595316</ZipCode>
<StreetAddress><![CDATA[3925 W Braker Lane, Ste 3.340]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~251700</FUND_OBLG>
<FUND_OBLG>2009~30000</FUND_OBLG>
<FUND_OBLG>2010~29050</FUND_OBLG>
<FUND_OBLG>2011~198300</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <p>The underlying goal of the project was to make it possible to efficiently index large volumes of visual data (images or videos) based on their content---a functionality that has the potential to greatly benefit a variety of users, from personal consumers to scientists and engineers.&nbsp; To this end, the main technical goal was to explore ways to effectively leverage incomplete information in a computationally efficient manner for the sake of visual search and recognition.&nbsp;</p> <p>&nbsp;</p> <p>In terms of intellectual merit, there are two key areas of technical contributions from the project.&nbsp; The first is the development of novel hashing algorithms for approximate nearest neighbor search---particularly for learned metrics, kernel functions, and margin-based large-scale active learning.&nbsp; The second is new methods for visual learning in spite of weakly labeled or scarce labeled data, which included new methods for unsupervised visual pattern mining and exploiting tagged images.&nbsp; Throughout, the project also explored in depth the computer vision applications for object recognition and image retrieval that can exploit these new algorithms.&nbsp; The work yielded numerous conference and journal papers in top computer vision and machine learning publications.</p> <p>&nbsp;</p> <p>In terms of broader impact, the key outcomes of the project entail graduate and undergraduate student training and mentorship, outreach efforts for promoting wider participation in computer science education, and scientific impact of the newly developed algorithms.&nbsp; &nbsp;The project helped train Ph.D. students in the areas of this research, as well as general skills needed to perform and present research. It also supported the PI&rsquo;s work with individual undergraduate students on independent research projects, helping them learn research skills and prepare for graduate school or employment in STEM areas.&nbsp; The project's outreach component contributed to efforts that widen participation in computer science, with particular emphasis on reaching female students and K-12 students.&nbsp; Finally, the generality of the search and learning approaches developed makes them transferrable to problems beyond those tackled in the project, including outside of computer vision.</p> <p>&nbsp;</p><br> <p>            Last Modified: 07/31/2015<br>      Modified by: Kristen&nbsp;L&nbsp;Grauman</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[    The underlying goal of the project was to make it possible to efficiently index large volumes of visual data (images or videos) based on their content---a functionality that has the potential to greatly benefit a variety of users, from personal consumers to scientists and engineers.  To this end, the main technical goal was to explore ways to effectively leverage incomplete information in a computationally efficient manner for the sake of visual search and recognition.      In terms of intellectual merit, there are two key areas of technical contributions from the project.  The first is the development of novel hashing algorithms for approximate nearest neighbor search---particularly for learned metrics, kernel functions, and margin-based large-scale active learning.  The second is new methods for visual learning in spite of weakly labeled or scarce labeled data, which included new methods for unsupervised visual pattern mining and exploiting tagged images.  Throughout, the project also explored in depth the computer vision applications for object recognition and image retrieval that can exploit these new algorithms.  The work yielded numerous conference and journal papers in top computer vision and machine learning publications.     In terms of broader impact, the key outcomes of the project entail graduate and undergraduate student training and mentorship, outreach efforts for promoting wider participation in computer science education, and scientific impact of the newly developed algorithms.   The project helped train Ph.D. students in the areas of this research, as well as general skills needed to perform and present research. It also supported the PIÆs work with individual undergraduate students on independent research projects, helping them learn research skills and prepare for graduate school or employment in STEM areas.  The project's outreach component contributed to efforts that widen participation in computer science, with particular emphasis on reaching female students and K-12 students.  Finally, the generality of the search and learning approaches developed makes them transferrable to problems beyond those tackled in the project, including outside of computer vision.          Last Modified: 07/31/2015       Submitted by: Kristen L Grauman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
