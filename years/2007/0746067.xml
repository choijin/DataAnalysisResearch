<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Learning Complex Auditory Categories</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2008</AwardEffectiveDate>
<AwardExpirationDate>03/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>229666.00</AwardTotalIntnAmount>
<AwardAmount>229666</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The growth in globalization across traditional language boundaries suggests a need for efficient second language (L2) acquisition training regimens. One of the most significant challenges for adult language learners is learning to hear fine distinctions among non-native sounds not used in the native language; such learning may require decades of experience with the second language. A classic example is the difficulty native Japanese have learning English /r/ and /l/, a sound contrast not present in Japanese. With prior NSF support, Drs. Holt and Lotto have uncovered principles of auditory learning using controlled experiments with non-speech sounds and have used these principles to design optimal training regimens. This project uncovered how characteristics of training, feedback and presentation mode affected auditory learning. &lt;br/&gt;&lt;br/&gt;The present project will apply these findings to adult learning of non-native speech sounds, with the aim of producing more efficient L2 learning. One series of studies will investigate the benefits of video-game-based training (found to foster non-speech category learning) in learning non-native speech sounds. Another series of experiments will test whether manipulation of the variability of sound cues, found to be important in non-speech auditory learning in prior research, is effective in shifting the attention listeners give to these cues in second-language learning. Such shifts appear to be important for many cases of L2 learning, such as native Japanese speakers learning English /r/ and /l/. Beyond practical application in adult second language learning, the project has important theoretical implications for understanding human auditory perception and language processing. Such understanding is a prerequisite to developing rehabilitative techniques for disorders such as autism, dyslexia, central auditory processing disorder and specific language impairment.</AbstractNarration>
<MinAmdLetterDate>03/31/2008</MinAmdLetterDate>
<MaxAmdLetterDate>01/11/2010</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0746067</AwardID>
<Investigator>
<FirstName>Lori</FirstName>
<LastName>Holt</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lori L Holt</PI_FULL_NAME>
<EmailAddress>lholt@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122684964</PI_PHON>
<NSF_ID>000338923</NSF_ID>
<StartDate>03/31/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~75920</FUND_OBLG>
<FUND_OBLG>2009~74559</FUND_OBLG>
<FUND_OBLG>2010~79187</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span class="Apple" style="font-size: 16px;"><span style="font-size: 14pt; color: black;">Hearing the minute differences that differentiate foreign speech sounds is notoriously difficult for adults learning a new language. For example, we have found that native Japanese adults who have lived in North America for more than ten years continue to struggle with hearing the difference between English /r/ and /l/ as in&nbsp;<em>rock&nbsp;</em>versus&nbsp;<em>lock.</em>There is a long history of research attempting to understand why adults&rsquo; learning is so poor for foreign speech sound learning. In general, this research suggests that there may be fundamental limits on the adult plasticity that prevent native-like acquisition of some foreign language sounds. In our NSF-supported research program we have developed an engagingvideo game to tap into powerful implicit learning and motivational mechanisms that promotes as much adult foreign language speech sound learning in 2.5 hours as has been demonstrated previously in 45 hours of training. Further, we have found that the effectiveness of this novel training approach scales to real-world language problems like discovering words from a continuous stream of fluent speech. Our research&nbsp;</span><span class="apple"><span style="font-size: 14.5pt; color: black;">also&nbsp;has led us to characterize of some of the learning challenges present across different languages through detailed acoustic analysis of speech across languages. This research is important because it suggests new ways of thinking about how to maximize adult brain plasticity and invites novel approaches to address the practical demands of adult language learning, a highly significant issue directly impacting military personnel and those engaged in global economic pursuits. In addition, our research project has contributed greatly to training the next generation of behavioral scientists who can skillfully incorporate cross-disciplinary perspectives in addressing challenges in human behavior, neuroscience and linguistics.</span></span></span></p><br> <p>            Last Modified: 03/29/2012<br>      Modified by: Lori&nbsp;L&nbsp;Holt</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Hearing the minute differences that differentiate foreign speech sounds is notoriously difficult for adults learning a new language. For example, we have found that native Japanese adults who have lived in North America for more than ten years continue to struggle with hearing the difference between English /r/ and /l/ as in rock versus lock.There is a long history of research attempting to understand why adultsÃ† learning is so poor for foreign speech sound learning. In general, this research suggests that there may be fundamental limits on the adult plasticity that prevent native-like acquisition of some foreign language sounds. In our NSF-supported research program we have developed an engagingvideo game to tap into powerful implicit learning and motivational mechanisms that promotes as much adult foreign language speech sound learning in 2.5 hours as has been demonstrated previously in 45 hours of training. Further, we have found that the effectiveness of this novel training approach scales to real-world language problems like discovering words from a continuous stream of fluent speech. Our research also has led us to characterize of some of the learning challenges present across different languages through detailed acoustic analysis of speech across languages. This research is important because it suggests new ways of thinking about how to maximize adult brain plasticity and invites novel approaches to address the practical demands of adult language learning, a highly significant issue directly impacting military personnel and those engaged in global economic pursuits. In addition, our research project has contributed greatly to training the next generation of behavioral scientists who can skillfully incorporate cross-disciplinary perspectives in addressing challenges in human behavior, neuroscience and linguistics.       Last Modified: 03/29/2012       Submitted by: Lori L Holt]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
