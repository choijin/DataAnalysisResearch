<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Characterizing Neural Mechanisms of State Estimation in the Posterior Parietal Cortex</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/15/2008</AwardEffectiveDate>
<AwardExpirationDate>04/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>609813.00</AwardTotalIntnAmount>
<AwardAmount>609813</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>08090200</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>IOS</Abbreviation>
<LongName>Division Of Integrative Organismal Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Coppola</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This project is aimed at understanding how the brain combines different forms of sensory information in order to help plan and modify our movements.  Information about the current state of objects in the world (i.e. their position and velocity) is transmitted to the brain by our senses, which describe this state using very different "languages".  For example, our eyes provide information about the visual motion of a fly buzzing around us with respect to where we are currently looking, while our ears relay complementary information, the buzzing sound generated by the flapping of the fly's wings, with respect to our heads.  Similarly, if we want to reach out and swat this fly, the brain must combine information from our eyes with information from the moving arm, which speaks yet another language altogether.  Clearly some sort of "interpreter" is required to allow the senses to work together to solve this task.  It is currently believed that the posterior parietal cortex (PPC) may serve this role, but precisely how this is accomplished is unclear. This project is aimed at understanding the role of the PPC in the perception of arm state, using electrophysiological recording techniques combined with a virtual reality based behavioral paradigm.&lt;br/&gt;&lt;br/&gt;This project also involves the development of a new biotechnology course at the high school level that will incorporate concepts and techniques relevant to systems neuroscience and neural engineering, which are currently underemphasized or not emphasized at all in high school level biotechnology curricula. Bioengineering graduate and undergraduate students will assist in developing and delivering various components of the course and select high school students will be given the opportunity for summer research internships.  This will provide the groundwork for a continuous pipeline of well-prepared biotechnology students from high school to college to grad school/industry.</AbstractNarration>
<MinAmdLetterDate>04/03/2008</MinAmdLetterDate>
<MaxAmdLetterDate>03/20/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0746398</AwardID>
<Investigator>
<FirstName>Christopher</FirstName>
<LastName>Buneo</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christopher A Buneo</PI_FULL_NAME>
<EmailAddress>christopher.buneo@asu.edu</EmailAddress>
<PI_PHON>4807270841</PI_PHON>
<NSF_ID>000177914</NSF_ID>
<StartDate>04/03/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2><![CDATA[660 South Mill Avenue, Suite 310]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>TEMPE</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852816011</ZipCode>
<StreetAddress><![CDATA[ORSPA]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>7713</Code>
<Text>Activation</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1096</Code>
<Text>NEURAL SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9183</Code>
<Text>GENERAL FOUNDATIONS OF BIOTECHNOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>BIOT</Code>
<Text>BIOTECHNOLOGY</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~106467</FUND_OBLG>
<FUND_OBLG>2009~112309</FUND_OBLG>
<FUND_OBLG>2010~118265</FUND_OBLG>
<FUND_OBLG>2011~134160</FUND_OBLG>
<FUND_OBLG>2012~138612</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The <strong>intellectual merit </strong>of this research was aimed at understanding how neurons in one part of the brain, the posterior parietal cortex (PPC), combine different types of sensory information during the production of arm movements.&nbsp; Many parts of the brain combine sensory information (for example, visual information coming from our eyes and auditory information from our ears), which is thought to help us perceive the world around us.&nbsp; Combining sensory information is also helpful for brain areas involved in movement, as combining visual information with proprioception (our sense of position and movement derived from our muscles, joint, and skin) is thought to help the brain better estimate where our limbs are in space, which is important for planning movements.&nbsp; &nbsp;</p> <p>In this project, we characterized how cells in the PPC of the rhesus monkey combine visual and proprioceptive information about arm position.&nbsp; This was done by training monkeys to reach to targets in a virtual reality environment.&nbsp; Once the animal acquired a given target they were then required to hold their arm at that position.&nbsp; On half the experimental trials they were allowed to see a visual representation of their arm while on the other trials they held their arm at the required position in darkness.&nbsp; We then analyzed how the activity of the neurons differed in the presence and absence of visual information.</p> <p>We found that for the majority of PPC cells, activity was reduced in the presence of vision.&nbsp; This was somewhat surprising as multisensory integration (the combining of sensory information in the brain) usually manifests as <em>more</em> activity when two pieces of sensory information are combined.&nbsp; Here we found the opposite; most cells were <em>less</em> active when both proprioceptive information and visual information were available.&nbsp; However, overall activity on trials with vision was better correlated with an animal&rsquo;s arm position than activity on trials without vision.&nbsp; In other words, when cells were less active, they were better indicators of the animal&rsquo;s arm position.&nbsp; Although this seems counterintuitive it can be explained by the relatively simple relationship between how active a cell is and how variable that activity is on a trial by trial basis.&nbsp; When cells are more active these activity patterns are also generally more variable.&nbsp; Thus, in our experiment when PPC cells were <em>less</em> active in the presence of vison they were also <em>less</em> variable in their activity patterns, which means their activity could better distinguish one arm position from another.&nbsp;</p> <p>Our finding that the combining of visual and proprioceptive information is associated with decreased activity in the PPC but a more accurate indication of arm position is consistent with recent findings from areas involved in perception.&nbsp; &nbsp;A recent study of the auditory cortex showed that activity and variability decreased in many cells when visual and auditory information were combined.&nbsp; Moreover, these effects were associated with more information about the presented stimuli.&nbsp; This suggests that multisensory suppression of activity improves the information content of this activity during the performance of not only sensorimotor tasks (such as ours) but perceptual tasks as well. &nbsp;It should be noted that there are many areas in the brain that are involved in producing arm movements and many of these areas are also multisensory.&nbsp; Future work should be directed at understanding how sensory information is combined in these other regions as well and how the resulting changes in activity across all areas are reflected in motor behavior.&nbsp;</p> <p>&nbsp;The <strong>broader impact </strong>of this research was the integration of research and education for advancing an u...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The intellectual merit of this research was aimed at understanding how neurons in one part of the brain, the posterior parietal cortex (PPC), combine different types of sensory information during the production of arm movements.  Many parts of the brain combine sensory information (for example, visual information coming from our eyes and auditory information from our ears), which is thought to help us perceive the world around us.  Combining sensory information is also helpful for brain areas involved in movement, as combining visual information with proprioception (our sense of position and movement derived from our muscles, joint, and skin) is thought to help the brain better estimate where our limbs are in space, which is important for planning movements.     In this project, we characterized how cells in the PPC of the rhesus monkey combine visual and proprioceptive information about arm position.  This was done by training monkeys to reach to targets in a virtual reality environment.  Once the animal acquired a given target they were then required to hold their arm at that position.  On half the experimental trials they were allowed to see a visual representation of their arm while on the other trials they held their arm at the required position in darkness.  We then analyzed how the activity of the neurons differed in the presence and absence of visual information.  We found that for the majority of PPC cells, activity was reduced in the presence of vision.  This was somewhat surprising as multisensory integration (the combining of sensory information in the brain) usually manifests as more activity when two pieces of sensory information are combined.  Here we found the opposite; most cells were less active when both proprioceptive information and visual information were available.  However, overall activity on trials with vision was better correlated with an animalÆs arm position than activity on trials without vision.  In other words, when cells were less active, they were better indicators of the animalÆs arm position.  Although this seems counterintuitive it can be explained by the relatively simple relationship between how active a cell is and how variable that activity is on a trial by trial basis.  When cells are more active these activity patterns are also generally more variable.  Thus, in our experiment when PPC cells were less active in the presence of vison they were also less variable in their activity patterns, which means their activity could better distinguish one arm position from another.   Our finding that the combining of visual and proprioceptive information is associated with decreased activity in the PPC but a more accurate indication of arm position is consistent with recent findings from areas involved in perception.   A recent study of the auditory cortex showed that activity and variability decreased in many cells when visual and auditory information were combined.  Moreover, these effects were associated with more information about the presented stimuli.  This suggests that multisensory suppression of activity improves the information content of this activity during the performance of not only sensorimotor tasks (such as ours) but perceptual tasks as well.  It should be noted that there are many areas in the brain that are involved in producing arm movements and many of these areas are also multisensory.  Future work should be directed at understanding how sensory information is combined in these other regions as well and how the resulting changes in activity across all areas are reflected in motor behavior.    The broader impact of this research was the integration of research and education for advancing an understanding of neuroscience and neural engineering, at the high school level. This was addressed using a combination of outreach and curriculum development. Educational modules were developed for the biomedical program at Campo Verde High School of the Gilbert Unified School District (G...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
