<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Automaton Theories of Human Sentence Comprehension</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2008</AwardEffectiveDate>
<AwardExpirationDate>08/31/2015</AwardExpirationDate>
<AwardTotalIntnAmount>498370.00</AwardTotalIntnAmount>
<AwardAmount>504370</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Badecker</SignBlockName>
<PO_EMAI>wbadecke@nsf.gov</PO_EMAI>
<PO_PHON>7032925069</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The mental process humans use to comprehend a sentence, like this one,&lt;br/&gt;can be simulated by automata.  These automata are specific kinds of computer programs that, when run, mimic the steps cognitive scientists think occur between the point at which people read or hear individual words and when they know what whole sentences mean.&lt;br/&gt;&lt;br/&gt;In this project, the research team is constructing automata in which three factors, usually studied singly, are combined.  The first factor is the linguistic grammar, which characterizes what people know when they know a language.  The second is the control strategy, which determines the particular order in which comprehenders deploy this knowledge in time.  The third factor is the theory of memory for words and phrases.  The researchers expect these triply-endowed automata to match human performance in a variety of sentence types.  In addition, since automata can be mathematically altered to take into account alternative grammars, memories and control strategies, they can be used to gain insights that would not come easily from behavioral experiments with real people. For example, behavioral experiments with elderly adults might show the effects of reduced memory capacity on the sentence comprehension process.  However, using automata allows the researchers to selectively alter not only memory but also control and grammar, revealing the role of each in ways that human experiments could not.  Similarly, mathematically rendering the automaton's grammar more Spanish-like (as opposed to English-like), for example, could also yield a deeper understanding of how the three factors interact and, more broadly, how people understand one another.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/18/2008</MinAmdLetterDate>
<MaxAmdLetterDate>06/03/2014</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0741666</AwardID>
<Investigator>
<FirstName>John</FirstName>
<LastName>Hale</LastName>
<PI_MID_INIT>T</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>John T Hale</PI_FULL_NAME>
<EmailAddress>jthale@uga.edu</EmailAddress>
<PI_PHON>7065422115</PI_PHON>
<NSF_ID>000221519</NSF_ID>
<StartDate>09/18/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY23</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>872612445</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CORNELL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002254837</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Cornell University]]></Name>
<CityName>Ithaca</CityName>
<StateCode>NY</StateCode>
<ZipCode>148502820</ZipCode>
<StreetAddress><![CDATA[373 Pine Tree Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>23</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY23</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1311</Code>
<Text>Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~123887</FUND_OBLG>
<FUND_OBLG>2009~77253</FUND_OBLG>
<FUND_OBLG>2010~110414</FUND_OBLG>
<FUND_OBLG>2011~192816</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project developed computer models of the process of language understanding.The scientific target was the process that occurs in the mind of a listener or reader who perceives words, one by one, combining them into a structured interpretation.</p> <p><br />These models incorporated three different conceptions of sentence structure.</p> <p>One such conception is dependency grammar, in which words "depend" on other words. Using this notion of grammar, the investigators compared the role of memory and expectancy in a model system where they systematically varied the amount of "memory" available. The results highlighted the role of experience in German readers' comprehension process (Boston et al 2011).</p> <p>Another conception is phrase structure grammar. Here, words and phrases nestle within each other. Using this notion of grammar, the investigators formalized a tradeoff between the need to understand quickly and the need to accurately comprehend what a speaker or writer intended. This approach highlighted the difference between a comprehender having a sharp idea about upcoming words, as opposed to being uncertain about the rest of the sentence (Hale 2011).</p> <p>Yet a third conception is formalized in Minimalist Grammars (Stabler 1997). This type of grammar derives phrase structure, but also the sorts of long-distance dependencies that we see in English questions, relative clauses and topicalized sentences. Using this notion of grammar, the investigators were able to derive the difficulty profiles of Chinese, Japanese and Korean relative clauses. These languages are crucial for adjudicating between theories based on memory load and theories based upon grammatical uncertainty. A theory based on grammatical uncertainty emerged as uniquely able to cover the available data (Yun et al 2015).</p> <p>These last two conceptions of grammar both turned out be helpful in analyzing signals collected with brain imaging (Hale 2015).</p> <p>The project led to freely-available software for calculating the consequences of these models as well as a book-length introduction to them (Hale 2014).</p> <p><br /><br />M. F. Boston, J. Hale, S. Vasishth, and R. Kliegl. Parallel processing and sentence comprehension difficulty. Language and Cognitive Processes, 26:301&ndash;349, 2011.<br />J. Hale. What a rational parser would do. Cognitive Science, 35(3):399&ndash;443, 2011.<br />J. Hale. Automaton theories of human sentence comprehension. CSLI Publications, September 2014.<br />J. Hale, D. Lutz, W.-M. Luh, and J. Brennan. Modeling fMRI time courses with linguistic structure at various grain sizes. In Proceedings of the 6th Workshop on Cognitive Modeling and Computational Linguistics, pages 89&ndash;97, Denver, Colorado, June 2015. Association for Computational Linguistics.<br />E. Stabler. Derivational minimalism. In C. Retore, editor, Logical Aspects of Computational Linguistics, pages 68&ndash;95. Springer, 1997.<br />J. Yun, Z. Chen, T. Hunter, J. Whitman, and J. Hale. Uncertainty in processing relative clauses across East Asian languages. Journal of East Asian Linguistics, 24(2):113&ndash;148, 2015.</p> <p>&nbsp;</p><br> <p>            Last Modified: 10/21/2015<br>      Modified by: John&nbsp;T&nbsp;Hale</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project developed computer models of the process of language understanding.The scientific target was the process that occurs in the mind of a listener or reader who perceives words, one by one, combining them into a structured interpretation.   These models incorporated three different conceptions of sentence structure.  One such conception is dependency grammar, in which words "depend" on other words. Using this notion of grammar, the investigators compared the role of memory and expectancy in a model system where they systematically varied the amount of "memory" available. The results highlighted the role of experience in German readers' comprehension process (Boston et al 2011).  Another conception is phrase structure grammar. Here, words and phrases nestle within each other. Using this notion of grammar, the investigators formalized a tradeoff between the need to understand quickly and the need to accurately comprehend what a speaker or writer intended. This approach highlighted the difference between a comprehender having a sharp idea about upcoming words, as opposed to being uncertain about the rest of the sentence (Hale 2011).  Yet a third conception is formalized in Minimalist Grammars (Stabler 1997). This type of grammar derives phrase structure, but also the sorts of long-distance dependencies that we see in English questions, relative clauses and topicalized sentences. Using this notion of grammar, the investigators were able to derive the difficulty profiles of Chinese, Japanese and Korean relative clauses. These languages are crucial for adjudicating between theories based on memory load and theories based upon grammatical uncertainty. A theory based on grammatical uncertainty emerged as uniquely able to cover the available data (Yun et al 2015).  These last two conceptions of grammar both turned out be helpful in analyzing signals collected with brain imaging (Hale 2015).  The project led to freely-available software for calculating the consequences of these models as well as a book-length introduction to them (Hale 2014).    M. F. Boston, J. Hale, S. Vasishth, and R. Kliegl. Parallel processing and sentence comprehension difficulty. Language and Cognitive Processes, 26:301&ndash;349, 2011. J. Hale. What a rational parser would do. Cognitive Science, 35(3):399&ndash;443, 2011. J. Hale. Automaton theories of human sentence comprehension. CSLI Publications, September 2014. J. Hale, D. Lutz, W.-M. Luh, and J. Brennan. Modeling fMRI time courses with linguistic structure at various grain sizes. In Proceedings of the 6th Workshop on Cognitive Modeling and Computational Linguistics, pages 89&ndash;97, Denver, Colorado, June 2015. Association for Computational Linguistics. E. Stabler. Derivational minimalism. In C. Retore, editor, Logical Aspects of Computational Linguistics, pages 68&ndash;95. Springer, 1997. J. Yun, Z. Chen, T. Hunter, J. Whitman, and J. Hale. Uncertainty in processing relative clauses across East Asian languages. Journal of East Asian Linguistics, 24(2):113&ndash;148, 2015.          Last Modified: 10/21/2015       Submitted by: John T Hale]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
