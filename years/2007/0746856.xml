<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:  Systematic Software Testing Using Test Abstractions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/01/2008</AwardEffectiveDate>
<AwardExpirationDate>05/31/2014</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>406000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>CCF-0746856&lt;br/&gt;CAREER: Systematic Software Testing Using Test Abstractions&lt;br/&gt;Darko Marinov&lt;br/&gt;&lt;br/&gt;Software testing is important for increasing software reliability, but expensive and can account for more than half of the software development cost.  Automated testing can significantly help programmers to develop and maintain reliable software.  However, test automation is mainly limited to test execution, while test generation remains manual and mostly ad hoc, which not only makes it hard to develop tests initially but also to maintain and reuse tests.&lt;br/&gt;&lt;br/&gt;To reduce the cost of developing, maintaining, and reusing tests, this project investigates a novel approach to automated testing based on test abstractions.  Conceptually, each test abstraction provides a high-level description of a desired test suite: programmers do not need to manually write large suites of individual tests but instead write only test abstractions from which tools automatically generate individual tests.  This project investigates five aspects of test abstractions: (1) What languages to use for writing test abstractions?  (2) Which tests to generate from test abstractions? (3) How to automatically generate tests from test abstractions? (4) How to determine whether the code under test passed or failed? (5) How to determine which failing tests are caused by the same code error?&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/08/2008</MinAmdLetterDate>
<MaxAmdLetterDate>06/01/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0746856</AwardID>
<Investigator>
<FirstName>Darko</FirstName>
<LastName>Marinov</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Darko Marinov</PI_FULL_NAME>
<EmailAddress>marinov@illinois.edu</EmailAddress>
<PI_PHON>2172656117</PI_PHON>
<NSF_ID>000095315</NSF_ID>
<StartDate>02/08/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207406</ZipCode>
<StreetAddress><![CDATA[1901 South First Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7944</Code>
<Text>SOFTWARE ENG &amp; FORMAL METHODS</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0111</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~80000</FUND_OBLG>
<FUND_OBLG>2009~80000</FUND_OBLG>
<FUND_OBLG>2010~80000</FUND_OBLG>
<FUND_OBLG>2011~86000</FUND_OBLG>
<FUND_OBLG>2012~80000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Software testing is important for increasing software quality but expensive and can account for more than half of the software development cost. Automated testing can significantly help programmers to develop and maintain reliable software. However, test automation is mainly limited to test execution, while test generation remains manual and mostly ad hoc, which not only makes it hard to develop tests initially but also to maintain and reuse tests.</p> <p>To reduce the cost of developing, maintaining, and reusing tests, this project investigated a novel approach to automated testing based on "test abstractions". Conceptually, each test abstraction provides a high-level description of a desired test suite: programmers do not need to manually write large suites of individual tests but instead write only test abstractions from which tools automatically generate individual tests. This project investigated five aspects of test abstractions: (1) What languages to use for writing test abstractions. (2) Which tests to generate from test abstractions. (3) How to automatically generate tests from test abstractions. (4) How to determine whether the code under test passed or failed. (5) How to determine which failing tests are caused by the same code error.</p> <p>The grant partially supported 40 papers (including one award-winning paper, two conference papers invited for journal submissions, and one more paper nominated for a best-paper award), public release of 11 testing tools and datasets (available from http://mir.cs.illinois.edu page on software and data), and training of at least a dozen graduate students (including three PhD theses and four MS theses) and eight undergraduate students. The broader impacts also include the use of test abstractions to find hundreds of bugs in various open-source software projects (linked from the above page), and the research is a step toward better testing tools and frameworks for reducing bugs in software, thus helping to improve the quality of software used in our daily lives.</p><br> <p>            Last Modified: 08/26/2014<br>      Modified by: Darko&nbsp;Marinov</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Software testing is important for increasing software quality but expensive and can account for more than half of the software development cost. Automated testing can significantly help programmers to develop and maintain reliable software. However, test automation is mainly limited to test execution, while test generation remains manual and mostly ad hoc, which not only makes it hard to develop tests initially but also to maintain and reuse tests.  To reduce the cost of developing, maintaining, and reusing tests, this project investigated a novel approach to automated testing based on "test abstractions". Conceptually, each test abstraction provides a high-level description of a desired test suite: programmers do not need to manually write large suites of individual tests but instead write only test abstractions from which tools automatically generate individual tests. This project investigated five aspects of test abstractions: (1) What languages to use for writing test abstractions. (2) Which tests to generate from test abstractions. (3) How to automatically generate tests from test abstractions. (4) How to determine whether the code under test passed or failed. (5) How to determine which failing tests are caused by the same code error.  The grant partially supported 40 papers (including one award-winning paper, two conference papers invited for journal submissions, and one more paper nominated for a best-paper award), public release of 11 testing tools and datasets (available from http://mir.cs.illinois.edu page on software and data), and training of at least a dozen graduate students (including three PhD theses and four MS theses) and eight undergraduate students. The broader impacts also include the use of test abstractions to find hundreds of bugs in various open-source software projects (linked from the above page), and the research is a step toward better testing tools and frameworks for reducing bugs in software, thus helping to improve the quality of software used in our daily lives.       Last Modified: 08/26/2014       Submitted by: Darko Marinov]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
