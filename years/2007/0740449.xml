<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>STTR Phase I: Eye-Gaze Correction for more Effective Telepresence</AwardTitle>
    <AwardEffectiveDate>01/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2009</AwardExpirationDate>
    <AwardAmount>198946</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ian M. Bennett</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Small Business Technology Transfer Research (STTR) project will develop a novel real-time depth sensor that exploits the inverse square law, e.g., the light radiance falls off as a function of distance. Compared to existing commercial full-frame sensors, it is expected to provide high resolution (e.g. 640x480) depth maps while reducing the cost by one or two orders of magnitude. Secondly it utilizes a hybrid approach for scene depth estimation, combing both active sensors and passive stereovision in an optimization-based probabilistic framework. The outcome from the project is expected to significantly improve the quality and robustness of the synthesized view.&lt;br/&gt;&lt;br/&gt;The telepresence market is enjoying 100% annualized growth with a projected market size of $1B in year 2011. It is anticipated that the proposed technology could offer tremendous communication improvements for telepresence systems. As cameras, large displays, and broadband become more and more ubiquitous, telepresence can be realized on every desktop and laptop. With correct eye gaze, life size imagery, and fluid motion, compelling telepresence experiences could someday significantly reduce the need for travel. Additionally, the proposed active range sensor can deliver video streams with depth information, which can be used in many markets such as immersive gaming, intelligent automotive, security, distance education, and factory automation.</AbstractNarration>
    <MinAmdLetterDate>11/02/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>01/28/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0740449</AwardID>
    <Investigator>
      <FirstName>Paul</FirstName>
      <LastName>Mostert</LastName>
      <EmailAddress>pmostert@alltel.net</EmailAddress>
      <StartDate>01/15/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Lei</FirstName>
      <LastName>Feng</LastName>
      <EmailAddress>lei@directi2i.com</EmailAddress>
      <StartDate>11/02/2007</StartDate>
      <EndDate>01/15/2008</EndDate>
      <RoleCode>Former Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Direct i2i Technologies Inc</Name>
      <CityName>Lexington</CityName>
      <ZipCode>405150000</ZipCode>
      <PhoneNumber>9192281162</PhoneNumber>
      <StreetAddress>4609 Braxton Ct</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Kentucky</StateName>
      <StateCode>KY</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0308000</Code>
      <Name>Industrial Technology</Name>
    </FoaInformation>
  </Award>
</rootTag>
