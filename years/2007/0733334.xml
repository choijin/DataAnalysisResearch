<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Formative Assessment Delivery System (FADS)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2007</AwardEffectiveDate>
<AwardExpirationDate>07/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>1499980.00</AwardTotalIntnAmount>
<AwardAmount>1499980</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Elizabeth VanderPutten</SignBlockName>
<PO_EMAI>evanderp@nsf.gov</PO_EMAI>
<PO_PHON>7032925147</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project uses new psychometric techniques to create a technological tool that could evaluate how well students in the 4th-8th mathematics and science classrooms respond to complex performance tasks. It will extend a research direction begun many years ago on classroom assessment initiated by the investigator.&lt;br/&gt;&lt;br/&gt;The purpose of this tool is to improve the instruction of teachers in mathematics and science. It will produce real-time individualized diagnoses of instructional needs to help teachers plan instruction that specifically addresses the learning needs of each student in that class.  Wilson has been working on related techniques for a number of years and in this project will work with two experimental curricula, the IQWST science curriculum from the University of Michigan and Northwestern University, and the CDMW data analysis project from Vanderbilt University.</AbstractNarration>
<MinAmdLetterDate>08/27/2007</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2011</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.076</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0733334</AwardID>
<Investigator>
<FirstName>Mark</FirstName>
<LastName>Wilson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mark Wilson</PI_FULL_NAME>
<EmailAddress>MarkW@berkeley.edu</EmailAddress>
<PI_PHON>5106427966</PI_PHON>
<NSF_ID>000307804</NSF_ID>
<StartDate>08/27/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>BERKELEY</CityName>
<StateCode>CA</StateCode>
<ZipCode>947101749</ZipCode>
<StreetAddress><![CDATA[Sponsored Projects Office]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7625</Code>
<Text>REAL</Text>
</ProgramElement>
<ProgramElement>
<Code>7645</Code>
<Text>Discovery Research K-12</Text>
</ProgramElement>
<ProgramReference>
<Code>9177</Code>
<Text>ELEMENTARY/SECONDARY EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0407</Code>
<Name>NSF,Education &amp; Human Resource</Name>
<APP_SYMB_ID>490106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0409</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0410</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0411</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2007~575015</FUND_OBLG>
<FUND_OBLG>2009~307803</FUND_OBLG>
<FUND_OBLG>2010~311580</FUND_OBLG>
<FUND_OBLG>2011~305582</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><h1>Overview</h1> <p>The three main goals of fads are to create an integrated assessment system that (1) focuses on robust evidence with sound measurement qualities, (2) employs tools and reports of high interest and usability for teachers, and (3) supports the use of rich and engaging content designs for assessment.</p> <p>fads is based on generalizing and integrating a range of assessment tools previously developed by the Berkeley Evaluation and Assessment Research (bear) Center for other projects. In addition to the fads software development, validity and usability trials took place with teacher-developed content in innovative item forms. This paper describes the activities and products that were developed during the fads project.</p> <h1>Summary of Project Activities</h1> <p>The fads project was developed in collaboration with two partner curriculums that served as prototype, providing the content that was used to populate the system. The first partner was Investigating and Questioning our World through Science and Technology (iqwst), developed at the University of Michigan and Northwestern University, and designed for elementary and middle school grades.&nbsp; The second partner was Constructing Data, Modeling Worlds (cdmw), developed at Vanderbilt University and the bear Center, and it is designed for middle-school grades.</p> <p>The first year of the fads project was dedicated to two main strands of work. On the one hand was the analysis of the types of questions used in the curriculums, while on the other hand was the design of the fads software architecture.</p> <p>Accordingly, on the content side the first year of the project was dedicated to reverse engineering of as many different item types as we can identify in the two partner curricula. This involved the selection of progress variables, modules, and sample items from each curriculum for prototyping in computer-deliverable forms. Meanwhile, in relation to the design of the software architecture, the team worked during the first year on the development of initial use cases for fads, the design of the fads database, and finally, in the development of prototypes for one or more aspects of user interface to the fads database.</p> <p>During the second year of the project, the separation of the initial strands of work was blurred when the project activities concentrated in the gathering teacher input into the design of the student and teacher interfaces for item taking, as well as their feedback on the development of prototypes for computerized item delivery and prototypes for scoring facilities for constructed responses. Moreover, the input from teachers working in these curriculums became central for the collection of usability feedback from initial computer-delivered item prototypes.</p> <p>In addition to the work directly related with the content analysis and programming tasks of fads, the project included a series of field trials to examine the quality and usability of the system that were conducted during the third and fourth year of the project. These trials contributed to collect evidence about the actual use of the system in the context of the two partner curriculums, which provided the opportunity to collect feedback directly from teachers and students and modify different aspects of the application accordingly.</p> <p>For the first round of field testing, which is referred to as the <em>alpha trials</em>, the goal was to implement and test single on-line assessments for both iqwst sixth grade physics and cdmw middle-school mathematics. The aim was not to examine the usefulness of the fads system for formative assessment per se, but rather to use the software in order to find bugs or difficulties with using the software and to assess initial student and teacher reactions to the system.&nbsp; Science teachers using the iqwst physics curriculum and their students participated in one arm of the alpha tr...]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[Overview  The three main goals of fads are to create an integrated assessment system that (1) focuses on robust evidence with sound measurement qualities, (2) employs tools and reports of high interest and usability for teachers, and (3) supports the use of rich and engaging content designs for assessment.  fads is based on generalizing and integrating a range of assessment tools previously developed by the Berkeley Evaluation and Assessment Research (bear) Center for other projects. In addition to the fads software development, validity and usability trials took place with teacher-developed content in innovative item forms. This paper describes the activities and products that were developed during the fads project. Summary of Project Activities  The fads project was developed in collaboration with two partner curriculums that served as prototype, providing the content that was used to populate the system. The first partner was Investigating and Questioning our World through Science and Technology (iqwst), developed at the University of Michigan and Northwestern University, and designed for elementary and middle school grades.  The second partner was Constructing Data, Modeling Worlds (cdmw), developed at Vanderbilt University and the bear Center, and it is designed for middle-school grades.  The first year of the fads project was dedicated to two main strands of work. On the one hand was the analysis of the types of questions used in the curriculums, while on the other hand was the design of the fads software architecture.  Accordingly, on the content side the first year of the project was dedicated to reverse engineering of as many different item types as we can identify in the two partner curricula. This involved the selection of progress variables, modules, and sample items from each curriculum for prototyping in computer-deliverable forms. Meanwhile, in relation to the design of the software architecture, the team worked during the first year on the development of initial use cases for fads, the design of the fads database, and finally, in the development of prototypes for one or more aspects of user interface to the fads database.  During the second year of the project, the separation of the initial strands of work was blurred when the project activities concentrated in the gathering teacher input into the design of the student and teacher interfaces for item taking, as well as their feedback on the development of prototypes for computerized item delivery and prototypes for scoring facilities for constructed responses. Moreover, the input from teachers working in these curriculums became central for the collection of usability feedback from initial computer-delivered item prototypes.  In addition to the work directly related with the content analysis and programming tasks of fads, the project included a series of field trials to examine the quality and usability of the system that were conducted during the third and fourth year of the project. These trials contributed to collect evidence about the actual use of the system in the context of the two partner curriculums, which provided the opportunity to collect feedback directly from teachers and students and modify different aspects of the application accordingly.  For the first round of field testing, which is referred to as the alpha trials, the goal was to implement and test single on-line assessments for both iqwst sixth grade physics and cdmw middle-school mathematics. The aim was not to examine the usefulness of the fads system for formative assessment per se, but rather to use the software in order to find bugs or difficulties with using the software and to assess initial student and teacher reactions to the system.  Science teachers using the iqwst physics curriculum and their students participated in one arm of the alpha trials, and mathematics teachers using the cdmw curriculum participated in the other arm.  Both arms of the alpha trials were conducted in Nove...]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
