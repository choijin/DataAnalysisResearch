<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>The Computational Intractability of Machine Learning Tasks</AwardTitle>
<AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
<AwardExpirationDate>02/29/2012</AwardExpirationDate>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dmitry Maslov</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This research involves understanding the computational complexity of&lt;br/&gt;fundamental machine learning problems.  In particular, the&lt;br/&gt;investigators study which classic learning problems are unlikely to&lt;br/&gt;admit efficient solutions.  In terms of broader impact, this line of&lt;br/&gt;research aids practitioners and algorithm designers as it outlines&lt;br/&gt;fundamental stumbling blocks for creating powerful learning systems.&lt;br/&gt;For example, can we reduce difficult open problems from cryptography&lt;br/&gt;(e.g., factoring) and complexity theory (e.g., NP-complete languages)&lt;br/&gt;to certain problems in machine learning?  If so, this provides strong&lt;br/&gt;evidence that particular machine learning problems are hopelessly&lt;br/&gt;intractable.  Another avenue of research is to prove unconditional&lt;br/&gt;lower bounds on the resources required to infer functions in&lt;br/&gt;restricted learning models.&lt;br/&gt;&lt;br/&gt;The intellectual merit of the research lies in finding new reductions&lt;br/&gt;between problems in cryptography and complexity theory-- in particular&lt;br/&gt;communication complexity-- and problems from learning theory.  For&lt;br/&gt;example, the PI studies the impact of lattice-based cryptography in&lt;br/&gt;machine learning and examines its implications for the DNF learning&lt;br/&gt;problem.  Additionally, the PI researches the use of communication&lt;br/&gt;complexity to rule out learning simple concept classes via small sets&lt;br/&gt;of arbitrary features.  We further delineate the role of Fourier&lt;br/&gt;analysis in proving lower bounds in the well known model of&lt;br/&gt;Statistical Query learning.  Finally, this research investigates the&lt;br/&gt;relationships between NP-completeness and circuit complexity to&lt;br/&gt;general questions about proper learning and distribution-specific&lt;br/&gt;query learning.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/24/2007</MinAmdLetterDate>
<MaxAmdLetterDate>08/24/2007</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0728536</AwardID>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Klivans</LastName>
<EmailAddress>klivans@cs.utexas.edu</EmailAddress>
<StartDate>08/24/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>2860</Code>
<Text>THEORY OF COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
