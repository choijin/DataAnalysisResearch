<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase II:  Implementation, Testing and Refinement of a Hybrid Distributed / Traditional System for Broadcasting Live and Pre-Recorded Content to Large Online Audiences</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/15/2008</AwardEffectiveDate>
<AwardExpirationDate>01/31/2013</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>1128000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Errol Arkilic</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>This Phase II project has two technical goals. In Year 1 the focus is on increasing the video quality (bit rate) of NFT delivered broadcasts, while keeping bandwidth costs low. In Year 2 the focus shifts to expanding product support to Mac and other non-Windows systems. Network Foundation Technologies (NFT) has developed a patented distributed broadcast technology that overcomes many of the current bottlenecks. The key difference between the NFT approach and the traditional approach is that with NFT the computers and Internet connections of the viewers watching a broadcast help deliver that broadcast on to other viewers. &lt;br/&gt;&lt;br/&gt;Network Foundation Technologies' products and technology have the potential to significantly impact the way television-style broadcasting is conducted over the Internet, greatly increasing the number of voices that can be heard. While NFT's near term goal is "to bring television to the Internet", the long term goal is to give ordinary citizens their own "online television stations."   &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/19/2008</MinAmdLetterDate>
<MaxAmdLetterDate>02/29/2012</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0750136</AwardID>
<Investigator>
<FirstName>Mike</FirstName>
<LastName>O'Neal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mike O'Neal</PI_FULL_NAME>
<EmailAddress>mike@nft-tv.com</EmailAddress>
<PI_PHON>3182575432</PI_PHON>
<NSF_ID>000068379</NSF_ID>
<StartDate>02/19/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Network Foundation Technologies</Name>
<CityName>Ruston</CityName>
<ZipCode>712720000</ZipCode>
<PhoneNumber>3182575432</PhoneNumber>
<StreetAddress>818 Nelson Avenue</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Louisiana</StateName>
<StateCode>LA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>LA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>622452055</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NETWORK FOUNDATION TECHNOLOGIE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Network Foundation Technologies]]></Name>
<CityName>Ruston</CityName>
<StateCode>LA</StateCode>
<ZipCode>712720000</ZipCode>
<StreetAddress><![CDATA[818 Nelson Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Louisiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>LA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0308000</Code>
<Name>Industrial Technology</Name>
</FoaInformation>
<ProgramElement>
<Code>5373</Code>
<Text>SBIR Phase II</Text>
</ProgramElement>
<ProgramReference>
<Code>116E</Code>
<Text>RESEARCH EXP FOR UNDERGRADS</Text>
</ProgramReference>
<ProgramReference>
<Code>1640</Code>
<Text>INFORMATION TECHNOLOGY RESEARC</Text>
</ProgramReference>
<ProgramReference>
<Code>5373</Code>
<Text>SMALL BUSINESS PHASE II</Text>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>9231</Code>
<Text>SUPPL FOR UNDERGRAD RES ASSIST</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0110</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0112</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~512000</FUND_OBLG>
<FUND_OBLG>2010~516000</FUND_OBLG>
<FUND_OBLG>2012~100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project supported, in part, the development of a novel system for efficient online broadcasting of audio and video content.&nbsp;</p> <p>Most TV style online broadcasting (defined as the streaming of content where the entire audience receives the same content at the same time) is conducted by large server farms which send a separate copy of the content stream to each and every viewer.&nbsp; &nbsp;Thus, 1,000 viewers require 1,000 separate streams while 100,000 viewers require 100,000 separate streams.&nbsp; Such a system does not easily and cost effectively scale to television-size audiences of millions of viewers.&nbsp;</p> <p>Our system bypasses the server farm bottleneck by employing the computers and Internet connections of the viewers watching a broadcast to also retransmit that broadcast on to a small number of other individuals (usually one or two other viewers).&nbsp; Viewers are arranged in a pyramid type fashion where a server provides the stream to a small number of individuals, who in turn each transmit the stream to a small number of individuals, who in turn each transmit the stream to a small number of individuals, and so on and so forth.&nbsp; The end result is a distributed broadcast environment where the effort (processing power and bandwidth) needed to support the broadcast is spread evenly throughout the broadcast network, rather than being focused on centralized servers.&nbsp; The benefits of such a distributed network include lower costs and less energy consumption as the viewers&rsquo; computers would be powered on and connected to the Internet whether they were simply receiving the broadcast or both receiving and retransmitting the broadcast.</p> <p>Significant effort has been devoted to implementing a robust system that can handle the constant turnover in viewers where new viewers are continually tuning in and other viewers are tuning out.&nbsp; The resulting system provides steady and reliable content transmission even in situations of very high audience turnover.</p> <p>The system has been successfully tested under real world conditions with paying customers and was in fact used by the Arena Football league for the online broadcasting of the vast majority of their games during the 2010 and 2011 seasons.</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/20/2012<br>      Modified by: Mike&nbsp;O'neal</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project supported, in part, the development of a novel system for efficient online broadcasting of audio and video content.   Most TV style online broadcasting (defined as the streaming of content where the entire audience receives the same content at the same time) is conducted by large server farms which send a separate copy of the content stream to each and every viewer.   Thus, 1,000 viewers require 1,000 separate streams while 100,000 viewers require 100,000 separate streams.  Such a system does not easily and cost effectively scale to television-size audiences of millions of viewers.   Our system bypasses the server farm bottleneck by employing the computers and Internet connections of the viewers watching a broadcast to also retransmit that broadcast on to a small number of other individuals (usually one or two other viewers).  Viewers are arranged in a pyramid type fashion where a server provides the stream to a small number of individuals, who in turn each transmit the stream to a small number of individuals, who in turn each transmit the stream to a small number of individuals, and so on and so forth.  The end result is a distributed broadcast environment where the effort (processing power and bandwidth) needed to support the broadcast is spread evenly throughout the broadcast network, rather than being focused on centralized servers.  The benefits of such a distributed network include lower costs and less energy consumption as the viewersÃ† computers would be powered on and connected to the Internet whether they were simply receiving the broadcast or both receiving and retransmitting the broadcast.  Significant effort has been devoted to implementing a robust system that can handle the constant turnover in viewers where new viewers are continually tuning in and other viewers are tuning out.  The resulting system provides steady and reliable content transmission even in situations of very high audience turnover.  The system has been successfully tested under real world conditions with paying customers and was in fact used by the Arena Football league for the online broadcasting of the vast majority of their games during the 2010 and 2011 seasons.          Last Modified: 04/20/2012       Submitted by: Mike O'neal]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
