<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Collaborative Research: Bion-Inspired Navigation</AwardTitle>
    <AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2011</AwardExpirationDate>
    <AwardAmount>210534</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>There has been successful research on establishing metric representations of the environment required together with motion planning for any navigation task. Such metric maps require though excessive amounts of storage to memorize the robots' trajectories and all landmark positions. On the other hand, animals have excellent navigation capabilities based on visual sensing and simple path integration.&lt;br/&gt;&lt;br/&gt;The technical approach can be summarized in the modeling of places and the map creation. An abstraction hierarchy is introduced for the visual modeling of places with the layers of feature landmarks, salient regions, and objects. A novel image similarity score will be used for tracking as well as loop closing and is robust to perceptual aliasing. Objects are learned from training sets of appearances of salient landmarks and in the highest abstraction level places are labeled depending on their object content and the constellation of objects in space. Topological maps are made of nodes labeled with place labels and associated with an action to neighboring nodes obtained from the relative pose between the two places. Learning of the maps will happen in the space of all possible topologies of place sets. A collaboration with biologists will try to cross-validate hypotheses based on visual inputs obtained from the animal's viewpoint.</AbstractNarration>
    <MinAmdLetterDate>08/16/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>08/10/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0713134</AwardID>
    <Investigator>
      <FirstName>Frank</FirstName>
      <LastName>Dellaert</LastName>
      <EmailAddress>dellaert@cc.gatech.edu</EmailAddress>
      <StartDate>08/16/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
  </Award>
</rootTag>
