<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CT-ISG: BIRT - Biometric Identification Red Team</AwardTitle>
<AwardEffectiveDate>08/01/2007</AwardEffectiveDate>
<AwardExpirationDate>07/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>350000.00</AwardTotalIntnAmount>
<AwardAmount>350000</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jeremy Epstein</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Summary Statement, Biometric Identification Red Team (BIRT)&lt;br/&gt;The BIRT methodology will aid biometric system designers in making effective refinements in their systems. The measurement of biological characteristics (biometrics) such as fingerprints and facial images provides a means of identification that neither needs to be carried nor remembered. Evaluation of biometrics has traditionally been focused on the ability of biometric systems to identify members from a population, e.g., for  purposes of authentication. As these systems come into more widespread use, attempts will naturally be made to test and frustrate their ability to identify individuals. Understanding these attempts requires a fundamental new analytic approach, based on modeling the capabilities of an adversary with full generality. BIRT develops the adversary model using the information controlled by the adversary, e.g., for recognition, the clothing, glasses and makeup they wear. BIRT uses  disinformation theory to abstractly  model the adversary capabilities to mask their identity from an interested observer. Disinformation theory is inspired by Shannon's information theoretic model for communications systems, but  views the ?noise source?  as controlled by the adversary, abstractly modeling the  capacity of the adversary to control the noise in the channel (for example, by transforming the image ?signal?) between the biometric sender being identified and the biometric system receiving the identifying  information. Face recognition systems will be used to  gain experience with and refine the disinformation theory models,  with a variety of  disguises used as disinformation sources.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/02/2007</MinAmdLetterDate>
<MaxAmdLetterDate>06/15/2009</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0716552</AwardID>
<Investigator>
<FirstName>Jonathan</FirstName>
<LastName>Smith</LastName>
<EmailAddress>jms@central.cis.upenn.edu</EmailAddress>
<StartDate>08/02/2007</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jianbo</FirstName>
<LastName>Shi</LastName>
<EmailAddress>jshi@cis.upenn.edu</EmailAddress>
<StartDate>08/02/2007</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<ProgramElement>
<Code>7371</Code>
<Text>CYBER TRUST</Text>
</ProgramElement>
<ProgramElement>
<Code>7795</Code>
<Text>TRUSTWORTHY COMPUTING</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
