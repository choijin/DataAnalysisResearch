<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Robust Decoding of Neural Command for Real Time Human Machine Interactions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2019</AwardEffectiveDate>
<AwardExpirationDate>03/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>549494.00</AwardTotalIntnAmount>
<AwardAmount>549494</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>07020000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CBET</Abbreviation>
<LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Grace Hwang</SignBlockName>
<PO_EMAI>ghwang@nsf.gov</PO_EMAI>
<PO_PHON>7032924271</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The human hand can produce complex dexterous movements, unmatched by any current robotic hand.  Such sophisticated movements are often taken for granted.  A majority of individuals with a stroke, however, tend to have persistent hand functional deficits, limiting their ability of living independently.  Human-machine interactions hold great potential to restore motor functions of stroke survivors.  Recently advanced rehabilitative or assistive techniques (e.g., hand exoskeletons) have the ability to substantially enhance motor functions.  However, few of these state-of-the-art techniques have been successfully translated to end users, and one critical limiting factor is the challenge in controlling the many movement directions robustly.  Therefore, there is an urgent need to develop non-invasive and robust neural decoding approaches for human-machine interactions that can directly translate to clinical applications.  Accordingly, this project aims to decode the neural command sent from the brain that controls individual finger movements.  This is accomplished by reading activities in the spinal cord using muscle electrical signals obtained from the skin surface.  The decoded finger-specific neural command can then be used to control rehabilitation or assistive robots, which can substantially enhance the quality of human-machine interactions.  This approach can also facilitate wide applications of robotic rehabilitation or assistance in stroke survivors.  The non-invasive nature of the techniques has a great potential for readily clinical translations.  The proposed research will be integrated with education through graduate and undergraduate research involvement and new course development.  Summer projects and demonstration materials on human-machine interactions will be developed for K-12 students.  Outreach programs will be organized to expose the proposed research topics to underrepresented students, highlight the opportunities in science and engineering, and promote students interests in choosing future STEM careers.&lt;br/&gt;&lt;br/&gt;The principal investigator's long-term research goal is to develop highly innovative non-invasive tools for human-machine interactions, with a particular interest in better understanding the neuromechanical properties of the upper extremity, and improve the functional performance in individuals with a central or peripheral injury.  Toward this goal, this project aims to decode the descending neural command that controls individual finger movements by extracting spinal motoneuron discharge activities using source separation of high-density electromyogram signals (HD-EMG) from finger muscles. The non-invasive, robust, and real-time neural decoding technique developed will be easy to implement, can accommodate the different impairment levels of individual stroke survivors, and will substantially improve the control quality of exoskeleton or neuroprosthesis. The Research Plan is organized under three aims.  The FIRST AIM is to develop non-invasive offline and real-time neural decoding approaches based on spinal motoneuron discharge probabilities at the population level that are directed at a designated finger.  This aim addresses the need for non-invasive human-machine interface signals that allow robust and intuitive interaction between humans and machines.  Surface EMG signals will be recorded over the targeted extrinsic muscles using an 8x16 channel electrode array with an inter-electrodedistance of 10 mm.  Motoneuron discharge activities will be obtained from different independent component analysis (ICA)-based HD EMG decomposition methods that will be evaluated on both simulated and experimental EMG data obtained from stroke survivors and healthy control subjects.  The decoding accuracy will be evaluated by comparing the decoded neural drive with finger force output and joint angles. Given that binary motoneuron discharge events are used, the decoded neural drive signals are expected to be robust to changes in action potential properties in the EMG signals, background noise, and motion artifacts. The evaluation of the performance and boundary conditions of different source separation algorithms can further ensure robust decoding performance in a variety of situations, especially in clinical populations.  The SECOND AIM is to classify the neural command specific to individual finger movements. This aim addresses the need for effective control of individual/flexible finger movement in developing human-machine interactions. Surface EMG signals will be recorded over the extrinsic forearm muscles using an 8x16 channel HD EMG electrode array and over the intrinsic extensors muscles to fingers using an 8x4 channel grid. Different features from HD EMG activities and from motor unit (MU) distributions will be extracted. With macro and micro level features, different muscle activation regions will be identified for individual fingers using pattern classification approaches. The neural drive associated with specific finger movement will then be calculated based on MU discharge activities of a specific finger. The classified neural command signals can enable robust and flexible control of individual finger movements non-invasively, and dramatically enhance the dexterity of hand function in clinical populations.  The THIRD AIM is to quantify the performance of the decoding technique by controlling a non-invasive neuroprosthesis for dexterous finger grasp patterns. A transcutaneous nerve stimulation technique developed in the PI's group will be used to elicit flexible individual and coordinated finger movements. The neural stimulation system targeting the affected hand of stroke survivors will be controlled by the decoded neural drive from the contralateral/unaffected arm (particularly if the stroke is severe) or from the affected arm, with time-sharing between stimulations and recordings. The force output (force absolute error and force variability) of neural drive controlled stimulation will be compared with the global EMG controlled stimulation to evaluate the performance of the neural decoding technique.  The overall outcomes of the project are expected to ultimately allow stroke survivors to intuitively interact with rehabilitative/assistive devices in a robust and non-invasive manner.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/15/2019</MinAmdLetterDate>
<MaxAmdLetterDate>10/15/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1847319</AwardID>
<Investigator>
<FirstName>Xiaogang</FirstName>
<LastName>Hu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xiaogang Hu</PI_FULL_NAME>
<EmailAddress>xiaogang@unc.edu</EmailAddress>
<PI_PHON>9199660696</PI_PHON>
<NSF_ID>000718699</NSF_ID>
<StartDate>02/15/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Chapel Hill]]></Name>
<CityName>Chapel Hill</CityName>
<StateCode>NC</StateCode>
<ZipCode>275997575</ZipCode>
<StreetAddress><![CDATA[144 MacNider CB #7575]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5342</Code>
<Text>Disability &amp; Rehab Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~434497</FUND_OBLG>
<FUND_OBLG>2020~114997</FUND_OBLG>
</Award>
</rootTag>
