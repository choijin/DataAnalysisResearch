<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Filmmaking for Everyone: Computational Video Editing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2019</AwardEffectiveDate>
<AwardExpirationDate>10/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>224734.00</AwardTotalIntnAmount>
<AwardAmount>224734</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will result from addressing video editing as a software problem. All the hurdles that surround this space - the clunkiness of having to poke at a timeline of clips with your fingers on a rectangle of glass, the time and technical skill required to even know how to put those clips together in a pleasing sequence, and the cost to have someone else do it for you - are all problems that can be solved with computational video editing. The cameras in mobile phones are the most important contemporary tool for artistic expression and cultural communication. The company's mobile video editing platform gives young and economically disadvantaged creators (who may only have a mobile device camera) access to the narrative format of video. With the growing adoption of mobile video by creators and viewers in every corner of the globe, high-quality video editing tools are increasingly needed for mobile platforms.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will investigate the use of video understanding techniques that support the creation of artistic and cultural output. This project will develop algorithms, representations, and datasets that allow consumer-grade devices such as smartphones, tablets, and commodity PCs to understand video and generate narrative video sequences. The goal of this Phase I project is at the intersection of human-computer interaction, computer vision, and computational videography. This project will explore rich semantic embedding spaces, end-to-end trained multi-task neural networks, and large-scale data and their application to video manipulation, enhancement, and the ultimate goal of automated film editing.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>12/21/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1842850</AwardID>
<Investigator>
<FirstName>Genevieve</FirstName>
<LastName>Patterson</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Genevieve Patterson</PI_FULL_NAME>
<EmailAddress>gen@trash.app</EmailAddress>
<PI_PHON>5202753170</PI_PHON>
<NSF_ID>000780842</NSF_ID>
<StartDate>12/21/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>TRASH INC.</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900260000</ZipCode>
<PhoneNumber>5202753170</PhoneNumber>
<StreetAddress>2430 Kent St</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>081177668</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRASH INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[TRASH INC.]]></Name>
<CityName>Brooklyn</CityName>
<StateCode>NY</StateCode>
<ZipCode>112018322</ZipCode>
<StreetAddress><![CDATA[20 Jay St - Suite 312]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~224734</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-765534a7-7fff-1ee6-c24f-c6dbf98effa3"> </span></p> <p dir="ltr"><span>The TRASH iOS app is both a place to edit together videos shot on an iPhone and a place to share video creations with other users. Users select input clips from the videos stored in their phone?s camera roll and proceed to their automatically generated edited video, which is also set to a soundtrack from our TRASH music library. Users can change the suggested soundtrack, pacing, or the color grading and visual effects applied to the output video. Once the user is satisfied with their creation, they can upload their video to their user profile and save their new creation to their own camera roll.&nbsp;</span></p> <p dir="ltr"><span>Initially we hypothesized our app would be most valuable to casual creators who want to make professional looking short form video content and also have a strong motivation to communicate and present themselves in the medium of video. Our initial user personas included people from domains such as fashion, music, and acton sports, which all require video to communicate well.&nbsp; We tested these assumptions through user testing at NYU with people between the ages of 18 to early 30s, 83% of whom were 21 or younger.  They represented 4 countries and 7 states with 12 different majors. We found that what was actually most valuable to our potential customers was fast, easy mobile video editing that made their videos aesthetically better. The test users prioritized speed of creation and a fast way to post new content to the internet. This made us shift our entire research and development program toward this goal.&nbsp;&nbsp;</span></p> <p dir="ltr"><span>During Phase I, TRASH Inc developed three deep learning based video editing algorithms. We have deployed two of these algorithms in our iOS app. Our goal is to simplify video editing to the point where users can shoot, edit, and share professional looking short videos from their phones. Mobile video editing lowers the barrier to entry for videography, empowering a new generation of video creators from underserved populations. Our technical objectives for Phase I were to 1) identify what visual concepts are informative for a baseline editing system, 2) create training/ testing datasets for these concepts, 3) train convolutional neural networks that could recognize cinematic concepts while running on commodity mobile phones, 4) create highlight detection CNNs to pick the best moments out of a user?s raw footage, and 5) train sequence generating neural networks that used our cinema-category classifications and highlight detections to recommend an ideal video sequence in order to automate the entire mobile video editing process.&nbsp;</span></p> <p dir="ltr"><span>We created proprietary CNNs that extract visual features at 10x real-time playback speed on an iPhone 8. Our prototype editing algorithm selects interesting moments from the raw footage using our highlight detection CNN. The output video sequence is ordered using baseline heuristics governed by the estimated cinematic content of the user?s footage. For example, our prototype editor will prefer to open on wide shots or action shots, then proceed to close-up shots. Our heuristics prefer shots where the faces of people or animals are visible.&nbsp;</span></p> <p dir="ltr"><span>We released a beta version of the TRASH app on the iOS app store in June 2019. We had to add a number of new software components to our production software stack to support user accounts, software testing, and user data storage.&nbsp; User reviews cite the speed of editing and the magical experience of seeing their personal videos turned into TRASH creations. As of October 2019, we have 1500 beta users and a 4.5/5 rating on the app store.</span></p> <p>&nbsp;</p><br> <p>            Last Modified: 11/02/2019<br>      Modified by: Genevieve&nbsp;Patterson</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1842850/1842850_10588178_1572737671719_new_app--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1842850/1842850_10588178_1572737671719_new_app--rgov-800width.jpg" title="TRASH iOS App Screenshots"><img src="/por/images/Reports/POR/2019/1842850/1842850_10588178_1572737671719_new_app--rgov-66x44.jpg" alt="TRASH iOS App Screenshots"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Screen capture of in-app process for creating a TRASH video.</div> <div class="imageCredit">TRASH INC</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Genevieve&nbsp;Patterson</div> <div class="imageTitle">TRASH iOS App Screenshots</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1842850/1842850_10588178_1572737731908_oscar_results--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1842850/1842850_10588178_1572737731908_oscar_results--rgov-800width.jpg" title="TRASH Video Category Examples"><img src="/por/images/Reports/POR/2019/1842850/1842850_10588178_1572737731908_oscar_results--rgov-66x44.jpg" alt="TRASH Video Category Examples"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Example Classifications by the TRASH in-app neural networks.</div> <div class="imageCredit">TRASH INC</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Genevieve&nbsp;Patterson</div> <div class="imageTitle">TRASH Video Category Examples</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The TRASH iOS app is both a place to edit together videos shot on an iPhone and a place to share video creations with other users. Users select input clips from the videos stored in their phone?s camera roll and proceed to their automatically generated edited video, which is also set to a soundtrack from our TRASH music library. Users can change the suggested soundtrack, pacing, or the color grading and visual effects applied to the output video. Once the user is satisfied with their creation, they can upload their video to their user profile and save their new creation to their own camera roll.  Initially we hypothesized our app would be most valuable to casual creators who want to make professional looking short form video content and also have a strong motivation to communicate and present themselves in the medium of video. Our initial user personas included people from domains such as fashion, music, and acton sports, which all require video to communicate well.  We tested these assumptions through user testing at NYU with people between the ages of 18 to early 30s, 83% of whom were 21 or younger.  They represented 4 countries and 7 states with 12 different majors. We found that what was actually most valuable to our potential customers was fast, easy mobile video editing that made their videos aesthetically better. The test users prioritized speed of creation and a fast way to post new content to the internet. This made us shift our entire research and development program toward this goal.   During Phase I, TRASH Inc developed three deep learning based video editing algorithms. We have deployed two of these algorithms in our iOS app. Our goal is to simplify video editing to the point where users can shoot, edit, and share professional looking short videos from their phones. Mobile video editing lowers the barrier to entry for videography, empowering a new generation of video creators from underserved populations. Our technical objectives for Phase I were to 1) identify what visual concepts are informative for a baseline editing system, 2) create training/ testing datasets for these concepts, 3) train convolutional neural networks that could recognize cinematic concepts while running on commodity mobile phones, 4) create highlight detection CNNs to pick the best moments out of a user?s raw footage, and 5) train sequence generating neural networks that used our cinema-category classifications and highlight detections to recommend an ideal video sequence in order to automate the entire mobile video editing process.  We created proprietary CNNs that extract visual features at 10x real-time playback speed on an iPhone 8. Our prototype editing algorithm selects interesting moments from the raw footage using our highlight detection CNN. The output video sequence is ordered using baseline heuristics governed by the estimated cinematic content of the user?s footage. For example, our prototype editor will prefer to open on wide shots or action shots, then proceed to close-up shots. Our heuristics prefer shots where the faces of people or animals are visible.  We released a beta version of the TRASH app on the iOS app store in June 2019. We had to add a number of new software components to our production software stack to support user accounts, software testing, and user data storage.  User reviews cite the speed of editing and the magical experience of seeing their personal videos turned into TRASH creations. As of October 2019, we have 1500 beta users and a 4.5/5 rating on the app store.          Last Modified: 11/02/2019       Submitted by: Genevieve Patterson]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
