<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Causal Discovery in the Presence of Measurement Error Theory and Practical Algorithms</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>59967.00</AwardTotalIntnAmount>
<AwardAmount>59967</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The discovery of cause-and-effect relationships is a fundamental notion in science. To find such causal relationships, traditional methods based on interventions or randomized experiments are usually expensive or even impossible. Causal discovery aims to find the underlying causal structure or model from purely observational data and has many applications in various disciplines. Despite its successes on a number of real problems, the presence of measurement error in the observed data can produce serious mistakes in the output of various causal discovery methods. Given the ubiquity of measurement error caused by instruments or proxies used in the measuring process, this problem has been recognized as one of the main obstacles to reliable causal discovery. It is still unknown to what extent the causal structure for relevant variables can be identified in the presence of measurement error, let alone how to develop practical algorithms to solve this problem. This project aims to fill the void. It will investigate what information of the causal model of interest can be recovered from observed data and what assumptions one has to make to achieve successful recovery of the causal information. Based on such theoretical results, the project will then investigate efficient estimation procedures. &lt;br/&gt; &lt;br/&gt;The project will establish theoretical identifiability results for the underlying, true causal structure and, in light of such results, develop practical causal discovery algorithms. Preliminary results show theoretically how measurement error changes the (conditional) independence and dependence relationships in the data, i.e., how the (conditional) independence and independence relations between the observed variables are different from those between the measurement-error-free variables. Based on the preliminary results, several research tasks will be carried out. First, classical causal discovery often assumes a linear-Gaussian model for the data, in which the causal relations are linear and the variables are jointly Gaussian. This project will establish the conditions under which the underlying causal model is identifiable up to an equivalence class or only partially identifiable. Second, this study will investigate how the identifiability of underlying causal structure in the presence of measurement error can actually benefit from the non-Gaussian noise assumption. Third, this study will develop statistically more efficient estimation procedures, by extending the GES method, by exploiting suitable sparsity constraints, or by extending the A* Bayesian network learning procedure. Finally, the above ideas will be extended to deal with related models in causality or statistics, including other contamination models, nonlinear causal models, and Markov networks.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/19/2018</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1829681</AwardID>
<Investigator>
<FirstName>Kun</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kun Zhang</PI_FULL_NAME>
<EmailAddress>kunz1@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122689527</PI_PHON>
<NSF_ID>000709961</NSF_ID>
<StartDate>07/19/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~59967</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Causality is a fundamental notion in science.&nbsp; In our daily life and science, people often attempt to find causal connections, for the purpose of understanding and manipulating systems properly. To find causal relations, traditional methods based on interventions or randomized experiments are usually expensive or even impossible. Causal discovery aims to find the underlying causal structure or model from purely observational data and has many applications in various disciplines. In the past decades, interesting advances in causal discovery were made in fields including machine learning, statistics, and philosophy. Despite its successes in a number of real problems, given that the data to be analyzed are produced by not only the underlying causal process of interest, but also the measuring process and unmeasured background variables, there are a number of practical issues to address for the purpose of achieving practical, reliable causal discovery. For instance, there is often measurement error in the obtained values of the variables because of the used instrument or surrogate to measure the underlying variables, and the presence of measurement error can produce serious mistakes in the output of traditional causal discovery methods; causal relations may be nonstationary for multiple reasons, i.e., they may change over time, across different scenarios, or across subgroups of the population; in a number of situations, variables to be analyzed may be discrete or have mixed continuous and discrete types and, as a consequence, recently developed functional causal model-based methods do not apply; we can only measure a certain number of variables in the studied system, and the existence of unmeasured hidden common causes may cause much trouble for traditional causal discovery methods; a number of datasets, especially those in healthcare, usually have missing values. Towards more practical and reliable causal discovery, this project systematically investigated practical challenges posed in the causal or sampling process or in the environment, including those issues mentioned above, and developed corresponding methods to deal with them. We further applied various causal discovery algorithms, including some of the methods developed in this project, to real problems including climate analysis and brain connectivity estimation, demonstrating the plausibility of research in causal discovery.<br /><br />On the other hand, we are also concerned with how to do realistic machine learning in complex environments. For instance, how can we make optimal predictions in non-stationary environments? Designing recommender systems is essentially a causal problem, and how can we improve such systems with causal approaches? In this project, we further demonstrated why and how the causal perspective helps in learning under data heterogeneity, focusing on the problems of domain adaptation (transfer learning) and recommender system design.<br /><br />The studied problems are widely recognized as being important but difficult to solve. The established theoretical identifiability results for causal discovery will hopefully further inspire a series of future methods to deal with the investigated problems and have immediate impact on advancing the theoretical foundations pertaining to causal discovery in several subject areas including machine learning and statistics, and the developed estimation methods are expected to have direct applications in real-world problems in various disciplines, such as effective connectivity identification in neuroscience and causal modeling in biology.&nbsp; Our results have been disseminated widely to a diverse, interdisciplinary audience, as journal publications in multiple fields, papers presented and published at top machine learning conferences, and presentations at various workshops. We have incorporated causal discovery in the presence of measurement error, nonstationary causal influences, or missing data, and the causal perspective of machine learning and artificial intelligence to existing graduate and undergraduate courses, in order to train next-generating data scientists.<br /><br />Some of the proposed causal discovery methods have been incorporated into the Tetrad package, a publicly available, widely-used causal discovery package developed at Carnegie Mellon University. The implementation of some developed methods is available on GitHub.</p><br> <p>            Last Modified: 11/30/2019<br>      Modified by: Kun&nbsp;Zhang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Causality is a fundamental notion in science.  In our daily life and science, people often attempt to find causal connections, for the purpose of understanding and manipulating systems properly. To find causal relations, traditional methods based on interventions or randomized experiments are usually expensive or even impossible. Causal discovery aims to find the underlying causal structure or model from purely observational data and has many applications in various disciplines. In the past decades, interesting advances in causal discovery were made in fields including machine learning, statistics, and philosophy. Despite its successes in a number of real problems, given that the data to be analyzed are produced by not only the underlying causal process of interest, but also the measuring process and unmeasured background variables, there are a number of practical issues to address for the purpose of achieving practical, reliable causal discovery. For instance, there is often measurement error in the obtained values of the variables because of the used instrument or surrogate to measure the underlying variables, and the presence of measurement error can produce serious mistakes in the output of traditional causal discovery methods; causal relations may be nonstationary for multiple reasons, i.e., they may change over time, across different scenarios, or across subgroups of the population; in a number of situations, variables to be analyzed may be discrete or have mixed continuous and discrete types and, as a consequence, recently developed functional causal model-based methods do not apply; we can only measure a certain number of variables in the studied system, and the existence of unmeasured hidden common causes may cause much trouble for traditional causal discovery methods; a number of datasets, especially those in healthcare, usually have missing values. Towards more practical and reliable causal discovery, this project systematically investigated practical challenges posed in the causal or sampling process or in the environment, including those issues mentioned above, and developed corresponding methods to deal with them. We further applied various causal discovery algorithms, including some of the methods developed in this project, to real problems including climate analysis and brain connectivity estimation, demonstrating the plausibility of research in causal discovery.  On the other hand, we are also concerned with how to do realistic machine learning in complex environments. For instance, how can we make optimal predictions in non-stationary environments? Designing recommender systems is essentially a causal problem, and how can we improve such systems with causal approaches? In this project, we further demonstrated why and how the causal perspective helps in learning under data heterogeneity, focusing on the problems of domain adaptation (transfer learning) and recommender system design.  The studied problems are widely recognized as being important but difficult to solve. The established theoretical identifiability results for causal discovery will hopefully further inspire a series of future methods to deal with the investigated problems and have immediate impact on advancing the theoretical foundations pertaining to causal discovery in several subject areas including machine learning and statistics, and the developed estimation methods are expected to have direct applications in real-world problems in various disciplines, such as effective connectivity identification in neuroscience and causal modeling in biology.  Our results have been disseminated widely to a diverse, interdisciplinary audience, as journal publications in multiple fields, papers presented and published at top machine learning conferences, and presentations at various workshops. We have incorporated causal discovery in the presence of measurement error, nonstationary causal influences, or missing data, and the causal perspective of machine learning and artificial intelligence to existing graduate and undergraduate courses, in order to train next-generating data scientists.  Some of the proposed causal discovery methods have been incorporated into the Tetrad package, a publicly available, widely-used causal discovery package developed at Carnegie Mellon University. The implementation of some developed methods is available on GitHub.       Last Modified: 11/30/2019       Submitted by: Kun Zhang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
