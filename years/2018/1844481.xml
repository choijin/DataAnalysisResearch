<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Valid and Scalable Inference for High-dimensional Statistical Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2019</AwardEffectiveDate>
<AwardExpirationDate>02/29/2024</AwardExpirationDate>
<AwardTotalIntnAmount>402189.00</AwardTotalIntnAmount>
<AwardAmount>237822</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Pena Edsel</SignBlockName>
<PO_EMAI>epena@nsf.gov</PO_EMAI>
<PO_PHON>7032928080</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Due to the advent of "big data" technologies, fine-grained data sets can be collected at unprecedented scales, bringing transformative changes to modern life ranging from healthcare, and social networks, to recommendations systems and commerce. As a result, data-driven methods are becoming de rigueur nowadays, driving the need for increasingly sophisticated algorithms that find subtle statistical patterns in massive amount of data. This trend however is a double-edged sword: on the one hand, modern statistical learning methods help researchers in various fields to discover unexpected patterns from data and to make better decisions impacting everyday life. On the other hand, the rapid growth in the size and scope of data sets as well as the complexity of the methods used has made statistical models less transparent. Employing the derived models without a proper understanding of their validity can lead to many false discoveries, incorrect predictions and massive costs. For example, suppose the medical records of patients are used to develop a model for providing personalized risk score for a chronic disease. A high-risk score can trigger an intervention, such as incentive for healthy behavior, additional tests, and medical follow-ups which are all costly. This raises the concern about the validity of the outcomes retuned by this model. Should one interpret them at an average level or an individual level? Are the model predictions biased and, if so, how much? The overarching goal of this project is to develop novel foundational perspectives on the emerging inferential and computational challenges in statistics and data science. In addition, the PI plans to develop software packages to implement the proposed methods and make them publicly available. The proposed work will benefit a broad range of researchers from various areas ranging from bioinformatics and machine learning to finance and engineering. The PI will also integrate components from this project into an advanced graduate class and use selected results to motivate undergraduate students to pursue careers in STEM (Science, Technology, Engineering and Math). &lt;br/&gt;&lt;br/&gt;This project aims at developing statistical methods that are 1) scalable and 2) valid in the sense that in addition point estimation, they also quantify the statistical uncertainty that is intrinsic in the estimation and predications. These issues are among the central topics in modern statistics and it is imperative to develop solid theory and powerful methodology to address them. This project focuses on three interrelated prongs that develop fundamental insights for these ubiquitous challenges: (1) Uncertainty assessment and high-dimensional inference: the PI will develop a flexible framework for general hypothesis testing problems in high-dimensional setting using the so-called debiasing approach, and further study inference for high-dimensional models with adaptively collected samples, such as time series; (2) Online hypotheses testing: the PI will formulate the decentralized false discovery rate (FDR) control where the number of hypotheses to be tested is unknown (possibly infinite) and the decision maker should take an action on each before the next p-value is received; and (3) Optimal iterative estimation for non-linear decision regions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/13/2019</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1844481</AwardID>
<Investigator>
<FirstName>Adel</FirstName>
<LastName>Javanmard</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adel Javanmard</PI_FULL_NAME>
<EmailAddress>ajavanma@usc.edu</EmailAddress>
<PI_PHON>2138214193</PI_PHON>
<NSF_ID>000736462</NSF_ID>
<StartDate>02/13/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[USC]]></Name>
<CityName>Los Angeles</CityName>
<StateCode>CA</StateCode>
<ZipCode>900890007</ZipCode>
<StreetAddress><![CDATA[3670 Trousdale Parkway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~85061</FUND_OBLG>
<FUND_OBLG>2020~74237</FUND_OBLG>
<FUND_OBLG>2021~78524</FUND_OBLG>
</Award>
</rootTag>
