<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Finding Semantic Security Bugs with Pseudo-Oracle Testing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sol Greenspan</SignBlockName>
<PO_EMAI>sgreensp@nsf.gov</PO_EMAI>
<PO_PHON>7032927841</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Semantic security bugs cause serious vulnerabilities across a wide range of software. For example, in a recent incident, attackers exploited a semantic security bug in Apache Struts to steal sensitive personal data of up to 143 million customers from Equifax servers. In fact, such vulnerabilities are quite common in practice. The total number of Common Vulnerabilities and Exposure Identifiers (CVEs) assigned to different types of semantic security bugs exceeds 2,000 just this year alone. The goal of this project is to improve security and reliability by automatically detecting such semantic vulnerabilities in critical software. Automatically detecting these bugs is hard because unlike crash bugs they may not show any obvious side effects. In contrast, semantic security bugs (e.g., bypassing security checks, gaining access to sensitive information, escalating privileges) usually result from violation of high-level safety/security specifications which, in practice, are rarely written formally. This project will investigate whether learning domain-specific metamorphic relations can help in detecting semantic bugs.  &lt;br/&gt;&lt;br/&gt;In Software Engineering, metamorphic relations, which correlate  outputs from multiple executions of a program with different inputs, have been shown to be effective at finding simple functional bugs. While metamorphic relations have promise to detect semantic security vulnerabilities, they are not able to detect semantic security vulnerabilities in their current form, as security properties cannot be expressed as simple input-output based properties. The approach uses pseudo-oracle testing techniques like differential testing and metamorphic testing. The project will use targeted path exploration techniques, with automata-learning algorithms to discover metamorphic testing rules. The project will learn how the semantics of metamorphic relations can be augmented to detect semantic security bugs. The research envisions a unified framework based on pseudo-random Oracles, which can automatically detect semantic security bugs without the need for manually creating formal specifications to compare program behaviors of related executions. As a first step, the objective of this EAGER project is to empirically measure whether there is a comprehensive range of semantically expressive pseudo-oracle relations that can detect semantic security vulnerabilities.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/11/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/11/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1842456</AwardID>
<Investigator>
<FirstName>Suman</FirstName>
<LastName>Jana</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Suman Jana</PI_FULL_NAME>
<EmailAddress>suman@cs.columbia.edu</EmailAddress>
<PI_PHON>2128546851</PI_PHON>
<NSF_ID>000701617</NSF_ID>
<StartDate>08/11/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Baishakhi</FirstName>
<LastName>Ray</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Baishakhi Ray</PI_FULL_NAME>
<EmailAddress>rayb@cs.columbia.edu</EmailAddress>
<PI_PHON>3037482958</PI_PHON>
<NSF_ID>000701468</NSF_ID>
<StartDate>08/11/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gail</FirstName>
<LastName>Kaiser</LastName>
<PI_MID_INIT>E</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gail E Kaiser</PI_FULL_NAME>
<EmailAddress>kaiser@cs.columbia.edu</EmailAddress>
<PI_PHON>2129397081</PI_PHON>
<NSF_ID>000094973</NSF_ID>
<StartDate>08/11/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Trustees of Columbia University in the City of New York]]></Name>
<CityName/>
<StateCode>NY</StateCode>
<ZipCode>100277922</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~200000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Automated detection of software vulnerabilities is a fundamental problem in software security. Conventional program analysis techniques either suffer from high false positives (reporting software as vulnerable when it is not) or false negatives (missing vulnerabilities in other software). Recent progress in Machine Learning (ML) has resulted in a surge of interest in applying ML for automated vulnerability detection. Several recent studies have demonstrated promising results achieving high accuracy (up to 97%) at detecting vulnerabilities.&nbsp;</p> <p>We systematically measured the generalizability of four state-of-the-art ML neural network architectures that reported achieving high accuracy (up to 97%). Our results demonstrate that none of these ML systems generalize beyond their own datasets due to implicit biases in these datasets introduced during the data collection and labeling process. We developed a taxonomy of different potential biases affecting venerability datasets and a measurement methodology to accurately estimate their effects. We used our bias measurement methodology to quantitatively estimate different classes of biases in the four popular vulnerability datasets.&nbsp;</p> <p><br />We collected a balanced real-world dataset from developer/user reported vulnerabilities from two popular real-world projects (Chromium and Debian) and demonstrate that all four of the tested ML systems drop to around 50% accuracy on this dataset. This demonstrates that dataset bias is a crucial issue in existing ML-based vulnerability detection schemes. We prepared a set of best practices that can help future researchers minimize such biases.&nbsp; The corresponding paper is&nbsp; currenltly under review.&nbsp; &nbsp;</p><br> <p>            Last Modified: 03/22/2021<br>      Modified by: Baishakhi&nbsp;Ray</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Automated detection of software vulnerabilities is a fundamental problem in software security. Conventional program analysis techniques either suffer from high false positives (reporting software as vulnerable when it is not) or false negatives (missing vulnerabilities in other software). Recent progress in Machine Learning (ML) has resulted in a surge of interest in applying ML for automated vulnerability detection. Several recent studies have demonstrated promising results achieving high accuracy (up to 97%) at detecting vulnerabilities.   We systematically measured the generalizability of four state-of-the-art ML neural network architectures that reported achieving high accuracy (up to 97%). Our results demonstrate that none of these ML systems generalize beyond their own datasets due to implicit biases in these datasets introduced during the data collection and labeling process. We developed a taxonomy of different potential biases affecting venerability datasets and a measurement methodology to accurately estimate their effects. We used our bias measurement methodology to quantitatively estimate different classes of biases in the four popular vulnerability datasets.    We collected a balanced real-world dataset from developer/user reported vulnerabilities from two popular real-world projects (Chromium and Debian) and demonstrate that all four of the tested ML systems drop to around 50% accuracy on this dataset. This demonstrates that dataset bias is a crucial issue in existing ML-based vulnerability detection schemes. We prepared a set of best practices that can help future researchers minimize such biases.  The corresponding paper is  currenltly under review.          Last Modified: 03/22/2021       Submitted by: Baishakhi Ray]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
