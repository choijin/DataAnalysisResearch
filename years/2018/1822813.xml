<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Cyberlearning: Sensei: High-Fidelity, Non-Invasive Classroom Sensing for Professional Development</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>750000.00</AwardTotalIntnAmount>
<AwardAmount>766000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amy Baylor</SignBlockName>
<PO_EMAI>abaylor@nsf.gov</PO_EMAI>
<PO_PHON>7032925126</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For years, research has shown that moving away from large lectures and increasing student engagement and participation in classrooms significantly improves learning. Unfortunately, professors lack quality professional development opportunities to improve their instruction, and typically receive no training on how to teach. This project is addressing the issue of college professors' professional development through a cyberlearning innovation called Sensei. Sensei has novel capabilities using sensors to capture, isolate, and analyze voice and video that will provide near real time data on classroom interactions such as the percent time students talk vs professors, the percent time students talk to students, student engagement through facial expression analysis, turn taking between students and professors, etc all of which involve multimodal analysis of voice and video. The second component of this research is the development of suggested actions to improve the professor's performance as a teacher.&lt;br/&gt;&lt;br/&gt;More precisely, Sensei draws on technical and socio-technical advances in sensing arrays, computer vision, intelligent environments, and personal informatics, as well as frameworks of professional development in higher education. In this project the researchers will 1) develop the technologies needed to automatically sense and display feedback to instructors, 2) deploy this system in-vivo to college instructors over semesters of use in a series of design-based research studies, and interpret the results to 3) iterate on our framework for the routine incorporation of classroom data into professional development. This research is enabled by a cyber innovation in which computing is expanded by the capabilities of state of the art multimodal sensing approaches to achieve non-invasive sensing at classroom-scale. This cyber innovation drives a learning innovation of delivering near-real-time data on teaching practices in a combined reflection and training system by delivering rapid and frequent feedback and instruction on good strategies in manageable instructional units, that support a focus on student-centered beliefs. In turn, the learning innovation advances understanding of how instructors learn in technology-rich learning environments by exploring mechanisms in a framework of professional development that would not be possible without this new cyberlearning genre. In particular, through a series of design-based research studies with instructors teaching STEM college courses, the researchers explore ways in which Sensei  a) can trigger critical self reflection, b) how this self-reflection changes based on the features of the data viewed, c) how datadriven goal-setting can foster self-efficacy in teaching, and d) how these effects vary over time. All of the code will be developed as open source and, if successful, Sensei could be generalized to include K-12 teachers.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/18/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/09/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1822813</AwardID>
<Investigator>
<FirstName>Yuvraj</FirstName>
<LastName>Agarwal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yuvraj Agarwal</PI_FULL_NAME>
<EmailAddress>Yuvraj.Agarwal@cs.cmu.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000552330</NSF_ID>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Amy</FirstName>
<LastName>Ogan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Amy Ogan</PI_FULL_NAME>
<EmailAddress>aeo@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122681161</PI_PHON>
<NSF_ID>000611527</NSF_ID>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Christopher</FirstName>
<LastName>Harrison</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Christopher Harrison</PI_FULL_NAME>
<EmailAddress>chris.harrison@cs.cmu.edu</EmailAddress>
<PI_PHON>4124363464</PI_PHON>
<NSF_ID>000664095</NSF_ID>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName>PITTSBURGH</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133815</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1536</Code>
<Text>S-STEM-Schlr Sci Tech Eng&amp;Math</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>13XX</Code>
<Name>H-1B FUND, EHR, NSF</Name>
<APP_SYMB_ID>045176</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~750000</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
</Award>
</rootTag>
