<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CIF: EAGER: Statistical Inference and Decision-Making With Sequential Samples</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>100527.00</AwardTotalIntnAmount>
<AwardAmount>100527</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
<PO_EMAI>pregalia@nsf.gov</PO_EMAI>
<PO_PHON>7032922981</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The modern world is rich with diverse sources of data that provide invaluable insights into underlying random phenomena. The data, however, generally provide only indirect or imprecise information about the latent phenomena due to measurement limitations or privacy protections. This project develops efficient algorithms to use sequential samples to infer a hidden random phenomenon and use this knowledge to make decisions. Outcomes of the project will improve the efficiency and accuracy of data-driven decision-making and inference in a wide range of applications such as marketing and recommendation systems, cloud computing, manufacturing, and health care. The investigators will publish the research outcomes to broad academic and professional audiences and incorporate them into teaching curricula via graduate and undergraduate courses.&lt;br/&gt;&lt;br/&gt;The framework studied in this project consists of a hidden random variable (or, a random vector) that can be indirectly sampled by choosing one of several measurement mechanisms (referred to as arms). Upon choosing one of the arms, an arbitrary function of a realization of the hidden random variable is observed, instead of a direct sample. Within this framework, the investigators pursue problems including i) maximizing the reward obtained by sampling different arms in a correlated multi-armed bandit setting; and ii) estimating the probability distribution of the hidden random variable using minimum number of samples. These research thrusts will be studied with three main goals: 1) understanding the fundamental limits of the problem via bounds on the cumulative regret, and the error in the estimated distribution; 2) designing efficient sampling algorithms that meet the fundamental limits; and 3) validating the proposed algorithms on real-world datasets. The project deviates from the classic multi-armed bandit framework due to the correlation between arms and from the classic statistical inference due to the sequential and multi-fidelity nature of the data generation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/21/2018</MinAmdLetterDate>
<MaxAmdLetterDate>07/21/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1840860</AwardID>
<Investigator>
<FirstName>Osman</FirstName>
<LastName>Yagan</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Osman Yagan</PI_FULL_NAME>
<EmailAddress>oyagan@ece.cmu.edu</EmailAddress>
<PI_PHON>4122683976</PI_PHON>
<NSF_ID>000661945</NSF_ID>
<StartDate>07/21/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Gauri</FirstName>
<LastName>Joshi</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gauri Joshi</PI_FULL_NAME>
<EmailAddress>gaurij@andrew.cmu.edu</EmailAddress>
<PI_PHON>4122681186</PI_PHON>
<NSF_ID>000732900</NSF_ID>
<StartDate>07/21/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7797</Code>
<Text>Comm &amp; Information Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>7935</Code>
<Text>COMM &amp; INFORMATION THEORY</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~100527</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Although learning from "big data" has been revolutionizing inference and decision-making from indirect or noisy samples, several important and relevant applications fall in the small data regime where obtaining training samples is expensive, slow or even hazardous. Several engineering applications suffer from this scarcity of training data -- for example, medical trials to identify the best treatment option, price optimization based on targeted marketing campaigns, or hyper-parameter tuning (optimizing the learning rate, momentum, neural network architecture etc.) in machine learning. Standard supervised learning methods such as deep neural networks, which rely on massive amounts of training samples, can give highly inaccurate results when used in data-scarce applications. Thus, there is a critical need for sample-efficient algorithms for decision-making and inference using carefully drawn sequential samples. The outcomes of this project include novel and sample-efficient algorithms for sequential decision-making and inference, in particular, for structured and correlated multi-armed bandits and active sequential inference. These methods are expected to impact critical applications on machine learning in the small-data regime where samples are expensive to obtain. By drastically reducing the sample complexity, the project outcomes boost the efficiency of data-driven decision-making and inference in diverse applications such as A/B testing, hyper-parameter tuning and federated learning. The research results are published at the 2018 Allerton Conference with three more preprints under submission to conferences and journals. The project outcomes are also incorporated into undergraduate and graduate classes at Carnegie Mellon University in the form of guest lectures and course projects.</p><br> <p>            Last Modified: 12/03/2019<br>      Modified by: Osman&nbsp;Yagan</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Although learning from "big data" has been revolutionizing inference and decision-making from indirect or noisy samples, several important and relevant applications fall in the small data regime where obtaining training samples is expensive, slow or even hazardous. Several engineering applications suffer from this scarcity of training data -- for example, medical trials to identify the best treatment option, price optimization based on targeted marketing campaigns, or hyper-parameter tuning (optimizing the learning rate, momentum, neural network architecture etc.) in machine learning. Standard supervised learning methods such as deep neural networks, which rely on massive amounts of training samples, can give highly inaccurate results when used in data-scarce applications. Thus, there is a critical need for sample-efficient algorithms for decision-making and inference using carefully drawn sequential samples. The outcomes of this project include novel and sample-efficient algorithms for sequential decision-making and inference, in particular, for structured and correlated multi-armed bandits and active sequential inference. These methods are expected to impact critical applications on machine learning in the small-data regime where samples are expensive to obtain. By drastically reducing the sample complexity, the project outcomes boost the efficiency of data-driven decision-making and inference in diverse applications such as A/B testing, hyper-parameter tuning and federated learning. The research results are published at the 2018 Allerton Conference with three more preprints under submission to conferences and journals. The project outcomes are also incorporated into undergraduate and graduate classes at Carnegie Mellon University in the form of guest lectures and course projects.       Last Modified: 12/03/2019       Submitted by: Osman Yagan]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
