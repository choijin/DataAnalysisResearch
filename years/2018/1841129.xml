<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: EAGER: A Wearable Body Motion Sensing Platform Using Conductive Stretchable Fabric</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>216000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Matt Mutka</SignBlockName>
<PO_EMAI>mmutka@nsf.gov</PO_EMAI>
<PO_PHON>7032927344</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project aims to develop a wearable platform that enables the generation of a three dimensional (3D) model of the human skeleton and tracking its motion. There exist techniques that use depth cameras and special image processing software to model motion of the human skeleton, and Microsoft Kinect is a well-known example. However, the techniques using fixed cameras need to deploy camera devices at fixed locations in order to sense human motions. While this may be suitable for indoor fixed scenarios, it is not feasible for outdoor ubiquitous scenarios. Instead, the wearable platform from this project works for both scenarios. &lt;br/&gt;&lt;br/&gt;This wearable platform is designed using a conductive stretchable fabric that is comfortable to wear.   To estimate 3D body motions using the wearable platform, the model of the body skeleton needs to be fused with the bend angles of major joints on the skeleton.  This project exploits the fabric's conductive resistance change to infer user dependent bend angles of body joints that the fabric covers.  Furthermore, a 3D motion estimation method is developed for the platform that optimizes motion estimation results with body kinematics constraints.&lt;br/&gt;&lt;br/&gt;Being comfortable for long-term wear and able to provide high motion sensing accuracy, this wearable platform will largely enhance the current practice of healthcare, sports, and outdoor entertainment. Benefits to senior residents and local retirement communities will be delivered through collaboration with the Center for Excellence in Aging and Geriatric Health. The research will be integrated into three undergraduate and graduate courses. Open houses will provide hands-on opportunities to a diverse group of minority students and high school students.&lt;br/&gt;&lt;br/&gt;Data from this project includes human-subjects data, experiment results, software code, and curriculum materials. Data collection and management will be under the supervision of the Protection of Human Subjects Committee at William &amp; Mary. Data will be stored securely on computers and regularly backed-up at William &amp; Mary. The project web site is http://gzhou.blogs.wm.edu/nsf-eager-18/ , and the project web server is maintained and achieved by William &amp; Mary. Data will be preserved for at least three years beyond the award period.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/04/2018</MinAmdLetterDate>
<MaxAmdLetterDate>02/10/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1841129</AwardID>
<Investigator>
<FirstName>Gang</FirstName>
<LastName>Zhou</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Gang Zhou</PI_FULL_NAME>
<EmailAddress>gzhou@cs.wm.edu</EmailAddress>
<PI_PHON>7572213458</PI_PHON>
<NSF_ID>000498113</NSF_ID>
<StartDate>08/04/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>College of William and Mary</Name>
<CityName>Williamsburg</CityName>
<ZipCode>231878795</ZipCode>
<PhoneNumber>7572213966</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 8795]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>074762238</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>COLLEGE OF WILLIAM &amp; MARY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>074762238</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[College of William and Mary]]></Name>
<CityName>Williamsburg</CityName>
<StateCode>VA</StateCode>
<ZipCode>231878795</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Programs]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~200000</FUND_OBLG>
<FUND_OBLG>2020~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project aims to develop a wearable platform that enables the generation of a three dimensional model of the human skeleton and tracking its motion. There exist techniques that use depth cameras and special image processing software to model the motion of a human skeleton, and Kinect is a well-known example. However, the techniques using fixed cameras need to deploy camera devices at fixed locations in order to sense human motions. While this is ok for indoor fixed scenarios, it does not work for outdoor ubiquitous scenarios. Instead, the wearable platform from this project works for both scenarios.</p> <p>This wearable platform was designed using conductive stretchable fabric that is comfortable to wear. This project exploited the fabric?s resistance change for inferring the bend angle of a body joint that the fabric covers. Joints? angles were then fused with body skeleton to estimate 3D body motions. The main intellectual merits included a novel wearable platform that enabled ubiquitous body motion sensing, novel user-dependent angle detection sensors with nonlinear mapping models from resistance measurements to joint bend angles, and a novel 3D body motion estimation method that fused independent joint angles and optimized estimation results with body kinematics constraints.</p> <p>Many students were engaged to conduct the proposed research and benefited from the experience, including 7 Ph.D. and 3 undergraduate students. Among them, 3 Ph.D. students (including one woman student) successfully defended their Ph.D. dissertations and graduated in 2020. Also, 2 undergraduate students were engaged in REU summer research in 2020, with one of them from William &amp; Mary and the other from Brown University. Four academic papers have already been published or accepted for publications based on the research results. Research results from this EAGER project were also extended beyond this project?s original scope to explore new directions in smart health and athletics, generating a few proposal submissions and paper preparations. The research results were also integrated into 3 existing courses at William &amp; Mary, including one undergraduate course and two graduate courses. &nbsp;&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 11/05/2020<br>      Modified by: Gang&nbsp;Zhou</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2020/1841129/1841129_10566053_1604612791928_Untitled--rgov-214x142.jpg" original="/por/images/Reports/POR/2020/1841129/1841129_10566053_1604612791928_Untitled--rgov-800width.jpg" title="TracKnee Sensor Prototype using Stretchable Conductive Fabric"><img src="/por/images/Reports/POR/2020/1841129/1841129_10566053_1604612791928_Untitled--rgov-66x44.jpg" alt="TracKnee Sensor Prototype using Stretchable Conductive Fabric"></a> <div class="imageCaptionContainer"> <div class="imageCaption">This set of images demonstrate the TracKnee sensor prototype using stretchable conductive fabric. They were extracted from our paper publication in ACM/IEEE CHASE 2019.</div> <div class="imageCredit">William & Mary</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Gang&nbsp;Zhou</div> <div class="imageTitle">TracKnee Sensor Prototype using Stretchable Conductive Fabric</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project aims to develop a wearable platform that enables the generation of a three dimensional model of the human skeleton and tracking its motion. There exist techniques that use depth cameras and special image processing software to model the motion of a human skeleton, and Kinect is a well-known example. However, the techniques using fixed cameras need to deploy camera devices at fixed locations in order to sense human motions. While this is ok for indoor fixed scenarios, it does not work for outdoor ubiquitous scenarios. Instead, the wearable platform from this project works for both scenarios.  This wearable platform was designed using conductive stretchable fabric that is comfortable to wear. This project exploited the fabric?s resistance change for inferring the bend angle of a body joint that the fabric covers. Joints? angles were then fused with body skeleton to estimate 3D body motions. The main intellectual merits included a novel wearable platform that enabled ubiquitous body motion sensing, novel user-dependent angle detection sensors with nonlinear mapping models from resistance measurements to joint bend angles, and a novel 3D body motion estimation method that fused independent joint angles and optimized estimation results with body kinematics constraints.  Many students were engaged to conduct the proposed research and benefited from the experience, including 7 Ph.D. and 3 undergraduate students. Among them, 3 Ph.D. students (including one woman student) successfully defended their Ph.D. dissertations and graduated in 2020. Also, 2 undergraduate students were engaged in REU summer research in 2020, with one of them from William &amp; Mary and the other from Brown University. Four academic papers have already been published or accepted for publications based on the research results. Research results from this EAGER project were also extended beyond this project?s original scope to explore new directions in smart health and athletics, generating a few proposal submissions and paper preparations. The research results were also integrated into 3 existing courses at William &amp; Mary, including one undergraduate course and two graduate courses.             Last Modified: 11/05/2020       Submitted by: Gang Zhou]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
