<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRI: CI-P: Creating the Largest Speech Emotional Database by Leveraging Existing Naturalistic Recordings</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>02/28/2021</AwardExpirationDate>
<AwardTotalIntnAmount>99390.00</AwardTotalIntnAmount>
<AwardAmount>115390</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This community infrastructure planning project aims to consider the needs from other researchers in the design of the largest publicly available naturalistic speech emotional database, broadening the impact of the corpus across speech processing areas. The project includes a workshop with researchers with relevant but diverse expertise to introduce the current protocol for data collection, and requests their recommendations for improvements. The proposed activity will improve the protocol to address the needs from the community. Affective computing is an important research area aiming to understand, analyze, recognize, and synthesize human emotions. Providing emotion capabilities to current speech-based interfaces can facilitate transformative applications in areas related to Human Computer Interaction (HCI), healthcare, security and defense, education and entertainment. The research infrastructure envisioned in this project will open new opportunities that we cannot address with current speech emotional databases. In the area of affective computing, the proposed corpus will provide suitable training sets to explore learning algorithms that are powerful, but require large amount of labeled data. It is expected that the size, naturalness, and speaker and recording variety in the proposed corpus will allow the community to create robust models that generalize across applications. Improvements on speech emotion recognition systems will facilitate the transition of these algorithms into practical applications, providing unique societal benefits. The proposed infrastructure will also play a key role on other speech processing tasks. For the first time, the community will have the infrastructure to address speaker verification and automatic speech recognition solutions against variations due to emotion.&lt;br/&gt;&lt;br/&gt;The proposed infrastructure relies on a novel approach based on emotion retrieval along with crowdsource-based annotations to effectively build a large, naturalistic emotional database with balanced emotional content, reduced cost and reduced manual labor. The database considers podcast recordings that are available in audio-sharing websites. Although the approach of building affective databases using media content has been previously explored, the contribution of this study is the use of machine learning algorithms to retrieve audio clips with balanced emotional content, providing natural stimuli with wider spectrum of emotions. The proposed approach relies on automatic algorithms to post-process podcasts and a cost effective annotation process, which make it possible to build large scale speech emotional databases. This approach provides natural emotional renditions that are difficult to obtain with alternative data collection protocols. This project involves the research community from the design of the corpus, which is the key goal in this community infrastructure planning project. The community also play a key role in the selection of target sentences to be emotionally annotated, with novel grand challenges where the goal is to recognize and retrieve target emotional behaviors in unconstrained, unlabeled recordings.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/25/2018</MinAmdLetterDate>
<MaxAmdLetterDate>03/30/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1823166</AwardID>
<Investigator>
<FirstName>Carlos</FirstName>
<LastName>Busso</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Carlos Busso</PI_FULL_NAME>
<EmailAddress>busso@utdallas.edu</EmailAddress>
<PI_PHON>9728834351</PI_PHON>
<NSF_ID>000544291</NSF_ID>
<StartDate>07/25/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Dallas</Name>
<CityName>Richardson</CityName>
<ZipCode>750803021</ZipCode>
<PhoneNumber>9728832313</PhoneNumber>
<StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX32</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>800188161</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT DALLAS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Dallas]]></Name>
<CityName/>
<StateCode>TX</StateCode>
<ZipCode>750803021</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>32</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX32</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7359</Code>
<Text>CCRI-CISE Cmnty Rsrch Infrstrc</Text>
</ProgramElement>
<ProgramReference>
<Code>7359</Code>
<Text>COMPUTING RES INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~99390</FUND_OBLG>
<FUND_OBLG>2019~8000</FUND_OBLG>
<FUND_OBLG>2020~8000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Research Objective and Significance:&nbsp;</p> <p>&nbsp;</p> <p>This community infrastructure planning project aimed to create the MSP-Podcast corpus, which will be the largest, publicly available, naturalistic speech emotional database. Affective computing is an important research area aiming to understand, analyze, recognize, and synthesize human emotions. Providing emotion capabilities to current interfaces can facilitate transformative applications in areas related to human computer interaction (HCI), healthcare, security and defense, education and entertainment. However, automatic emotion recognition from speech in realistic domains is a challenging task given the subtle expressive behaviors that occur during human interactions. Current speech emotional databases are limited in size, number of speakers, inadequate/inconsistent emotional descriptors, lack of naturalistic behaviors, and unbalanced emotional content. The research community does not have the resources to leverage powerful learning algorithms to create robust emotion models. This project aims to create the largest speech emotional database in the community (over 400 hours, from over 1,500 speakers). The key objective of this community infrastructure planning project is to consider the community&nbsp;needs in the design of the proposed emotional speech corpus, so this resource can have broader impact across speech processing areas.&nbsp;</p> <p>&nbsp;</p> <p>Outcomes:</p> <p>&nbsp;</p> <p>1)- Organizing the planning workshop&nbsp;</p> <p>The key objective of this CI planning project is to collect feedback from researchers working on areas which may benefit from this corpus. The outcome of the workshop is an improved design that will meet the needs from the community. We organized a one-day workshop in Dallas, Texas, where we invited researchers with different background from academy, industry, and government. The workshop was held on June 17, 2019 at UT Dallas, Richardson, TX. We had 11 participants, in addition to four students involved in the corpus: Richard Stern (CMU); Ani Nenkova (University of Pennsylvania); John Hansen (UT Dallas); Emily Mower Provost (University of Michigan); Shri Narayanan (USC); Mark Liberman (University of Pennsylvania); Julia Hirschberg (Columbia University); Carol Espy-Wilson (University of Maryland College Park); Oscar Morales-Gonzalez (Department of Defense); Zixiaofan (Brenda) Yang (Columbia University); Oren Wright (CMU); Lei Chen (Liulishuo AI Lab). We also have researchers who accepted the invitation, but were not able to attend: Chi-Chun (Jeremy) Lee (National Tsing Hua University); Tina Kohler (Department of Defense); Yang Liu (Liulishuo AI Lab); Stefan Scherer (USC). They also provided valuable feedback. The workshop was very productive, providing key suggestions to improve our data collection.</p> <p>&nbsp;</p> <p>(2) Writing the CCRI proposal &nbsp;</p> <p>A key objective of this planning project was to write a CISE Community Research Infrastructure (CCRI) proposal. After carefully collecting the feedback from the participants, we wrote a proposal responding to the NSF solicitation NSF 19-512. The project ?CCRI: Medium: MSP-Podcast: Creating The Largest Speech Emotional Database by Leveraging Existing Naturalistic Recordings? (CNS: 2016719) was submitted in January 2020. The project was awarded by NSF. The starting day of this project was September 1, 2020.</p> <p>&nbsp;</p> <p>(3) Increasing the size of the MSP-Podcast corpus</p> <p>At the beginning of the project in September 2018, we had 31,345 speaking turns (53h24m), where 22,617 of them had speaker information. By the end of the project (February 2021), we have 81,149 speaking turns (123h22m), where 73,101 of them have speaking information. The document attached to this report summarizes the progress on the data collection effort over the years, and the current status of the corpus.</p> <p>&nbsp;</p> <p>(4) Start the collection of the MSP-Conversation corpus</p> <p>Contextual information plays an important role on the expression of emotion. Learning the dynamics of expressive behaviors between interlocutors provides relevant information that cannot be obtained from isolated speech segments. The MSP-Podcast corpus is not appropriate to study contextual information as the isolated turns are separately evaluated missing temporal relationships. We are addressing this problem by selecting continuous segments within the podcasts with duration ranging between 10 and 20 minutes. These conversation segments convey natural emotional content, spanning a broad range of emotions from multiple speakers appearing in multiple podcasts. We refer to this portion of the corpus as the MSP-Conversation dataset. The first release of the corpus contains 74 conversation segments from the podcasts (approximately 17 hours). The conversations are annotated with time-continuous emotional evaluations. The evaluator uses a graphical user interface (GUI), where he/she continuously moves the bar as he/she perceives the emotional content of the sentence. At least five evaluators per conversation annotated the corpus with emotional traces for valence, arousal and dominance using the CARMA tool. This corpus is a perfect complement of the MSP-Podcast corpus.</p> <p>&nbsp;</p> <p>(5)- Interdisciplinary training for undergraduate and graduate students</p> <p>Training undergraduate and graduate students is the first mission of the PIs. We are committed to prepare the future scientist in signal processing. The role of human centered technologies, especially contextualized in real world applications of direct societal relevance can inspire young scholars into computing and engineering. One graduate student and four undergraduate students participated in this project.&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 06/15/2021<br>      Modified by: Carlos&nbsp;Busso</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623813437753_Slide1--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623813437753_Slide1--rgov-800width.jpg" title="Progress on the collection of the MSP-Podcast corpus"><img src="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623813437753_Slide1--rgov-66x44.jpg" alt="Progress on the collection of the MSP-Podcast corpus"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The figure shows the progress over time in the collection of the MSP-Podcast corpus.</div> <div class="imageCredit">Carlos Busso</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Carlos&nbsp;Busso</div> <div class="imageTitle">Progress on the collection of the MSP-Podcast corpus</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623800784661_Pictures--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623800784661_Pictures--rgov-800width.jpg" title="MSP-Podcast Workshop"><img src="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623800784661_Pictures--rgov-66x44.jpg" alt="MSP-Podcast Workshop"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The figure shows the participants of the workshop organized in June 17th, 2019. Some of the participants presented technical presentations the day after the workshop.</div> <div class="imageCredit">Carlos Busso</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Carlos&nbsp;Busso</div> <div class="imageTitle">MSP-Podcast Workshop</div> </div> </li> <li> <a href="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623815212285_Slide1--rgov-214x142.jpg" original="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623815212285_Slide1--rgov-800width.jpg" title="Status of the MSP-Podcast corpus"><img src="/por/images/Reports/POR/2021/1823166/1823166_10561337_1623815212285_Slide1--rgov-66x44.jpg" alt="Status of the MSP-Podcast corpus"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Status of the corpus, showing the distribution of emotional content in terms of emotional categories and emotional attributes.</div> <div class="imageCredit">Carlos Busso</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Carlos&nbsp;Busso</div> <div class="imageTitle">Status of the MSP-Podcast corpus</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Research Objective and Significance:      This community infrastructure planning project aimed to create the MSP-Podcast corpus, which will be the largest, publicly available, naturalistic speech emotional database. Affective computing is an important research area aiming to understand, analyze, recognize, and synthesize human emotions. Providing emotion capabilities to current interfaces can facilitate transformative applications in areas related to human computer interaction (HCI), healthcare, security and defense, education and entertainment. However, automatic emotion recognition from speech in realistic domains is a challenging task given the subtle expressive behaviors that occur during human interactions. Current speech emotional databases are limited in size, number of speakers, inadequate/inconsistent emotional descriptors, lack of naturalistic behaviors, and unbalanced emotional content. The research community does not have the resources to leverage powerful learning algorithms to create robust emotion models. This project aims to create the largest speech emotional database in the community (over 400 hours, from over 1,500 speakers). The key objective of this community infrastructure planning project is to consider the community needs in the design of the proposed emotional speech corpus, so this resource can have broader impact across speech processing areas.      Outcomes:     1)- Organizing the planning workshop   The key objective of this CI planning project is to collect feedback from researchers working on areas which may benefit from this corpus. The outcome of the workshop is an improved design that will meet the needs from the community. We organized a one-day workshop in Dallas, Texas, where we invited researchers with different background from academy, industry, and government. The workshop was held on June 17, 2019 at UT Dallas, Richardson, TX. We had 11 participants, in addition to four students involved in the corpus: Richard Stern (CMU); Ani Nenkova (University of Pennsylvania); John Hansen (UT Dallas); Emily Mower Provost (University of Michigan); Shri Narayanan (USC); Mark Liberman (University of Pennsylvania); Julia Hirschberg (Columbia University); Carol Espy-Wilson (University of Maryland College Park); Oscar Morales-Gonzalez (Department of Defense); Zixiaofan (Brenda) Yang (Columbia University); Oren Wright (CMU); Lei Chen (Liulishuo AI Lab). We also have researchers who accepted the invitation, but were not able to attend: Chi-Chun (Jeremy) Lee (National Tsing Hua University); Tina Kohler (Department of Defense); Yang Liu (Liulishuo AI Lab); Stefan Scherer (USC). They also provided valuable feedback. The workshop was very productive, providing key suggestions to improve our data collection.     (2) Writing the CCRI proposal    A key objective of this planning project was to write a CISE Community Research Infrastructure (CCRI) proposal. After carefully collecting the feedback from the participants, we wrote a proposal responding to the NSF solicitation NSF 19-512. The project ?CCRI: Medium: MSP-Podcast: Creating The Largest Speech Emotional Database by Leveraging Existing Naturalistic Recordings? (CNS: 2016719) was submitted in January 2020. The project was awarded by NSF. The starting day of this project was September 1, 2020.     (3) Increasing the size of the MSP-Podcast corpus  At the beginning of the project in September 2018, we had 31,345 speaking turns (53h24m), where 22,617 of them had speaker information. By the end of the project (February 2021), we have 81,149 speaking turns (123h22m), where 73,101 of them have speaking information. The document attached to this report summarizes the progress on the data collection effort over the years, and the current status of the corpus.     (4) Start the collection of the MSP-Conversation corpus  Contextual information plays an important role on the expression of emotion. Learning the dynamics of expressive behaviors between interlocutors provides relevant information that cannot be obtained from isolated speech segments. The MSP-Podcast corpus is not appropriate to study contextual information as the isolated turns are separately evaluated missing temporal relationships. We are addressing this problem by selecting continuous segments within the podcasts with duration ranging between 10 and 20 minutes. These conversation segments convey natural emotional content, spanning a broad range of emotions from multiple speakers appearing in multiple podcasts. We refer to this portion of the corpus as the MSP-Conversation dataset. The first release of the corpus contains 74 conversation segments from the podcasts (approximately 17 hours). The conversations are annotated with time-continuous emotional evaluations. The evaluator uses a graphical user interface (GUI), where he/she continuously moves the bar as he/she perceives the emotional content of the sentence. At least five evaluators per conversation annotated the corpus with emotional traces for valence, arousal and dominance using the CARMA tool. This corpus is a perfect complement of the MSP-Podcast corpus.     (5)- Interdisciplinary training for undergraduate and graduate students  Training undergraduate and graduate students is the first mission of the PIs. We are committed to prepare the future scientist in signal processing. The role of human centered technologies, especially contextualized in real world applications of direct societal relevance can inspire young scholars into computing and engineering. One graduate student and four undergraduate students participated in this project.           Last Modified: 06/15/2021       Submitted by: Carlos Busso]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
