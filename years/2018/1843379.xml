<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Real-Time Pose and Grasping Affordance Estimation for Vine Crops</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>220982.00</AwardTotalIntnAmount>
<AwardAmount>220982</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this project affects one of the most critical problems facing the United States agricultural industry, a shortage of available labor.   This shortage has had a particularly pronounced effect on the fruit and vegetable industry, where even a brief loss of labor can result in a total loss of harvestable products.  More recently, U.S. produce suppliers have been forced to rely heavily on imported produce sourced from greater distances and of lower quality.  Advancements in agricultural technology have already dramatically improved the efficiency of produce farms in terms of land utilization and water consumption by enabling produce to be grown indoors using highly sophisticated commercial greenhouses, automated nutrient delivery, and light control.  However, to date, these commercial greenhouses still lack a comprehensive solution for automating routine harvesting, pruning, and crop care labor tasks.  Thus, newly developed agricultural technologies which can automate these tasks have the potential for substantial commercial impact by making domestic farming operations more profitable and efficient.  Commercial adoption of automated harvesting technology will also benefit consumers by enabling higher quality produce grown closer to market and position the U.S. agricultural sector as a new area of growth for highly skilled technical jobs.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will focus on the development of new deep learning techniques used to identify harvestable fruits (initially tomatoes) using computer vision cameras and to accurately estimate their orientation and connectivity (bunches of fruits that are connected by the same stem or vine).  Successful development of a method capable of running in real-time would resolve substantial technical risks which inhibit the ability to commercialize robotic automated harvesting solutions.  Such advancements would also contribute newfound insights to the broader computer vision and robotic manipulation communities into the unique challenges that sparse and deformable ?vine? like structures present to traditional methods of object pose estimation and grasping.  In the later portion of this Phase I project, Root AI will incorporate these new methods of sensing tomato fruit orientation into an improved motion and task planning system which uses the additional information to intelligently plan a complex movement path to harvest individual fruits in congested and heavily occluded natural growing environments.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/29/2019</MinAmdLetterDate>
<MaxAmdLetterDate>01/29/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1843379</AwardID>
<Investigator>
<FirstName>Joshua</FirstName>
<LastName>Lessing</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joshua Lessing</PI_FULL_NAME>
<EmailAddress>jlessing@root-ai.com</EmailAddress>
<PI_PHON>9178553989</PI_PHON>
<NSF_ID>000780050</NSF_ID>
<StartDate>01/29/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>ROOT AI, INC.</Name>
<CityName>Woburn</CityName>
<ZipCode>018012057</ZipCode>
<PhoneNumber>9178553989</PhoneNumber>
<StreetAddress>78 Olympia Ave.</StreetAddress>
<StreetAddress2><![CDATA[STE F.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>081227492</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ROOT AI, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[ROOT AI, INC.]]></Name>
<CityName>Somerville</CityName>
<StateCode>MA</StateCode>
<ZipCode>021433260</ZipCode>
<StreetAddress><![CDATA[444 Somerville Ave.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>8035</Code>
<Text>Hardware Devices</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~220982</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>As a result of the SBIR Phase I project, Root AI has overcome key technical risks in computer vision, perception and grasping, which enable the newly developed autonomous harvesting robot, called Virgo, to dexterously pick fruits in hard to reach places directly from living vines.&nbsp; During the project, new methods of filtering and processing images under the unique lighting conditions of a greenhouse were developed and empirically verified.&nbsp; Using these new innovations, improved techniques for spatially mapping growing environments through fusion of 2D RGB and 3D point cloud information were developed.&nbsp; Finally, novel mechanisms for grasping were developed and tested at U.S. farms, which mimic the complex motions that a person intuitively makes while harvesting fruits. This work has contributed to the broader robotic manipulation and computer vision communities&rsquo; understanding of 3D mapping and motion planning in and around living plants, an understudied and highly relevant topic in robotics and computer vision.</p> <p>Two new technical metrics, pick cycle time and harvesting coverage, were developed and verified with greenhouse growers to gauge Virgo&rsquo;s progress towards commercial viability.&nbsp; Analysis of these metrics over the course of the Phase I showed that the integrated developments from this project produced a 2.5X increase in picking speed and a 35% increase in harvesting coverage (the percentage of harvestable ripe fruits the system can access and collect).&nbsp; Now that Virgo is capable of harvesting at compelling speeds and of reaching most fruits, the technology is ready for adaptation into a commercial product.&nbsp; The successful outcome of this work will ultimately be the first truly autonomous and universal produce harvesting robotic platform, a capability which would precipitate a complete shift in how we think about crop management in the future.&nbsp; The commercial and societal ramifications cannot be overstated. &nbsp;Virgo is the foundation for a high-quality &amp; dependable source of labor, which would stabilize the margin-compressed agricultural industry and ensure our ability to sustainably feed a rapidly expanding population.&nbsp; Ultimately, we view Virgo as a pioneer in the new age of agriculture, and a necessary innovation to ensure the democratization of nutritious, affordable and locally grown produce.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/30/2019<br>      Modified by: Joshua&nbsp;Lessing</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1843379/1843379_10588987_1567181492605_DSC07057_(edit)--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1843379/1843379_10588987_1567181492605_DSC07057_(edit)--rgov-800width.jpg" title="The Virgo Harvesting Robot"><img src="/por/images/Reports/POR/2019/1843379/1843379_10588987_1567181492605_DSC07057_(edit)--rgov-66x44.jpg" alt="The Virgo Harvesting Robot"></a> <div class="imageCaptionContainer"> <div class="imageCaption">The Virgo harvesting robot in action picking small grape tomato varietals at a greenhouse facility in New York state.</div> <div class="imageCredit">Jason Chrisos</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Joshua&nbsp;Lessing</div> <div class="imageTitle">The Virgo Harvesting Robot</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ As a result of the SBIR Phase I project, Root AI has overcome key technical risks in computer vision, perception and grasping, which enable the newly developed autonomous harvesting robot, called Virgo, to dexterously pick fruits in hard to reach places directly from living vines.  During the project, new methods of filtering and processing images under the unique lighting conditions of a greenhouse were developed and empirically verified.  Using these new innovations, improved techniques for spatially mapping growing environments through fusion of 2D RGB and 3D point cloud information were developed.  Finally, novel mechanisms for grasping were developed and tested at U.S. farms, which mimic the complex motions that a person intuitively makes while harvesting fruits. This work has contributed to the broader robotic manipulation and computer vision communities? understanding of 3D mapping and motion planning in and around living plants, an understudied and highly relevant topic in robotics and computer vision.  Two new technical metrics, pick cycle time and harvesting coverage, were developed and verified with greenhouse growers to gauge Virgo?s progress towards commercial viability.  Analysis of these metrics over the course of the Phase I showed that the integrated developments from this project produced a 2.5X increase in picking speed and a 35% increase in harvesting coverage (the percentage of harvestable ripe fruits the system can access and collect).  Now that Virgo is capable of harvesting at compelling speeds and of reaching most fruits, the technology is ready for adaptation into a commercial product.  The successful outcome of this work will ultimately be the first truly autonomous and universal produce harvesting robotic platform, a capability which would precipitate a complete shift in how we think about crop management in the future.  The commercial and societal ramifications cannot be overstated.  Virgo is the foundation for a high-quality &amp; dependable source of labor, which would stabilize the margin-compressed agricultural industry and ensure our ability to sustainably feed a rapidly expanding population.  Ultimately, we view Virgo as a pioneer in the new age of agriculture, and a necessary innovation to ensure the democratization of nutritious, affordable and locally grown produce.          Last Modified: 08/30/2019       Submitted by: Joshua Lessing]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
