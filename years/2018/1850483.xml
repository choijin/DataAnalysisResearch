<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: CSR: Mitigating Tail Latency in Prediction-serving Systems using Coding-theoretic Tools</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>175000.00</AwardTotalIntnAmount>
<AwardAmount>175000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Matt Mutka</SignBlockName>
<PO_EMAI>mmutka@nsf.gov</PO_EMAI>
<PO_PHON>7032927344</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Prediction-serving systems take in queries and return predictions from a machine learning model. For example, an image classification service would take an image as a query and respond with a prediction of whether there is a car in the image. Prediction-serving systems are increasingly important for a wide variety of applications today. These systems are typically run in large-scale computing infrastructures, where failures and slowdowns are common. Such unavailability results in significant increase in the query-response latency, thereby degrading the quality-of-service. The research project designs and implements a resource-efficient solution for robustness in prediction-serving systems using a tool from the domain of coding theory called "erasure-coded computation".&lt;br/&gt;&lt;br/&gt;The overarching goal of the project is to design and implement a solution for reducing the potential long latency in prediction-serving systems using erasure-coded computations. The project overcomes critical limitations in existing coded-computation solutions by employing machine learning in a novel way. Specifically, the project involves the following key tasks: (1) Designing a low-overhead coded-computation solution that efficiently supports complex non-linear functions by employing a learning-based approach; (2) Designing an efficient training methodology conforming to the constraints of real-world prediction-serving systems; and (3) System design and implementation.&lt;br/&gt;&lt;br/&gt;The software resulting from the project will be integrated into open-source prediction-serving systems for use in both research and education. Active engagement in promoting diversity in science, technology, engineering and mathematics disciplines and undergraduate mentorship will be continued. The findings from the project will be integrated into graduate and undergraduate courses in computer science.&lt;br/&gt;&lt;br/&gt;The results from the research project, including software, will be made available at http://www.cs.cmu.edu/~rvinayak/crii .&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/13/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/13/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1850483</AwardID>
<Investigator>
<FirstName>Rashmi</FirstName>
<LastName>Vinayak</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rashmi Vinayak</PI_FULL_NAME>
<EmailAddress>rvinayak@cs.cmu.edu</EmailAddress>
<PI_PHON>4122689527</PI_PHON>
<NSF_ID>000754726</NSF_ID>
<StartDate>02/13/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie-Mellon University]]></Name>
<CityName/>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~175000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p><span id="docs-internal-guid-d348fddd-7fff-f6ac-48c4-14428165803e"> </span></p> <p dir="ltr"><span>Predictions-serving systems take in queries and return predictions from a machine learning model. For example, an image classification service would take an image as a query and respond with a prediction of whether there is a car in the image. Prediction-serving systems are increasingly becoming the primary workhorses behind a wide variety of applications today. These systems are typically run in large-scale computing infrastructures, where failures and slowdowns are common. Such unavailabilities result in significant increase in the query-response latency, thereby degrading the quality-of-service. The research project designs and implements a resource-efficient solution for robustness in prediction-serving systems using a tool from the domain of coding theory called "erasure-coded computation".&nbsp;</span></p> <p dir="ltr"><span>&nbsp;</span>In this project we designed, implemented and evaluated a catch-all solution for reining in tail latency in prediction-serving systems using erasure-coded computations. The project overcomes critical limitations in existing coded-computation solutions by employing machine learning in a novel way. Specifically, the project involved the following key tasks: (1) Designing a low-overhead coded-computation solution that efficiently supports complex non-linear functions by employing a learning-based approach; (2) Designing an efficient training methodology conforming to the constraints of real-world prediction-serving systems; and (3) System design and implementation. All the three tasks were successfully completed.</p> <p dir="ltr"><span id="docs-internal-guid-1ad47cb5-7fff-4e8b-bbe3-1386259512ca"><span>Machine learning models are now playing critical roles in a wide variety of applications that are deeply impacting human society -- machine translation in breaking communication barriers, voice recognition and natural language processing in home automation,&nbsp; object recognition in self driving cars, to name a few. Going ahead, large-scale prediction serving systems are going to see widespread usage as more and more cloud-based applications leverage prediction services offered by cloud server providers. By designing and building a prediction serving system that mitigates tail latency inflation, the outcomes of this research project enables this trend. The push towards this trend hastens the technology advancement and adoption in our society, and ultimately improves our quality of life.</span></span></p> <p dir="ltr"><span>&nbsp;</span>The software resulting from the project has been integrated into open-source prediction-serving systems for use in both research and education. The findings from the project were integrated into courses at CMU.</p> <p dir="ltr"><span>&nbsp;</span>The software resulting from this project is made available at&nbsp; <a href="https://github.com/Thesys-lab/parity-models">https://github.com/Thesys-lab/parity-models</a></p> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 02/07/2021<br>      Modified by: Rashmi&nbsp;Vinayak</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   Predictions-serving systems take in queries and return predictions from a machine learning model. For example, an image classification service would take an image as a query and respond with a prediction of whether there is a car in the image. Prediction-serving systems are increasingly becoming the primary workhorses behind a wide variety of applications today. These systems are typically run in large-scale computing infrastructures, where failures and slowdowns are common. Such unavailabilities result in significant increase in the query-response latency, thereby degrading the quality-of-service. The research project designs and implements a resource-efficient solution for robustness in prediction-serving systems using a tool from the domain of coding theory called "erasure-coded computation".   In this project we designed, implemented and evaluated a catch-all solution for reining in tail latency in prediction-serving systems using erasure-coded computations. The project overcomes critical limitations in existing coded-computation solutions by employing machine learning in a novel way. Specifically, the project involved the following key tasks: (1) Designing a low-overhead coded-computation solution that efficiently supports complex non-linear functions by employing a learning-based approach; (2) Designing an efficient training methodology conforming to the constraints of real-world prediction-serving systems; and (3) System design and implementation. All the three tasks were successfully completed. Machine learning models are now playing critical roles in a wide variety of applications that are deeply impacting human society -- machine translation in breaking communication barriers, voice recognition and natural language processing in home automation,  object recognition in self driving cars, to name a few. Going ahead, large-scale prediction serving systems are going to see widespread usage as more and more cloud-based applications leverage prediction services offered by cloud server providers. By designing and building a prediction serving system that mitigates tail latency inflation, the outcomes of this research project enables this trend. The push towards this trend hastens the technology advancement and adoption in our society, and ultimately improves our quality of life.  The software resulting from the project has been integrated into open-source prediction-serving systems for use in both research and education. The findings from the project were integrated into courses at CMU.  The software resulting from this project is made available at  https://github.com/Thesys-lab/parity-models             Last Modified: 02/07/2021       Submitted by: Rashmi Vinayak]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
