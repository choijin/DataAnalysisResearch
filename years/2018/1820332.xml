<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I: TerraSentia: Ultra-compact, Autonomous, Teachable Under-canopy Phenotyping Robot for Plant Breeders and Crop Scientists</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2018</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anna Brady-Estevez</SignBlockName>
<PO_EMAI>abrady@nsf.gov</PO_EMAI>
<PO_PHON>7032927077</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Broader Impacts: The broader impact of this Small Business Innovation Research (SBIR) project include improving food security, while at the same time enhancing the economic viability and environmental sustainability of large-scale production agriculture. In order to improve crop varieties, agricultural production, and sustainability of farming, there is an urgent need for better technologies to acquire under-canopy plant trait and health data. Examples of high-value under-canopy data include emergence, stem width, corn ear height, plant life-cycle events like flowering and fruiting, and symptoms of pathogens, diseases, and nutrient deficiency. Because these data cannot be obtained by aerial imaging, under-canopy data collection has dramatically greater actionability and value compared to aerial data. However no cost-effective, scalable ways of collecting this data are currently available. In fact, the state of the art is manual data collection by crop scientists (and their students or interns), agronomists, crop-scouts or farmers - an extremely labor intensive, and therefore expensive way of collecting this highly valuable data. Our work will greatly enhance the availability of under-canopy data from field crops. The commercial value of the field data for crop breeding is in excess of $50 Million/year for breeding major row-crops in the US.&lt;br/&gt;&lt;br/&gt;Intellectual Merits: This SBIR Phase I project will demonstrate the technical feasibility of autonomously collecting under-canopy data from field crops using TerraSentia, our low-cost ground robot. In preliminary work, we have built the robot hardware, demonstrated its ability to collect high-value plant data from row-crop fields, and analyze it to generate plant-trait information. In the proposed work, we will enable and demonstrate the ability of TerraSentia to collect data autonomously throughout the season. We will demonstrate the technical feasibility of fusing information from low-cost LIDAR, GPS, and vision. We will also demonstrate the feasibility using real-time control algorithms to adapt camera perspective and robot path in order to obtain the highest quality information from the complex and dynamic under- canopy field environments. These high-risk innovations will together enable long-term deployment of TerraSentia for effective data collection and phenotyping, benefiting crop scientists and agricultural product development professionals.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/29/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/29/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1820332</AwardID>
<Investigator>
<FirstName>Chinmay</FirstName>
<LastName>Soman</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chinmay Soman</PI_FULL_NAME>
<EmailAddress>chinmay@earthsense.co</EmailAddress>
<PI_PHON>2174024767</PI_PHON>
<NSF_ID>000736751</NSF_ID>
<StartDate>06/29/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>EarthSense, Inc.</Name>
<CityName>Champaign</CityName>
<ZipCode>618207460</ZipCode>
<PhoneNumber>2174024767</PhoneNumber>
<StreetAddress>60 Hazelwood Drive</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080358600</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>EARTHSENSE, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[EarthSense, Inc.]]></Name>
<CityName>Champaign</CityName>
<StateCode>IL</StateCode>
<ZipCode>618207460</ZipCode>
<StreetAddress><![CDATA[60 Hazelwood Drive]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8030</Code>
<Text>Chemical Technology</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 3"> <div class="layoutArea"> <div class="column"> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <div class="column"> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p>With SBIR Phase I funding, EarthSense has demonstrated the technical feasibility of the TerraSentia robotics and analytics platform to deliver large scale,&nbsp;under canopy, quantitative plant trait data for crop breeding and agricultural product research and development. Major corporations and public sector institutions currently spend over $250 Million per year on equipment, software, sensors, and&nbsp;most of all, manual labor&nbsp;on collecting field data. However, this data is incomplete, low-volume, and low-reliability.</p> <p>This lack of data is called the&nbsp;"field phenotyping bottleneck". The inability to get&nbsp;large scale&nbsp;quantitative plant trait information from R&amp;D fields is preventing us from significantly improving the yield and sustainability of agriculture. Yields of major crops -corn, soybean, wheat, rice, etc. - must double by 2050 in order to feed the global population. Unfortunately, we are on track to increase yields only by around 50%. This catastrophic shortfall is despite major seed companies spending over $6.5 Billion every year on product R&amp;D, out of which over $250 Million is spent on field data collection. In large part, the current glacial rate of crop performance improvement is due to the field phenotyping bottleneck.</p> </div> </div> </div> </div> <div class="column"> <div class="page" title="Page 1"> <div class="layoutArea"> <div class="column"> <p>With SBIR Phase I support, EarthSense has successfully demonstrated the technical feasibility of using the TerraSentia platform to break through the field phenotyping bottleneck. Outcomes of the SBIR Phase I work include:</p> <div class="page" title="Page 3"> <div class="layoutArea"> <div class="column"><ol> <li>Robust ultracompact TerraSentia robot that travels in row-crop fields</li> <li>Lidar or GPS based autonomous navigation in these fields&nbsp;</li> <li>Rapid collection of under-canopy, high volume, quantitative data with low-cost RGB cameras and 2D Lidars&nbsp;</li> <li>Analysis of these data on our cloud-hosted machine-learning algorithms&nbsp;</li> <li>Delivery of quantitative plant trait information to crop breeders</li> </ol></div> </div> </div> <p>The unique datasets generated by TerraSentia at scale will enable&nbsp; development of new high yielding varieties of crops that require less water, chemicals, and other inputs; even as climate conditions become steadily unfavorable.</p> <div class="page" title="Page 2"> <div class="layoutArea"> <div class="column"> <p>While our first target market is crop breeding, the unique data gathered by TerraSentia robots will also&nbsp;improve agricultural sustainability and productivity&nbsp;by enabling precision agriculture based on real-time, high-resolution, clearly actionable data. With clear, actionable insights derived from unique, under-canopy data collected by TerraSentia, farmers would detect diseases, nutrient deficiency, water stress etc. earlier and treat them far more efficiently.</p> </div> </div> </div> <p>To accelerate the path to market of the TerraSentia platform, EarthSense has marshaled other resources to supplement the SBIR Phase I support. These resources include sweat equity, revenues from pilot tests, and venture investment. These supplementary resources are being used for low-risk aspects of product development like web and tablet app development, industrial design, and manufacturing.</p> <p>Ultimately, the mission at EarthSense is to enable sustainable abundance through intelligent machines. This SBIR Phase I funding has enabled us to lay the groundwork for long-term technical and product development that will enable large-scale adoption of environmentally and socially beneficial agricultural ecosystems enabled by robotics and machine learning products specifically designed for agriculture.</p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div><br> <p>            Last Modified: 08/19/2019<br>      Modified by: Chinmay&nbsp;Soman</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566248502451_TerraSentia--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566248502451_TerraSentia--rgov-800width.jpg" title="TerraSentia - Field Phenotyping Robot"><img src="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566248502451_TerraSentia--rgov-66x44.jpg" alt="TerraSentia - Field Phenotyping Robot"></a> <div class="imageCaptionContainer"> <div class="imageCaption">TerraSentia collects high-value, under canopy data with simple sensors. This data is used for accelerating the breeding of high-yeilding crops that require fewer fertilizers and chemicals and can thrive in stressful weather and degraded soils.</div> <div class="imageCredit">EarthSense, Inc.</div> <div class="imageSubmitted">Chinmay&nbsp;Soman</div> <div class="imageTitle">TerraSentia - Field Phenotyping Robot</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566235554380_stem-width--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566235554380_stem-width--rgov-800width.jpg" title="Stem Width Measurement"><img src="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566235554380_stem-width--rgov-66x44.jpg" alt="Stem Width Measurement"></a> <div class="imageCaptionContainer"> <div class="imageCaption">EarthSense has developed a suite of machine-learning and machine-vision algorithms that enable quantification of critical under-canopy traits of plants, including stem width, true leaf area index, corn ear height, soybean node count, flower count and others.</div> <div class="imageCredit">EarthSense, Inc.</div> <div class="imageSubmitted">Chinmay&nbsp;Soman</div> <div class="imageTitle">Stem Width Measurement</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566255333931_3DLidarImage--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566255333931_3DLidarImage--rgov-800width.jpg" title="3D Lidar Map"><img src="/por/images/Reports/POR/2019/1820332/1820332_10554222_1566255333931_3DLidarImage--rgov-66x44.jpg" alt="3D Lidar Map"></a> <div class="imageCaptionContainer"> <div class="imageCaption">EarthSense has developed algorithms to reconstruct the 3D structure of crop canopies using data from low-cost 2D Lidars.</div> <div class="imageCredit">EarthSense, Inc.</div> <div class="imageSubmitted">Chinmay&nbsp;Soman</div> <div class="imageTitle">3D Lidar Map</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[           With SBIR Phase I funding, EarthSense has demonstrated the technical feasibility of the TerraSentia robotics and analytics platform to deliver large scale, under canopy, quantitative plant trait data for crop breeding and agricultural product research and development. Major corporations and public sector institutions currently spend over $250 Million per year on equipment, software, sensors, and most of all, manual labor on collecting field data. However, this data is incomplete, low-volume, and low-reliability.  This lack of data is called the "field phenotyping bottleneck". The inability to get large scale quantitative plant trait information from R&amp;D fields is preventing us from significantly improving the yield and sustainability of agriculture. Yields of major crops -corn, soybean, wheat, rice, etc. - must double by 2050 in order to feed the global population. Unfortunately, we are on track to increase yields only by around 50%. This catastrophic shortfall is despite major seed companies spending over $6.5 Billion every year on product R&amp;D, out of which over $250 Million is spent on field data collection. In large part, the current glacial rate of crop performance improvement is due to the field phenotyping bottleneck.          With SBIR Phase I support, EarthSense has successfully demonstrated the technical feasibility of using the TerraSentia platform to break through the field phenotyping bottleneck. Outcomes of the SBIR Phase I work include:    Robust ultracompact TerraSentia robot that travels in row-crop fields Lidar or GPS based autonomous navigation in these fields  Rapid collection of under-canopy, high volume, quantitative data with low-cost RGB cameras and 2D Lidars  Analysis of these data on our cloud-hosted machine-learning algorithms  Delivery of quantitative plant trait information to crop breeders     The unique datasets generated by TerraSentia at scale will enable  development of new high yielding varieties of crops that require less water, chemicals, and other inputs; even as climate conditions become steadily unfavorable.     While our first target market is crop breeding, the unique data gathered by TerraSentia robots will also improve agricultural sustainability and productivity by enabling precision agriculture based on real-time, high-resolution, clearly actionable data. With clear, actionable insights derived from unique, under-canopy data collected by TerraSentia, farmers would detect diseases, nutrient deficiency, water stress etc. earlier and treat them far more efficiently.     To accelerate the path to market of the TerraSentia platform, EarthSense has marshaled other resources to supplement the SBIR Phase I support. These resources include sweat equity, revenues from pilot tests, and venture investment. These supplementary resources are being used for low-risk aspects of product development like web and tablet app development, industrial design, and manufacturing.  Ultimately, the mission at EarthSense is to enable sustainable abundance through intelligent machines. This SBIR Phase I funding has enabled us to lay the groundwork for long-term technical and product development that will enable large-scale adoption of environmentally and socially beneficial agricultural ecosystems enabled by robotics and machine learning products specifically designed for agriculture.                 Last Modified: 08/19/2019       Submitted by: Chinmay Soman]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
