<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Sensory-Biased Working Memory &amp; Attention Networks in the Human Brain</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>591061.00</AwardTotalIntnAmount>
<AwardAmount>591061</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jonathan Fritz</SignBlockName>
<PO_EMAI>jfritz@nsf.gov</PO_EMAI>
<PO_PHON>7032927923</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Abstract&lt;br/&gt;&lt;br/&gt;Humans experience the world via multiple sensory modalities --  we see, we hear, and we touch. Each sensory modality has unique strengths and weaknesses in its ability to represent the world around us. Our minds are able to flexibly recruit visual or auditory brain structures when their strengths correspond to the task at hand. In addition, our experience at any moment depends both on sensory input and on working memory and attention mechanisms in the brain. These mechanisms have very limited capacities, which in turn limit cognition. The overarching goal of this project is to examine the human brain mechanisms that support attention and working memory in vision, hearing, and touch. The research team will perform functional MRI experiments to study the brain activity of healthy adults while they perform demanding sensory working memory tasks. Preliminary studies by the research group suggest that there are extensive brain networks, extending into the frontal lobes of the cerebral cortex, that are specialized for each sensory modality, as well as a shared network that supports and unifies these three senses. The current research program will examine individual differences in working memory performance and brain network organization. It will also develop advanced computational models that can predict the functional organization of an individual's brain from their unique pattern or 'fingerprint' of brain connectivity. The project will facilitate other research efforts through the dissemination of new models and computational tools, and will recruit and train young scientists, including members of groups that are under-represented in STEM, in cognitive neuroscience research.&lt;br/&gt;&lt;br/&gt;This proposal has 4 primary intellectual goals: (1) identify the fine-scale organization of tactile, visual, auditory, and modality-independent attention &amp; working memory (WM) regions within human cerebral cortex; (2) reveal the specificity of coding of WM information across cortical regions for each modality; (3) detail the network organization of attention &amp; WM circuits; and (4) test hypotheses about content-specific WM mechanisms and cross-modality WM coding. Individual subject fMRI analyses permit fine-scale observation of distinct functional regions. Drawing on subject-specific maps of cortical organization, the research group will re-examine the highly debated question of which brain structures support stimulus-specific working memory for each modality. It will investigate the specificity of sensory modality biased regions by examining functional networks in the resting-state within individual participants. The research team will leverage its findings to probe these networks in 1200 subjects from the Human Connectome Project dataset. The research group will also test and validate a machine-learning approach, Connectome Fingerprinting, for predicting the location of modality-specific working memory regions in individual brains from their unique functional connectome. Vision excels in coding spatial information, but codes timing less reliably; conversely, the auditory system performs high-fidelity temporal coding but coarse spatial coding. The research team has observed cross-modal recoding of WM information into cortical structures that prefer the 'appropriate modality' - auditory spatial WM recruits visual-biased regions and visual temporal WM recruits auditory-biased regions. To probe content-specific WM mechanisms, the researchers will examine interactions between sensory modality WM and space/time WM. The research group hypothesizes that visual and spatial WM stores are distinct, but that auditory and timing WM stores are shared. Collectively, these studies will elucidate the human brain networks and mechanisms that support sensory working memory.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/21/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/21/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1829394</AwardID>
<Investigator>
<FirstName>David</FirstName>
<LastName>Somers</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David C Somers</PI_FULL_NAME>
<EmailAddress>somers@bu.edu</EmailAddress>
<PI_PHON>6173581372</PI_PHON>
<NSF_ID>000198617</NSF_ID>
<StartDate>08/21/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<CountyName/>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Boston University]]></Name>
<CityName>Boston</CityName>
<CountyName/>
<StateCode>MA</StateCode>
<ZipCode>022152407</ZipCode>
<StreetAddress><![CDATA[64 Cummington Mall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>1699</Code>
<Text>COGNEURO</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~591061</FUND_OBLG>
</Award>
</rootTag>
