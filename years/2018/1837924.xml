<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CSR: Small: Cross-Layer Design of Power Delivery and Load Balancing for Green Data Centers</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>212488.00</AwardTotalIntnAmount>
<AwardAmount>228488</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Marilyn McClure</SignBlockName>
<PO_EMAI>mmcclure@nsf.gov</PO_EMAI>
<PO_PHON>7032925197</PO_PHON>
</ProgramOfficer>
<AbstractNarration>As ever more computing is moved to the cloud, the energy consumption of data centers becomes increasingly important, both from an environmental and cost viewpoint.  As a result, there is an increasing trend towards reducing the energy and carbon foot- print of data centers. While there has been considerable efforts to reduce the energy consumption,  relatively little attention has been paid towards the power delivery in data centers. The objective  of this work is to reduce the high voltage conversion losses (currently contributing 10-15%  power loss) to almost zero by designing a joint software and hardware power delivery architecture specifically for a multi-server  environment.  This research, which could lead to drastic reduction of power conversion losses in data centers, has far-reaching impact on the design of  sustainable and green data centers. Participation of underrepresented groups is encouraged, and  portions of the research is incorporated into cloud computing courses, as hardware projects  into a laboratory power electronics course, and as a case study of data center power delivery in  an advanced graduate level power electronics course. An interactive online  power usage portal, that visualizes in real-time the power usage of each individual server in  the test-cluster provides opportunities for public interaction with the research. These open-source software and hardware demonstrations enable practitioners  from around the world to learn more about sustainable computing. &lt;br/&gt;&lt;br/&gt;This research explores a cross-layer design approach to data centers, where the power delivery architecture and software load balancing algorithms work together to achieve the highest possible power delivery efficiency. The research explores electrically series-connected racks of servers, to minimize overall power conversion and attendant losses. A key challenge in series voltage stacking is the variation in input voltage of each server due to  imbalance of computational load in a series-stack. In this research, the challenge is addressed both in  hardware and software. In software, scalable load balancing algorithms that ensure uniform power consumption in each server in the rack are developed. The load balancing algorithms simultaneously optimize for response time and power loss. Moreover, hardware power converters and distributed energy storage (e.g., capacitors, batteries) provide filtering and power balance in cases when software alone does not suffice. A key question being addressed is the suitable size of energy storage, and the required control bandwidth of the power converters to ensure proper operation for realistic workloads. In addition, high speed sensing and communication of electrical measurements of voltage and currents are employed in combination with operation of servers at asymmetric input voltages for static power consumption mismatch mitigation.  The load balancing algorithms is tested with two types of workloads: (1) Interactive web workloads with short turnaround time and homogeneous servers; and (2) Map-reduce type workloads with long turnaround time and servers with data locality constraint.</AbstractNarration>
<MinAmdLetterDate>06/28/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/28/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1837924</AwardID>
<Investigator>
<FirstName>Robert</FirstName>
<LastName>Pilawa-Podgurski</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robert Pilawa-Podgurski</PI_FULL_NAME>
<EmailAddress>pilawa@berkeley.edu</EmailAddress>
<PI_PHON>5106645171</PI_PHON>
<NSF_ID>000632839</NSF_ID>
<StartDate>06/28/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<StreetAddress2><![CDATA[1608 Fourth Street, Suite 220]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>124726725</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Berkeley]]></Name>
<CityName>Berkeley</CityName>
<StateCode>CA</StateCode>
<ZipCode>947045940</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramElement>
<Code>7354</Code>
<Text>CSR-Computer Systems Research</Text>
</ProgramElement>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0117</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~212488</FUND_OBLG>
<FUND_OBLG>2017~16000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="western">We have developed hardware and software solutions to reduce the high voltage conversion losses present in today's data centers to almost zero by designing a power delivery architecture specifically for a multi-server environment. <span style="color: #000000;"><span style="font-family: &quot;Times New Roman&quot;, serif;"><span><span lang="en-US">We have demonstrated, in hardware and software, the</span></span></span></span> idea of series-stacked servers, which, with the assistance of well-designed hardware and software, can drastically reduce the power delivery loss. Specifically, we have developed custom differential power processing (DPP) power converters, capable of powering a stack of series-connected ARM Cortex-based embedded computers, running Linux operating systems and distributed data processing software. We have demonstrated a peak efficiency of 99% power delivery, using computer workloads similar to that which occurs in datacenters. Moreover, we have successfully demonstrated startup, shutdown, and hot-swapping of individual computers, with un-interrupted continued operation. The high efficiency operation of this system relies on two primary research efforts, based in hardware and software innovations:</p> <p class="western">&nbsp;</p> <p class="western">1. Differential power conversion. <span style="color: #000000;"><span style="font-family: &quot;Times New Roman&quot;, serif;"><span><span lang="en-US">We addressed</span></span></span></span> the challenge of differing server voltage caused by load imbalance by designing and employing differential power converters. The differential power converters provide voltage balancing by processing the difference in power between imbalanced loads, hence replacing inefficient high-voltage bulk power conversion with differential power conversion between servers. By processing only the difference in power between servers, substantial efficiency improvements can be realized. This was demonstrated using a resonant switched-capacitor power converter architectures with ultra-high efficiency.</p> <p class="western">&nbsp;</p> <p class="western">2. Randomized load balancing. The conversion loss in differential power converters depends on the amount of load imbalance in a series-connected stack. This makes effective load balancing critical to</p> <p class="western">reducing the conversion loss. In addition, the load balancing algorithm needs to be scalable in a large</p> <p class="western">data center and must optimize for both response time and power at the same time. Computational load</p> <p class="western">needs to be balanced within each series stack to minimize the mismatch and processed power. This was accomplished through custom software to ensure distributed computing and load balancing across the series-stacked computing domains</p> <p>&nbsp;</p><br> <p>            Last Modified: 01/11/2021<br>      Modified by: Robert&nbsp;Pilawa-Podgurski</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[We have developed hardware and software solutions to reduce the high voltage conversion losses present in today's data centers to almost zero by designing a power delivery architecture specifically for a multi-server environment. We have demonstrated, in hardware and software, the idea of series-stacked servers, which, with the assistance of well-designed hardware and software, can drastically reduce the power delivery loss. Specifically, we have developed custom differential power processing (DPP) power converters, capable of powering a stack of series-connected ARM Cortex-based embedded computers, running Linux operating systems and distributed data processing software. We have demonstrated a peak efficiency of 99% power delivery, using computer workloads similar to that which occurs in datacenters. Moreover, we have successfully demonstrated startup, shutdown, and hot-swapping of individual computers, with un-interrupted continued operation. The high efficiency operation of this system relies on two primary research efforts, based in hardware and software innovations:   1. Differential power conversion. We addressed the challenge of differing server voltage caused by load imbalance by designing and employing differential power converters. The differential power converters provide voltage balancing by processing the difference in power between imbalanced loads, hence replacing inefficient high-voltage bulk power conversion with differential power conversion between servers. By processing only the difference in power between servers, substantial efficiency improvements can be realized. This was demonstrated using a resonant switched-capacitor power converter architectures with ultra-high efficiency.   2. Randomized load balancing. The conversion loss in differential power converters depends on the amount of load imbalance in a series-connected stack. This makes effective load balancing critical to reducing the conversion loss. In addition, the load balancing algorithm needs to be scalable in a large data center and must optimize for both response time and power at the same time. Computational load needs to be balanced within each series stack to minimize the mismatch and processed power. This was accomplished through custom software to ensure distributed computing and load balancing across the series-stacked computing domains          Last Modified: 01/11/2021       Submitted by: Robert Pilawa-Podgurski]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
