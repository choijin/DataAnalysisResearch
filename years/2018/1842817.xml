<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Visual category learning by toddlers provides new principles for teaching rapid generalization</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>548791.00</AwardTotalIntnAmount>
<AwardAmount>548791</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Soo-Siang Lim</SignBlockName>
<PO_EMAI>slim@nsf.gov</PO_EMAI>
<PO_PHON>7032927878</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Learning is adaptive change in response to experience.  Future experiences never repeat exactly and the world often poses new never-before encountered problems. Therefore, training systems that lead to effective generalization are sought after in both human and machine learning. Extensive experience with many training examples is known to promote generalization but this requires time and a large set of training examples.  There are cases of human learning in which appropriate generalization requires only one or a few examples, or 'few-shot' learning. The human infant begins learns to become a few-shot learner of visual object categories who is able, for example, to appropriately generalize the category 'tractor' after seeing a tractor. This research will determine the learning experiences that teach young children to be few-shot learners of visual object categories with the goal of determining the general principles of training sets that lead to rapid learning and generalization.  These principles will be tested in machine learning models and in experiments with children. General principles of how to design and structure training materials to lead to effective learning and rapid generalization have useful applications in education, in image recognition, and in machine learning. &lt;br/&gt; &lt;br/&gt;Most models and theories of category learning concentrate on learning to discriminate categories with training consisting of many examples of many different categories. Despite remarkable advances in computer vision there is a large class of problems that remain unsolved because they require few-shot learning.  Despite extensive research on educational practices, there is a limited understanding of how best to structure material for generalization and knowledge transfer. In becoming few-shot learners of visual object categories, human infants first collect extensive experience with a few individual objects within a few early-learned categories -- their own sippy cup, the family dog, their own shoes and then they progress to becoming rapid few-shot learners of other visual object categories. The core hypothesis tested in the research is that few-shot learning emerges as a generalization of expertise about a very few categories. The research will capture the visual experiences supporting the development of expertise for a few categories using head cameras and head-mounted eye trackers worn by infants. Algorithms from visual science and computer vision will be used to analyze the statistical properties of these visual experiences and of expertise that then generalizes to other visual categories.  Those principles will be tested in behavioral experiments with infants and tested and formalized in modeling experiments using deep convolutional neural networks (CNNs).  The principles offer a solution to the problem of rapid generalization from few examples that is potentially general to any visual learning problem.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/13/2019</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1842817</AwardID>
<Investigator>
<FirstName>Linda</FirstName>
<LastName>Smith</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Linda B Smith</PI_FULL_NAME>
<EmailAddress>smith4@indiana.edu</EmailAddress>
<PI_PHON>8128558256</PI_PHON>
<NSF_ID>000085967</NSF_ID>
<StartDate>08/13/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Chen</FirstName>
<LastName>Yu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chen Yu</PI_FULL_NAME>
<EmailAddress>chenyu@indiana.edu</EmailAddress>
<PI_PHON>8128560838</PI_PHON>
<NSF_ID>000175165</NSF_ID>
<StartDate>08/13/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>David</FirstName>
<LastName>Crandall</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>David Crandall</PI_FULL_NAME>
<EmailAddress>djcran@indiana.edu</EmailAddress>
<PI_PHON>8128561115</PI_PHON>
<NSF_ID>000571471</NSF_ID>
<StartDate>08/13/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Indiana University</Name>
<CityName>Bloomington</CityName>
<ZipCode>474013654</ZipCode>
<PhoneNumber>3172783473</PhoneNumber>
<StreetAddress>509 E 3RD ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IN09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>006046700</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF INDIANA UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006046700</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Indiana University]]></Name>
<CityName>Bloomington</CityName>
<StateCode>IN</StateCode>
<ZipCode>474057000</ZipCode>
<StreetAddress><![CDATA[1101 East 10th Street, Indiana U]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IN09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>004Y</Code>
<Text>Science of Learning</Text>
</ProgramElement>
<ProgramElement>
<Code>1698</Code>
<Text>DS -Developmental Sciences</Text>
</ProgramElement>
<ProgramReference>
<Code>059Z</Code>
<Text>Science of Learning</Text>
</ProgramReference>
<ProgramReference>
<Code>1698</Code>
<Text>DS-Developmental Sciences</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~548791</FUND_OBLG>
</Award>
</rootTag>
