<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Numerical Methods for Parametric Partial Differential Equations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2018</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>369192.00</AwardTotalIntnAmount>
<AwardAmount>369192</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Leland Jameson</SignBlockName>
<PO_EMAI>ljameson@nsf.gov</PO_EMAI>
<PO_PHON>7032924883</PO_PHON>
</ProgramOfficer>
<AbstractNarration>One of the most significant scientific challenges of this century is the accurate description and computation of complex processes such as climate change, contaminant flow, genomics, and even social media and finance. While one can create a mathematical model for these processes, the large number of parameters in the model inhibits the use of traditional computational tools for fast and reliable predictions. In addition, there is the question of the efficacy of the mathematical model. The proposed research puts forward new mathematical ideas, based primarily on model reduction, to determine the importance of the various parameters and derive simpler models that still faithfully describe the underlying process. This, in turn, leads to more accurate and less costly computational models that can be implemented within today's existing  computing resources.  The project also investigates how to quantify uncertainty in both the model and the parameters from data observations of the process.&lt;br/&gt;&lt;br/&gt;This project investigates three demanding computational tasks in parametric partial differential equations (PDEs). The first of these, called the forward problem, seeks the creation of fast and accurate online solvers for the PDE when given a parameter query. Such online solvers are used in a myriad of applications that seek to optimize performance through parameter selection. The second seeks optimal methods to compute the state of the PDE from observational data. Related to this is the third problem of estimating the parameters of the PDE from observational data. Because of the large number of parameters, traditional numerical methods for such high dimensional problems face the so-called "curse of dimensionality", i.e., they cannot obtain the desired accuracy of computation in a reasonable computational time. The proposed research circumvents this difficulty by developing novel methods of model reduction based on sparsity ad highly nonlinear approximation such as n-term dictionary approximation. Foundational results will also be established for inverse parameter estimation that prove Lipschitz smoothness for the forward and inverse maps under minimal smoothness conditions on the parameters. These foundational results are then coupled with reduced modeling to create numerical methods for parameter estimation and model verification.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/31/2018</MinAmdLetterDate>
<MaxAmdLetterDate>05/31/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1817603</AwardID>
<Investigator>
<FirstName>Ronald</FirstName>
<LastName>DeVore</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ronald A DeVore</PI_FULL_NAME>
<EmailAddress>rdevore@math.tamu.edu</EmailAddress>
<PI_PHON>9798453336</PI_PHON>
<NSF_ID>000329812</NSF_ID>
<StartDate>05/31/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Guergana</FirstName>
<LastName>Petrova</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Guergana Petrova</PI_FULL_NAME>
<EmailAddress>gpetrova@math.tamu.edu</EmailAddress>
<PI_PHON>9798457554</PI_PHON>
<NSF_ID>000256375</NSF_ID>
<StartDate>05/31/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M University</Name>
<CityName>College Station</CityName>
<ZipCode>778454375</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Pkwy South</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>020271826</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A &amp; M UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042915991</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M University Main Campus]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433368</ZipCode>
<StreetAddress><![CDATA[3368 TAMU]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1271</Code>
<Text>COMPUTATIONAL MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~369192</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Complex physical and biological systems are&nbsp; mathematically described by partial differential equations (PDEs).&nbsp; These PDEs are solved on computers using numerical algorithms.&nbsp; The usefulness of the computed solutions depends critically on the accuracy of these algorithms.</p> <p>This project studies theory and&nbsp; numerical algorithms for solving PDEs that depend on many variables or parameters. Such PDEs arise in&nbsp; several important areas of applied mathematics including the modeling&nbsp; of complex physical and biological systems as well as in optimal design in engineering.&nbsp; The main challenge in this research is to break the `curse of high dimensionality'&nbsp; by developing algorithms&nbsp; that are not severely deteriorating as the number of parameters/variables gets large.</p> <p><br />&nbsp;&nbsp; There are three main threads to this project:</p> <p>(i) building fast solvers for the forward problem, i.e., accurately computing the solution to the PDE when the parameters are given;</p> <p>(ii) developing theory and algorithms for&nbsp;&nbsp; parameter estimation when given observations of the state;</p> <p>(iii) exploring the utility of&nbsp; new methods based on neural networks (NN) and deep learning for the above tasks.</p> <p>The&nbsp;&nbsp; project has made major contributions to each of these areas.</p> <p>(i) The forward problem seeks fast and efficient solvers which, when given prescribed&nbsp; parameters, quickly produce the solution to the PDE (the so-called state) for these parameters.&nbsp; The most efficient solvers for the forward problem&nbsp; are based on what is called `model reduction'. Our current research on forward solvers has been directed at using nonlinear reduced models in place of linear spaces for the reduced models since the power of nonlinearity in other numerical settings (such as adaptive PDE solvers) is by now well established.&nbsp; We have developed&nbsp; two strategies for employing nonlinear reduced models and&nbsp; have given the first rigorous analysis of using parameter space partitioning in conjunction with polynomial reduced models for solving parametric elliptic PDEs. We also have shown that random queries of the solution manifold reduces the number of necessary queries from exponential to polynomial in the number of parameters.</p> <p>(ii) We have made significant progress on parameter estimation when given information about the state of a parametric PDE, which&nbsp; is a significant and challenging&nbsp; inverse problem. More precisely, we have&nbsp; described the optimal affine algorithm for data assimilation and its execution&nbsp; through convex minimization.&nbsp; We have discussed the most recent advances in the state and parameter estimation from data observations.</p> <p>(iii) An emerging approach to high dimensional numerical methods for PDEs is to use neural networks (NN) and deep learning as the vehicle for developing numerical algorithms.&nbsp; This is motivated by the&nbsp; great success of deep learning in the field of artificial intelligence.&nbsp; However, so far,&nbsp; the use of NN methodology in designing numerical methods for PDEs has not been given a provable advantage. The reason seems to be the fact that NN methods are not well enough understood.&nbsp; Our research is directed at identifying&nbsp; when and why deep learning works and pinpointing the application domains where NN&nbsp; methods promise to give improved numerical performance. We have made some major steps in understanding the approximation properties of deep NNs and identifying classes of functions for which they perform well in approximation.&nbsp; These new model classes are based on notions of sparsity and self similarity. We have provided a comprehensive treatise on the approximation efficiency of deep neural networks with ReLU activation and explored the intimate connection between dynamical systems and deep NN approximation by establishing exponential recovery of certain classes of refinable functions. Finally, we have introduced&nbsp; a definition of stable recovery and determined optimal recovery rate (error versus number of parameters)&nbsp; for many classical model classes.</p> <p>&nbsp;Intellectual merit and broader impact:</p> <p>The findings from the project were published in 10 papers and&nbsp; discussed in numerous conference and workshop talks. Undergraduate student, postdocs and female faculty members were involved in the research activities. Software development accompanied the theoretical findings. Parts of the code served as educational tools for PhD students.</p><br> <p>            Last Modified: 07/10/2021<br>      Modified by: Guergana&nbsp;Petrova</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Complex physical and biological systems are  mathematically described by partial differential equations (PDEs).  These PDEs are solved on computers using numerical algorithms.  The usefulness of the computed solutions depends critically on the accuracy of these algorithms.  This project studies theory and  numerical algorithms for solving PDEs that depend on many variables or parameters. Such PDEs arise in  several important areas of applied mathematics including the modeling  of complex physical and biological systems as well as in optimal design in engineering.  The main challenge in this research is to break the `curse of high dimensionality'  by developing algorithms  that are not severely deteriorating as the number of parameters/variables gets large.      There are three main threads to this project:  (i) building fast solvers for the forward problem, i.e., accurately computing the solution to the PDE when the parameters are given;  (ii) developing theory and algorithms for   parameter estimation when given observations of the state;  (iii) exploring the utility of  new methods based on neural networks (NN) and deep learning for the above tasks.  The   project has made major contributions to each of these areas.  (i) The forward problem seeks fast and efficient solvers which, when given prescribed  parameters, quickly produce the solution to the PDE (the so-called state) for these parameters.  The most efficient solvers for the forward problem  are based on what is called `model reduction'. Our current research on forward solvers has been directed at using nonlinear reduced models in place of linear spaces for the reduced models since the power of nonlinearity in other numerical settings (such as adaptive PDE solvers) is by now well established.  We have developed  two strategies for employing nonlinear reduced models and  have given the first rigorous analysis of using parameter space partitioning in conjunction with polynomial reduced models for solving parametric elliptic PDEs. We also have shown that random queries of the solution manifold reduces the number of necessary queries from exponential to polynomial in the number of parameters.  (ii) We have made significant progress on parameter estimation when given information about the state of a parametric PDE, which  is a significant and challenging  inverse problem. More precisely, we have  described the optimal affine algorithm for data assimilation and its execution  through convex minimization.  We have discussed the most recent advances in the state and parameter estimation from data observations.  (iii) An emerging approach to high dimensional numerical methods for PDEs is to use neural networks (NN) and deep learning as the vehicle for developing numerical algorithms.  This is motivated by the  great success of deep learning in the field of artificial intelligence.  However, so far,  the use of NN methodology in designing numerical methods for PDEs has not been given a provable advantage. The reason seems to be the fact that NN methods are not well enough understood.  Our research is directed at identifying  when and why deep learning works and pinpointing the application domains where NN  methods promise to give improved numerical performance. We have made some major steps in understanding the approximation properties of deep NNs and identifying classes of functions for which they perform well in approximation.  These new model classes are based on notions of sparsity and self similarity. We have provided a comprehensive treatise on the approximation efficiency of deep neural networks with ReLU activation and explored the intimate connection between dynamical systems and deep NN approximation by establishing exponential recovery of certain classes of refinable functions. Finally, we have introduced  a definition of stable recovery and determined optimal recovery rate (error versus number of parameters)  for many classical model classes.   Intellectual merit and broader impact:  The findings from the project were published in 10 papers and  discussed in numerous conference and workshop talks. Undergraduate student, postdocs and female faculty members were involved in the research activities. Software development accompanied the theoretical findings. Parts of the code served as educational tools for PhD students.       Last Modified: 07/10/2021       Submitted by: Guergana Petrova]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
