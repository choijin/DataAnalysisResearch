<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: A Tensor-Based Computational Framework for Model Reduction and Structured Matrices</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>139997.00</AwardTotalIntnAmount>
<AwardAmount>139997</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Pena Edsel</SignBlockName>
<PO_EMAI>epena@nsf.gov</PO_EMAI>
<PO_PHON>7032928080</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many tasks in scientific computing involve either data or operators that are inherently multidimensional: for example, a database of gray-scale images constitutes a three-dimensional array when each image is stored in a standard two-dimensional array format. Yet many standard numerical methods treat the data and associated operators as two-dimensional arrays, or matrices. This suggests that additional structure that could be leveraged for computational gain may be going undiscovered and underutilized. Recent research has shown that tensors (multidimensional arrays) and several types of corresponding decomposition methods can be instrumental in revealing latent correlations of both data and operators residing in high-dimensional spaces. Indeed, tensor decompositions can be provably superior to matrix-based counterparts in representation of certain types of data. This research project tackles two important questions: (1) how to uncover latent structure in data and operators using multidimensional tensor factorizations, and (2) how to use these revealed structures to develop a powerful computational framework that can harvest the benefits of this structure. Hands-on teaching material for graduate courses will be developed on randomized matrix methods and tensor decompositions. This teaching material, in the form of Python notebooks, along with the code developed as a part of this project, will be freely available as a software library under an open source license.&lt;br/&gt;&lt;br/&gt;The investigators aim to answer these questions in the context of two applications in scientific computing of major importance and far-reaching consequences: model reduction, a mathematical framework for reducing the computational cost associated with high-fidelity simulations of complicated physical phenomena, and structured matrix approximation, which is important in applications such as parametric partial differential equations and image deblurring. The work will approach these questions through an entirely new, multidimensional lens with the advantages of providing new computational efficiencies and structure that can only be obtained by moving to a higher-dimensional regime. Two signature features of the project are: (1) design and analysis of structured tensor decompositions that are efficient in terms of computations and memory accesses, by using randomized matrix methods and the algebraic structure of tensor decompositions; and (2) use of tensor models, and a corresponding suite of structured decompositions, to exploit latent multidimensional structure in model reduction and structured matrix approximations. The research is expected to benefit numerous other applications in science and engineering as well.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/11/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/01/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1821148</AwardID>
<Investigator>
<FirstName>Misha</FirstName>
<LastName>Kilmer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Misha Kilmer</PI_FULL_NAME>
<EmailAddress>misha.kilmer@tufts.edu</EmailAddress>
<PI_PHON>6176272005</PI_PHON>
<NSF_ID>000447484</NSF_ID>
<StartDate>08/11/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Tufts University</Name>
<CityName>Boston</CityName>
<ZipCode>021111817</ZipCode>
<PhoneNumber>6176273696</PhoneNumber>
<StreetAddress>136 Harrison Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>073134835</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF TUFTS COLLEGE INC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>073134835</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Tufts University]]></Name>
<CityName>Medford</CityName>
<StateCode>MA</StateCode>
<ZipCode>021555807</ZipCode>
<StreetAddress><![CDATA[Bromfield Pearson-503 boston]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~49129</FUND_OBLG>
<FUND_OBLG>2019~90868</FUND_OBLG>
</Award>
</rootTag>
