<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  A CVML platform for intelligent machines</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2018</AwardEffectiveDate>
<AwardExpirationDate>11/30/2018</AwardExpirationDate>
<AwardTotalIntnAmount>224996.00</AwardTotalIntnAmount>
<AwardAmount>224996</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
<PO_EMAI>patherto@nsf.gov</PO_EMAI>
<PO_PHON>7032928772</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is that it will enable small and mid-size robotics and industrial vehicle manufacturers to rapidly deploy computer vision and machine learning in their products and make their machines competitive in the global market place. The project will create a multi-vendor real-time vision stack for industrial machines that enables multiple types of machines to be developed using a uniform software interface. Combined with an app store model, such interfaces will enable a developer community to create application-specific solutions with ease, add features to machines via software and essentially create a new market. When deployed by equipment manufacturers, it will have societal impact by reducing the number of forklift and other industrial and construction machine related accidents, deaths and property damage. There are secondary benefits such as reducing the amount spent on worker compensation. The scientific impact will be the enhanced understanding of principled approaches to stereoscopic depth estimation combined with machine learning based object detectors to create integrated vision systems that function in real-time on commodity hardware.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project addresses the fact that current solutions for autonomous vehicles and machines use expensive LIDARs and RADARs in conjunction with cameras. Such systems are cost-prohibitive and ill-suited for industrial applications that operate in structured warehouse and manufacturing environments rather than highways. Manufacturers can benefit from a cheaper integrated vision-based system where all the necessary algorithms, software and hardware engineering has already been done for them. The intellectual merit of the project lies in achieving the following research goals. 1) Develop an algorithmic approach to stereoscopic depth estimation that combines quick-to-generate classic features (e.g., edges and corners) with machine learning. 2) Combine machine learning based object detectors with stereoscopic depth to create an integrated vision pipeline that functions in real-time on commodity hardware. 3) Devise methods to train the system more easily by relying on depth and motion features. 4) Address critical operational design considerations such as thermal and power management and understand requirements to maintain mechanical and structural integrity through periods of intense use.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/15/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/15/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1820469</AwardID>
<Investigator>
<FirstName>BINU</FirstName>
<LastName>MATHEW</LastName>
<PI_MID_INIT>K</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>BINU K MATHEW</PI_FULL_NAME>
<EmailAddress>BINU@SATVAD.COM</EmailAddress>
<PI_PHON>6502839142</PI_PHON>
<NSF_ID>000750972</NSF_ID>
<StartDate>06/15/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>KRAENION LABS LLC</Name>
<CityName>LOS GATOS</CityName>
<ZipCode>950330000</ZipCode>
<PhoneNumber>6502839142</PhoneNumber>
<StreetAddress>17094 LON RD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>15</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA15</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080693151</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>KRAENION LABS LLC</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[KRAENION LABS LLC]]></Name>
<CityName/>
<StateCode>CA</StateCode>
<ZipCode>950338510</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~224996</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div id="magicparlabel-336941" class="standard"> <div id="magicparlabel-337050" class="standard">Kraenion is an applied machine learning company developing a visual cortex (a "brain in a box") for machines that directly assist humans with tasks requiring interaction with the physical world. Our vision algorithms, stereo camera technology, sensors and compute hardware together deliver integrated perception solutions for low-velocity vehicles, robotics and industrial machinery. For low-velocity vehicles such as wheelchairs and warehouse equipment, our software platform solves indoor and sidewalk navigation in areas shared with pedestrians. Our solutions use stereo cameras, Computer Vision, and Machine Learning (CVML) on high-performance low-power hardware originally developed for laptops. We enable manufacturers to add perception and visual commonsense to their products without having to do years of research.</div> <div class="standard">Kraenion was awarded a Phase I National Science Foundation SBIR grant to develop a subset of the CVML platform and incorporate it into a vision guided smart wheelchair. During the Phase I period, we successfully retrofitted a wheelchair with a Kraenion designed stereo camera, control circuits and a laptop computer running our CVML software. The software is capable of detecting sidewalks and pedestrians and driving the wheelchair. As an example, it automatically pauses driving when a pedestrian crosses its path and resumes driving when the pedestrian has safely passed.</div> <div class="standard"><strong>Demo videos</strong></div> <div class="standard">Wheelchair:</div> <div class="standard"><span class="flex_url">https://youtu.be/HhU4X43iFsM</span></div> <div class="standard"><span class="flex_url">Software:&nbsp;</span></div> <div class="standard"><span class="flex_url">&nbsp;</span><span class="flex_url">https://youtu.be/nOnpJbAkxm0</span>&nbsp;</div> <div class="standard">Company details:</div> <div class="standard"><span class="flex_url">http://kraenion.com</span></div> <h2 id="magicparlabel-337055" class="section_">Scientific and Technological Impact</h2> <div id="magicparlabel-337056" class="standard">Much of the current research in AI and Machine Learning are focused on improvements to prediction accuracy. Those methods usually require very powerful computers that work in the cloud. Custom computers used in prototype autonomous cars need multiple kilowatts of electricity. There is a dearth of research that targets accuracy under strict budgets on compute performance, power dissipation and real-time performance. Low-velocity, low-cost vehicles such as wheelchairs and last mile transportation need high accuracy at compute, power, and cost budgets similar to a laptop. They need to execute all the software locally on the vehicle without causing excessive drain on the vehicle's batteries. The project explores methods for combining fast mathematically based techniques with trained neural networks to extract useful information such as ground planes, and locations of pedestrians and obstacles. These methods not only extend the application of CVML techniques to performance and power limited scenarios but also contribute to the body of knowledge on combining black-box neural network approaches with interpretable statistical approaches.</div> <div class="standard">Machine learning is critically dependent on training data. During Phase 1, we have created a small video data set for sidewalk navigation of wheelchairs and scooters. Many other projects have created video datasets for autonomous cars, but, we were unable to find any video data suitable for wheelchair navigation. Our dataset is likely the first of its kind in the world.</div> <h2 id="magicparlabel-337058" class="section_">Business Impact</h2> <div id="magicparlabel-337059" class="standard">Engineers who understand the overlap of CVML with system software and robotics are extremely rare and valuable and often not available to small manufacturers because of competition for talent from the likes of Google and major automotive companies. Our CVML platform enables small manufacturers to add perception and visual commonsense to their products without having to do years of research. The personal light vehicle market is concentrated in the USA and Europe. The electric wheelchair industry is dominated by American manufacturers. By leveraging our CVML platform, these manufacturers will be able deploy smart features using their existing U.S. based non-CVML engineering teams and continue their technological dominance in this area. We are already in talks with potential customers who see value in our platform from this human resource perspective.</div> <h2 id="magicparlabel-337060" class="section_">Societal Impact</h2> <div id="magicparlabel-337061" class="standard">According to the wheelchair research report from Statista, about 1.85% of the global population (~140M people) will need a wheelchair at some point in life. Demand for wheelchairs is increasing on account of population growth and also because of the aging of the citizenry in developed nations. Personal light vehicles such as wheelchairs and mobility scooters have not seen any significant technology improvements during the last decade. Our SBIR project is creating foundational technology for intelligent personal light vehicles that have the potential to significantly improve the quality of life of America&rsquo;s aging population. The overall social impact of improving the mobility of a significant fraction of the population cannot be over estimated. For example, a wheelchair that can automatically stow and release itself from a carrier at the rear of a car and approach a vehicle door can be of great benefit to a user who needs a walker or an elderly person without enough physical strength to maneuver the wheelchair onto the carrier.</div> <div class="standard">The broad impact of our project will also enable small and mid-size robotics and industrial vehicle manufacturers to rapidly deploy computer vision and machine learning in their products and make their machines competitive in the international market place. American companies have been a dominant force in this area and our platform will help them maintain their global lead.</div> </div><br> <p>            Last Modified: 02/01/2019<br>      Modified by: Binu&nbsp;K&nbsp;Mathew</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1820469/1820469_10550613_1549051062198_prototype--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1820469/1820469_10550613_1549051062198_prototype--rgov-800width.jpg" title="Smart Wheelchair Prototype by Kraenion"><img src="/por/images/Reports/POR/2019/1820469/1820469_10550613_1549051062198_prototype--rgov-66x44.jpg" alt="Smart Wheelchair Prototype by Kraenion"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Smart Wheelchair Prototype by Kraenion</div> <div class="imageCredit">Kraenion Labs LLC</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Binu&nbsp;K&nbsp;Mathew</div> <div class="imageTitle">Smart Wheelchair Prototype by Kraenion</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1820469/1820469_10550613_1549051177925_prototype_stereo_mount--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1820469/1820469_10550613_1549051177925_prototype_stereo_mount--rgov-800width.jpg" title="Stereo camera mounted on smart wheelchair"><img src="/por/images/Reports/POR/2019/1820469/1820469_10550613_1549051177925_prototype_stereo_mount--rgov-66x44.jpg" alt="Stereo camera mounted on smart wheelchair"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Stereo camera mounted on smart wheelchair</div> <div class="imageCredit">Kraenion Labs LLC</div> <div class="imageSubmitted">Binu&nbsp;K&nbsp;Mathew</div> <div class="imageTitle">Stereo camera mounted on smart wheelchair</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Kraenion is an applied machine learning company developing a visual cortex (a "brain in a box") for machines that directly assist humans with tasks requiring interaction with the physical world. Our vision algorithms, stereo camera technology, sensors and compute hardware together deliver integrated perception solutions for low-velocity vehicles, robotics and industrial machinery. For low-velocity vehicles such as wheelchairs and warehouse equipment, our software platform solves indoor and sidewalk navigation in areas shared with pedestrians. Our solutions use stereo cameras, Computer Vision, and Machine Learning (CVML) on high-performance low-power hardware originally developed for laptops. We enable manufacturers to add perception and visual commonsense to their products without having to do years of research. Kraenion was awarded a Phase I National Science Foundation SBIR grant to develop a subset of the CVML platform and incorporate it into a vision guided smart wheelchair. During the Phase I period, we successfully retrofitted a wheelchair with a Kraenion designed stereo camera, control circuits and a laptop computer running our CVML software. The software is capable of detecting sidewalks and pedestrians and driving the wheelchair. As an example, it automatically pauses driving when a pedestrian crosses its path and resumes driving when the pedestrian has safely passed. Demo videos Wheelchair: https://youtu.be/HhU4X43iFsM Software:   https://youtu.be/nOnpJbAkxm0  Company details: http://kraenion.com Scientific and Technological Impact Much of the current research in AI and Machine Learning are focused on improvements to prediction accuracy. Those methods usually require very powerful computers that work in the cloud. Custom computers used in prototype autonomous cars need multiple kilowatts of electricity. There is a dearth of research that targets accuracy under strict budgets on compute performance, power dissipation and real-time performance. Low-velocity, low-cost vehicles such as wheelchairs and last mile transportation need high accuracy at compute, power, and cost budgets similar to a laptop. They need to execute all the software locally on the vehicle without causing excessive drain on the vehicle's batteries. The project explores methods for combining fast mathematically based techniques with trained neural networks to extract useful information such as ground planes, and locations of pedestrians and obstacles. These methods not only extend the application of CVML techniques to performance and power limited scenarios but also contribute to the body of knowledge on combining black-box neural network approaches with interpretable statistical approaches. Machine learning is critically dependent on training data. During Phase 1, we have created a small video data set for sidewalk navigation of wheelchairs and scooters. Many other projects have created video datasets for autonomous cars, but, we were unable to find any video data suitable for wheelchair navigation. Our dataset is likely the first of its kind in the world. Business Impact Engineers who understand the overlap of CVML with system software and robotics are extremely rare and valuable and often not available to small manufacturers because of competition for talent from the likes of Google and major automotive companies. Our CVML platform enables small manufacturers to add perception and visual commonsense to their products without having to do years of research. The personal light vehicle market is concentrated in the USA and Europe. The electric wheelchair industry is dominated by American manufacturers. By leveraging our CVML platform, these manufacturers will be able deploy smart features using their existing U.S. based non-CVML engineering teams and continue their technological dominance in this area. We are already in talks with potential customers who see value in our platform from this human resource perspective. Societal Impact According to the wheelchair research report from Statista, about 1.85% of the global population (~140M people) will need a wheelchair at some point in life. Demand for wheelchairs is increasing on account of population growth and also because of the aging of the citizenry in developed nations. Personal light vehicles such as wheelchairs and mobility scooters have not seen any significant technology improvements during the last decade. Our SBIR project is creating foundational technology for intelligent personal light vehicles that have the potential to significantly improve the quality of life of America?s aging population. The overall social impact of improving the mobility of a significant fraction of the population cannot be over estimated. For example, a wheelchair that can automatically stow and release itself from a carrier at the rear of a car and approach a vehicle door can be of great benefit to a user who needs a walker or an elderly person without enough physical strength to maneuver the wheelchair onto the carrier. The broad impact of our project will also enable small and mid-size robotics and industrial vehicle manufacturers to rapidly deploy computer vision and machine learning in their products and make their machines competitive in the international market place. American companies have been a dominant force in this area and our platform will help them maintain their global lead.        Last Modified: 02/01/2019       Submitted by: Binu K Mathew]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
