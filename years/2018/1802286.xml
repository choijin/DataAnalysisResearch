<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: The Moral Foundations of the Big Data Economy</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2018</AwardEffectiveDate>
<AwardExpirationDate>02/28/2019</AwardExpirationDate>
<AwardTotalIntnAmount>11999.00</AwardTotalIntnAmount>
<AwardAmount>11999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Toby Parcel</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Increasingly the United States is a big data economy, a society in which corporations gather and analyze massive amounts of personal information to predict how individuals will behave so that they can more profitably price goods and services and allocate economic resources like insurance, credit, and jobs. This project addresses the question: What ideas about fairness underpin an economic system that uses data about individuals and their past behavior to determine who gets what going forward? Economic sociologists have long studied how markets and the people who decide their contours, like business leaders and regulators, institutionalize certain understandings of good and bad, of legitimate and inappropriate. Over time, these ideas about how markets should operate become taken-for-granted assumptions that seem natural and obvious, but when market practices are new, these ideas are not yet settled on. By studying the big data economy in its early years, this project seeks to capture how certain ideas about market fairness are becoming accepted?and others are being left aside. &lt;br/&gt;&lt;br/&gt;To understand these dynamics, the project focuses on the case of car insurance pricing and leverages a series of U.S. policy debates to study how market actors?including companies, regulators, and consumers?morally frame the use of personal data in insurance pricing. The project also studies how different moral frames enable or deflect the use of various types of information, such as credit scores, social media posts, and real-time driving data. The project draws from policy and industry documents, in-depth interviews, and ethnographic observations at insurance conferences to analyze how different ways of construing fairness lead to different business practices and policy outcomes. To complement these data, the project includes a survey of American consumers to understand the moral intuitions of the people whose lives are affected by these policies and practices. With this analysis, the project contributes to economic sociology?s morals and markets literature and burgeoning efforts to understand the practices of mass data collection, predictive analytics, and algorithmic decision-making, which increasingly give markets their shape.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/14/2018</MinAmdLetterDate>
<MaxAmdLetterDate>03/14/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1802286</AwardID>
<Investigator>
<FirstName>Frank</FirstName>
<LastName>Dobbin</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Frank R Dobbin</PI_FULL_NAME>
<EmailAddress>frank_dobbin@harvard.edu</EmailAddress>
<PI_PHON>6174969091</PI_PHON>
<NSF_ID>000100891</NSF_ID>
<StartDate>03/14/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Barbara</FirstName>
<LastName>Kiviat</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Barbara Kiviat</PI_FULL_NAME>
<EmailAddress>barbarakiviat@fas.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000758395</NSF_ID>
<StartDate>03/14/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[HARVARD UNIVERSITY, DEPT. OF SOCIOLOGY]]></Name>
<CityName>CAMBRIDGE</CityName>
<StateCode>MA</StateCode>
<ZipCode>021385369</ZipCode>
<StreetAddress><![CDATA[33 KIRKLAND ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1331</Code>
<Text>Sociology</Text>
</ProgramElement>
<ProgramReference>
<Code>1331</Code>
<Text>SOCIOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~11999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Companies increasingly leverage massive amounts of personal data to mathematically predict how individuals will behave in order to decide which people to sell to and at what price. This research set out to understand how ideas about fairness justify and challenge these new market arrangements. Co-principal investigator Barbara Kiviat conducted a case study of the U.S. car insurance industry, which has long used personal data to predict how individuals will behave (e.g., whether they will file claims) and then price in line with those expectations. Even though the use of personal, predictive data in car insurance is well-established, the past 25 years have seen a series of public policy debates over the use of certain types of data and prediction. This contestation reveals underlying--and conflicting--ideas about market fairness. The research included: analyzing more than 12,000 pages of documents produced during policy debates about insurers' use of credit scores and other consumer data; interviewing 50 key actors, including insurance regulators and members of industry; observing meetings of the National Association of Insurance Commissioners; and conducting a nationally representative survey to gauge how American consumers evaluate the fairness of data use.<br /><br />In terms of intellectual merit, this research was designed to advance the sociological literature on the moral foundations of markets. This research did so by showing that mathematical prediction functions as a moral justification partly because it obscures the events and circumstances that lead people to show up in the data the way they do. Yet it is precisely this social context behind the numbers that policymakers and others work to recover as they mobilize a competing framework--one based on notions of moral desert--in order to determine if the market is treating certain people unfairly. These competing understandings of fairness subsequently shape law and regulation. This research also provided an account of how moral contestation arises in markets by showing how decidedly amoral concerns, such as different understandings of commonly used terms, can lead to dramatically different views on whether a market practice is good or bad. This research further demonstrated how the idea that personal data are about specific individuals helps sustain arguments about pricing fairness, even though prediction mathematically relies on comparing people to one another. Finally, this research showed that American consumers make strong moral distinctions among the types of data companies use.<br /><br />In terms of broader impact, this research suggests that corporate data use may be contentious in other market settings partly because of the sorts of information algorithmic predictions ignore. Algorithms are "black boxes" not only because it's tough to see how the math works, but also because they impede the causal intuition people rely on to decide if individuals are getting what they deserve. Kiviat is now sharing the results of this research in both academic and non-academic settings. Members of industry and insurance regulators are especially interested in the results of the nationally representative survey of American consumers, and by the summer of 2019, Kiviat will have presented findings to both audiences.</p><br> <p>            Last Modified: 04/12/2019<br>      Modified by: Barbara&nbsp;Kiviat</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Companies increasingly leverage massive amounts of personal data to mathematically predict how individuals will behave in order to decide which people to sell to and at what price. This research set out to understand how ideas about fairness justify and challenge these new market arrangements. Co-principal investigator Barbara Kiviat conducted a case study of the U.S. car insurance industry, which has long used personal data to predict how individuals will behave (e.g., whether they will file claims) and then price in line with those expectations. Even though the use of personal, predictive data in car insurance is well-established, the past 25 years have seen a series of public policy debates over the use of certain types of data and prediction. This contestation reveals underlying--and conflicting--ideas about market fairness. The research included: analyzing more than 12,000 pages of documents produced during policy debates about insurers' use of credit scores and other consumer data; interviewing 50 key actors, including insurance regulators and members of industry; observing meetings of the National Association of Insurance Commissioners; and conducting a nationally representative survey to gauge how American consumers evaluate the fairness of data use.  In terms of intellectual merit, this research was designed to advance the sociological literature on the moral foundations of markets. This research did so by showing that mathematical prediction functions as a moral justification partly because it obscures the events and circumstances that lead people to show up in the data the way they do. Yet it is precisely this social context behind the numbers that policymakers and others work to recover as they mobilize a competing framework--one based on notions of moral desert--in order to determine if the market is treating certain people unfairly. These competing understandings of fairness subsequently shape law and regulation. This research also provided an account of how moral contestation arises in markets by showing how decidedly amoral concerns, such as different understandings of commonly used terms, can lead to dramatically different views on whether a market practice is good or bad. This research further demonstrated how the idea that personal data are about specific individuals helps sustain arguments about pricing fairness, even though prediction mathematically relies on comparing people to one another. Finally, this research showed that American consumers make strong moral distinctions among the types of data companies use.  In terms of broader impact, this research suggests that corporate data use may be contentious in other market settings partly because of the sorts of information algorithmic predictions ignore. Algorithms are "black boxes" not only because it's tough to see how the math works, but also because they impede the causal intuition people rely on to decide if individuals are getting what they deserve. Kiviat is now sharing the results of this research in both academic and non-academic settings. Members of industry and insurance regulators are especially interested in the results of the nationally representative survey of American consumers, and by the summer of 2019, Kiviat will have presented findings to both audiences.       Last Modified: 04/12/2019       Submitted by: Barbara Kiviat]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
