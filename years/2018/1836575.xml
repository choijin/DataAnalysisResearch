<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Collaborative Research: An Unified Learnable Roadmap for Sequential Decision Making in Relational Domains</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>12/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>100000.00</AwardTotalIntnAmount>
<AwardAmount>100000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project seeks to develop new algorithms and data structures for learning and planning in situations where the environment is represented with a set of relations between objects. Relational representations capture interactions between objects in a succinct and easily interpretable representation. Examples of domains that are well-suited to relational representations includes intelligent drones assisting soldiers, activities in a supply chain management, communication and friendship connections in a social network, and tracking individuals and activities in video.  Most recent advances in machine learning and planning, such as so-called "deep neural networks", however, employ simple "flat" representations, where the state of the world is an uninterpreted string of bits.  This project will make machine learning and planning methods easier to use and more robust by generalizing them so that they explicitly work with relational models and data.   The methods, theory, and data resulting from this proposal will impact the scientific community in several positive ways and will be made publicly available through an appropriate website. The research will be disseminated through refereed journals and conference proceedings and made available to researchers. Code for the proposed algorithms and descriptions of new benchmark problems will also be made publicly available. The investigators will work on organizing workshops and tutorials based on the challenges and findings arising from this project. &lt;br/&gt;&lt;br/&gt;Many special purpose solutions have been developed to address small parts of these problems, but there are no &lt;br/&gt;general purpose tools that harness recent advances in machine learning to tackle this family of problems. This proposal seeks to develop such tools, drawing upon the investigators' prior experience in learning relational regression trees and experience in value function approximation for reinforcement learning. In addition, this project seeks to build a bridge between recent advances in deep learning, which generally has not been compatible with relational representations, and recent advances in relational learning.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/18/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1836575</AwardID>
<Investigator>
<FirstName>Ronald</FirstName>
<LastName>Parr</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ronald Parr</PI_FULL_NAME>
<EmailAddress>parr@cs.duke.edu</EmailAddress>
<PI_PHON>9196606537</PI_PHON>
<NSF_ID>000188767</NSF_ID>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Duke University</Name>
<CityName>Durham</CityName>
<ZipCode>277054010</ZipCode>
<PhoneNumber>9196843030</PhoneNumber>
<StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
<StreetAddress2><![CDATA[Erwin Square]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>044387793</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>DUKE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>044387793</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Duke University]]></Name>
<CityName>Durham</CityName>
<StateCode>NC</StateCode>
<ZipCode>277054010</ZipCode>
<StreetAddress><![CDATA[LSRC / Box 90129]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~100000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="p1">The primary objective of this project was the development of algorithms for relational reinforcement learning. The relational term refers to a description of the world based upon objects and relationships between those objects, such as &ldquo;on(box, floor)&rdquo; or &ldquo;studied(student1, Spanish)&rdquo;. In these examples &ldquo;on&rdquo; and &ldquo;studied&rdquo; are the relations. Reinforcement learning refers to a technique for learning to act (approximately) optimally in an environment through trial-and-error style interactions with the environment.</p> <p class="p2">&nbsp;</p> <p class="p1">Reinforcement learning has been combined with deep learning to produce impressive results in some robotics and game-playing domains. Like most deep learning methods, however, deep reinforcement learning tends to produce results that are not human-interpretable. Moreover, it is difficult to find principled ways to add human knowledge to these systems.</p> <p class="p2">&nbsp;</p> <p class="p1">This project sought to bring some of the power of deep reinforcement learning techniques to reinforcement learning with relational representations, thereby achieving strong machine learning results that are more easily understood and more easily seeded with human knowledge.<span>&nbsp;</span></p> <p class="p2">&nbsp;</p> <p class="p1">Some success was achieved in combining function approximation with relational methods for reinforcement learning, leading to an abstract in the 17th International Conference on Knowledge Representation and Reasoning (KR 2020). The new method that was developed was simple and easy to implement, and achieved experimental results in test domains that were at least as good as previously proposed methods that were more complicated. Limitations of the new approach are that it does not take full advantage of deep learning, using function approximation that is closer to simpler, linear function approximation techniques. Since it does not use the full power of deep learning, it also does not dramatically expand the scale of problems that can be solved with relational reinforcement learning. <span>&nbsp;</span></p> <p class="p2">&nbsp;</p> <p class="p1">The investigators plan to apply lessons learned from the progress made in this project to develop more sophisticated approaches that will be explored in future grant proposals.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/04/2021<br>      Modified by: Ronald&nbsp;Parr</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[The primary objective of this project was the development of algorithms for relational reinforcement learning. The relational term refers to a description of the world based upon objects and relationships between those objects, such as "on(box, floor)" or "studied(student1, Spanish)". In these examples "on" and "studied" are the relations. Reinforcement learning refers to a technique for learning to act (approximately) optimally in an environment through trial-and-error style interactions with the environment.   Reinforcement learning has been combined with deep learning to produce impressive results in some robotics and game-playing domains. Like most deep learning methods, however, deep reinforcement learning tends to produce results that are not human-interpretable. Moreover, it is difficult to find principled ways to add human knowledge to these systems.   This project sought to bring some of the power of deep reinforcement learning techniques to reinforcement learning with relational representations, thereby achieving strong machine learning results that are more easily understood and more easily seeded with human knowledge.    Some success was achieved in combining function approximation with relational methods for reinforcement learning, leading to an abstract in the 17th International Conference on Knowledge Representation and Reasoning (KR 2020). The new method that was developed was simple and easy to implement, and achieved experimental results in test domains that were at least as good as previously proposed methods that were more complicated. Limitations of the new approach are that it does not take full advantage of deep learning, using function approximation that is closer to simpler, linear function approximation techniques. Since it does not use the full power of deep learning, it also does not dramatically expand the scale of problems that can be solved with relational reinforcement learning.     The investigators plan to apply lessons learned from the progress made in this project to develop more sophisticated approaches that will be explored in future grant proposals.          Last Modified: 08/04/2021       Submitted by: Ronald Parr]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
