<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CDS&amp;E: Efficient and Robust Recurrent Neural Networks</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>200000.00</AwardTotalIntnAmount>
<AwardAmount>200000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Christopher Stark</SignBlockName>
<PO_EMAI>cstark@nsf.gov</PO_EMAI>
<PO_PHON>7032924869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Deep neural networks have emerged over the last decade as one of the most powerful machine learning methods. Recurrent neural networks (RNNs) are special neural networks that are designed to efficiently model sequential data such as speech and text data by exploiting temporal connections within a sequence and handling varying sequence lengths in a dataset. While RNN and its variants have found success in many real-world applications, there are various issues that make them difficult to use in practice. This project will systematically address some of these difficulties and develop an efficient and robust RNN. Computer codes derived in this project will be made freely available. The research results will have applications in a variety of areas involving sequential data learning, including computer vision, speech recognition, natural language processing, financial data analysis, and bioinformatics.&lt;br/&gt;&lt;br/&gt;As in other neural networks, training of RNNs typically involves some variants of gradient descent optimization, which is prone to so-called vanishing or exploding gradient problems. Regularization of RNNs, which refers to techniques used to prevent the model from overfitting the raining data and hence poor generalization to new data, is also challenging. The current preferred RNN architectures such as the Long-Short-Term-Memory networks have highly complex structures with numerous additional interacting elements that are not easy to understand. This project develops an RNN that extends a recent orthogonal/unitary RNNs to more effectively model long and short term dependency of sequential data. Through an indirect parametrization of recurrent matrix, dropout regularization techniques will be developed. The network developed in this project will retain the simplicity and efficiency of basic RNNs but enhance some key capabilities for robust applications. In particular, the project will include a study of applications of RNNs to some bioinformatics problems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/14/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1821144</AwardID>
<Investigator>
<FirstName>Qiang</FirstName>
<LastName>Ye</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qiang Ye</PI_FULL_NAME>
<EmailAddress>qye3@uky.edu</EmailAddress>
<PI_PHON>8592574653</PI_PHON>
<NSF_ID>000482987</NSF_ID>
<StartDate>06/14/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Kentucky Research Foundation</Name>
<CityName>Lexington</CityName>
<ZipCode>405260001</ZipCode>
<PhoneNumber>8592579420</PhoneNumber>
<StreetAddress>109 Kinkead Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<StateCode>KY</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>KY06</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>939017877</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF KENTUCKY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>007400724</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Kentucky Research Foundation]]></Name>
<CityName>Lexington</CityName>
<StateCode>KY</StateCode>
<ZipCode>405260001</ZipCode>
<StreetAddress><![CDATA[500 S Limestone 109 Kinkead Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Kentucky</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>KY06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8069</Code>
<Text>CDS&amp;E-MSS</Text>
</ProgramElement>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9263</Code>
<Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~200000</FUND_OBLG>
</Award>
</rootTag>
