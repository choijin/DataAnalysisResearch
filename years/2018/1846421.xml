<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:  Stein Variational Gradient Descent: A New Foundation for Inference</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499766.00</AwardTotalIntnAmount>
<AwardAmount>294840</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Rebecca Hwa</SignBlockName>
<PO_EMAI>rhwa@nsf.gov</PO_EMAI>
<PO_PHON>7032927148</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In recent years, machine learning (ML) and artificial intelligence (AI) have achieved remarkable progress. Smart computer programs can now categorize images better than humans, beat the world champion at Go, and make intelligent recommendations in areas from health care to education. Under the hood, many of these technologies are made possible by the idea of using highly flexible and structured probabilistic models to express and reason with complex phenomena. Meanwhile, probabilistic models required for modern machine learning systems are becoming increasingly complex, and the ability to compute probabilities efficiently becomes one of the main bottlenecks of modern learning systems. The goal of this project is to develop a new theoretical and algorithmic framework of efficient and approximate computation of probabilities for highly complex probabilistic models. This project provides research opportunities for undergraduates and it also develops educational modules for outreach activities to high school students and undergraduates.&lt;br/&gt;&lt;br/&gt;Markov chain Monte Carlo (MCMC) and variational inference (VI) have been the two major types of approximate inference algorithms that dominate the literature. However, both of them have their own critical weaknesses. MCMC is accurate but suffers from slow convergence; VI is typically faster but introduces deterministic errors and lacks theoretical guarantees.  This project aims to introduce a new Stein variational paradigm for approximate inference that integrates the advantages of MCMC and VI, enabling algorithms that are as flexible and accurate as MCMC and as fast as VI. The key idea is to directly optimize a non-parametric particle-based representation to fit intractable distributions with fast deterministic gradient-based updates, which is made possible by integrating and generalizing key mathematical tools from Stein's method, optimal transport and interacting particle systems. A basic algorithm derived from this framework, called Stein variational gradient descent (SVGD),  has already been found to be a powerful tool in a range of applications. This project extends this initial success to a higher level, by (1) systematically investigating basic theoretical problems, (2) developing more efficient and practical algorithms and software,  and (3) demonstrating its power in various interdisciplinary applications, including reinforcement learning and molecule dynamics.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/21/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1846421</AwardID>
<Investigator>
<FirstName>Qiang</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Qiang Liu</PI_FULL_NAME>
<EmailAddress>lqiang@cs.utexas.edu</EmailAddress>
<PI_PHON>9492323238</PI_PHON>
<NSF_ID>000701870</NSF_ID>
<StartDate>02/21/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121757</ZipCode>
<StreetAddress><![CDATA[2317 Speedway, D9500]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~96650</FUND_OBLG>
<FUND_OBLG>2020~98269</FUND_OBLG>
<FUND_OBLG>2021~99921</FUND_OBLG>
</Award>
</rootTag>
