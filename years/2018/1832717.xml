<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Workshop on Artificial Intelligence and the "Barrier of Meaning"</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>05/01/2018</AwardEffectiveDate>
<AwardExpirationDate>04/30/2019</AwardExpirationDate>
<AwardTotalIntnAmount>20088.00</AwardTotalIntnAmount>
<AwardAmount>20088</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
<PO_EMAI>jdonlon@nsf.gov</PO_EMAI>
<PO_PHON>7032928074</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This workshop brings together eminent scholars in the fields of computer science, psychology, biology, neuroscience, and others to address the topic of "understanding" in artificial intelligence.  In this activity, participants will consider what it would mean for advanced computer systems to possess human-like understanding, explore how necessary it is for intelligent systems to exhibit such understanding, and discuss approaches to imbuing these systems with such a capability.  Engagement of a multidisciplinary community will develop new and actionable insight into how we define, design, implement, and control complex systems that overcome this barrier of meaning.  The workshop will likely also lead to outcomes and follow-on activities to benefit AI education and public awareness regarding the state of current artificial intelligence, including its limitations and potential vulnerabilities.&lt;br/&gt;&lt;br/&gt;The approach in this workshop is to explore how complex systems extract meaning from the information they encounter. Workshop participants will engage questions about the function and mechanisms of "understanding" or "extracting meaning" in complex systems across many disciplines, and focus specifically on the relevance of human-like understanding for creating artificial intelligence systems that are reliable, adaptable to novel situations, and robust against adversarial attacks.  Understanding the nature and necessity of understanding remains among the deepest intellectual challenges in AI research. Workshop discussions will be aimed at clarifying common questions and identifying possible novel pathways to answering these questions. Organizers will publish both technical and general-readership summaries communicating the results of the workshop discussions concerning the notions of understanding or meaning as phenomena in diverse disciplines, and how these phenomena relate to, or enable, the robustness that will be needed for safe and trustworthy AI in the real world.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/13/2018</MinAmdLetterDate>
<MaxAmdLetterDate>04/13/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1832717</AwardID>
<Investigator>
<FirstName>Melanie</FirstName>
<LastName>Mitchell</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Melanie Mitchell</PI_FULL_NAME>
<EmailAddress>mm@santafe.edu</EmailAddress>
<PI_PHON>9712055307</PI_PHON>
<NSF_ID>000461779</NSF_ID>
<StartDate>04/13/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Santa Fe Institute</Name>
<CityName>SANTA FE</CityName>
<ZipCode>875018943</ZipCode>
<PhoneNumber>5059462727</PhoneNumber>
<StreetAddress>1399 HYDE PARK ROAD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<StateCode>NM</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NM03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>178044996</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>SANTA FE INSTITUTE OF SCIENCE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Santa Fe Institute]]></Name>
<CityName/>
<StateCode>NM</StateCode>
<ZipCode>875018943</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Mexico</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NM03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7556</Code>
<Text>CONFERENCE AND WORKSHOPS</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~20088</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p class="normal">In 1986, the mathematician and philosopher Gian-Carlo Rota wrote, &ldquo;I wonder whether or when artificial intelligence will ever crash the barrier of meaning.&rdquo; Here, the phrase &ldquo;barrier of meaning&rdquo; refers to a belief about humans versus machines: humans are able to &ldquo;actually understand&rdquo; the situations they encounter, whereas even the most advanced of today&rsquo;s AI systems do not yet have a human-like understanding of the concepts that we are trying to teach them.&nbsp; This lack of understanding may underlie current limitations on the generality and reliability of modern AI systems.&nbsp; In October 2018, the Santa Fe Institute held a three-day workshop, organized by Melanie Mitchell, Barbara Grosz, and Dawn Song, called &ldquo;Artificial Intelligence and the Barrier of Meaning&rdquo;.&nbsp; Thirty participants from a diverse set of disciplines&mdash;AI, robotics, cognitive and developmental psychology, animal behavior, information theory, and philosophy, among others&mdash;met to discuss questions related to the notion of &ldquo;understanding&rdquo; in living systems and the prospect for such understanding in machines. &nbsp;&nbsp;</p> <p class="normal">The questions posed by the organizers at the outset were the following:</p> <p class="normal">&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; By what mechanisms do humans and other natural information-driven systems extract meaning from data or experience?&nbsp; Can insights from such systems be used to improve AI?</p> <p class="normal">&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To what extent do current-day AI systems need to <em>understand</em> the situations they deal with in order to perform reliably, particularly in situations outside their training regimes?</p> &nbsp; <p class="normal">&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To what extent do systems need to understand in order to be able to <em>explain</em> their decisions and predictions?</p> &nbsp; <p class="normal">&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Does a lack of understanding make data-driven AI systems (e.g., deep networks) susceptible to adversarial examples?&nbsp; Is there a way to defend against such attacks without imbuing such systems with human-like understanding?</p> <p class="normal">&#9679;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; How do we determine if a system is actually understanding?</p> <p>The workshop talks and discussions were wide-ranging.&nbsp; The main focus of discussion was on developing a list of criteria or &ldquo;correlates&rdquo; for understanding in living systems and machines.&nbsp; In addition we discussed the predominate &ldquo;framing&rdquo; of the learning problem in modern AI, and whether that framing was misguided.&nbsp; Finally, we discussed the research methodology of using benchmark datasets as drivers of research in AI, and the extent to which this practice was driving the field away from developing systems that have the understanding needed for robust and reliable AI.&nbsp;This topic is becoming increasingly important in society as AI systems are increasingly broadly deployed.&nbsp;</p><br> <p>            Last Modified: 08/19/2019<br>      Modified by: Melanie&nbsp;Mitchell</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[In 1986, the mathematician and philosopher Gian-Carlo Rota wrote, "I wonder whether or when artificial intelligence will ever crash the barrier of meaning." Here, the phrase "barrier of meaning" refers to a belief about humans versus machines: humans are able to "actually understand" the situations they encounter, whereas even the most advanced of today?s AI systems do not yet have a human-like understanding of the concepts that we are trying to teach them.  This lack of understanding may underlie current limitations on the generality and reliability of modern AI systems.  In October 2018, the Santa Fe Institute held a three-day workshop, organized by Melanie Mitchell, Barbara Grosz, and Dawn Song, called "Artificial Intelligence and the Barrier of Meaning".  Thirty participants from a diverse set of disciplines&mdash;AI, robotics, cognitive and developmental psychology, animal behavior, information theory, and philosophy, among others&mdash;met to discuss questions related to the notion of "understanding" in living systems and the prospect for such understanding in machines.    The questions posed by the organizers at the outset were the following: &#9679;      By what mechanisms do humans and other natural information-driven systems extract meaning from data or experience?  Can insights from such systems be used to improve AI? &#9679;      To what extent do current-day AI systems need to understand the situations they deal with in order to perform reliably, particularly in situations outside their training regimes?   &#9679;      To what extent do systems need to understand in order to be able to explain their decisions and predictions?   &#9679;      Does a lack of understanding make data-driven AI systems (e.g., deep networks) susceptible to adversarial examples?  Is there a way to defend against such attacks without imbuing such systems with human-like understanding? &#9679;      How do we determine if a system is actually understanding?  The workshop talks and discussions were wide-ranging.  The main focus of discussion was on developing a list of criteria or "correlates" for understanding in living systems and machines.  In addition we discussed the predominate "framing" of the learning problem in modern AI, and whether that framing was misguided.  Finally, we discussed the research methodology of using benchmark datasets as drivers of research in AI, and the extent to which this practice was driving the field away from developing systems that have the understanding needed for robust and reliable AI. This topic is becoming increasingly important in society as AI systems are increasingly broadly deployed.        Last Modified: 08/19/2019       Submitted by: Melanie Mitchell]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
