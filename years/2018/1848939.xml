<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Visual feature perception during dynamic spatial attention and distraction</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>450265.00</AwardTotalIntnAmount>
<AwardAmount>450265</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Michael Hout</SignBlockName>
<PO_EMAI>mhout@nsf.gov</PO_EMAI>
<PO_PHON>7032922163</PO_PHON>
</ProgramOfficer>
<AbstractNarration>How does our visual system make sense of the world around us? Our brains construct incredibly rich perceptual experiences from the rawest of visual inputs: patterns of light on the eye's retina. A major challenge is that the environment presents more information than our visual system can fully process at a time, so we rely on the mechanisms of attention to prioritize the most relevant information. Attention and perception are vital cognitive processes that affect every aspect of our daily functioning. Understanding how these processes typically work - and when we are susceptible to perceptual errors and distortions - has critical repercussions for both the healthy visual system and various disorders, along with broad-reaching applications ranging from maximizing human behavior to development of artificial intelligence and technology. The project's education component will increase STEM opportunities for underrepresented racial and ethnic groups, enhance undergraduate education, and offer community outreach. &lt;br/&gt;&lt;br/&gt;This proposal outlines a three-year integrated research and education plan addressing how visual feature perception is altered during dynamic spatial attention and distraction. The proposal investigates a fundamental challenge for our visual systems: How do we successfully integrate information about 'what' an object is with 'where' it is? While the binding process is challenging enough on its own, it becomes particularly crucial during dynamic vision and cognition, where there are often multiple objects or locations of interest in the environment and spatial attention is constantly shifting. Using a paradigm recently developed by PI Golomb, we test the hypothesis that unstable spatial attention can cause errors in feature and object perception. In Aim 1, we focus on how visual feature perception might be altered during conditions of distraction, in collaboration with co-PI Leber, an expert in attentional control and distraction. In Aim 2, we expand in an even more fundamental direction, asking how different types of dynamic spatial attention might impact object integration for multi-feature objects. The experiments include a combination of perceptual feature reports, probabilistic mixture modeling, EEG alpha decoding, eye-tracking, and reward-based manipulations. This innovative and novel approach strives to advance our understanding of how we achieve stable and integrated visual perception, especially under conditions of dynamic attention and distraction.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/17/2019</MinAmdLetterDate>
<MaxAmdLetterDate>09/11/2019</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1848939</AwardID>
<Investigator>
<FirstName>Andrew</FirstName>
<LastName>Leber</LastName>
<PI_MID_INIT>B</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Andrew B Leber</PI_FULL_NAME>
<EmailAddress>leber.30@osu.edu</EmailAddress>
<PI_PHON>6146881372</PI_PHON>
<NSF_ID>000521759</NSF_ID>
<StartDate>06/17/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Julie</FirstName>
<LastName>Golomb</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Julie D Golomb</PI_FULL_NAME>
<EmailAddress>golomb.9@osu.edu</EmailAddress>
<PI_PHON>6146881445</PI_PHON>
<NSF_ID>000675077</NSF_ID>
<StartDate>06/17/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[The Ohio State University]]></Name>
<CityName>Columbus</CityName>
<StateCode>OH</StateCode>
<ZipCode>432101351</ZipCode>
<StreetAddress><![CDATA[1835 Neil Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~450265</FUND_OBLG>
</Award>
</rootTag>
