<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Teachers are the Learners: Providing Automated Feedback on Classroom Inter-Personal Dynamics</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>749969.00</AwardTotalIntnAmount>
<AwardAmount>775969</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Amy Baylor</SignBlockName>
<PO_EMAI>abaylor@nsf.gov</PO_EMAI>
<PO_PHON>7032925126</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The quality of teacher-student interactions in school classrooms both predicts and impacts students' learning outcomes. Training teachers to perceive subtle interactions and interpersonal classroom dynamics more accurately can help them to implement more effective interactions in their own classrooms. Contemporary methods of training teachers to understand classroom interactions are based mostly on watching classroom observation videos of other teachers, which have been annotated for different dimensions ("positive climate", "teacher sensitivity", etc.). Only rarely do teachers receive personalized feedback on their own classroom interactions captured in video, and when they do, it is sparse - typically one comment for every 15-minute video segment without any details. This project will automate classroom observations using a system called Automatic Classroom Observation Recognition neural Network (ACORN). This system will integrate multimodal features consisting of facial expression, eye gaze, auditory emotion, speech, and language in order to assess classroom dynamics automatically. As a complement to ACORN, the researchers will also develop a Classroom Observation Interactive Learning System (COILS) that trains teachers to perceive classroom dynamics more precisely.&lt;br/&gt;&lt;br/&gt;ACORN will be trained and tested on two coded classroom observation datasets of hundreds of pre-school and elementary school teachers across the USA. Moreover, based on the ACORN prototype, COILS will be developed. COILS will then be evaluated in a study on 50 pre-service teachers. The research questions are: 1) Will the observation training with COILS help them perceive classroom interactions more precisely? 2) How well will ACORN perform vs human coders? and 3) How well can the machine  learned automated subjective activity perform in the new domain of classroom dynamics?  The researchers will also explore different machine learning computational architectures that can utilize modest-sized data sets to accurately learn from multi-modal data. If successful, both ACORN and COILS can be extended from pre-service teachers to train in-service teachers in understanding classroom dynamics to improve their teaching.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/29/2018</MinAmdLetterDate>
<MaxAmdLetterDate>05/19/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1822768</AwardID>
<Investigator>
<FirstName>Erin</FirstName>
<LastName>Ottmar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Erin Ottmar</PI_FULL_NAME>
<EmailAddress>erottmar@wpi.edu</EmailAddress>
<PI_PHON>5088316096</PI_PHON>
<NSF_ID>000661763</NSF_ID>
<StartDate>07/29/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jacob</FirstName>
<LastName>Whitehill</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jacob Whitehill</PI_FULL_NAME>
<EmailAddress>jrwhitehill@wpi.edu</EmailAddress>
<PI_PHON>5088315357</PI_PHON>
<NSF_ID>000709937</NSF_ID>
<StartDate>07/29/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Lane</FirstName>
<LastName>Harrison</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Lane Harrison</PI_FULL_NAME>
<EmailAddress>ltharrison@wpi.edu</EmailAddress>
<PI_PHON>9802008363</PI_PHON>
<NSF_ID>000710896</NSF_ID>
<StartDate>07/29/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Worcester Polytechnic Institute</Name>
<CityName>WORCESTER</CityName>
<ZipCode>016092247</ZipCode>
<PhoneNumber>5088315000</PhoneNumber>
<StreetAddress>100 INSTITUTE RD</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA02</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041508581</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>WORCESTER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041508581</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Worcester Polytechnic Institute]]></Name>
<CityName>Worcester</CityName>
<StateCode>MA</StateCode>
<ZipCode>016092280</ZipCode>
<StreetAddress><![CDATA[100 Institute Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>02</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA02</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7980</Code>
<Text>ECR-EHR Core Research</Text>
</ProgramElement>
<ProgramElement>
<Code>8020</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramReference>
<ProgramReference>
<Code>7218</Code>
<Text>RET SUPP-Res Exp for Tchr Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0418</Code>
<Name>NSF Education &amp; Human Resource</Name>
<APP_SYMB_ID>040106</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~749969</FUND_OBLG>
<FUND_OBLG>2020~10000</FUND_OBLG>
<FUND_OBLG>2021~16000</FUND_OBLG>
</Award>
</rootTag>
