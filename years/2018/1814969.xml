<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: A Scalable Architecture for Ubiquitous Parallelism</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2022</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yuanyuan Yang</SignBlockName>
<PO_EMAI>yyang@nsf.gov</PO_EMAI>
<PO_PHON>7032928067</PO_PHON>
</ProgramOfficer>
<AbstractNarration>With cost-performance gains predicted by Moore's Law slowing down, future computer systems will need to harness increasing amounts of parallelism to improve performance. Achieving this goal requires new techniques to make massive parallelism practical, as current multicore systems fall short of this goal: they squander most of the parallelism available in applications and are exceedingly hard to program. To address these challenges, this project is investigating a novel parallel architecture that efficiently scales to thousands of cores and is almost as easy to program as sequential systems. It achieves these benefits by exploiting ordered parallelism, which is general and abundant but is hard to mine in current systems. The technologies being investigated will make future parallel systems more versatile, scalable, and easier to program. These techniques will especially benefit hard-to-parallelize irregular applications that are key in emerging domains, such as graph analytics, machine learning, and in-memory databases. The prototyping efforts will bring the benefits of ordered parallelism to existing systems. Finally, the infrastructure developed as part of this project will be released publicly, enabling others to build on the results of this work.&lt;br/&gt;&lt;br/&gt;Towards the goal of efficiently parallelizing the vast majority of applications while retaining the programming simplicity of sequential systems, this project is investigating and developing the following techniques: (1) distributed data-centric execution, which scales fine-grained ordered parallelism and speculative execution to rack-scale systems with tens of thousands of cores; (2) an expressive execution model that supports seamless combinations of speculative and non-speculative tasks, improving efficiency and parallelism; (3) adaptive speculation and resource management techniques that avoid performance pathologies, reduce wasted work, and make more efficient use of this novel architecture; and (4) an FPGA-based prototype of this architecture that leverages these techniques to exploit ordered parallelism and accelerate important applications. In this architecture, programs consist of tiny tasks with order constraints. The system executes tasks speculatively and out of order, and efficiently speculates thousands of tasks ahead to uncover ordered parallelism. Tasks are distributed to run close to their data, reducing data movement and allowing the system to scale across multiple chips and boards. An early 256-core design demonstrates near-linear scalability on programs that are often deemed sequential, outperforming state-of-the-art algorithms by one to two orders of magnitude.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/20/2018</MinAmdLetterDate>
<MaxAmdLetterDate>07/20/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1814969</AwardID>
<Investigator>
<FirstName>Daniel</FirstName>
<LastName>Sanchez Martin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Daniel Sanchez Martin</PI_FULL_NAME>
<EmailAddress>sanchez@csail.mit.edu</EmailAddress>
<PI_PHON>6172531000</PI_PHON>
<NSF_ID>000636815</NSF_ID>
<StartDate>07/20/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[NE18-901]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001425594</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>MASSACHUSETTS INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001425594</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Massachusetts Institute of Technology]]></Name>
<CityName>Cambridge</CityName>
<StateCode>MA</StateCode>
<ZipCode>021394307</ZipCode>
<StreetAddress><![CDATA[77 Massachusetts Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~450000</FUND_OBLG>
</Award>
</rootTag>
