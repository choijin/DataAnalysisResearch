<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>BIGDATA: F: DKA: Scalable, Private Algorithms for Continual Data Analysis</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/24/2017</AwardEffectiveDate>
<AwardExpirationDate>08/31/2018</AwardExpirationDate>
<AwardTotalIntnAmount>21497.00</AwardTotalIntnAmount>
<AwardAmount>21497</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For the very same reasons that big data is transforming modern life, it also presents a profound threat to privacy and the control of personal information. A major challenge associated with big data is to enable statistical analysis of complex data sets, without compromising the privacy of the individuals whose data they contain. Addressing this challenge is both necessary, since access to many data sources is restricted due to privacy concerns, and difficult, as numerous attacks on supposedly anonymized data demonstrate.  This project will investigate the design and limitations of algorithms for the private, continual analysis of time-varying data sets.  That is, it will study algorithms that release information about a data set as it is collected (say, in the form of a data stream from the web, or a long-term sociological study). The research will advance the state of the art in the private analysis of "big" -- massive, complex, time-varying -- data. If successful, the project will provide enabling technologies that facilitate research in areas where access to sensitive data is limited by confidentiality concerns.&lt;br/&gt;&lt;br/&gt;The project will focus on the design of algorithms that satisfy differential privacy -- a rigorous notion of privacy that is widely studied in computer science and related fields. The privacy implications of sequential releases are still poorly understood, and relatively few of the algorithms developed in the extensive recent literature on private data analysis allow for sequential releases with high accuracy. The two major thrusts of the project are (1) algorithms for the "continual release" model, and (2) algorithms for the "local" model, which offers even stronger privacy guarantees. The work will provide novel algorithmic design techniques and understanding of complexity-theoretic limitations of algorithms for these models. The research will entail advances in related areas such as learning theory, statistical inference and streaming algorithms. The project will also include educational, outreach and work-force training activities designed to broaden the impact of the research.&lt;br/&gt;&lt;br/&gt;For further information see the project web site at: http://www.cse.psu.edu/~asmith/projects/continual/</AbstractNarration>
<MinAmdLetterDate>05/08/2018</MinAmdLetterDate>
<MaxAmdLetterDate>05/08/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1832766</AwardID>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Smith</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam Smith</PI_FULL_NAME>
<EmailAddress>ads22@bu.edu</EmailAddress>
<PI_PHON>6173538919</PI_PHON>
<NSF_ID>000105737</NSF_ID>
<StartDate>05/08/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Trustees of Boston University</Name>
<CityName>BOSTON</CityName>
<ZipCode>022151300</ZipCode>
<PhoneNumber>6173534365</PhoneNumber>
<StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049435266</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF BOSTON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049435266</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Trustees of Boston University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>022151300</ZipCode>
<StreetAddress><![CDATA[881 Commonwealth Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramElement>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramElement>
<ProgramReference>
<Code>7433</Code>
<Text>CyberInfra Frmwrk 21st (CIF21)</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>8083</Code>
<Text>Big Data Science &amp;Engineering</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~21496</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p id="docs-internal-guid-f1b2e231-7fff-8bc9-327f-162904b95d4a" dir="ltr"><span>This project developed new general algorithmic tools and specific algorithms that allow useful statistical analysis of a database with sensitive personal information, while preserving privacy of individuals. The algorithms that were developed satisfy formal privacy guarantees, specifically, differential privacy. Differential privacy guarantees that the output of the algorithm is approximately the same in all situations when data of one person is added or removed from the analysis. Intuitively, it guarantees that an individual cannot be harmed when his/her data is used. Differential private algorithms are used to share the results of analyzing sensitive data by organizations as diverse as the US Census, hospitals, Google, Facebook, and Apple.</span></p> <p dir="ltr"><span>One example of specific domain for which new tools and techniques were developed is analysis of social networks. This project developed new techniques for node differentially private graph analyses. Such analyses protect individuals participating in social networks and all their connections by requiring that that the output remains approximate the same when each individual, together with all their connections, is removed from the social network. Techniques developed in this project allow for release of multidimensional statistics about social networks, such as the degree distribution, while satisfying node differential privacy.</span></p> <p dir="ltr"><span>Along the way, the project led to advances in other areas of computer science. One example is a better understanding of the limits of parallel optimization algorithms. Optimization is a key step in many machine learning systems. The project showed that recent efforts to &ldquo;parallelize&rdquo; these algorithms--that is, spread the work among many servers to speed it up--will face barriers that require a different paradigm from the one currently used in their design. </span></p> <p id="docs-internal-guid-cc411294-7fff-9b8d-af95-1b84a1f2b0fb" dir="ltr">&nbsp;</p><br> <p>            Last Modified: 05/01/2019<br>      Modified by: Adam&nbsp;Smith</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[This project developed new general algorithmic tools and specific algorithms that allow useful statistical analysis of a database with sensitive personal information, while preserving privacy of individuals. The algorithms that were developed satisfy formal privacy guarantees, specifically, differential privacy. Differential privacy guarantees that the output of the algorithm is approximately the same in all situations when data of one person is added or removed from the analysis. Intuitively, it guarantees that an individual cannot be harmed when his/her data is used. Differential private algorithms are used to share the results of analyzing sensitive data by organizations as diverse as the US Census, hospitals, Google, Facebook, and Apple. One example of specific domain for which new tools and techniques were developed is analysis of social networks. This project developed new techniques for node differentially private graph analyses. Such analyses protect individuals participating in social networks and all their connections by requiring that that the output remains approximate the same when each individual, together with all their connections, is removed from the social network. Techniques developed in this project allow for release of multidimensional statistics about social networks, such as the degree distribution, while satisfying node differential privacy. Along the way, the project led to advances in other areas of computer science. One example is a better understanding of the limits of parallel optimization algorithms. Optimization is a key step in many machine learning systems. The project showed that recent efforts to "parallelize" these algorithms--that is, spread the work among many servers to speed it up--will face barriers that require a different paradigm from the one currently used in their design.          Last Modified: 05/01/2019       Submitted by: Adam Smith]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
