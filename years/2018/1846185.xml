<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Semantic Multi-Task Learning for Generalizable and Interpretable Language Generation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2019</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>445604.00</AwardTotalIntnAmount>
<AwardAmount>445604</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Natural language generation (NLG) systems has several important applications around us, e.g., the task of automatically summarizing and simplifying long documents into a short useful summary, or the task of video captioning to automatically describe a stream of surrounding visual information for assisting persons with visual disability, or a dialogue system that predicts the next response in a conversation. Current state-of-the-art NLG systems are good at generating 'shallow' outputs which are correct at the word and phrase (syntax) level. However, they lack several important semantic "knowledge skills", which this project addresses: (1) avoiding output information that is contradictory or unrelated to the given input, (2) being able to extract the most important topics of information from the large input document or video, and (3) maintaining a correctly-ordered sequence of sentences and paragraphs. Moreover, the project will focus on making these automated systems more interpretable, i.e., enable them to explain their decisions to humans, which makes them safer and more trustworthy when interfacing with students and persons with disability. The resulting knowledge-enhanced NLG systems will be more robust in new unseen scenarios that they have not seen before. This will allow making the technology widely accessible and societally impactful, by allowing trustworthy, engaging agents that can generate more natural and accurate language for diverse, real-world applications such as automated assistants for vision-speech impairments, intelligent tutoring by automated personal assistants in healthcare and schools, as well as for robot-human collaboration (e.g., verbal instructions for navigation, assembly, and troubleshooting). &lt;br/&gt;&lt;br/&gt;This project contributes techniques on how to enhance NLG models with crucial linguistic-semantic knowledge skills e.g., logical entailment to avoid contradictory and unrelated information with respect to the input, saliency to extract the most important information subsets, and discourse structure to enforce coherent order in the generated text. This will be achieved via a general multi-task learning (MTL) framework, which jointly trains the primary NLG model at hand with the auxiliary skill models (of entailment, saliency, and discourse) via shared parameters and model components. Thrust 1 will study how sharing specific model components (e.g., higher task-agnostic versus lower task-dependent layers) via flexible sharing strengths can lead to stronger and generalized task performance via domain-agnostic knowledge transfer. Thrust 2 will develop self-learned multi-task learning models that can avoid expensive manual tuning and automatically decide what the best auxiliary skill tasks are to share with the primary task (and which model components), via multi-armed bandit and reinforcement reward-based controllers. Thrust 3 will contribute novel controller rewards that allow domain-transferability without hurting in-domain task performance. Finally, these models will also be more interpretable in explaining their semantic errors in the generated language, as well as in visualizing what sharing decisions the self-learning MTL model made. The project will comprehensively evaluate the knowledge-enhanced NLG models on several diverse NLG tasks of document summarization, data-to-document, and video captioning. The effort will also include the release of a public suite of the auxiliary knowledge skills and MTL framework for promoting generalization and interpretability advancements in other NLG tasks.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/01/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1846185</AwardID>
<Investigator>
<FirstName>Mohit</FirstName>
<LastName>Bansal</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mohit Bansal</PI_FULL_NAME>
<EmailAddress>mbansal@cs.unc.edu</EmailAddress>
<PI_PHON>5105203282</PI_PHON>
<NSF_ID>000689943</NSF_ID>
<StartDate>07/01/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Chapel Hill</Name>
<CityName>CHAPEL HILL</CityName>
<ZipCode>275991350</ZipCode>
<PhoneNumber>9199663411</PhoneNumber>
<StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC04</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>608195277</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>142363428</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[UNC Chapel Hill]]></Name>
<CityName>Chapel Hill</CityName>
<StateCode>NC</StateCode>
<ZipCode>275993175</ZipCode>
<StreetAddress><![CDATA[201 S. Columbia St, CB3175]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>04</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC04</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~107244</FUND_OBLG>
<FUND_OBLG>2020~321022</FUND_OBLG>
<FUND_OBLG>2021~17338</FUND_OBLG>
</Award>
</rootTag>
