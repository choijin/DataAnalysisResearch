<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: SHF: HPC Solutions to Big NGS Data Compression</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>01/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>7708.00</AwardTotalIntnAmount>
<AwardAmount>7708</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Sequencing of genomes for numerous species including humans has become increasingly affordable due to next generation high-throughput genome sequencing (NGS) technologies. This opens up perspectives for diagnosis and treatment of genetic diseases and is increasingly effective in conducting system biology studies. However, there remain many computational challenges that need to be addressed before these technologies find their way into every day health and human care. One such daunting challenge is the volume of sequencing data which can reach peta-byte level for comprehensive system-biology studies. &lt;br/&gt;Genomic data compression is needed to reduce the storage size, to increase the speed and reduce the cost of I/O bandwidth required for transmission of such data. However, existing genomic compression solutions yield poor performance for Big Genomic Data. Further, the existing state of the art tools require the user to decompress the data before it can be used for further analysis. This project is focused on compression of genomic information and developing a framework which will allow analysis of compressed form of the data. The project develops HPC solutions for fast compression of Big NGS Data sets using ubiquitous architectures such as GPUs and multicore processors. HPC techniques are utilized to compute essential functions such as alignment and mapping using the compressed form of the NGS data. More efficient encoding of the NGS data for better network utilization is also being investigated.</AbstractNarration>
<MinAmdLetterDate>10/22/2018</MinAmdLetterDate>
<MaxAmdLetterDate>10/22/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1855441</AwardID>
<Investigator>
<FirstName>Fahad</FirstName>
<LastName>Saeed</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Fahad Saeed</PI_FULL_NAME>
<EmailAddress>FSAEED@FIU.EDU</EmailAddress>
<PI_PHON>3053483131</PI_PHON>
<NSF_ID>000602101</NSF_ID>
<StartDate>10/22/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida International University</Name>
<CityName>Miami</CityName>
<ZipCode>331990001</ZipCode>
<PhoneNumber>3053482494</PhoneNumber>
<StreetAddress>11200 SW 8TH ST</StreetAddress>
<StreetAddress2><![CDATA[MARC 430]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL26</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>071298814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA INTERNATIONAL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida International University]]></Name>
<CityName/>
<StateCode>FL</StateCode>
<ZipCode>331990001</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL26</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0116</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2016~7708</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Analysis of high-throughput omics data is an essential task in experimental and computational biology. Millions of short DNA read are generated from high-throughput next generation sequencing machines from a single run of experiment. The big data that one gets from these high-throughput techniques is so large that no matter how good the conventional techniques are they will never be able to keep up with the rate of these data sets. The big data that one gets from these high-throughput machines required novel ways of managing the data.</p> <p>The outcome of this project was the design, development and testing of high-performance computing algorithms for compression and processing of omics data. Our proposed techniques allowed us to compress massive amounts of data on memory-distributed clusters, and novel data structures that allowed us to analyze the compressed form of the genomics as well as proteomics data. Further, we developed novel algorithms that allowed lossy compression of mass spectrometry-based proteomics data sets. We also demonstrated that these data sets can be processed using graphical processing units. We demonstrated that these compressed data sets can be transmitted in much smaller time due to small memory-footprint. We expect that all of these fundamental contributions will have significant impact for domain systems biology scientists. Using HPC algorithms will allow these scientists to perform much more complex and accurate analysis than was previously possible. The efficiency and portability of our proposed techniques will have seminal impact in precision and personal medicine.</p> <p>Dr. Saeed's group has made fundamental advnaces in dealing  with these large data sets for processing. One of the most interesting  aspects of the research was compression of these large omics data sets  and processing on these data sets without the need to decompress them.</p> <p>The NSF CRII award has partially supported 7 PhD students, 2 MS and 4 undergraduate students, numerous research talks, and has resulted in more than 12 peer-reviewed publications. The software resulting from these novel high-performance computing is available on the PI lab webpage at: <a href="https://saeedlab.cs.fiu.edu/software/">https://saeedlab.cs.fiu.edu/software/</a></p><br> <p>            Last Modified: 02/17/2020<br>      Modified by: Fahad&nbsp;Saeed</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Analysis of high-throughput omics data is an essential task in experimental and computational biology. Millions of short DNA read are generated from high-throughput next generation sequencing machines from a single run of experiment. The big data that one gets from these high-throughput techniques is so large that no matter how good the conventional techniques are they will never be able to keep up with the rate of these data sets. The big data that one gets from these high-throughput machines required novel ways of managing the data.  The outcome of this project was the design, development and testing of high-performance computing algorithms for compression and processing of omics data. Our proposed techniques allowed us to compress massive amounts of data on memory-distributed clusters, and novel data structures that allowed us to analyze the compressed form of the genomics as well as proteomics data. Further, we developed novel algorithms that allowed lossy compression of mass spectrometry-based proteomics data sets. We also demonstrated that these data sets can be processed using graphical processing units. We demonstrated that these compressed data sets can be transmitted in much smaller time due to small memory-footprint. We expect that all of these fundamental contributions will have significant impact for domain systems biology scientists. Using HPC algorithms will allow these scientists to perform much more complex and accurate analysis than was previously possible. The efficiency and portability of our proposed techniques will have seminal impact in precision and personal medicine.  Dr. Saeed's group has made fundamental advnaces in dealing  with these large data sets for processing. One of the most interesting  aspects of the research was compression of these large omics data sets  and processing on these data sets without the need to decompress them.  The NSF CRII award has partially supported 7 PhD students, 2 MS and 4 undergraduate students, numerous research talks, and has resulted in more than 12 peer-reviewed publications. The software resulting from these novel high-performance computing is available on the PI lab webpage at: https://saeedlab.cs.fiu.edu/software/       Last Modified: 02/17/2020       Submitted by: Fahad Saeed]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
