<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Data Infrastructure for Open Science in Support of LIGO and IceCube</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/01/2018</AwardEffectiveDate>
<AwardExpirationDate>09/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>55094.00</AwardTotalIntnAmount>
<AwardAmount>55094</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05090000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>OAC</Abbreviation>
<LongName>Office of Advanced Cyberinfrastructure (OAC)</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Miller</SignBlockName>
<PO_EMAI>wlmiller@nsf.gov</PO_EMAI>
<PO_PHON>7032927886</PO_PHON>
</ProgramOfficer>
<AbstractNarration>In 2015, the NSF-funded LIGO Observatory made the first-ever detection of gravitational waves, from the collision of two black holes, a discovery that was recognized by the 2017 Nobel Prize in Physics. In 2017, LIGO and its sister observatory Virgo in Italy made the first detection of gravitational waves from another extreme event in the Universe - the collision of two neutron stars. Gamma rays from the same neutron star collision were also simultaneously detected by NASA's Fermi space telescope. Meanwhile, the NSF-funded IceCube facility, located at the U.S. South Pole Station, has made the first detection of high-energy neutrinos from beyond our galaxy, giving us unobstructed views of other extreme objects in Universe such as supermassive black holes and supernova remnants. The revolutionary ability to observe gravitational waves, neutrinos, and optical and radio waves from the same celestial events has launched the era of "Multi-Messenger Astrophysics," an exciting new field supported by one of NSF's ten Big Ideas, "Windows on the Universe".&lt;br/&gt;&lt;br/&gt;The success of Multi-Messenger Astrophysics depends on building new data infrastructure to seamlessly share, integrate, and analyze data from many large observing instruments. The investigators propose a cohesive, federated, national-scale research data infrastructure for large instruments, focused initially on LIGO and IceCube, to address the need to access, share, and combine science data, and make the entire data processing life cycle more robust. The novel working model of the project is a multi-institutional collaboration comprising the LIGO and IceCube observatories, Internet2, and platform integration experts. The investigators will conduct a fast-track two-year effort that draws heavily on prior and concurrent NSF investments in software, computing and data infrastructure, and international software developments including at CERN.  Internet2 will establish data caches inside the national network backbone to optimize the LIGO data analysis. The goal is to achieve a data infrastructure platform that addresses the production needs of LIGO and IceCube while serving as an exemplar for the entire scope of Multi-messenger Astrophysics and beyond. In the process, the investigators are prototyping a redefinition of the role the academic internet plays in supporting science.&lt;br/&gt;&lt;br/&gt;This project is supported by the Office of Advanced Cyberinfrastructure in the Directorate for Computer and Information Science and Engineering.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/07/2018</MinAmdLetterDate>
<MaxAmdLetterDate>09/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1841546</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Couvares</LastName>
<PI_MID_INIT>F</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter F Couvares</PI_FULL_NAME>
<EmailAddress>peter.couvares@ligo.org</EmailAddress>
<PI_PHON>3154435962</PI_PHON>
<NSF_ID>000328523</NSF_ID>
<StartDate>09/07/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>California Institute of Technology</Name>
<CityName>PASADENA</CityName>
<ZipCode>911250600</ZipCode>
<PhoneNumber>6263956219</PhoneNumber>
<StreetAddress>1200 E California Blvd</StreetAddress>
<StreetAddress2><![CDATA[Mail Code 273-6]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA27</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>009584210</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CALIFORNIA INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>009584210</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[California Institute of Technology]]></Name>
<CityName>Pasadena</CityName>
<StateCode>CA</StateCode>
<ZipCode>911250600</ZipCode>
<StreetAddress><![CDATA[1200 E California Blvd]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>27</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA27</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7684</Code>
<Text>CESER-Cyberinfrastructure for</Text>
</ProgramElement>
<ProgramReference>
<Code>020Z</Code>
<Text>OAC Facility Cyberinfrastructure</Text>
</ProgramReference>
<ProgramReference>
<Code>062Z</Code>
<Text>Harnessing the Data Revolution</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~55094</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><div class="page" title="Page 10"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>We deployed a global content delivery network for the Laser Interferometer Gravitational Wave Observatory and expanded the GPU capacity to both Icecube and LIGO.&nbsp; The result is a better global resource and data integration which allows for more simulations and analysis enabling better delivery of science. </span></p> </div> </div> </div> </div> <div class="page" title="Page 2"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>We successfully deployed a total of thirteen caches. In addition to the three caches mentioned in the proposal (Kansas City, Chicago, NYC), caches in Amsterdam, Cardiff, KISTI (South Korea), UCSD, and Georgia Tech have been deployed in support of LIGO/Virgo operations. These are in addition to caches in Madison, Nebraska, Syracuse, University of Chicago, PIC (Barcelona), CNAF (Bologna) and an older, smaller cache at UCSD that preceded this project. </span></p> <p><span>We identified additional locations in the Internet2 backbone that benefit from additional cache deployments and deployed caches in Sunnyvale and Houston in addition to giving support for the installation of two more in CNAF (Bologna, Italy) and PIC (Barcelona, Spain).&nbsp; As a general rule, all caches deployed in the network backbone, or at large multi-user facilities are open to all of science. The caching built out of this project thus benefits open science broadly.<br /></span></p> <div class="page" title="Page 3"> <div class="section"> <div class="layoutArea"> <div class="column"> <p><span>Finally, we performed multiple cloud bursts, including the largest GPU simulation ever done in the cloud. Highlights include 51,500 GPUs at peak across AWS, Azure, and Google.</span></p> </div> </div> </div> </div> </div> </div> </div> </div><br> <p>            Last Modified: 03/04/2021<br>      Modified by: Peter&nbsp;F&nbsp;Couvares</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[     We deployed a global content delivery network for the Laser Interferometer Gravitational Wave Observatory and expanded the GPU capacity to both Icecube and LIGO.  The result is a better global resource and data integration which allows for more simulations and analysis enabling better delivery of science.           We successfully deployed a total of thirteen caches. In addition to the three caches mentioned in the proposal (Kansas City, Chicago, NYC), caches in Amsterdam, Cardiff, KISTI (South Korea), UCSD, and Georgia Tech have been deployed in support of LIGO/Virgo operations. These are in addition to caches in Madison, Nebraska, Syracuse, University of Chicago, PIC (Barcelona), CNAF (Bologna) and an older, smaller cache at UCSD that preceded this project.   We identified additional locations in the Internet2 backbone that benefit from additional cache deployments and deployed caches in Sunnyvale and Houston in addition to giving support for the installation of two more in CNAF (Bologna, Italy) and PIC (Barcelona, Spain).  As a general rule, all caches deployed in the network backbone, or at large multi-user facilities are open to all of science. The caching built out of this project thus benefits open science broadly.       Finally, we performed multiple cloud bursts, including the largest GPU simulation ever done in the cloud. Highlights include 51,500 GPUs at peak across AWS, Azure, and Google.               Last Modified: 03/04/2021       Submitted by: Peter F Couvares]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
