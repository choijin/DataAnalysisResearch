<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>AF: Small: New Directions in Learning Theory</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2017</AwardEffectiveDate>
<AwardExpirationDate>05/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>98041.00</AwardTotalIntnAmount>
<AwardAmount>98041</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>A. Funda Ergun</SignBlockName>
<PO_EMAI>fergun@nsf.gov</PO_EMAI>
<PO_PHON>7032922216</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This project is to develop core principles and technologies for systems that learn from observation and experience in order to better help their users.  While there is already a significant body of work in the area of machine learning, today's interconnected world provides both new challenges and new opportunities that classic methods are not able to address or take advantage of.  This project has three main thrusts.  The first involves development of methods that can extract useful information from auxiliary sources in addition to traditional labeled data.  This includes methods for quickly learning multiple related tasks by taking advantage of ways in which they relate to each other.  The second involves approaches for learning about what different users or agents want by observing the results of their interactions.  Finally, the third thrust involves development of new rigorous methods for quickly estimating the amount of resources that would be needed to solve a given learning task.  Broader impacts of the project include the training of a diverse set of graduate students, improving undergraduate curricula with respect to machine learning technology, and developing a new book for advanced undergraduates on algorithms and analysis for data science.&lt;br/&gt;&lt;br/&gt;More specifically, the first main thrust of this work involves a combination of unsupervised, semi-supervised, and multi-task learning. This work will investigate problems of estimating error rates from unlabeled data, unifying co-training and topic models, learning multiple related tasks from limited supervision, and learning new representations of data using tools from high-dimensional geometry.  The second main thrust will focus on reconstructing estimates of agent utilities from observing the outcomes of economic mechanisms such as combinatorial auctions.  This thrust also includes problems of learning the rules of unknown mechanisms from experimentation.  Finally, the last thrust focuses on development of the theory of property testing for machine learning problems, with the goal of quickly estimating natural formal measures of complexity of a given learning task.</AbstractNarration>
<MinAmdLetterDate>10/18/2017</MinAmdLetterDate>
<MaxAmdLetterDate>10/18/2017</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1800317</AwardID>
<Investigator>
<FirstName>Avrim</FirstName>
<LastName>Blum</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Avrim Blum</PI_FULL_NAME>
<EmailAddress>avrim@ttic.edu</EmailAddress>
<PI_PHON>7738341740</PI_PHON>
<NSF_ID>000445508</NSF_ID>
<StartDate>10/18/2017</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Toyota Technological Institute at Chicago</Name>
<CityName>Chicago</CityName>
<ZipCode>606372803</ZipCode>
<PhoneNumber>7738340409</PhoneNumber>
<StreetAddress>6045 S Kenwood Ave</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>127228927</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TOYOTA TECHNOLOGICAL INSTITUTE AT CHICAGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Toyota Technological Institute at Chicago]]></Name>
<CityName/>
<StateCode>IL</StateCode>
<ZipCode>606372902</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7796</Code>
<Text>Algorithmic Foundations</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7926</Code>
<Text>ALGORITHMS</Text>
</ProgramReference>
<Appropriation>
<Code>0115</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2015~98041</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This project investigated core principles for important directions and challenges in the development of machine learning systems.</p> <p>One main direction involved developing new understanding of how fairness considerations interact with classic optimization goals in algorithms for adaptive decision-making.&nbsp; This work specifically focused on decision making in non-stationary environments.&nbsp; In such environments, one may have multiple different decision-making strategies one can use (often called "experts" in the technical literature), but which of these is best may change over time.&nbsp; The challenge is that to keep accuracy high one may need to switch strategies mid-stream, but this switching may conflict with fairness considerations if the strategies have different characteristics.&nbsp; We showed in this work that some fairness notions, including one known as "equalized odds", could have inherent conflicts with accuracy goals even if the strategies each individually satisfy this fairness condition, whereas related notions including "equalized error rates" can be obtained without conflict using the right adaptive algorithms.</p> <p>A second main direction involved developing algorithms for estimating, from a small amount of labeled data, what the performance of a given machine learning method would be <em>if one were to train it on a much larger labeled data set</em>.&nbsp; The aim is to use this to enable researchers to perform fast estimations of whether a given learning approach is worth performing, and to more quickly (and from less labeled data) set higher-level structural properties called "hyperparameters".</p> <p>A third main direction involved a study of how collaboration can benefit machine learning systems.&nbsp; Consider, for example, the problem of creating a spam filter that is good simultaneously for <em>k</em> different people.&nbsp; Even if the <em>k</em> people would all agree on whether any given email message is spam or not (formally, they all wish to learn the same target function <em>f</em>), they may have very different typical non-spam emails (formally, they each care about how well the learned rule approximates <em>f</em> over different data distributions). The question studied in this project was whether in such a setting, the <em>k</em> people by collaborating could learn to a given desired accuracy from much less data per person than by learning separately.&nbsp; This work showed that in fact there is a collaboration procedure that under quite general conditions will produce significant reductions in data needed per person.</p> <p>Finally, this work also addressed problems in lifelong machine learning, topic modeling, and in learning algorithms for adversarial environments.</p><br> <p>            Last Modified: 07/20/2019<br>      Modified by: Avrim&nbsp;Blum</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This project investigated core principles for important directions and challenges in the development of machine learning systems.  One main direction involved developing new understanding of how fairness considerations interact with classic optimization goals in algorithms for adaptive decision-making.  This work specifically focused on decision making in non-stationary environments.  In such environments, one may have multiple different decision-making strategies one can use (often called "experts" in the technical literature), but which of these is best may change over time.  The challenge is that to keep accuracy high one may need to switch strategies mid-stream, but this switching may conflict with fairness considerations if the strategies have different characteristics.  We showed in this work that some fairness notions, including one known as "equalized odds", could have inherent conflicts with accuracy goals even if the strategies each individually satisfy this fairness condition, whereas related notions including "equalized error rates" can be obtained without conflict using the right adaptive algorithms.  A second main direction involved developing algorithms for estimating, from a small amount of labeled data, what the performance of a given machine learning method would be if one were to train it on a much larger labeled data set.  The aim is to use this to enable researchers to perform fast estimations of whether a given learning approach is worth performing, and to more quickly (and from less labeled data) set higher-level structural properties called "hyperparameters".  A third main direction involved a study of how collaboration can benefit machine learning systems.  Consider, for example, the problem of creating a spam filter that is good simultaneously for k different people.  Even if the k people would all agree on whether any given email message is spam or not (formally, they all wish to learn the same target function f), they may have very different typical non-spam emails (formally, they each care about how well the learned rule approximates f over different data distributions). The question studied in this project was whether in such a setting, the k people by collaborating could learn to a given desired accuracy from much less data per person than by learning separately.  This work showed that in fact there is a collaboration procedure that under quite general conditions will produce significant reductions in data needed per person.  Finally, this work also addressed problems in lifelong machine learning, topic modeling, and in learning algorithms for adversarial environments.       Last Modified: 07/20/2019       Submitted by: Avrim Blum]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
