<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RAPID: Collaborative Research: Machine Learning for Dehazing Unmanned Aerial System Imagery from Volcanic Eruptions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>80742.00</AwardTotalIntnAmount>
<AwardAmount>80742</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>David Miller</SignBlockName>
<PO_EMAI>damiller@nsf.gov</PO_EMAI>
<PO_PHON>7032924914</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ongoing eruption of the Kilauea volcano in Hawaii is the first reported time that small unmanned aerial systems (UAS) have been used for the emergency response to a volcanic eruption. The Center for Robot-Assisted Search and Rescue (CRASAR) flew 44 small UAS flights for the Hilo Fire Department and Hawaii County Civil Defense. The eruption imagery was partially occluded by plumes of steam carrying toxic gases, something that had not been encountered before. The plumes interfere with responders comprehending the tactical situation because it obscures the ground below and often prevents software from generating useful surface maps. While volcanic eruptions are fairly rare, the same plume problem is likely to occur in other hazardous material events. Machine learning techniques for dehazing were only partially successful because plumes present a very different set of challenges than removing urban haze or smog. This project conducts rapid research to remove or reduce plumes, from stills and video, in near real-time in order to support responses to the ongoing disaster. It will make the datasets available so that they can be used for training and evaluating new machine learning algorithms. The project will host a follow up workshop at the 2019 AAAI Conference on Artificial Intelligence in Hawaii.&lt;br/&gt;&lt;br/&gt;This project creates a UAS open-source imagery dataset from the ongoing Leilani, Hawaii, volcanic eruption event. It uses the dataset to expand and refine dehazing algorithms that will help Hawaii public safety agencies and volcanologists see through the plumes of steam and gas that is interfering with mapping the extent and volume of the lava. Plumes of steam mingled with sulfur dioxide interfered with interpreting the boundaries of the lava field and introduced errors into stitching images together or caused details to be averaged out. Smog is a homogeneous, thin visual phenomenon while plumes are heterogeneous and thick, limiting the utility of current techniques and requiring focused research. The dataset offers an opportunity for a corpus of real imagery that can serve as machine learning training data and enable comparison of before and after results. The intellectual merit of the project is twofold. It provides a unique opportunity to explore a new area of machine learning for heterogeneous, thick plumes in images. The comprehensive dataset will enable foundational work in computer vision, machine learning, and emergency informatics.  The research will immediately improve emergency management of the Leilani eruption event and emergency management in general.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/04/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1840873</AwardID>
<Investigator>
<FirstName>Robin</FirstName>
<LastName>Murphy</LastName>
<PI_MID_INIT>R</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Robin R Murphy</PI_FULL_NAME>
<EmailAddress>robin.r.murphy@tamu.edu</EmailAddress>
<PI_PHON>9798621696</PI_PHON>
<NSF_ID>000511836</NSF_ID>
<StartDate>08/04/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zhangyang</FirstName>
<LastName>Wang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhangyang Wang</PI_FULL_NAME>
<EmailAddress>atlaswang@utexas.edu</EmailAddress>
<PI_PHON>2179790905</PI_PHON>
<NSF_ID>000746175</NSF_ID>
<StartDate>08/04/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Texas A&amp;M Engineering Experiment Station</Name>
<CityName>College Station</CityName>
<ZipCode>778454645</ZipCode>
<PhoneNumber>9798626777</PhoneNumber>
<StreetAddress>400 Harvey Mitchell Pkwy S</StreetAddress>
<StreetAddress2><![CDATA[Suite 300]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX17</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>847205572</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TEXAS A&amp;M ENGINEERING EXPERIMENT STATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042915991</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Texas A&M Engineering Experiment Station]]></Name>
<CityName>College Station</CityName>
<StateCode>TX</StateCode>
<ZipCode>778433112</ZipCode>
<StreetAddress><![CDATA[TAMU 3112]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>17</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX17</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~80742</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>&nbsp;</p> <div>The 2018 eruption event of the Kilauea volcano in Hawaii was the first reported time that small unmanned aerial systems (UAS) have been used for the emergency response to a volcanic eruption. Prior efforts have used sUAS to monitor and conduct scientific data collection about the geological processes, gaseous emissions, and post-disaster assessments but not the actual time-critical response effort.&nbsp;The most fundamental finding was that a volcanic eruption poses a notable challenge for robotics and artificial intelligence that has not been seen in previous natural or man-made disasters. Specifically, the aerial&nbsp;imagery was partially occluded by plumes of steam carrying toxic gases. <span>The plumes interfere with responders comprehending the tactical situation because it obscures the ground below. It also often prevents software from generating useful panoramic, orthomosiac and digital surface maps because the plume is constantly&nbsp;shifting location and density, which is very different from smog or pollution haze in urban areas. As a result, machine learning algorithms for&nbsp;dehazing urban images failed. Unfortunately,&nbsp;this problem is likely to occur in other hazardous material events, e.g., chemical train derailments and the Bhopal, India, industrial disaster.&nbsp;</span></div> <div><span><br /></span></div> <div>The goal of this project was to create an unmanned aerial system (UAS) open-source imagery dataset from the ongoing Leilani, Hawaii, volcanic eruption event while at the same time using the dataset to expand and refine dehazing algorithms that will help Hawaii public safety agencies and vulcanologists see through the plumes of steam and hydrogen sulfide gas that is interfering with mapping the extent and volume of the lava. This dataset allows researchers in computer vision and machine learning to develop effective algorithms fo this new category of plumes and will improve emergency management and geosciences, while advancing machine learning. The project also hosted a field workshop that brought together emergency responders with 19 experts in computer vision, machine learning, robotics, and geosciences to form a nucleus of a new community dedicated to artificial intelligence for natural disasters. Three graduate students and one undergraduate student were trained in research and two publications and an undergraduate honor thesis has used the datasets to investigate how to improve machine learning for volcanic plumes.&nbsp;</div> <p>&nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/05/2019<br>      Modified by: Robin&nbsp;R&nbsp;Murphy</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Images (<span id="selectedPhoto0">1</span> of <span class="totalNumber"></span>)           </div> <div class="galControls" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1840873/1840873_10565955_1564762142372_hawaiiso2clouds--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1840873/1840873_10565955_1564762142372_hawaiiso2clouds--rgov-800width.jpg" title="SO2 Plumes at Kilauea"><img src="/por/images/Reports/POR/2019/1840873/1840873_10565955_1564762142372_hawaiiso2clouds--rgov-66x44.jpg" alt="SO2 Plumes at Kilauea"></a> <div class="imageCaptionContainer"> <div class="imageCaption">SO2 Plumes at Kilauea interfering with situation awareness.</div> <div class="imageCredit">Center for Robot-Assisted Search and Rescue</div> <div class="imagePermisssions">Public Domain</div> <div class="imageSubmitted">Robin&nbsp;R&nbsp;Murphy</div> <div class="imageTitle">SO2 Plumes at Kilauea</div> </div> </li> <li> <a href="/por/images/Reports/POR/2019/1840873/1840873_10565955_1565035368524_pilotsgasmasks--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1840873/1840873_10565955_1565035368524_pilotsgasmasks--rgov-800width.jpg" title="UAS pilots wearing masks due to SO2 clouds"><img src="/por/images/Reports/POR/2019/1840873/1840873_10565955_1565035368524_pilotsgasmasks--rgov-66x44.jpg" alt="UAS pilots wearing masks due to SO2 clouds"></a> <div class="imageCaptionContainer"> <div class="imageCaption">UAS pilots wearing masks due to SO2 clouds</div> <div class="imageCredit">Center for Robot-Assisted Search and Rescue</div> <div class="imageSubmitted">Robin&nbsp;R&nbsp;Murphy</div> <div class="imageTitle">UAS pilots wearing masks due to SO2 clouds</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[   The 2018 eruption event of the Kilauea volcano in Hawaii was the first reported time that small unmanned aerial systems (UAS) have been used for the emergency response to a volcanic eruption. Prior efforts have used sUAS to monitor and conduct scientific data collection about the geological processes, gaseous emissions, and post-disaster assessments but not the actual time-critical response effort. The most fundamental finding was that a volcanic eruption poses a notable challenge for robotics and artificial intelligence that has not been seen in previous natural or man-made disasters. Specifically, the aerial imagery was partially occluded by plumes of steam carrying toxic gases. The plumes interfere with responders comprehending the tactical situation because it obscures the ground below. It also often prevents software from generating useful panoramic, orthomosiac and digital surface maps because the plume is constantly shifting location and density, which is very different from smog or pollution haze in urban areas. As a result, machine learning algorithms for dehazing urban images failed. Unfortunately, this problem is likely to occur in other hazardous material events, e.g., chemical train derailments and the Bhopal, India, industrial disaster.    The goal of this project was to create an unmanned aerial system (UAS) open-source imagery dataset from the ongoing Leilani, Hawaii, volcanic eruption event while at the same time using the dataset to expand and refine dehazing algorithms that will help Hawaii public safety agencies and vulcanologists see through the plumes of steam and hydrogen sulfide gas that is interfering with mapping the extent and volume of the lava. This dataset allows researchers in computer vision and machine learning to develop effective algorithms fo this new category of plumes and will improve emergency management and geosciences, while advancing machine learning. The project also hosted a field workshop that brought together emergency responders with 19 experts in computer vision, machine learning, robotics, and geosciences to form a nucleus of a new community dedicated to artificial intelligence for natural disasters. Three graduate students and one undergraduate student were trained in research and two publications and an undergraduate honor thesis has used the datasets to investigate how to improve machine learning for volcanic plumes.              Last Modified: 08/05/2019       Submitted by: Robin R Murphy]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
