<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: An Open Mobile App Platform to Support Research on Fraudulent Reviews</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>149999.00</AwardTotalIntnAmount>
<AwardAmount>149999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
<PO_EMAI>skiesler@nsf.gov</PO_EMAI>
<PO_PHON>7032928643</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The pressure to succeed in online, peer-review websites has created a black market for search rank fraud. Fraud workers, who may control hundreds of user accounts, connect with product developers through crowdsourcing sites, then, from the accounts that they control, post fake activities, ratings, and reviews for site-owners' products. Most peer-review systems use fraud detection to filter out fake activities, but fraud nevertheless persists. Academic fraud detection research has been hampered by a scarcity of validated fraud data, the lack of a platform on which to evaluate and compare solutions, and the unwillingness of commercial peer-review sites to share insights, algorithms, and data. This project is developing an open mobile app platform, the first collaborative environment for the research community to ethically commission and share validated fraud data, classify observed fraud posting behaviors, evaluate fraud detection algorithms, and experiment with the inner functionality of an app market. This platform has the potential to significantly advance fraud detection research and make it more relevant to commercial peer-review sites, thus helping reduce the daily exposure to fraud of their millions of users.&lt;br/&gt;&lt;br/&gt;This project will investigate, develop and evaluate an online framework to study search rank fraud in app markets. The team is building an open-source app market to collect ground truth fraud datasets, validate existing and discover new fraud behaviors, and evaluate fraud detection solutions in a live environment. The team will develop protocols of interaction with fraud workers that will evaluate the quality of the data that they post using assurances of its fraudulence, attribution of fraud, and similarity to fraud posted in commercial sites. The team will develop new techniques to validate the output of fraud detection and prevention algorithms that transform participating fraud workers into human oracles. To help bridge the gap between assumptions made by fraud detection solutions and strategies employed by fraud workers, the team will develop semi-structured questionnaires and conduct user studies with fraud workers recruited from crowdsourcing sites, to identify and classify their most popular fraud preferences, constraints, capabilities and evasion strategies.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/04/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/04/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1840714</AwardID>
<Investigator>
<FirstName>Bogdan</FirstName>
<LastName>Carbunar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Bogdan Carbunar</PI_FULL_NAME>
<EmailAddress>carbunar@gmail.com</EmailAddress>
<PI_PHON>3053482494</PI_PHON>
<NSF_ID>000591376</NSF_ID>
<StartDate>08/04/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Florida International University</Name>
<CityName>Miami</CityName>
<ZipCode>331990001</ZipCode>
<PhoneNumber>3053482494</PhoneNumber>
<StreetAddress>11200 SW 8TH ST</StreetAddress>
<StreetAddress2><![CDATA[MARC 430]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<StateCode>FL</StateCode>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>FL26</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>071298814</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>FLORIDA INTERNATIONAL UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>159621697</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Florida International University]]></Name>
<CityName>Miami</CityName>
<StateCode>FL</StateCode>
<ZipCode>331990001</ZipCode>
<StreetAddress><![CDATA[11200 SW 8th St., ECS 352]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Florida</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>FL26</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>065Z</Code>
<Text>Human factors for security research</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~149999</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Academic research on detecting search rank fraud in peer-opinion services has been hampered by a scarcity of validated fraud data, the lack of a platform on which to evaluate and compare solutions, and the unwillingness of commercial peer-review sites to share insights, algorithms, and data. In this project we proposed to develop an online framework to study app search optimization (ASO) in app markets, that includes (1) developing protocols to study ASO workers, (2) devising new techniques to validate the output of fraud detection and prevention algorithms, and (3) developing an open-source app market to collect ground truth fraud datasets.</p> <p>Work has encompassed the following thrusts. First, we have designed a structured interview study comprised of 118 questions, about the capabilities, behaviors and detection avoidance strategies of app search optimization (ASO) workers. We performed the study with 18 ASO workers. We also performed a quantitative investigation with data that we collected from 39 other ASO workers. We found and reported novel insights into the working patterns of ASO workers. Some of our findings provide evidence that supports observations and assumptions made by previous fraud detection work. However, we also found and validated ASO worker-revealed strategy changes, detection avoidance and exploitation of Google bugs behaviors that contradict existing assumptions.</p> <p>We analyzed worker-reported answers and identified vulnerabilities in their workflow that provide new suggestions for future research. For instance, we found that a significant proportion of ASO workers pool accounts and devices to maximize the impact and revenue of their activities. To provide a disincentive for such behaviors, in a second thrust of this project we introduced the fraud de-anonymization problem, to attribute user accounts flagged by fraud detection algorithms to the human ASO workers who control them. We have developed theoretical and practical solutions to de-anonymize fraud posted in Google Play. We have further introduced the first cheating-resistant, fraud de-anonymization validation protocol that converts ASO workers into ground truth, performance evaluation oracles. We have shown that our solutions achieve high accuracy on ground truth data and are able to attribute thousands of new user accounts to known ASO workers.</p> <p>&nbsp;</p><br> <p>            Last Modified: 08/17/2020<br>      Modified by: Bogdan&nbsp;Carbunar</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Academic research on detecting search rank fraud in peer-opinion services has been hampered by a scarcity of validated fraud data, the lack of a platform on which to evaluate and compare solutions, and the unwillingness of commercial peer-review sites to share insights, algorithms, and data. In this project we proposed to develop an online framework to study app search optimization (ASO) in app markets, that includes (1) developing protocols to study ASO workers, (2) devising new techniques to validate the output of fraud detection and prevention algorithms, and (3) developing an open-source app market to collect ground truth fraud datasets.  Work has encompassed the following thrusts. First, we have designed a structured interview study comprised of 118 questions, about the capabilities, behaviors and detection avoidance strategies of app search optimization (ASO) workers. We performed the study with 18 ASO workers. We also performed a quantitative investigation with data that we collected from 39 other ASO workers. We found and reported novel insights into the working patterns of ASO workers. Some of our findings provide evidence that supports observations and assumptions made by previous fraud detection work. However, we also found and validated ASO worker-revealed strategy changes, detection avoidance and exploitation of Google bugs behaviors that contradict existing assumptions.  We analyzed worker-reported answers and identified vulnerabilities in their workflow that provide new suggestions for future research. For instance, we found that a significant proportion of ASO workers pool accounts and devices to maximize the impact and revenue of their activities. To provide a disincentive for such behaviors, in a second thrust of this project we introduced the fraud de-anonymization problem, to attribute user accounts flagged by fraud detection algorithms to the human ASO workers who control them. We have developed theoretical and practical solutions to de-anonymize fraud posted in Google Play. We have further introduced the first cheating-resistant, fraud de-anonymization validation protocol that converts ASO workers into ground truth, performance evaluation oracles. We have shown that our solutions achieve high accuracy on ground truth data and are able to attribute thousands of new user accounts to known ASO workers.          Last Modified: 08/17/2020       Submitted by: Bogdan Carbunar]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
