<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Situational Awareness in Autonomous Agriculture</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>06/15/2018</AwardEffectiveDate>
<AwardExpirationDate>02/28/2019</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>225000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Muralidharan Nair</SignBlockName>
<PO_EMAI>mnair@nsf.gov</PO_EMAI>
<PO_PHON>7032927059</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this project is to enable real-time situational awareness in autonomous vehicles.  With the global population expected to reach 9 billion by 2050 and the uncertain climate changes that create concern over the resources allocated to farming activities, precision agriculture has become the ultimate solution to increase agricultural productivity and efficiency. The proposed system, aiming to integrate aerial and terrain robotics and provide high-throughput crop imaging, will push precision agriculture to the next evolutionary stage ? fully autonomous agriculture. With the R&amp;D efforts in this project, the integrated aerial-terrain robotics and high-throughput imaging system will be ready for commercialization under the proposed sustainable business model and impact farming industries globally. Moreover, the system prototype enabled by smart and mobile docking can be readily adapted to accommodate needs in a variety of other industries, where geospatially large-scale sensing and analytics are in demand, such as transportation network monitoring, civil infrastructure and urban monitoring, logistics and freight management, and monitoring of environmental hazards. The proposed invention and its future robotic products are expected to impact all these sectors by imparting automation in terms of high-dimensional data collection and real-time analytics. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research Phase I project provides a technology leap that furnishes state-of-the-art terrain robotics with long-range and real-time situational awareness, including pre-operation reconnaissance and post-operation evaluation. A smart docking platform will be developed that provides an unlimited energy supply while serving as an ad-hoc computing engine and enables the possibility of high-throughput imaging for single plants or plant groups.  Such a systematically coupled docking-imaging-computing platform is not found to date. The docking will be realized through three independent mechanisms, including kinetic sensing and calculation, low-cost stereo vision, and radar ranging; and real-time positioning algorithms based on the three mechanisms will be developed through a fail-safe data fusion process. The aerial imaging drone, charged by the docking platform, can perform two modes of imaging activities either towards conventional terrain/field mapping or the novel 4-dimensional (4D) reconstruction proposed in this project. The reconstruction algorithms will be developed based on the fusion of the stereo data and the hyperspectral data, which produces the first-of-its kind 4D spatial-spectral models for high-throughput phenotyping.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/14/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1818982</AwardID>
<Investigator>
<FirstName>Jianfei</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jianfei Chen</PI_FULL_NAME>
<EmailAddress>jchen@awarevehicles.com</EmailAddress>
<PI_PHON>8168449649</PI_PHON>
<NSF_ID>000752069</NSF_ID>
<StartDate>06/14/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Aware Vehicles, Inc</Name>
<CityName>Kansas City</CityName>
<ZipCode>641132907</ZipCode>
<PhoneNumber>8168449649</PhoneNumber>
<StreetAddress>1224 w 62nd st Ste 2</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>080667323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>AWARE VEHICLES, INC.</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Aware Vehicles, Inc.]]></Name>
<CityName>Kansas City</CityName>
<StateCode>MO</StateCode>
<ZipCode>641102499</ZipCode>
<StreetAddress><![CDATA[5100 Rockhill Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8034</Code>
<Text>Hardware Components</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~225000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>This Small Business&nbsp;Innovation&nbsp;Research Phase&nbsp;I project provides a technology leap that furnishes terrain-based Farming Robotic Vehicles (FRVs) with long-range and real-time situational awareness, including pre-operation reconnaissance and post-operation evaluation.&nbsp;A&nbsp;mobile smart docking platform has been developed that provides&nbsp;an&nbsp;unlimited energy supply for drone use while serving&nbsp;as an edge computing&nbsp;and communications engine&nbsp;and&nbsp;enables the possibility of real-time high-throughput imaging, analysis and decision-making for a wide variety of agricultural applications.&nbsp;</p> <p>&nbsp;</p> <p>The innovative features of the invention include: (1) intelligent and robust data fusion for docking an aerial drone-imaging system to a mobile FRV; (2) high-throughput hyperspectral imaging of geo-positioned&nbsp;plants, crop zones or other agricultural targets of interest; and (3) real-time computing to produce crop-field analytics (4-D spatial-spectral modeling) and navigation parameters for FRVs path planning.&nbsp;These outcomes pave the way for the next-phase studies of human-machine interface and deep learning of high-throughput phenotyping data and large-scale field development and validation.&nbsp;</p> <p>&nbsp;</p> <p>With the global population expected to reach 9 billion by 2050 and the&nbsp;uncertain climate changes that&nbsp;create concern over the&nbsp;resources&nbsp;available to farming activities, precision agriculture has become&nbsp;the ultimate solution and necessity to&nbsp;increase&nbsp;agricultural productivity and efficiency. Aware Vehicles innovative system integrates advanced aerial and terrain robotics, high-throughput imaging and data analytics, pushing&nbsp;precision agriculture towards the next evolutionary stage...&nbsp;fully&nbsp;autonomous agriculture.&nbsp;With the research and development efforts in this project, the integrated aerial-terrain robotics and high-throughput imaging system&nbsp;will be ready for commercialization under a&nbsp;sustainable&nbsp;business model and impact farming industries globally.&nbsp;Moreover, systems enabled by smart and mobile docking can be readily adapted to accommodate needs in&nbsp;a variety&nbsp;of&nbsp;other industries, where geospatially large-scale sensing and analytics are&nbsp;in demand, such as civil infrastructure, disaster response (including fire-fighting),&nbsp;logistics&nbsp;and freight management&nbsp;and&nbsp;defense (including Intelligence, Surveillance and Reconnaissance). &nbsp;</p> <p>&nbsp;</p><br> <p>            Last Modified: 04/15/2019<br>      Modified by: Jianfei&nbsp;Chen</p> </div> <div class="porSideCol"> <div class="each-gallery"> <div class="galContent" id="gallery0"> <div class="photoCount" id="photoCount0">          Image         </div> <div class="galControls onePhoto" id="controls0"></div> <div class="galSlideshow" id="slideshow0"></div> <div class="galEmbox" id="embox"> <div class="image-title"></div> </div> </div> <div class="galNavigation onePhoto" id="navigation0"> <ul class="thumbs" id="thumbs0"> <li> <a href="/por/images/Reports/POR/2019/1818982/1818982_10550197_1555360361731_IMG_0318--rgov-214x142.jpg" original="/por/images/Reports/POR/2019/1818982/1818982_10550197_1555360361731_IMG_0318--rgov-800width.jpg" title="Aware Vehicles' Mobile Smart Docking Station"><img src="/por/images/Reports/POR/2019/1818982/1818982_10550197_1555360361731_IMG_0318--rgov-66x44.jpg" alt="Aware Vehicles' Mobile Smart Docking Station"></a> <div class="imageCaptionContainer"> <div class="imageCaption">Providing real-time situational awareness and actionable insights for agricultural applications</div> <div class="imageCredit">Aware Vehicles, Inc.</div> <div class="imagePermisssions">Copyrighted</div> <div class="imageSubmitted">Jianfei&nbsp;Chen</div> <div class="imageTitle">Aware Vehicles' Mobile Smart Docking Station</div> </div> </li> </ul> </div> </div> </div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ This Small Business Innovation Research Phase I project provides a technology leap that furnishes terrain-based Farming Robotic Vehicles (FRVs) with long-range and real-time situational awareness, including pre-operation reconnaissance and post-operation evaluation. A mobile smart docking platform has been developed that provides an unlimited energy supply for drone use while serving as an edge computing and communications engine and enables the possibility of real-time high-throughput imaging, analysis and decision-making for a wide variety of agricultural applications.      The innovative features of the invention include: (1) intelligent and robust data fusion for docking an aerial drone-imaging system to a mobile FRV; (2) high-throughput hyperspectral imaging of geo-positioned plants, crop zones or other agricultural targets of interest; and (3) real-time computing to produce crop-field analytics (4-D spatial-spectral modeling) and navigation parameters for FRVs path planning. These outcomes pave the way for the next-phase studies of human-machine interface and deep learning of high-throughput phenotyping data and large-scale field development and validation.      With the global population expected to reach 9 billion by 2050 and the uncertain climate changes that create concern over the resources available to farming activities, precision agriculture has become the ultimate solution and necessity to increase agricultural productivity and efficiency. Aware Vehicles innovative system integrates advanced aerial and terrain robotics, high-throughput imaging and data analytics, pushing precision agriculture towards the next evolutionary stage... fully autonomous agriculture. With the research and development efforts in this project, the integrated aerial-terrain robotics and high-throughput imaging system will be ready for commercialization under a sustainable business model and impact farming industries globally. Moreover, systems enabled by smart and mobile docking can be readily adapted to accommodate needs in a variety of other industries, where geospatially large-scale sensing and analytics are in demand, such as civil infrastructure, disaster response (including fire-fighting), logistics and freight management and defense (including Intelligence, Surveillance and Reconnaissance).            Last Modified: 04/15/2019       Submitted by: Jianfei Chen]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
