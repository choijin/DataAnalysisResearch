<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Drawing inferences for human-like language understanding</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2019</AwardEffectiveDate>
<AwardExpirationDate>07/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>499914.00</AwardTotalIntnAmount>
<AwardAmount>499914</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>D.  Langendoen</SignBlockName>
<PO_EMAI>dlangend@nsf.gov</PO_EMAI>
<PO_PHON>7032925088</PO_PHON>
</ProgramOfficer>
<AbstractNarration>When dealing with language, readers and listeners understand more than just the literal meaning of the words they read or hear; they also draw inferences from them. For instance, if someone tells you "I said you were mad to come over at this time. It's a world event. Do you know that Venice is packed with visitors?", they will likely infer that Venice is indeed packed with visitors. However in "How long has she been like this? Did you see a doctor? Do you know that it is incurable?", they will not infer that it is incurable, even though both events are in a question and embedded under the same string of words "do you know". Different factors, like the tone used or world knowledge, play a role in deriving these inferences. The project aims at studying these factors and developing broad-coverage models that automatically capture inferences. Such models have implications for natural language processing (NLP) tasks that require an accurate inference process, such as information extraction. Further, to achieve human-like language understanding, it is not only crucial for NLP technologies to develop models that capture what is conveyed in language without being explicitly said, but to also assess whether the inferences are systematic for most people, or whether different interpretations arise. This project investigates how the variability present in "common sense" data that come from people's intuitions can be accurately represented in the type of datasets on which NLP systems are currently built, and thereby be captured. &lt;br/&gt;&lt;br/&gt;Recently a large body of work in NLP has focused on deep learning, hill-climbing on new tasks and benchmarks. However such ventures do not help with the understanding of the details of human language or in determining which features actually matter for language processing. This project targets both categorical and non-categorical inferences in a diverse set: inferences about sentiment, agreement and speaker commitment (whether speakers are committed to the truth of the events they describe), and redefining the kind of benchmarks needed to achieve human-like natural language understanding. It investigates how a better synergy between data-driven methods and the use of specialized linguistic features can lead to fundamental advances in NLP systems. The project also quantitatively studies the interactions of linguistic features on a large amount of naturally occurring examples, and has thus an impact not only for NLP but also for linguistic theories. Results will include a better grasp of how linguistic insights can be used to automatically achieve human-level understanding; a publicly available data that better fit human intuitions on language than current datasets do and can thereby serve to sharpen NLP models; and course materials for students and demos for the general public that raise awareness of societal problems engendered by social media, emphasize the importance of what gets conveyed by language beyond the explicit string of words in everyday communication, and demonstrate what can be achieved when research in linguistics and computer science is combined.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/05/2019</MinAmdLetterDate>
<MaxAmdLetterDate>06/04/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1845122</AwardID>
<Investigator>
<FirstName>Marie-Catherine</FirstName>
<LastName>de Marneffe</LastName>
<PI_MID_INIT>H</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Marie-Catherine H de Marneffe</PI_FULL_NAME>
<EmailAddress>demarneffe.1@osu.edu</EmailAddress>
<PI_PHON>6142923805</PI_PHON>
<NSF_ID>000676570</NSF_ID>
<StartDate>08/05/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2><![CDATA[1960 Kenny Road]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>OH03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>832127323</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>OHIO STATE UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001964634</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Ohio State University]]></Name>
<CityName/>
<StateCode>OH</StateCode>
<ZipCode>432101016</ZipCode>
<StreetAddress/>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>OH03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~155697</FUND_OBLG>
<FUND_OBLG>2020~344217</FUND_OBLG>
</Award>
</rootTag>
