<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Learning Symbolic Representations for Robot Manipulation</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2019</AwardEffectiveDate>
<AwardExpirationDate>03/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>549988.00</AwardTotalIntnAmount>
<AwardAmount>565988</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent years have seen a dramatic improvement in the quality and cost of general-purpose robot hardware. However, programming that hardware to solve any non-trivial task is extremely hard. It would be far preferable if robots could plan to reach user-specified goals on their own, without requiring highly detailed programming. A key challenge here is dealing with the low-level details of sensing and perception, while also reasoning at a high-level about the task to be completed. This project aims to develop a framework that allows robots to learn how to manipulate objects, how to usefully represent those objects abstractly, and how to generalize across objects that appear different but have the same functionality (e.g., different microwaves). This project will develop new algorithms that will enable robots to reason and plan in complex scenarios in the real world; it could therefore substantially accelerate the deployment of complex robots in semi-structured environments like the home, hospitals, light manufacturing facilities, and space. &lt;br/&gt;&lt;br/&gt;This project aims to enable robots to autonomously learn reusable object-centric motor skills and the portable symbolic representations that support planning with those skills.  Learning motor skills to manipulate, and abstract representations to reason about, objects in the world---while generalizing across objects of similar functionality---will enable robots to generate intelligent, goal-directed mobile manipulation behavior. The project will 1) design practical algorithms that discover motor skills for manipulating objects by interacting with them, 2) design algorithms for generalizing those skills across objects with different appearances but similar functionality, and 3) develop a theoretically sound framework for learning object-centric abstract representations that support goal-directed planning using those skills, and demonstrate its use on a mobile manipulation robot.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/25/2019</MinAmdLetterDate>
<MaxAmdLetterDate>07/07/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1844960</AwardID>
<Investigator>
<FirstName>George</FirstName>
<LastName>Konidaris</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>George D Konidaris</PI_FULL_NAME>
<EmailAddress>George_konidaris@brown.edu</EmailAddress>
<PI_PHON>4018632777</PI_PHON>
<NSF_ID>000732307</NSF_ID>
<StartDate>03/25/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129093</ZipCode>
<StreetAddress><![CDATA[Office of Sponsored Projects]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~112323</FUND_OBLG>
<FUND_OBLG>2020~131533</FUND_OBLG>
<FUND_OBLG>2021~322132</FUND_OBLG>
</Award>
</rootTag>
