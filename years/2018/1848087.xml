<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Signal Recovery from Generative Priors</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2019</AwardEffectiveDate>
<AwardExpirationDate>06/30/2024</AwardExpirationDate>
<AwardTotalIntnAmount>434989.00</AwardTotalIntnAmount>
<AwardAmount>255979</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Victor Roytburd</SignBlockName>
<PO_EMAI>vroytbur@nsf.gov</PO_EMAI>
<PO_PHON>7032928584</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Recent progress in artificial intelligence and machine learning has led to exceptional performance in tasks involving understanding what objects are in digital images.  These developments enable a new class of algorithms for Magnetic Resonance Imaging, astronomical imaging, microscopy, and imaging based on X-ray diffractions.  These new algorithms have the potential to drastically reduce the time and expense of scientific and medical data collection for the purpose of imaging.  For example, using these techniques, MRI machines could increase in efficiency, allowing shorter scan times and shorter waits for medical care.  Additionally, these new techniques can accelerate the process of drug discovery and development by minimizing the cost of imaging of molecules.  While some new algorithms have recently appeared, theoretical understanding of them is currently minimal.  This is a serious concern as technology, upon which professionals make scientific discoveries and medical diagnoses, should be reliable in common and novel situations.  The investigator and his colleagues introduce novel approaches for recovering images, scientific and medical, that succeed while needing less data than earlier methods.  Additionally, the investigator and his colleagues provide mathematical justification for why such imaging methods recover a sufficiently high-quality image.  Graduate students are engaged in the research of the project.&lt;br/&gt;&lt;br/&gt;The investigator and his colleagues develop a rigorous recovery theory for multiple signal recovery problems in the context of generative neural network priors.  These problems are linear compressed sensing, phase retrieval, and blind deconvolution.  In each, the recovery problem is phrased as a nonconvex optimization under the constraint that the desired signal belongs to the range of a pre-trained generative model given by an artificial neural network.  For each problem, the investigator and his colleagues provide (1) computationally efficient, specific numerical algorithms with convergence guarantees that (2) operate at optimal sample complexity with respect to the dimensionality of the modeled manifold of natural signals, and (3) apply to realistic neural network architectures.  The impact of this work follows from two ideas: (1) generative priors learned from data may provide lower-dimensional representations than sparsity priors in many contexts; and (2) generative priors may be easier to exploit than sparsity priors in nonlinear inverse problems such as phase retrieval.  Graduate students are engaged in the research of the project.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/05/2019</MinAmdLetterDate>
<MaxAmdLetterDate>06/28/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1848087</AwardID>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Hand</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Paul Hand</PI_FULL_NAME>
<EmailAddress>p.hand@northeastern.edu</EmailAddress>
<PI_PHON>6265904727</PI_PHON>
<NSF_ID>000576228</NSF_ID>
<StartDate>03/05/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northeastern University</Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress>360 HUNTINGTON AVE</StreetAddress>
<StreetAddress2><![CDATA[177-500]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001423631</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001423631</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>Boston</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 Huntington Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1266</Code>
<Text>APPLIED MATHEMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>079Z</Code>
<Text>Machine Learning Theory</Text>
</ProgramReference>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<Appropriation>
<Code>0119</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2019~83602</FUND_OBLG>
<FUND_OBLG>2020~74421</FUND_OBLG>
<FUND_OBLG>2021~97956</FUND_OBLG>
</Award>
</rootTag>
