<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI:Small: Nonlinear signal representations for speech applications</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>336814.00</AwardTotalIntnAmount>
<AwardAmount>336814</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Human speech is a very rich signal. In addition to words, it contains several kinds of important information about the speaker such as identity, gender, age, native language, dialect, and emotion. It also provides information about the transmission channel and environment; for example, whether the speech came from a phone call or a high-fidelity recording, and whether or not there was background noise.   This project aims to create a powerful uniform representation that reflects all the information carried by speech. Such representation would enable important speech applications in multiple sectors of society: commercial (security, healthcare, user interfaces), government (security, information filtering), and law enforcement (speaker identification, forensics).&lt;br/&gt;&lt;br/&gt;In this project, Johns Hopkins University researchers, who invented the original i-vector framework, intend to progress beyond the linear i-vector approach by investigating non-linear models with the expectation to better explain the complex structure of speech. To achieve this goal, two different models are investigated. First, a non-linear i-vector version is explored. In this method, the speech signal distribution is modeled by a Gaussian mixture model (GMM). The super-vector formed by the GMM means is a non-linear function (neural network) of a latent variable (speech representation). The parameters of the neural network and the latent representation can be jointly estimated by stochastic gradient descent iterations. Secondly, the team intends to investigate different types of auto-encoder networks (AE, VAE, RBM, DBM) to obtain representations from their hidden layers. Preliminary research shows that it is feasible to obtain good representations by combining activations from several hidden layers. Visualization tools are used to understand how the speech data have been represented and structured. By understanding the non-linear relationships created via the auto-encoder network modeling and using the visualization tools, there is potential to produce valuable insights into speech modeling. These insights can help cognitive science and neuroscience researchers to understand how the brain represents speech signals. The proposed methods are developed as software that takes a speech segment as input and generates a single vector that may be used to characterize the segment for the important applications mentioned in the previous paragraph.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/02/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1816165</AwardID>
<Investigator>
<FirstName>Najim</FirstName>
<LastName>Dehak</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Najim Dehak</PI_FULL_NAME>
<EmailAddress>ndehak3@jhu.edu</EmailAddress>
<PI_PHON>8575441625</PI_PHON>
<NSF_ID>000724141</NSF_ID>
<StartDate>08/02/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jesus</FirstName>
<LastName>Villalba Lopez</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jesus Villalba Lopez</PI_FULL_NAME>
<EmailAddress>jesus.antonio.villalba@gmail.com</EmailAddress>
<PI_PHON>4105168668</PI_PHON>
<NSF_ID>000764206</NSF_ID>
<StartDate>08/02/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Johns Hopkins University</Name>
<CityName>Baltimore</CityName>
<ZipCode>212182686</ZipCode>
<PhoneNumber>4439971898</PhoneNumber>
<StreetAddress>1101 E 33rd St</StreetAddress>
<StreetAddress2><![CDATA[Suite B001]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<StateCode>MD</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MD07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001910777</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>JOHNS HOPKINS UNIVERSITY, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001910777</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Johns Hopkins University]]></Name>
<CityName>Baltimore</CityName>
<StateCode>MD</StateCode>
<ZipCode>212182686</ZipCode>
<StreetAddress><![CDATA[3400 N. Charles St.]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Maryland</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MD07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~336814</FUND_OBLG>
</Award>
</rootTag>
