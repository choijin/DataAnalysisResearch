<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Estimation of Smooth Functionals of Covariance and Other Parameters of High-Dimensional Models</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2018</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>250000.00</AwardTotalIntnAmount>
<AwardAmount>250000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Gabor Szekely</SignBlockName>
<PO_EMAI>gszekely@nsf.gov</PO_EMAI>
<PO_PHON>7032928869</PO_PHON>
</ProgramOfficer>
<AbstractNarration>A crucial problem in statistical inference for complex, high-dimensional data is to develop statistical estimators of parameters represented by high-dimensional vectors or large matrices. Optimal error rates in such estimation problems are often rather slow due to the ``curse of dimensionality", and it becomes increasingly important to identify low-dimensional structures and features of high-dimensional parameters that could be estimated efficiently with error rates common in classical, ``low-dimensional" statistics. Such features are often represented by functionals that depend smoothly of unknown parameters and the goal is to take advantage of their smoothness to develop efficient estimation procedures. The problems of this nature often occur in a variety of applications such as signal and image processing, machine learning and data analytics.  The purpose of this project is to study these problems systematically and to develop new approaches to efficient estimation of smooth functionals. The project is in an interdisciplinary area between mathematics, statistics and computer science and it includes a number of activities to facilitate interactions with researchers in these areas and to ensure the impact of proposed research on education. &lt;br/&gt;&lt;br/&gt;The main focus of the project is on the development of general methods of estimation of smooth functionals of covariance operators based on high-dimensional or infinite-dimensional observations. It is expected that these methods will be applicable to other important high-dimensional  models such as Gaussian shift models (both in vector and in matrix case); linear regression models (including trace regression and regression models in quantum state tomography); some non-linear models. The methods to be developed include a new approach to bias reduction in smooth functional estimation problems based on iterative application of bootstrap (bootstrap chains) and concentration and normal approximation bounds needed to establish asymptotic efficiency of estimators with reduced bias. The goal is to determine optimal smoothness thresholds for functionals of interest that ensure their efficient estimation, in particular, in a dimension free high-complexity setting, with complexity of the problem characterized by the effective rank of the true covariance. Other directions include the study of efficient estimation of smooth functionals under regularity assumptions on the parameter set and applications of methods of functional estimation to hypotheses testing for high-dimensional parameters.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/07/2018</MinAmdLetterDate>
<MaxAmdLetterDate>05/07/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1810958</AwardID>
<Investigator>
<FirstName>Vladimir</FirstName>
<LastName>Koltchinskii</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vladimir Koltchinskii</PI_FULL_NAME>
<EmailAddress>vlad@math.gatech.edu</EmailAddress>
<PI_PHON>4048942718</PI_PHON>
<NSF_ID>000118109</NSF_ID>
<StartDate>05/07/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>097394084</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORPORATION</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>097394084</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Institute of Technology]]></Name>
<CityName>Atlanta</CityName>
<StateCode>GA</StateCode>
<ZipCode>303320002</ZipCode>
<StreetAddress><![CDATA[225 North Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<Appropriation>
<Code>0118</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2018~250000</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>The main outcomes of the project include the development of new methods of statistical estimation of low dimensional features of complex, high-dimensional parameters of statistical models. Such methods are of importance in a variety of applications of high-dimensional statistical inference in such areas as machine learning, signal and image processing, quantum statistics. These methods are based on a novel approch to bias reduction in high-dimensional statistics and they yield nearly optimal statistical estimators of the features of interest. In particular, this includes estimators of spectral characteristics of high-dimensional covariance matrices that are of importance in principal component analysis and other problems of high-dimensional statistics. The results of the project include the derivation of sharp bounds on statistical errors of resulting estimators establishing their optimality properties. The proofs of these bounds required the development of a number of mathematical tools such as concentration inequalities, coupling methods and bias reduction techniques. The results of the project were discussed at many international conferences and presented in series of lectures. A number of educational activities were closely related to this project, including supervising graduate students; the development of new graduate level courses on high-dimensional probability and statistics;&nbsp; incorporating topics related to this project to other graduate courses; offering special topics and reading courses.</p><br> <p>            Last Modified: 08/16/2021<br>      Modified by: Vladimir&nbsp;Koltchinskii</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ The main outcomes of the project include the development of new methods of statistical estimation of low dimensional features of complex, high-dimensional parameters of statistical models. Such methods are of importance in a variety of applications of high-dimensional statistical inference in such areas as machine learning, signal and image processing, quantum statistics. These methods are based on a novel approch to bias reduction in high-dimensional statistics and they yield nearly optimal statistical estimators of the features of interest. In particular, this includes estimators of spectral characteristics of high-dimensional covariance matrices that are of importance in principal component analysis and other problems of high-dimensional statistics. The results of the project include the derivation of sharp bounds on statistical errors of resulting estimators establishing their optimality properties. The proofs of these bounds required the development of a number of mathematical tools such as concentration inequalities, coupling methods and bias reduction techniques. The results of the project were discussed at many international conferences and presented in series of lectures. A number of educational activities were closely related to this project, including supervising graduate students; the development of new graduate level courses on high-dimensional probability and statistics;  incorporating topics related to this project to other graduate courses; offering special topics and reading courses.       Last Modified: 08/16/2021       Submitted by: Vladimir Koltchinskii]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
