<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ABI Innovation: A New Automated Data Integration, Annotations, and Interaction Network Inference System for Analyzing Drosophila Gene Expression</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2017</AwardEffectiveDate>
<AwardExpirationDate>10/31/2019</AwardExpirationDate>
<AwardTotalIntnAmount>112577.00</AwardTotalIntnAmount>
<AwardAmount>112577</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>08080000</Code>
<Directorate>
<Abbreviation>BIO</Abbreviation>
<LongName>Direct For Biological Sciences</LongName>
</Directorate>
<Division>
<Abbreviation>DBI</Abbreviation>
<LongName>Div Of Biological Infrastructure</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter McCartney</SignBlockName>
<PO_EMAI>pmccartn@nsf.gov</PO_EMAI>
<PO_PHON>7032928470</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Large-scale in situ hybridization (ISH) screens are providing an abundance of data showing spatio-temporal patterns of gene expression that are valuable for understanding the mechanisms of gene regulation. Knowledge gained from analysis of Drosophila expression patterns is widely important, because a large number of genes involved in fruit fly development are commonly found in humans and other species. Thus, research efforts into the spatial and temporal characteristics of Drosophila gene expression images have been at the leading-edge of scientific investigations into the fundamental principles of different species development. Drosophila gene expression pattern images enable the integration of spatial expression patterns with other genomic datasets that link regulator with their downstream targets. This project addresses the computational challenges in analyzing Drosophila gene expression patterns by leveraging a new bioinformatics software system. It focuses on designing principled bioinformatics and computational biology algorithms and tools that will integrate multi-modal spatial patterns of gene expression for Drosophila embryos' developmental stage recognition and anatomical ontology term annotation, and will infer gene interaction networks to generate a more comprehensive picture of gene function and interaction. The bioinformatics methods resulting from the project activities are broadly applicable to a variety of fields such as biomedical science and engineering, systems biology, clinical pathology, oncology, and pharmaceutics. Novel tools to enhance courses and research experiences for diverse populations of students are planned to broaden participation in science. &lt;br/&gt;&lt;br/&gt;This project investigates three challenging problems for studying the Drosophila embryo ISH Images via innovative bioinformatics algorithms: 1) the sparse multi-dimensional feature learning method to integrate the multimodal spatial gene expression patterns for annotating Drosophila ISH images, 2) the heterogeneous multi-task learning models using the high-order relational graph to jointly recognize the developmental stages and annotate anatomical ontology terms, 3) the embedded sparse representation algorithm to infer the gene interaction network. It is innovative to apply structured sparse learning, multi-task learning, and high-order relational graph models to Drosophila gene expression patterns analysis and holds great promise for scientific investigations into the fundamental principles of animal development. The algorithms and tools as outcomes of this research are expected to help knowledge discovery for applications in broader scientific and biological domains with massive high-dimensional and heterogeneous data sets. This project facilitates the development of novel educational tools to enhance several current courses at University of Texas at Arlington. The PIs engage minority students and under-served populations in research activities to provide opportunities for exposure to cutting-edge scientific research. For further information see the web site at: http://ranger.uta.edu/~heng/NSF-DBI-1356628.html</AbstractNarration>
<MinAmdLetterDate>07/26/2018</MinAmdLetterDate>
<MaxAmdLetterDate>07/26/2018</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.074</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>1836866</AwardID>
<Investigator>
<FirstName>Heng</FirstName>
<LastName>Huang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Heng Huang</PI_FULL_NAME>
<EmailAddress>heng.huang@pitt.edu</EmailAddress>
<PI_PHON>4123834421</PI_PHON>
<NSF_ID>000086248</NSF_ID>
<StartDate>07/26/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pittsburgh</Name>
<CityName>Pittsburgh</CityName>
<ZipCode>152133203</ZipCode>
<PhoneNumber>4126247400</PhoneNumber>
<StreetAddress>300 Murdoch Building</StreetAddress>
<StreetAddress2><![CDATA[3420 Forbes Avenue]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>004514360</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF PITTSBURGH, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>004514360</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pittsburgh]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152132303</ZipCode>
<StreetAddress><![CDATA[123 University Place]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1165</Code>
<Text>ADVANCES IN BIO INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0114</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2014~112577</FUND_OBLG>
<POR>
<DRECONTENT><![CDATA[<div class="porColContainerWBG"> <div class="porContentCol"><p>Our research findings are highly relevant to the interdisciplinary research of machine learning and bioinformatics. The investigation of this project produces several important outcomes.</p> <p>&nbsp;</p> <p>1. We developed new multi-dimensional visual descriptors integration algorithm for Drosophila gene expression patterns anatomical annotations. To facilitate the search and comparison of Drosophila gene expression patterns during Drosophila embryogenesis, it is highly desirable to annotate the tissue-level anatomical ontology terms for ISH images. In ISH image annotations, the image content representation is crucial to achieve satisfactory results. However, existing methods mainly focus on improving the classification algorithms and only using simple visual descriptor. We proposed a novel structured sparsity-inducing norms based feature learning model to integrate the multi-dimensional visual descriptors for Drosophila gene expression patterns annotations. The new mixed norms are designed to learn the importance of different features from both local and global point of views. We successfully integrated six widely used visual descriptors to annotate the Drosophila gene expression patterns from the lateral, dorsal, and ventral views. The empirical results show that the proposed new method can effectively integrate different visual descriptors, and consistently outperforms related methods using the concatenated visual descriptors.</p> <p>&nbsp;</p> <p>2. We developed a novel multi-instance learning model with learning biological relevance for Drosophila ISH image annotations. We explored the multi-instance learning (MIL) model for annotating Drosophila ISH gene expression images. We proposed to directly assess the relevance between annotation terms and image panels by using the Class-to-Bag (C2B) distance for MIL. We apply our new approach to automatic gene expression pattern classification and annotation on the Drosophila melanogaster species. Our experiments demonstrated the effectiveness of the new multi-instance learning method.</p> <p>&nbsp;</p> <p>3. We conducted biological network inference via minimizing joint capped norms based matrix recovery model. We used the low-rank matrix recovery model to predict the new links in biological networks. We proposed a new robust matrix recovery model to address the above two challenges. The joint capped trace norm and capped L1-norm are used to tightly approximate the rank minimization and enhance the robustness to outliers. The evaluation experiments are performed on both synthetic data and network link prediction task. All empirical results show our new method outperforms the existing matrix recovery methods. We applied the new model to infer the incomplete gene interaction network from Drosophila gene expression images.</p> <p>&nbsp;</p> <p>4. We also designed new deep learning model to infer the incomplete gene interaction network from Drosophila gene expression images. We used the emerging deep neural network embedding model to predict the new links in biological networks. Network embedding has attracted increasing attention in recent data mining research with many important applications. We proposed a novel self-paced network embedding method. Specifically, our method can adaptively capture the informativeness of each node based on the current training state, and sample negative context nodes in terms of their informativeness. The proposed self-paced sampling strategy can gradually select difficult negative context nodes with training process going on to learn better node representations. Moreover, to better capture the node informativeness for learning node representations, we extended our method to the generative adversarial network framework, which has the larger capacity to discover node informativeness. The extensive experiments have been conducted on the biological network datasets to validate the effectiveness of our proposed methods.</p> <p>&nbsp;</p> <p>5. We addressed the fast image retrieval problem of Drosophila gene expression data via designing a new unsupervised deep generative adversarial hashing network method. Considering the labeled Drosophila images are lacking, we proposed a new deep unsupervised hashing function, called HashGAN, which efficiently obtains binary representation of input Drosophila images without any supervised pretraining. In our experiments, HashGAN outperforms the previous unsupervised hash functions in image retrieval and achieves the state-of-the-art performance on various datasets.</p> <p>&nbsp;</p> <p>6. We designed new bilevel distance metric learning model to enhance the Drosophila gene expression image annotations. We integrated both feature extraction and metric learning into one joint optimization framework and proposed a new bilevel distance metric learning model. Specifically, the lower level characterizes the intrinsic data structure using graph regularized sparse coefficients, while the upper level forces the data samples from the same class to be close to each other and pushes those from different classes far away. Experiments on Drosophila gene expression image data demonstrated the effectiveness and robustness of our method.</p> <p>&nbsp;</p> <p>7. We released the machine learning software tools at the project website.</p> <p>&nbsp;</p> <p>We published over 40 full-length papers related to this project in peer-reviewed conference proceedings and journals.</p> <p>&nbsp;</p> <p>This project supported three Ph.D. students (one of them is female) at University of Pittsburgh and University of Texas at Arlington. All of them have graduated and one of them becomes a tenure-track assistant professor in Purdue University.</p> <p>&nbsp;</p> <p>The research materials produced in this project are used in teaching several graduate courses at University of Texas at Arlington and University of Pittsburgh.</p><br> <p>            Last Modified: 03/13/2020<br>      Modified by: Heng&nbsp;Huang</p> </div> <div class="porSideCol"></div> </div>]]></DRECONTENT>
<POR_COPY_TXT><![CDATA[ Our research findings are highly relevant to the interdisciplinary research of machine learning and bioinformatics. The investigation of this project produces several important outcomes.     1. We developed new multi-dimensional visual descriptors integration algorithm for Drosophila gene expression patterns anatomical annotations. To facilitate the search and comparison of Drosophila gene expression patterns during Drosophila embryogenesis, it is highly desirable to annotate the tissue-level anatomical ontology terms for ISH images. In ISH image annotations, the image content representation is crucial to achieve satisfactory results. However, existing methods mainly focus on improving the classification algorithms and only using simple visual descriptor. We proposed a novel structured sparsity-inducing norms based feature learning model to integrate the multi-dimensional visual descriptors for Drosophila gene expression patterns annotations. The new mixed norms are designed to learn the importance of different features from both local and global point of views. We successfully integrated six widely used visual descriptors to annotate the Drosophila gene expression patterns from the lateral, dorsal, and ventral views. The empirical results show that the proposed new method can effectively integrate different visual descriptors, and consistently outperforms related methods using the concatenated visual descriptors.     2. We developed a novel multi-instance learning model with learning biological relevance for Drosophila ISH image annotations. We explored the multi-instance learning (MIL) model for annotating Drosophila ISH gene expression images. We proposed to directly assess the relevance between annotation terms and image panels by using the Class-to-Bag (C2B) distance for MIL. We apply our new approach to automatic gene expression pattern classification and annotation on the Drosophila melanogaster species. Our experiments demonstrated the effectiveness of the new multi-instance learning method.     3. We conducted biological network inference via minimizing joint capped norms based matrix recovery model. We used the low-rank matrix recovery model to predict the new links in biological networks. We proposed a new robust matrix recovery model to address the above two challenges. The joint capped trace norm and capped L1-norm are used to tightly approximate the rank minimization and enhance the robustness to outliers. The evaluation experiments are performed on both synthetic data and network link prediction task. All empirical results show our new method outperforms the existing matrix recovery methods. We applied the new model to infer the incomplete gene interaction network from Drosophila gene expression images.     4. We also designed new deep learning model to infer the incomplete gene interaction network from Drosophila gene expression images. We used the emerging deep neural network embedding model to predict the new links in biological networks. Network embedding has attracted increasing attention in recent data mining research with many important applications. We proposed a novel self-paced network embedding method. Specifically, our method can adaptively capture the informativeness of each node based on the current training state, and sample negative context nodes in terms of their informativeness. The proposed self-paced sampling strategy can gradually select difficult negative context nodes with training process going on to learn better node representations. Moreover, to better capture the node informativeness for learning node representations, we extended our method to the generative adversarial network framework, which has the larger capacity to discover node informativeness. The extensive experiments have been conducted on the biological network datasets to validate the effectiveness of our proposed methods.     5. We addressed the fast image retrieval problem of Drosophila gene expression data via designing a new unsupervised deep generative adversarial hashing network method. Considering the labeled Drosophila images are lacking, we proposed a new deep unsupervised hashing function, called HashGAN, which efficiently obtains binary representation of input Drosophila images without any supervised pretraining. In our experiments, HashGAN outperforms the previous unsupervised hash functions in image retrieval and achieves the state-of-the-art performance on various datasets.     6. We designed new bilevel distance metric learning model to enhance the Drosophila gene expression image annotations. We integrated both feature extraction and metric learning into one joint optimization framework and proposed a new bilevel distance metric learning model. Specifically, the lower level characterizes the intrinsic data structure using graph regularized sparse coefficients, while the upper level forces the data samples from the same class to be close to each other and pushes those from different classes far away. Experiments on Drosophila gene expression image data demonstrated the effectiveness and robustness of our method.     7. We released the machine learning software tools at the project website.     We published over 40 full-length papers related to this project in peer-reviewed conference proceedings and journals.     This project supported three Ph.D. students (one of them is female) at University of Pittsburgh and University of Texas at Arlington. All of them have graduated and one of them becomes a tenure-track assistant professor in Purdue University.     The research materials produced in this project are used in teaching several graduate courses at University of Texas at Arlington and University of Pittsburgh.       Last Modified: 03/13/2020       Submitted by: Heng Huang]]></POR_COPY_TXT>
</POR>
</Award>
</rootTag>
