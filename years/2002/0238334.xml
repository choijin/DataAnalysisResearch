<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER:     Social Robots and Human Social Development</AwardTitle>
<AwardEffectiveDate>03/15/2003</AwardEffectiveDate>
<AwardExpirationDate>02/29/2008</AwardExpirationDate>
<AwardTotalIntnAmount>432286.00</AwardTotalIntnAmount>
<AwardAmount>432286</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Paul Yu Oh</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project focuses on the development of anthropomorphic robots that interact with people using natural social cues.  Socially-competent robots would have great practical impact; users could interact with these robots in a more natural and effortless way, could command them through social instruction, and could integrate them into daily life.  This project seeks to address both the technical challenges involved in constructing these robots and the ways in which they can be used as tools to study human social development.&lt;br/&gt;&lt;br/&gt;The technical challenges of building social robots are substantial.  The design and construction of a robot that can produce gestures and utterances which can be easily interpreted by a human observer is a challenging mechanical design problem.  A more difficult technical challenge will be to build machines that can recognize human social cues such as pointing gestures, direction of gaze, and tone of voice.  Existing research succeeds in recognizing a few of these cues in structured situations, requiring visual scenes that have a constant background or audio signals that contain only the voice of a single speaker.  This project proposes to build on existing work by integrating techniques from multiple sensory modalities and using models of human social development as a roadmap for constructing more complex social behaviors.  A final engineering challenge will be the implementation of a computational infrastructure to support these algorithms.  &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>02/27/2003</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2007</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0238334</AwardID>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Scassellati</LastName>
<EmailAddress>brian.scassellati@yale.edu</EmailAddress>
<StartDate>02/27/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>New Haven</CityName>
<ZipCode>065208327</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>Office of Sponsored Projects</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
