<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RUI: Machine Learning of Improvisational Time Series</AwardTitle>
<AwardEffectiveDate>09/01/2002</AwardEffectiveDate>
<AwardExpirationDate>08/31/2006</AwardExpirationDate>
<AwardTotalIntnAmount>188366.00</AwardTotalIntnAmount>
<AwardAmount>188366</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Edwina L. Rissland</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This award for research at an undergraduate institution will support the development and testing of methods to create recurrent reinforcement learning neural networks that can solve challenging problems related to time series generation and analysis.  There are two main attributes of improvisation that make it an excellent research area for machine learning.  First, it is a procedure in which one makes up a solution to a problem in real-time, using available materials and knowledge, and in response to environmental effects.  Second, it requires variety, modifying the solution from one time to another, even under the same conditions.  Yet the overall result must be cohesive from beginning to end.  Thus, improvisation is a significant challenge for computer science.&lt;br/&gt;&lt;br/&gt;This project will extend the range of problems that can be solved, through a fusion of two separate methods.  The first is recurrent neural networks, that are nonlinear neural networks in which the outputs of parts of the network are fed back to provide input to some or all parts of the network.  They are emerging as feedback systems that can learn to model non-Markov processes, can learn to predict values in a time series, and can learn to generate actions or control signals that depend on past behavior.  The second method is reinforcement learning, an area of machine learning that has taken on an important role in computationally solving problems that are characterized by sparse feedback as to whether a proposed solution is correct, given a situation or state.  Human beings have a much greater ability than machines currently do to improvise in uncertain environments, and the ability to extemporize would be a very important asset for intelligent software systems.&lt;br/&gt;&lt;br/&gt;In addition to supporting promising research, this award will encourage broader participation of women in science, by involving women in research and by helping to enable progress in computer science at a college for women.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/23/2002</MinAmdLetterDate>
<MaxAmdLetterDate>08/23/2002</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0222541</AwardID>
<Investigator>
<FirstName>Judy</FirstName>
<LastName>Franklin</LastName>
<EmailAddress>jfrankli@scinix.smith.edu</EmailAddress>
<StartDate>08/23/2002</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Smith College</Name>
<CityName>Northampton</CityName>
<ZipCode>010636304</ZipCode>
<PhoneNumber>4135842700</PhoneNumber>
<StreetAddress>10 ELM STREET</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
