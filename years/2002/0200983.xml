<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Synthesis and Acquisition of Communicative Gestures</AwardTitle>
<AwardEffectiveDate>09/15/2002</AwardEffectiveDate>
<AwardExpirationDate>08/31/2005</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>427000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Procedural synthesis of natural and contextually appropriate gestures in embodied virtual human agents is challenging.  Laban Movement Analysis (LMA) offers a descriptive system for human gesture qualities that fills the gap between pre-defined gesture playback systems and human animator intuition.  A computational analog of LMA called EMOTE has been constructed whose parameters modify the performance qualities of arm gesture movements.  EMOTE will be developed in several new ways:&lt;br/&gt;&lt;br/&gt;* Connect EMOTE with an agent model so that an agent's affect, personality, and communicative needs set appropriate EMOTE parameters for gesture performance.&lt;br/&gt;&lt;br/&gt;* Investigate motion analysis techniques for extracting EMOTE parameters from live dual or single camera views.&lt;br/&gt;&lt;br/&gt;* Experimentally validate the automated acquisition of EMOTE parameters by using professional LMA notators for ground truth.&lt;br/&gt;&lt;br/&gt;* Use the extracted parameters to create instances of parameterized actions which may be subsequently used for action, affect, and manner descriptions and, ultimately, for content-directed analysis of existing film or video material.&lt;br/&gt;&lt;br/&gt;This study will help set synthetic agent animation techniques on a sound empirical footing, provide evidence that computers can in fact observe important motion qualities, and lead to strong connections between internal agent state and external behavior qualities.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>09/13/2002</MinAmdLetterDate>
<MaxAmdLetterDate>04/14/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0200983</AwardID>
<Investigator>
<FirstName>Norman</FirstName>
<LastName>Badler</LastName>
<EmailAddress>badler@central.cis.upenn.edu</EmailAddress>
<StartDate>09/13/2002</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Dimitris</FirstName>
<LastName>Metaxas</LastName>
<EmailAddress>dnm@cs.rutgers.edu</EmailAddress>
<StartDate>09/13/2002</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>6845</Code>
<Text>HUMAN COMPUTER INTER PROGRAM</Text>
</ProgramElement>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
