<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ITR: High Performance Imaging Using an Array of Low-Cost Cameras</AwardTitle>
<AwardEffectiveDate>08/01/2002</AwardEffectiveDate>
<AwardExpirationDate>07/31/2006</AwardExpirationDate>
<AwardTotalIntnAmount>497409.00</AwardTotalIntnAmount>
<AwardAmount>497409</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Stephen Griffin</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project will explore the capabilities of an array of 128 cameras, which can be combined computationally in many different configurations for a wide range of scientific, commercial, and communication applications.  Over the past few years, the ability of image-based rendering (IBR) techniques to create photorealistic images of real scenes has generated great interest in building sensor systems that can capture environments from multiple viewpoints.  At the same time, we have witnessed the advent of CMOS image sensors, which are inexpensive and easy to use because of their digital interface. Furthermore, because they are manufactured in a CMOS process, processing power can be placed on the sensors themselves.  Finally, advances in semiconductor technology are making increasing computing power available for decreasing cost, power, and chip area.  These trends raise the questions: What can we do with many inexpensive CMOS image sensors, equally inexpensive optics, and a lot of processing power?  Can we use more cameras of lesser quality to enable more robust IBR algorithms?  Can we use clusters of inexpensive imagers and processors to create virtual cameras that outperform real ones?&lt;br/&gt;&lt;br/&gt;Each camera in the 128-camera array contains a CMOS image sensor, MPEG encoder, and programmable processor, in order to investigate these questions.  The device is designed to record 128 synchronized video datasets through three PCs to a disk array.  This project will explore applications of the array to scientific imaging and computer vision and graphics. Multi-camera systems can function in many ways.  If the cameras are packed close together, then the system effectively functions as a single-center-of-projection synthetic camera, which can be configured to provide high performance along one or more imaging dimensions, such as resolution, signal-to-noise ratio, dynamic range, depth of field, frame rate, or spectral sensitivity. For example, one configuration could produce high-resolution images 10,240 x 3,830 pixels, and another could generate 7,680 frames per second.  Such capabilities are unprecedented for a video system, and they will have many scientific, engineering, and military uses. &lt;br/&gt;&lt;br/&gt;If the cameras are placed farther apart, then the system functions as a multiple-center-of-projection camera, and the data it captures is called a light field.  Of particular interest are novel methods for estimating 3D scene geometry from the dense imagery captured by the array.  This information can be used to improve compression of the light field and to interpolate smoothly between widely spaced cameras, allowing smooth virtual navigation through the scene.  Potential applications include evaluation of design models for manufacturing, medical and forensic consultation, online shopping, and virtual museum displays.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/12/2002</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2004</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0219856</AwardID>
<Investigator>
<FirstName>Marc</FirstName>
<LastName>Levoy</LastName>
<EmailAddress>levoy@cs.stanford.edu</EmailAddress>
<StartDate>08/12/2002</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stanford University</Name>
<CityName>Stanford</CityName>
<ZipCode>943052004</ZipCode>
<PhoneNumber>6507232300</PhoneNumber>
<StreetAddress>450 Jane Stanford Way</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>1686</Code>
<Text>ITR SMALL GRANTS</Text>
</ProgramElement>
<ProgramReference>
<Code>1655</Code>
<Text>INFORMATION MANAGEMENT</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
