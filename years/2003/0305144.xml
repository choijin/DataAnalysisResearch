<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NGS: Collaborative Research:  Adapting Program Code Continuously and Aggressively</AwardTitle>
<AwardEffectiveDate>09/01/2003</AwardEffectiveDate>
<AwardExpirationDate>08/31/2007</AwardExpirationDate>
<AwardTotalIntnAmount>532411.00</AwardTotalIntnAmount>
<AwardAmount>532411</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anita La Salle</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Much of the past and recent research in program optimization has focused on developing new algorithms to perform a particular optimization or transformation. Indeed, over the previous decade the compiler research community has developed  sophisticated, powerful optimization  algorithms for a variety of code improvements: register allocation and assignment, common subexpression elimination, partial redundancy elimination, loop optimizations (e.g., loop fusion, loop unrolling, loop interchange, etc.), code scheduling, and function inlining to name a few. While there are still avenues of promising research for particular optimizations, we are at the point where the performance gains of a new or improved optimization algorithm is usually small?an improvement of a few percent is typical.  Today?s  challenge  for  optimization  research  is  to  develop  new  techniques  and approaches  that  yield  performance improvements that go beyond today?s small single digit improvements. In this research, we address this challenge by investigating and developing an innovative framework and system for continuously and adaptively applying optimizations.  Our system, the Continuous Compiler (CoCo), applies optimizations both statically at compile-time and dynamically at run-time using optimization plans developed at compile time and adapted at run time.&lt;br/&gt;Rather than focusing on developing new optimization algorithms (e.g., a new register allocation algorithm, a&lt;br/&gt;new loop interchange algorithm) or improving existing optimizations (e.g., better coloring heuristics, better placement algorithms), the proposed research focuses on understanding the interaction of existing optimizations and the efficacy  of  static  and  dynamic  optimizations.  Using  this  knowledge  along  with  information  about  the  application gathered by static analysis, profile information and monitoring, CoCo will determine how to apply a suite of optimizations so that the optimizations work in concert to yield the best improvements. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/26/2003</MinAmdLetterDate>
<MaxAmdLetterDate>07/26/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0305144</AwardID>
<Investigator>
<FirstName>Jack</FirstName>
<LastName>Davidson</LastName>
<EmailAddress>jwd@virginia.edu</EmailAddress>
<StartDate>08/26/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>2884</Code>
<Text>NEXT GENERATION SOFTWARE PROGR</Text>
</ProgramElement>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
