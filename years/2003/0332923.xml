<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>New Methods for Maintaining Good Stereoscopic Viewing During Interaction with Large-Scale Head-Tracked Displays</AwardTitle>
<AwardEffectiveDate>03/10/2003</AwardEffectiveDate>
<AwardExpirationDate>07/31/2004</AwardExpirationDate>
<AwardTotalIntnAmount>70729.00</AwardTotalIntnAmount>
<AwardAmount>70729</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Virtual reality (VR) aims to perceptually place the user in an artificial world through computer-generated sight and sound.  VR thus offers a new human-computer interaction paradigm which can improve the user's understanding of and interaction with 3D information spaces in diverse applications domains such as design, data visualization, training, education, and medicine.  Stereoscopic VR systems generate imagery by presenting a separate perspective image to each eye.  As a result, the user perceives a single, true 3D image that appears to exist in front of and behind the physical display surface.  While stereoscopic display is an important and common feature in VR systems, further research is needed because stereoscopic viewing raises concerns beyond those raised in monoscopic VR systems as the user travels through and manipulates the virtual environment.  This is especially true for extended virtual environments where the scene contains rendered geometric detail at scales covering several orders of magnitude.  In such environments, users need to zoom in and out to move between detailed and global views.  This project will investigate techniques for maintaining good stereoscopic viewing conditions under such conditions.  The PIs will focus on stereoscopic Head-Tracked Display systems such as the virtual workbench (as distinguished from head-mounted displays in which the display surface is mounted on the user's head).  The expected impact of this project will be better understanding and implementations of head-tracked displays based on a thorough geometric and analytic analysis of false eye separation and head-tracking distortions; new and improved techniques for automatic view optics adjustments and automatic view position adjustments to maintain good stereoscopic viewing conditions; and a systematic study of the compatibility between the above methods and the relevant geometric attributes of VR applications.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>05/27/2003</MinAmdLetterDate>
<MaxAmdLetterDate>05/27/2003</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0332923</AwardID>
<Investigator>
<FirstName>Larry</FirstName>
<LastName>Hodges</LastName>
<EmailAddress>lfh@clemson.edu</EmailAddress>
<StartDate>05/27/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of North Carolina at Charlotte</Name>
<CityName>CHARLOTTE</CityName>
<ZipCode>282230001</ZipCode>
<PhoneNumber>7046871888</PhoneNumber>
<StreetAddress>9201 University City Boulevard</StreetAddress>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6845</Code>
<Text>HUMAN COMPUTER INTER PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
