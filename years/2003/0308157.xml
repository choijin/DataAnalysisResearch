<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Interactive Multisensory Modeling of Physical Objects</AwardTitle>
<AwardEffectiveDate>07/01/2003</AwardEffectiveDate>
<AwardExpirationDate>06/30/2007</AwardExpirationDate>
<AwardTotalIntnAmount>249979.00</AwardTotalIntnAmount>
<AwardAmount>249979</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Daniel F. DeMenthon</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Robotics and Human Augmentation Program&lt;br/&gt;&lt;br/&gt;ABSTRACT&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Proposal #: 308157&lt;br/&gt;Title: Interactive Multisensory Modeling of Physical Objects&lt;br/&gt;PI: Pai, Dinesh&lt;br/&gt;Rutgers Univ New Brunswick&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;We will investigate techniques for easy and interactive construction of high quality multisensory computer models of real, physical objects.  By multisensory models we mean models that are capable of supporting multisensory interaction, supporting not only simulation of the appearance of an object but also its physical response, including associated forces and sounds.  Because human interaction with the physical world is inherently multisensory, people will be able to effortlessly combine information from vision, hearing, and touch to manipulate such computer models.&lt;br/&gt;&lt;br/&gt;Specifically, we propose to develop an integrated environment with excellent conditions for interactive modeling by humans. We will explore new techniques to make the  modeling task extremely easy, by providing rapid feedback about the state of the model, developing novel sensing and display systems, and developing software tools to plan and generalize measurements.  We will use these techniques to interactively create multisensory models of contact.&lt;br/&gt; &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>05/05/2003</MinAmdLetterDate>
<MaxAmdLetterDate>06/08/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0308157</AwardID>
<Investigator>
<FirstName>Dinesh</FirstName>
<LastName>Pai</LastName>
<EmailAddress>dpai@cs.rutgers.edu</EmailAddress>
<StartDate>05/05/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rutgers University New Brunswick</Name>
<CityName>Piscataway</CityName>
<ZipCode>088543925</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress>33 Knightsbridge Road</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7339</Code>
<Text>COMPUTER VISION</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
