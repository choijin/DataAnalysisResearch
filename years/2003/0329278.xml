<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Relational Reinforcement Learning</AwardTitle>
<AwardEffectiveDate>09/01/2003</AwardEffectiveDate>
<AwardExpirationDate>08/31/2007</AwardExpirationDate>
<AwardTotalIntnAmount>411602.00</AwardTotalIntnAmount>
<AwardAmount>411602</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Kenneth Whang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project develops new algorithms, programs, and theory for Relational Reinforcement Learning. Reinforcement Learning  (RL) seeks to design and build intelligent programs that optimize their behavior by taking actions and receiving reinforcement or feedback from the environment. Current research in RL is focused mainly on problem domains where the environmental states are represented as vectors of propositions. Many real world domains such as logistics planning, information extraction, and semantic information retrieval from the Web require relational representations and are not amenable to propositional learning methods. This project develops methods to solve reinforcement learning problems in such domains by extending to the relational setting techniques such as hierarchical learning, building and exploiting models of the world, learning compact representations of value functions and policies, and combining planning with learning. &lt;br/&gt;&lt;br/&gt;The broader impacts of the project include discovery of more general and effective reinforcement learning algorithms, development of new heuristics to solve logistics planning problems, and more effective ways to interact with the Web to retrieve useful information. &lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/21/2003</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0329278</AwardID>
<Investigator>
<FirstName>Prasad</FirstName>
<LastName>Tadepalli</LastName>
<EmailAddress>tadepall@eecs.orst.edu</EmailAddress>
<StartDate>08/21/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Oregon State University</Name>
<CityName>Corvallis</CityName>
<ZipCode>973318507</ZipCode>
<PhoneNumber>5417374933</PhoneNumber>
<StreetAddress>OREGON STATE UNIVERSITY</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Oregon</StateName>
<StateCode>OR</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
