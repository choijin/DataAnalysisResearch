<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: ASSISTED NAVIGATION IN DYNAMIC AND COMPLEX ENVIRONMENTS</AwardTitle>
<AwardEffectiveDate>02/01/2004</AwardEffectiveDate>
<AwardExpirationDate>02/28/2011</AwardExpirationDate>
<AwardTotalIntnAmount>496836.00</AwardTotalIntnAmount>
<AwardAmount>549204</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>In this project, the PI will develop a System for Assisted Navigation of Dynamic and Complex Environments (SANDEE) that will significantly increase navigation effectiveness for the visually impaired in dynamic and complex indoor and outdoor environments.  Specific goals are: To develop new localization, orientation, and wayfinding algorithms; To develop new sensor fusion algorithms; To design lightweight wearable wayfinding toolkits for the visually impaired; To design multi-modal communication interfaces; To test the technology on the target population of visually impaired users; And to mentor and train young scientists in assistive technology research..  Critical aspects of navigation effectiveness will be systematically evaluated through longitudinal user studies.&lt;br/&gt;&lt;br/&gt;This project will significantly advance our understanding of: localization, orientation, and wayfinding; audio representation of environments; sensor fusion; multi-modal user interfaces; and pervasive computing.  Current navigation technologies can be quite error-prone and inflexible due to their tendency to rely on one type of sensor.  The PI's premise is that in many environments exploiting a broad range of sensor types will lead to superior navigation effectiveness.  Current navigation technologies require that the user commit to a specific communication model.  The PI expects to show that multi-modal communication interfaces reduce the user's navigation-related cognitive load, and allow him/her to add intelligence to the system dynamically.  Existing navigation technologies for the visually impaired rely on body sensors, or sensors embedded in the environment.  This project will demonstrate that, in unfamiliar indoor environments, better navigation effectiveness and user satisfaction are achieved through the use of mobile robotic guides.  To achieve these objectives, a particularly challenging tasks the PI will address include the design and implementation of robust localization, orientation, and wayfinding algorithms that integrate information from multiple sensors, the design and development of multi-modal communication interfaces, and the evaluation of the human ability to learn and adjust critical aspects of the system and to use the system on a continuous basis.&lt;br/&gt;&lt;br/&gt;Broader Impact: This project will develop new assistive technology for the visually impaired. Individuals with vision loss will be included in this project at all stages, both as researchers and as participants in longitudinal evaluation studies. Both undergraduate and graduate students will be involved in the PI's research activities, and the findings will be integrated into the university coursework.  Software and hardware innovations resulting from this research will be documented and, in the case of software, distributed over the Internet to the target population, the scientific community, and the general public.</AbstractNarration>
<MinAmdLetterDate>02/02/2004</MinAmdLetterDate>
<MaxAmdLetterDate>01/11/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0346880</AwardID>
<Investigator>
<FirstName>Vladimir</FirstName>
<LastName>Kulyukin</LastName>
<EmailAddress>vladimir.kulyukin@usu.edu</EmailAddress>
<StartDate>02/02/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Utah State University</Name>
<CityName>Logan</CityName>
<ZipCode>843221415</ZipCode>
<PhoneNumber>4357971226</PhoneNumber>
<StreetAddress>Sponsored Programs Office</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Utah</StateName>
<StateCode>UT</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>6846</Code>
<Text>UNIVERSAL ACCESS</Text>
</ProgramElement>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<ProgramReference>
<Code>SMET</Code>
<Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
