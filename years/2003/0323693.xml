<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Feedback Control of Visual Appearance With Maximally Sensitive Sensors for Decentralized Event Detection and Security</AwardTitle>
<AwardEffectiveDate>08/15/2003</AwardEffectiveDate>
<AwardExpirationDate>07/31/2007</AwardExpirationDate>
<AwardTotalIntnAmount>256101.00</AwardTotalIntnAmount>
<AwardAmount>256101</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Radhakisan Baheti</SignBlockName>
</ProgramOfficer>
<AbstractNarration>&lt;br/&gt;In many surveillance problems, one would use several c.c.d. (charged coupled device) cameras&lt;br/&gt;connected in a network, that would generate a stream of images. The problem is to process the&lt;br/&gt;image stream so as to detect a typical event in the scene from the observed recording of the image&lt;br/&gt;sequences. Such an event might be quantified, for example, by a sudden movement in the scene or&lt;br/&gt;existence of an unfamiliar target. Difficulty in identifying an event is that the 'event characteristic'&lt;br/&gt;is hard to quantify and extracted from the complex scene imagery, a process that would typically&lt;br/&gt;required to be done in real time. Additional difficulty arises from the fact that a single view of the&lt;br/&gt;scene may not be enough to isolate an event - hence the need for multiple view over an interval of&lt;br/&gt;time.&lt;br/&gt;We propose that every visual stream be quantified and represented locally by an internal dy-namic&lt;br/&gt;model that produces its own spatiotemporal sequence. The importance of this internal repre-sentation&lt;br/&gt;is that it does not represent the entire scene, or all the events in the scene. Rather, its sole&lt;br/&gt;purpose is to amplify specific intruding event anywhere in the scene and to respond as to 'when'&lt;br/&gt;and 'where' it has occurred. The design problem that we propose to investigate is to synthesize&lt;br/&gt;the internal dynamics so as to respond 'maximally' in presence of an intruding event as opposed&lt;br/&gt;to somewhat more routine events. The internal dynamics would be implemented on a processor&lt;br/&gt;locally connected to the sensor and in its simplest form would be a directionally selective flow&lt;br/&gt;model with inputs from the scene images taken by the camera. The model parameters are tuned&lt;br/&gt;to respond to specific events in the scene. In order to be able to synthesize the above described&lt;br/&gt;'maximally sensitive sensor', we subdivide this project into three distinct parts.&lt;br/&gt;The first is to introduce 'appearance models' to represent a sequence of images taken by a&lt;br/&gt;camera. Such an appearance model results in a suitable data-compression and is particularly useful&lt;br/&gt;when a suitable set of appearances have to be isolated and detected in the scene. Our second goal&lt;br/&gt;is to introduce a suitable internal representation of the observed spatiotemporal signal using 'flow&lt;br/&gt;models'. The proposed flow models have flow velocities that are dependant on the direction of&lt;br/&gt;propagation and can be altered by the magnitude and position of the input target events. The flow&lt;br/&gt;models can be tuned by feedback to produce maximal activity to selected targets in the scene. Our&lt;br/&gt;third goal is to network a distributed set of cameras, together with associated internal models, for&lt;br/&gt;distributed detection. The model activity from each camera sensor, confirming detection of a local&lt;br/&gt;event, is fused together in order to detect a spatio-temporal global event.&lt;br/&gt;The intellectual merits of this project are described as follows. The first is Selective Encoding&lt;br/&gt;of the Spatio-Temporal Events in the Scene through Appearance Models. The second is Internal&lt;br/&gt;Modelling and Feedback Tuning for Maximal Response. Finally the third is Decentralized Detec-tion&lt;br/&gt;and Feedback Control of the Network Structure.&lt;br/&gt;Broader impact of the proposal includes interaction between Signal Processing, Sensor Based&lt;br/&gt;Control and Sensor Networks. Feedback control for sensor tuning and network reconfiguration are&lt;br/&gt;two research areas that this proposal makes the most impact.&lt;br/&gt;The project would be carried out by the PI with 2 PhD students at the Center for BioCybernetics&lt;br/&gt;and Intelligent Systems and would also provide an interdisciplinary training ground for senior&lt;br/&gt;undergraduates from Computer Science, Electrical and Systems Engineering.</AbstractNarration>
<MinAmdLetterDate>08/07/2003</MinAmdLetterDate>
<MaxAmdLetterDate>08/07/2003</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0323693</AwardID>
<Investigator>
<FirstName>Bijoy</FirstName>
<LastName>Ghosh</LastName>
<EmailAddress>bijoy.ghosh@ttu.edu</EmailAddress>
<StartDate>08/07/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Washington University</Name>
<CityName>Saint Louis</CityName>
<ZipCode>631304862</ZipCode>
<PhoneNumber>3147474134</PhoneNumber>
<StreetAddress>CAMPUS BOX 1054</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
</Institution>
<FoaInformation>
<Code>0112000</Code>
<Name>System Theory</Name>
</FoaInformation>
<ProgramElement>
<Code>1519</Code>
<Text>INTEGRATIVE SYSTEMS</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>7238</Code>
<Text>ENG ITR CORE ACTIVITIES</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
