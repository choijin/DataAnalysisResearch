<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Hierarchal Perceptual Organization with the Center-Surround Algorithm</AwardTitle>
<AwardEffectiveDate>09/01/2003</AwardEffectiveDate>
<AwardExpirationDate>08/31/2007</AwardExpirationDate>
<AwardTotalIntnAmount>500000.00</AwardTotalIntnAmount>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Daniel F. DeMenthon</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Robotics and Computer Vision Program&lt;br/&gt;&lt;br/&gt;ABSTRACT&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Proposal #: 0329156&lt;br/&gt;Title: Hierarchal Perceptual Organization with the Center-Surround Algorithm&lt;br/&gt;PI: Siskind, Jeffery&lt;br/&gt;Purdue University&lt;br/&gt;&lt;br/&gt;The objective of this research is to develop a general analytic and algorithmic framework for multidimensional context-free grammars (PCFG) that can be used to model the hierarchical structure of images and other multidimensional data sets. This framework extends the notions of PCFGs from 1D word strings to 2D image data and similarly extends the inside-outside algorithm to support training, classification, and parsing on 2D image data with these extended PCFGs. The extended framework is called spatial random trees (SRTs) and the extended algorithm the center-surround algorithm. The framework is both sound and efficient because of a novel notion of constituency that constrains the allowable ways to partition a parent segment into child subsegments during parsing. &lt;br/&gt;This research has great intellectual merit because it forms a fundamental basis for:&lt;br/&gt; Inferring semantically meaningful hierarchal structure from low-level image properties such as edge saliency and region shape, color, texture, and relative position.&lt;br/&gt; Discovering the common hierarchal structure shared by a collection of natural images in an unsupervised fashion from unlabeled training data.&lt;br/&gt; Distinguishing between different natural image-scene classes on the basis of global hierarchal structure, rather than local low-level features. &lt;br/&gt;This research will achieve broad impact by addressing a problem that is shared among a wide array of applications in a variety of technical fields. In particular, we will:&lt;br/&gt; Extend the SRT framework so that it can be used to accurately model the geometric relations between constituents in hierarchal structures. This will enhance the value of SRTs in high-level modeling of images.&lt;br/&gt; Develop tools for combining SRT models and merging SRT models with other available data models. This will provide a general framework for both improved speed and accuracy of the methods.&lt;br/&gt; Explore the use of SRTs as a distance metric for classifying high-dimensional data. This opens the techniques to potential applications such as Web clustering. &lt;br/&gt; Develop a unified approach to combined spatial and temporal parsing of video. These new methods can support both video indexing and surveillance tasks. &lt;br/&gt; Develop novel approaches for the parsing and recognition of images. This can be useful in applications such as the analysis of printed information, the monitoring of surveillance video, or the analysis of medical imagery.&lt;br/&gt;The research team includes researchers who bring to our project, expertise from a wide variety of different fields including computational linguistics, machine vision, inverse problems, stochastic processes, and natural language processing. This broad background allows the team to collectively leverage ideas from multiple fields and have broad impact on these fields in a way that would not be possible without such collaboration. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>07/10/2003</MinAmdLetterDate>
<MaxAmdLetterDate>06/10/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0329156</AwardID>
<Investigator>
<FirstName>Charles</FirstName>
<LastName>Bouman</LastName>
<EmailAddress>bouman@purdue.edu</EmailAddress>
<StartDate>07/10/2003</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ilya</FirstName>
<LastName>Pollak</LastName>
<EmailAddress>ipollak@ecn.purdue.edu</EmailAddress>
<StartDate>07/10/2003</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Siskind</LastName>
<EmailAddress>qobi@purdue.edu</EmailAddress>
<StartDate>07/10/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramElement>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramElement>
<Code>7339</Code>
<Text>COMPUTER VISION</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>9139</Code>
<Text>INFORMATION INFRASTRUCTURE &amp; TECH APPL</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
