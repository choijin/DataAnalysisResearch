<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Transductive Learning for Retrieving and Mining Visual Contents</AwardTitle>
<AwardEffectiveDate>09/01/2003</AwardEffectiveDate>
<AwardExpirationDate>05/31/2008</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>281702</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Contemporary visual learning methods for visual content mining tasks are plagued by several critical and fundamental challenges: (1) the unavailability of large annotated datasets prevents effective supervised learning;  (2) the variability in different working environments challenges the generalization of inductive learning  approaches; and (3) the high-dimensionality of these tasks confronts the efficiency of many existing learning  techniques. The goal of this research project is to overcome these challenges by exploring a novel transductive  learning approach.&lt;br/&gt;&lt;br/&gt;The approach provides a unified framework accommodating four subtasks: (1) transduction that integrates unlabelled  and labeled data to alleviate the challenge of limited supervision and to enable automatic annotation&lt;br/&gt; propagation; (2) model transduction that automatically adapts a learned model to untrained environments for&lt;br/&gt; efficient model reuse; (3) co-transduction that facilitates transduction with multi-modalities to handle&lt;br/&gt; high-dimensionality in visual data; and (4) co-inference that exploits the interactions among multiple modalities to enable efficient model transduction.&lt;br/&gt;&lt;br/&gt;The research is linked to educational activities including the development of an integrated course of&lt;br/&gt; content-based visual data mining and the development of innovative course projects to engage students in&lt;br/&gt;research. The project disseminates research to other research communities through organizing workshops and tutorials, and to the general public, minority groups and woman students through creating Open House events.&lt;br/&gt;&lt;br/&gt;The results of this project will lead to significant improvement on the quality of content-based and object-level multimedia retrieval, will greatly benefit visual recognition that requires large datasets for training and evaluation, will significantly reduce the efforts of training brand new models for un-trained scenarios, and will be very useful in intelligent video surveillance applications thus having a great impact on homeland security. A website, http://www.ece.nwu.edu/~yingwu, contains research results, including demos, constructed benchmark datasets and software can be accessed.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/26/2003</MinAmdLetterDate>
<MaxAmdLetterDate>04/29/2008</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0308222</AwardID>
<Investigator>
<FirstName>Ying</FirstName>
<LastName>Wu</LastName>
<EmailAddress>yingwu@eecs.northwestern.edu</EmailAddress>
<StartDate>08/26/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Northwestern University</Name>
<CityName>Chicago</CityName>
<ZipCode>606114579</ZipCode>
<PhoneNumber>3125037955</PhoneNumber>
<StreetAddress>750 N. Lake Shore Drive</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>6855</Code>
<Text>INFORMATION &amp; KNOWLEDGE MANAGE</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
