<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>ALGORITHM: Scalable Algorithms for Regularized Tomography via Decoupling</AwardTitle>
<AwardEffectiveDate>06/01/2003</AwardEffectiveDate>
<AwardExpirationDate>05/31/2007</AwardExpirationDate>
<AwardTotalIntnAmount>359799.00</AwardTotalIntnAmount>
<AwardAmount>359799</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
</ProgramOfficer>
<AbstractNarration>X-ray computerized tomography (CT) and related imaging modalities (e.g., PET) are notorious for their excessive computational demands.  While early CT algorithms such as filtered backprojection are now trivial in two-dimensions and scalable in three-dimensions, the more noise-resistant probabilistic methods such as regularized tomography are still prohibitive.&lt;br/&gt;&lt;br/&gt;The basic idea of regularization is to compute a smooth image whose simulated projections (line integrals) approximate the observed (but noisy) X-ray projections.  The computational expense in previous methods stems from explicitly applying a large sparse projection matrix (to compute line integrals of the image) and its transpose to enforce these smoothness and data approximation constraints during each of many iterations of the algorithm.  &lt;br/&gt;&lt;br/&gt;We propose to study a new formulation of regularized tomography in which the smoothness constraint is analytically transformed from the image to the projection domain, before any computations begin.  As a result, iterations take place entirely in the projection domain, avoiding the repeated sparse matrix-vector products.  A more surprising benefit is the decoupling of a large system of regularization equations into many small systems of simpler equations.  The computation thus becomes ``embarassingly parallel'', so that latency tolerant and ideally scalable parallel computations are possible, as our preliminary results show in 2-d.  We propose to apply this technique to modalities other than CT, to implement it in three-dimensions, and to embellish the probability models. Further, the network-friendly nature of this method will allow us to study the feasibility of harnessing the increasingly wasted desktop compute power in a typical hospital.  We see decoupled regularization as an exciting development in tomography, benefiting society by providing images to doctors, patients, and scientists with fewer artifacts, at higher resolutions, and with greater interactivity.&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/18/2003</MinAmdLetterDate>
<MaxAmdLetterDate>03/01/2005</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0305719</AwardID>
<Investigator>
<FirstName>Takeo</FirstName>
<LastName>Kanade</LastName>
<EmailAddress>kanade@cs.cmu.edu</EmailAddress>
<StartDate>04/18/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<FoaInformation>
<Code>0000099</Code>
<Name>Other Applications NEC</Name>
</FoaInformation>
<ProgramElement>
<Code>4080</Code>
<Text>ADVANCED COMP RESEARCH PROGRAM</Text>
</ProgramElement>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
