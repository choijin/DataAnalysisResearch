<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Neural Bases of Speech Perception in Human Auditory Cortex</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2004</AwardEffectiveDate>
<AwardExpirationDate>09/30/2006</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>136983</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040500</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Douglas H. Whalen</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration>Speech perception is one of our most important skills - something we spend a great deal of time acquiring as children and that is of the utmost importance in social interactions. It is also one of the skills commonly affected by strokes, as well as by hearing loss. Speech perception is characterized by considerable flexibility and robustness - we can understand speakers in noisy environments, and we can cope with wide variations in the speaker's mood and accent, all of which affect the nature of the speech signal we need to decode. With support from the National Science Foundation, Dr. Josef Rauschecker seeks answers to these and related questions. His studies will help to transfer knowledge gained from animal models toward the understanding of higher cognitive processes of speech and language perception in humans. The notions of hierarchical networks, processing streams, and higher-order computational maps have been used successfully in animal research on complex visual and auditory perception. Dr. Rauschecker will perform analogous investigations directly in humans using noninvasive, high-resolution functional magnetic resonance imaging (fMRI) to determine activation of auditory cortices by speech and speech-like sounds. Using high-field fMRI the studies will not only determine the location of cortical areas activated by natural and synthetic speech sounds, as opposed to other sounds with similar complexity, but also reveal detailed organizational principles of higher-order acoustic-phonetic feature maps within human auditory and language cortex. The studies will provide a wealth of new information in the under-researched field of higher auditory pathways in humans as well as insight into general organizational principles of functional architecture in cortical processing.&lt;br/&gt;&lt;br/&gt;A better understanding of the neural basis of speech perception has potential broader impacts on clinical issues such as recovery from aphasic stroke, as well as on educational neuroscience. This research could have impacts for understanding second language learning and the development of multilingual children. The broader impacts of this project include opportunities for hands-on research experience of undergraduate and graduate students in Cognitive Science as well as Neuroscience. This direct immersion into ongoing research will lead to tighter integration of teaching and research. The funded project will enhance the infrastructure for research at Georgetown University and help support two formal training programs offered at GU. The project will strive to further increase the number of minority students at all levels. It will broadly disseminate the results of its research through publications and public databases to scientific as well as lay audiences thus enhancing scientific understanding by the public&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>04/05/2004</MinAmdLetterDate>
<MaxAmdLetterDate>05/23/2006</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0350041</AwardID>
<Investigator>
<FirstName>Josef</FirstName>
<LastName>Rauschecker</LastName>
<PI_MID_INIT>P</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Josef P Rauschecker</PI_FULL_NAME>
<EmailAddress>rauschej@georgetown.edu</EmailAddress>
<PI_PHON>2026878842</PI_PHON>
<NSF_ID>000233003</NSF_ID>
<StartDate>04/05/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgetown University</Name>
<CityName>Washington</CityName>
<ZipCode>200571789</ZipCode>
<PhoneNumber>2026250100</PhoneNumber>
<StreetAddress>37th &amp; O St N W</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DC00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049515844</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>GEORGETOWN UNIVERSITY (THE)</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049515844</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgetown University]]></Name>
<CityName>Washington</CityName>
<StateCode>DC</StateCode>
<ZipCode>200571789</ZipCode>
<StreetAddress><![CDATA[37th &amp; O St N W]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DC00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1397</Code>
<Text>Cross-Directorate  Activities</Text>
</ProgramElement>
<ProgramElement>
<Code>1699</Code>
<Text>Cognitive Neuroscience</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>7266</Code>
<Text>ENHANCING HUMAN PERFORMANCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9232</Code>
<Text>RES OPPOR AWARDS(ROA) (SUPPLEM</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0104</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0105</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>490100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2004~111984</FUND_OBLG>
<FUND_OBLG>2005~24999</FUND_OBLG>
</Award>
</rootTag>
