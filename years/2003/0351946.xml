<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RUI:   Experimental Investigations of Value Elicitation Mechanisms</AwardTitle>
<AwardEffectiveDate>04/01/2004</AwardEffectiveDate>
<AwardExpirationDate>03/31/2008</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>62486</AwardAmount>
<AwardInstrument>
<Value>Interagency Agreement</Value>
</AwardInstrument>
<Organization>
<Code>04050100</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jacqueline Meszaros</SignBlockName>
</ProgramOfficer>
<AbstractNarration>To make sound public policy decisions it is critical that policy makers understand the values consumers assign to those things policies will impact. Surveys using hypothetical referendum questions are sometimes used to collect the information used to estimate these values.  Research indicates that if consumers respond to the survey as if they were participating in a real referendum vote, the survey will result in unbiased estimates of consumer values.  However, surveys that contains multiple referendum questions and surveys in which voters believe they have an opportunity to influence government policy at no cost, generate biased estimate of consumer values.  It is important to understand both the nature and source of this bias as well as how to mitigate it in order to generate accurate benefits estimates for public policy making.  This study will investigate these questions for three different survey mechanisms: the double referendum mechanism, the choice experiment mechanism, and an incentive compatible mechanism.  The study will also include an investigation of the role that ill-defined consumer preferences plays in generating biases in survey responses.&lt;br/&gt;&lt;br/&gt;This research will use the tools of experimental economics to test for the nature and source of biases in the survey mechanisms described above.  The results of this study will shed light on how the incentive structures of these alternative survey designs affect the reliability of the resulting benefits estimates.  Such information will allow researchers and policy analysts to design instruments when can generate improved benefits estimates for policy-making purposes.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>03/19/2004</MinAmdLetterDate>
<MaxAmdLetterDate>04/26/2007</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0351946</AwardID>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Silz Carson</LastName>
<EmailAddress>Kate.Carson@usafa.edu</EmailAddress>
<StartDate>03/19/2004</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>United States Air Force Academy</Name>
<CityName>USAF Academy</CityName>
<ZipCode>808406208</ZipCode>
<PhoneNumber>7193334195</PhoneNumber>
<StreetAddress>2354 Fairchild Dr Ste 2h29</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Colorado</StateName>
<StateCode>CO</StateCode>
</Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>1321</Code>
<Text>Decision, Risk &amp; Mgmt Sci</Text>
</ProgramElement>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>1094</Code>
<Text>POLICY SCIENCES</Text>
</ProgramReference>
<ProgramReference>
<Code>9178</Code>
<Text>UNDERGRADUATE EDUCATION</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>9278</Code>
<Text>HUMAN DIMENSIONS OF GLOBAL CHANGE</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
</Award>
</rootTag>
