<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SGER:      Exploring New Auditory Perception Based Approaches to ASR</AwardTitle>
<AwardEffectiveDate>09/01/2003</AwardEffectiveDate>
<AwardExpirationDate>08/31/2005</AwardExpirationDate>
<AwardTotalIntnAmount>99485.00</AwardTotalIntnAmount>
<AwardAmount>99485</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>In the last two decades, automatic speech recognition (ASR) has been addressed using a pattern matching paradigm with a top-down characterization of acoustic, pronunciation, and language models as an integrated finite state network.  Although there have been significant advances over the years, the progress has begun to slow recently; however, the current state-of-the-state has yet to rival human speech recognition capability. This is mainly due to: (1) the inability to obtain a complete specification of all the knowledge sources needed to solve the ASR problem in a top-down manner, and (2) the ASR robustness problem.  &lt;br/&gt;&lt;br/&gt;This project is developing and evaluating an auditory perception approach to ASR that is both knowledge-based and data-driven.  By decomposing the ASR problem into detection of acoustic and phonetic landmarks in the speech signal followed by a sequence of spectral and temporal knowledge integration stages, the proposed approach mimics the human auditory perception process while retaining many of the key features in stochastic modeling of speech and language that have contributed to the success of the currently prevailing pattern matching approaches.  The project is investigating the feasibility of feature detection and knowledge integration algorithms that are foundational to the approach and is creating a plug-and-play platform to facilitate cooperation between broad speech science and speech processing communities.  &lt;br/&gt;&lt;br/&gt;This research should facilitate a better understanding of the link between auditory perception and ASR, provide educational opportunities to students and researchers to better understand speech fundamentals, challenge the signal processing community to develop new speech feature detection algorithms, and pave the way for a common software and evaluation platform to facilitate collaborative ASR research.&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/20/2003</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2004</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>0350408</AwardID>
<Investigator>
<FirstName>Chin-Hui</FirstName>
<LastName>Lee</LastName>
<EmailAddress>chl@ece.gatech.edu</EmailAddress>
<StartDate>08/20/2003</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
</Institution>
<FoaInformation>
<Code>0104000</Code>
<Name>Information Systems</Name>
</FoaInformation>
<ProgramElement>
<Code>7274</Code>
<Text>HUMAN LANGUAGE &amp; COMMUNICATION</Text>
</ProgramElement>
<ProgramReference>
<Code/>
<Text/>
</ProgramReference>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>9237</Code>
<Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
</Award>
</rootTag>
